Title,Abstract,Keywords
Front-End Factor Analysis for Speaker Verification,"This paper presents an extension of our previous work which proposes a new speaker representation for speaker verification. In this modeling, a new low-dimensional speaker- and channel-dependent space is defined using a simple factor analysis. This space is named the total variability space because it models both speaker and channel variabilities. Two speaker verification systems are proposed which use this new representation. The first system is a support vector machine-based system that uses the cosine kernel to estimate the similarity between the input data. The second system directly uses the cosine similarity as the final decision score. We tested three channel compensation techniques in the total variability space, which are within-class covariance normalization (WCCN), linear discriminate analysis (LDA), and nuisance attribute projection (NAP). We found that the best results are obtained when LDA is followed by WCCN. We achieved an equal error rate (EER) of 1.12% and MinDCF of 0.0094 using the cosine distance scoring on the male English trials of the core condition of the NIST 2008 Speaker Recognition Evaluation dataset. We also obtained 4% absolute EER improvement for both-gender trials on the 10 s-10 s condition compared to the classical joint factor analysis scoring.","Support vector machines,
Kernel,
Testing,
Linear discriminant analysis,
NIST,
Speaker recognition,
Permission,
Natural languages,
Speech analysis,
Context modeling"
The NumPy Array: A Structure for Efficient Numerical Computation,"In the Python world, NumPy arrays are the standard representation for numerical data and enable efficient implementation of numerical computations in a high-level language. As this effort shows, NumPy performance can be improved through three techniques: vectorizing calculations, avoiding copying data in memory, and minimizing operation counts.","Arrays,
Numerical analysis,
Performance evaluation,
Computational efficiency,
Finite element methods,
Vector quantization,
Resource management"
"Analysis, Experimental Results, and Range Adaptation of Magnetically Coupled Resonators for Wireless Power Transfer","Wireless power technology offers the promise of cutting the last cord, allowing users to seamlessly recharge mobile devices as easily as data are transmitted through the air. Initial work on the use of magnetically coupled resonators for this purpose has shown promising results. We present new analysis that yields critical insight into the design of practical systems, including the introduction of key figures of merit that can be used to compare systems with vastly different geometries and operating conditions. A circuit model is presented along with a derivation of key system concepts, such as frequency splitting, the maximum operating distance (critical coupling), and the behavior of the system as it becomes undercoupled. This theoretical model is validated against measured data and shows an excellent average coefficient of determination of 0.9875. An adaptive frequency tuning technique is demonstrated, which compensates for efficiency variations encountered when the transmitter-to-receiver distance and/or orientation are varied. The method demonstrated in this paper allows a fixed-load receiver to be moved to nearly any position and/or orientation within the range of the transmitter and still achieve a near-constant efficiency of over 70% for a range of 0-70 cm.",
Energy Harvesting Sensor Nodes: Survey and Implications,"Sensor networks with battery-powered nodes can seldom simultaneously meet the design goals of lifetime, cost, sensing reliability and sensing and transmission coverage. Energy-harvesting, converting ambient energy to electrical energy, has emerged as an alternative to power sensor nodes. By exploiting recharge opportunities and tuning performance parameters based on current and expected energy levels, energy harvesting sensor nodes have the potential to address the conflicting design goals of lifetime and performance. This paper surveys various aspects of energy harvesting sensor systems- architecture, energy sources and storage technologies and examples of harvesting-based nodes and applications. The study also discusses the implications of recharge opportunities on sensor node operation and design of sensor network solutions.","Batteries,
Costs,
Monitoring,
Energy storage,
Computer networks,
Routing protocols,
Energy states,
Sensor systems and applications,
Collaboration,
Embedded computing"
A Distributed Numerical Approach to Interference Alignment and Applications to Wireless Interference Networks,"Recent results establish the optimality of interference alignment to approach the Shannon capacity of interference networks at high SNR. However, the extent to which interference can be aligned over a finite number of signalling dimensions remains unknown. Another important concern for interference alignment schemes is the requirement of global channel knowledge. In this work, we provide examples of iterative algorithms that utilize the reciprocity of wireless networks to achieve interference alignment with only local channel knowledge at each node. These algorithms also provide numerical insights into the feasibility of interference alignment that are not yet available in theory.","Transmitters,
Signal to noise ratio,
Interference channels,
Iterative methods,
Receiving antennas"
Wireless Network Information Flow: A Deterministic Approach,"In a wireless network with a single source and a single destination and an arbitrary number of relay nodes, what is the maximum rate of information flow achievable? We make progress on this long standing problem through a two-step approach. First, we propose a deterministic channel model which captures the key wireless properties of signal strength, broadcast and superposition. We obtain an exact characterization of the capacity of a network with nodes connected by such deterministic channels. This result is a natural generalization of the celebrated max-flow min-cut theorem for wired networks. Second, we use the insights obtained from the deterministic analysis to design a new quantize-map-and-forward scheme for Gaussian networks. In this scheme, each relay quantizes the received signal at the noise level and maps it to a random Gaussian codeword for forwarding, and the final destination decodes the source's message based on the received signal. We show that, in contrast to existing schemes, this scheme can achieve the cut-set upper bound to within a gap which is independent of the channel parameters. In the case of the relay channel with a single relay as well as the two-relay Gaussian diamond network, the gap is 1 bit/s/Hz. Moreover, the scheme is universal in the sense that the relays need no knowledge of the values of the channel parameters to (approximately) achieve the rate supportable by the network. We also present extensions of the results to multicast networks, half-duplex networks, and ergodic networks.","Relays,
Wireless networks,
Noise level,
Receivers,
Noise,
Channel models"
Compute-and-Forward: Harnessing Interference Through Structured Codes,"Interference is usually viewed as an obstacle to communication in wireless networks. This paper proposes a new strategy, compute-and-forward, that exploits interference to obtain significantly higher rates between users in a network. The key idea is that relays should decode linear functions of transmitted messages according to their observed channel coefficients rather than ignoring the interference as noise. After decoding these linear equations, the relays simply send them towards the destinations, which given enough equations, can recover their desired messages. The underlying codes are based on nested lattices whose algebraic structure ensures that integer combinations of codewords can be decoded reliably. Encoders map messages from a finite field to a lattice and decoders recover equations of lattice points which are then mapped back to equations over the finite field. This scheme is applicable even if the transmitters lack channel state information.","Relays,
Equations,
Lattices,
Transmitters,
Mathematical model,
AWGN,
Encoding"
Differential Evolution With Composite Trial Vector Generation Strategies and Control Parameters,"Trial vector generation strategies and control parameters have a significant influence on the performance of differential evolution (DE). This paper studies whether the performance of DE can be improved by combining several effective trial vector generation strategies with some suitable control parameter settings. A novel method, called composite DE (CoDE), has been proposed in this paper. This method uses three trial vector generation strategies and three control parameter settings. It randomly combines them to generate trial vectors. CoDE has been tested on all the CEC2005 contest test instances. Experimental results show that CoDE is very competitive.","Convergence,
Search problems,
Optimization,
Robustness,
Encoding,
Space exploration,
Equations"
Achieving Controllability of Electric Loads,"This paper discusses conceptual frameworks for actively involving highly distributed loads in power system control actions. The context for load control is established by providing an overview of system control objectives, including economic dispatch, automatic generation control, and spinning reserve. The paper then reviews existing initiatives that seek to develop load control programs for the provision of power system services. We then discuss some of the challenges to achieving a load control scheme that balances device-level objectives with power system-level objectives. One of the central premises of the paper is that, in order to achieve full responsiveness, direct load control (as opposed to price response) is required to enable fast time scale, predictable control opportunities, especially for the provision of ancillary services such as regulation and contingency reserves. Centralized, hierarchical, and distributed control architectures are discussed along with benefits and disadvantages, especially in relation to integration with the legacy power system control architecture. Implications for the supporting communications infrastructure are also considered. Fully responsive load control is illustrated in the context of thermostatically controlled loads and plug-in electric vehicles.","Generators,
Power system economics,
Load flow control,
Economics,
Load modeling,
Electricity supply industry"
Reduced Switching-Frequency Modulation and Circulating Current Suppression for Modular Multilevel Converters,"This paper describes a modified phase-shifted carrier-based pulsewidth-modulation (PSC-PWM) scheme for modular multilevel converters (MMC). In order to reduce the average device switching frequency, a reduced switching-frequency (RSF) voltage balancing algorithm is developed. This paper also proposes a circulating current suppressing controller (CCSC) to minimize the inner circulating current in an MMC. Based on the double line-frequency, negative-sequence rotational frame, the three-phase alternative circulating currents are decomposed into two dc components and are minimized by a pair of proportional integral controllers. Simulation results based on a detailed PSCAD/EMTDC model prove the effectiveness of the modified PSC-PWM method and the RSF voltage-balancing algorithm. The proposed CCSC not only eliminates the inner circulating current but also improves the quality of the converter ac output voltage. A simple loss evaluation demonstrates that the RSF voltage-balancing algorithm and the CCSC reduce the converter power losses.","Switches,
Converters,
Capacitors,
Switching frequency,
Voltage control,
Pulse width modulation"
A large-scale hierarchical multi-view RGB-D object dataset,"Over the last decade, the availability of public image repositories and recognition benchmarks has enabled rapid progress in visual object category and instance detection. Today we are witnessing the birth of a new generation of sensing technologies capable of providing high quality synchronized videos of both color and depth, the RGB-D (Kinect-style) camera. With its advanced sensing capabilities and the potential for mass adoption, this technology represents an opportunity to dramatically increase robotic object recognition, manipulation, navigation, and interaction capabilities. In this paper, we introduce a large-scale, hierarchical multi-view object dataset collected using an RGB-D camera. The dataset contains 300 objects organized into 51 categories and has been made publicly available to the research community so as to enable rapid progress based on this promising technology. This paper describes the dataset collection procedure and introduces techniques for RGB-D based object recognition and detection, demonstrating that combining color and depth information substantially improves quality of results.","Cameras,
Videos,
Video sequences,
Three dimensional displays,
Visualization,
Object recognition,
Robot sensing systems"
Energy Efficiency in the Future Internet: A Survey of Existing Approaches and Trends in Energy-Aware Fixed Network Infrastructures,"The concept of energy-efficient networking has begun to spread in the past few years, gaining increasing popularity. Besides the widespread sensitivity to ecological issues, such interest also stems from economic needs, since both energy costs and electrical requirements of telcos' and Internet Service Providers' infrastructures around the world show a continuously growing trend. In this respect, a common opinion among networking researchers is that the sole introduction of low consumption silicon technologies may not be enough to effectively curb energy requirements. Thus, for disruptively boosting the network energy efficiency, these hardware enhancements must be integrated with ad-hoc mechanisms that explicitly manage energy saving, by exploiting network-specific features. This paper aims at providing a twofold contribution to green networking. At first, we explore current perspectives in power consumption for next generation networks. Secondly, we provide a detailed survey on emerging technologies, projects, and work-in-progress standards, which can be adopted in networks and related infrastructures in order to reduce their carbon footprint. The considered approaches range from energy saving techniques for networked hosts, to technologies and mechanisms for designing next-generation and energy-aware networks and networking equipment.","Energy efficiency,
IP networks,
Next generation networking,
Power generation economics,
Environmental economics,
Costs,
Web and internet services,
Silicon,
Boosting,
Hardware"
A Level Set Method for Image Segmentation in the Presence of Intensity Inhomogeneities With Application to MRI,"Intensity inhomogeneity often occurs in real-world images, which presents a considerable challenge in image segmentation. The most widely used image segmentation algorithms are region-based and typically rely on the homogeneity of the image intensities in the regions of interest, which often fail to provide accurate segmentation results due to the intensity inhomogeneity. This paper proposes a novel region-based method for image segmentation, which is able to deal with intensity inhomogeneities in the segmentation. First, based on the model of images with intensity inhomogeneities, we derive a local intensity clustering property of the image intensities, and define a local clustering criterion function for the image intensities in a neighborhood of each point. This local clustering criterion function is then integrated with respect to the neighborhood center to give a global criterion of image segmentation. In a level set formulation, this criterion defines an energy in terms of the level set functions that represent a partition of the image domain and a bias field that accounts for the intensity inhomogeneity of the image. Therefore, by minimizing this energy, our method is able to simultaneously segment the image and estimate the bias field, and the estimated bias field can be used for intensity inhomogeneity correction (or bias correction). Our method has been validated on synthetic images and real images of various modalities, with desirable performance in the presence of intensity inhomogeneities. Experiments show that our method is more robust to initialization, faster and more accurate than the well-known piecewise smooth model. As an application, our method has been used for segmentation and bias correction of magnetic resonance (MR) images with promising results.","Level set,
Image segmentation,
Nonhomogeneous media,
Minimization,
Estimation,
Imaging,
Electronic mail"
The Future Renewable Electric Energy Delivery and Management (FREEDM) System: The Energy Internet,"This paper presents an architecture for a future electric power distribution system that is suitable for plug-and-play of distributed renewable energy and distributed energy storage devices. Motivated by the success of the (information) Internet, the architecture described in this paper was proposed by the NSF FREEDM Systems Center, Raleigh, NC, as a roadmap for a future automated and flexible electric power distribution system. In the envisioned “Energy Internet,” a system that enables flexible energy sharing is proposed for consumers in a residential distribution system. The key technologies required to achieve such a vision are presented in this paper as a result of the research partnership of the FREEDM Systems Center.","Power distribution,
Power system management,
Renewable energy resources,
Power systems,
Power electronics,
Voltage control,
Fossil fuels"
Articulated pose estimation with flexible mixtures-of-parts,"We describe a method for human pose estimation in static images based on a novel representation of part models. Notably, we do not use articulated limb parts, but rather capture orientation with a mixture of templates for each part. We describe a general, flexible mixture model for capturing contextual co-occurrence relations between parts, augmenting standard spring models that encode spatial relations. We show that such relations can capture notions of local rigidity. When co-occurrence and spatial relations are tree-structured, our model can be efficiently optimized with dynamic programming. We present experimental results on standard benchmarks for pose estimation that indicate our approach is the state-of-the-art system for pose estimation, outperforming past work by 50% while being orders of magnitude faster.","Estimation,
Springs,
Computational modeling,
Humans,
Training,
Deformable models,
Joints"
Visual Odometry [Tutorial],"Visual odometry (VO) is the process of estimating the egomotion of an agent (e.g., vehicle, human, and robot) using only the input of a single or If multiple cameras attached to it. Application domains include robotics, wearable computing, augmented reality, and automotive. The term VO was coined in 2004 by Nister in his landmark paper. The term was chosen for its similarity to wheel odometry, which incrementally estimates the motion of a vehicle by integrating the number of turns of its wheels over time. Likewise, VO operates by incrementally estimating the pose of the vehicle through examination of the changes that motion induces on the images of its onboard cameras. For VO to work effectively, there should be sufficient illumination in the environment and a static scene with enough texture to allow apparent motion to be extracted. Furthermore, consecutive frames should be captured by ensuring that they have sufficient scene overlap.","wheels,
cameras,
image texture,
motion estimation,
pose estimation,
road vehicles,
robots"
Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis,"Previous work on action recognition has focused on adapting hand-designed local features, such as SIFT or HOG, from static images to the video domain. In this paper, we propose using unsupervised feature learning as a way to learn features directly from video data. More specifically, we present an extension of the Independent Subspace Analysis algorithm to learn invariant spatio-temporal features from unlabeled video data. We discovered that, despite its simplicity, this method performs surprisingly well when combined with deep learning techniques such as stacking and convolution to learn hierarchical representations. By replacing hand-designed features with our learned features, we achieve classification results superior to all previous published results on the Hollywood2, UCF, KTH and YouTube action recognition datasets. On the challenging Hollywood2 and YouTube action datasets we obtain 53.3% and 75.8% respectively, which are approximately 5% better than the current best published results. Further benefits of this method, such as the ease of training and the efficiency of training and prediction, will also be discussed. You can download our code and learned spatio-temporal features here: http://ai.stanford.edu/~wzou/.","Videos,
Feature extraction,
Image edge detection,
Neurons,
Convolution,
Detectors,
Training"
Vacuum Electronic High Power Terahertz Sources,"Recent research and development has been incredibly successful at advancing the capabilities for vacuum electronic device (VED) sources of powerful terahertz (THz) and near-THz coherent radiation, both CW or average and pulsed. Currently, the VED source portfolio covers over 12 orders of magnitude in power (mW-to-GW) and two orders of magnitude in frequency (from <; 0.1 to >; 10 THz). Further advances are still possible and anticipated. They will be enabled by improved understanding of fundamental beam-wave interactions, electromagnetic mode competition and mode control, along with research and development of new materials, fabrication methods, cathodes, electron beam alignment and focusing, magnet technologies, THz metrology and advanced, broadband output radiation coupling techniques.","Electron beams,
Radio frequency,
Cavity resonators,
Oscillators,
Klystrons,
Cathodes,
Modulation"
"Advancements in Noncontact, Multiparameter Physiological Measurements Using a Webcam","We present a simple, low-cost method for measuring multiple physiological parameters using a basic webcam. By applying independent component analysis on the color channels in video recordings, we extracted the blood volume pulse from the facial regions. Heart rate (HR), respiratory rate, and HR variability (HRV, an index for cardiac autonomic activity) were subsequently quantified and compared to corresponding measurements using Food and Drug Administration-approved sensors. High degrees of agreement were achieved between the measurements across all physiological parameters. This technology has significant potential for advancing personal health care and telemedicine.","Heart rate variability,
Biomedical measurements,
Sensors,
Frequency measurement,
Resonant frequency,
Hafnium"
Iterative quantization: A procrustean approach to learning binary codes,"This paper addresses the problem of learning similarity-preserving binary codes for efficient retrieval in large-scale image collections. We propose a simple and efficient alternating minimization scheme for finding a rotation of zero-centered data so as to minimize the quantization error of mapping this data to the vertices of a zero-centered binary hypercube. This method, dubbed iterative quantization (ITQ), has connections to multi-class spectral clustering and to the orthogonal Procrustes problem, and it can be used both with unsupervised data embeddings such as PCA and supervised embeddings such as canonical correlation analysis (CCA). Our experiments show that the resulting binary coding schemes decisively outperform several other state-of-the-art methods.","Principal component analysis,
Quantization,
Binary codes,
Semantics,
Encoding,
Training,
Minimization"
Sensitivity to Basis Mismatch in Compressed Sensing,"The theory of compressed sensing suggests that successful inversion of an image of the physical world (broadly defined to include speech signals, radar/sonar returns, vibration records, sensor array snapshot vectors, 2-D images, and so on) for its source modes and amplitudes can be achieved at measurement dimensions far lower than what might be expected from the classical theories of spectrum or modal analysis, provided that the image is sparse in an apriori known basis. For imaging problems in spectrum analysis, and passive and active radar/sonar, this basis is usually taken to be a DFT basis. However, in reality no physical field is sparse in the DFT basis or in any apriori known basis. No matter how finely we grid the parameter space the sources may not lie in the center of the grid cells and consequently there is mismatch between the assumed and the actual bases for sparsity. In this paper, we study the sensitivity of compressed sensing to mismatch between the assumed and the actual sparsity bases. We start by analyzing the effect of basis mismatch on the best k-term approximation error, which is central to providing exact sparse recovery guarantees. We establish achievable bounds for the l1 error of the best k -term approximation and show that these bounds grow linearly with the image (or grid) dimension and the mismatch level between the assumed and actual bases for sparsity. We then derive bounds, with similar growth behavior, for the basis pursuit l1 recovery error, indicating that the sparse recovery may suffer large errors in the presence of basis mismatch. Although, we present our results in the context of basis pursuit, our analysis applies to any sparse recovery principle that relies on the accuracy of best k-term approximations for its performance guarantees. We particularly highlight the problematic nature of basis mismatch in Fourier imaging, where spillage from off-grid DFT components turns a sparse representation into an incompressible one. We substantiate our mathematical analysis by numerical examples that demonstrate a considerable performance degradation for image inversion from compressed sensing measurements in the presence of basis mismatch, for problem sizes common to radar and sonar.","Compressed sensing,
Approximation methods,
Radar imaging,
Discrete Fourier transforms,
Sparse matrices,
Sonar"
On the Levy-Walk Nature of Human Mobility,"We report that human walk patterns contain statistically similar features observed in Levy walks. These features include heavy-tail flight and pause-time distributions and the super-diffusive nature of mobility. Human walks are not random walks, but it is surprising that the patterns of human walks and Levy walks contain some statistical similarity. Our study is based on 226 daily GPS traces collected from 101 volunteers in five different outdoor sites. The heavy-tail flight distribution of human mobility induces the super-diffusivity of travel, but up to 30 min to 1 h due to the boundary effect of people's daily movement, which is caused by the tendency of people to move within a predefined (also confined) area of daily activities. These tendencies are not captured in common mobility models such as random way point (RWP). To evaluate the impact of these tendencies on the performance of mobile networks, we construct a simple truncated Levy walk mobility (TLW) model that emulates the statistical features observed in our analysis and under which we measure the performance of routing protocols in delay-tolerant networks (DTNs) and mobile ad hoc networks (MANETs). The results indicate the following. Higher diffusivity induces shorter intercontact times in DTN and shorter path durations with higher success probability in MANET. The diffusivity of TLW is in between those of RWP and Brownian motion (BM). Therefore, the routing performance under RWP as commonly used in mobile network studies and tends to be overestimated for DTNs and underestimated for MANETs compared to the performance under TLW.",
Orthogonal Learning Particle Swarm Optimization,"Particle swarm optimization (PSO) relies on its learning strategy to guide its search direction. Traditionally, each particle utilizes its historical best experience and its neighborhood's best experience through linear summation. Such a learning strategy is easy to use, but is inefficient when searching in complex problem spaces. Hence, designing learning strategies that can utilize previous search information (experience) more efficiently has become one of the most salient and active PSO research topics. In this paper, we proposes an orthogonal learning (OL) strategy for PSO to discover more useful information that lies in the above two experiences via orthogonal experimental design. We name this PSO as orthogonal learning particle swarm optimization (OLPSO). The OL strategy can guide particles to fly in better directions by constructing a much promising and efficient exemplar. The OL strategy can be applied to PSO with any topological structure. In this paper, it is applied to both global and local versions of PSO, yielding the OLPSO-G and OLPSO-L algorithms, respectively. This new learning strategy and the new algorithms are tested on a set of 16 benchmark functions, and are compared with other PSO algorithms and some state of the art evolutionary algorithms. The experimental results illustrate the effectiveness and efficiency of the proposed learning strategy and algorithms. The comparisons show that OLPSO significantly improves the performance of PSO, offering faster global convergence, higher solution quality, and stronger robustness.","Particle swarm optimization,
Algorithm design and analysis,
Optimization,
Oscillators,
Convergence,
Search problems,
Arrays"
A Novel Improved Variable Step-Size Incremental-Resistance MPPT Method for PV Systems,"Maximum power point (MPP) tracking (MPPT) techniques are widely applied in photovoltaic (PV) systems to make PV array generate peak power which depends on solar irradiation. Among all the MPPT strategies, the incremental-conductance (INC) algorithm is widely employed due to easy implementation and high tracking accuracy. In this paper, a novel variable step-size incremental-resistance MPPT algorithm is introduced, which not only has the merits of INC but also automatically adjusts the step size to track the PV array MPP. Compared with the variable step-size INC method, the proposed scheme can greatly improve the MPPT response speed and accuracy at steady state simultaneously. Moreover, it is more suitable for practical operating conditions due to a wider operating range. This paper provides the theoretical analysis and the design principle of the proposed MPPT strategy. Simulation and experimental results verify its feasibility.","Arrays,
Power generation,
Radiation effects,
Steady-state,
Resistance,
Accuracy,
Mathematical model"
Threshold Saturation via Spatial Coupling: Why Convolutional LDPC Ensembles Perform So Well over the BEC,"Convolutional low-density parity-check (LDPC) ensembles, introduced by Felström and Zigangirov, have excellent thresholds and these thresholds are rapidly increasing functions of the average degree. Several variations on the basic theme have been proposed to date, all of which share the good performance characteristics of convolutional LDPC ensembles. We describe the fundamental mechanism that explains why “convolutional-like” or “spatially coupled” codes perform so well. In essence, the spatial coupling of individual codes increases the belief-propagation (BP) threshold of the new ensemble to its maximum possible value, namely the maximum a posteriori (MAP) threshold of the underlying ensemble. For this reason, we call this phenomenon “threshold saturation.” This gives an entirely new way of approaching capacity. One significant advantage of this construction is that one can create capacity-approaching ensembles with an error correcting radius that is increasing in the blocklength. Although we prove the “threshold saturation” only for a specific ensemble and for the binary erasure channel (BEC), empirically the phenomenon occurs for a wide class of ensembles and channels. More generally, we conjecture that for a large range of graphical systems a similar saturation of the “dynamical” threshold occurs once individual components are coupled sufficiently strongly. This might give rise to improved algorithms and new techniques for analysis.","Parity check codes,
Convolutional codes,
Decoding,
Couplings,
Sockets,
Equations,
Constellation diagram"
Noisy Network Coding,"A noisy network coding scheme for communicating messages between multiple sources and destinations over a general noisy network is presented. For multi-message multicast networks, the scheme naturally generalizes network coding over noiseless networks by Ahlswede, Cai, Li, and Yeung, and compress-forward coding for the relay channel by Cover and El Gamal to discrete memoryless and Gaussian networks. The scheme also extends the results on coding for wireless relay networks and deterministic networks by Avestimehr, Diggavi, and Tse, and coding for wireless erasure networks by Dana, Gowaikar, Palanki, Hassibi, and Effros. The scheme involves lossy compression by the relay as in the compress-forward coding scheme for the relay channel. However, unlike previous compress-forward schemes in which independent messages are sent over multiple blocks, the same message is sent multiple times using independent codebooks as in the network coding scheme for cyclic networks. Furthermore, the relays do not use Wyner-Ziv binning as in previous compress-forward schemes, and each decoder performs simultaneous decoding of the received signals from all the blocks without uniquely decoding the compression indices. A consequence of this new scheme is that achievability is proved simply and more generally without resorting to time expansion to extend results for acyclic networks to networks with cycles. The noisy network coding scheme is then extended to general multi-message networks by combining it with decoding techniques for the interference channel. For the Gaussian multicast network, noisy network coding improves the previously established gap to the cutset bound. We also demonstrate through two popular Gaussian network examples that noisy network coding can outperform conventional compress-forward, amplify-forward, and hash-forward coding schemes.","Network coding,
Noise measurement,
Relays,
Encoding,
Decoding,
Interference,
Indexes"
Smart Operation of Smart Grid: Risk-Limiting Dispatch,"The drastic reduction of carbon emission to combat global climate change cannot be realized without a significant contribution from the electricity sector. Renewable energy resources must take a bigger share in the generation mix, effective demand response must be widely implemented, and high-capacity energy storage systems must be developed. A smart grid is necessary to manage and control the increasingly complex future grid. Certain smart grid elements-renewables, storage, microgrid, consumer choice, and smart appliances-increase uncertainty in both supply and demand of electric power. Other smart gird elements-sensors, smart meters, demand response, and communications-provide more accurate information about the power system and more refined means of control. Simply building hardware for renewable generators and the smart grid, but still using the same operating paradigm of the grid, will not realize the full potential for overall system efficiency and carbon reduction. In this paper, a new operating paradigm, called risk-limiting dispatch, is proposed. It treats generation as a heterogeneous commodity of intermittent or stochastic power and uses information and control to design hedging techniques to manage the risk of uncertainty.","Smart grids,
Generators,
Load management,
Meteorology,
Renewable energy resources,
Load flow control"
Enterprise Systems: State-of-the-Art and Future Trends,"Rapid advances in industrial information integration methods have spurred tremendous growth in the use of enterprise systems. Consequently, a variety of techniques have been used for probing enterprise systems. These techniques include business process management, workflow management, Enterprise Application Integration (EAI), Service-Oriented Architecture (SOA), grid computing, and others. Many applications require a combination of these techniques, which is giving rise to the emergence of enterprise systems. Development of the techniques has originated from different disciplines and has the potential to significantly improve the performance of enterprise systems. However, the lack of powerful tools still poses a major hindrance to exploiting the full potential of enterprise systems. In particular, formal methods and systems methods are crucial for modeling complex enterprise systems, which poses unique challenges. In this paper, we briefly survey the state of the art in the area of enterprise systems as they relate to industrial informatics.",
Data-Driven Intelligent Transportation Systems: A Survey,"For the last two decades, intelligent transportation systems (ITS) have emerged as an efficient way of improving the performance of transportation systems, enhancing travel security, and providing more choices to travelers. A significant change in ITS in recent years is that much more data are collected from a variety of sources and can be processed into various forms for different stakeholders. The availability of a large amount of data can potentially lead to a revolution in ITS development, changing an ITS from a conventional technology-driven system into a more powerful multifunctional data-driven intelligent transportation system (D2ITS) : a system that is vision, multisource, and learning algorithm driven to optimize its performance. Furthermore, D2ITS is trending to become a privacy-aware people-centric more intelligent system. In this paper, we provide a survey on the development of D2ITS, discussing the functionality of its key components and some deployment issues associated with D2ITS Future research directions for the development of D2ITS is also presented.",
A New Supervised Method for Blood Vessel Segmentation in Retinal Images by Using Gray-Level and Moment Invariants-Based Features,"This paper presents a new supervised method for blood vessel detection in digital retinal images. This method uses a neural network (NN) scheme for pixel classification and computes a 7-D vector composed of gray-level and moment invariants-based features for pixel representation. The method was evaluated on the publicly available DRIVE and STARE databases, widely used for this purpose, since they contain retinal images where the vascular structure has been precisely marked by experts. Method performance on both sets of test images is better than other existing solutions in literature. The method proves especially accurate for vessel detection in STARE images. Its application to this database (even when the NN was trained on the DRIVE database) outperforms all analyzed segmentation approaches. Its effectiveness and robustness with different image conditions, together with its simplicity and fast implementation, make this blood vessel segmentation proposal suitable for retinal image computer analyses such as automated screening for early diabetic retinopathy detection.",
Domain Adaptation via Transfer Component Analysis,"Domain adaptation allows knowledge from a source domain to be transferred to a different but related target domain. Intuitively, discovering a good feature representation across domains is crucial. In this paper, we first propose to find such a representation through a new learning method, transfer component analysis (TCA), for domain adaptation. TCA tries to learn some transfer components across domains in a reproducing kernel Hilbert space using maximum mean miscrepancy. In the subspace spanned by these transfer components, data properties are preserved and data distributions in different domains are close to each other. As a result, with the new representations in this subspace, we can apply standard machine learning methods to train classifiers or regression models in the source domain for use in the target domain. Furthermore, in order to uncover the knowledge hidden in the relations between the data labels from the source and target domains, we extend TCA in a semisupervised learning setting, which encodes label information into transfer components learning. We call this extension semisupervised TCA. The main contribution of our work is that we propose a novel dimensionality reduction framework for reducing the distance between domains in a latent space for domain adaptation. We propose both unsupervised and semisupervised feature extraction approaches, which can dramatically reduce the distance between domain distributions by projecting data onto the learned transfer components. Finally, our approach can handle large datasets and naturally lead to out-of-sample generalization. The effectiveness and efficiency of our approach are verified by experiments on five toy datasets and two real-world applications: cross-domain indoor WiFi localization and cross-domain text classification.","Kernel,
Optimization,
Manifolds,
Hilbert space,
Learning systems,
Feature extraction,
Noise measurement"
A Survey on Network Codes for Distributed Storage,"Distributed storage systems often introduce redundancy to increase reliability. When coding is used, the repair problem arises: if a node storing encoded information fails, in order to maintain the same level of reliability we need to create encoded information at a new node. This amounts to a partial recovery of the code, whereas conventional erasure coding focuses on the complete recovery of the information from a subset of encoded packets. The consideration of the repair network traffic gives rise to new design challenges. Recently, network coding techniques have been instrumental in addressing these challenges, establishing that maintenance bandwidth can be reduced by orders of magnitude compared to standard erasure codes. This paper provides an overview of the research results on this topic.","Distributed processing,
Bandwidth,
Peer to peer computing,
Flow graphs,
Encoding,
Data storage systems,
Network coding"
MR Image Reconstruction From Highly Undersampled k-Space Data by Dictionary Learning,"Compressed sensing (CS) utilizes the sparsity of magnetic resonance (MR) images to enable accurate reconstruction from undersampled k-space data. Recent CS methods have employed analytical sparsifying transforms such as wavelets, curvelets, and finite differences. In this paper, we propose a novel framework for adaptively learning the sparsifying transform (dictionary), and reconstructing the image simultaneously from highly undersampled k-space data. The sparsity in this framework is enforced on overlapping image patches emphasizing local structure. Moreover, the dictionary is adapted to the particular image instance thereby favoring better sparsities and consequently much higher undersampling rates. The proposed alternating reconstruction algorithm learns the sparsifying dictionary, and uses it to remove aliasing and noise in one step, and subsequently restores and fills-in the k-space data in the other step. Numerical experiments are conducted on MR images and on real MR data of several anatomies with a variety of sampling schemes. The results demonstrate dramatic improvements on the order of 4-18 dB in reconstruction error and doubling of the acceptable undersampling factor using the proposed adaptive dictionary as compared to previous CS methods. These improvements persist over a wide range of practical data signal-to-noise ratios, without any parameter tuning.","Dictionaries,
Image reconstruction,
Wavelet transforms,
Magnetic resonance imaging,
Pixel,
Noise"
Differential Evolution as Applied to Electromagnetics,"In electromagnetics, optimization problems generally require high computational resources and involve a large number of unknowns. They are usually characterized by non-convex functionals and continuous spaces suitable for strategies based on Differential Evolution (DE). In such a framework, this paper is aimed at presenting an overview of Differential Evolution-based approaches used in electromagnetics, pointing out novelties and customizations with respect to other fields of application. Starting from a general description of the evolutionary mechanism of Differential Evolution, Differential Evolution-based techniques for electromagnetic optimization are presented. Some hints on the convergence properties and the sensitivity to control parameters are also given. Finally, a comprehensive coverage of different Differential Evolution formulations in solving optimization problems in the area of computational electromagnetics is presented, focusing on antenna synthesis and inverse scattering.","Optimization,
Electromagnetic modeling,
Computational modeling,
Scattering,
Differential equations,
Inverse problems"
Stability and Stabilization of Systems with Time Delay,"Time-delays are important components of many dynamical systems that describe coupling or interconnection between dynamics, propagation, or transport phenomena in shared environments, in heredity, and in competition in population dynamics. This monograph addresses the problem of stability analysis and the stabilisation of dynamical systems subjected to time-delays. It presents a wide and self-contained panorama of analytical methods and computational algorithms using a unified eigenvalue-based approach illustrated by examples and applications in electrical and mechanical engineering, biology, and complex network analysis.","Delay,
Stability analysis,
Vehicles,
Timing,
Mathematical model,
Aerospace electronics,
Driver circuits"
From learning models of natural image patches to whole image restoration,"Learning good image priors is of utmost importance for the study of vision, computer vision and image processing applications. Learning priors and optimizing over whole images can lead to tremendous computational challenges. In contrast, when we work with small image patches, it is possible to learn priors and perform patch restoration very efficiently. This raises three questions - do priors that give high likelihood to the data also lead to good performance in restoration? Can we use such patch based priors to restore a full image? Can we learn better patch priors? In this work we answer these questions. We compare the likelihood of several patch models and show that priors that give high likelihood to data perform better in patch restoration. Motivated by this result, we propose a generic framework which allows for whole image restoration using any patch based prior for which a MAP (or approximate MAP) estimate can be calculated. We show how to derive an appropriate cost function, how to optimize it and how to use it to restore whole images. Finally, we present a generic, surprisingly simple Gaussian Mixture prior, learned from a set of natural images. When used with the proposed framework, this Gaussian Mixture Model outperforms all other generic prior methods for image denoising, deblurring and inpainting.","Image restoration,
Noise reduction,
Equations,
Noise measurement,
Image reconstruction,
Mathematical model,
Estimation"
Local Binary Patterns and Its Application to Facial Image Analysis: A Survey,"Local binary pattern (LBP) is a nonparametric descriptor, which efficiently summarizes the local structures of images. In recent years, it has aroused increasing interest in many areas of image processing and computer vision and has shown its effectiveness in a number of applications, in particular for facial image analysis, including tasks as diverse as face detection, face recognition, facial expression analysis, and demographic classification. This paper presents a comprehensive survey of LBP methodology, including several more recent variations. As a typical application of the LBP approach, LBP-based facial image analysis is extensively reviewed, while its successful extensions, which deal with various tasks of facial image analysis, are also highlighted.",
Control and Operation of a DC Microgrid With Variable Generation and Energy Storage,"Control and operation of a dc microgrid, which can be operated at grid connected or island modes, are investigated in this paper. The dc microgrid consists of a wind turbine, a battery energy storage system, dc loads, and a grid-connected converter system. When the system is grid connected, active power is balanced through the grid supply during normal operation to ensure a constant dc voltage. Automatic power balancing during a grid ac fault is achieved by coordinating the battery energy storage system and the grid converter. To ensure that the system can operate under island conditions, a coordinated strategy for the battery system, wind turbine, and load management, including load shedding, are proposed. PSCAD/EMTDC simulations are presented to demonstrate the robust operation performance and to validate the proposed control system during various operating conditions, such as variations of wind power generation and load, grid ac faults, and islanding.","Distributed power generation,
Voltage control,
Wind turbines,
Energy storage,
Power system control"
Face recognition in unconstrained videos with matched background similarity,"Recognizing faces in unconstrained videos is a task of mounting importance. While obviously related to face recognition in still images, it has its own unique characteristics and algorithmic requirements. Over the years several methods have been suggested for this problem, and a few benchmark data sets have been assembled to facilitate its study. However, there is a sizable gap between the actual application needs and the current state of the art. In this paper we make the following contributions. (a) We present a comprehensive database of labeled videos of faces in challenging, uncontrolled conditions (i.e., `in the wild'), the `YouTube Faces' database, along with benchmark, pair-matching tests1. (b) We employ our benchmark to survey and compare the performance of a large variety of existing video face recognition techniques. Finally, (c) we describe a novel set-to-set similarity measure, the Matched Background Similarity (MBGS). This similarity is shown to considerably improve performance on the benchmark tests.",
Robust Beamforming for Security in MIMO Wiretap Channels With Imperfect CSI,"In this paper, we investigate methods for reducing the likelihood that a message transmitted between two multi-antenna nodes is intercepted by an undetected eavesdropper. In particular, we focus on the judicious transmission of artificial interference to mask the desired signal at the time it is broadcast. Unlike previous work that assumes some prior knowledge of the eavesdropper's channel and focuses on maximizing secrecy capacity, we consider the case where no information regarding the eavesdropper is available, and we use signal-to-interference-plus-noise-ratio (SINR) as our performance metric. Specifically, we focus on the problem of maximizing the amount of power available to broadcast a jamming signal intended to hide the desired signal from a potential eavesdropper, while maintaining a prespecified SINR at the desired receiver. The jamming signal is designed to be orthogonal to the information signal when it reaches the desired receiver, assuming both the receiver and the eavesdropper employ optimal beamformers and possess exact channel state information (CSI). In practice, the assumption of perfect CSI at the transmitter is often difficult to justify. Therefore, we also study the resulting performance degradation due to the presence of imperfect CSI, and we present robust beamforming schemes that recover a large fraction of the performance in the perfect CSI case. Numerical simulations verify our analytical performance predictions, and illustrate the benefit of the robust beamforming schemes.",
Cooperative Jamming for Secure Communications in MIMO Relay Networks,"Secure communications can be impeded by eavesdroppers in conventional relay systems. This paper proposes cooperative jamming strategies for two-hop relay networks where the eavesdropper can wiretap the relay channels in both hops. In these approaches, the normally inactive nodes in the relay network can be used as cooperative jamming sources to confuse the eavesdropper. Linear precoding schemes are investigated for two scenarios where single or multiple data streams are transmitted via a decode-and-forward (DF) relay, under the assumption that global channel state information (CSI) is available. For the case of single data stream transmission, we derive closed-form jamming beamformers and the corresponding optimal power allocation. Generalized singular value decomposition (GSVD)-based secure relaying schemes are proposed for the transmission of multiple data streams. The optimal power allocation is found for the GSVD relaying scheme via geometric programming. Based on this result, a GSVD-based cooperative jamming scheme is proposed that shows significant improvement in terms of secrecy rate compared to the approach without jamming. Furthermore, the case involving an eavesdropper with unknown CSI is also investigated in this paper. Simulation results show that the secrecy rate is dramatically increased when inactive nodes in the relay network participate in cooperative jamming.",
A Survey on Trust Management for Mobile Ad Hoc Networks,"Managing trust in a distributed Mobile Ad Hoc Network (MANET) is challenging when collaboration or cooperation is critical to achieving mission and system goals such as reliability, availability, scalability, and reconfigurability. In defining and managing trust in a military MANET, we must consider the interactions between the composite cognitive, social, information and communication networks, and take into account the severe resource constraints (e.g., computing power, energy, bandwidth, time), and dynamics (e.g., topology changes, node mobility, node failure, propagation channel conditions). We seek to combine the notions of ""social trust"" derived from social networks with ""quality-of-service (QoS) trust"" derived from information and communication networks to obtain a composite trust metric. We discuss the concepts and properties of trust and derive some unique characteristics of trust in MANETs, drawing upon social notions of trust. We provide a survey of trust management schemes developed for MANETs and discuss generally accepted classifications, potential attacks, performance metrics, and trust metrics in MANETs. Finally, we discuss future research areas on trust management in MANETs based on the concept of social and cognitive networks.","Network security,
Mobile ad hoc networks,
Trust management,
Social network services,
Reliability"
Synchronization of Networks of Nonidentical Euler-Lagrange Systems With Uncertain Parameters and Communication Delays,"This paper addresses the problem of synchronizing networks of nonidentical, nonlinear dynamical systems described by Euler-Lagrange equations, which are assumed fully-actuated, with their states available for measurement, but with unknown parameters. The only assumption made on the communication graph is that it is connected. Moreover, the communication is subject to constant time delays, which are also unknown. The main result of the paper is the construction of an adaptive controller that achieves global full-state synchronization, i.e., the difference between the agents positions and velocities asymptotically converges to zero. If a desired trajectory for all systems is given, a slight modification to the proposed scheme achieves also full-state synchronization. Simulations using a ten robot manipulator network are used to illustrate the performance of the proposed schemes.",
Adaptive Neural Output Feedback Tracking Control for a Class of Uncertain Discrete-Time Nonlinear Systems,"This brief studies an adaptive neural output feedback tracking control of uncertain nonlinear multi-input-multi-output (MIMO) systems in the discrete-time form. The considered MIMO systems are composed of n subsystems with the couplings of inputs and states among subsystems. In order to solve the noncausal problem and decouple the couplings, it needs to transform the systems into a predictor form. The higher order neural networks are utilized to approximate the desired controllers. By using Lyapunov analysis, it is proven that all the signals in the closed-loop system is the semi-globally uniformly ultimately bounded and the output errors converge to a compact set. In contrast to the existing results, the advantage of the scheme is that the number of the adjustable parameters is highly reduced. The effectiveness of the scheme is verified by a simulation example.","Artificial neural networks,
Adaptive systems,
MIMO,
Nonlinear systems,
Control systems,
Approximation methods,
Couplings"
A Two-Phase Test Sample Sparse Representation Method for Use With Face Recognition,"In this paper, we propose a two-phase test sample representation method for face recognition. The first phase of the proposed method seeks to represent the test sample as a linear combination of all the training samples and exploits the representation ability of each training sample to determine M “nearest neighbors” for the test sample. The second phase represents the test sample as a linear combination of the determined M nearest neighbors and uses the representation result to perform classification. We propose this method with the following assumption: the test sample and its some neighbors are probably from the same class. Thus, we use the first phase to detect the training samples that are far from the test sample and assume that these samples have no effects on the ultimate classification decision. This is helpful to accurately classify the test sample. We will also show the probability explanation of the proposed method. A number of face recognition experiments show that our method performs very well.",
Globally-optimal greedy algorithms for tracking a variable number of objects,"We analyze the computational problem of multi-object tracking in video sequences. We formulate the problem using a cost function that requires estimating the number of tracks, as well as their birth and death states. We show that the global solution can be obtained with a greedy algorithm that sequentially instantiates tracks using shortest path computations on a flow network. Greedy algorithms allow one to embed pre-processing steps, such as nonmax suppression, within the tracking algorithm. Furthermore, we give a near-optimal algorithm based on dynamic programming which runs in time linear in the number of objects and linear in the sequence length. Our algorithms are fast, simple, and scalable, allowing us to process dense input data. This results in state-of-the-art performance.","Heuristic algorithms,
Approximation algorithms,
Hidden Markov models,
Algorithm design and analysis,
Spatiotemporal phenomena,
Dynamic programming,
Greedy algorithms"
Distributed Coordinated Tracking With a Dynamic Leader for Multiple Euler-Lagrange Systems,"In this note, we study a distributed coordinated tracking problem for multiple networked Euler-Lagrange systems. The objective is for a team of followers modeled by full-actuated Euler-Lagrange equations to track a dynamic leader whose vector of generalized coordinates is time varying under the constraints that the leader is a neighbor of only a subset of the followers and the followers have only local interaction. We consider two cases: i) The leader has a constant vector of generalized coordinate derivatives, and ii) The leader has a varying vector of generalized coordinate derivatives. In the first case, we propose a distributed continuous estimator and an adaptive control law to account for parametric uncertainties. In the second case, we propose a model-independent sliding mode control algorithm. Simulation results on multiple networked two-link revolute joint arms are provided to show the effectiveness of the proposed control algorithms.",
Maximum Correntropy Criterion for Robust Face Recognition,"In this paper, we present a sparse correntropy framework for computing robust sparse representations of face images for recognition. Compared with the state-of-the-art l1norm-based sparse representation classifier (SRC), which assumes that noise also has a sparse representation, our sparse algorithm is developed based on the maximum correntropy criterion, which is much more insensitive to outliers. In order to develop a more tractable and practical approach, we in particular impose nonnegativity constraint on the variables in the maximum correntropy criterion and develop a half-quadratic optimization technique to approximately maximize the objective function in an alternating way so that the complex optimization problem is reduced to learning a sparse representation through a weighted linear least squares problem with nonnegativity constraint at each iteration. Our extensive experiments demonstrate that the proposed method is more robust and efficient in dealing with the occlusion and corruption problems in face recognition as compared to the related state-of-the-art methods. In particular, it shows that the proposed method can improve both recognition accuracy and receiver operator characteristic (ROC) curves, while the computational cost is much lower than the SRC algorithms.","Robustness,
Face recognition,
Optimization,
Noise,
Training,
Face,
Kernel"
Graph Regularized Sparse Coding for Image Representation,"Sparse coding has received an increasing amount of interest in recent years. It is an unsupervised learning algorithm, which finds a basis set capturing high-level semantics in the data and learns sparse coordinates in terms of the basis set. Originally applied to modeling the human visual cortex, sparse coding has been shown useful for many applications. However, most of the existing approaches to sparse coding fail to consider the geometrical structure of the data space. In many real applications, the data is more likely to reside on a low-dimensional submanifold embedded in the high-dimensional ambient space. It has been shown that the geometrical information of the data is important for discrimination. In this paper, we propose a graph based algorithm, called graph regularized sparse coding, to learn the sparse representations that explicitly take into account the local manifold structure of the data. By using graph Laplacian as a smooth operator, the obtained sparse representations vary smoothly along the geodesics of the data manifold. The extensive experimental results on image classification and clustering have demonstrated the effectiveness of our proposed algorithm.",
Accelerated Dynamic MRI Exploiting Sparsity and Low-Rank Structure: k-t SLR,"We introduce a novel algorithm to reconstruct dynamic magnetic resonance imaging (MRI) data from under-sampled k-t space data. In contrast to classical model based cine MRI schemes that rely on the sparsity or banded structure in Fourier space, we use the compact representation of the data in the Karhunen Louve transform (KLT) domain to exploit the correlations in the dataset. The use of the data-dependent KL transform makes our approach ideally suited to a range of dynamic imaging problems, even when the motion is not periodic. In comparison to current KLT-based methods that rely on a two-step approach to first estimate the basis functions and then use it for reconstruction, we pose the problem as a spectrally regularized matrix recovery problem. By simultaneously determining the temporal basis functions and its spatial weights from the entire measured data, the proposed scheme is capable of providing high quality reconstructions at a range of accelerations. In addition to using the compact representation in the KLT domain, we also exploit the sparsity of the data to further improve the recovery rate. Validations using numerical phantoms and in vivo cardiac perfusion MRI data demonstrate the significant improvement in performance offered by the proposed scheme over existing methods.",
Four-Component Scattering Power Decomposition With Rotation of Coherency Matrix,"This paper presents an improvement to a decomposition scheme for the accurate classification of polarimetric synthetic aperture radar (POLSAR) images. Using a rotation of the coherency matrix to minimize the cross-polarized component, the four-component scattering power decomposition is applied to fully polarimetric SAR images. It is known that oriented urban area and vegetation signatures are decomposed into the same volume scattering mechanism in the previous decompositions and that it is difficult to distinguish vegetation from oblique urban areas with respect to the radar direction of illumination within the volume scattering mechanism. It is desirable to distinguish these two scattering mechanisms for accurate classification although they exhibit similar polarimetric responses. The new decomposition scheme by implementing a rotation of the coherency matrix first and, subsequently, the four-component decomposition yields considerably improved accurate results that oriented urban areas are recognized as double bounce objects from volume scattering.",
Reliable Physical Layer Network Coding,"When two or more users in a wireless network transmit simultaneously, their electromagnetic signals are linearly superimposed on the channel. As a result, a receiver that is interested in one of these signals sees the others as unwanted interference. This property of the wireless medium is typically viewed as a hindrance to reliable communication over a network. However, using a recently developed coding strategy, interference can in fact be harnessed for network coding. In a wired network, (linear) network coding refers to each intermediate node taking its received packets, computing a linear combination over a finite field, and forwarding the outcome towards the destinations. Then, given an appropriate set of linear combinations, a destination can solve for its desired packets. For certain topologies, this strategy can attain significantly higher throughputs over routing-based strategies. Reliable physical layer network coding takes this idea one step further: using judiciously chosen linear error-correcting codes, intermediate nodes in a wireless network can directly recover linear combinations of the packets from the observed noisy superpositions of transmitted signals. Starting with some simple examples, this paper explores the core ideas behind this new technique and the possibilities it offers for communication over interference-limited wireless networks.",
Person re-identification by probabilistic relative distance comparison,"Matching people across non-overlapping camera views, known as person re-identification, is challenging due to the lack of spatial and temporal constraints and large visual appearance changes caused by variations in view angle, lighting, background clutter and occlusion. To address these challenges, most previous approaches aim to extract visual features that are both distinctive and stable under appearance changes. However, most visual features and their combinations under realistic conditions are neither stable nor distinctive thus should not be used indiscriminately. In this paper, we propose to formulate person re-identification as a distance learning problem, which aims to learn the optimal distance that can maximises matching accuracy regardless the choice of representation. To that end, we introduce a novel Probabilistic Relative Distance Comparison (PRDC) model, which differs from most existing distance learning methods in that, rather than minimising intra-class variation whilst maximising intra-class variation, it aims to maximise the probability of a pair of true match having a smaller distance than that of a wrong match pair. This makes our model more tolerant to appearance changes and less susceptible to model over-fitting. Extensive experiments are carried out to demonstrate that 1) by formulating the person re-identification problem as a distance learning problem, notable improvement on matching accuracy can be obtained against conventional person re-identification techniques, which is particularly significant when the training sample size is small; and 2) our PRDC outperforms not only existing distance learning methods but also alternative learning methods based on boosting and learning to rank.","Computer aided instruction,
Cameras,
Probabilistic logic,
Training,
Optimization,
Learning systems,
Feature extraction"
Improvements on Twin Support Vector Machines,"For classification problems, the generalized eigenvalue proximal support vector machine (GEPSVM) and twin support vector machine (TWSVM) are regarded as milestones in the development of the powerful SVMs, as they use the nonparallel hyperplane classifiers. In this brief, we propose an improved version, named twin bounded support vector machines (TBSVM), based on TWSVM. The significant advantage of our TBSVM over TWSVM is that the structural risk minimization principle is implemented by introducing the regularization term. This embodies the marrow of statistical learning theory, so this modification can improve the performance of classification. In addition, the successive overrelaxation technique is used to solve the optimization problems to speed up the training procedure. Experimental results show the effectiveness of our method in both computation time and classification accuracy, and therefore confirm the above conclusion further.","Static VAr compensators,
Accuracy,
Support vector machines,
Risk management,
Kernel,
Training,
Optimization"
Parallel Spectral Clustering in Distributed Systems,"Spectral clustering algorithms have been shown to be more effective in finding clusters than some traditional algorithms, such as k-means. However, spectral clustering suffers from a scalability problem in both memory use and computational time when the size of a data set is large. To perform clustering on large data sets, we investigate two representative ways of approximating the dense similarity matrix. We compare one approach by sparsifying the matrix with another by the Nyström method. We then pick the strategy of sparsifying the matrix via retaining nearest neighbors and investigate its parallelization. We parallelize both memory use and computation on distributed computers. Through an empirical study on a document data set of 193,844 instances and a photo data set of 2,121,863, we show that our parallel algorithm can effectively handle large problems.","Sparse matrices,
Clustering algorithms,
Nearest neighbor searches,
Distributed computing,
Concurrent computing,
Laplace equations,
Computer science,
USA Councils,
Scalability,
Parallel algorithms"
Describable Visual Attributes for Face Verification and Image Search,"We introduce the use of describable visual attributes for face verification and image search. Describable visual attributes are labels that can be given to an image to describe its appearance. This paper focuses on images of faces and the attributes used to describe them, although the concepts also apply to other domains. Examples of face attributes include gender, age, jaw shape, nose size, etc. The advantages of an attribute-based representation for vision tasks are manifold: They can be composed to create descriptions at various levels of specificity; they are generalizable, as they can be learned once and then applied to recognize new objects or categories without any further training; and they are efficient, possibly requiring exponentially fewer attributes (and training data) than explicitly naming each category. We show how one can create and label large data sets of real-world images to train classifiers which measure the presence, absence, or degree to which an attribute is expressed in images. These classifiers can then automatically label new images. We demonstrate the current effectiveness-and explore the future potential-of using attributes for face verification and image search via human and computational experiments. Finally, we introduce two new face data sets, named FaceTracer and PubFig, with labeled attributes and identities, respectively.","Face,
Visualization,
Lighting,
Search engines,
Databases,
Face recognition,
Accuracy"
Bounded H_{\infty} Synchronization and State Estimation for Discrete Time-Varying Stochastic Complex Networks Over a Finite Horizon,"In this paper, new synchronization and state estimation problems are considered for an array of coupled discrete time-varying stochastic complex networks over a finite horizon. A novel concept of bounded H∞ synchronization is proposed to handle the time-varying nature of the complex networks. Such a concept captures the transient behavior of the time-varying complex network over a finite horizon, where the degree of bounded synchronization is quantified in terms of the H∞-norm. A general sector-like nonlinear function is employed to describe the nonlinearities existing in the network. By utilizing a timevarying real-valued function and the Kronecker product, criteria are established that ensure the bounded H∞ synchronization in terms of a set of recursive linear matrix inequalities (RLMIs), where the RLMIs can be computed recursively by employing available MATLAB toolboxes. The bounded H∞ state estimation problem is then studied for the same complex network, where the purpose is to design a state estimator to estimate the network states through available output measurements such that, over a finite horizon, the dynamics of the estimation error is guaranteed to be bounded with a given disturbance attenuation level. Again, an RLMI approach is developed for the state estimation problem. Finally, two simulation examples are exploited to show the effectiveness of the results derived in this paper.","Complex networks,
Synchronization,
State estimation,
Attenuation,
Stochastic processes,
Symmetric matrices,
Transient analysis"
Mayavi: 3D Visualization of Scientific Data,"Mayavi is a general purpose, open source 3D scientific visualization package that is tightly integrated with the rich ecosystem of Python scientific packages. Mayavi provides a continuum of tools for developing scientific applications, ranging from interactive and script-based data visualization in Python to full-blown custom end-user applications.","Data visualization,
Scientific computing,
Three dimensional displays,
Image color analysis,
Science - general"
"Adaptive Dynamic Programming for Finite-Horizon Optimal Control of Discrete-Time Nonlinear Systems With \varepsilon
-Error Bound","In this paper, we study the finite-horizon optimal control problem for discrete-time nonlinear systems using the adaptive dynamic programming (ADP) approach. The idea is to use an iterative ADP algorithm to obtain the optimal control law which makes the performance index function close to the greatest lower bound of all performance indices within an -error bound. The optimal number of control steps can also be obtained by the proposed ADP algorithms. A convergence analysis of the proposed ADP algorithms in terms of performance index function and control policy is made. In order to facilitate the implementation of the iterative ADP algorithms, neural networks are used for approximating the performance index function, computing the optimal control policy, and modeling the nonlinear system. Finally, two simulation examples are employed to illustrate the applicability of the proposed method.","Performance analysis,
Optimal control,
Iterative algorithm,
Dynamic programming,
Equations,
Trajectory,
Nonlinear systems"
Scene recognition and weakly supervised object localization with deformable part-based models,"Weakly supervised discovery of common visual structure in highly variable, cluttered images is a key problem in recognition. We address this problem using deformable part-based models (DPM's) with latent SVM training [6]. These models have been introduced for fully supervised training of object detectors, but we demonstrate that they are also capable of more open-ended learning of latent structure for such tasks as scene recognition and weakly supervised object localization. For scene recognition, DPM's can capture recurring visual elements and salient objects; in combination with standard global image features, they obtain state-of-the-art results on the MIT 67-category indoor scene dataset. For weakly supervised object localization, optimization over latent DPM parameters can discover the spatial extent of objects in cluttered training images without ground-truth bounding boxes. The resulting method outperforms a recent state-of-the-art weakly supervised object localization approach on the PASCAL-07 dataset.","support vector machines,
image recognition,
object detection"
Recognizing human actions by attributes,"In this paper we explore the idea of using high-level semantic concepts, also called attributes, to represent human actions from videos and argue that attributes enable the construction of more descriptive models for human action recognition. We propose a unified framework wherein manually specified attributes are: i) selected in a discriminative fashion so as to account for intra-class variability; ii) coherently integrated with data-driven attributes to make the attribute set more descriptive. Data-driven attributes are automatically inferred from the training data using an information theoretic approach. Our framework is built upon a latent SVM formulation where latent variables capture the degree of importance of each attribute for each action class. We also demonstrate that our attribute-based action representation can be effectively used to design a recognition procedure for classifying novel action classes for which no training samples are available. We test our approach on several publicly available datasets and obtain promising results that quantitatively demonstrate our theoretical claims.","Training,
Videos,
Humans,
Semantics,
Torso,
Support vector machines,
Legged locomotion"
Efficient Reversible Watermarking Based on Adaptive Prediction-Error Expansion and Pixel Selection,"Prediction-error expansion (PEE) is an important technique of reversible watermarking which can embed large payloads into digital images with low distortion. In this paper, the PEE technique is further investigated and an efficient reversible watermarking scheme is proposed, by incorporating in PEE two new strategies, namely, adaptive embedding and pixel selection. Unlike conventional PEE which embeds data uniformly, we propose to adaptively embed 1 or 2 bits into expandable pixel according to the local complexity. This avoids expanding pixels with large prediction-errors, and thus, it reduces embedding impact by decreasing the maximum modification to pixel values. Meanwhile, adaptive PEE allows very large payload in a single embedding pass, and it improves the capacity limit of conventional PEE. We also propose to select pixels of smooth area for data embedding and leave rough pixels unchanged. In this way, compared with conventional PEE, a more sharply distributed prediction-error histogram is obtained and a better visual quality of watermarked image is observed. With these improvements, our method outperforms conventional PEE. Its superiority over other state-of-the-art methods is also demonstrated experimentally.","Distortion,
Histograms,
Payloads,
Embedded systems,
Watermarking,
Decoding"
Spectrum Trading in Cognitive Radio Networks: A Contract-Theoretic Modeling Approach,"Cognitive radio is a promising paradigm to achieve efficient utilization of spectrum resource by allowing the unlicensed users (i.e., secondary users, SUs) to access the licensed spectrum. Market-driven spectrum trading is an efficient way to achieve dynamic spectrum accessing/sharing. In this paper, we consider the problem of spectrum trading with single primary spectrum owner (or primary user, PO) selling his idle spectrum to multiple SUs. We model the trading process as a monopoly market, in which the PO acts as monopolist who sets the qualities and prices for the spectrum he sells, and the SUs act as consumers who choose the spectrum with appropriate quality and price for purchasing. We design a monopolist-dominated quality-price contract, which is offered by the PO and contains a set of quality-price combinations each intended for a consumer type. A contract is feasible if it is incentive compatible (IC) and individually rational (IR) for each SU to purchase the spectrum with the quality-price intended for his type. We propose the necessary and sufficient conditions for the contract to be feasible. We further derive the optimal contract, which is feasible and maximizes the utility of the PO, for both discrete-consumer-type model and continuous-consumer-type model. Moreover, we analyze the social surplus, i.e., the aggregate utility of both PO and SUs, and we find that, depending on the distribution of consumer types, the social surplus under the optimal contract may be less than or close to the maximum social surplus.",
Free-Viewpoint TV,"Free-viewpoint television (FTV) is an innovative visual media that enables us to view a three-dimensional (3-D) scene by freely changing our viewpoints. We proposed the concept of FTV and constructed the world???s first real-time system including the complete chain of operation from image capture to display. We also carried out the FTV on a single personal computer (PC) and a mobile player. FTV is based on the ray-space method that represents one ray in real space with one point in the ray-space. We have developed several types of ray capture systems and interfaces such as a 360° capture/ray-reproducing display. FTV is regarded as the ultimate 3DTV, since it can generate infinite number of views. Thus, FTV is the key to immersive communication. Regarding FTV as the most challenging 3-D media, the Motion Picture Experts Group (MPEG) has been conducting its international standardization activities. This article reviews FTV and its related technologies.","TV,
Rendering (computer graphics),
Information processing,
Interpolation,
Receivers,
Real time systems"
Mobile Visual Search,"Mobile phones have evolved into powerful image and video processing devices equipped with high-resolution cameras, color displays, and hardware-accelerated graphics. They are also increasingly equipped with a global positioning system and connected to broadband wireless networks. All this enables a new class of applications that use the camera phone to initiate search queries about objects in visual proximity to the user (Figure 1). Such applications can be used, e.g., for identifying products, comparison shopping, finding information about movies, compact disks (CDs), real estate, print media, or artworks.",
Evaluation of Registration Methods on Thoracic CT: The EMPIRE10 Challenge,"EMPIRE10 (Evaluation of Methods for Pulmonary Image REgistration 2010) is a public platform for fair and meaningful comparison of registration algorithms which are applied to a database of intra patient thoracic CT image pairs. Evaluation of nonrigid registration techniques is a nontrivial task. This is compounded by the fact that researchers typically test only on their own data, which varies widely. For this reason, reliable assessment and comparison of different registration algorithms has been virtually impossible in the past. In this work we present the results of the launch phase of EMPIRE10, which comprised the comprehensive evaluation and comparison of 20 individual algorithms from leading academic and industrial research groups. All algorithms are applied to the same set of 30 thoracic CT pairs. Algorithm settings and parameters are chosen by researchers expert in the con figuration of their own method and the evaluation is independent, using the same criteria for all participants. All results are published on the EMPIRE10 website (http://empire10.isi.uu.nl). The challenge remains ongoing and open to new participants. Full results from 24 algorithms have been published at the time of writing. This paper details the organization of the challenge, the data and evaluation methods and the outcome of the initial launch with 20 algorithms. The gain in knowledge and future work are discussed.","Lungs,
Computed tomography,
Image segmentation,
Biomedical imaging,
Algorithm design and analysis"
"Vertical Si-Nanowire n
-Type Tunneling FETs With Low Subthreshold Swing (\leq \hbox{50}\ \hbox{mV/decade}
) at Room Temperature","This letter presents a Si nanowire based tunneling field-effect transistor (TFET) using a CMOS-compatible vertical gate-all-around structure. By minimizing the thermal budget with low-temperature dopant-segregated silicidation for the source-side dopant activation, excellent TFET characteristics were obtained. We have demonstrated for the first time the lowest ever reported subthreshold swing (SS) of 30 mV/decade at room temperature. In addition, we reported a very convincing SS of 50 mV/decade for close to three decades of drain current. Moreover, our TFET device exhibits excellent characteristics without ambipolar behavior and with high Ion/Ioff ratio (105), as well as low Drain-Induced Barrier Lowering of 70 mV/V.",
Understanding traffic dynamics in cellular data networks,"We conduct the first detailed measurement analysis of network resource usage and subscriber behavior using a large-scale data set collected inside a nationwide 3G cellular data network. The data set tracks close to a million subscribers over thousands of base stations. We analyze individual subscriber behaviors and observe a significant variation in network usage among subscribers. We characterize subscriber mobility and temporal activity patterns and identify their relation to traffic volume. We then investigate how efficiently radio resources are used by different subscribers as well as by different applications. We also analyze the network traffic from the point of view of the base stations and find significant temporal and spatial variations in different parts of the network, while the aggregated behavior appears predictable. Broadly, our observations deliver important insights into network-wide resource usage. We describe implications in pricing, protocol design and resource and spectrum management.","Base stations,
Bit rate,
Mobile communication,
Trajectory,
Planning,
Virtual private networks,
Protocols"
Design of a Robust Grid Interface System for PMSG-Based Wind Turbine Generators,"A robust and reliable grid power interface system for wind turbines using a permanent-magnet synchronous generator (PMSG) is proposed in this paper, where an integration of a generator-side three-switch buck-type rectifier and a grid-side Z-source inverter is employed as a bridge between the generator and the grid. The modulation strategy for the proposed topology is developed from space-vector modulation and Z-source network operation principles. Two PMSG control methods, namely, unity-power-factor control and rotor-flux-orientation control (Id = 0), are studied to establish an optimized control scheme for the generator-side three-switch buck-type rectifier. The system control scheme decouples active- and reactive-power control through voltage-oriented control and optimizes PMSG control for the grid- and generator-side converters independently. Maximum power point tracking is implemented by adjusting the shoot-through duty cycles of the Z-source network. The design considerations of the passive components are also provided. The performances and practicalities of the designed architecture have been verified by simulations and experiments.",
Manifold Regularized Discriminative Nonnegative Matrix Factorization With Fast Gradient Descent,"Nonnegative matrix factorization (NMF) has become a popular data-representation method and has been widely used in image processing and pattern-recognition problems. This is because the learned bases can be interpreted as a natural parts-based representation of data and this interpretation is consistent with the psychological intuition of combining parts to form a whole. For practical classification tasks, however, NMF ignores both the local geometry of data and the discriminative information of different classes. In addition, existing research results show that the learned basis is unnecessarily parts-based because there is neither explicit nor implicit constraint to ensure the representation parts-based. In this paper, we introduce the manifold regularization and the margin maximization to NMF and obtain the manifold regularized discriminative NMF (MD-NMF) to overcome the aforementioned problems. The multiplicative update rule (MUR) can be applied to optimizing MD-NMF, but it converges slowly. In this paper, we propose a fast gradient descent (FGD) to optimize MD-NMF. FGD contains a Newton method that searches the optimal step length, and thus, FGD converges much faster than MUR. In addition, FGD includes MUR as a special case and can be applied to optimizing NMF and its variants. For a problem with 165 samples in R1600 , FGD converges in 28 s, while MUR requires 282 s. We also apply FGD in a variant of MD-NMF and experimental results confirm its efficiency. Experimental results on several face image datasets suggest the effectiveness of MD-NMF.",
Adaptive Neural Network Decentralized Backstepping Output-Feedback Control for Nonlinear Large-Scale Systems With Time Delays,"In this paper, two adaptive neural network (NN) decentralized output feedback control approaches are proposed for a class of uncertain nonlinear large-scale systems with immeasurable states and unknown time delays. Using NNs to approximate the unknown nonlinear functions, an NN state observer is designed to estimate the immeasurable states. By combining the adaptive backstepping technique with decentralized control design principle, an adaptive NN decentralized output feedback control approach is developed. In order to overcome the problem of “explosion of complexity” inherent in the proposed control approach, the dynamic surface control (DSC) technique is introduced into the first adaptive NN decentralized control scheme, and a simplified adaptive NN decentralized output feedback DSC approach is developed. It is proved that the two proposed control approaches can guarantee that all the signals of the closed-loop system are semi-globally uniformly ultimately bounded, and the observer errors and the tracking errors converge to a small neighborhood of the origin. Simulation results are provided to show the effectiveness of the proposed approaches.",
Minimum Complexity Echo State Network,"Reservoir computing (RC) refers to a new class of state-space models with a fixed state transition structure (the reservoir) and an adaptable readout form the state space. The reservoir is supposed to be sufficiently complex so as to capture a large number of features of the input stream that can be exploited by the reservoir-to-output readout mapping. The field of RC has been growing rapidly with many successful applications. However, RC has been criticized for not being principled enough. Reservoir construction is largely driven by a series of randomized model-building stages, with both researchers and practitioners having to rely on a series of trials and errors. To initialize a systematic study of the field, we concentrate on one of the most popular classes of RC methods, namely echo state network, and ask: What is the minimal complexity of reservoir construction for obtaining competitive models and what is the memory capacity (MC) of such simplified reservoirs? On a number of widely used time series benchmarks of different origin and characteristics, as well as by conducting a theoretical analysis we show that a simple deterministically constructed cycle reservoir is comparable to the standard echo state network methodology. The (short-term) of linear cyclic reservoirs can be made arbitrarily close to the proved optimal value.","Reservoirs,
Thyristors,
Training,
Time series analysis,
Topology,
Communication channels,
Computational modeling"
High quality depth map upsampling for 3D-TOF cameras,"This paper describes an application framework to perform high quality upsampling on depth maps captured from a low-resolution and noisy 3D time-of-flight (3D-ToF) camera that has been coupled with a high-resolution RGB camera. Our framework is inspired by recent work that uses nonlocal means filtering to regularize depth maps in order to maintain fine detail and structure. Our framework extends this regularization with an additional edge weighting scheme based on several image features based on the additional high-resolution RGB input. Quantitative and qualitative results show that our method outperforms existing approaches for 3D-ToF upsampling. We describe the complete process for this system, including device calibration, scene warping for input alignment, and even how the results can be further processed using simple user markup.",
Design of a Maximally Permissive Liveness- Enforcing Petri Net Supervisor for Flexible Manufacturing Systems,"Deadlock prevention plays an important role in the modeling and control of flexible manufacturing systems (FMS). This paper presents a novel and computationally efficient method to design optimal control places, and an iteration approach that only computes the reachability graph of a plant Petri net model once in order to obtain a maximally permissive liveness-enforcing supervisor for an FMS. By using a vector covering approach, a minimal covering set of legal markings and a minimal covered set of first-met bad markings (FBM) are computed. At each iteration, an FBM from the minimal covered set is selected. By solving an integer linear programming problem, a place invariant is designed to prevent the FBM from being reached and no marking in the minimal covering set of legal markings is forbidden. This process is carried out until no FBM can be reached. In order to make the considered problem computationally tractable, binary decision diagrams (BDD) are used to compute the sets of legal markings and FBM, and solve the vector covering problem to get a minimal covering set of legal markings and a minimal covered set of FBM. Finally, a number of FMS examples are presented to illustrate the proposed approaches.","Law,
System recovery,
Petri nets,
Computational modeling,
Data structures,
Boolean functions"
On building an accurate stereo matching system on graphics hardware,"This paper presents a GPU-based stereo matching system with good performance in both accuracy and speed. The matching cost volume is initialized with an AD-Census measure, aggregated in dynamic cross-based regions, and updated in a scanline optimization framework to produce the disparity results. Various errors in the disparity results are effectively handled in a multi-step refinement process. Each stage of the system is designed with parallelism considerations such that the computations can be accelerated with CUDA implementations. Experimental results demonstrate the accuracy and the efficiency of the system: currently it is the top performer in the Middlebury benchmark, and the results are achieved on GPU within 0.1 seconds. We also provide extra examples on stereo video sequences and discuss the limitations of the system.","Stereo vision,
Image color analysis,
Graphics processing unit,
Reliability,
Interpolation,
Image edge detection,
Accuracy"
Enhancing Differential Evolution Utilizing Proximity-Based Mutation Operators,"Differential evolution is a very popular optimization algorithm and considerable research has been devoted to the development of efficient search operators. Motivated by the different manner in which various search operators behave, we propose a novel framework based on the proximity characteristics among the individual solutions as they evolve. Our framework incorporates information of neighboring individuals, in an attempt to efficiently guide the evolution of the population toward the global optimum, without sacrificing the search capabilities of the algorithm. More specifically, the random selection of parents during mutation is modified, by assigning to each individual a probability of selection that is inversely proportional to its distance from the mutated individual. The proposed framework can be applied to any mutation strategy with minimal changes. In this paper, we incorporate this framework in the original differential evolution algorithm, as well as other recently proposed differential evolution variants. Through an extensive experimental study, we show that the proposed framework results in enhanced performance for the majority of the benchmark problems studied.",
Energy-Efficient Distributed Spectrum Sensing for Cognitive Sensor Networks,"Reliability and energy consumption in detection are key objectives for distributed spectrum sensing in cognitive sensor networks. In conventional distributed sensing approaches, although the detection performance improves with the number of radios, so does the network energy consumption. We consider a combined sleeping and censoring scheme as an energy efficient spectrum sensing technique for cognitive sensor networks. Our objective is to minimize the energy consumed in distributed sensing subject to constraints on the detection performance, by optimally choosing the sleeping and censoring design parameters. The constraint on the detection performance is given by a minimum target probability of detection and a maximum permissible probability of false alarm. Depending on the availability of prior knowledge about the probability of primary user presence, two cases are considered. The case where a priori knowledge is not available defines the blind setup; otherwise the setup is called knowledge-aided. By considering a sensor network based on IEEE 802.15.4/ZigBee radios, we show that significant energy savings can be achieved by the proposed scheme.",
Control of Wind Turbines,"Wind energy is a fast-growing interdisciplinary field that encompasses multiple branches of engineering and science. Despite the growth in the installed capacity of wind turbines in recent years, larger wind turbines have energy capture and economic advantages, the typical size of utility scale wind turbines has grown by two orders of magnitude. Since modern wind turbines are large, flexible structures operating in uncertain environments, advanced control technology can improve their performance.The goal of this article is to describe the technical challenges in the wind industry relating to control engineering.",
Traffic sign recognition with multi-scale Convolutional Networks,"We apply Convolutional Networks (ConvNets) to the task of traffic sign classification as part of the GTSRB competition. ConvNets are biologically-inspired multi-stage architectures that automatically learn hierarchies of invariant features. While many popular vision approaches use hand-crafted features such as HOG or SIFT, ConvNets learn features at every level from data that are tuned to the task at hand. The traditional ConvNet architecture was modified by feeding 1st stage features in addition to 2nd stage features to the classifier. The system yielded the 2nd-best accuracy of 98.97% during phase I of the competition (the best entry obtained 98.98%), above the human performance of 98.81%, using 32×32 color input images. Experiments conducted after phase 1 produced a new record of 99.17% by increasing the network capacity, and by using greyscale images instead of color. Interestingly, random features still yielded competitive results (97.33%).",
A study of the routing and spectrum allocation in spectrum-sliced Elastic Optical Path networks,"In OFDM-based optical networks, multiple subcarriers can be allocated to accommodate various size of traffic demands. By using the multi-carrier modulation technique, subcarriers for the same node-pair can be overlapping in the spectrum domain. Compared to the traditional wavelength routed networks (WRNs), the OFDM-based Spectrum-sliced Elastic Optical Path (SLICE) network has higher spectrum efficiency due to its finer granularity and frequency-resource saving. In this work, for the first time, we comprehensively study the routing and spectrum allocation (RSA) problem in the SLICE network. After proving the NP-hardness of the static RSA problem, we formulate the RSA problem using the Integer Linear Programming (ILP) formulations to optimally minimize the maximum number of sub-carriers required on any fiber of a SLICE network. We then analyze the lower/upper bounds for the sub-carrier number in a network with general or specific topology. We also propose two efficient algorithms, namely, balanced load spectrum allocation (BLSA) algorithm and shortest path with maximum spectrum reuse (SPSR) algorithm to minimize the required sub-carrier number in a SLICE network. The results show that the proposed algorithms can match the analysis and approximate the optimal solutions using the ILP model.","OFDM,
Routing,
Resource management,
Optical fiber networks,
Indexes,
Upper bound,
Frequency domain analysis"
A Survey on Visual Content-Based Video Indexing and Retrieval,"Video indexing and retrieval have a wide spectrum of promising applications, motivating the interest of researchers worldwide. This paper offers a tutorial and an overview of the landscape of general strategies in visual content-based video indexing and retrieval, focusing on methods for video structure analysis, including shot boundary detection, key frame extraction and scene segmentation, extraction of features including static key frame features, object features and motion features, video data mining, video annotation, video retrieval including query interfaces, similarity measure and relevance feedback, and video browsing. Finally, we analyze future research directions.",
Piezoelectric MEMS Energy Harvester for Low-Frequency Vibrations With Wideband Operation Range and Steadily Increased Output Power,"A piezoelectric MEMS energy harvester (EH) with low resonant frequency and wide operation bandwidth was designed, microfabricated, and characterized. The MEMS piezoelectric energy harvesting cantilever consists of a silicon beam integrated with piezoelectric thin film (PZT) elements parallel-arranged on top and a silicon proof mass resulting in a low resonant frequency of 36 Hz. The whole chip was assembled onto a metal carrier with a limited spacer such that the operation frequency bandwidth can be widened to 17 Hz at the input acceleration of 1.0 g during frequency up-sweep. Load voltage and power generation for different numbers of PZT elements in series and in parallel connections were compared and discussed based on experimental and simulation results. Moreover, the EH device has a wideband and steadily increased power generation from 19.4 nW to 51.3 nW within the operation frequency bandwidth ranging from 30 Hz to 47 Hz at 1.0 g. Based on theoretical estimation, a potential output power of 0.53 μW could be harvested from low and irregular frequency vibrations by adjusting the PZT pattern and spacer thickness to achieve an optimal design.","Resonant frequency,
Vibrations,
Wideband,
Acceleration,
Strain,
Energy harvesting,
Micromechanical devices"
A Lightweight Message Authentication Scheme for Smart Grid Communications,"Smart grid (SG) communication has recently received significant attentions to facilitate intelligent and distributed electric power transmission systems. However, communication trust and security issues still present practical concerns to the deployment of SG. In this paper, to cope with these challenging concerns, we propose a lightweight message authentication scheme features as a basic yet crucial component for secure SG communication framework. Specifically, in the proposed scheme, the smart meters which are distributed at different hierarchical networks of the SG can first achieve mutual authentication and establish the shared session key with Diffie-Hellman exchange protocol. Then, with the shared session key between smart meters and hash-based authentication code technique, the subsequent messages can be authenticated in a lightweight way. Detailed security analysis shows that the proposed scheme can satisfy the desirable security requirements of SG communications. In addition, extensive simulations have also been conducted to demonstrate the effectiveness of the proposed scheme in terms of low latency and few signal message exchanges.",
Relaxing non-volatility for fast and energy-efficient STT-RAM caches,"Spin-Transfer Torque RAM (STT-RAM) is an emerging non-volatile memory technology that is a potential universal memory that could replace SRAM in processor caches. This paper presents a novel approach for redesigning STT-RAM memory cells to reduce the high dynamic energy and slow write latencies. We lower the retention time by reducing the planar area of the cell, thereby reducing the write current, which we then use with CACTI to design caches and memories. We simulate quad-core processor designs using a combination of SRAM- and STT-RAM-based caches. Since ultra-low retention STT-RAM may lose data, we also provide a preliminary evaluation for a simple, DRAM-style refresh policy. We found that a pure STT-RAM cache hierarchy provides the best energy efficiency, though a hybrid design of SRAM-based L1 caches with reduced-retention STT-RAM L2 and L3 caches eliminates performance loss while still reducing the energy-delay product by more than 70%.","Random access memory,
Magnetic tunneling,
Nonvolatile memory,
Integrated circuit modeling,
Switches,
Temperature,
Thermal stability"
Efficient Fully Homomorphic Encryption from (Standard) LWE,"We present a fully homomorphic encryption scheme that is based solely on the (standard) learning with errors (LWE) assumption. Applying known results on LWE, the security of our scheme is based on the worst-case hardness of ""short vector problems"" on arbitrary lattices. Our construction improves on previous works in two aspects: 1) We show that ""somewhat homomorphic"" encryption can be based on LWE, using a new re-linearization technique. In contrast, all previous schemes relied on complexity assumptions related to ideals in various rings. 2) We deviate from the ""squashing paradigm"" used in all previous works. We introduce a new dimension-modulus reduction technique, which shortens the ciphertexts and reduces the decryption complexity of our scheme, without introducing additional assumptions. Our scheme has very short ciphertexts and we therefore use it to construct an asymptotically efficient LWE-based single-server private information retrieval (PIR) protocol. The communication complexity of our protocol (in the public-key model) is k · polylog(k) + log |DB| bits per single-bit query (here, A; is a security parameter).","Encryption,
Lattices,
Complexity theory,
Protocols,
Databases"
Indoor scene segmentation using a structured light sensor,"In this paper we explore how a structured light depth sensor, in the form of the Microsoft Kinect, can assist with indoor scene segmentation. We use a CRF-based model to evaluate a range of different representations for depth information and propose a novel prior on 3D location. We introduce a new and challenging indoor scene dataset, complete with accurate depth maps and dense label coverage. Evaluating our model on this dataset reveals that the combination of depth and intensity images gives dramatic performance gains over intensity images alone. Our results clearly demonstrate the utility of structured light sensors for scene understanding.","Three dimensional displays,
Image edge detection,
Cameras,
Histograms,
TV,
Training,
Feature extraction"
Less is More: Efficient 3-D Object Retrieval With Query View Selection,"The explosively increasing 3-D objects make their efficient retrieval technology highly desired. Extensive research efforts have been dedicated to view-based 3-D object retrieval for its advantage of using 2-D views to represent 3-D objects. In this paradigm, typically the retrieval is accomplished by matching the views of the query object with the objects in database. However, using all the query views may not only introduce difficulty in rapid retrieval but also degrade retrieval accuracy when there is a mismatch between the query views and the object views in the database. In this work, we propose an interactive 3-D object retrieval scheme. Given a set of query views, we first perform clustering to obtain several candidates. We then incrementally select query views for object matching: in each round of relevance feedback, we only add the query view that is judged to be the most informative one based on the labeling information. In addition, we also propose an efficient approach to learn a distance metric for the newly selected query view and the weights for combining all of the selected query views. We conduct experiments on the National Taiwan University 3D Model database, ETH 3D object collection, and Shape Retrieval Content of Non-Rigid 3D Model, and results demonstrated that our approach not only significantly speeds up the retrieval process but also achieves encouraging retrieval performance.","Three dimensional displays,
Solid modeling,
Computational modeling,
Databases,
Feature extraction,
Cameras,
Radio frequency"
Non-Negative Patch Alignment Framework,"In this paper, we present a non-negative patch alignment framework (NPAF) to unify popular non-negative matrix factorization (NMF) related dimension reduction algorithms. It offers a new viewpoint to better understand the common property of different NMF algorithms. Although multiplicative update rule (MUR) can solve NPAF and is easy to implement, it converges slowly. Thus, we propose a fast gradient descent (FGD) to overcome the aforementioned problem. FGD uses the Newton method to search the optimal step size, and thus converges faster than MUR. Experiments on synthetic and real-world datasets confirm the efficiency of FGD compared with MUR for optimizing NPAF. Based on NPAF, we develop non-negative discriminative locality alignment (NDLA). Experiments on face image and handwritten datasets suggest the effectiveness of NDLA in classification tasks and its robustness to image occlusions, compared with representative NMF-related dimension reduction algorithms.",
Sparsity-Cognizant Total Least-Squares for Perturbed Compressive Sampling,"Solving linear regression problems based on the total least-squares (TLS) criterion has well-documented merits in various applications, where perturbations appear both in the data vector as well as in the regression matrix. However, existing TLS approaches do not account for sparsity possibly present in the unknown vector of regression coefficients. On the other hand, sparsity is the key attribute exploited by modern compressive sampling and variable selection approaches to linear regression, which include noise in the data, but do not account for perturbations in the regression matrix. The present paper fills this gap by formulating and solving (regularized) TLS optimization problems under sparsity constraints. Near-optimum and reduced-complexity suboptimum sparse (S-) TLS algorithms are developed to address the perturbed compressive sampling (and the related dictionary learning) challenge, when there is a mismatch between the true and adopted bases over which the unknown vector is sparse. The novel S-TLS schemes also allow for perturbations in the regression matrix of the least-absolute selection and shrinkage selection operator (Lasso), and endow TLS approaches with ability to cope with sparse, under-determined “errors-in-variables” models. Interesting generalizations can further exploit prior knowledge on the perturbations to obtain novel weighted and structured S-TLS solvers. Analysis and simulations demonstrate the practical impact of S-TLS in calibrating the mismatch effects of contemporary grid-based approaches to cognitive radio sensing, and robust direction-of-arrival estimation using antenna arrays.","Vectors,
Sparse matrices,
Convergence,
Image reconstruction,
Covariance matrix,
Antenna arrays,
Data models"
Cluster Synchronization in Directed Networks Via Intermittent Pinning Control,"In this paper, we investigate the cluster synchronization problem for linearly coupled networks, which can be recurrently connected neural networks, cellular neural networks, Hodgkin-Huxley models, Lorenz chaotic oscillators, etc., by adding some simple intermittent pinning controls. We assume the nodes in the network to be identical and the coupling matrix to be asymmetric. Some sufficient conditions to guarantee global cluster synchronization are presented. Furthermore, a centralized adaptive intermittent control is introduced and theoretical analysis is provided. Then, by applying the adaptive approach on the diagonal submatrices of the asymmetric coupling matrix, we also get the corresponding cluster synchronization result. Finally, numerical simulations are given to verify the theoretical results.",
Human action recognition by learning bases of action attributes and parts,"In this work, we propose to use attributes and parts for recognizing human actions in still images. We define action attributes as the verbs that describe the properties of human actions, while the parts of actions are objects and poselets that are closely related to the actions. We jointly model the attributes and parts by learning a set of sparse bases that are shown to carry much semantic meaning. Then, the attributes and parts of an action image can be reconstructed from sparse coefficients with respect to the learned bases. This dual sparsity provides theoretical guarantee of our bases learning and feature reconstruction approach. On the PASCAL action dataset and a new “Stanford 40 Actions” dataset, we show that our method extracts meaningful high-order interactions between attributes and parts in human actions while achieving state-of-the-art classification performance.","Humans,
Detectors,
Image reconstruction,
Vectors,
Feature extraction,
Noise,
Image recognition"
People detection in RGB-D data,"People detection is a key issue for robots and intelligent systems sharing a space with people. Previous works have used cameras and 2D or 3D range finders for this task. In this paper, we present a novel people detection approach for RGB-D data. We take inspiration from the Histogram of Oriented Gradients (HOG) detector to design a robust method to detect people in dense depth data, called Histogram of Oriented Depths (HOD). HOD locally encodes the direction of depth changes and relies on an depth-informed scale-space search that leads to a 3-fold acceleration of the detection process. We then propose Combo-HOD, a RGB-D detector that probabilistically combines HOD and HOG. The experiments include a comprehensive comparison with several alternative detection approaches including visual HOG, several variants of HOD, a geometric person detector for 3D point clouds, and an Haar-based AdaBoost detector. With an equal error rate of 85% in a range up to 8m, the results demonstrate the robustness of HOD and Combo-HOD on a real-world data set collected with a Kinect sensor in a populated indoor environment.",
"Hyperspectral Unmixing via
L
1/2
Sparsity-Constrained Nonnegative Matrix Factorization","Hyperspectral unmixing is a crucial preprocessing step for material classification and recognition. In the last decade, nonnegative matrix factorization (NMF) and its extensions have been intensively studied to unmix hyperspectral imagery and recover the material end-members. As an important constraint for NMF, sparsity has been modeled making use of the L1 regularizer. Unfortunately, the L1 regularizer cannot enforce further sparsity when the full additivity constraint of material abundances is used, hence limiting the practical efficacy of NMF methods in hyperspectral unmixing. In this paper, we extend the NMF method by incorporating the L1/2 sparsity constraint, which we name L1/2 -NMF. The L1/2 regularizer not only induces sparsity but is also a better choice among Lq(0 <; q <; 1) regularizers. We propose an iterative estimation algorithm for L1/2-NMF, which provides sparser and more accurate results than those delivered using the L1 norm. We illustrate the utility of our method on synthetic and real hyperspectral data and compare our results to those yielded by other state-of-the-art methods.","Hyperspectral imaging,
Pixel,
Materials,
Convergence,
Optimization,
Matrix decomposition"
Cython: The Best of Both Worlds,"Cython is a Python language extension that allows explicit type declarations and is compiled directly to C. As such, it addresses Python's large overhead for numerical loops and the difficulty of efficiently using existing C and Fortran code, which Cython can interact with natively.","Sparse matrices,
Runtime,
Syntactics,
Computer programs,
Programming"
Recent Developments in High Performance Computing for Remote Sensing: A Review,"Remote sensing data have become very widespread in recent years, and the exploitation of this technology has gone from developments mainly conducted by government intelligence agencies to those carried out by general users and companies. There is a great deal more to remote sensing data than meets the eye, and extracting that information turns out to be a major computational challenge. For this purpose, high performance computing (HPC) infrastructure such as clusters, distributed networks or specialized hardware devices provide important architectural developments to accelerate the computations related with information extraction in remote sensing. In this paper, we review recent advances in HPC applied to remote sensing problems; in particular, the HPC-based paradigms included in this review comprise multiprocessor systems, large-scale and heterogeneous networks of computers, grid and cloud computing environments, and hardware systems such as field programmable gate arrays (FPGAs) and graphics processing units (GPUs). Combined, these parts deliver a snapshot of the state-of-the-art and most recent developments in those areas, and offer a thoughtful perspective of the potential and emerging challenges of applying HPC paradigms to remote sensing problems.",
3D Face Reconstruction from a Single Image Using a Single Reference Face Shape,"Human faces are remarkably similar in global properties, including size, aspect ratio, and location of main features, but can vary considerably in details across individuals, gender, race, or due to facial expression. We propose a novel method for 3D shape recovery of faces that exploits the similarity of faces. Our method obtains as input a single image and uses a mere single 3D reference model of a different person's face. Classical reconstruction methods from single images, i.e., shape-from-shading, require knowledge of the reflectance properties and lighting as well as depth values for boundary conditions. Recent methods circumvent these requirements by representing input faces as combinations (of hundreds) of stored 3D models. We propose instead to use the input image as a guide to ""mold” a single reference model to reach a reconstruction of the sought 3D shape. Our method assumes Lambertian reflectance and uses harmonic representations of lighting. It has been tested on images taken under controlled viewing conditions as well as on uncontrolled images downloaded from the Internet, demonstrating its accuracy and robustness under a variety of imaging conditions and overcoming significant differences in shape between the input and reference individuals including differences in facial expressions, gender, and race.",
Adaptive deconvolutional networks for mid and high level feature learning,"We present a hierarchical model that learns image decompositions via alternating layers of convolutional sparse coding and max pooling. When trained on natural images, the layers of our model capture image information in a variety of forms: low-level edges, mid-level edge junctions, high-level object parts and complete objects. To build our model we rely on a novel inference scheme that ensures each layer reconstructs the input, rather than just the output of the layer directly beneath, as is common with existing hierarchical approaches. This makes it possible to learn multiple layers of representation and we show models with 4 layers, trained on images from the Caltech-101 and 256 datasets. When combined with a standard classifier, features extracted from these models outperform SIFT, as well as representations from other feature learning methods.","Image reconstruction,
Switches,
Computational modeling,
Adaptation models,
Mathematical model,
Training,
Deconvolution"
Relay Selection for Two-Way Relaying With Amplify-and-Forward Protocols,"In this paper, we propose a relay selection amplify-and-forward (RS-AF) protocol in general bidirectional relay networks with two sources and N relays. In the proposed scheme, the two sources first simultaneously transmit to all the relays, and then, a single relay with a minimum sum symbol error rate (SER) will be selected to broadcast the received signals back to both sources. To facilitate the selection process, we propose a simple suboptimal min-max criterion for relay selection, where a single relay that minimizes the maximum SER of two source nodes will be selected. Simulation results show that the proposed min-max selection has almost the same performance as the optimal selection with lower complexity. We also present a simple asymptotic SER expression and make a comparison with the conventional all-participate AF relaying scheme. The analytical results are verified through simulations. To improve the system performance, optimal power allocation (OPA) between the sources and the relay is determined based on the asymptotic SER. Simulation results indicate that the proposed RS-AF scheme with OPA yields considerable performance improvement over an equal-power-allocation scheme, particularly with a large number of relay nodes.","Relays,
Signal to noise ratio,
Resource management,
Bidirectional control,
Simulation,
Protocols,
Silicon"
A Self-Organizing Strategy for Power Flow Control of Photovoltaic Generators in a Distribution Network,"The focus of this paper is to develop a distributed control algorithm that will regulate the power output of multiple photovoltaic generators (PVs) in a distribution network. To this end, the cooperative control methodology from network control theory is used to make a group of PV generators converge and operate at certain (or the same) ratio of available power, which is determined by the status of the distribution network and the PV generators. The proposed control only requires asynchronous information intermittently from neighboring PV generators, making a communication network among the PV units both simple and necessary. The minimum requirement on communication topologies is also prescribed for the proposed control. It is shown that the proposed analysis and design methodology has the advantages that the corresponding communication networks are local, their topology can be time varying, and their bandwidth may be limited. These features enable PV generators to have both self-organizing and adaptive coordination properties even under adverse conditions. The proposed method is simulated using the IEEE standard 34-bus distribution network.","Generators,
Communication networks,
Topology,
Distributed control,
Network topology,
Voltage control,
Power system dynamics"
Robust Video Surveillance for Fall Detection Based on Human Shape Deformation,"Faced with the growing population of seniors, developed countries need to establish new healthcare systems to ensure the safety of elderly people at home. Computer vision provides a promising solution to analyze personal behavior and detect certain unusual events such as falls. In this paper, a new method is proposed to detect falls by analyzing human shape deformation during a video sequence. A shape matching technique is used to track the person's silhouette along the video sequence. The shape deformation is then quantified from these silhouettes based on shape analysis methods. Finally, falls are detected from normal activities using a Gaussian mixture model. This paper has been conducted on a realistic data set of daily activities and simulated falls, and gives very good results (as low as 0% error with a multi-camera setup) compared with other common image processing methods.","Shape,
Cameras,
Machine vision,
Three dimensional displays,
Image edge detection,
Humans,
Video sequences"
An Attack Surface Metric,"Measurement of software security is a long-standing challenge to the research community. At the same time, practical security metrics and measurements are essential for secure software development. Hence, the need for metrics is more pressing now due to a growing demand for secure software. In this paper, we propose using a software system's attack surface measurement as an indicator of the system's security. We formalize the notion of a system's attack surface and introduce an attack surface metric to measure the attack surface in a systematic manner. Our measurement method is agnostic to a software system's implementation language and is applicable to systems of all sizes; we demonstrate our method by measuring the attack surfaces of small desktop applications and large enterprise systems implemented in C and Java. We conducted three exploratory empirical studies to validate our method. Software developers can mitigate their software's security risk by measuring and reducing their software's attack surfaces. Our attack surface reduction approach complements the software industry's traditional code quality improvement approach for security risk mitigation and is useful in multiple phases of the software development lifecycle. Our collaboration with SAP demonstrates the use of our metric in the software development process.",
"Reserve Requirement Impacts of Large-Scale Integration of Wind, Solar, and Ocean Wave Power Generation","Many sources of renewable energy, including solar, wind, and ocean wave, offer significant advantages such as no fuel costs and no emissions from generation. However, in most cases these renewable power sources are variable and nondispatchable. The utility grid is already able to accommodate the variability of the load and some additional variability introduced by sources such as wind. However, at high penetration levels, the variability of renewable power sources can severely impact the utility reserve requirements. This paper presents an analysis of the interaction between the variability characteristics of the utility load, wind power generation, solar power generation, and ocean wave power generation. The results show that a diversified variable renewable energy mix can reduce the utility reserve requirement and help reduce the effects of variability.","Wind forecasting,
Wind power generation,
Forecasting,
Renewable energy resources,
Ocean waves"
Bayesian Compressive Sampling for Pattern Synthesis With Maximally Sparse Non-Uniform Linear Arrays,A numerically-efficient technique based on the Bayesian compressive sampling (BCS) for the design of maximally-sparse linear arrays is introduced. The method is based on a probabilistic formulation of the array synthesis and it exploits a fast relevance vector machine (RVM) for the problem solution. The proposed approach allows the design of linear arrangements fitting desired power patterns with a reduced number of non-uniformly spaced active elements. The numerical validation assesses the effectiveness and computational efficiency of the proposed approach as a suitable complement to existing state-of-the-art techniques for the design of sparse arrays.,"Pattern matching,
Accuracy,
Bayesian methods,
Apertures,
Phased arrays,
Layout,
Sensitivity analysis"
"Applications, Architectures, and Protocol Design Issues for Mobile Social Networks: A Survey","The mobile social network (MSN) combines techniques in social science and wireless communications for mobile networking. The MSN can be considered as a system which provides a variety of data delivery services involving the social relationship among mobile users. This paper presents a comprehensive survey on the MSN specifically from the perspectives of applications, network architectures, and protocol design issues. First, major applications of the MSN are reviewed. Next, different architectures of the MSN are presented. Each of these different architectures supports different data delivery scenarios. The unique characteristics of social relationship in MSN give rise to different protocol design issues. These research issues (e.g., community detection, mobility, content distribution, content sharing protocols, and privacy) and the related approaches to address data delivery in the MSN are described. At the end, several important research directions are outlined.","Mobile communication,
Social network services,
Mobile computing,
Mobile handsets,
Network architecture,
Privacy,
Wireless communication"
Classification of Hyperspectral Images by Using Extended Morphological Attribute Profiles and Independent Component Analysis,"In this letter, a technique based on independent component analysis (ICA) and extended morphological attribute profiles (EAPs) is presented for the classification of hyperspectral images. The ICA maps the data into a subspace in which the components are as independent as possible. APs, which are extracted by using several attributes, are applied to each image associated with an extracted independent component, leading to a set of extended EAPs. Two approaches are presented for including the computed profiles in the analysis. The features extracted by the morphological processing are then classified with an SVM. The experiments carried out on two hyperspectral images proved the effectiveness of the proposed technique.",
Aiming Perfectly in the Dark-Blind Interference Alignment Through Staggered Antenna Switching,"We propose a blind interference alignment scheme for the vector broadcast channel where the transmitter is equipped with M antennas and there are K receivers, each equipped with a reconfigurable antenna capable of switching among M preset modes. Without any knowledge of the channel coefficient values at the transmitters and with only mild assumptions on the channel coherence structure we show that MK/M+K-1 degrees of freedom are achievable. The key to the blind interference alignment scheme is the ability of the receivers to switch between reconfigurable antenna modes to create short term channel fluctuation patterns that are exploited by the transmitter. The achievable scheme does not require cooperation between transmit antennas and is therefore applicable to the M × K X network as well. Only finite symbol extensions are used, and no channel knowledge at the receivers is required to null the interference.",
Batch-Mode Active-Learning Methods for the Interactive Classification of Remote Sensing Images,"This paper investigates different batch-mode active-learning (AL) techniques for the classification of remote sensing (RS) images with support vector machines. This is done by generalizing to multiclass problem techniques defined for binary classifiers. The investigated techniques exploit different query functions, which are based on the evaluation of two criteria: uncertainty and diversity. The uncertainty criterion is associated to the confidence of the supervised algorithm in correctly classifying the considered sample, while the diversity criterion aims at selecting a set of unlabeled samples that are as more diverse (distant one another) as possible, thus reducing the redundancy among the selected samples. The combination of the two criteria results in the selection of the potentially most informative set of samples at each iteration of the AL process. Moreover, we propose a novel query function that is based on a kernel-clustering technique for assessing the diversity of samples and a new strategy for selecting the most informative representative sample from each cluster. The investigated and proposed techniques are theoretically and experimentally compared with state-of-the-art methods adopted for RS applications. This is accomplished by considering very high resolution multispectral and hyperspectral images. By this comparison, we observed that the proposed method resulted in better accuracy with respect to other investigated and state-of-the art methods on both the considered data sets. Furthermore, we derived some guidelines on the design of AL systems for the classification of different types of RS images.","Training,
Support vector machines,
Uncertainty,
Labeling,
Hyperspectral imaging,
Classification algorithms,
Machine learning"
Distributed Intrusion Detection System in a Multi-Layer Network Architecture of Smart Grids,"The advent of the smart grid promises to usher in an era that will bring intelligence, efficiency, and optimality to the power grid. Most of these changes will occur as an Internet-like communications network is superimposed on top of the current power grid using wireless mesh network technologies with the 802.15.4, 802.11, and WiMAX standards. Each of these will expose the power grid to cybersecurity threats. In order to address this issue, this work proposes a distributed intrusion detection system for smart grids (SGDIDS) by developing and deploying an intelligent module, the analyzing module (AM), in multiple layers of the smart grid. Multiple AMs will be embedded at each level of the smart grid-the home area networks (HANs), neighborhood area networks (NANs), and wide area networks (WANs)-where they will use the support vector machine (SVM) and artificial immune system (AIS) to detect and classify malicious data and possible cyberattacks. AMs at each level are trained using data that is relevant to their level and will also be able to communicate in order to improve detection. Simulation results demonstrate that this is a promising methodology for supporting the optimal communication routing and improving system security through the identification of malicious network traffic.",
Driver Drowsiness Classification Using Fuzzy Wavelet-Packet-Based Feature-Extraction Algorithm,"Driver drowsiness and loss of vigilance are a major cause of road accidents. Monitoring physiological signals while driving provides the possibility of detecting and warning of drowsiness and fatigue. The aim of this paper is to maximize the amount of drowsiness-related information extracted from a set of electroencephalogram (EEG), electrooculogram (EOG), and electrocardiogram (ECG) signals during a simulation driving test. Specifically, we develop an efficient fuzzy mutual-information (MI)- based wavelet packet transform (FMIWPT) feature-extraction method for classifying the driver drowsiness state into one of predefined drowsiness levels. The proposed method estimates the required MI using a novel approach based on fuzzy memberships providing an accurate-information content-estimation measure. The quality of the extracted features was assessed on datasets collected from 31 drivers on a simulation test. The experimental results proved the significance of FMIWPT in extracting features that highly correlate with the different drowsiness levels achieving a classification accuracy of 95%-97% on an average across all subjects.","Feature extraction,
Entropy,
Mutual information,
Wavelet packets,
Driver circuits,
Electroencephalography"
Complex-Valued Signal Processing: The Proper Way to Deal With Impropriety,"Complex-valued signals occur in many areas of science and engineering and are thus of fundamental interest. In the past, it has often been assumed, usually implicitly, that complex random signals are proper or circular. A proper complex random variable is uncorrelated with its complex conjugate, and a circular complex random variable has a probability distribution that is invariant under rotation in the complex plane. While these assumptions are convenient because they simplify computations, there are many cases where proper and circular random signals are very poor models of the underlying physics. When taking impropriety and noncircularity into account, the right type of processing can provide significant performance gains. There are two key ingredients in the statistical signal processing of complex-valued data: 1) utilizing the complete statistical characterization of complex-valued random signals; and 2) the optimization of real-valued cost functions with respect to complex parameters. In this overview article, we review the necessary tools, among which are widely linear transformations, augmented statistical descriptions, and Wirtinger calculus. We also present some selected recent developments in the field of complex-valued signal processing, addressing the topics of model selection, filtering, and source separation.",
Fast mode decision algorithm for intra prediction in HEVC,"As the next generation standard of video coding, the High Efficiency Video Coding (HEVC) is intended to provide significantly better coding efficiency than all existing video coding standards. To improve the coding efficiency of intra frame coding, up to 34 intra prediction modes are defined in HEVC. The best mode among these pre-defined intra prediction modes is selected by rate-distortion optimization (RDO) for each block. If all directions are tested in the RDO process, it will be very time-consuming. To alleviate the encoder computation load, this paper proposes a new method to reduce the candidates in RDO process. In addition, the direction information of the neighboring blocks is made full use of to speed up intra mode decision. Experimental results show that the proposed scheme provides 20% and 28% time savings in intra high efficiency and low complexity cases on average compared to the default encoding scheme in HM 1.0 with almost the same coding efficiency. This algorithm has been proposed to HEVC standard and partially adopted into the HEVC test model.",
Adaptive Neural Output Feedback Controller Design With Reduced-Order Observer for a Class of Uncertain Nonlinear SISO Systems,"An adaptive output feedback control is studied for uncertain nonlinear single-input-single-output systems with partial unmeasured states. In the scheme, a reduced-order observer (ROO) is designed to estimate those unmeasured states. By employing radial basis function neural networks and incorporating the ROO into a new backstepping design, an adaptive output feedback controller is constructively developed. A prominent advantage is its ability to balance the control action between the state feedback and the output feedback. In addition, the scheme can be still implemented when all the states are not available. The stability of the closed-loop system is guaranteed in the sense that all the signals are semiglobal uniformly ultimately bounded and the system output tracks the reference signal to a bounded compact set. A simulation example is given to validate the effectiveness of the proposed scheme.","Nonlinear systems,
Output feedback,
Observers,
Silicon,
Adaptive systems,
Lyapunov methods,
Artificial neural networks"
Road Detection Based on Illuminant Invariance,"By using an onboard camera, it is possible to detect the free road surface ahead of the ego-vehicle. Road detection is of high relevance for autonomous driving, road departure warning, and supporting driver-assistance systems such as vehicle and pedestrian detection. The key for vision-based road detection is the ability to classify image pixels as belonging or not to the road surface. Identifying road pixels is a major challenge due to the intraclass variability caused by lighting conditions. A particularly difficult scenario appears when the road surface has both shadowed and nonshadowed areas. Accordingly, we propose a novel approach to vision-based road detection that is robust to shadows. The novelty of our approach relies on using a shadow-invariant feature space combined with a model-based classifier. The model is built online to improve the adaptability of the algorithm to the current lighting and the presence of other vehicles in the scene. The proposed algorithm works in still images and does not depend on either road shape or temporal restrictions. Quantitative and qualitative experiments on real-world road sequences with heavy traffic and shadows show that the method is robust to shadows and lighting variations. Moreover, the proposed method provides the highest performance when compared with hue-saturation-intensity (HSI)-based algorithms.",
A Computational Framework for Uncertainty Quantification and Stochastic Optimization in Unit Commitment With Wind Power Generation,We present a computational framework for integrating a state-of-the-art numerical weather prediction (NWP) model in stochastic unit commitment/economic dispatch formulations that account for wind power uncertainty. We first enhance the NWP model with an ensemble-based uncertainty quantification strategy implemented in a distributed-memory parallel computing architecture. We discuss computational issues arising in the implementation of the framework and validate the model using real wind-speed data obtained from a set of meteorological stations. We build a simulated power system to demonstrate the developments.,"Uncertainty,
Stochastic processes,
Wind power generation,
Power system modeling,
Power system simulation,
Weather forecasting,
Predictive models,
Power generation economics,
Economic forecasting,
Wind energy"
Combining randomization and discrimination for fine-grained image categorization,"In this paper, we study the problem of fine-grained image categorization. The goal of our method is to explore fine image statistics and identify the discriminative image patches for recognition. We achieve this goal by combining two ideas, discriminative feature mining and randomization. Discriminative feature mining allows us to model the detailed information that distinguishes different classes of images, while randomization allows us to handle the huge feature space and prevents over-fitting. We propose a random forest with discriminative decision trees algorithm, where every tree node is a discriminative classifier that is trained by combining the information in this node as well as all upstream nodes. Our method is tested on both subordinate categorization and activity recognition datasets. Experimental results show that our method identifies semantically meaningful visual information and outperforms state-of-the-art algorithms on various datasets.","Vegetation,
Decision trees,
Humans,
Correlation,
Visualization,
Training,
Feature extraction"
The first facial expression recognition and analysis challenge,"Automatic Facial Expression Recognition and Analysis, in particular FACS Action Unit (AU) detection and discrete emotion detection, has been an active topic in computer science for over two decades. Standardisation and comparability has come some way; for instance, there exist a number of commonly used facial expression databases. However, lack of a common evaluation protocol and lack of sufficient details to reproduce the reported individual results make it difficult to compare systems to each other. This in turn hinders the progress of the field. A periodical challenge in Facial Expression Recognition and Analysis would allow this comparison in a fair manner. It would clarify how far the field has come, and would allow us to identify new goals, challenges and targets. In this paper we present the first challenge in automatic recognition of facial expressions to be held during the IEEE conference on Face and Gesture Recognition 2011, in Santa Barbara, California. Two sub-challenges are defined: one on AU detection and another on discrete emotion detection. It outlines the evaluation protocol, the data used, and the results of a baseline method for the two sub-challenges.",
Anytime Motion Planning using the RRT*,"The Rapidly-exploring Random Tree (RRT) algorithm, based on incremental sampling, efficiently computes motion plans. Although the RRT algorithm quickly produces candidate feasible solutions, it tends to converge to a solution that is far from optimal. Practical applications favor ""anytime"" algorithms that quickly identify an initial feasible plan, then, given more computation time available during plan execution, improve the plan toward an optimal solution. This paper describes an anytime algorithm based on the RRT* which (like the RRT) finds an initial feasible solution quickly, but (unlike the RRT) almost surely converges to an optimal solution. We present two key extensions to the RRT% committed trajectories and branch-and-bound tree adaptation, that together enable the algorithm to make more efficient use of computation time online, resulting in an anytime algorithm for real-time implementation. We evaluate the method using a series of Monte Carlo runs in a high-fidelity simulation environment, and compare the operation of the RRT and RRT* methods. We also demonstrate experimental results for an outdoor wheeled robotic vehicle.",
Multi-target tracking by continuous energy minimization,"We propose to formulate multi-target tracking as minimization of a continuous energy function. Other than a number of recent approaches we focus on designing an energy function that represents the problem as faithfully as possible, rather than one that is amenable to elegant optimization. We then go on to construct a suitable optimization scheme to find strong local minima of the proposed energy. The scheme extends the conjugate gradient method with periodic trans-dimensional jumps. These moves allow the search to escape weak minima and explore a much larger portion of the variable-dimensional search space, while still always reducing the energy. To demonstrate the validity of this approach we present an extensive quantitative evaluation both on synthetic data and on six different real video sequences. In both cases we achieve a significant performance improvement over an extended Kalman filter baseline as well as an ILP-based state-of-the-art tracker.","Trajectory,
Target tracking,
Optimization,
Minimization,
Detectors,
Search problems"
Rethinking the Secrecy Outage Formulation: A Secure Transmission Design Perspective,"This letter studies information-theoretic security without knowing the eavesdropper's channel fading state. We present an alternative secrecy outage formulation to measure the probability that message transmissions fail to achieve perfect secrecy. Using this formulation, we design two transmission schemes that satisfy the given security requirement while achieving good throughput performance.","Security,
Throughput,
Signal to noise ratio,
Quality of service,
Fading,
Delay,
Channel capacity"
MRF Energy Minimization and Beyond via Dual Decomposition,"This paper introduces a new rigorous theoretical framework to address discrete MRF-based optimization in computer vision. Such a framework exploits the powerful technique of Dual Decomposition. It is based on a projected subgradient scheme that attempts to solve an MRF optimization problem by first decomposing it into a set of appropriately chosen subproblems, and then combining their solutions in a principled way. In order to determine the limits of this method, we analyze the conditions that these subproblems have to satisfy and demonstrate the extreme generality and flexibility of such an approach. We thus show that by appropriately choosing what subproblems to use, one can design novel and very powerful MRF optimization algorithms. For instance, in this manner we are able to derive algorithms that: 1) generalize and extend state-of-the-art message-passing methods, 2) optimize very tight LP-relaxations to MRF optimization, and 3) take full advantage of the special structure that may exist in particular MRFs, allowing the use of efficient inference techniques such as, e.g., graph-cut-based methods. Theoretical analysis on the bounds related with the different algorithms derived from our framework and experimental results/comparisons using synthetic and real data for a variety of tasks in computer vision demonstrate the extreme potentials of our approach.","Computer vision,
Optimization methods,
Inference algorithms,
Algorithm design and analysis,
Markov random fields,
Graphical models,
Computer science,
Design optimization,
Linear programming,
Application software"
Novel Dry Polymer Foam Electrodes for Long-Term EEG Measurement,"A novel dry foam-based electrode for long-term EEG measurement was proposed in this study. In general, the conventional wet electrodes are most frequently used for EEG measurement. However, they require skin preparation and conduction gels to reduce the skin-electrode contact impedance. The aforementioned procedures when wet electrodes were used usually make trouble to users easily. In order to overcome the aforesaid issues, a novel dry foam electrode, fabricated by electrically conductive polymer foam covered by a conductive fabric, was proposed. By using conductive fabric, which provides partly polarizable electric characteristic, our dry foam electrode exhibits both polarization and conductivity, and can be used to measure biopotentials without skin preparation and conduction gel. In addition, the foam substrate of our dry electrode allows a high geometric conformity between the electrode and irregular scalp surface to maintain low skin-electrode interface impedance, even under motion. The experimental results presented that the dry foam electrode performs better for long-term EEG measurement, and is practicable for daily life applications.","Electrodes,
Electroencephalography,
Impedance,
Skin,
Forehead,
Fabrics,
Scalp"
Enhanced Differential Evolution With Adaptive Strategies for Numerical Optimization,"Differential evolution (DE) is a simple, yet efficient, evolutionary algorithm for global numerical optimization, which has been widely used in many areas. However, the choice of the best mutation strategy is difficult for a specific problem. To alleviate this drawback and enhance the performance of DE, in this paper, we present a family of improved DE that attempts to adaptively choose a more suitable strategy for a problem at hand. In addition, in our proposed strategy adaptation mechanism (SaM), different parameter adaptation methods of DE can be used for different strategies. In order to test the efficiency of our approach, we combine our proposed SaM with JADE, which is a recently proposed DE variant, for numerical optimization. Twenty widely used scalable benchmark problems are chosen from the literature as the test suit. Experimental results verify our expectation that the SaM is able to adaptively determine a more suitable strategy for a specific problem. Compared with other state-of-the-art DE variants, our approach performs better, or at least comparably, in terms of the quality of the final solutions and the convergence rate. Finally, we validate the powerful capability of our approach by solving two real-world optimization problems.","Optimization,
Chromium,
Benchmark testing,
Next generation networking,
Artificial neural networks,
Cybernetics,
Silicon"
A Fuzzy Association Rule-Based Classification Model for High-Dimensional Problems With Genetic Rule Selection and Lateral Tuning,"The inductive learning of fuzzy rule-based classification systems suffers from exponential growth of the fuzzy rule search space when the number of patterns and/or variables becomes high. This growth makes the learning process more difficult and, in most cases, it leads to problems of scalability (in terms of the time and memory consumed) and/or complexity (with respect to the number of rules obtained and the number of variables included in each rule). In this paper, we propose a fuzzy association rule-based classification method for high-dimensional problems, which is based on three stages to obtain an accurate and compact fuzzy rule-based classifier with a low computational cost. This method limits the order of the associations in the association rule extraction and considers the use of subgroup discovery, which is based on an improved weighted relative accuracy measure to preselect the most interesting rules before a genetic postprocessing process for rule selection and parameter tuning. The results that are obtained more than 26 real-world datasets of different sizes and with different numbers of variables demonstrate the effectiveness of the proposed approach.",
Globally Optimal Linear Precoders for Finite Alphabet Signals Over Complex Vector Gaussian Channels,"We study the design optimization of linear precoders for maximizing the mutual information between finite alphabet input and the corresponding output over complex-valued vector channels. This mutual information is a nonlinear and non-concave function of the precoder parameters, posing a major obstacle to precoder design optimization. Our work presents three main contributions: First, we prove that the mutual information is a concave function of a matrix which itself is a quadratic function of the precoder matrix. Second, we propose a parameterized iterative algorithm for finding optimal linear precoders to achieve the global maximum of the mutual information. The proposed iterative algorithm is numerically robust, computationally efficient, and globally convergent. Third, we demonstrate that maximizing the mutual information between a discrete constellation input and the corresponding output of a vector channel not only provides the highest practically achievable rate but also serves as an excellent criterion for minimizing the coded bit error rate. Our numerical examples show that the proposed algorithm achieves mutual information very close to the channel capacity for channel coding rate under 0.75, and also exhibits a large gain over existing linear precoding and/or power allocation algorithms. Moreover, our examples show that certain existing methods are susceptible to being trapped at locally optimal precoders.",
Periocular Biometrics in the Visible Spectrum,"The term periocular refers to the facial region in the immediate vicinity of the eye. Acquisition of the periocular biometric is expected to require less subject cooperation while permitting a larger depth of field compared to traditional ocular biometric traits (viz., iris, retina, and sclera). In this work, we study the feasibility of using the periocular region as a biometric trait. Global and local information are extracted from the periocular region using texture and point operators resulting in a feature set for representing and matching this region. A number of aspects are studied in this work, including the 1) effectiveness of incorporating the eyebrows, 2) use of side information (left or right) in matching, 3) manual versus automatic segmentation schemes, 4) local versus global feature extraction schemes, 5) fusion of face and periocular biometrics, 6) use of the periocular biometric in partially occluded face images, 7) effect of disguising the eyebrows, 8) effect of pose variation and occlusion, 9) effect of masking the iris and eye region, and 10) effect of template aging on matching performance. Experimental results show a rank-one recognition accuracy of 87.32% using 1136 probe and 1136 gallery periocular images taken from 568 different subjects (2 images/subject) in the Face Recognition Grand Challenge (version 2.0) database with the fusion of three different matchers.","Iris recognition,
Face,
Feature extraction,
Retina,
Eyebrows,
Sensors"
A Sparse Aperture MIMO-SAR-Based UWB Imaging System for Concealed Weapon Detection,"A high-resolution imaging system based on the combination of ultrawideband (UWB) transmission, multiple-input-multiple-output (MIMO) array, and synthetic aperture radar (SAR) is suggested and studied. Starting from the resolution requirements, spatial sampling criteria for nonmonochromatic waves are investigated. Exploring the decisive influence of the system's fractional bandwidth (instead of previously claimed aperture sparsity) on the imaging capabilities of sparse aperture arrays, a MIMO linear array is designed based on the principle of effective aperture. For the antenna array, an optimized UWB antenna is designed allowing for distortionless impulse radiation with more than 150% fractional bandwidth. By combining the digital beamforming in the MIMO array with the SAR in the orthogonal direction, a high-resolution 3-D volumetric imaging system with a significantly reduced number of antenna elements is proposed. The proposed imaging system is experimentally verified against the conventional 2-D SAR under different conditions, including a typical concealed-weapon-detection scenario. The imaging results confirm the correctness of the proposed system design and show a strong potential of the MIMO-SAR-based UWB system for security applications.","Apertures,
Weapons,
High-resolution imaging,
MIMO,
Bandwidth,
Linear antenna arrays,
Ultra wideband antennas,
Antenna arrays,
Radar detection,
Ultra wideband technology"
A Comprehensive Analysis of the MAC Unreliability Problem in IEEE 802.15.4 Wireless Sensor Networks,"Wireless Sensor Networks (WSNs) represent a very promising solution in the field of wireless technologies for industrial applications. However, for a credible deployment of WSNs in an industrial environment, four main properties need to be fulfilled, i.e., energy efficiency, scalability, reliability, and timeliness. In this paper, we focus on IEEE 802.15.4 WSNs and show that they can suffer from a serious unreliability problem. This problem arises whenever the power management mechanism is enabled for energy efficiency, and results in a very low packet delivery ratio, also when the number of sensor nodes in the network is very low (e.g., 5). We carried out an extensive analysis-based on both simulation and experiments on a real WSN-to investigate the fundamental reasons of this problem, and we found that it is caused by the contention-based Medium Access Control (MAC) protocol used for channel access and its default parameter values. We also found that, with a more appropriate MAC parameters setting, it is possible to mitigate the problem and achieve a delivery ratio up to 100%, at least in the scenarios considered in this paper. However, this improvement in communication reliability is achieved at the cost of an increased latency, which may not be acceptable for industrial applications with stringent timing requirements. In addition, in some cases this is possible only by choosing MAC parameter values formally not allowed by the standard.","Wireless sensor networks,
Media Access Protocol,
Multiaccess communication,
Reliability,
Analytical models,
Wireless communication,
Sensors"
A Printed Leaky-Wave Antenna Based on a Sinusoidally-Modulated Reactance Surface,"A simple procedure for designing a sinusoidally-modulated reactance surface (SMRS) that radiates at an arbitrary off-broadside angle is outlined. The procedure allows for nearly independent control of the leakage and phase constants along the surface. Printing an array of metallic strips over a grounded dielectric substrate is discussed as a way to practically implement the theoretical SMRS. A method of mapping the gaps between metallic strips to a desired surface impedance is presented as an efficient alternative to mapping methods used in the past. A printed leaky-wave antenna with a sinusoidally-modulated surface reactance is designed using the procedure mentioned above. The TM-polarized antenna radiates at 30° from broadside at 10 GHz, and exhibits an experimental gain of 18.4 dB. Theoretical, simulated, and experimental results are presented.",
"Bypassing synthesis: PLS for face recognition with pose, low-resolution and sketch","This paper presents a novel way to perform multi-modal face recognition. We use Partial Least Squares (PLS) to linearly map images in different modalities to a common linear subspace in which they are highly correlated. PLS has been previously used effectively for feature selection in face recognition. We show both theoretically and experimentally that PLS can be used effectively across modalities. We also formulate a generic intermediate subspace comparison framework for multi-modal recognition. Surprisingly, we achieve high performance using only pixel intensities as features. We experimentally demonstrate the highest published recognition rates on the pose variations in the PIE data set, and also show that PLS can be used to compare sketches to photos, and to compare images taken at different resolutions.",
Impact of SiC Devices on Hybrid Electric and Plug-In Hybrid Electric Vehicles,"The application of silicon carbide (SiC) devices as battery interface, motor controller, etc., in a hybrid electric vehicle (HEV) will be beneficial due to their high-temperature capability, high-power density, and high efficiency. Moreover, the light weight and small volume will affect the whole powertrain system in a HEV and, thus, the performance and cost. In this paper, the performance of HEVs is analyzed using the vehicle simulation software Powertrain System Analysis Toolkit (PSAT). Power loss models of a SiC inverter based on the test results of latest SiC devices are incorporated into PSAT powertrain models in order to study the impact of SiC devices on HEVs from a system standpoint and give a direct correlation between the inverter efficiency and weight and the vehicle's fuel economy. Two types of HEVs are considered. One is the 2004 Toyota Prius HEV, and the other is a plug-in HEV (PHEV), whose powertrain architecture is the same as that of the 2004 Toyota Prius HEV. The vehicle-level benefits from the introduction of SiC devices are demonstrated by simulations. Not only the power loss in the motor controller but also those in other components in the vehicle powertrain are reduced. As a result, the system efficiency is improved, and vehicles that incorporate SiC power electronics are predicted to consume less energy and have lower emissions and improved system compactness with a simplified thermal management system. For the PHEV, the benefits are even more distinct; in particular, the size of the battery bank can be reduced for optimum design.",
Online detection of unusual events in videos via dynamic sparse coding,"Real-time unusual event detection in video stream has been a difficult challenge due to the lack of sufficient training information, volatility of the definitions for both normality and abnormality, time constraints, and statistical limitation of the fitness of any parametric models. We propose a fully unsupervised dynamic sparse coding approach for detecting unusual events in videos based on online sparse re-constructibility of query signals from an atomically learned event dictionary, which forms a sparse coding bases. Based on an intuition that usual events in a video are more likely to be reconstructible from an event dictionary, whereas unusual events are not, our algorithm employs a principled convex optimization formulation that allows both a sparse reconstruction code, and an online dictionary to be jointly inferred and updated. Our algorithm is completely un-supervised, making no prior assumptions of what unusual events may look like and the settings of the cameras. The fact that the bases dictionary is updated in an online fashion as the algorithm observes more data, avoids any issues with concept drift. Experimental results on hours of real world surveillance video and several Youtube videos show that the proposed algorithm could reliably locate the unusual events in the video sequence, outperforming the current state-of-the-art methods.","Videos,
Dictionaries,
Encoding,
Event detection,
Image reconstruction,
Optimization,
Video sequences"
A Survey of Network Design Problems and Joint Design Approaches in Wireless Mesh Networks,"Over the last decade, the paradigm of Wireless Mesh Networks (WMNs) has matured to a reasonably commonly understood one, and there has been extensive research on various areas related to WMNs such as design, deployment, protocols, performance, etc. The quantity of research being conducted in the area of wireless mesh design has dramatically increased in the past few years, due to increasing interest in this paradigm as its potential for the ""last few miles"", and the possibility of significant wireless services in metropolitan area networks. This recent work has focused increasingly on joint design problems, together with studies in designing specific aspects of the WMN such as routing, power control etc. in isolation. While excellent surveys and tutorials pertaining to WMNs exist in literature, the explosive growth of research in the area of specific design issues, and especially joint design, has left them behind. Our objective in this paper is to identify the fundamental WMN design problems of interference modeling, power control, topology control, link scheduling, and routing, and provide brief overviews, together with a survey of the recent research on these topics, with special stress on joint design methods. We believe this paper will fulfill an outstanding need in informing the interested student and researcher in getting familiar with this abundant recent research area, and starting research.","Wireless mesh networks,
Routing,
Power control,
Wireless application protocol,
Metropolitan area networks,
Explosives,
Interference,
Topology,
Stress control,
Design methodology"
Center-surround divergence of feature statistics for salient object detection,"In this paper, we introduce a new method to detect salient objects in images. The approach is based on the standard structure of cognitive visual attention models, but realizes the computation of saliency in each feature dimension in an information-theoretic way. The method allows a consistent computation of all feature channels and a well-founded fusion of these channels to a saliency map. Our framework enables the computation of arbitrarily scaled features and local center-surround pairs in an efficient manner. We show that our approach outperforms eight state-of-the-art saliency detectors in terms of precision and recall.",
Self-repairing homomorphic codes for distributed storage systems,"Erasure codes provide a storage efficient alternative to replication based redundancy in (networked) storage systems. They however entail high communication overhead for maintenance, when some of the encoded fragments are lost and need to be replenished. Such overheads arise from the fundamental need to recreate (or keep separately) first a copy of the whole object before any individual encoded fragment can be generated and replenished. There has recently been intense interest to explore alternatives, most prominent ones being regenerating codes (RGC) and hierarchical codes (HC). We propose as an alternative a new family of codes to improve the maintenance process, called self-repairing codes (SRC), with the following salient features: (a) encoded fragments can be repaired directly from other subsets of encoded fragments by downloading less data than the size of the complete object, ensuring that (b) a fragment is repaired from a fixed number of encoded fragments, the number depending only on how many encoded blocks are missing and independent of which specific blocks are missing. These properties allow for not only low communication overhead to recreate a missing fragment, but also independent reconstruction of different missing fragments in parallel, possibly in different parts of the network. The fundamental difference between SRCs and HCs is that different encoded fragments in HCs do not have symmetric roles (equal importance). Consequently the number of fragments required to replenish a specific fragment in HCs depends on which specific fragments are missing, and not solely on how many. Likewise, object reconstruction may need different number of fragments depending on which fragments are missing. RGCs apply network coding over (n, k) erasure codes, and provide network information flow based limits on the minimal maintenance overheads. RGCs need to communicate with at least k other nodes to recreate any fragment, and the minimal overhead is achieved if only one fragment is missing, and information is downloaded from all the other n-1 nodes. We analyze the static resilience of SRCs with respect to erasure codes, and observe that SRCs incur marginally larger storage overhead in order to achieve the aforementioned properties. The salient SRC properties naturally translate to low communication overheads for reconstruction of lost fragments, and allow reconstruction with lower latency by facilitating repairs in parallel. These desirable properties make SRC a practical candidate for networked distributed storage systems.",
Experience-Driven Procedural Content Generation,"Procedural content generation (PCG) is an increasingly important area of technology within modern human-computer interaction (HCI) design. Personalization of user experience via affective and cognitive modeling, coupled with real-time adjustment of the content according to user needs and preferences are important steps toward effective and meaningful PCG. Games, Web 2.0, interface, and software design are among the most popular applications of automated content generation. The paper provides a taxonomy of PCG algorithms and introduces a framework for PCG driven by computational models of user experience. This approach, which we call Experience-Driven Procedural Content Generation (EDPCG), is generic and applicable to various subareas of HCI. We employ games as an example indicative of rich HCI and complex affect elicitation, and demonstrate the approach's effectiveness via dissimilar successful studies.","Games,
Computational modeling,
Human computer interaction,
Data models,
Adaptation model,
Content distribution networks,
User interfaces,
Behavioral science"
Graphene Sensors,"This paper reviews the potential of graphene as a material for fabricating various types of sensors. Graphene is a monolayer of carbon atoms which exhibits some remarkable electronic and mechanical properties and many of these properties lend themselves to sensor applications. The review attempts to be comprehensive in sensor types covering chemical and electrochemical sensors, magnetic and electric field sensors, optical sensors together with mass and strain sensors. The fact that graphene offers some advantages over this entire range of sensing modalities is an indication of its versatility and importance.","Chemical sensors,
Mechanical sensors,
Magnetic sensors,
Optical sensors,
Strain control,
Carbon electronics"
Distributed Subgradient Methods for Convex Optimization Over Random Networks,"We consider the problem of cooperatively minimizing the sum of convex functions, where the functions represent local objective functions of the agents. We assume that each agent has information about his local function, and communicate with the other agents over a time-varying network topology. For this problem, we propose a distributed subgradient method that uses averaging algorithms for locally sharing information among the agents. In contrast to previous works on multi-agent optimization that make worst-case assumptions about the connectivity of the agents (such as bounded communication intervals between nodes), we assume that links fail according to a given stochastic process. Under the assumption that the link failures are independent and identically distributed over time (possibly correlated across links), we provide almost sure convergence results for our subgradient algorithm.",
Recognition using visual phrases,"In this paper we introduce visual phrases, complex visual composites like “a person riding a horse”. Visual phrases often display significantly reduced visual complexity compared to their component objects, because the appearance of those objects can change profoundly when they participate in relations. We introduce a dataset suitable for phrasal recognition that uses familiar PASCAL object categories, and demonstrate significant experimental gains resulting from exploiting visual phrases. We show that a visual phrase detector significantly outperforms a baseline which detects component objects and reasons about relations, even though visual phrase training sets tend to be smaller than those for objects. We argue that any multi-class detection system must decode detector outputs to produce final results; this is usually done with non-maximum suppression. We describe a novel decoding procedure that can account accurately for local context without solving difficult inference problems. We show this decoding procedure outperforms the state of the art. Finally, we show that decoding a combination of phrasal and object detectors produces real improvements in detector results.",
Optimal Energy Storage Sizing and Control for Wind Power Applications,"The variable output of a large wind farm presents many integration challenges, especially at high levels of penetration. The uncertainty in the output of a large wind plant can be covered by using fast-acting dispatchable sources, such as natural gas turbines or hydro generators. However, using dispatchable sources on short notice to smooth the variability of wind power can increase the cost of large-scale wind power integration. To remedy this, the inclusion of large-scale energy storage at the wind farm output can be used to improve the predictability of wind power and reduce the need for load following and regulation hydro or fossil-fuel reserve generation. This paper presents sizing and control methodologies for a zinc-bromine flow battery-based energy storage system. The results show that the power flow control strategy does have a significant impact on proper sizing of the rated power and energy of the system. In particular, artificial neural network control strategies resulted in significantly lower cost energy storage systems than simplified controllers. The results show that through more effective control and coordination of energy storage systems, the predictability of wind plant outputs can be increased and the cost of integration associated with reserve requirements can be decreased.","Energy storage,
Optimal control,
Wind energy,
Control systems,
Costs,
Wind farms,
Wind energy generation,
Uncertainty,
Natural gas,
Hydraulic turbines"
Optimal decentralized protocol for electric vehicle charging,"Motivated by the power-grid-side challenges in the integration of electric vehicles, we propose a decentralized protocol for negotiating day-ahead charging schedules for electric vehicles. The overall goal is to shift the load due to electric vehicles to fill the overnight electricity demand valley. In each iteration of the proposed protocol, electric vehicles choose their own charging profiles for the following day according to the price profile broadcast by the utility, and the utility updates the price profile to guide their behavior. This protocol is guaranteed to converge, irrespective of the specifications (e.g., maximum charging rate and deadline) of electric vehicles. At convergence, the l2 norm of the aggregated demand is minimized, and the aggregated demand profile is as “flat” as it can possibly be. The proposed protocol needs no coordination among the electric vehicles, hence requires low communication and computation capability. Simulation results demonstrate convergence to optimal collections of charging profiles within few iterations.",
Variational Bayesian Super Resolution,"In this paper, we address the super resolution (SR) problem from a set of degraded low resolution (LR) images to obtain a high resolution (HR) image. Accurate estimation of the sub-pixel motion between the LR images significantly affects the performance of the reconstructed HR image. In this paper, we propose novel super resolution methods where the HR image and the motion parameters are estimated simultaneously. Utilizing a Bayesian formulation, we model the unknown HR image, the acquisition process, the motion parameters and the unknown model parameters in a stochastic sense. Employing a variational Bayesian analysis, we develop two novel algorithms which jointly estimate the distributions of all unknowns. The proposed framework has the following advantages: 1) Through the incorporation of uncertainty of the estimates, the algorithms prevent the propagation of errors between the estimates of the various unknowns; 2) the algorithms are robust to errors in the estimation of the motion parameters; and 3) using a fully Bayesian formulation, the developed algorithms simultaneously estimate all algorithmic parameters along with the HR image and motion parameters, and therefore they are fully-automated and do not require parameter tuning. We also show that the proposed motion estimation method is a stochastic generalization of the classical Lucas-Kanade registration algorithm. Experimental results demonstrate that the proposed approaches are very effective and compare favorably to state-of-the-art SR algorithms.",
Network Coding Meets TCP: Theory and Implementation,"The theory of network coding promises significant benefits in network performance, especially in lossy networks and in multicast and multipath scenarios. To realize these benefits in practice, we need to understand how coding across packets interacts with the acknowledgment (ACK)-based flow control mechanism that forms a central part of today's Internet protocols such as transmission control protocol (TCP). Current approaches such as rateless codes and batch-based coding are not compatible with TCP's retransmission and sliding-window mechanisms. In this paper, we propose a new mechanism called TCP/NC that incorporates network coding into TCP with only minor changes to the protocol stack, thereby allowing incremental deployment. In our scheme, the source transmits random linear combinations of packets currently in the congestion window. At the heart of our scheme is a new interpretation of ACKs-the sink acknowledges every degree of freedom (i.e., a linear combination that reveals one unit of new information) even if it does not reveal an original packet immediately. Thus, our new TCP ACK rule takes into account the network coding operations in the lower layer and enables a TCP-compatible sliding-window approach to network coding. Coding essentially masks losses from the congestion control algorithm and allows TCP/NC to react smoothly to losses, resulting in a novel and effective approach for congestion control over lossy networks such as wireless networks. An important feature of our solution is that it allows intermediate nodes to perform re-encoding of packets, which is known to provide significant throughput gains in lossy networks and multicast scenarios. Simulations show that our scheme, with or without re-encoding inside the network, achieves much higher throughput compared to TCP over lossy wireless links. We present a real-world implementation of this protocol that addresses the practical aspects of incorporating network coding and decoding with TCP's window management mechanism. We work with TCP-Reno, which is a widespread and practical variant of TCP. Our implementation significantly advances the goal of designing a deployable, general, TCP-compatible protocol that provides the benefits of network coding.","Network coding,
Encoding,
Protocols,
Telecommunication network reliability,
Throughput,
Multicast communication"
Resolving the Limb Position Effect in Myoelectric Pattern Recognition,"Reported studies on pattern recognition of electromyograms (EMG) for the control of prosthetic devices traditionally focus on classification accuracy of signals recorded in a laboratory. The difference between the constrained nature in which such data are often collected and the unpredictable nature of prosthetic use is an example of the semantic gap between research findings and a viable clinical implementation. In this paper, we demonstrate that the variations in limb position associated with normal use can have a substantial impact on the robustness of EMG pattern recognition, as illustrated by an in- crease in average classification error from 3.8% to 18%. We propose to solve this problem by: 1) collecting EMG data and training the classifier in multiple limb positions and by 2) measuring the limb position with accelerometers. Applying these two methods to data from ten normally limbed subjects, we reduce the average classification error from 18% to 5.7% and 5.0%, respectively. Our study shows how sensor fusion (using EMG and accelerometers) may be an efficient method to mitigate the effect of limb position and improve classification accuracy.",
Spatial pyramid co-occurrence for image classification,"We describe a novel image representation termed spatial pyramid co-occurrence which characterizes both the photometric and geometric aspects of an image. Specifically, the co-occurrences of visual words are computed with respect to spatial predicates over a hierarchical spatial partitioning of an image. The representation captures both the absolute and relative spatial arrangement of the words and, through the choice and combination of the predicates, can characterize a variety of spatial relationships. Our representation is motivated by the analysis of overhead imagery such as from satellites or aircraft. This imagery generally does not have an absolute reference frame and thus the relative spatial arrangement of the image elements often becomes the key discriminating feature. We validate this hypothesis using a challenging ground truth image dataset of 21 land-use classes manually extracted from high-resolution aerial imagery. Our approach is shown to result in higher classification rates than a non-spatial bagof- visual-words approach as well as a popular approach for characterizing the absolute spatial arrangement of visual words, the spatial pyramid representation of Lazebnik et al. [7]. While our primary objective is analyzing overhead imagery, we demonstrate that our approach achieves state-of-the-art performance on the Graz-01 object class dataset and performs competitively on the 15 Scene dataset.","Visualization,
Kernel,
Histograms,
Dictionaries,
Spatial resolution,
Feature extraction"
Depth kernel descriptors for object recognition,"Consumer depth cameras, such as the Microsoft Kinect, are capable of providing frames of dense depth values at real time. One fundamental question in utilizing depth cameras is how to best extract features from depth frames. Motivated by local descriptors on images, in particular kernel descriptors, we develop a set of kernel features on depth images that model size, 3D shape, and depth edges in a single framework. Through extensive experiments on object recognition, we show that (1) our local features capture different aspects of cues from a depth frame/view that complement one another; (2) our kernel features significantly outperform traditional 3D features (e.g. Spin images); and (3) we significantly improve the capabilities of depth and RGB-D (color+depth) recognition, achieving 10–15% improvement in accuracy over the state of the art.",
TextFlow: Towards Better Understanding of Evolving Topics in Text,"Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.","Text analysis,
Data visualization,
Tag clouds,
Image color analysis"
Feedback Capacity of the Gaussian Interference Channel to Within 2 Bits,"We characterize the capacity region to within 2 bits/s/Hz and the symmetric capacity to within 1 bit/s/Hz for the two-user Gaussian interference channel (IC) with feedback. We develop achievable schemes and derive a new outer bound to arrive at this conclusion. One consequence of the result is that feedback provides multiplicative gain at high signal-to-noise ratio: the gain becomes arbitrarily large for certain channel parameters. This finding is in contrast to point-to-point and multiple-access channels where feedback provides no gain and only bounded additive gain respectively. The result makes use of a linear deterministic model to provide insights into the Gaussian channel. This deterministic model is a special case of the El Gamal-Costa deterministic model and as a side-generalization, we establish the exact feedback capacity region of this general class of deterministic ICs.","Receivers,
Transmitters,
Integrated circuit modeling,
Interference channels,
Gain"
Achievable Rate Regions and Performance Comparison of Half Duplex Bi-Directional Relaying Protocols,"In a bi-directional relay channel, two nodes wish to exchange independent messages over a shared wireless half-duplex channel with the help of a relay. In this paper, we derive achievable rate regions for four new half-duplex protocols and compare these to four existing half-duplex protocols and outer bounds. In time, our protocols consist of either two or three phases. In the two phase protocols, both users simultaneously transmit during the first phase and the relay alone transmits during the second phase, while in the three phase protocol the two users sequentially transmit followed by a transmission from the relay. The relay may forward information in one of four manners; we outline existing amplify and forward (AF), decode and forward (DF), lattice based, and compress and forward (CF) relaying schemes and introduce the novel mixed forward scheme. The latter is a combination of CF in one direction and DF in the other. We derive achievable rate regions for the CF and Mixed relaying schemes for the two and three phase protocols. We provide a comprehensive treatment of eight possible half-duplex bi-directional relaying protocols in Gaussian noise, obtaining their relative performance under different SNR and relay geometries.","Protocols,
Relays,
Markov processes,
Bidirectional control,
Decoding,
Lattices,
Gaussian noise"
Saliency estimation using a non-parametric low-level vision model,"Many successful models for predicting attention in a scene involve three main steps: convolution with a set of filters, a center-surround mechanism and spatial pooling to construct a saliency map. However, integrating spatial information and justifying the choice of various parameter values remain open problems. In this paper we show that an efficient model of color appearance in human vision, which contains a principled selection of parameters as well as an innate spatial pooling mechanism, can be generalized to obtain a saliency model that outperforms state-of-the-art models. Scale integration is achieved by an inverse wavelet transform over the set of scale-weighted center-surround responses. The scale-weighting function (termed ECSF) has been optimized to better replicate psychophysical data on color appearance, and the appropriate sizes of the center-surround inhibition windows have been determined by training a Gaussian Mixture Model on eye-fixation data, thus avoiding ad-hoc parameter selection. Additionally, we conclude that the extension of a color appearance model to saliency estimation adds to the evidence for a common low-level visual front-end for different visual tasks.",
A Distributed Model for Border Traps in \hbox{Al}_{2} \hbox{O}_{3}-\hbox{InGaAs} MOS Devices,A distributed border trap model based on tunneling between the semiconductor surface and trap states in the gate dielectric film is formulated to account for the observed frequency dispersion in the capacitance and conductance of Al2O3/InGaAs MOS devices biased in accumulation. The distributed circuit model is more physical and descriptive than previous lumped circuit border trap models in the literature. The distributed model correctly depicts the frequency dependence of both capacitance and conductance data in accumulation. A border trap volume density is extracted from the quantitative agreement with measured data.,"Capacitance,
Logic gates,
Integrated circuit modeling,
Tunneling,
Aluminum oxide,
Biological system modeling,
Semiconductor device measurement"
The computer expression recognition toolbox (CERT),"We present the Computer Expression Recognition Toolbox (CERT), a software tool for fully automatic real-time facial expression recognition, and officially release it for free academic use. CERT can automatically code the intensity of 19 different facial actions from the Facial Action Unit Coding System (FACS) and 6 different prototypical facial expressions. It also estimates the locations of 10 facial features as well as the 3-D orientation (yaw, pitch, roll) of the head. On a database of posed facial expressions, Extended Cohn-Kanade (CK+[1]), CERT achieves an average recognition performance (probability of correctness on a two-alternative forced choice (2AFC) task between one positive and one negative example) of 90.1% when analyzing facial actions. On a spontaneous facial expression dataset, CERT achieves an accuracy of nearly 80%. In a standard dual core laptop, CERT can process 320 × 240 video images in real time at approximately 10 frames per second.",
Coordinated Beamforming for MISO Interference Channel: Complexity Analysis and Efficient Algorithms,"In a cellular wireless system, users located at cell edges often suffer significant out-of-cell interference. Assuming each base station is equipped with multiple antennas, we can model this scenario as a multiple-input single-output (MISO) interference channel. In this paper we consider a coordinated beamforming approach whereby multiple base stations jointly optimize their downlink beamforming vectors in order to simultaneously improve the data rates of a given group of cell edge users. Assuming perfect channel knowledge, we formulate this problem as the maximization of a system utility (which balances user fairness and average user rates), subject to individual power constraints at each base station. We show that, for the single-carrier case and when the number of antennas at each base station is at least two, the optimal coordinated beamforming problem is NP-hard for both the harmonic mean utility and the proportional fairness utility. For general utilities, we propose a cyclic coordinate descent algorithm, which enables each transmitter to update its beamformer locally with limited information exchange and establish its global convergence to a stationary point. We illustrate its effectiveness in computer simulations by using the space matched beamformer as the benchmark.",
Richardson-Lucy Deblurring for Scenes under a Projective Motion Path,"This paper addresses how to model and correct image blur that arises when a camera undergoes ego motion while observing a distant scene. In particular, we discuss how the blurred image can be modeled as an integration of the clear scene under a sequence of planar projective transformations (i.e., homographies) that describe the camera's path. This projective motion path blur model is more effective at modeling the spatially varying motion blur exhibited by ego motion than conventional methods based on space-invariant blur kernels. To correct the blurred image, we describe how to modify the Richardson-Lucy (RL) algorithm to incorporate this new blur model. In addition, we show that our projective motion RL algorithm can incorporate state-of-the-art regularization priors to improve the deblurred results. The projective motion path blur model, along with the modified RL algorithm, is detailed, together with experimental results demonstrating its overall effectiveness. Statistical analysis on the algorithm's convergence properties and robustness to noise is also provided.","Mathematical model,
Cameras,
Equations,
Pixel,
Convolution,
Algorithm design and analysis,
Kernel"
High Performance Computing for Hyperspectral Remote Sensing,"Advances in sensor and computer technology are revolutionizing the way remotely sensed data is collected, managed and analyzed. In particular, many current and future applications of remote sensing in Earth science, space science, and soon in exploration science will require real- or near real-time processing capabilities. In recent years, several efforts have been directed towards the incorporation of high-performance computing (HPC) models to remote sensing missions. A relevant example of a remote sensing application in which the use of HPC technologies (such as parallel and distributed computing) is becoming essential is hyperspectral remote sensing, in which an imaging spectrometer collects hundreds or even thousands of measurements (at multiple wavelength channels) for the same area on the surface of the Earth. In this paper, we review recent developments in the application of HPC techniques to hyperspectral imaging problems, with particular emphasis on commodity architectures such as clusters, heterogeneous networks of computers, and specialized hardware devices such as field programmable gate arrays (FPGAs) and commodity graphic processing units (GPUs). A quantitative comparison across these architectures is given by analyzing performance results of different parallel implementations of the same hyperspectral unmixing chain, delivering a snapshot of the state-of-the-art in this area and a thoughtful perspective on the potential and emerging challenges of applying HPC paradigms to hyperspectral remote sensing problems.","Hyperspectral imaging,
Field programmable gate arrays,
Pixel,
Hardware,
Data processing"
Parallel MR Image Reconstruction Using Augmented Lagrangian Methods,"Magnetic resonance image (MRI) reconstruction using SENSitivity Encoding (SENSE) requires regularization to suppress noise and aliasing effects. Edge-preserving and sparsity-based regularization criteria can improve image quality, but they demand computation-intensive nonlinear optimization. In this paper, we present novel methods for regularized MRI reconstruction from undersampled sensitivity encoded data-SENSE-reconstruction-using the augmented Lagrangian (AL) framework for solving large-scale constrained optimization problems. We first formulate regularized SENSE-reconstruction as an unconstrained optimization task and then convert it to a set of (equivalent) constrained problems using variable splitting. We then attack these constrained versions in an AL framework using an alternating minimization method, leading to algorithms that can be implemented easily. The proposed methods are applicable to a general class of regularizers that includes popular edge-preserving (e.g., total-variation) and sparsity-promoting (e.g., -norm of wavelet coefficients) criteria and combinations thereof. Numerical experiments with synthetic and in vivo human data illustrate that the proposed AL algorithms converge faster than both general-purpose optimization algorithms such as nonlinear conjugate gradient (NCG) and state-of-the-art MFISTA.","Convergence,
Humans,
Coils,
Image reconstruction,
Covariance matrix,
Optimized production technology,
Sensitivity"
Inverter VAR control for distribution systems with renewables,"Motivated by the need to cope with rapid and random fluctuations of renewable generation, we presents a model that augments the traditional Volt/VAR control through switched controllers on a slow timescale with inverter control on a fast timescale. The optimization problem is generally nonconvex and therefore hard to solve. We propose a simple convex relaxation and prove that it is exact provided over-satisfaction of load is allowed. Hence Volt/VAR control over radial networks is efficiently solvable. Simulations of a real-world distribution circuit illustrates that the proposed inverter control achieves significant improvement over the IEEE 1547 standard in terms of power quality and power savings.","Reactive power,
Inverters,
Capacitors,
Switches,
Substations,
Optimization"
PW-MAC: An energy-efficient predictive-wakeup MAC protocol for wireless sensor networks,"This paper presents PW-MAC (Predictive-Wakeup MAC), a new energy-efficient MAC protocol based on asynchronous duty cycling. In PW-MAC, nodes each wake up to receive at randomized, asynchronous times. PW-MAC minimizes sensor node energy consumption by enabling senders to predict receiver wakeup times; to enable accurate predictions, PW-MAC introduces an on-demand prediction error correction mechanism that effectively addresses timing challenges such as unpredictable hardware and operating system delays and clock drift. PW-MAC also introduces an efficient prediction-based retransmission mechanism to achieve high energy efficiency even when wireless collisions occur and packets must be retransmitted. We evaluate PW-MAC on a testbed of MICAz motes and compare it to X-MAC, WiseMAC, and RI-MAC, three previous energy-efficient MAC protocols, under multiple concurrent multihop traffic flows and under hidden-terminal scenarios and scenarios in which nodes have wakeup schedule conflicts. In all experiments, PW-MAC significantly outperformed these other protocols. For example, evaluated on scenarios with 15 concurrent transceivers in the network, the average sender duty cycle for X-MAC, WiseMAC, and RI-MAC were all over 66%, while PW-MAC's average sender duty cycle was only 11%; the delivery latency for PW-MAC in these scenarios was less than 5% that for WiseMAC and X-MAC. In all experiments, PW-MAC maintained a delivery ratio of 100%.",
"Smart Generation and Transmission With Coherent, Real-Time Data","In recent years, much of the discussion involving “smart grids” has implicitly involved only the distribution side, notably advanced metering. However, today's electric systems have many challenges that also involve the rest of the system. An enabling technology for improving the power system, which has emerged in recent years, is the ability to measure coherent, real-time data. In this paper, we describe major challenges facing electrical generation and transmission today that availability of these measurements can help address. We overview applications using coherent, real-time measurements that are in use today or proposed by researchers. Specifically, we describe, normalize, and then quantitatively compare key factors for these power applications that influence how the delivery system should be planned, implemented, and managed. These factors include whether a person or computer is in the loop and (for both inputs and outputs) latency, rate, criticality, quantity, and geographic scope. From this, we abstract the baseline communications requirements of a data delivery system supporting these applications and suggest implementation guidelines to achieve them. Finally, we overview the state of the art in the supporting computer science areas of overlay networking and distributed computing (including middleware) and analyze gaps in commercial middleware products, utility standards, and issues that limit low-level network protocols from meeting these requirements when used in isolation.","Power system stability,
Real time systems,
Power measurement,
Smart grids,
Power system reliability,
Power system dynamics"
THz Medical Imaging: in vivo Hydration Sensing,"The application of THz to medical imaging is experiencing a surge in both interest and federal funding. A brief overview of the field is provided along with promising and emerging applications and ongoing research. THz imaging phenomenology is discussed and tradeoffs are identified. A THz medical imaging system, operating at ~525 GHz center frequency with ~125 GHz of response normalized bandwidth is introduced and details regarding principles of operation are provided. Two promising medical applications of THz imaging are presented: skin burns and cornea. For burns, images of second degree, partial thickness burns were obtained in rat models in vivo over an 8 hour period. These images clearly show the formation and progression of edema in and around the burn wound area. For cornea, experimental data measuring the hydration of ex vivo porcine cornea under drying is presented demonstrating utility in ophthalmologic applications.","Biomedical imaging,
Absorption,
Skin,
In vivo,
Dielectric constant"
Distributed Algorithms for Learning and Cognitive Medium Access with Logarithmic Regret,"The problem of distributed learning and channel access is considered in a cognitive network with multiple secondary users. The availability statistics of the channels are initially unknown to the secondary users and are estimated using sensing decisions. There is no explicit information exchange or prior agreement among the secondary users and sensing and access decisions are undertaken by them in a completely distributed manner. We propose policies for distributed learning and access which achieve order-optimal cognitive system throughput (number of successful secondary transmissions) under self play, i.e., when implemented at all the secondary users. Equivalently, our policies minimize the sum regret in distributed learning and access, which is the loss in secondary throughput due to learning and distributed access. For the scenario when the number of secondary users is known to the policy, we prove that the total regret is logarithmic in the number of transmission slots. This policy achieves order-optimal regret based on a logarithmic lower bound for regret under any uniformly-good learning and access policy. We then consider the case when the number of secondary users is fixed but unknown, and is estimated at each user through feedback. We propose a policy whose sum regret grows only slightly faster than logarithmic in the number of transmission slots.",
Process Allocation Algorithms for Saving Power Consumption in Peer-to-Peer Systems,"Information systems are composed of various types of computers interconnected in networks. In addition, information systems are being shifted from the traditional client-server model to the peer-to-peer (P2P) model. P2P systems are scalable and fully distributed without any centralized coordinator. Here, it is getting more significant to discuss how to reduce the total electric power consumption of computers in addition to developing distributed algorithms to minimize the computation time and memory space. In this paper, we do not discuss microlevel models like the hardware specifications of computers like low-energy CPUs. We rather discuss a macrolevel model to show the relation of the amount of computation and the total power consumption of multiple peer computers to perform Web types of application processes. We also discuss algorithms for allocating a process to a computer so that the deadline constraint is satisfied and the total power consumption is reduced.",
Understanding egocentric activities,"We present a method to analyze daily activities, such as meal preparation, using video from an egocentric camera. Our method performs inference about activities, actions, hands, and objects. Daily activities are a challenging domain for activity recognition which are well-suited to an egocentric approach. In contrast to previous activity recognition methods, our approach does not require pre-trained detectors for objects and hands. Instead we demonstrate the ability to learn a hierarchical model of an activity by exploiting the consistent appearance of objects, hands, and actions that results from the egocentric context. We show that joint modeling of activities, actions, and objects leads to superior performance in comparison to the case where they are considered independently. We introduce a novel representation of actions based on object-hand interactions and experimentally demonstrate the superior performance of our representation in comparison to standard activity representations such as bag of words.",
State-of-Charge Estimation and State-of-Health Prediction of a Li-Ion Degraded Battery Based on an EKF Combined With a Per-Unit System,"This paper describes the application of an extended Kalman filter (EKF) combined with a per-unit (p.u.) system to the identification of suitable battery model parameters for the high-accuracy state-of-charge (SOC) estimation and state-of-health (SOH) prediction of a Li-Ion degraded battery. Variances in electrochemical characteristics among Li-Ion batteries caused by aging differences result in erroneous SOC estimation and SOH prediction when using the existing EKF algorithm. To apply the battery model parameters varied by the aging effect, based on the p.u. system, the absolute values of the parameters in the equivalent circuit model in addition to the discharging/charging voltage and current are converted into dimensionless values relative to a set of base value. The converted values are applied to dynamic and measurement models in the EKF algorithm. In particular, based on two methods such as direct current internal resistance measurement and the statistical analysis of voltage pattern, each diffusion resistance (RDiff) can be measured and used for offline and online SOC estimations, respectively. All SOC estimates are within ±5% of the values estimated by ampere-hour counting. Moreover, it is shown that RDiff is more sensitive than other model parameters under identical experimental conditions and, hence, implementable for SOH prediction.","Batteries,
System-on-a-chip,
Voltage measurement,
Battery charge measurement,
Current measurement,
Integrated circuit modeling,
Kalman filters"
Optimizing the Channel Selection and Classification Accuracy in EEG-Based BCI,"Multichannel EEG is generally used in brain-computer interfaces (BCIs), whereby performing EEG channel selection 1) improves BCI performance by removing irrelevant or noisy channels and 2) enhances user convenience from the use of lesser channels. This paper proposes a novel sparse common spatial pattern (SCSP) algorithm for EEG channel selection. The proposed SCSP algorithm is formulated as an optimization problem to select the least number of channels within a constraint of classification accuracy. As such, the proposed approach can be customized to yield the best classification accuracy by removing the noisy and irrelevant channels, or retain the least number of channels without compromising the classification accuracy obtained by using all the channels. The proposed SCSP algorithm is evaluated using two motor imagery datasets, one with a moderate number of channels and another with a large number of channels. In both datasets, the proposed SCSP channel selection significantly reduced the number of channels, and outperformed existing channel selection methods based on Fisher criterion, mutual information, support vector machine, common spatial pattern, and regularized common spatial pattern in classification accuracy. The proposed SCSP algorithm also yielded an average improvement of 10% in classification accuracy compared to the use of three channels (C3, C4, and Cz).","Accuracy,
Electroencephalography,
Covariance matrix,
Optimization,
Eigenvalues and eigenfunctions,
Support vector machines,
Testing"
Collaborative Spectrum Sensing from Sparse Observations in Cognitive Radio Networks,"Spectrum sensing, which aims at detecting spectrum holes, is the precondition for the implementation of cognitive radio (CR). Collaborative spectrum sensing among the cognitive radio nodes is expected to improve the ability of checking complete spectrum usage. Due to hardware limitations, each cognitive radio node can only sense a relatively narrow band of radio spectrum. Consequently, the available channel sensing information is far from being sufficient for precisely recognizing the wide range of unoccupied channels. Aiming at breaking this bottleneck, we propose to apply matrix completion and joint sparsity recovery to reduce sensing and transmission requirements and improve sensing results. Specifically, equipped with a frequency selective filter, each cognitive radio node senses linear combinations of multiple channel information and reports them to the fusion center, where occupied channels are then decoded from the reports by using novel matrix completion and joint sparsity recovery algorithms. As a result, the number of reports sent from the CRs to the fusion center is significantly reduced. We propose two decoding approaches, one based on matrix completion and the other based on joint sparsity recovery, both of which allow exact recovery from incomplete reports. The numerical results validate the effectiveness and robustness of our approaches. In particular, in small-scale networks, the matrix completion approach achieves exact channel detection with a number of samples no more than 50% of the number of channels in the network, while joint sparsity recovery achieves similar performance in large-scale networks.","Sensors,
Joints,
Cognitive radio,
Heuristic algorithms,
Collaboration,
Approximation algorithms,
Fading"
Robust Brain Extraction Across Datasets and Comparison With Publicly Available Methods,"Automatic whole-brain extraction from magnetic resonance images (MRI), also known as skull stripping, is a key component in most neuroimage pipelines. As the first element in the chain, its robustness is critical for the overall performance of the system. Many skull stripping methods have been proposed, but the problem is not considered to be completely solved yet. Many systems in the literature have good performance on certain datasets (mostly the datasets they were trained/tuned on), but fail to produce satisfactory results when the acquisition conditions or study populations are different. In this paper we introduce a robust, learning-based brain extraction system (ROBEX). The method combines a discriminative and a generative model to achieve the final result. The discriminative model is a Random Forest classifier trained to detect the brain boundary; the generative model is a point distribution model that ensures that the result is plausible. When a new image is presented to the system, the generative model is explored to find the contour with highest likelihood according to the discriminative model. Because the target shape is in general not perfectly represented by the generative model, the contour is refined using graph cuts to obtain the final segmentation. Both models were trained using 92 scans from a proprietary dataset but they achieve a high degree of robustness on a variety of other datasets. ROBEX was compared with six other popular, publicly available methods (BET, BSE, FreeSurfer, AFNI, BridgeBurner, and GCUT) on three publicly available datasets (IBSR, LPBA40, and OASIS, 137 scans in total) that include a wide range of acquisition hardware and a highly variable population (different age groups, healthy/diseased). The results show that ROBEX provides significantly improved performance measures for almost every method/dataset combination.",
Real-time visual odometry from dense RGB-D images,"We present an energy-based approach to visual odometry from RGB-D images of a Microsoft Kinect camera. To this end we propose an energy function which aims at finding the best rigid body motion to map one RGB-D image into another one, assuming a static scene filmed by a moving camera. We then propose a linearization of the energy function which leads to a 6×6 normal equation for the twist coordinates representing the rigid body motion. To allow for larger motions, we solve this equation in a coarse-to-fine scheme. Extensive quantitative analysis on recently proposed benchmark datasets shows that the proposed solution is faster than a state-of-the-art implementation of the iterative closest point (ICP) algorithm by two orders of magnitude. While ICP is more robust to large camera motion, the proposed method gives better results in the regime of small displacements which are often the case in camera tracking applications.",
Jump-stay based channel-hopping algorithm with guaranteed rendezvous for cognitive radio networks,"Cognitive radio networks (CRNs) have emerged as advanced and promising paradigm to exploit the existing wireless spectrum opportunistically. It is crucial for users in CRNs to search for neighbors via rendezvous process and thereby establish the communication links to exchange the information necessary for spectrum management and channel contention etc. This paper focuses on the design of algorithms for blind rendezvous, i.e., rendezvous without using any central controller and common control channel (CCC). We propose a jump-stay based channel-hopping (CH) algorithm for blind rendezvous. The basic idea is to generate CH sequence in rounds and each round consists of a jump-pattern and a stay-pattern. Users “jump” on available channels in the jump-pattern while “stay” on a specific channel in the stay-pattern. Compared with the existing CH algorithms, our algorithm achieves the following advances: i) guaranteed rendezvous without the need of time-synchronization; ii) applicability to rendezvous of multi-user and multi-hop scenarios. We derive the maximum time-to-rendezvous (TTR) and the upper-bound of expected TTR of our algorithm for both 2-user and multi-user scenarios (shown in Table I). Extensive simulations are further conducted to evaluate performance of our algorithm.","Algorithm design and analysis,
Indexes,
Cognitive radio,
Servers,
Clocks,
Synchronization"
Diversity Management in Evolutionary Many-Objective Optimization,"In evolutionary multiobjective optimization, the task of the optimizer is to obtain an accurate and useful approximation of the true Pareto-optimal front. Proximity to the front and diversity of solutions within the approximation set are important requirements. Most established multiobjective evolutionary algorithms (MOEAs) have mechanisms that address these requirements. However, in many-objective optimization, where the number of objectives is greater than 2 or 3, it has been found that these two requirements can conflict with one another, introducing problems such as dominance resistance and speciation. In this paper, two diversity management mechanisms are introduced to investigate their impact on overall solution convergence. They are introduced separately, and in combination, and tested on a set of test functions with an increasing number of objectives (6-20). It is found that the inclusion of one of the mechanisms improves the performance of a well-established MOEA in many-objective optimization problems, in terms of both convergence and diversity. The relevance of this for many-objective MOEAs is discussed.","Optimization,
Convergence,
Approximation methods,
Measurement,
Algorithm design and analysis,
Polynomials,
Delta modulation"
Adaptive Interference Management of OFDMA Femtocells for Co-Channel Deployment,"Femtocell technology has been drawing considerable attention as a cost-effective means of extending cellular coverage and enhancing capacity as well as realizing its potential, when combined with orthogonal frequency-division multiple access (OFDMA), for improved indoor broadband wireless services. However, under the expected co-channel deployment of femto- and macro-cells, femtocells may incur high uplink interference to macrocells, and vice versa. To mitigate this interference, we propose a distributed and self-organizing femtocell management architecture, called the Complementary TRi-control Loops (CTRL), that consists of three control loops to determine (1) maximum transmit power of femtocell users based on the fed-back macrocell load margin for protection of the macrocell uplink communications; (2) target signal to interference plus noise ratios (SINRs) of femtocell users to reach a Nash equilibrium; and (3) instantaneous transmit power of femtocell users to achieve the target SINRs against bursty interference from other nearby users. CTRL requires neither special hardware nor change to the radio resource management (RRM) of existing macrocells, thus facilitating non-disruptive (hence seamless) penetration of femtocells. Also, CTRL guarantees convergence in the presence of environmental changes and delayed feedback. Our evaluation has shown CTRL to successfully preserve the macrocell users' service quality under highly dynamic user transmission conditions and be able to make a tradeoff between macrocell and femtocell capacities.",
User-centric data dissemination in disruption tolerant networks,"Data dissemination is useful for many applications of Disruption Tolerant Networks (DTNs). Current data dissemination schemes are generally network-centric ignoring user interests. In this paper, we propose a novel approach for user-centric data dissemination in DTNs, which considers satisfying user interests and maximizes the cost-effectiveness of data dissemination. Our approach is based on a social centrality metric, which considers the social contact patterns and interests of mobile users simultaneously, and thus ensures effective relay selection. The performance of our approach is evaluated from both theoretical and experimental perspectives. By formal analysis, we show the lower bound on the cost-effectiveness of data dissemination, and analytically investigate the tradeoff between the effectiveness of relay selection and the overhead of maintaining network information. By trace-driven simulations, we show that our approach achieves better cost-effectiveness than existing data dissemination schemes.",
Simultaneous Reconstruction of Activity and Attenuation for PET/MR,"Medical investigations targeting a quantitative analysis of the position emission tomography (PET) images require the incorporation of additional knowledge about the photon attenuation distribution in the patient. Today, energy range adapted attenuation maps derived from computer tomography (CT) scans are used to effectively compensate for image quality degrading effects, such as attenuation and scatter. Replacing CT by magnetic resonance (MR) is considered as the next evolutionary step in the field of hybrid imaging systems. However, unlike CT, MR does not measure the photon attenuation and thus does not provide an easy access to this valuable information. Hence, many research groups currently investigate different technologies for MR-based attenuation correction (MR-AC). Typically, these approaches are based on techniques such as special acquisition sequences (alone or in combination with subsequent image processing), anatomical atlas registration, or pattern recognition techniques using a data base of MR and corresponding CT images. We propose a generic iterative reconstruction approach to simultaneously estimate the local tracer concentration and the attenuation distribution using the segmented MR image as anatomical reference. Instead of applying predefined attenuation values to specific anatomical regions or tissue types, the gamma attenuation at 511 keV is determined from the PET emission data. In particular, our approach uses a maximum-likelihood estimation for the activity and a gradient-ascent based algorithm for the attenuation distribution. The adverse effects of scattered and accidental gamma coincidences on the quantitative accuracy of PET, as well as artifacts caused by the inherent crosstalk between activity and attenuation estimation are efficiently reduced using enhanced decay event localization provided by time-of-flight PET, accurate correction for accidental coincidences, and a reduced number of unknown attenuation coefficients. First results achieved with measured whole body PET data and reference segmentation from CT showed an absolute mean difference of 0.005 cm in the lungs, 0.0009 cm in case of fat, and 0.0015 cm for muscles and blood. The proposed method indicates a robust and reliable alternative to other MR-AC approaches targeting patient specific quantitative analysis in time-of-flight PET/MR.",
Input-to-State Stability of Packetized Predictive Control Over Unreliable Networks Affected by Packet-Dropouts,"This work studies a predictive networked control scheme in which packets containing optimizing sequences of control inputs are sent over an unreliable communication network affected by data-loss. We show that, provided the number of consecutive packet losses is bounded, input-to-state stability can be ensured by appropriate choice of design parameters. Our results apply to the general case of constrained nonlinear plants which are affected by uncertain and unmeasured disturbances.",
Response-Time Analysis for Mixed Criticality Systems,"Many safety-critical embedded systems are subject to certification requirements. However, only a subset of the functionality of the system may be safety-critical and hence subject to certification, the rest of the functionality is non safety-critical and does not need to be certified, or is certified to a lower level. The resulting mixed criticality system offers challenges both for static schedulability analysis and run-time monitoring. This paper considers a novel implementation scheme for fixed priority uniprocessor scheduling of mixed criticality systems. The scheme requires that jobs have their execution times monitored (as is usually the case in high integrity systems). An optimal priority assignment scheme is derived and sufficient response-time analysis is provided. The new scheme formally dominates those previously published. Evaluations illustrate the benefits of the scheme.","Monitoring,
Time factors,
Switches,
Real time systems,
Computer science,
Educational institutions,
Electronic mail"
An Efficient Method for Supervised Hyperspectral Band Selection,"Band selection is often applied to reduce the dimensionality of hyperspectral imagery. When the desired object information is known, it can be achieved by finding the bands that contain the most object information. It is expected that these bands can provide an overall satisfactory detection and classification performance. In this letter, we propose a new supervised band-selection algorithm that uses the known class signatures only without examining the original bands or the need of class training samples. Thus, it can complete the task much faster than traditional methods that test bands or band combinations. The experimental result shows that our approach can generally yield better results than other popular supervised band-selection methods in the literature.",
RF Performance and Small-Signal Parameter Extraction of Junctionless Silicon Nanowire MOSFETs,"This paper presents a radio-frequency (RF) model and extracted model parameters for junctionless silicon nanowire (JLSNW) metal-oxide-semiconductor field-effect transistors (MOSFETs) using a 3-D device simulator. JLSNW MOSFETs are evaluated for various RF parameters such as cutoff frequency fT, gate input capacitance, distributed channel resistances, transport time delay, and capacitance by the drain-induced barrier lowering effect. Direct comparisons of high-frequency performances and extracted parameters are made with conventional silicon nanowire MOSFETs. A non-quasi-static RF model has been used, along with SPICE to simulate JLSNW MOSFETs with RF parameters extracted from 3-D-simulated Y-parameters. The results show excellent agreements with the 3-D-simulated results up to the high frequency of fT.",
Efficiency Impact of Silicon Carbide Power Electronics for Modern Wind Turbine Full Scale Frequency Converter,"Power electronics is an enabling technology found in most renewable energy generation systems. Because of its superior voltage blocking capabilities and fast switching speeds, silicon carbide (SiC) power electronics are considered for use in power conversion units in wind generation systems in this paper. The potential efficiency gains from the use of SiC devices in a wind generation system are explored by simulations, with the system modeling explained in detail. The performance of the SiC converter is analyzed and compared to its silicon counterpart at different wind speeds, temperatures, and switching frequencies. The quantitative results are based on SiC metal-oxide-semiconductor field-effect transistor (MOSFET) prototypes from Cree and modern Si insulated-gate bipolar transistor (IGBT) products. A conclusion is drawn that the SiC converters can improve the wind system power conversion efficiency and can reduce the system's size and cost due to the low-loss, high-frequency, and high-temperature properties of SiC devices, even for one-for-one replacement for Si devices.","Silicon carbide,
Power electronics,
Wind turbines,
Frequency conversion,
Wind energy generation,
Power generation,
Power conversion,
Renewable energy resources,
Voltage,
Wind power generation"
Prediction or Not? An Energy-Efficient Framework for Clustering-Based Data Collection in Wireless Sensor Networks,"For many applications in wireless sensor networks (WSNs), users may want to continuously extract data from the networks for analysis later. However, accurate data extraction is difficult-it is often too costly to obtain all sensor readings, as well as not necessary in the sense that the readings themselves only represent samples of the true state of the world. Clustering and prediction techniques, which exploit spatial and temporal correlation among the sensor data provide opportunities for reducing the energy consumption of continuous sensor data collection. Integrating clustering and prediction techniques makes it essential to design a new data collection scheme, so as to achieve network energy efficiency and stability. We propose an energy-efficient framework for clustering-based data collection in wireless sensor networks by integrating adaptively enabling/disabling prediction scheme. Our framework is clustering based. A cluster head represents all sensor nodes in the cluster and collects data values from them. To realize prediction techniques efficiently in WSNs, we present adaptive scheme to control prediction used in our framework, analyze the performance tradeoff between reducing communication cost and limiting prediction cost, and design algorithms to exploit the benefit of adaptive scheme to enable/disable prediction operations. Our framework is general enough to incorporate many advanced features and we show how sleep/awake scheduling can be applied, which takes our framework approach to designing a practical algorithm for data aggregation: it avoids the need for rampant node-to-node propagation of aggregates, but rather it uses faster and more efficient cluster-to-cluster propagation. To the best of our knowledge, this is the first work adaptively enabling/disabling prediction scheme for clustering-based continuous data collection in sensor networks. Our proposed models, analysis, and framework are validated via simulation and comparison with competing techniques.",
Petri Net-Based Scheduling of Single-Arm Cluster Tools With Reentrant Atomic Layer Deposition Processes,"For some wafer fabrication processes in cluster tools, e.g., atomic layer deposition (ALD), wafer revisiting is required. Typically, in such processes, wafers need to visit two consecutive processing steps several times. Such a revisiting process can be denoted as (mi, mi + 1)h, where i means the ith-step and mi and mi + 1 mean the corresponding quantity of the processing modules in i and (i+1)th steps, and h the number of visiting times. This paper conducts a study for scheduling single-arm cluster tools with such a wafer revisiting process. The system is modeled by Petri nets (PNs) to guarantee the feasibility of robot activities. Based on the model, a deadlock avoidance policy is presented. With the control policy, cycle time analysis for the revisiting process is made. With the fact that wafer processing times are much longer than robot movement times in cluster tools, it is shown that, when mi = mi + 1 = 1, i.e., each step has only one processing module, the optimal one-wafer cyclic schedule is deterministic and unique, and the minimal cycle time can be calculated by an analytical expression. It is also shown that, when mi = 1 and mi + 1 = 2 or mi = 2 and mi + 1 = 1, the optimal one-wafer cyclic schedule can be obtained by finding h deterministic schedules and the one with the least cycle time. A novel analytical method is finally presented to schedule the overall system containing such reentrant wafer flow. This represents a significant advance in single-arm cluster equipment automation.","Atomic layer deposition,
Job shop scheduling,
Robots,
Fabrication,
Educational programs,
Semiconductor device modeling,
Petri nets,
Automation,
Partial response channels,
Manufacturing processes"
Visual saliency detection by spatially weighted dissimilarity,"In this paper, a new visual saliency detection method is proposed based on the spatially weighted dissimilarity. We measured the saliency by integrating three elements as follows: the dissimilarities between image patches, which were evaluated in the reduced dimensional space, the spatial distance between image patches and the central bias. The dissimilarities were inversely weighted based on the corresponding spatial distance. A weighting mechanism, indicating a bias for human fixations to the center of the image, was employed. The principal component analysis (PCA) was the dimension reducing method used in our system. We extracted the principal components (PCs) by sampling the patches from the current image. Our method was compared with four saliency detection approaches using three image datasets. Experimental results show that our method outperforms current state-of-the-art methods on predicting human fixations.","Humans,
Color,
Visualization,
Image color analysis,
Principal component analysis,
Correlation,
Computational modeling"
Year,,
A Battery-Powered Activity-Dependent Intracortical Microstimulation IC for Brain-Machine-Brain Interface,"This paper describes an activity-dependent intracortical microstimulation (ICMS) system-on-chip (SoC) that converts extracellular neural spikes recorded from one brain region to electrical stimuli delivered to another brain region in real time in vivo. The 10.9-mm2 SoC incorporates two identical 4-channel modules, each comprising an analog recording front-end with total input noise voltage of 3.12 μVrms and noise efficiency factor (NEF) of 2.68, 5.9-μW 10-bit successive approximation register analog-to-digital converters (SAR ADCs), 12.4-μW digital spike discrimination processor, and a programmable constant-current microstimulating back-end that delivers up to 94.5 μA with 6-bit resolution to stimulate the cortical tissue when triggered by neural activity. For autonomous operation, the SoC also integrates biasing and clock generation circuitry, frequency-shift-keyed (FSK) transmitter at 433 MHz, and dc-dc converter that generates a power supply of 5.05 V for the microstimulating back-end from a single 1.5-V battery. Measured results from electrical performance characterization and biological experiments with anesthetized rats are presented from a prototype chip fabricated in AMS 0.35 μm two-poly four-metal (2P/4M) CMOS. A noise analysis for the selected low-noise amplifier (LNA) topology is presented that obtains a minimum NEF of 2.33 for a practical design given the technology parameters and power supply voltage. Future considerations in the SoC design with respect to silicon area and power consumption when increasing the number of channels are also discussed.","System-on-a-chip,
Digital signal processing,
Clocks,
Timing,
Converters,
MOS devices"
Globus Online: Accelerating and Democratizing Science through Cloud-Based Services,"Many businesses today save time and money, and increase their agility, by outsourcing mundane IT tasks to cloud providers. The author argues that similar methods can be used to overcome the complexities inherent in increas ingly data-intensive, computational, and collaborative scientific research. He describes Globus Online, a system that he and his colleagues are developing to realize this vision.",
A survey of Cyber-Physical Systems,"Cyber-Physical Systems (CPSs) are characterized by integrating computation and physical processes. The theories and applications of CPSs face the enormous challenges. The aim of this work is to provide a better understanding of this emerging multi-disciplinary methodology. First, the features of CPSs are described, and the research progresses are summarized from different perspectives such as energy control, secure control, transmission and management, control technique, system resource allocation, and model-based software design. Then three classic applications are given to show that the prospects of CPSs are engaging. Finally, the research challenges and some suggestions for future work are in brief outlined.","Computational modeling,
Real time systems,
Unified modeling language,
Conferences,
Security,
Educational institutions,
Software"
The Impact of Node Selfishness on Multicasting in Delay Tolerant Networks,"Due to the uncertainty of transmission opportunities between mobile nodes, delay tolerant networks (DTNs) exploit the opportunistic forwarding mechanism. This mechanism requires nodes to forward messages in a cooperative and selfish way. However, in the real word, most of the nodes exhibit selfish behaviors, such as individual and social selfishness. In this paper, we are the first to investigate how the selfish behaviors of nodes affect the performance of DTN multicast. We consider two typical multicast relaying schemes, namely, two-hop relaying and epidemic relaying, and study their performance in terms of average message transmission delay and transmission cost. Specifically, we model the message delivery process under selfish behaviors by a 3-D continuous time Markov chain; under this model, we derive closed-form formulas for the message transmission delay and cost. Then, we evaluate the accuracy of the proposed Markov chain model by comparing the theoretical results with the simulation results obtained by simulating the message dissemination under both two-hop and epidemic relaying with different network sizes and mobility models. Our study shows that different selfish behaviors may have different impacts on different performance metrics. In addition, selfish behaviors influence epidemic relaying more than two-hop relaying. Furthermore, our results show that the performance of multicast with selfish nodes depends on the multicast group size.",
Delay- and Disruption-Tolerant Networking (DTN): An Alternative Solution for Future Satellite Networking Applications,"Satellite communications are characterized by long delays, packet losses, and sometimes intermittent connectivity and link disruptions. The TCP/IP stack is ineffective against these impairments and even dedicated solutions, such as performance enhancing proxies (PEPs), can hardly tackle the most challenging environments, and create compatibility issues with current security protocols. An alternative solution arises from the delay- and disruption-tolerant networking (DTN) architecture, which specifies an overlay protocol, called bundle protocol (BP), on top of either transport protocols (TCP, UDP, etc.), or of lower layer protocols (Bluetooth, Ethernet, etc.). The DTN architecture provides long-term information storage on intermediate nodes, suitable for coping with disrupted links, long delays, and intermittent connectivity. By dividing the end-to-end path into multiple DTN hops, in a way that actually extends the TCP-splitting concept exploited in most PEPs, DTN allows the use of specialized protocols on the satellite (or space) links. This paper discusses the prospects for use of DTN in future satellite networks. We present a broad DTN overview, to make the reader familiar with the characteristics that differentiate DTN from ordinary TCP/IP networking, compare the DTN and PEP architectures and stacks, as a preliminary step for the subsequent DTN performance assessment carried out in practical LEO/GEO satellite scenarios. DTN security is studied next, examining the advantages over present satellite architectures, the threats faced in satellite scenarios, and also open issues. Finally, the relation between DTN and quality of service (QoS) is investigated, by focusing on QoS architectures and QoS tools and by discussing the state of the art of DTN research activity in modeling, routing, and congestion control.","Satellite communication,
Delay,
Satellite communication,
Packet switching,
Quality of service,
Internet,
IP networks,
Loss measurement"
NeuFlow: A runtime reconfigurable dataflow processor for vision,"In this paper we present a scalable dataflow hardware architecture optimized for the computation of general-purpose vision algorithms - neuFlow - and a dataflow compiler - luaFlow - that transforms high-level flow-graph representations of these algorithms into machine code for neuFlow. This system was designed with the goal of providing real-time detection, categorization and localization of objects in complex scenes, while consuming 10 Watts when implemented on a Xilinx Virtex 6 FPGA platform, or about ten times less than a laptop computer, and producing speedups of up to 100 times in real-world applications. We present an application of the system on street scene analysis, segmenting 20 categories on 500 × 375 frames at 12 frames per second on our custom hardware neuFlow.","Tiles,
Computer architecture,
Runtime,
Field programmable gate arrays,
Hardware,
Convolvers,
Feature extraction"
Missing Value Estimation for Mixed-Attribute Data Sets,"Missing data imputation is a key issue in learning from incomplete data. Various techniques have been developed with great successes on dealing with missing values in data sets with homogeneous attributes (their independent attributes are all either continuous or discrete). This paper studies a new setting of missing data imputation, i.e., imputing missing data in data sets with heterogeneous attributes (their independent attributes are of different types), referred to as imputing mixed-attribute data sets. Although many real applications are in this setting, there is no estimator designed for imputing mixed-attribute data sets. This paper first proposes two consistent estimators for discrete and continuous missing target values, respectively. And then, a mixture-kernel-based iterative estimator is advocated to impute mixed-attribute data sets. The proposed method is evaluated with extensive experiments compared with some typical algorithms, and the result demonstrates that the proposed approach is better than these existing imputation methods in terms of classification accuracy and root mean square error (RMSE) at different missing ratios.","Kernel,
Databases,
Machine learning algorithms,
Iterative algorithms,
Root mean square,
Data mining,
Machine learning,
Iterative methods,
Information science,
Bibliographies"
Robust classification using structured sparse representation,"In many problems in computer vision, data in multiple classes lie in multiple low-dimensional subspaces of a high-dimensional ambient space. However, most of the existing classification methods do not explicitly take this structure into account. In this paper, we consider the problem of classification in the multi-sub space setting using sparse representation techniques. We exploit the fact that the dictionary of all the training data has a block structure where the training data in each class form few blocks of the dictionary. We cast the classification as a structured sparse recovery problem where our goal is to find a representation of a test example that uses the minimum number of blocks from the dictionary. We formulate this problem using two different classes of non-convex optimization programs. We propose convex relaxations for these two non-convex programs and study conditions under which the relaxations are equivalent to the original problems. In addition, we show that the proposed optimization programs can be modified properly to also deal with corrupted data. To evaluate the proposed algorithms, we consider the problem of automatic face recognition. We show that casting the face recognition problem as a structured sparse recovery problem can improve the results of the state-of-the-art face recognition algorithms, especially when we have relatively small number of training data for each class. In particular, we show that the new class of convex programs can improve the state-of-the-art face recognition results by 10% with only 25% of the training data. In addition, we show that the algorithms are robust to occlusion, corruption, and disguise.",
Gradient Profile Prior and Its Applications in Image Super-Resolution and Enhancement,"In this paper, we propose a novel generic image prior-gradient profile prior, which implies the prior knowledge of natural image gradients. In this prior, the image gradients are represented by gradient profiles, which are 1-D profiles of gradient magnitudes perpendicular to image structures. We model the gradient profiles by a parametric gradient profile model. Using this model, the prior knowledge of the gradient profiles are learned from a large collection of natural images, which are called gradient profile prior. Based on this prior, we propose a gradient field transformation to constrain the gradient fields of the high resolution image and the enhanced image when performing single image super-resolution and sharpness enhancement. With this simple but very effective approach, we are able to produce state-of-the-art results. The reconstructed high resolution images or the enhanced images are sharp while have rare ringing or jaggy artifacts.",
A Fast and Scalable Multiobjective Genetic Fuzzy System for Linguistic Fuzzy Modeling in High-Dimensional Regression Problems,"Linguistic fuzzy modeling in high-dimensional regression problems poses the challenge of exponential-rule explosion when the number of variables and/or instances becomes high. One way to address this problem is by determining the used variables, the linguistic partitioning and the rule set together, in order to only evolve very simple, but still accurate models. However, evolving these components together is a difficult task, which involves a complex search space. In this study, we propose an effective multiobjective evolutionary algorithm that, based on embedded genetic database (DB) learning (involved variables, granularities, and slight fuzzy-partition displacements), allows the fast learning of simple and quite-accurate linguistic models. Some efficient mechanisms have been designed to ensure a very fast, but not premature, convergence in problems with a high number of variables. Further, since additional problems could arise for datasets with a large number of instances, we also propose a general mechanism for the estimation of the model error when using evolutionary algorithms, by only considering a reduced subset of the examples. By doing so, we can also apply a fast postprocessing stage for further refining the learned solutions. We tested our approach on 17 real-world datasets with different numbers of variables and instances. Three well-known methods based on embedded genetic DB learning have been executed as references. We compared the different approaches by applying nonparametric statistical tests for multiple comparisons. The results confirm the effectiveness of the proposed method not only in terms of scalability but in terms of the simplicity and generalizability of the obtained models as well.",
Multidimensional X-Space Magnetic Particle Imaging,"Magnetic particle imaging (MPI) is a promising new medical imaging tracer modality with potential applications in human angiography, cancer imaging, in vivo cell tracking, and inflammation imaging. Here we demonstrate both theoretically and experimentally that multidimensional MPI is a linear shift-invariant imaging system with an analytic point spread function. We also introduce a fast image reconstruction method that obtains the intrinsic MPI image with high signal-to-noise ratio via a simple gridding operation in x-space. We also demonstrate a method to reconstruct large field-of-view (FOV) images using partial FOV scanning, despite the loss of first harmonic image information due to direct feedthrough contamination. We conclude with the first experimental test of multidimensional x-space MPI.","Magnetic resonance imaging,
Image reconstruction,
Harmonic analysis,
Three dimensional displays,
Coils,
Nanoparticles"
A Discriminative Model for Age Invariant Face Recognition,"Aging variation poses a serious problem to automatic face recognition systems. Most of the face recognition studies that have addressed the aging problem are focused on age estimation or aging simulation. Designing an appropriate feature representation and an effective matching framework for age invariant face recognition remains an open problem. In this paper, we propose a discriminative model to address face matching in the presence of age variation. In this framework, we first represent each face by designing a densely sampled local feature description scheme, in which scale invariant feature transform (SIFT) and multi-scale local binary patterns (MLBP) serve as the local descriptors. By densely sampling the two kinds of local descriptors from the entire facial image, sufficient discriminatory information, including the distribution of the edge direction in the face image (that is expected to be age invariant) can be extracted for further analysis. Since both SIFT-based local features and MLBP-based local features span a high-dimensional feature space, to avoid the overfitting problem, we develop an algorithm, called multi-feature discriminant analysis (MFDA) to process these two local feature spaces in a unified framework. The MFDA is an extension and improvement of the LDA using multiple features combined with two different random sampling methods in feature and sample space. By random sampling the training set as well as the feature space, multiple LDA-based classifiers are constructed and then combined to generate a robust decision via a fusion rule. Experimental results show that our approach outperforms a state-of-the-art commercial face recognition engine on two public domain face aging data sets: MORPH and FG-NET. We also compare the performance of the proposed discriminative model with a generative aging model. A fusion of discriminative and generative models further improves the face matching accuracy in the presence of aging.","Face,
Aging,
Face recognition,
Feature extraction,
Training,
Bagging,
Lighting"
Point feature extraction on 3D range scans taking into account object boundaries,"In this paper we address the topic of feature extraction in 3D point cloud data for object recognition and pose identification. We present a novel interest keypoint extraction method that operates on range images generated from arbitrary 3D point clouds, which explicitly considers the borders of the objects identified by transitions from foreground to background. We furthermore present a feature descriptor that takes the same information into account. We have implemented our approach and present rigorous experiments in which we analyze the individual components with respect to their repeatability and matching capabilities and evaluate the usefulness for point feature based object detection methods.",
Complex Object Correspondence Construction in Two-Dimensional Animation,"Correspondence construction of objects in key frames is the precondition for inbetweening and coloring in 2-D computer-assisted animation production. Since each frame of an animation consists of multiple layers, objects are complex in terms of shape and structure. Therefore, existing shape-matching algorithms specifically designed for simple structures such as a single closed contour cannot perform well on objects constructed by multiple contours with an open shape. This paper introduces a semisupervised patch alignment framework for complex object correspondence construction. In particular, the new framework constructs local patches for each point on an object and aligns these patches in a new feature space, in which correspondences between objects can be detected by the subsequent clustering. For local patch construction, pairwise constraints, which indicate the corresponding points (must link) or unfitting points (cannot link), are introduced by users to improve the performance of correspondence construction. This kind of input is convenient for animation software users via user-friendly interfaces. A dozen of experimental results on our cartoon data set that is built on industrial production suggest the effectiveness of the proposed framework for constructing correspondences of complex objects. As an extension of our framework, additional shape retrieval experiments on MPEG-7 data set show that its performance is comparable with that of a prominent algorithm published in T-PAMI 2009.","Shape,
Animation,
Context,
Optimization,
Production,
Algorithm design and analysis,
Geometry"
Emotion Assessment From Physiological Signals for Adaptation of Game Difficulty,"This paper proposes to maintain player's engagement by adapting game difficulty according to player's emotions assessed from physiological signals. The validity of this approach was first tested by analyzing the questionnaire responses, electroencephalogram (EEG) signals, and peripheral signals of the players playing a Tetris game at three difficulty levels. This analysis confirms that the different difficulty levels correspond to distinguishable emotions, and that, playing several times at the same difficulty level gives rise to boredom. The next step was to train several classifiers to automatically detect the three emotional classes from EEG and peripheral signals in a player-independent framework. By using either type of signals, the emotional classes were successfully recovered, with EEG having a better accuracy than peripheral signals on short periods of time. After the fusion of the two signal categories, the accuracy raised up to 63%.","Games,
Electroencephalography,
Pattern classification,
Emotion recognition,
Physiology"
Sparse approximated nearest points for image set classification,"Classification based on image sets has recently attracted great research interest as it holds more promise than single image based classification. In this paper, we propose an efficient and robust algorithm for image set classification. An image set is represented as a triplet: a number of image samples, their mean and an affine hull model. The affine hull model is used to account for unseen appearances in the form of affine combinations of sample images. We introduce a novel between-set distance called Sparse Approximated Nearest Point (SANP) distance. Unlike existing methods, the dissimilarity of two sets is measured as the distance between their nearest points, which can be sparsely approximated from the image samples of their respective set. Different from standard sparse modeling of a single image, this novel sparse formulation for the image set enforces sparsity on the sample coefficients rather than the model coefficients and jointly optimizes the nearest points as well as their sparse approximations. A convex formulation for searching the optimal SANP between two sets is proposed and the accelerated proximal gradient method is adapted to efficiently solve this optimization. Experimental evaluation was performed on the Honda, MoBo and Youtube datasets. Comparison with existing techniques shows that our method consistently achieves better results.","Approximation methods,
Data models,
Convergence,
Joints,
Adaptation models,
Gradient methods"
Capacitive power transfer for contactless charging,"The simplicity and low cost of capacitive interfaces makes them very attractive for wireless charging stations. Major benefits include low electromagnetic radiation and the amenability of combined power and data transfer over the same interface. We present a capacitive power transfer circuit using series resonance that enables efficient high frequency, moderate voltage operation through soft-switching. An included analysis predicts fundamental limitations on the maximum achievable efficiency for a given amount of coupling capacitance and is used to find the optimum circuit component values and operating point. Automatic tuning loops ensure the circuit operates at the optimum frequency and maximum efficiency over a wide range of coupling capacitance and load conditions. An example interface achieves near 80% efficiency at 3.7 W with only 63pF of coupling capacitance. An automatic tuning loop adjusts the frequency from 4.2 MHz down to 4MHz to allow for 25% variation in the nominal coupling capacitance. The duty cycle is also automatically adjusted to maintain over 70% efficiency for light loads down to 0.3 W.",
Cardinality Estimation for Large-Scale RFID Systems,"Counting the number of RFID tags (cardinality) is a fundamental problem for large-scale RFID systems. Not only does it satisfy some real application requirements, it also acts as an important aid for RFID identification. Due to the extremely long processing time, slotted ALOHA-based or tree-based arbitration protocols are often impractical for many applications, because tags are usually attached to moving objects and they may have left the readers interrogation region before being counted. Recently, estimation schemes have been proposed to count the approximate number of tags. Most of them, however, suffer from two scalability problems: time inefficiency and multiple-reading. Without resolving these problems, large-scale RFID systems cannot easily apply the estimation scheme as well as the corresponding identification. In this paper, we present the Lottery Frame (LoF) estimation scheme, which can achieve high accuracy, low latency, and scalability. LoF estimates the tag numbers by utilizing the collision information. We show the significant advantages, e.g., high accuracy, short processing time, and low overhead, of the proposed LoF scheme through analysis and simulations.",
Essential roles of exploiting internal parallelism of flash memory based solid state drives in high-speed data processing,"Flash memory based solid state drives (SSDs) have shown a great potential to change storage infrastructure fundamentally through their high performance and low power. Most recent studies have mainly focused on addressing the technical limitations caused by special requirements for writes in flash memory. However, a unique merit of an SSD is its rich internal parallelism, which allows us to offset for the most part of the performance loss related to technical limitations by significantly increasing data processing throughput. In this work we present a comprehensive study of essential roles of internal parallelism of SSDs in high-speed data processing. Besides substantially improving I/O bandwidth (e.g. 7.2×), we show that by exploiting internal parallelism, SSD performance is no longer highly sensitive to access patterns, but rather to other factors, such as data access interferences and physical data layout. Specifically, through extensive experiments and thorough analysis, we obtain the following new findings in the context of concurrent data processing in SSDs. (1) Write performance is largely independent of access patterns (regardless of being sequential or random), and can even outperform reads, which is opposite to the long-existing common understanding about slow writes on SSDs. (2) One performance concern comes from interference between concurrent reads and writes, which causes substantial performance degradation. (3) Parallel I/O performance is sensitive to physical data-layout mapping, which is largely not observed without parallelism. (4) Existing application designs optimized for magnetic disks can be suboptimal for running on SSDs with parallelism. Our study is further supported by a group of case studies in database systems as typical data-intensive applications. With these critical findings, we give a set of recommendations to application designers and system architects for exploiting internal parallelism and maximizing the performance potential of SSDs.","Parallel processing,
Ash,
Layout,
Bandwidth,
Hard disks,
Optimization,
Throughput"
Internal statistics of a single natural image,"Statistics of `natural images' provides useful priors for solving under-constrained problems in Computer Vision. Such statistics is usually obtained from large collections of natural images. We claim that the substantial internal data redundancy within a single natural image (e.g., recurrence of small image patches), gives rise to powerful internal statistics, obtained directly from the image itself. While internal patch recurrence has been used in various applications, we provide a parametric quantification of this property. We show that the likelihood of an image patch to recur at another image location can be expressed parametricly as a function of the spatial distance from the patch, and its gradient content. This “internal parametric prior” is used to improve existing algorithms that rely on patch recurrence. Moreover, we show that internal image-specific statistics is often more powerful than general external statistics, giving rise to more powerful image-specific priors. In particular: (i) Patches tend to recur much more frequently (densely) inside the same image, than in any random external collection of natural images. (ii) To find an equally good external representative patch for all the patches of an image, requires an external database of hundreds of natural images. (iii) Internal statistics often has stronger predictive power than external statistics, indicating that it may potentially give rise to more powerful image-specific priors.","Databases,
Noise reduction,
Image resolution,
Noise,
Noise measurement,
Redundancy,
Estimation"
Wireless Model-Based Predictive Networked Control System Over Cooperative Wireless Network,"Owing to their distributed architecture, networked control systems (NCSs) are proven to be feasible in scenarios where a spatially distributed feedback control system is required. Traditionally, such NCSs operate over real-time wired networks. Recently, in order to achieve the utmost flexibility, scalability, ease of deployment, and maintainability, wireless networks such as IEEE 802.11 wireless local area networks (LANs) are being preferred over dedicated wired networks. However, conventional NCSs with event-triggered controllers and actuators cannot operate over such general purpose wireless networks since the stability of the system is compromised due to unbounded delays and unpredictable packet losses that are typical in the wireless medium. Approaching the wireless networked control problem from two perspectives, this work introduces a practical wireless NCS and an implementation of a cooperative medium access control protocol that work jointly to achieve decent control under severe impairments, such as unbounded delay, bursts of packet loss and ambient wireless traffic. The proposed system is evaluated on a dedicated test platform under numerous scenarios and significant performance gains are observed, making cooperative communications a strong candidate for improving the reliability of industrial wireless networks.",
Parallel Elite Genetic Algorithm and Its Application to Global Path Planning for Autonomous Robot Navigation,"This paper presents a parallel elite genetic algorithm (PEGA) and its application to global path planning for autonomous mobile robots navigating in structured environments. This PEGA, consisting of two parallel EGAs along with a migration operator, takes advantages of maintaining better population diversity, inhibiting premature convergence, and keeping parallelism in comparison with conventional GAs. This initial feasible path generated from the PEGA planner is then smoothed using the cubic B-spline technique, in order to construct a near-optimal collision-free continuous path. Both global path planner and smoother are implemented in one field-programmable gate array chip utilizing the system-on-a-programmable-chip technology and the pipelined hardware implementation scheme, thus significantly expediting computation speed. Simulations and experimental results are conducted to show the merit of the proposed PEGA path planner and smoother for global path planning of autonomous mobile robots.",
Recurrent Neural Network for Non-Smooth Convex Optimization Problems With Application to the Identification of Genetic Regulatory Networks,"A recurrent neural network is proposed for solving the non-smooth convex optimization problem with the convex inequality and linear equality constraints. Since the objective function and inequality constraints may not be smooth, the Clarke's generalized gradients of the objective function and inequality constraints are employed to describe the dynamics of the proposed neural network. It is proved that the equilibrium point set of the proposed neural network is equivalent to the optimal solution of the original optimization problem by using the Lagrangian saddle-point theorem. Under weak conditions, the proposed neural network is proved to be stable, and the state of the neural network is convergent to one of its equilibrium points. Compared with the existing neural network models for non-smooth optimization problems, the proposed neural network can deal with a larger class of constraints and is not based on the penalty method. Finally, the proposed neural network is used to solve the identification problem of genetic regulatory networks, which can be transformed into a non-smooth convex optimization problem. The simulation results show the satisfactory identification accuracy, which demonstrates the effectiveness and efficiency of the proposed approach.",
The German Traffic Sign Recognition Benchmark: A multi-class classification competition,"The “German Traffic Sign Recognition Benchmark” is a multi-category classification competition held at IJCNN 2011. Automatic recognition of traffic signs is required in advanced driver assistance systems and constitutes a challenging real-world computer vision and pattern recognition problem. A comprehensive, lifelike dataset of more than 50,000 traffic sign images has been collected. It reflects the strong variations in visual appearance of signs due to distance, illumination, weather conditions, partial occlusions, and rotations. The images are complemented by several precomputed feature sets to allow for applying machine learning algorithms without background knowledge in image processing. The dataset comprises 43 classes with unbalanced class frequencies. Participants have to classify two test sets of more than 12,500 images each. Here, the results on the first of these sets, which was used in the first evaluation stage of the two-fold challenge, are reported. The methods employed by the participants who achieved the best results are briefly described and compared to human traffic sign recognition performance and baseline results.",
Optimal Tracking Control for a Class of Nonlinear Discrete-Time Systems With Time Delays Based on Heuristic Dynamic Programming,"In this paper, a novel heuristic dynamic programming (HDP) iteration algorithm is proposed to solve the optimal tracking control problem for a class of nonlinear discrete-time systems with time delays. The novel algorithm contains state updating, control policy iteration, and performance index iteration. To get the optimal states, the states are also updated. Furthermore, the “backward iteration” is applied to state updating. Two neural networks are used to approximate the performance index function and compute the optimal control policy for facilitating the implementation of HDP iteration algorithm. At last, we present two examples to demonstrate the effectiveness of the proposed HDP iteration algorithm.","Delay effects,
Performance analysis,
Algorithm design and analysis,
Dynamic programming,
Approximation algorithms,
Optimal control,
Nonlinear systems"
Dynamic Vehicle Routing for Robotic Systems,"Recent years have witnessed great advancements in the science and technology of autonomy, robotics, and networking. This paper surveys recent concepts and algorithms for dynamic vehicle routing (DVR), that is, for the automatic planning of optimal multivehicle routes to perform tasks that are generated over time by an exogenous process. We consider a rich variety of scenarios relevant for robotic applications. We begin by reviewing the basic DVR problem: demands for service arrive at random locations at random times and a vehicle travels to provide on-site service while minimizing the expected wait time of the demands. Next, we treat different multivehicle scenarios based on different models for demands (e.g., demands with different priority levels and impatient demands), vehicles (e.g., motion constraints, communication, and sensing capabilities), and tasks. The performance criterion used in these scenarios is either the expected wait time of the demands or the fraction of demands serviced successfully. In each specific DVR scenario, we adopt a rigorous technical approach that relies upon methods from queueing theory, combinatorial optimization, and stochastic geometry. First, we establish fundamental limits on the achievable performance, including limits on stability and quality of service. Second, we design algorithms, and provide provable guarantees on their performance with respect to the fundamental limits.",
A computationally inexpensive empirical model of IEEE 802.11p radio shadowing in urban environments,"We present a realistic, yet computationally inexpensive simulation model for IEEE 802.11p radio shadowing in urban environments. Based on real world measurements using IEEE 802.11p/DSRC devices, we estimated the effect that buildings and other obstacles have on the radio communication between vehicles. Especially for evaluating safety applications in the field of Vehicular Ad Hoc Networks (VANETs), stochastic models are not sufficient for evaluating the radio communication in simulation. Motivated by similar work on WiFi measurements, we therefore created an empirical model for modeling buildings and their properties to accurately simulate the signal propagation. We validated our model using real world measurements in a city scenario for different types of obstacles. Our simulation results show a very high accuracy when compared with the measurement results, while only requiring a marginal overhead in terms of computational complexity.","Buildings,
Computational modeling,
Mathematical model,
Shadow mapping,
Attenuation,
Predictive models,
Loss measurement"
Joint Forensics-Scheduling Strategy for Delay-Sensitive Multimedia Applications over Heterogeneous Networks,"High quality multimedia forensics service is increasingly critical for delay-sensitive applications over heterogeneous networks. Up to now, it is a challenging problem, where the demand for less forensics overhead, higher authentication level and smaller transmission delay needs to be reconciled with the limited and often dynamic network resources. Traditional multimedia forensics mechanisms, however, either overlook the available network resource or neglect the interaction between multimedia forensics and network scheduling. This work presents a novel framework for delay-sensitive multimedia applications over resource-limited heterogeneous networks by jointly considering multimedia forensics, network adaptation, and deadline-driven scheduling. In particular, we develop a joint forensics-scheduling scheme, which allocates the available network resources based on the affordable forensics overhead and expected quality of service, adaptively adjusts the scalable media-aware forensics, and schedules the transmissions to meet the application's delay constraints. Through analysis and simulation, we demonstrate that the proposed scheme not only can provide a satisfying multimedia forensics service with nearly full utilization of the network resource, but also can achieve substantial performance improvements compared to other reference approaches.","Forensics,
Authentication,
Multimedia communication,
Joints,
Delay,
Streaming media"
A General Alignment Repulsion Algorithm for Flocking of Multi-Agent Systems,"A novel individual-based alignment/repulsion algorithm is proposed in this note for a flock of multiple agents. With this algorithm, each individual repels its sufficiently close neighbors and aligns to the average velocity of its neighbors with moderate distances. In both mathematical analysis and numerical simulation, we prove that the algorithm guarantees an uncrowded flocking behavior with asymptotic velocity synchronization when sufficiently intensive communication exists within the agents. Moreover, we provide the conditions for collision avoidance along the whole transient procedure. The proposed flocking model has its references in natural collective behaviors like escaping panic and traffic jam motions.","Joints,
Strontium,
Synchronization,
Collision avoidance,
Algorithm design and analysis,
Analytical models,
Evolution (biology)"
"Sensor Management: Past, Present, and Future","Sensor systems typically operate under resource constraints that prevent the simultaneous use of all resources all of the time. Sensor management becomes relevant when the sensing system has the capability of actively managing these resources; i.e., changing its operating configuration during deployment in reaction to previous measurements. Examples of systems in which sensor management is currently used or is likely to be used in the near future include autonomous robots, surveillance and reconnaissance networks, and waveform-agile radars. This paper provides an overview of the theory, algorithms, and applications of sensor management as it has developed over the past decades and as it stands today.","Robot sensing systems,
Radar antennas,
Sensor systems,
Measurement,
Radar applications"
Decomposition-Based Memetic Algorithm for Multiobjective Capacitated Arc Routing Problem,"The capacitated arc routing problem (CARP) is a challenging combinatorial optimization problem with many real-world applications, e.g., salting route optimization and fleet management. There have been many attempts at solving CARP using heuristic and meta-heuristic approaches, including evolutionary algorithms. However, almost all such attempts formulate CARP as a single-objective problem although it usually has more than one objective, especially considering its real-world applications. This paper studies multiobjective CARP (MO-CARP). A new memetic algorithm (MA) called decomposition-based MA with extended neighborhood search (D-MAENS) is proposed. The new algorithm combines the advanced features from both the MAENS approach for single-objective CARP and multiobjective evolutionary optimization. Our experimental studies have shown that such combination outperforms significantly an off-the-shelf multiobjective evolutionary algorithm, namely nondominated sorting genetic algorithm II, and the state-of-the-art multiobjective algorithm for MO-CARP (LMOGA). Our work has also shown that a specifically designed multiobjective algorithm by combining its single-objective version and multiobjective features may lead to competitive multiobjective algorithms for multiobjective combinatorial optimization problems.",
Making Deep Belief Networks effective for large vocabulary continuous speech recognition,"To date, there has been limited work in applying Deep Belief Networks (DBNs) for acoustic modeling in LVCSR tasks, with past work using standard speech features. However, a typical LVCSR system makes use of both feature and model-space speaker adaptation and discriminative training. This paper explores the performance of DBNs in a state-of-the-art LVCSR system, showing improvements over Multi-Layer Perceptrons (MLPs) and GMM/HMMs across a variety of features on an English Broadcast News task. In addition, we provide a recipe for data parallelization of DBN training, showing that data parallelization can provide linear speed-up in the number of machines, without impacting WER.","Training,
Hidden Markov models,
Computers,
Training data,
Mathematical model,
Speech recognition,
Artificial neural networks"
Predicting Flu Trends using Twitter data,"Reducing the impact of seasonal influenza epidemics and other pandemics such as the H1N1 is of paramount importance for public health authorities. Studies have shown that effective interventions can be taken to contain the epidemics if early detection can be made. Traditional approach employed by the Centers for Disease Control and Prevention (CDC) includes collecting influenza-like illness (ILI) activity data from “sentinel” medical practices. Typically there is a 1-2 week delay between the time a patient is diagnosed and the moment that data point becomes available in aggregate ILI reports. In this paper we present the Social Network Enabled Flu Trends (SNEFT) framework, which monitors messages posted on Twitter with a mention of flu indicators to track and predict the emergence and spread of an influenza epidemic in a population. Based on the data collected during 2009 and 2010, we find that the volume of flu related tweets is highly correlated with the number of ILI cases reported by CDC. We further devise auto-regression models to predict the ILI activity level in a population. The models predict data collected and published by CDC, as the percentage of visits to “sentinel” physicians attributable to ILI in successively weeks. We test models with previous CDC data, with and without measures of Twitter data, showing that Twitter data can substantially improve the models prediction accuracy. Therefore, Twitter data provides real-time assessment of ILI activity.","Twitter,
Data models,
Predictive models,
Medical services,
Correlation,
Real time systems,
Delay"
Opportunistic Relaying for Secrecy Communications: Cooperative Jamming vs. Relay Chatting,"In this letter, we study the opportunistic use of relays for secret communications, and propose two transmission schemes that do not require the knowledge of the eavesdropper's channel state information. Both analytic and numerical results are provided.",
Monitoring of Posture Allocations and Activities by a Shoe-Based Wearable Sensor,"Monitoring of posture allocations and activities enables accurate estimation of energy expenditure and may aid in obesity prevention and treatment. At present, accurate devices rely on multiple sensors distributed on the body and thus may be too obtrusive for everyday use. This paper presents a novel wearable sensor, which is capable of very accurate recognition of common postures and activities. The patterns of heel acceleration and plantar pressure uniquely characterize postures and typical activities while requiring minimal preprocessing and no feature extraction. The shoe sensor was tested in nine adults performing sitting and standing postures and while walking, running, stair ascent/descent and cycling. Support vector machines (SVMs) were used for classification. A fourfold validation of a six-class subject-independent group model showed 95.2% average accuracy of posture/activity classification on full sensor set and over 98% on optimized sensor set. Using a combination of acceleration/pressure also enabled a pronounced reduction of the sampling frequency (25 to 1 Hz) with out significant loss of accuracy (98% versus 93%). Subjects had shoe sizes (US) M9.5-11 and W7-9 and body mass index from 18.1 to 39.4 kg/m2 and thus suggesting that the device can be used by individuals with varying anthropometric characteristics.","Monitoring,
Wearable sensors,
Sensor phenomena and characterization,
Acceleration,
Footwear,
Feature extraction,
Testing,
Performance evaluation,
Legged locomotion,
Support vector machines"
TDOA-based optical wireless indoor localization using LED ceiling lamps,"We propose an optical wireless indoor localization using light emitting diodes (LEDs) and demonstrate it via simulation. Unique frequency addresses are assigned to each LED lamp, and transmitted through the light radiated by the LED. Using the phase difference, time difference of arrival (TDOA) localization algorithm is employed. Because the proposed localization method used pre-installed LED ceiling lamps, no additional infrastructure for localization is required to install and therefore, inexpensive system can be realized. The performance of the proposed localization method is evaluated by computer simulation, and the indoor location accuracy is less than 1 cm in the space of 5m x 5 m x 3 m.","Light emitting diodes,
Detectors,
Wireless communication,
Optical receivers,
Optical distortion,
Optical detectors,
Optical signal processing"
Approximate Analysis of Resonant LLC DC-DC Converter,"This paper presents an approximate analysis of LLC resonant converter with capacitive filter operating above and below resonance. An equivalent ac resistance model of the rectifier valid for discontinuous as well as continuous conduction modes is proposed. The dc voltage conversion ratio is then obtained using the fundamental harmonic approximation analysis method. Based on the analysis, LLC converter design plots and guidelines are suggested. The theory is verified by simulation and experiment.","Converters,
Rectifiers,
Resistance,
Harmonic analysis,
Inductors,
Approximation methods,
Power harmonic filters"
A Shapley Value-Based Approach to Discover Influential Nodes in Social Networks,"Our study concerns an important current problem, that of diffusion of information in social networks. This problem has received significant attention from the Internet research community in the recent times, driven by many potential applications such as viral marketing and sales promotions. In this paper, we focus on the target set selection problem, which involves discovering a small subset of influential players in a given social network, to perform a certain task of information diffusion. The target set selection problem manifests in two forms: 1) top-k nodes problem and 2) λ -coverage problem. In the top-k nodes problem, we are required to find a set of k key nodes that would maximize the number of nodes being influenced in the network. The λ-coverage problem is concerned with finding a set of key nodes having minimal size that can influence a given percentage λ of the nodes in the entire network. We propose a new way of solving these problems using the concept of Shapley value which is a well known solution concept in cooperative game theory. Our approach leads to algorithms which we call the ShaPley value-based Influential Nodes (SPINs) algorithms for solving the top-k nodes problem and the λ -coverage problem. We compare the performance of the proposed SPIN algorithms with well known algorithms in the literature. Through extensive experimentation on four synthetically generated random graphs and six real-world data sets (Celegans, Jazz, NIPS coauthorship data set, Netscience data set, High-Energy Physics data set, and Political Books data set), we show that the proposed SPIN approach is more powerful and computationally efficient.","Social network services,
Games,
Diffusion processes,
Algorithm design and analysis,
Greedy algorithms,
Heuristic algorithms,
Context"
Harmonic Beamforming in Time-Modulated Linear Arrays,"In this paper, the synthesis of simultaneous multibeams through time-modulated linear arrays is studied. Unlike classical phased arrays where the antenna aperture is usually shared to generate multiple beams, the periodic on-off sequences controlling the static excitations are properly defined by means of an optimization strategy based on the Particle Swarm algorithm to afford desired multiple patterns at harmonic frequencies to make practical application of these harmonic beams which are typically regarded as an undesirable effect in time-modulated arrays. The synthesis of simultaneous broadside sum and difference patterns, flat-top and narrow beam patterns, and steered multibeams is enabled as assessed by a set of selected results reported and discussed to show the potentialities of the proposed method. Comparisons with previously published results are reported, as well.","Harmonic analysis,
Switches,
Amplitude modulation,
Indexes,
Optimization,
Antenna arrays,
Power system harmonics"
On the Capacity and Diversity-Multiplexing Tradeoff of the Two-Way Relay Channel,"In a two-way relay channel, two sources use one or more relay nodes to exchange data with each other. This paper considers a multiple input multiple output (MIMO) two-way relay channel, where each relay node has one or more antennas. Optimal relay transmission strategies for the two-way relay channel are derived to maximize the achievable rate with amplify and forward (AF) at each relay and to achieve the optimal diversity-multiplexing tradeoff (DM-tradeoff). To maximize the achievable rate with AF, an iterative algorithm is proposed which solves a power minimization problem subject to minimum signal-to-interference-and-noise ratio constraints at every step. The power minimization problem is nonconvex. The Karush Kuhn Tucker conditions, however, are shown to be sufficient for optimality. Capacity scaling law of the two-way relay channel with increasing number of relays is also established by deriving a lower and upper bound on the capacity region of the two-way relay channel. To achieve the optimal DM-tradeoff, a compress and forward strategy is proposed and its DM-tradeoff is derived. For the full-duplex two-way relay channel, the proposed strategy achieves the optimal DM-tradeoff, while for the half-duplex case the proposed strategy is shown to achieve the optimal DM-tradeoff under some conditions.",
CMOS-Compatible Vertical-Silicon-Nanowire Gate-All-Around p-Type Tunneling FETs With \leq 50-mV/decade Subthreshold Swing,"We present a vertical-silicon-nanowire-based p-type tunneling field-effect transistor (TFET) using CMOS-compatible process flow. Following our recently reported n-TFET , a low-temperature dopant segregation technique was employed on the source side to achieve steep dopant gradient, leading to excellent tunneling performance. The fabricated p-TFET devices demonstrate a subthreshold swing (SS) of 30 mV/decade averaged over a decade of drain current and an Ion/Ioff ratio of >; 105. Moreover, an SS of 50 mV/decade is maintained for three orders of drain current. This demonstration completes the complementary pair of TFETs to implement CMOS-like circuits.","Logic gates,
Tunneling,
Silicon,
FETs,
Junctions"
Aesthetics and Emotions in Images,"In this tutorial, we define and discuss key aspects of the problem of computational inference of aesthetics and emotion from images. We begin with a background discussion on philosophy, photography, paintings, visual arts, and psychology. This is followed by introduction of a set of key computational problems that the research community has been striving to solve and the computational framework required for solving them. We also describe data sets available for performing assessment and outline several real-world applications where research in this domain can be employed. A significant number of papers that have attempted to solve problems in aesthetics and emotion inference are surveyed in this tutorial. We also discuss future directions that researchers can pursue and make a strong case for seriously attempting to solve problems in this research domain.","Emotion recognition,
Photography,
Semantics,
Data visualization,
Painting,
Human factors"
LMI-Based Approach for Global Asymptotic Stability Analysis of Recurrent Neural Networks with Various Delays and Structures,"Global asymptotic stability problem is studied for a class of recurrent neural networks with distributed delays satisfying Lebesgue-Stieljies measures on the basis of linear matrix inequality. The concerned network model includes many neural network models with various delays and structures as its special cases, such as the delays covering the discrete delays and distributed delays, and the network structures containing the neutral-type networks and high-order networks. Therefore, many new stability criteria for the above neural network models have also been derived from the present stability analysis method. All the obtained stability results have similar matrix inequality structures and can be easily checked. Three numerical examples are used to show the effectiveness of the obtained results.","Delay,
Stability criteria,
Asymptotic stability,
Artificial neural networks,
Recurrent neural networks,
Lead"
Intersection-Based Geographical Routing Protocol for VANETs: A Proposal and Analysis,"This paper presents a class of routing protocols for vehicular ad hoc networks (VANETs) called the Intersection-based Geographical Routing Protocol (IGRP), which outperforms existing routing schemes in city environments. IGRP is based on an effective selection of road intersections through which a packet must pass to reach the gateway to the Internet. The selection is made in a way that guarantees, with high probability, network connectivity among the road intersections while satisfying quality-of-service (QoS) constraints on tolerable delay, bandwidth usage, and error rate. Geographical forwarding is used to transfer packets between any two intersections on the path, reducing the path's sensitivity to individual node movements. To achieve this, we mathematically formulate the QoS routing problem as a constrained optimization problem. Specifically, analytical expressions for the connectivity probability, end-to-end delay, hop count, and bit error rate (BER) of a route in a two-way road scenario are derived. Then, we propose a genetic algorithm to solve the optimization problem. Numerical and simulation results show that the proposed approach gives optimal or near-optimal solutions and significantly improves VANET performance when compared with several prominent routing protocols, such as greedy perimeter stateless routing (GPSR), greedy perimeter coordinator routing (GPCR), and optimized link-state routing (OLSR).","Ad hoc networks,
Routing protocols,
Logic gates,
Quality of service,
Message systems"
Energy Efficient Security Algorithm for Power Grid Wide Area Monitoring System,"Modern power grid is the most complex human-made system, which is monitored by wide-area monitoring system (WAMS). Providing time-synchronized data of power system operating states, WAMS will play a crucial role in next generation smart grid protection and control. WAMS helps secure efficient energy transmission as well as reliable and optimal grid management. As the key enabler of a smart grid, numerous sensors such as PMU and current sensors transmit real-time dynamic data, which is usually protected by encryption algorithm from malicious attacks, over wide-area-network (WAN) to power system control centers so that monitoring and control of the whole system is possible. Security algorithms for power grid need to consider both performance and energy efficiency through code optimization techniques on encryption and decryption. In this paper, we take power nodes (sites) as platforms to experimentally study ways of energy consumptions in different security algorithms. First, we measure energy consumptions of various security algorithms on CrossBow and Ember sensor nodes. Second, we propose an array of novel code optimization methods to increase energy consumption efficiency of different security algorithms. Finally, based on careful analysis of measurement results, we propose a set of principles on using security algorithms in WAMS nodes, such as cryptography selections, parameter configuration, and the like. Such principles can be used widely in other computing systems with energy constraints.","Computer security,
Energy consumption,
Sensors,
Algorithm design and analysis,
Radio frequency,
Energy measurement,
Power demand"
"High-Frequency Modeling of TSVs for 3-D Chip Integration and Silicon Interposers Considering Skin-Effect, Dielectric Quasi-TEM and Slow-Wave Modes","Through-silicon vias (TSVs) in low, medium and high resistivity silicon for 3-D chip integration and interposers are modeled and thoroughly characterized from 100 MHz to 130 GHz, considering the slow-wave, dielectric quasi-TEM and skin-effect modes. The frequency ranges of these modes and their transitions are predicted using resistivity-frequency domain charts. The impact of the modes on signal integrity is quantified, and three coaxial TSV configurations are proposed to minimize this impact. Finally, conventional expressions for calculating the per-unit-length circuit parameters of transmission lines are extended and used to analytically capture the frequency dependent behavior of TSVs, considering the impact of the mixed dielectric (silicon dioxide-silicon-silicon dioxide) around the TSVs. Excellent correlation is obtained between the analytical calculations using the extended expressions and electromagnetic field simulations up to 130 GHz. These extended expressions can be implemented directly in electronic design automation tools to facilitate performance evaluation of TSVs, prior to system design.",
An Algorithm for License Plate Recognition Applied to Intelligent Transportation System,"An algorithm for license plate recognition (LPR) applied to the intelligent transportation system is proposed on the basis of a novel shadow removal technique and character recognition algorithms. This paper has two major contributions. One contribution is a new binary method, i.e., the shadow removal method, which is based on the improved Bernsen algorithm combined with the Gaussian filter. Our second contribution is a character recognition algorithm known as support vector machine (SVM) integration. In SVM integration, character features are extracted from the elastic mesh, and the entire address character string is taken as the object of study, as opposed to a single character. This paper also presents improved techniques for image tilt correction and image gray enhancement. Our algorithm is robust to the variance of illumination, view angle, position, size, and color of the license plates when working in a complex environment. The algorithm was tested with 9026 images, such as natural-scene vehicle images using different backgrounds and ambient illumination particularly for low-resolution images. The license plates were properly located and segmented as 97.16% and 98.34%, respectively. The optical character recognition system is the SVM integration with different character features, whose performance for numerals, Kana, and address recognition reached 99.5%, 98.6%, and 97.8%, respectively. Combining the preceding tests, the overall performance of success for the license plate achieves 93.54% when the system is used for LPR in various complex conditions.",
Control Over Imperfect Networks: Model-Based Predictive Networked Control Systems,"Networked control systems (NCSs) are digital control systems in which the functionality of the sensor, control, and actuator reside in physically different computer nodes communicating over a network. However, random delays and data loss of the communication network can endanger the stability of an NCS. We have proposed model-based predictive NCSs (MBPNCSs) that compensate for the aforementioned problems and avoid performance loss using a predictive control scheme based on a model of the plant. There are three main contributions of this paper to existing methods: an NCS that can work under random network delay and data loss with realistic structural assumptions, an explicit mechanism for reducing the effects of network delay and data loss on the deviation of plant state estimates from actual plant states, and an architecture where upstream nodes can work without receiving acknowledge information about the status of previously sent data packets from downstream nodes. In this paper, we describe MBPNCS and then introduce a stability criterion. This is followed by computer simulations and experiments involving the speed control of a dc motor. The results show that considerable improvement over performance is achieved with respect to an event-based NCS.",
Color Constancy Using Natural Image Statistics and Scene Semantics,"Existing color constancy methods are all based on specific assumptions such as the spatial and spectral characteristics of images. As a consequence, no algorithm can be considered as universal. However, with the large variety of available methods, the question is how to select the method that performs best for a specific image. To achieve selection and combining of color constancy algorithms, in this paper natural image statistics are used to identify the most important characteristics of color images. Then, based on these image characteristics, the proper color constancy algorithm (or best combination of algorithms) is selected for a specific image. To capture the image characteristics, the Weibull parameterization (e.g., grain size and contrast) is used. It is shown that the Weibull parameterization is related to the image attributes to which the used color constancy methods are sensitive. An MoG-classifier is used to learn the correlation and weighting between the Weibull-parameters and the image attributes (number of edges, amount of texture, and SNR). The output of the classifier is the selection of the best performing color constancy method for a certain image. Experimental results show a large improvement over state-of-the-art single algorithms. On a data set consisting of more than 11,000 images, an increase in color constancy performance up to 20 percent (median angular error) can be obtained compared to the best-performing single algorithm. Further, it is shown that for certain scene categories, one specific color constancy algorithm can be used instead of the classifier considering several algorithms.",
"Generalized Space-Time Shift Keying Designed for Flexible Diversity-, Multiplexing- and Complexity-Tradeoffs","In this paper, motivated by the recent concept of Spatial Modulation (SM), we propose a novel Generalized Space-Time Shift Keying (G-STSK) architecture, which acts as a unified Multiple-Input Multiple-Output (MIMO) framework. More specifically, our G-STSK scheme is based on the rationale that P out of Q dispersion matrices are selected and linearly combined in conjunction with the classic PSK/QAM modulation, where activating P out of Q dispersion matrices provides an implicit means of conveying information bits in addition to the classic modem. Due to its substantial flexibility, our G-STSK framework includes diverse MIMO arrangements, such as SM, Space-Shift Keying (SSK), Linear Dispersion Codes (LDCs), Space-Time Block Codes (STBCs) and Bell Lab's Layered Space-Time (BLAST) scheme. Hence it has the potential of subsuming all of them, when flexibly adapting a set of system parameters. Moreover, we also derive the Discrete-input Continuous-output Memoryless Channel (DCMC) capacity for our G-STSK scheme, which serves as the unified capacity limit, hence quantifying the capacity of the class of MIMO arrangements. Furthermore, EXtrinsic Information Transfer (EXIT) chart analysis is used for designing our G-STSK scheme and for characterizing its iterative decoding convergence.",
Service-Oriented Infrastructure to Support the Deployment of Evolvable Production Systems,"Nowadays, Service-oriented Architecture (SOA) paradigm is becoming a broadly deployed standard for business and enterprise integration. It continuously spreads across the diverse layers of the enterprise organization and disparate domains of application envisioning a unified communication solution. In the industrial domain, Evolvable Production System (EPS) paradigm focus on the identification of guidelines and solutions to support the design, operation, maintenance, and evolution of complete industrial infrastructures. Similarly to several other domains, the crescent ubiquity of smart devices is raising important lifecycle concerns such as device setup, control, management, supervision and diagnosis. From initial setup and deployment to system lifecycle monitoring and evolution, each device needs to be taken into account and easily reachable. The present work exploits the association of EPS and SOA paradigms in the pursuit of a common architectural solution to support the different phases of the device lifecycle. The result is a modular, adaptive and open infrastructure forming a complete SOA ecosystem that will make use of the embedded capabilities supported by the proposed device model. The infrastructure components are specified and it is shown how they can interact and be combined to adapt to current system specificity and requirements. Finally, a proof-of-concept prototype deployed in a real industrial production scenario is also detailed and results are presented.","Service oriented architecture,
Ontologies,
Production systems,
Semantics,
Software"
Trajectory Space: A Dual Representation for Nonrigid Structure from Motion,"Existing approaches to nonrigid structure from motion assume that the instantaneous 3D shape of a deforming object is a linear combination of basis shapes. These bases are object dependent and therefore have to be estimated anew for each video sequence. In contrast, we propose a dual approach to describe the evolving 3D structure in trajectory space by a linear combination of basis trajectories. We describe the dual relationship between the two approaches, showing that they both have equal power for representing 3D structure. We further show that the temporal smoothness in 3D trajectories alone can be used for recovering nonrigid structure from a moving camera. The principal advantage of expressing deforming 3D structure in trajectory space is that we can define an object independent basis. This results in a significant reduction in unknowns and corresponding stability in estimation. We propose the use of the Discrete Cosine Transform (DCT) as the object independent basis and empirically demonstrate that it approaches Principal Component Analysis (PCA) for natural motions. We report the performance of the proposed method, quantitatively using motion capture data, and qualitatively on several video sequences exhibiting nonrigid motions, including piecewise rigid motion, partially nonrigid motion (such as a facial expressions), and highly nonrigid motion (such as a person walking or dancing).","Trajectory,
Shape,
Three dimensional displays,
Equations,
Discrete cosine transforms,
Markov processes,
Cameras"
In Vitro and In Vivo Evaluation of PEDOT Microelectrodes for Neural Stimulation and Recording,"Cortical neural prostheses require chronically implanted small-area microelectrode arrays that simultaneously record and stimulate neural activity. It is necessary to develop new materials with low interface impedance and large charge transfer capacity for this application and we explore the use of conducting polymer poly(3,4-ethylenedioxythiophene) (PEDOT) for the same. We subjected PEDOT coated electrodes to voltage cycling between -0.6 and 0.8 V, 24 h continuous biphasic stimulation at 3 mC/cm2 and accelerated aging for four weeks. Characterization was performed using cyclic voltammetry, electrochemical impedance spectroscopy, and voltage transient measurements. We found that PEDOT coated electrodes showed a charge injection limit 15 times higher than Platinum Iridium (Ptlr) electrodes and electroplated Iridium Oxide (IrOx) electrodes when using constant current stimulation at zero voltage bias. In vivo chronic testing of microelectrode arrays implanted in rat cortex revealed that PEDOT coated electrodes show higher signal-to-noise recordings and superior charge injection compared to Ptlr electrodes.","Electrodes,
Voltage measurement,
Current measurement,
Transient analysis,
Impedance,
In vivo,
Coatings"
Abnormal detection using interaction energy potentials,"A new method is proposed to detect abnormal behaviors in human group activities. This approach effectively models group activities based on social behavior analysis. Different from previous work that uses independent local features, our method explores the relationships between the current behavior state of a subject and its actions. An interaction energy potential function is proposed to represent the current behavior state of a subject, and velocity is used as its actions. Our method does not depend on human detection or segmentation, so it is robust to detection errors. Instead, tracked spatio-temporal interest points are able to provide a good estimation of modeling group interaction. SVM is used to find abnormal events. We evaluate our algorithm in two datasets: UMN and BEHAVE. Experimental results show its promising performance against the state-of-art methods.","Solid modeling,
Tracking,
Computational modeling,
Humans,
Support vector machines,
Color,
Feature extraction"
Impact of Graphene Interface Quality on Contact Resistance and RF Device Performance,"This letter demonstrates the importance of the graphene/metal interface on the ohmic contacts of high-frequency graphene transistors grown by chemical vapor deposition (CVD) on copper. Using an Al sacrificial layer during ohmic lithography, the graphene surface roughness underneath the ohmic contacts is reduced by fourfold, resulting in an improvement in the contact resistance from 2.0 to 0.2-0.5 kΩ·μm. Using this technology, top-gated CVD graphene transistors achieved direct-current transconductances of 200 mS/mm, maximum on current densities in excess of 1000 mA/mm, and hole mobilities ~ 1500-3000 cm2/(V·s) on silicon substrates. Radio-frequency device performance yielded an extrinsic current-gain cutoff frequency fT of 12 GHz after pad capacitance de-embedding resulting in an fT - LG product of 24 GHz·μm.","Logic gates,
Contact resistance,
Resists,
Radio frequency,
Surface treatment,
Substrates,
FETs"
Exact-Repair MDS Code Construction Using Interference Alignment,"The high repair cost of (n, k) Maximum Distance Separable (MDS) erasure codes has recently motivated a new class of MDS codes, called Repair MDS codes, that can significantly reduce repair bandwidth over conventional MDS codes. In this paper, we describe (n, k, d) Exact-Repair MDS codes, which allow for any failed node to be repaired exactly with access to d survivor nodes, where k ≤ d ≤ n-1. We construct Exact-Repair MDS codes that are optimal in repair bandwidth for the cases of: (α) k/n ≤ 1/2 and d ≥ 2k - 11; (b) k ≤ 3. Our codes are deterministic and require a finite-field size of at most 2(n - k). Our constructive codes are based on interference alignment techniques.","Maintenance engineering,
Interference,
Systematics,
Encoding,
Bandwidth,
Equations,
Vectors"
All-Inkjet-Printed Organic Thin-Film Transistor Inverter on Flexible Plastic Substrate,"We report an all-inkjet-printed inverter using two p-type organic thin-film transistors (OTFTs) on a flexible plastic substrate. Metal-organic precursor-type silver ink, poly-4-vinylphenol solution, and 6,13-bis (triisopropylsilylethynyl)-pentacene solution were used to print gate and source/drain electrodes, gate-dielectric layer, and active semiconductor layer, respectively. By optimizing fabrication conditions, we obtained OTFTs with a mobility of 0.02 cm2/V·s, an on/off ratio of 104, and a threshold voltage of -1.2 V, and inverters with good switching performance showing a gain of 7.8 at a supply voltage of VDD = -40 V .","Organic thin film transistors,
Inverters,
Logic gates,
Substrates,
Electrodes"
Sparse target counting and localization in sensor networks based on compressive sensing,"In this paper, we propose a novel compressive sensing (CS) based approach for sparse target counting and positioning in wireless sensor networks. While this is not the first work on applying CS to count and localize targets, it is the first to rigorously justify the validity of the problem formulation. Moreover, we propose a novel greedy matching pursuit algorithm (GMP) that complements the well-known signal recovery algorithms in CS theory and prove that GMP can accurately recover a sparse signal with a high probability. We also propose a framework for counting and positioning targets from multiple categories, a novel problem that has never been addressed before. Finally, we perform a comprehensive set of simulations whose results demonstrate the superiority of our approach over the existing CS and non-CS based techniques.","Matching pursuit algorithms,
Compressed sensing,
Sparse matrices,
Algorithm design and analysis,
Argon,
Sensors,
Monitoring"
On the Effectiveness of an Opportunistic Traffic Management System for Vehicular Networks,"Road congestion results in a huge waste of time and productivity for millions of people. A possible way to deal with this problem is to have transportation authorities distribute traffic information to drivers, which, in turn, can decide (or be aided by a navigator) to route around congested areas. Such traffic information can be gathered by relying on static sensors placed at specific road locations (e.g., induction loops and video cameras) or by having single vehicles report their location, speed, and travel time. While the former approach has been widely exploited, the latter has come about only more recently; consequently, its potential is less understood. For this reason, in this paper, we study a realistic test case that allows the evaluation of the effectiveness of such a solution. As part of this process, (a) we designed a system that allows vehicles to crowd-source traffic information in an ad hoc manner, allowing them to dynamically reroute based on individually collected traffic information; (b) we implemented a realistic network-mobility simulator that allowed us to evaluate such a model; and (c) we performed a case study that evaluates whether such a decentralized system can help drivers to minimize trip times, which is the main focus of this paper. This study is based on traffic survey data from Portland, OR, and our results indicate that such navigation systems can indeed greatly improve traffic flow. Finally, to test the feasibility of our approach, we implemented our system and ran some real experiments at UCLA's C-Vet test bed.",
The Emergence of Social and Community Intelligence,"Social and community intelligence research aims to reveal individual and group behaviors, social interactions, and community dynamics by mining the digital traces that people leave while interacting with Web applications, static infrastructure, and mobile and wearable devices.",
Anticollision Protocols for Single-Reader RFID Systems: Temporal Analysis and Optimization,"One of the major challenges in the use of Radio Frequency-based Identification (RFID) on a large scale is the ability to read a large number of tags quickly. Central to solving this problem is resolving collisions that occur when multiple tags reply to the query of a reader. To this purpose, several MAC protocols for passive RFID systems have been proposed. These typically build on traditional MAC schemes, such as aloha and tree-based protocols. In this paper, we propose a new performance metric by which to judge these anticollision protocols: time system efficiency. This metric provides a direct measure of the time taken to read a group of tags. We then evaluate a set of well-known RFID MAC protocols in light of this metric. Based on the insights gained, we propose a new anticollision protocol, and show that it significantly outperforms previously proposed mechanisms.","Radiofrequency identification,
Media Access Protocol,
RFID tags,
Access protocols,
Radio frequency,
Passive RFID tags,
Computer science,
Large-scale systems,
Time measurement,
Inventory management"
Observer Design for Switched Recurrent Neural Networks: An Average Dwell Time Approach,"This paper is concerned with the problem of observer design for switched recurrent neural networks with time-varying delay. The attention is focused on designing the full-order observers that guarantee the global exponential stability of the error dynamic system. Based on the average dwell time approach and the free-weighting matrix technique, delay-dependent sufficient conditions are developed for the solvability of such problem and formulated as linear matrix inequalities. The error-state decay estimate is also given. Then, the stability analysis problem for the switched recurrent neural networks can be covered as a special case of our results. Finally, four illustrative examples are provided to demonstrate the effectiveness and the superiority of the proposed methods.","Switches,
Delay,
Observers,
Biological neural networks,
Recurrent neural networks,
Stability analysis,
Neurons"
Multi-Mode Transmission for the MIMO Broadcast Channel with Imperfect Channel State Information,"This paper proposes an adaptive multi-mode transmission strategy to improve the spectral efficiency achieved in the multiple-input multiple-output (MIMO) broadcast channel with delayed and quantized channel state information. The adaptive strategy adjusts the number of active users, denoted as the transmission mode, to balance transmit array gain, spatial division multiplexing gain, and residual inter-user interference. Accurate closed-form approximations are derived for the achievable rates for different modes, which help identify the active mode that maximizes the average sum throughput for given feedback delay and channel quantization error. The proposed transmission strategy can be easily combined with round-robin scheduling to serve a large number of users. As instantaneous channel information is not exploited, the proposed algorithm cannot provide multiuser diversity gain, but it is still able to provide throughput gain over single-user MIMO at moderate signal-to-noise ratio. In addition, it has a light feedback overhead and only requires feedback of instantaneous channel state information from a small number of users. In the system with a feedback load constraint, it is shown that the proposed algorithm provides performance close to that achieved by opportunistic scheduling with instantaneous feedback from a large number of users.","Interference,
Signal to noise ratio,
Approximation methods,
Delay,
Multiplexing,
Quantization,
Switches"
Mars: Accelerating MapReduce with Graphics Processors,"We design and implement Mars, a MapReduce runtime system accelerated with graphics processing units (GPUs). MapReduce is a simple and flexible parallel programming paradigm originally proposed by Google, for the ease of large-scale data processing on thousands of CPUs. Compared with CPUs, GPUs have an order of magnitude higher computation power and memory bandwidth. However, GPUs are designed as special-purpose coprocessors and their programming interfaces are less familiar than those on the CPUs to MapReduce programmers. To harness GPUs' power for MapReduce, we developed Mars to run on NVIDIA GPUs, AMD GPUs as well as multicore CPUs. Furthermore, we integrated Mars into Hadoop, an open-source CPU-based MapReduce system. Mars hides the programming complexity of GPUs behind the simple and familiar MapReduce interface, and automatically manages task partitioning, data distribution, and parallelization on the processors. We have implemented six representative applications on Mars and evaluated their performance on PCs equipped with GPUs as well as multicore CPUs. The experimental results show that, the GPU-CPU coprocessing of Mars on an NVIDIA GTX280 GPU and an Intel quad-core CPU outperformed Phoenix, the state-of-the-art MapReduce on the multicore CPU with a speedup of up to 72 times and 24 times on average, depending on the applications. Additionally, integrating Mars into Hadoop enabled GPU acceleration for a network of PCs.","Graphics processing unit,
Mars,
Programming,
Memory management,
Acceleration,
Bandwidth"
DC voltage control and power dispatch of a multi-terminal HVDC system for integrating large offshore wind farms,"Multi-terminal HVDC transmission technology using voltage source converters is proposed for integrating large offshore wind farms with transmission grids. Different DC voltage control and power dispatch strategies are proposed to demonstrate the flexibility and capability of such a transmission system in integrating large-scale variable wind generation. Various options for ensuring satisfactory ride through onshore grid faults are discussed. PSCAD/EMTDC simulations on a four-terminal high voltage direct current (HVDC) system with two offshore and two onshore converter stations during wind speed and power variations, and control mode switching are presented to show the robust performance and ability of the proposed system. Further studies during severe fault on one of the connected onshore AC networks are provided to validate the fault ride through capability of the multi-terminal HVDC system.","wind power,
HVDC power transmission,
offshore installations,
power grids,
voltage control"
Fifty Years of Acoustic Feedback Control: State of the Art and Future Challenges,"The acoustic feedback problem has intrigued researchers over the past five decades, and a multitude of solutions has been proposed. In this survey paper, we aim to provide an overview of the state of the art in acoustic feedback control, to report results of a comparative evaluation with a selection of existing methods, and to cast a glance at the challenges for future research.","Acoustics,
Feedback control,
Loudspeakers,
Microphones,
Technology forecasting,
Stability analysis,
Transfer functions"
Tabula rasa: Model transfer for object category detection,"Our objective is transfer training of a discriminatively trained object category detector, in order to reduce the number of training images required. To this end we propose three transfer learning formulations where a template learnt previously for other categories is used to regularize the training of a new category. All the formulations result in convex optimization problems. Experiments (on PASCAL VOC) demonstrate significant performance gains by transfer learning from one class to another (e.g. motorbike to bicycle), including one-shot learning, specialization from class to a subordinate class (e.g. from quadruped to horse) and transfer using multiple components. In the case of multiple training samples it is shown that a detection performance approaching that of the state of the art can be achieved with substantially fewer training samples.",
End-to-end scene text recognition,"This paper focuses on the problem of word detection and recognition in natural images. The problem is significantly more challenging than reading text in scanned documents, and has only recently gained attention from the computer vision community. Sub-components of the problem, such as text detection and cropped image word recognition, have been studied in isolation [7, 4, 20]. However, what is unclear is how these recent approaches contribute to solving the end-to-end problem of word recognition. We fill this gap by constructing and evaluating two systems. The first, representing the de facto state-of-the-art, is a two stage pipeline consisting of text detection followed by a leading OCR engine. The second is a system rooted in generic object recognition, an extension of our previous work in [20]. We show that the latter approach achieves superior performance. While scene text recognition has generally been treated with highly domain-specific methods, our results demonstrate the suitability of applying generic computer vision methods. Adopting this approach opens the door for real world scene text recognition to benefit from the rapid advances that have been taking place in object recognition.",
"A Perspective on Nanowire Photodetectors: Current Status, Future Challenges, and Opportunities","One-dimensional semiconductor nanostructures (nanowires (NWs), nanotubes, nanopillars, nanorods, etc.) based photodetectors (PDs) have been gaining traction in the research community due to their ease of synthesis and unique optical, mechanical, electrical, and thermal properties. Specifically, the physics and technology of NW PDs offer numerous insights and opportunities for nanoscale optoelectronics, photovoltaics, plasmonics, and emerging negative index metamaterials devices. The successful integration of these NW PDs on CMOS-compatible substrates and various low-cost substrates via direct growth and transfer-printing techniques would further enhance and facilitate the adaptation of this technology module in the semiconductor foundries. In this paper, we review the unique advantages of NW-based PDs, current device integration schemes and practical strategies, recent device demonstrations in lateral and vertical process integration with methods to incorporate NWs in PDs via direct growth (nanoepitaxy) methods and transfer-printing methods, and discuss the numerous technical design challenges. In particular, we present an ultrafast surface-illuminated PD with 11.4-ps full-width at half-maximum (FWHM), edge-illuminated novel waveguide PDs, and some novel concepts of light trapping to provide a full-length discussion on the topics of: 1) low-resistance contact and interfaces for NW integration; 2) high-speed design and impedance matching; and 3) CMOS-compatible mass-manufacturable device fabrication. Finally, we offer a brief outlook into the future opportunities of NW PDs for consumer and military application.","Silicon,
Substrates,
Photonics,
Nanoscale devices,
Lattices,
Absorption"
Dynamic Programming and Graph Algorithms in Computer Vision,"Optimization is a powerful paradigm for expressing and solving problems in a wide range of areas, and has been successfully applied to many vision problems. Discrete optimization techniques are especially interesting since, by carefully exploiting problem structure, they often provide nontrivial guarantees concerning solution quality. In this paper, we review dynamic programming and graph algorithms, and discuss representative examples of how these discrete optimization techniques have been applied to some classical vision problems. We focus on the low-level vision problem of stereo, the mid-level problem of interactive object segmentation, and the high-level problem of model-based recognition.","Dynamic programming,
Computer vision,
Optimization methods,
Stereo vision,
Computer science,
Application software,
Object segmentation,
Layout,
Artificial intelligence,
Probability"
Correlation Rotation Linear Precoding for MIMO Broadcast Communications,"A simple linear precoding technique is proposed for multiple input multiple output (MIMO) broadcast systems using phase shift keying (PSK) modulation. The proposed technique is based on the fact that, on an instantaneous basis, the interference between spatial links in a MIMO system can be constructive and can contribute to the power of the useful signal to improve the performance of signal detection. In MIMO downlinks this co-channel interference (CCI) can be predicted and characterised prior to transmission. Contrary to common practice where knowledge of the interference is used to eliminate it, the main idea proposed here is to use this knowledge to influence the interference and benefit from it, thus gaining advantage from energy already existing in the communication system that is left unexploited otherwise. The proposed precoding aims at adaptively rotating, rather than zeroing, the correlation between the MIMO substreams depending on the transmitted data, so that the signal of interfering transmissions is aligned to the signal of interest at each receive antenna. By doing so, the CCI is always kept constructive and the received signal to interference-plus-noise ratio (SINR) delivered to the mobile units (MUs) is enhanced without the need to invest additional signal power per transmitted symbol at the MIMO base station (BS). It is shown by means of theoretical analysis and simulations that the proposed MIMO precoding technique offers significant performance and throughput gains compared to its conventional counterparts.","MIMO,
Interference,
Downlink,
Receiving antennas,
Transmitters,
Correlation"
Social-aware stateless forwarding in pocket switched networks,"In this paper we describe SANE, the first forwarding mechanism that combines the advantages of both social-aware and stateless approaches in pocket switched network routing. SANE is based on the observation“that we validate on real-world traces”that individuals with similar interests tend to meet more often. In our approach, individuals (network members) are characterized by their interest profile, a compact representation of their interests. Through extensive experiments, we show the superiority of social-aware, stateless forwarding over existing stateful, social-aware and stateless, social-oblivious forwarding. An important byproduct of our interest-based approach is that it easily enables innovative routing primitives, such as interest-casting. An interest-casting protocol is also described, and extensively evaluated through experiments based on both real-world and synthetic mobility traces.","Protocols,
Correlation,
Delay,
Unicast,
Routing,
Relays"
From co-saliency to co-segmentation: An efficient and fully unsupervised energy minimization model,"We address two key issues of co-segmentation over multiple images. The first is whether a pure unsupervised algorithm can satisfactorily solve this problem. Without the user's guidance, segmenting the foregrounds implied by the common object is quite a challenging task, especially when substantial variations in the object's appearance, shape, and scale are allowed. The second issue concerns the efficiency if the technique can lead to practical uses. With these in mind, we establish an MRF optimization model that has an energy function with nice properties and can be shown to effectively resolve the two difficulties. Specifically, instead of relying on the user inputs, our approach introduces a co-saliency prior as the hint about possible foreground locations, and uses it to construct the MRF data terms. To complete the optimization framework, we include a novel global term that is more appropriate to co-segmentation, and results in a submodular energy function. The proposed model can thus be optimally solved by graph cuts. We demonstrate these advantages by testing our method on several benchmark datasets.",
ABAKA: An Anonymous Batch Authenticated and Key Agreement Scheme for Value-Added Services in Vehicular Ad Hoc Networks,"In this paper, we introduce an anonymous batch authenticated and key agreement (ABAKA) scheme to authenticate multiple requests sent from different vehicles and establish different session keys for different vehicles at the same time. In vehicular ad hoc networks (VANETs), the speed of a vehicle is changed from 10 to 40 m/s (36-144 km/h); therefore, the need for efficient authentication is inevitable. Compared with the current key agreement scheme, ABAKA can efficiently authenticate multiple requests by one verification operation and negotiate a session key with each vehicle by one broadcast message. Elliptic curve cryptography is adopted to reduce the verification delay and transmission overhead. The security of ABAKA is based on the elliptic curve discrete logarithm problem, which is an unsolved NP-complete problem. To deal with the invalid request problem, which may cause the batch verification fail, a detection algorithm has been proposed. Moreover, we demonstrate the efficiency merits of ABAKA through performance evaluations in terms of verification delay, transmission overhead, and cost for rebatch verifications, respectively. Simulation results show that both the message delay and message loss rate of ABAKA are less than that of the existing elliptic curve digital signature algorithm (ECDSA)-based scheme.","Vehicles,
Authentication,
Delay,
Elliptic curve cryptography,
Privacy,
Elliptic curves"
"Effects of TMAH Treatment on Device Performance of Normally Off
Al
2
O
3
/GaN
MOSFET","Normally off Al2O3/GaN MOSFETs are fabricated by utilizing a simple tetramethylammonium hydroxide (TMAH) treatment as a postgate-recess process. The TMAH-treated device with a gate length of 2.5 μm exhibited excellent device performances, such as a threshold voltage of 3.5 V, a maximum drain current of 336 mA/mm, and a breakdown voltage of 725 V, along with extremely small gate leakage current of about 10-9 A/mm at Vgs = 15 V, which is approximately six orders lower in magnitude compared to that of the device without TMAH treatment.",
Deep Belief Networks using discriminative features for phone recognition,"Deep Belief Networks (DBNs) are multi-layer generative models. They can be trained to model windows of coefficients extracted from speech and they discover multiple layers of features that capture the higher-order statistical structure of the data. These features can be used to initialize the hidden units of a feed-forward neural network that is then trained to predict the HMM state for the central frame of the window. Initializing with features that are good at generating speech makes the neural network perform much better than initializing with random weights. DBNs have already been used successfully for phone recognition with input coefficients that are MFCCs or filterbank outputs. In this paper, we demonstrate that they work even better when their inputs are speaker adaptive, discriminative features. On the standard TIMIT corpus, they give phone error rates of 19.6% using monophone HMMs and a bigram language model and 19.4% using monophone HMMs and a trigram language model.","Hidden Markov models,
Training,
Artificial neural networks,
Decoding,
Speech,
Error analysis,
Mel frequency cepstral coefficient"
Robust Shrinkage Estimation of High-Dimensional Covariance Matrices,"We address high dimensional covariance estimation for elliptical distributed samples, which are also known as spherically invariant random vectors (SIRV) or compound-Gaussian processes. Specifically we consider shrinkage methods that are suitable for high dimensional problems with a small number of samples (large p small n). We start from a classical robust covariance estimator [Tyler (1987)], which is distribution-free within the family of elliptical distribution but inapplicable when n <; p. Using a shrinkage coefficient, we regularize Tyler's fixed-point iterations. We prove that, for all n and p , the proposed fixed-point iterations converge to a unique limit regardless of the initial condition. Next, we propose a simple, closed-form and data dependent choice for the shrinkage coefficient, which is based on a minimum mean squared error framework. Simulations demonstrate that the proposed method achieves low estimation error and is robust to heavy-tailed samples. Finally, as a real-world application we demonstrate the performance of the proposed technique in the context of activity/intrusion detection using a wireless sensor network.",
Optimal charging of plug-in hybrid electric vehicles in smart grids,"Plug-in hybrid electric vehicles (PHEVs) play an important role in making a greener future. Given a group of PHEVs distributed across a power network equipped with the smart grid technology (e.g. wireless communication devices), the objective of this paper is to study how to schedule the charging of the PHEV batteries. To this end, we assume that each battery must be fully charged by a pre-specified time, and that the charging rate can be time-varying at discrete-time instants. The scheduling problem for the PHEV charging can be augmented into the optimal power flow (OPF) problem to obtain a joint OPF-charging (dynamic) optimization. A solution to this highly nonconvex problem optimizes the network performance by minimizing the generation and charging costs while satisfying the network, physical and inelastic-load constraints. A global optimum to the joint OPF-charging optimization can be found efficiently in polynomial time by solving its convex dual problem whenever the duality gap is zero for the joint OPF-charging problem. It is shown in a recent work that the duality gap is expected to be zero for the classical OPF problem. We build on this result and prove that the duality gap is zero for the joint OPF-charging optimization if it is zero for the classical OPF problem. The results of this work are applied to the IEEE 14 bus system.","Batteries,
Joints,
Optimization,
Smart grids,
Pricing,
Polynomials"
RCFile: A fast and space-efficient data placement structure in MapReduce-based warehouse systems,"MapReduce-based data warehouse systems are playing important roles of supporting big data analytics to understand quickly the dynamics of user behavior trends and their needs in typical Web service providers and social network sites (e.g., Facebook). In such a system, the data placement structure is a critical factor that can affect the warehouse performance in a fundamental way. Based on our observations and analysis of Facebook production systems, we have characterized four requirements for the data placement structure: (1) fast data loading, (2) fast query processing, (3) highly efficient storage space utilization, and (4) strong adaptivity to highly dynamic workload patterns. We have examined three commonly accepted data placement structures in conventional databases, namely row-stores, column-stores, and hybrid-stores in the context of large data analysis using MapReduce. We show that they are not very suitable for big data processing in distributed systems. In this paper, we present a big data placement structure called RCFile (Record Columnar File) and its implementation in the Hadoop system. With intensive experiments, we show the effectiveness of RCFile in satisfying the four requirements. RCFile has been chosen in Facebook data warehouse system as the default option. It has also been adopted by Hive and Pig, the two most widely used data analysis systems developed in Facebook and Yahoo!","Facebook,
Data storage systems,
Data handling,
Information management,
Data warehouses,
Data compression,
Query processing"
A New Scanning Method for Fast Atomic Force Microscopy,"In recent years, the atomic force microscope (AFM) has become an important tool in nanotechnology research. It was first conceived to generate 3-D images of conducting as well as nonconducting surfaces with a high degree of accuracy. Presently, it is also being used in applications that involve manipulation of material surfaces at a nanoscale. In this paper, we describe a new scanning method for fast atomic force microscopy. In this technique, the sample is scanned in a spiral pattern instead of the well-established raster pattern. A constant angular velocity spiral scan can be produced by applying single frequency cosine and sine signals with slowly varying amplitudes to the x-axis and y -axis of AFM nanopositioner, respectively. The use of single-frequency input signals allows the scanner to move at high speeds without exciting the mechanical resonance of the device. Alternatively, the frequency of the sinusoidal set points can be varied to maintain a constant linear velocity (CLV) while a spiral trajectory is being traced. Thus, producing a CLV spiral. These scan methods can be incorporated into most modern AFMs with minimal effort since they can be implemented in software using the existing hardware. Experimental results obtained by implementing the method on a commercial AFM indicate that high-quality images can be generated at scan frequencies well beyond the raster scans.","Atomic force microscopy,
Spirals,
Frequency,
Image generation,
Nanotechnology,
Conducting materials,
Angular velocity,
Nanopositioning,
Resonance,
Hardware"
Sparse distance learning for object recognition combining RGB and depth information,"In this work we address joint object category and instance recognition in the context of RGB-D (depth) cameras. Motivated by local distance learning, where a novel view of an object is compared to individual views of previously seen objects, we define a view-to-object distance where a novel view is compared simultaneously to all views of a previous object. This novel distance is based on a weighted combination of feature differences between views. We show, through jointly learning per-view weights, that this measure leads to superior classification performance on object category and instance recognition. More importantly, the proposed distance allows us to find a sparse solution via Group-Lasso regularization, where a small subset of representative views of an object is identified and used, with the rest discarded. This significantly reduces computational cost without compromising recognition accuracy. We evaluate the proposed technique, Instance Distance Learning (IDL), on the RGB-D Object Dataset, which consists of 300 object instances in 51 everyday categories and about 250,000 views of objects with both RGB color and depth. We empirically compare IDL to several alternative state-of-the-art approaches and also validate the use of visual and shape cues and their combination.","Computer aided instruction,
Shape,
Visualization,
Three dimensional displays,
Accuracy,
Object recognition,
Feature extraction"
TAIEX Forecasting Based on Fuzzy Time Series and Fuzzy Variation Groups,"In this paper, we present a new method to forecast the daily Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX) based on fuzzy time series and fuzzy variation groups, where the main input factor is the previous day's TAIEX, and the secondary factor is either the Dow Jones, the NASDAQ, the M 1b, or their combination. First, the proposed method fuzzifies the historical training data of the TAIEX into fuzzy sets to form fuzzy logical relationships. Second, it groups the fuzzy logical relationships into fuzzy logical relationship groups (FLRGs) based on the fuzzy variations of the secondary factor. Third, it evaluates the leverage of the fuzzy variations between the main factor and the secondary factor to construct fuzzy variation groups. Fourth, it gets the statistics of the fuzzy variations appearing in each fuzzy variation group. Fifth, it calculates the weights of the statistics of the fuzzy variations appearing in each fuzzy variation group, respectively. Finally, based on the weights of the statistics of the fuzzy variations appearing in the fuzzy variation groups and the FLRGs, it performs the forecasting of the daily TAIEX. Because the proposed method uses both fuzzy variation groups and FLRGs to analyze in detail the historical training data, it gets higher forecasting accuracy rates to forecast the TAIEX than the existing methods.",
Eyes in the Sky: Decentralized Control for the Deployment of Robotic Camera Networks,"This paper presents a decentralized control strategy for positioning and orienting multiple robotic cameras to collectively monitor an environment. The cameras may have various degrees of mobility from six degrees of freedom, to one degree of freedom. The control strategy is proven to locally minimize a novel metric representing information loss over the environment. It can accommodate groups of cameras with heterogeneous degrees of mobility (e.g., some that only translate and some that only rotate), and is adaptive to robotic cameras being added or deleted from the group, and to changing environmental conditions. The robotic cameras share information for their controllers over a wireless network using a specially designed multihop networking algorithm. The control strategy is demonstrated in repeated experiments with three flying quadrotor robots indoors, and with five flying quadrotor robots outdoors. Simulation results for more complex scenarios are also presented.","Cameras,
Robot vision systems,
Ad hoc networks,
Cost function,
Distributed control,
Multirobot systems,
Nonlinear control systems,
Unmanned aerial vehicles,
Mobile communication,
Wireless sensor networks"
Estimation in Gaussian Noise: Properties of the Minimum Mean-Square Error,"Consider the minimum mean-square error (MMSE) of estimating an arbitrary random variable from its observation contaminated by Gaussian noise. The MMSE can be regarded as a function of the signal-to-noise ratio (SNR) as well as a functional of the input distribution (of the random variable to be estimated). It is shown that the MMSE is concave in the input distribution at any given SNR. For a given input distribution, the MMSE is found to be infinitely differentiable at all positive SNR, and in fact a real analytic function in SNR under mild conditions. The key to these regularity results is that the posterior distribution conditioned on the observation through Gaussian channels always decays at least as quickly as some Gaussian density. Furthermore, simple expressions for the first three derivatives of the MMSE with respect to the SNR are obtained. It is also shown that, as functions of the SNR, the curves for the MMSE of a Gaussian input and that of a non-Gaussian input cross at most once over all SNRs. These properties lead to simple proofs of the facts that Gaussian inputs achieve both the secrecy capacity of scalar Gaussian wiretap channels and the capacity of scalar Gaussian broadcast channels, as well as a simple proof of the entropy power inequality in the special case where one of the variables is Gaussian.","Signal to noise ratio,
Random variables,
Gaussian noise,
Entropy,
Estimation error,
Noise measurement"
An Optimal Algorithm for Relay Node Assignment in Cooperative Ad Hoc Networks,"Recently, cooperative communications, in the form of having each node equipped with a single antenna and exploit spatial diversity via some relay node's antenna, is shown to be a promising approach to increase data rates in wireless networks. Under this communication paradigm, the choice of a relay node (among a set of available relay nodes) is critical in the overall network performance. In this paper, we study the relay node assignment problem in a cooperative ad hoc network environment, where multiple source-destination pairs compete for the same pool of relay nodes in the network. Our objective is to assign the available relay nodes to different source-destination pairs so as to maximize the minimum data rate among all pairs. The main contribution of this paper is the development of an optimal polynomial time algorithm, called ORA, that achieves this objective. A novel idea in this algorithm is a “linear marking” mechanism, which maintains linear complexity of each iteration. We give a formal proof of optimality for ORA and use numerical results to demonstrate its capability.","Relays,
Ad hoc networks,
Wireless communication,
Antennas,
Complexity theory,
Physical layer,
Transceivers"
Multicast Authentication in the Smart Grid With One-Time Signature,"Multicast has been envisioned to be useful in many smart grid applications such as demand-response, wide area protection , in-substation protection and various operation and control. Since the multicast messages are related to critical control, authentication is necessary to prevent message forgery attacks. In this paper, we first identify the requirements of multicast communication and multicast authentication in the smart grid. Based on these requirements, we find that one-time signature based multicast authentication is a promising solution, due to its short authentication delay and low computation cost. However, existing one-time signatures are not designed for the smart grid and they may have high storage and bandwidth overhead. To address this problem, we propose a new one-time signature scheme which can reduce the storage cost by a factor of 8 and reduce the signature size by 40% compared with existing schemes. Thus, our scheme is more appropriate for smart grid applications where the receivers have limited storage (e.g., home appliances and field devices) or where data communication is frequent and short (e.g., phasor data). These gains are at the cost of increased computations in signature generation and/or verification and fortunately our scheme can flexibly allocate the computations between the sender and receiver based on their computing resources. We formulate the computation allocation as a nonlinear integer programming problem to minimize the signing cost under a certain verification cost and propose a heuristic solution to solve it.",
A Robust Optimization Approach for Planning the Transition to Plug-in Hybrid Electric Vehicles,"This paper proposes a new technique to analyze the electricity and transport sectors within a single integrated framework to realize an environmentally and economically sustainable integration of plug-in hybrid electric vehicles (PHEVs) into the electric grid, considering the most relevant planning uncertainties. The method is based on a comprehensive robust optimization planning that considers the constraints of both the electricity grid and the transport sector. The proposed model is justified and described in some detail, applying it to the real case of Ontario, Canada, to determine Ontario's grid potential to support PHEVs for the planning horizon 2008-2025.",
Home 3D body scans from noisy image and range data,"The 3D shape of the human body is useful for applications in fitness, games and apparel. Accurate body scanners, however, are expensive, limiting the availability of 3D body models. We present a method for human shape reconstruction from noisy monocular image and range data using a single inexpensive commodity sensor. The approach combines low-resolution image silhouettes with coarse range data to estimate a parametric model of the body. Accurate 3D shape estimates are obtained by combining multiple monocular views of a person moving in front of the sensor. To cope with varying body pose, we use a SCAPE body model which factors 3D body shape and pose variations. This enables the estimation of a single consistent shape while allowing pose to vary. Additionally, we describe a novel method to minimize the distance between the projected 3D body contour and the image silhouette that uses analytic derivatives of the objective function. We propose a simple method to estimate standard body measurements from the recovered SCAPE model and show that the accuracy of our method is competitive with commercial body scanning systems costing orders of magnitude more.",
Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features,"Glaucoma is the second leading cause of blindness worldwide. It is a disease in which fluid pressure in the eye increases continuously, damaging the optic nerve and causing vision loss. Computational decision support systems for the early detection of glaucoma can help prevent this complication. The retinal optic nerve fiber layer can be assessed using optical coherence tomography, scanning laser polarimetry, and Heidelberg retina tomography scanning methods. In this paper, we present a novel method for glaucoma detection using a combination of texture and higher order spectra (HOS) features from digital fundus images. Support vector machine, sequential minimal optimization, naive Bayesian, and random-forest classifiers are used to perform supervised classification. Our results demonstrate that the texture and HOS features after z-score normalization and feature selection, and when combined with a random-forest classifier, performs better than the other classifiers and correctly identifies the glaucoma images with an accuracy of more than 91%. The impact of feature ranking and normalization is also studied to improve results. Our proposed novel features are clinically significant and can be used to detect glaucoma accurately.","Feature extraction,
Optical imaging,
Classification algorithms,
Optical fibers,
Artificial neural networks,
Entropy"
Performance of LDPC Codes Under Faulty Iterative Decoding,"Departing from traditional communication theory where decoding algorithms are assumed to perform without error, a system where noise perturbs both computational devices and communication channels is considered here. This paper studies limits in processing noisy signals with noisy circuits by investigating the effect of noise on standard iterative decoders for low-density parity-check (LDPC) codes. Concentration of decoding performance around its average is shown to hold when noise is introduced into message-passing and local computation. Density evolution equations for simple faulty iterative decoders are derived. In one model, computing nonlinear estimation thresholds shows that performance degrades smoothly as decoder noise increases, but arbitrarily small probability of error is not achievable. Probability of error may be driven to zero in another system model; the decoding threshold again decreases smoothly with decoder noise. As an application of the methods developed, an achievability result for reliable memory systems constructed from unreliable components is provided.","Decoding,
Noise,
Noise measurement,
Circuit faults,
Iterative decoding,
Wires"
Algorithm-Enabled Low-Dose Micro-CT Imaging,"Micro-computed tomography (micro-CT) is an important tool in biomedical research and preclinical applications that can provide visual inspection of and quantitative information about imaged small animals and biological samples such as vasculature specimens. Currently, micro-CT imaging uses projection data acquired at a large number (300-1000) of views, which can limit system throughput and potentially degrade image quality due to radiation-induced deformation or damage to the small animal or specimen. In this work, we have investigated low-dose micro-CT and its application to specimen imaging from substantially reduced projection data by using a recently developed algorithm, referred to as the adaptive-steepest-descent-projection-onto-convex-sets (ASD-POCS) algorithm, which reconstructs an image through minimizing the image total-variation and enforcing data constraints. To validate and evaluate the performance of the ASD-POCS algorithm, we carried out quantitative evaluation studies in a number of tasks of practical interest in imaging of specimens of real animal organs. The results show that the ASD-POCS algorithm can yield images with quality comparable to that obtained with existing algorithms, while using one-sixth to one quarter of the 361-view data currently used in typical micro-CT specimen imaging.","Image reconstruction,
Variable speed drives,
Image segmentation,
Computed tomography,
Heart,
Image quality"
Reduced-Complexity Coherent Versus Non-Coherent QAM-Aided Space-Time Shift Keying,"A novel reduced-complexity near-optimal detection algorithm is proposed for enhancing the recent Coherently-detected Space-Time Shift Keying (CSTSK) scheme employing arbitrary constellations, such as {\cal L}-point Phase-Shift Keying (PSK) and Quadrature Amplitude Modulation (QAM). The proposed detector relies on a modified Matched Filter (MF) concept. More specifically, we exploit both the constellation diagram of the modulation scheme employed as well as the Inter-Element-Interference (IEI)-free STSK architecture. Furthermore, we generalize the Pulse Amplitude Modulation (PAM)- or PSK-aided Differentially-encoded STSK (DSTSK) concept and conceive its more bandwidth-efficient QAM-aided counterpart. Then, the proposed reduced-complexity CSTSK detector is applied to the QAM-aided DSTSK scheme, which enables us to carry out low-complexity non-coherent detection, while dispensing with channel estimation. It is revealed that the proposed detector is capable of approaching the optimal Maximum Likelihood (ML) detector's performance, while avoiding the exhaustive ML search. Interestingly, our simulation results also demonstrate that the reduced-complexity detector advocated may achieve the same performance as that of the optimal ML detector for the specific STSK scheme's parameters. Another novelty of this paper is that the star-QAM STSK scheme tends to outperform its square-QAM counterpart, especially for high number of dispersion matrices. Furthermore, we provided both the theoretical analysis and the simulations, in order to support this unexpected fact.","Detectors,
Quadrature amplitude modulation,
Complexity theory,
Phase shift keying,
Receivers"
Simultaneous dimensionality reduction and human age estimation via kernel partial least squares regression,"Human age estimation has recently become an active research topic in computer vision and pattern recognition, because of many potential applications in reality. In this paper we propose to use the kernel partial least squares (KPLS) regression for age estimation. The KPLS (or linear PLS) method has several advantages over previous approaches: (1) the KPLS can reduce feature dimensionality and learn the aging function simultaneously in a single learning framework, instead of performing each task separately using different techniques; (2) the KPLS can find a small number of latent variables, e.g., 20, to project thousands of features into a very low-dimensional subspace, which may have great impact on real-time applications; and (3) the KPLS regression has an output vector that can contain multiple labels, so that several related problems, e.g., age estimation, gender classification, and ethnicity estimation can be solved altogether. This is the first time that the kernel PLS method is introduced and applied to solve a regression problem in computer vision with high accuracy. Experimental results on a very large database show that the KPLS is significantly better than the popular SVM method, and outperform the state-of-the-art approaches in human age estimation.","Estimation,
Databases,
Kernel,
Feature extraction,
Support vector machines,
Manifolds,
Aging"
Resource Allocation for Wireless Multiuser OFDM Networks,"Resource allocation issues are investigated in this paper for multiuser wireless transmissions based on orthogonal frequency division multiplexing (OFDM). Relying on convex and stochastic optimization tools, the novel approach to resource allocation includes: i) development of jointly optimal subcarrier, power, and rate allocation for weighted sum-average-rate maximization; ii) judicious formulation and derivation of the optimal resource allocation for maximizing the utility of average user rates; and iii) development of the stochastic resource allocation schemes, and rigorous proof of their convergence and optimality. Simulations are also provided to demonstrate the merits of the novel schemes.","Resource management,
OFDM,
Fading,
Wireless communication,
Downlink,
Quality of service,
Optimization"
Multi-Scale Dictionary Learning Using Wavelets,"In this paper, we present a multi-scale dictionary learning paradigm for sparse and redundant signal representations. The appeal of such a dictionary is obvious-in many cases data naturally comes at different scales. A multi-scale dictionary should be able to combine the advantages of generic multi-scale representations (such as Wavelets), with the power of learned dictionaries, in capturing the intrinsic characteristics of a family of signals. Using such a dictionary would allow representing the data in a more efficient, i.e., sparse, manner, allowing applications to take a more global look at the signal. In this paper, we aim to achieve this goal without incurring the costs of an explicit dictionary with large atoms. The K-SVD using Wavelets approach presented here applies dictionary learning in the analysis domain of a fixed multi-scale operator. This way, sub-dictionaries at different data scales, consisting of small atoms, are trained. These dictionaries can then be efficiently used in sparse coding for various image processing applications, potentially outperforming both single-scale trained dictionaries and multi-scale analytic ones. In this paper, we demonstrate this construction and discuss its potential through several experiments performed on fingerprint and coastal scenery images.","Dictionaries,
Wavelet transforms,
Training,
Wavelet domain,
Wavelet analysis,
Matching pursuit algorithms"
Challenges and Opportunities for Next-Generation Intracortically Based Neural Prostheses,"Neural prosthetic systems aim to help disabled patients by translating neural signals from the brain into control signals for guiding computer cursors, prosthetic arms, and other assistive devices. Intracortical electrode arrays measure action potentials and local field potentials from individual neurons, or small populations of neurons, in the motor cortices and can provide considerable information for controlling prostheses. Despite several compelling proof-of-concept laboratory animal experiments and an initial human clinical trial, at least three key challenges remain which, if left unaddressed, may hamper the translation of these systems into widespread clinical use. We review these challenges: achieving able-bodied levels of performance across tasks and across environments, achieving robustness across multiple decades, and restoring able-bodied quality proprioception and somatosensation. We also describe some emerging opportunities for meeting these challenges. If these challenges can be largely or fully met, intracortically based neural prostheses may achieve true clinical viability and help increasing numbers of disabled patients.","Prosthetics,
Electrodes,
Decoding,
Neurons,
Electric potential,
Materials,
Computers"
Reinforcement Learning With Function Approximation for Traffic Signal Control,"We propose, for the first time, a reinforcement learning (RL) algorithm with function approximation for traffic signal control. Our algorithm incorporates state-action features and is easily implementable in high-dimensional settings. Prior work, e.g., the work of Abdulhai , on the application of RL to traffic signal control requires full-state representations and cannot be implemented, even in moderate-sized road networks, because the computational complexity exponentially grows in the numbers of lanes and junctions. We tackle this problem of the curse of dimensionality by effectively using feature-based state representations that use a broad characterization of the level of congestion as low, medium, or high. One advantage of our algorithm is that, unlike prior work based on RL, it does not require precise information on queue lengths and elapsed times at each lane but instead works with the aforementioned described features. The number of features that our algorithm requires is linear to the number of signaled lanes, thereby leading to several orders of magnitude reduction in the computational complexity. We perform implementations of our algorithm on various settings and show performance comparisons with other algorithms in the literature, including the works of Abdulhai and Cools , as well as the fixed-timing and the longest queue algorithms. For comparison, we also develop an RL algorithm that uses full-state representation and incorporates prioritization of traffic, unlike the work of Abdulhai We observe that our algorithm outperforms all the other algorithms on all the road network settings that we consider.",
Direct and Indirect Couplings in Coherent Feedback Control of Linear Quantum Systems,"The purpose of this paper is to study and design direct and indirect couplings for use in coherent feedback control of a class of linear quantum stochastic systems. A general physical model for a nominal linear quantum system coupled directly and indirectly to external systems is presented. Fundamental properties of stability, dissipation, passivity, and gain for this class of linear quantum models are presented and characterized using complex Lyapunov equations and linear matrix inequalities (LMIs). Coherent H∞ and LQG synthesis methods are extended to accommodate direct couplings using multistep optimization. Examples are given to illustrate the results.","Couplings,
Mathematical model,
Equations,
Oscillators,
Feedback control,
Stability analysis,
Quantum mechanics"
A Multidimensional Critical State Analysis for Detecting Intrusions in SCADA Systems,"A relatively new trend in Critical Infrastructures (e.g., power plants, nuclear plants, energy grids, etc.) is the massive migration from the classic model of isolated systems, to a system-of-systems model, where these infrastructures are intensifying their interconnections through Information and Communications Technology (ICT) means. The ICT core of these industrial installations is known as Supervisory Control And Data Acquisition Systems (SCADA). Traditional ICT security countermeasures (e.g., classic firewalls, anti-viruses and IDSs) fail in providing a complete protection to these systems since their needs are different from those of traditional ICT. This paper presents an innovative approach to Intrusion Detection in SCADA systems based on the concept of Critical State Analysis and State Proximity. The theoretical framework is supported by tests conducted with an Intrusion Detection System prototype implementing the proposed detection approach.","Temperature sensors,
SCADA systems,
Monitoring,
Turbines,
Accuracy,
Measurement,
Intrusion detection"
Integral Resonant Control for Vibration Damping and Precise Tip-Positioning of a Single-Link Flexible Manipulator,"In this paper, we propose a control design method for single-link flexible manipulators. The proposed technique is based on the integral resonant control (IRC) scheme. The controller consists of two nested feedback loops. The inner loop controls the joint angle and makes the system robust to joint friction. The outer loop, which is based on the IRC technique, damps the vibration and makes the system robust to the unmodeled dynamics (spill-over) and resonance frequency variations due to changes in the payload. The objectives of this work are: 1) to demonstrate the advantages of IRC, which is a high-performance controller design methodology for flexible structures with collocated actuator-sensor pairs and 2) to illustrate its capability of achieving precise end-point (tip) positioning with effective vibration suppression when applied to a typical flexible manipulator. The theoretical formulation of the proposed control scheme, a detailed stability analysis and experimental results obtained on a flexible manipulator are presented.",
Ferroelectric negative capacitance MOSFET: Capacitance tuning & antiferroelectric operation,"A design methodology of ferroelectric (FE) negative capacitance FETs (NCFETs) based on the concept of capacitance matching is presented. A new mode of NCFET operation, called the “antiferroelectric mode” is proposed, which, besides achieving sub-60mV/dec subthreshold swing, can significantly boost the on-current in exchange for a nominal hysteresis. Design considerations for different device parameters (FE thickness, EOT, source/drain overlap & gate length) are explored. It is suggested that relative improvement in device performance due to FE negative capacitance becomes more significant in very short channel length devices because of the increased drain-to-channel coupling.","Hysteresis,
Capacitance,
Iron,
CMOS integrated circuits,
MOSFET circuits,
Performance evaluation,
Logic gates"
"Maximizing Sum Rate and Minimizing MSE on Multiuser Downlink: Optimality, Fast Algorithms and Equivalence via Max-min SINR","Maximizing the minimum weighted signal-to-interference-and-noise ratio (SINR), minimizing the weighted sum mean-square error (MSE) and maximizing the weighted sum rate in a multiuser downlink system are three important performance objectives in nonconvex joint transceiver and power optimization, where all the users have a total power constraint. We show that, through connections with the nonlinear Perron-Frobenius theory, jointly optimizing power and beamformers in the max-min weighted SINR problem can be solved optimally in a distributed fashion. Then, connecting these three performance objectives through the arithmetic-geometric mean inequality and nonnegative matrix theory, we solve the weighted sum MSE minimization and the weighted sum rate maximization in the weak interference regimes using fast algorithms. In the general case, we first establish optimality conditions to the weighted sum MSE minimization and the weighted sum rate maximization problems and provide their further connection to the max-min weighted SINR problem. We then propose a distributed weighted proportional SINR algorithm that leverages our fast max-min weighted SINR algorithm to solve for local optimal solution of the two nonconvex problems, and give conditions under which global optimality is achieved. Numerical results are provided to complement the analysis.","Signal processing algorithms,
Interference,
Optimization,
Signal to noise ratio,
Mean square error methods,
Downlink"
Error-Correcting Codes in Projective Space,"The projective space of order n over the finite field \BBFq, denoted here as Pq(n), is the set of all subspaces of the vector space \BBFqn . The projective space can be endowed with the distance function d(U, V) = dimU + dimV -2 dim(U ∩ V) which turns Pq(n) into a metric space. With this, an (n,M,d) code \BBC in projective space is a subset of Pq(n) of size M such that the distance between any two codewords (subspaces) is at least d . Koetter and Kschischang recently showed that codes in projective space are precisely what is needed for error-correction in networks: an (n,M,d) code can correct t packet errors and ρ packet erasures introduced (adversarially) anywhere in the network as long as 2t + 2ρ <; d. This motivates our interest in such codes. In this paper, we investigate certain basic aspects of “coding theory in projective space.” First, we present several new bounds on the size of codes in Pq(n), which may be thought of as counterparts of the classical bounds in coding theory due to Johnson, Delsarte, and Gilbert-Varshamov. Some of these are stronger than all the previously known bounds, at least for certain code parameters. We also present several specific constructions of codes and code families in Pq(n). Finally, we prove that nontrivial perfect codes in Pq(n) do not exist.","Extraterrestrial measurements,
Upper bound,
Error correction codes,
Vectors,
Geometry"
Towards a New Quality Metric for 3-D Synthesized View Assessment,"3DTV technology has brought out new challenges such as the question of synthesized views evaluation. Synthesized views are generated through a depth image-based rendering (DIBR) process. This process induces new types of artifacts whose impact on visual quality has to be identified considering various contexts of use. While visual quality assessment has been the subject of many studies in the last 20 years, there are still some unanswered questions regarding new technological improvement. DIBR is bringing new challenges mainly because it deals with geometric distortions. This paper considers the DIBR-based synthesized view evaluation problem. Different experiments have been carried out. They question the protocols of subjective assessment and the reliability of the objective quality metrics in the context of 3DTV, in these specific conditions (DIBR-based synthesized views), and they consist in assessing seven different view synthesis algorithms through subjective and objective measurements. Results show that usual metrics are not sufficient for assessing 3-D synthesized views, since they do not correctly render human judgment. Synthesized views contain specific artifacts located around the disoccluded areas, but usual metrics seem to be unable to express the degree of annoyance perceived in the whole image. This study provides hints for a new objective measure. Two approaches are proposed: the first one is based on the analysis of the shifts of the contours of the synthesized view; the second one is based on the computation of a mean SSIM score of the disoccluded areas.","Cameras,
Measurement,
Context,
Extrapolation,
Protocols,
Reliability,
Stereo image processing"
Securing Dynamic Distributed Storage Systems Against Eavesdropping and Adversarial Attacks,"We address the problem of securing distributed storage systems against eavesdropping and adversarial attacks. An important aspect of these systems is node failures over time, necessitating, thus, a repair mechanism in order to maintain a desired high system reliability. In such dynamic settings, an important security problem is to safeguard the system from an intruder who may come at different time instances during the lifetime of the storage system to observe and possibly alter the data stored on some nodes. In this scenario, we give upper bounds on the maximum amount of information that can be stored safely on the system. For an important operating regime of the distributed storage system, which we call the bandwidth-limited regime, we show that our upper bounds are tight and provide explicit code constructions. Moreover, we provide a way to short list the malicious nodes and expurgate the system.",
Accuracy of RSS-Based Centroid Localization Algorithms in an Indoor Environment,"In this paper, we analyze the accuracy of indoor localization measurement based on a wireless sensor network. The position estimation procedure is based on the received-signal-strength measurements collected in a real indoor environment. Two different classes of low-computational-effort algorithms based on the centroid concept are considered, i.e., the weighted centroid localization method and the relative-span exponential weighted localization method. In particular, different sources of measurement uncertainty are analyzed by means of theoretical simulations and experimental results.",
A Unified Approach for Developing Software Reliability Growth Models in the Presence of Imperfect Debugging and Error Generation,"In this paper, we propose two general frameworks for deriving several software reliability growth models based on a non-homogeneous Poisson process (NHPP) in the presence of imperfect debugging and error generation. The proposed models are initially formulated for the case when there is no differentiation between failure observation and fault removal testing processes, and then extended for the case when there is a clear differentiation between failure observation and fault removal testing processes. During the last three decades, many software reliability growth models (SRGM) have been developed to describe software failures as a random process, and can be used to evaluate development status during testing. With SRGM, software engineers can easily measure (or forecast) the software reliability (or quality), and plot software reliability growth charts. It is not easy to select the best model from a plethora of models available. There are few SRGM in the literature of software engineering that differentiates between failure observation and fault removal processes. In real software development environments, the number of failures observed need not be the same as the number of faults removed. Due to the complexity of software systems, and an incomplete understanding of software, the testing team may not be able to remove the fault perfectly on observation of a failure, and the original fault may remain, resulting in a phenomenon known as imperfect debugging, or get replaced by another fault causing error generation. In the case of imperfect debugging, the fault content of the software remains the same; while in the case of error generation, the fault content increases as the testing progresses. Removal of observed faults may result in the introduction of new faults.","Debugging,
Testing,
Software,
Software reliability,
Fault detection,
Mathematical model,
Modeling"
Solutions for the MIMO Gaussian Wiretap Channel With a Cooperative Jammer,"We study the Gaussian MIMO wiretap channel with a transmitter, a legitimate receiver, an eavesdropper and an external helper, each equipped with multiple antennas. The transmitter sends confidential messages to its intended receiver, while the helper transmits jamming signals independent of the source message to confuse the eavesdropper. The jamming signal is assumed to be treated as noise at both the intended receiver and the eavesdropper. We obtain a closed-form expression for the structure of the artificial noise covariance matrix that guarantees a secrecy rate larger or at least equal to the secrecy capacity of the wiretap channel with no jamming signal. We also describe how to find specific realizations of this covariance matrix expression that provide good secrecy rate performance, even when there is no nontrivial null space between the helper and the intended receiver. Unlike prior work, our approach considers the general MIMO case, and is not restricted to SISO or MISO scenarios.","Jamming,
Receivers,
Transmitters,
Covariance matrix,
MIMO,
Noise,
Mutual information"
Sensorless Drives in Industrial Applications,"The changes in the market of motor drives over the last few years, especially the wish to complete the portfolio toward the satisfaction of most of the customer needs, have brought a new thrust in the area of drives and have favored the realization of procedures that were known from academic discussion. Under certain conditions, the injection sensorless control schemes that exploit the anisotropy of the AC machine and inject a test signal are now found in drives with permanent magnet synchronous machine, while the fundamental wave procedures seem to be the most common solution in the case of induction machines. In this paper, different aspects regarding the state of the art of sensorless drives in industrial applications and the reasons that determine the acceptance or refusal of the different solutions on the side of manufacturers of motor drives are explained and discussed.",
A Framework for Automatic Human Emotion Classification Using Emotion Profiles,"Automatic recognition of emotion is becoming an increasingly important component in the design process for affect-sensitive human-machine interaction (HMI) systems. Well-designed emotion recognition systems have the potential to augment HMI systems by providing additional user state details and by informing the design of emotionally relevant and emotionally targeted synthetic behavior. This paper describes an emotion classification paradigm, based on emotion profiles (EPs). This paradigm is an approach to interpret the emotional content of naturalistic human expression by providing multiple probabilistic class labels, rather than a single hard label. EPs provide an assessment of the emotion content of an utterance in terms of a set of simple categorical emotions: anger; happiness; neutrality; and sadness. This method can accurately capture the general emotional label (attaining an accuracy of 68.2% in our experiment on the IEMOCAP data) in addition to identifying underlying emotional properties of highly emotionally ambiguous utterances. This capability is beneficial when dealing with naturalistic human emotional expressions, which are often not well described by a single semantic label.","Feature extraction,
Humans,
Accuracy,
Support vector machines,
Databases,
Eyebrows,
Hidden Markov models"
THz Dynamic Nuclear Polarization NMR,"Dynamic nuclear polarization (DNP) increases the sensitivity of nuclear magnetic resonance (NMR) spectroscopy by using high frequency microwaves to transfer the polarization of the electrons to the nuclear spins. The enhancement in NMR sensitivity can amount to a factor of well above 100, enabling faster data acquisition and greatly improved NMR measurements. With the increasing magnetic fields (up to 23 T) used in NMR research, the required frequency for DNP falls into the THz band (140- 600 GHz ). Gyrotrons have been developed to meet the demanding specifications for DNP NMR, including power levels of tens of watts; frequency stability of a few megahertz; and power stability of 1% over runs that last for several days to weeks. Continuous gyrotron frequency tuning of over 1 GHz has also been demonstrated. The complete DNP NMR system must include a low loss transmission line; an optimized antenna; and a holder for efficient coupling of the THz radiation to the sample. This paper describes the DNP NMR process and illustrates the THz systems needed for this demanding spectroscopic application. THz DNP NMR is a rapidly developing, exciting area of THz science and technology.","Nuclear magnetic resonance,
Proteins,
Gyrotrons,
Solids,
Sensitivity,
Polarization,
Couplings"
Neutron- and Proton-Induced Single Event Upsets for D- and DICE-Flip/Flop Designs at a 40 nm Technology Node,Neutron- and proton-induced single-event upset cross sections of D- and DICE-Flip/Flops are analyzed for designs implemented in a 40 nm bulk technology node. Neutron and proton testing of the flip/flops show only a 30%-50% difference between D- and DICE-Flip/Flop error rates and cross sections. Simulations are used to show that charge sharing is the primary cause for the similar failures-in-time (FIT) rates. Such small improvement in the single-event performance of the DICE implementation over standard D-Flip/Flop designs may warrant careful consideration for the use of DICE designs in 40 nm bulk technologies and beyond.,"Transistors,
Protons,
Neutrons,
Shift registers,
Particle beams,
Solid modeling,
Simulation"
On the Influence of the Number of Objectives on the Hardness of a Multiobjective Optimization Problem,"In this paper, we study the influence of the number of objectives of a continuous multiobjective optimization problem on its hardness for evolution strategies which is of particular interest for many-objective optimization problems. To be more precise, we measure the hardness in terms of the evolution (or convergence) of the population toward the set of interest, the Pareto set. Previous related studies consider mainly the number of nondominated individuals within a population which greatly improved the understanding of the problem and has led to possible remedies. However, in certain cases this ansatz is not sophisticated enough to understand all phenomena, and can even be misleading. In this paper, we suggest alternatively to consider the probability to improve the situation of the population which can, to a certain extent, be measured by the sizes of the descent cones. As an example, we make some qualitative considerations on a general class of uni-modal test problems and conjecture that these problems get harder by adding an objective, but that this difference is practically not significant, and we support this by some empirical studies. Further, we address the scalability in the number of objectives observed in the literature. That is, we try to extract the challenges for the treatment of many-objective problems for evolution strategies based on our observations and use them to explain recent advances in this field.",
Power Flow Stabilization and Control of Microgrid with Wind Generation by Superconducting Magnetic Energy Storage,"High penetration of renewable energy sources such as wind generation in microgrids (MGs) causes fluctuations of power flow and significantly affects the power system (PS) operation. This can lead to severe problems, such as system frequency oscillations, and/or violations of power lines capability. With the proper control, superconducting magnetic energy storage (SMES) is able to significantly enhance the dynamic security of the PS. In an SMES system, the power conditioning system (PCS) is the crucial component that directly influences the validity of the SMES in the dynamic control of the PS. This paper proposes the use of an improved SMES controller for the stabilization and control of the power flow of wind-hybrid MGs. In this sense, the design and implementation of a novel high-performance PCS scheme of the SMES is described. Moreover, a detailed model of the SMES unit is derived and a novel three-level control scheme is designed, comprising a full decoupled current control strategy in the d -q reference frame and an enhanced PS frequency controller. The dynamic performance of the proposed systems is fully validated by computer simulation.","Power system dynamics,
Power conditioning,
Reactive power,
Load flow,
Inverters"
Adaptive algorithms for detecting community structure in dynamic social networks,"Social networks exhibit a very special property: community structure. Understanding the network community structure is of great advantages. It not only provides helpful information in developing more social-aware strategies for social network problems but also promises a wide range of applications enabled by mobile networking, such as routings in Mobile Ad Hoc Networks (MANETs) and worm containments in cellular networks. Unfortunately, understanding this structure is very challenging, especially in dynamic social networks where social activities and interactions are evolving rapidly. Can we quickly and efficiently identify the network community structure? Can we adaptively update the network structure based on previously known information instead of recomputing from scratch? In this paper, we present Quick Community Adaptation (QCA), an adaptive modularity-based method for identifying and tracing community structure of dynamic online social networks. Our approach has not only the power of quickly and efficiently updating network communities, through a series of changes, by only using the structures identified from previous network snapshots, but also the ability of tracing the evolution of community structure over time. To illustrate the effectiveness of our algorithm, we extensively test QCA on real-world dynamic social networks including ENRON email network, arXiv e-print citation network and Facebook network. Finally, we demonstrate the bright applicability of our algorithm via a realistic application on routing strategies in MANETs. The comparative results reveal that social-aware routing strategies employing QCA as a community detection core outperform current available methods.",
Empirical Studies of Pair Programming for CS/SE Teaching in Higher Education: A Systematic Literature Review,"The objective of this paper is to present the current evidence relative to the effectiveness of pair programming (PP) as a pedagogical tool in higher education CS/SE courses. We performed a systematic literature review (SLR) of empirical studies that investigated factors affecting the effectiveness of PP for CS/SE students and studies that measured the effectiveness of PP for CS/SE students. Seventy-four papers were used in our synthesis of evidence, and 14 compatibility factors that can potentially affect PP's effectiveness as a pedagogical tool were identified. Results showed that students' skill level was the factor that affected PP's effectiveness the most. The most common measure used to gauge PP's effectiveness was time spent on programming. In addition, students' satisfaction when using PP was overall higher than when working solo. Our meta-analyses showed that PP was effective in improving students' grades on assignments. Finally, in the studies that used quality as a measure of effectiveness, the number of test cases succeeded, academic performance, and expert opinion were the quality measures mostly applied. The results of this SLR show two clear gaps in this research field: 1) a lack of studies focusing on pair compatibility factors aimed at making PP an effective pedagogical tool and 2) a lack of studies investigating PP for software design/modeling tasks in conjunction with programming tasks.","Programming profession,
Education,
Educational programs,
Computer science,
Performance evaluation,
Time measurement,
Testing,
Software design,
Collaborative work,
Algorithm design and analysis"
Multimodal templates for real-time detection of texture-less objects in heavily cluttered scenes,"We present a method for detecting 3D objects using multi-modalities. While it is generic, we demonstrate it on the combination of an image and a dense depth map which give complementary object information. It works in real-time, under heavy clutter, does not require a time consuming training stage, and can handle untextured objects. It is based on an efficient representation of templates that capture the different modalities, and we show in many experiments on commodity hardware that our approach significantly outperforms state-of-the-art methods on single modalities.",Robustness
A Novel Contour Error Estimation for Position Loop-Based Cross-Coupled Control,"Reduction of contour error is the main control objective in contour-following applications. A common approach to this objective is to design a controller based on the contour error directly. In this case, the contour error estimation is a key factor in the contour-following operation. Contour error can be approximated by the linear distance from the actual position to the tangent line or plane at the desired position. This approach suffers from a significant error due to linear approximation. A novel approach to contour error calculation of an arbitrary smooth path is proposed in this paper. The proposed method is based on coordinate transformation and circular approximation. In this method, the contour error is represented by the coordinate of the actual position with respect to a specific virtual coordinate frame. The method is incorporated in a position loop-based cross-coupled control structure. An equivalent robust control system is used to establish stability of the closed-loop system. Experimental results demonstrate the efficiency and performance of the proposed contour error estimation algorithm and the motion control strategy.","Error analysis,
Error correction,
Computer errors,
Linear approximation,
Robust control,
Motion control,
Application software,
Mechatronics,
Robust stability,
Stability analysis"
Blind Spectral Unmixing Based on Sparse Nonnegative Matrix Factorization,"Nonnegative matrix factorization (NMF) is a widely used method for blind spectral unmixing (SU), which aims at obtaining the endmembers and corresponding fractional abundances, knowing only the collected mixing spectral data. It is noted that the abundance may be sparse (i.e., the endmembers may be with sparse distributions) and sparse NMF tends to lead to a unique result, so it is intuitive and meaningful to constrain NMF with sparseness for solving SU. However, due to the abundance sum-to-one constraint in SU, the traditional sparseness measured by L0/L1-norm is not an effective constraint any more. A novel measure (termed as S-measure) of sparseness using higher order norms of the signal vector is proposed in this paper. It features the physical significance. By using the S-measure constraint (SMC), a gradient-based sparse NMF algorithm (termed as NMF-SMC) is proposed for solving the SU problem, where the learning rate is adaptively selected, and the endmembers and abundances are simultaneously estimated. In the proposed NMF-SMC, there is no pure index assumption and no need to know the exact sparseness degree of the abundance in prior. Yet, it does not require the preprocessing of dimension reduction in which some useful information may be lost. Experiments based on synthetic mixtures and real-world images collected by AVIRIS and HYDICE sensors are performed to evaluate the validity of the proposed method.",
Multirobot Active Target Tracking With Combinations of Relative Observations,"In this paper, we study the problem of optimal trajectory generation for a team of heterogeneous robots moving in a plane and tracking a moving target by processing relative observations, i.e., distance and/or bearing. Contrary to previous approaches, we explicitly consider limits on the robots' speed and impose constraints on the minimum distance at which the robots are allowed to approach the target. We first address the case of a single tracking sensor and seek the next sensing location in order to minimize the uncertainty about the target's position. We show that although the corresponding optimization problem involves a nonconvex objective function and a nonconvex constraint, its global optimal solution can be determined analytically. We then extend the approach to the case of multiple sensors and propose an iterative algorithm, i.e., the Gauss-Seidel relaxation (GSR), to determine the next best sensing location for each sensor. Extensive simulation results demonstrate that the GSR algorithm, whose computational complexity is linear in the number of sensors, achieves higher tracking accuracy than gradient descent methods and has performance that is indistinguishable from that of a grid-based exhaustive search, whose cost is exponential in the number of sensors. Finally, through experiments, we demonstrate that the proposed GSR algorithm is robust and applicable to real systems.","Robot sensing systems,
Target tracking,
Mathematical model,
Covariance matrix,
Time measurement,
Equations"
CloudStream: Delivering high-quality streaming videos through a cloud-based SVC proxy,"Existing media providers such as YouTube and Hulu deliver videos by turning it into a progressive download. This can result in frequent video freezes under varying network dynamics. In this paper, we present CloudStream: a cloud-based video proxy that can deliver high-quality streaming videos by transcoding the original video in real time to a scalable codec which allows streaming adaptation to network dynamics. The key is a multi-level transcoding parallelization framework with two mapping options (Hallsh-based Mapping and Lateness-first Mapping) that optimize transcoding speed and reduce the transcoding jitters while preserving the encoded video quality. We evaluate the performance of CloudStream on our campus cloud testbed.",
A User-Oriented Image Retrieval System Based on Interactive Genetic Algorithm,"Digital image libraries and other multimedia databases have been dramatically expanded in recent years. In order to effectively and precisely retrieve the desired images from a large image database, the development of a content-based image retrieval (CBIR) system has become an important research issue. However, most of the proposed approaches emphasize on finding the best representation for different image features. Furthermore, very few of the representative works well consider the user's subjectivity and preferences in the retrieval process. In this paper, a user-oriented mechanism for CBIR method based on an interactive genetic algorithm (IGA) is proposed. Color attributes like the mean value, the standard deviation, and the image bitmap of a color image are used as the features for retrieval. In addition, the entropy based on the gray level co-occurrence matrix and the edge histogram of an image are also considered as the texture features. Furthermore, to reduce the gap between the retrieval results and the users' expectation, the IGA is employed to help the users identify the images that are most satisfied to the users' need. Experimental results and comparisons demonstrate the feasibility of the proposed approach.","Image color analysis,
Image retrieval,
Image edge detection,
Humans,
Semantics,
Biological cells,
Pixel"
A Probabilistic Analysis of Link Duration in Vehicular Ad Hoc Networks,"The past decade has witnessed a phenomenal market penetration of wireless communications and a steady increase in the number of mobile users. Unlike wired networks, where communication links are inherently stable, in wireless networks, the lifetime of a link is a random variable whose probability distribution depends on mobility, transmission range, and various impairments of radio communications. Because of the very dynamic nature of Vehicular Ad hoc NETworks (VANETs) and the short transmission range mandated by the Federal Communications Commission (FCC), individual communication links come into existence and vanish unpredictably, making the task of establishing and maintaining routing paths between fast-moving vehicles very challenging. The main contribution of this work is to investigate the probability distribution of the lifetime of individual links in a VANET under the combined assumptions of a realistic radio transmission model and a realistic probability distribution model of intervehicle headway distance. Our analytical results were validated and confirmed by extensive simulation.","Wireless communication,
Probability distribution,
Ad hoc networks,
Log-normal distribution,
Random variables,
Analytical models"
Spatially Regularized Compressed Sensing for High Angular Resolution Diffusion Imaging,"Despite the relative recency of its inception, the theory of compressive sampling (aka compressed sensing) (CS) has already revolutionized multiple areas of applied sciences, a particularly important instance of which is medical imaging. Specifically, the theory has provided a different perspective on the important problem of optimal sampling in magnetic resonance imaging (MRI), with an ever-increasing body of works reporting stable and accurate reconstruction of MRI scans from the number of spectral measurements which would have been deemed unacceptably small as recently as five years ago. In this paper, the theory of CS is employed to palliate the problem of long acquisition times, which is known to be a major impediment to the clinical application of high angular resolution diffusion imaging (HARDI). Specifically, we demonstrate that a substantial reduction in data acquisition times is possible through minimization of the number of diffusion encoding gradients required for reliable reconstruction of HARDI scans. The success of such a minimization is primarily due to the availability of spherical ridgelet transformation, which excels in sparsifying HARDI signals. What makes the resulting reconstruction procedure even more accurate is a combination of the sparsity constraints in the diffusion domain with additional constraints imposed on the estimated diffusion field in the spatial domain. Accordingly, the present paper describes an original way to combine the diffusion- and spatial-domain constraints to achieve a maximal reduction in the number of diffusion measurements, while sacrificing little in terms of reconstruction accuracy. Finally, details are provided on an efficient numerical scheme which can be used to solve the aforementioned reconstruction problem by means of standard and readily available estimation tools. The paper is concluded with experimental results which support the practical value of the proposed reconstruction methodology.",
Discrimination of multiple PD sources using wavelet decomposition and principal component analysis,"Partial discharge (PD) signals generated within electrical power equipment can be used to assess the condition of the insulation. In practice, testing often results in multiple PD sources. In order to assess the impact of individual PD sources, signals must first be discriminated from one another. This paper presents a procedure for the identification of PD signals generated by multiple sources. Starting with the assumption that different PD sources will display unique signal profiles this will be manifested in the distribution of energies with respect to frequency and time. Therefore the technique presented is based on the comparison of signal energies associated with particular wavelet-decomposition levels. Principal component analysis is adopted to reduce the dimensionality of the data, whilst minimizing lost information in the data concentration step. Physical parameters are extracted from individual PD pulses and projected into 3-dimensional space to allow clustering of data from specific PD sources. The density-based spatial clustering of applications with noise (DBSCAN) clustering algorithm is chosen for its ability to discover clusters of arbitrary shape in n-dimension space. PD data from individual clusters can then be further analyzed by projecting the clustered data with respect to the original phase relationship. Results and analysis of the technique are compared for experimentally measured PD data from a range of sources commonly found in three different types of high voltage (HV) equipment; ac synchronous generators, induction motors and distribution cables. These experiments collect data using varied test arrangements including sensors with different bandwidths to demonstrate the robustness and indicate the potential for wide applicability of the technique to PD analysis for a range of insulation systems.",
Palm NMR and 1-Chip NMR,"In our earlier work, we developed a 2-kg NMR system, which was 60 X lighter, 40× smaller, yet 60× more spin-mass sensitive than a 120-kg state-of-the-art commercial benchtop system. Here we report on two new nuclear magnetic resonance (NMR) systems that represent further orders-of-magnitude size reduction and lab-on-a-chip capability. The first system, which weighs 0.1 kg and can be held in the palm of a hand, is the smallest NMR system ever built, and is 1200× lighter, 1200× smaller, yet 150× more spin-mass sensitive than the commercial system. It is enabled by combining the physics of NMR with a CMOS RF transceiver. The second system, which even integrates a sample coil, directly interfaces the CMOS chip with a sample for lab-on-a-chip operation. The two systems detect biological objects such as avidin, human chorionic gonadotropin, and human bladder cancer cells.","Nuclear magnetic resonance,
Coils,
Transceivers,
Magnetic separation,
Radio frequency,
CMOS integrated circuits"
Distributed and Decentralized Multicamera Tracking,"We discussed emerging multicamera tracking algorithms that find their roots in signal processing, wireless sensor networks, and computer vision. Based on how cameras share estimates and fuse information, we classified these trackers as distributed, decentralized, and centralized algorithms. We also highlighted the challenges to be addressed in the design of decentralized and distributed tracking algorithms. In particular, we showed how the constraints derived from the topology of the networks and the nature of the task have favored so far decentralized architectures with multiple local fusion centers. Because of the availability of fewer fusion centers compared to distributed algorithms, decentralized algorithms can share larger amounts of data (e.g., occupancy maps) and can back-project estimates among views and fusion centers to validate results. Distributed tracking uses algorithms that can operate with smaller amounts of data at any particular node and obtain state estimates through iterative fusion. Despite recent advances, there are important issues to be addressed to achieve efficient multitarget multicamera tracking. Current algorithms either assume the track-to-measurement association information to be available for the tracker or operate on a small (known) number of targets. Algorithms performing track-to-measurement association for a time-varying number of targets with higher accuracy usually incur much higher costs, whose reduction is an important open problem to be addressed in multicamera networks.","Cameras,
Target tracking,
Feature extraction,
State estimation,
Signal processing algorithms,
Hidden Markov models,
Trajectory"
Directing Crowd Simulations Using Navigation Fields,"We present a novel approach to direct and control virtual crowds using navigation fields. Our method guides one or more agents toward desired goals based on guidance fields. The system allows the user to specify these fields by either sketching paths directly in the scene via an intuitive authoring interface or by importing motion flow fields extracted from crowd video footage. We propose a novel formulation to blend input guidance fields to create singularity-free, goal-directed navigation fields. Our method can be easily combined with the most current local collision avoidance methods and we use two such methods as examples to highlight the potential of our approach. We illustrate its performance on several simulation scenarios.","Navigation,
Computational modeling,
Collision avoidance,
Animation,
Decision making,
Computer science,
Layout,
Virtual reality,
Artificial intelligence,
Computer simulation"
On the degrees of freedom of X channel with delayed CSIT,"We consider the X channel and the 3-user X network with independent and identically distributed fading across antennas and channel uses and with the delayed channel state information at the transmitters (CSIT). We provide new results for degrees of freedom of these channels. Specifically, we show that the single antenna X channel with delayed CSIT can achieve 6/5 degrees of freedom while the 3-user X network can achieve 5/4 degrees of freedom.","Receivers,
Transmitters,
Equations,
MIMO,
Interference,
Antenna theory"
AlGaN/GaN High-Electron-Mobility Transistors Fabricated Through a Au-Free Technology,"This letter reports undoped AlGaN/GaN high-electron-mobility transistors (HEMTs) fabricated with a Si-CMOS-compatible technology based on Ti/Al/W ohmic and Schottky contacts. The use of ohmic recess is key to reduce the contact resistance of this Au-free metallization below 0.5 Ω·mm. Comparison of HEMTs fabricated on the same wafer with and without ohmic recess shows that the recess provides a tenfold reduction in contact resistance, resulting in a fivefold lower forward voltage drop at IDS = 100 mA/mm. The reported Au-free AlGaN/GaN HEMT fabrication technology provides similar performance (i.e., contact resistance, leakage current, and breakdown voltage) than state-of-the-art Au-based AlGaN/GaN HEMTs and can be used in standard Si fabs without the risk of contamination.","Gallium nitride,
HEMTs,
Aluminum gallium nitride,
MODFETs,
Gold,
Ohmic contacts,
Metallization"
A Real-Time Vision System for Nighttime Vehicle Detection and Traffic Surveillance,"This paper presents an effective traffic surveillance system for detecting and tracking moving vehicles in nighttime traffic scenes. The proposed method identifies vehicles by detecting and locating vehicle headlights and taillights using image segmentation and pattern analysis techniques. First, a fast bright-object segmentation process based on automatic multilevel histogram thresholding is applied to effectively extract bright objects of interest. This automatic multilevel thresholding approach provides a robust and adaptable detection system that operates well under various nighttime illumination conditions. The extracted bright objects are then processed by a spatial clustering and tracking procedure that locates and analyzes the spatial and temporal features of vehicle light patterns, and identifies and classifies moving cars and motorbikes in traffic scenes. The proposed real-time vision system has also been implemented and evaluated on a TI DM642 DSP-based embedded platform. The system is set up on elevated platforms to perform traffic surveillance on real highways and urban roads. Experimental results demonstrate that the proposed traffic surveillance approach is feasible and effective for vehicle detection and identification in various nighttime environments.","Real time systems,
Machine vision,
Vehicle detection,
Surveillance,
Forward error correction,
Digital video broadcasting,
Mobile TV,
Robustness,
Fading,
Encoding"
A Decentralized Approach for Anticipatory Vehicle Routing Using Delegate Multiagent Systems,"Advanced vehicle guidance systems use real-time traffic information to route traffic and to avoid congestion. Unfortunately, these systems can only react upon the presence of traffic jams and not to prevent the creation of unnecessary congestion. Anticipatory vehicle routing is promising in that respect, because this approach allows directing vehicle routing by accounting for traffic forecast information. This paper presents a decentralized approach for anticipatory vehicle routing that is particularly useful in large-scale dynamic environments. The approach is based on delegate multiagent systems, i.e., an environment-centric coordination mechanism that is, in part, inspired by ant behavior. Antlike agents explore the environment on behalf of vehicles and detect a congestion forecast, allowing vehicles to reroute. The approach is explained in depth and is evaluated by comparison with three alternative routing strategies. The experiments are done in simulation of a real-world traffic environment. The experiments indicate a considerable performance gain compared with the most advanced strategy under test, i.e., a traffic-message-channel-based routing strategy.",
Variation-tolerant ultra low-power heterojunction tunnel FET SRAM design,"Steep sub-threshold Interband Tunnel FETs (TFETs) are promising candidates for low supply voltage applications with higher switching performance than traditional CMOS. Unlike CMOS, TFETs exhibit uni-directional conduction due to their asymmetric source-drain architecture, and delayed output saturation characteristics. These unconventional characteristics of TFETs pose a challenge for providing good read/write noise margin characteristics in TFET SRAMs. We provide an analysis of 8T and 10T TFET SRAM cells, including Schmitt-Trigger (ST) based cells, to address these shortcomings. By benchmarking a variety of TFET-based SRAM cells, we show the utility of the Schmitt-Trigger feedback mechanism in improving the read/write noise margins, thus enabling ultra low-VCC operation for TFET SRAMs. We also propose a variation model for studying the impact of device-level variation on TFET SRAM cells. We show that the TFET ST SRAM cell has sufficient variation tolerance to operate at low-VCC, and is a very promising cell to achieve a VCC-min of 124mV. The TFET ST cell operating at its VCC-min provides a 1.2x reduction in dynamic energy and 13x reduction in leakage power compared to the best CMOS-based SRAM implementation operating at it's VCC-min, while giving better performance at the same time.",
Saliency and Gist Features for Target Detection in Satellite Images,"Reliably detecting objects in broad-area overhead or satellite images has become an increasingly pressing need, as the capabilities for image acquisition are growing rapidly. The problem is particularly difficult in the presence of large intraclass variability, e.g., finding “boats” or “buildings,” where model-based approaches tend to fail because no good model or template can be defined for the highly variable targets. This paper explores an automatic approach to detect and classify targets in high-resolution broad-area satellite images, which relies on detecting statistical signatures of targets, in terms of a set of biologically-inspired low-level visual features. Broad-area images are cut into small image chips, analyzed in two complementary ways: “attention/saliency” analysis exploits local features and their interactions across space, while “gist” analysis focuses on global nonspatial features and their statistics. Both feature sets are used to classify each chip as containing target(s) or not, using a support vector machine. Four experiments were performed to find “boats” (Experiments 1 and 2), “buildings” (Experiment 3) and “airplanes” (Experiment 4). In experiment 1, 14 416 image chips were randomly divided into training (300 boat, 300 nonboat) and test sets (13 816), and classification was performed on the test set (ROC area: 0.977 ±0.003). In experiment 2, classification was performed on another test set of 11 385 chips from another broad-area image, keeping the same training set as in experiment 1 (ROC area: 0.952 ±0.006). In experiment 3, 600 training chips (300 for each type) were randomly selected from 108 885 chips, and classification was conducted (ROC area: 0.922 ±0.005). In experiment 4, 20 training chips (10 for each type) were randomly selected to classify the remaining 2581 chips (ROC area: 0.976 ±0.003). The proposed algorithm outperformed the state-of-the-art SIFT, HMAX, and hidden-scale salient structure methods, and previous gist-only features in all four experiments. This study shows that the proposed target search method can reliably and effectively detect highly variable target objects in large image datasets.","Feature extraction,
Satellites,
Visualization,
Object detection,
Humans,
Computational modeling,
Biological system modeling"
m-SNE: Multiview Stochastic Neighbor Embedding,"Dimension reduction has been widely used in real-world applications such as image retrieval and document classification. In many scenarios, different features (or multiview data) can be obtained, and how to duly utilize them is a challenge. It is not appropriate for the conventional concatenating strategy to arrange features of different views into a long vector. That is because each view has its specific statistical property and physical interpretation. Even worse, the performance of the concatenating strategy will deteriorate if some views are corrupted by noise. In this paper, we propose a multiview stochastic neighbor embedding (m-SNE) that systematically integrates heterogeneous features into a unified representation for subsequent processing based on a probabilistic framework. Compared with conventional strategies, our approach can automatically learn a combination coefficient for each view adapted to its contribution to the data embedding. This combination coefficient plays an important role in utilizing the complementary information in multiview data. Also, our algorithm for learning the combination coefficient converges at a rate of O(1/k2), which is the optimal rate for smooth problems. Experiments on synthetic and real data sets suggest the effectiveness and robustness of m-SNE for data visualization, image retrieval, object categorization, and scene recognition.","Probability distribution,
Optimization,
Image retrieval,
Image color analysis,
Noise,
Algorithm design and analysis,
Probabilistic logic"
Texture Classification Using Dominant Neighborhood Structure,"This paper proposes a new approach to extract global image features for the purpose of texture classification. The proposed texture features are obtained by generating an estimated global map representing the measured intensity similarity between any given image pixel and its surrounding neighbors within a certain window. The intensity similarity map is an average representation of the texture-image dominant neighborhood similarity. The estimated dominant neighborhood similarity is robust to noise and referred to as image dominant neighborhood structure. The global rotation-invariant features are then extracted from the generated image dominant neighborhood structure. Features obtained from the local binary patterns (LBPs) are then extracted in order to supply additional local texture features to the generated features from the dominant neighborhood structure. Both features complement each other. The experimental results on representative texture databases show that the proposed method is robust to noise and can achieve significant improvement in terms of the obtained classification accuracy in comparison to the LBP method. In addition, the method classification accuracy is comparable to the two recent LBP extensions: dominant LBP and completed LBP.",
Distilled Sensing: Adaptive Sampling for Sparse Detection and Estimation,"Adaptive sampling results in significant improvements in the recovery of sparse signals in white Gaussian noise. A sequential adaptive sampling-and-refinement procedure called Distilled Sensing (DS) is proposed and analyzed. DS is a form of multistage experimental design and testing. Because of the adaptive nature of the data collection, DS can detect and localize far weaker signals than possible from non-adaptive measurements. In particular, reliable detection and localization (support estimation) using non-adaptive samples is possible only if the signal amplitudes grow logarithmically with the problem dimension. Here it is shown that using adaptive sampling, reliable detection is possible provided the amplitude exceeds a constant, and localization is possible when the amplitude exceeds any arbitrarily slowly growing function of the dimension.","Testing,
Sensors,
Reliability,
Extraterrestrial measurements,
Adaptation models,
Estimation,
Noise"
Toward a Minimal Representation of Affective Gestures,"This paper presents a framework for analysis of affective behavior starting with a reduced amount of visual information related to human upper-body movements. The main goal is to individuate a minimal representation of emotional displays based on nonverbal gesture features. The GEMEP (Geneva multimodal emotion portrayals) corpus was used to validate this framework. Twelve emotions expressed by 10 actors form the selected data set of emotion portrayals. Visual tracking of trajectories of head and hands were performed from a frontal and a lateral view. Postural/shape and dynamic expressive gesture features were identified and analyzed. A feature reduction procedure was carried out, resulting in a 4D model of emotion expression that effectively classified/grouped emotions according to their valence (positive, negative) and arousal (high, low). These results show that emotionally relevant information can be detected/measured/obtained from the dynamic qualities of gesture. The framework was implemented as software modules (plug-ins) extending the EyesWeb XMI Expressive Gesture Processing Library and is going to be used in user centric, networked media applications, including future mobiles, characterized by low computational resources, and limited sensor systems.","Feature extraction,
Trajectory,
Head,
Humans,
Visualization,
Emotion recognition,
Three dimensional displays"
A Novel Structure and Access Mechanism for Mobile Data Broadcast in Digital Ecosystems,"Digital ecosystems offer cost-effective digital services that attract and benefit the species within them (i.e., humans, organizations, and computers). As a cornerstone technology for digital information delivery, data broadcast provides a strong backbone for the digital ecosystem infrastructure. Its scalability feature is highly significant for various digital ecosystem applications, including mobile broadcast services. This paper proposes a novel structure and access for mobile data broadcast. The proposed scheme addresses the tradeoff for minimizing query-access and tuning times by specifying a new message structure. Correspondingly, a new access and processing mode for mobile clients is required. We study the effectiveness of the proposed approach in minimizing query-access time while maintaining low tuning time. The results of our experiments are used to make comparisons with existing approaches. The results affirm the effectiveness of our proposed scheme.",
"An Integrated Framework for Smart Microgrids Modeling, Monitoring, Control, Communication, and Verification","The microgrid (MG) paradigm is a new concept which is considered as a solution for addressing technical, economical, and environmental issues of modern power systems. The application of MG is the subject of extensive studies and experimental tests. It is recognized that there are a number of technical challenges concerning the operation, monitoring, control, and protection of MGs systems. In this respect, the rapid development of the information and communication technologies (ICTs) has opened the door for feasible and cost-effective solutions allowing more extensive intra- and interutility information exchange, diffusion, and open access to a wide range of real-time information. Consequently, the ICTs could represent a strategic tool in supporting effective MG operation. According to this statement, the paper proposes an advanced framework based on the service-oriented architectures for integrated MG modeling, monitoring, and control. The proposed framework is platform, language, and vendor independent, and thus it is an ideal candidate for an effective integration in existing energy management systems and distribution management systems (EMSs/DMSs).",
Encumbrance-free telepresence system with real-time 3D capture and display using commodity depth cameras,"This paper introduces a proof-of-concept telepresence system that offers fully dynamic, real-time 3D scene capture and continuous-viewpoint, head-tracked stereo 3D display without requiring the user to wear any tracking or viewing apparatus. We present a complete software and hardware framework for implementing the system, which is based on an array of commodity Microsoft Kinect™color-plus-depth cameras. Novel contributions include an algorithm for merging data between multiple depth cameras and techniques for automatic color calibration and preserving stereo quality even with low rendering rates. Also presented is a solution to the problem of interference that occurs between Kinect cameras with overlapping views. Emphasis is placed on a fully GPU-accelerated data processing and rendering pipeline that can apply hole filling, smoothing, data merger, surface generation, and color correction at rates of up to 100 million triangles/sec on a single PC and graphics board. Also presented is a Kinect-based marker-less tracking system that combines 2D eye recognition with depth information to allow head-tracked stereo views to be rendered for a parallax barrier autostereoscopic display. Our system is affordable and reproducible, offering the opportunity to easily deliver 3D telepresence beyond the researcher's lab.","Cameras,
Three dimensional displays,
Image color analysis,
Graphics processing unit,
Interference,
Rendering (computer graphics),
Smoothing methods"
Majority Voting: Material Classification by Tactile Sensing Using Surface Texture,"In this paper, we present an application of machine learning to distinguish between different materials based on their surface texture. Such a system can be used for the estimation of surface friction during manipulation tasks; quality assurance in the textile, cosmetics, and harvesting industries; and other applications requiring tactile sensing. Several machine learning algorithms, such as naive Bayes, decision trees, and naive Bayes trees, have been trained to distinguish textures sensed by a biologically inspired artificial finger. The finger has randomly distributed strain gauges and polyvinylidene fluoride (PVDF) films embedded in silicone. Different textures induce different intensities of vibrations in the silicone. Consequently, textures can be distinguished by the presence of different frequencies in the signal. The data from the finger are preprocessed, and the Fourier coefficients of the sensor outputs are used to train classifiers. We show that the classifiers generalize well for unseen datasets with performance exceeding previously reported algorithms. Our classifiers can distinguish between different materials, such as carpet, flooring vinyls, tiles, sponge, wood, and polyvinyl-chloride (PVC) woven mesh with an accuracy of on unseen test data.","Materials,
Strain,
Humans,
Tactile sensors"
Detection of Cognitive Injured Body Region Using Multiple Triaxial Accelerometers for Elderly Falling,"This paper aimed to use several triaxial acceleration sensor devices for joint sensing of injured body parts, when an accidental fall occurs. The model transmitted the information fed by the sensors distributed over various body parts to the computer through wireless transmission devices for further analysis and judgment, and employed cognitive adjustment method to adjust the acceleration range of various body parts in different movements. The model can determine the possible occurrence of fall accidents, when the acceleration significantly exceeds the usual acceleration range. In addition, after a fall accident occurs, the impact acceleration and normal (habitual) acceleration can be compared to determine the level of injury. This study also implemented a sensing system for analysis. The area of the body parts that may sustain greater impact force are marked red in this system, so that more information can be provided for medical personnel for more accurate judgment.",
A Fuzzy Expert System for Diabetes Decision Support Application,"An increasing number of decision support systems based on domain knowledge are adopted to diagnose medical conditions such as diabetes and heart disease. It is widely pointed that the classical ontologies cannot sufficiently handle imprecise and vague knowledge for some real world applications, but fuzzy ontology can effectively resolve data and knowledge problems with uncertainty. This paper presents a novel fuzzy expert system for diabetes decision support application. A five-layer fuzzy ontology, including a fuzzy knowledge layer, fuzzy group relation layer, fuzzy group domain layer, fuzzy personal relation layer, and fuzzy personal domain layer, is developed in the fuzzy expert system to describe knowledge with uncertainty. By applying the novel fuzzy ontology to the diabetes domain, the structure of the fuzzy diabetes ontology (FDO) is defined to model the diabetes knowledge. Additionally, a semantic decision support agent (SDSA), including a knowledge construction mechanism, fuzzy ontology generating mechanism, and semantic fuzzy decision making mechanism, is also developed. The knowledge construction mechanism constructs the fuzzy concepts and relations based on the structure of the FDO. The instances of the FDO are generated by the fuzzy ontology generating mechanism. Finally, based on the FDO and the fuzzy ontology, the semantic fuzzy decision making mechanism simulates the semantic description of medical staff for diabetes-related application. Importantly, the proposed fuzzy expert system can work effectively for diabetes decision support application.","Hybrid intelligent systems,
Diabetes,
Ontologies,
Fuzzy systems,
Uncertainty,
Decision making,
Decision support systems,
Medical conditions,
Cardiac disease,
Medical simulation"
GUI Interaction Testing: Incorporating Event Context,"Graphical user interfaces (GUIs), due to their event-driven nature, present an enormous and potentially unbounded way for users to interact with software. During testing, it is important to “adequately cover” this interaction space. In this paper, we develop a new family of coverage criteria for GUI testing grounded in combinatorial interaction testing. The key motivation of using combinatorial techniques is that they enable us to incorporate “context” into the criteria in terms of event combinations, sequence length, and by including all possible positions for each event. Our new criteria range in both efficiency (measured by the size of the test suite) and effectiveness (the ability of the test suites to detect faults). In a case study on eight applications, we automatically generate test cases and systematically explore the impact of context, as captured by our new criteria. Our study shows that by increasing the event combinations tested and by controlling the relative positions of events defined by the new criteria, we can detect a large number of faults that were undetectable by earlier techniques.","Graphical user interfaces,
System testing,
Software testing,
Automatic testing,
Fault detection,
Context modeling,
Computer science,
Software performance,
Logic testing,
User interfaces"
Affine Legendre Moment Invariants for Image Watermarking Robust to Geometric Distortions,"Geometric distortions are generally simple and effective attacks for many watermarking methods. They can make detection and extraction of the embedded watermark difficult or even impossible by destroying the synchronization between the watermark reader and the embedded watermark. In this paper, we propose a new watermarking approach which allows watermark detection and extraction under affine transformation attacks. The novelty of our approach stands on a set of affine invariants we derived from Legendre moments. Watermark embedding and detection are directly performed on this set of invariants. We also show how these moments can be exploited for estimating the geometric distortion parameters in order to permit watermark extraction. Experimental results show that the proposed watermarking scheme is robust to a wide range of attacks: geometric distortion, filtering, compression, and additive noise.","Watermarking,
Robustness,
PSNR,
Transforms,
Image coding,
Electronic mail,
Transform coding"
Automatic Recognition of Non-Acted Affective Postures,"The conveyance and recognition of affect and emotion partially determine how people interact with others and how they carry out and perform in their day-to-day activities. Hence, it is becoming necessary to endow technology with the ability to recognize users' affective states to increase the technologies' effectiveness. This paper makes three contributions to this research area. First, we demonstrate recognition models that automatically recognize affective states and affective dimensions from non-acted body postures instead of acted postures. The scenario selected for the training and testing of the automatic recognition models is a body-movement-based video game. Second, when attributing affective labels and dimension levels to the postures represented as faceless avatars, the level of agreement for observers was above chance level. Finally, with the use of the labels and affective dimension levels assigned by the observers as ground truth and the observers' level of agreement as base rate, automatic recognition models grounded on low-level posture descriptions were built and tested for their ability to generalize to new observers and postures using random repeated subsampling validation. The automatic recognition models achieve recognition percentages comparable to the human base rates as hypothesized.","Observers,
Games,
Humans,
Emotion recognition,
Labeling,
Computational modeling,
Joints"
"Voronoi-Based Continuous
k
Nearest Neighbor Search in Mobile Navigation","Digital ecosystems are formed by “digital organisms” in complex, dynamic, and interrelated ecosystems and utilize multiple technologies to provide cost-efficient digital services and value-creating activities. A distributed wireless mobile network that serves as the underlying infrastructure to digital ecosystems provides important applications to the digital ecosystems, two of which are mobile navigation and continuous mobile information services. Most information and query services in a mobile environment are continuous mobile query processing or continuous k nearest neighbor (CKNN), which finds the locations where interest points or interest objects change while mobile users are moving. These locations are known as “split nodes.” All of the existing works on CKNN divide the query path into segments, which is a segment of road separated by two intersections, and then, the process to find split nodes is applied to each segment. Since there are many segments (due to many intersections, obviously), processing each segment is naturally inefficient. In this paper, we propose an alternative solution to overcome this problem. We use the Voronoi diagram for CKNN [called Voronoi CKNN (VCKNN)]. Our proposed approach does not need to divide the query path into segments, hence improving the overall query processing performance. Our experiment verified the applicability of the VCKNN approach to solve CKNN queries.","Nearest neighbor searches,
Navigation,
Ecosystems,
Query processing,
Roads,
Global Positioning System,
Monitoring,
Spatial databases,
Organisms,
Permission"
Cloud Computing for Agent-Based Urban Transportation Systems,"Agent-based traffic management systems can use the autonomy, mobility, and adaptability of mobile agents to deal with dynamic traffic environments. Cloud computing can help such systems cope with the large amounts of storage and computing resources required to use traffic strategy agents and mass transport data effectively. This article reviews the history of the development of traffic control and management systems within the evolving computing paradigm and shows the state of traffic control and management systems based on mobile multiagent technology.",
mrFPGA: A novel FPGA architecture with memristor-based reconfiguration,"In this paper, we introduce a novel FPGA architecture with memristor-based reconfiguration (mrFPGA). The proposed architecture is based on the existing CMOS-compatible memristor fabrication process. The programmable interconnects of mrFPGA use only memristors and metal wires so that the interconnects can be fabricated over logic blocks, resulting in significant reduction of overall area and interconnect delay but without using a 3D die-stacking process. Using memristors to build up the interconnects can also provide capacitance shielding from unused routing paths and reduce interconnect delay further. Moreover we propose an improved architecture that allows adaptive buffer insertion in interconnects to achieve more speedup. Compared to the fixed buffer pattern in conventional FPGAs, the positions of inserted buffers in mrFPGA are optimized on demand. A complete CAD flow is provided for mrFPGA, with an advanced P&R tool named mrVPR that was developed for mrFPGA. The tool can deal with the novel routing structure of mrFPGA, the memristor shielding effect, and the algorithm for optimal buffer insertion. We evaluate the area, performance and power consumption of mrFPGA based on the 20 largest MCNC benchmark circuits. Results show that mrFPGA achieves 5.18x area savings, 2.28x speedup and 1.63x power savings. Further improvement is expected with combination of 3D technologies and mrFPGA.","Field programmable gate arrays,
Memristors,
Routing,
Integrated circuit interconnections,
Delay,
Wires,
Metals"
Full DOF tracking of a hand interacting with an object by modeling occlusions and physical constraints,"Due to occlusions, the estimation of the full pose of a human hand interacting with an object is much more challenging than pose recovery of a hand observed in isolation. In this work we formulate an optimization problem whose solution is the 26-DOF hand pose together with the pose and model parameters of the manipulated object. Optimization seeks for the joint hand-object model that (a) best explains the incompleteness of observations resulting from occlusions due to hand-object interaction and (b) is physically plausible in the sense that the hand does not share the same physical space with the object. The proposed method is the first that solves efficiently the continuous, full-DOF, joint hand-object tracking problem based solely on markerless multicamera input. Additionally, it is the first to demonstrate how hand-object interaction can be exploited as a context that facilitates hand pose estimation, instead of being considered as a complicating factor. Extensive quantitative and qualitative experiments with simulated and real world image sequences as well as a comparative evaluation with a state-of-the-art method for pose estimation of isolated hands, support the above findings.",Cameras
Win-Coupon: An incentive framework for 3G traffic offloading,"3G networks are currently facing severe traffic overload problems caused by excessive demands of mobile users. Offloading part of the 3G traffic through other forms of networks, such as Delay Tolerant Networks (DTNs), WiFi hotspots, and Femtocells, is a promising solution. However, since these networks can only provide intermittent and opportunistic connectivity to mobile users, utilizing them for 3G traffic offloading may result in a non-negligible delay. As the delay increases, the users' satisfaction decreases. In this paper, we investigate the tradeoff between the amount of traffic being offloaded and the users' satisfaction. We provide a novel incentive framework to motivate users to leverage their delay tolerance for 3G traffic offloading. To minimize the incentive cost given an offloading target, users with high delay tolerance and large offloading potential should be prioritized for traffic offloading. To effectively capture the dynamic characteristics of users' delay tolerance, our incentive framework is based on reverse auction to let users proactively express their delay tolerance by submitting bids. We further take DTN as a case study to illustrate how to predict the offloading potential of the users by using stochastic analysis. Extensive trace-driven simulations verify the efficiency of our incentive framework for 3G traffic offloading.",
Subspaces Indexing Model on Grassmann Manifold for Image Search,"Conventional linear subspace learning methods like principal component analysis (PCA), linear discriminant analysis (LDA) derive subspaces from the whole data set. These approaches have limitations in the sense that they are linear while the data distribution we are trying to model is typically nonlinear. Moreover, these algorithms fail to incorporate local variations of the intrinsic sample distribution manifold. Therefore, these algorithms are ineffective when applied on large scale datasets. Kernel versions of these approaches can alleviate the problem to certain degree but face a serious computational challenge when data set is large, where the computing involves Eigen/QP problems of size N × N. When N is large, kernel versions are not computationally practical. To tackle the aforementioned problems and improve recognition/searching performance, especially on large scale image datasets, we propose a novel local subspace indexing model for image search termed Subspace Indexing Model on Grassmann Manifold (SIM-GM). SIM-GM partitions the global space into local patches with a hierarchical structure; the global model is, therefore, approximated by piece-wise linear local subspace models. By further applying the Grassmann manifold distance, SIM-GM is able to organize localized models into a hierarchy of indexed structure, and allow fast query selection of the optimal ones for classification. Our proposed SIM-GM enjoys a number of merits: 1) it is able to deal with a large number of training samples efficiently; 2) it is a query-driven approach, i.e., it is able to return an effective local space model, so the recognition performance could be significantly improved; 3) it is a common framework, which can incorporate many learning algorithms. Theoretical analysis and extensive experimental results confirm the validity of this model.","Manifolds,
Indexing,
Data models,
Classification algorithms,
Algorithm design and analysis,
Computational modeling,
Principal component analysis"
Coalition Formation Games for Collaborative Spectrum Sensing,"Collaborative spectrum sensing (CSS) between secondary users (SUs) in cognitive networks exhibits an inherent tradeoff between minimizing the probability of missing the detection of the primary user (PU) and maintaining a reasonable false alarm probability (e.g., for maintaining good spectrum utilization). In this paper, we study the impact of this tradeoff on the network structure and the cooperative incentives of the SUs that seek to cooperate to improve their detection performance. We model the CSS problem as a nontransferable coalitional game, and we propose distributed algorithms for coalition formation (CF). First, we construct a distributed CF algorithm that allows the SUs to self-organize into disjoint coalitions while accounting for the CSS tradeoff. Then, the CF algorithm is complemented with a coalitional voting game to enable distributed CF with detection probability (CF-PD) guarantees when required by the PU. The CF-PD algorithm allows the SUs to form minimal winning coalitions (MWCs), i.e., coalitions that achieve the target detection probability with minimal costs. For both algorithms, we study and prove various properties pertaining to network structure, adaptation to mobility, and stability. Simulation results show that CF reduces the average probability of miss per SU up to 88.45%, relative to the noncooperative case, while maintaining a desired false alarm. For CF-PD, the results show that up to 87.25% of the SUs achieve the required detection probability through MWCs.",
Markov Models for Biogeography-Based Optimization,"Biogeography-based optimization (BBO) is a population-based evolutionary algorithm that is based on the mathematics of biogeography. Biogeography is the science and study of the geographical distribution of biological organisms. In BBO, problem solutions are analogous to islands, and the sharing of features between solutions is analogous to the migration of species. This paper derives Markov models for BBO with selection, migration, and mutation operators. Our models give the theoretically exact limiting probabilities for each possible population distribution for a given problem. We provide simulation results to confirm the Markov models.",
Output Feedback Control of Discrete-Time Systems in Networked Environments,"This correspondence paper addresses the problem of output feedback stabilization of control systems in networked environments with quality-of-service (QoS) constraints. The problem is investigated in discrete-time state space using Lyapunov's stability theory and the linear inequality matrix technique. A new discrete-time modeling approach is developed to describe a networked control system (NCS) with parameter uncertainties and nonideal network QoS. It integrates a network-induced delay, packet dropout, and other network behaviors into a unified framework. With this modeling, an improved stability condition, which is dependent on the lower and upper bounds of the equivalent network-induced delay, is established for the NCS with norm-bounded parameter uncertainties. It is further extended for the output feedback stabilization of the NCS with nonideal QoS. Numerical examples are given to demonstrate the main results of the theoretical development.","Delay,
Quality of service,
Actuators,
Stability analysis,
Output feedback,
Uncertain systems"
Keeneland: Bringing Heterogeneous GPU Computing to the Computational Science Community,"The Keeneland project's goal is to develop and deploy an innovative, GPU-based high-performance computing system for the NSF computational science community.","Graphics processing unit,
Computer architecture,
Benchmark testing,
Random access memory,
Scientific computing,
Computational modeling,
Hardware"
Wings: Intelligent Workflow-Based Design of Computational Experiments,"Describes the Wings intelligent workflow system that assists scientists with designing computational experiments by automatically tracking constraints and ruling out invalid designs, letting scientists focus on their experiments and goals.",
Multiuser MISO Interference Channels With Single-User Detection: Optimality of Beamforming and the Achievable Rate Region,"For a multiuser interference channel with multi-antenna transmitters and single-antenna receivers, by restricting each transmitter to a Gaussian input and each receiver to a single-user detector, computing the largest achievable rate region amounts to solving a family of nonconvex optimization problems. Recognizing the intrinsic connection between the signal power at the intended receiver and the interference power at the unintended receiver, the original family of nonconvex optimization problems is converted into a new family of convex optimization problems. It is shown that, for such interference channels with each receiver implementing single-user detection, transmitter beamforming can achieve all boundary points of the achievable rate region.",
Fast Dictionary Learning for Sparse Representations of Speech Signals,"For dictionary-based decompositions of certain types, it has been observed that there might be a link between sparsity in the dictionary and sparsity in the decomposition. Sparsity in the dictionary has also been associated with the derivation of fast and efficient dictionary learning algorithms. Therefore, in this paper we present a greedy adaptive dictionary learning algorithm that sets out to find sparse atoms for speech signals. The algorithm learns the dictionary atoms on data frames taken from a speech signal. It iteratively extracts the data frame with minimum sparsity index, and adds this to the dictionary matrix. The contribution of this atom to the data frames is then removed, and the process is repeated. The algorithm is found to yield a sparse signal decomposition, supporting the hypothesis of a link between sparsity in the decomposition and dictionary. The algorithm is applied to the problem of speech representation and speech denoising, and its performance is compared to other existing methods. The method is shown to find dictionary atoms that are sparser than their time-domain waveform, and also to result in a sparser speech representation. In the presence of noise, the algorithm is found to have similar performance to the well established principal component analysis.",
On full-view coverage in camera sensor networks,"Camera sensors are different from traditional scalar sensors as different cameras from different positions can form distinct views of the object. However, traditional disk sensing model does not consider this intrinsic property of camera sensors. To this end, we propose a novel model called full-view coverage. An object is considered to be full-view covered if for any direction from 0 to 2π (object's facing direction), there is always a sensor such that the object is within the sensor's range and more importantly the sensor's viewing direction is sufficiently close to the object's facing direction. With this model, we propose an efficient method for full-view coverage detection in any given camera sensor networks. We also derive a sufficient condition on the sensor density needed for full-view coverage in a random uniform deployment. Finally, we show a necessary and sufficient condition on the sensor density for full-view coverage in a triangular lattice based deployment.","object detection,
cameras"
The Hybrid Reciprocal Velocity Obstacle,"We present the hybrid reciprocal velocity obstacle for collision-free and oscillation-free navigation of multiple mobile robots or virtual agents. Each robot senses its surroundings and acts independently without central coordination or communication with other robots. Our approach uses both the current position and the velocity of other robots to compute their future trajectories in order to avoid collisions. Moreover, our approach is reciprocal and avoids oscillations by explicitly taking into account that the other robots sense their surroundings as well and change their trajectories accordingly. We apply hybrid reciprocal velocity obstacles to iRobot Create mobile robots and demonstrate direct, collision-free, and oscillation-free navigation.",
Information Granularity in Fuzzy Binary GrC Model,"Zadeh's seminal work in theory of fuzzy-information granulation in human reasoning is inspired by the ways in which humans granulate information and reason with it. This has led to an interesting research topic: granular computing (GrC). Although many excellent research contributions have been made, there remains an important issue to be addressed: What is the essence of measuring a fuzzy-information granularity of a fuzzy-granular structure? What is needed to answer this question is an axiomatic constraint with a partial-order relation that is defined in terms of the size of each fuzzy-information granule from a fuzzy-binary granular structure. This viewpoint is demonstrated for fuzzy-binary granular structure, which is called the binary GrC model by Lin. We study this viewpoint from from five aspects in this study, which are fuzzy BINARY-granular-structure operators, partial-order relations, measures for fuzzy-information granularity, an axiomatic approach to fuzzy-information granularity, and fuzzy-information entropies.",
RGBD-HuDaAct: A color-depth video database for human daily activity recognition,"In this paper, we present a home-monitoring oriented human activity recognition benchmark database, based on the combination of a color video camera and a depth sensor. Our contributions are two-fold: 1) We have created a publicly releasable human activity video database (i.e., named as RGBD-HuDaAct), which contains synchronized color-depth video streams, for the task of human daily activity recognition. This database aims at encouraging more research efforts on human activity recognition based on multi-modality sensor combination (e.g., color plus depth). 2) Two multi-modality fusion schemes, which naturally combine color and depth information, have been developed from two state-of-the-art feature representation methods for action recognition, i.e., spatio-temporal interest points (STIPs) and motion history images (MHIs). These depth-extended feature representation methods are evaluated comprehensively and superior recognition performances over their uni-modality (e.g., color only) counterparts are demonstrated.","Databases,
Humans,
History,
Image color analysis,
Cameras,
Histograms,
Visualization"
A Fast Wavelet-Based Reconstruction Method for Magnetic Resonance Imaging,"In this work, we exploit the fact that wavelets can represent magnetic resonance images well, with relatively few coefficients. We use this property to improve magnetic resonance imaging (MRI) reconstructions from undersampled data with arbitrary k-space trajectories. Reconstruction is posed as an optimization problem that could be solved with the iterative shrinkage/thresholding algorithm (ISTA) which, unfortunately, converges slowly. To make the approach more practical, we propose a variant that combines recent improvements in convex optimization and that can be tuned to a given specific k-space trajectory. We present a mathematical analysis that explains the performance of the algorithms. Using simulated and in vivo data, we show that our nonlinear method is fast, as it accelerates ISTA by almost two orders of magnitude. We also show that it remains competitive with TV regularization in terms of image quality.","Image reconstruction,
Magnetic resonance imaging,
Algorithm design and analysis,
Convergence,
Discrete wavelet transforms,
Minimization"
Total Variation Regularization for fMRI-Based Prediction of Behavior,"While medical imaging typically provides massive amounts of data, the extraction of relevant information for predictive diagnosis remains a difficult challenge. Functional magnetic resonance imaging (fMRI) data, that provide an indirect measure of task-related or spontaneous neuronal activity, are classically analyzed in a mass-univariate procedure yielding statistical parametric maps. This analysis framework disregards some important principles of brain organization: population coding, distributed and overlapping representations. Multivariate pattern analysis, i.e., the prediction of behavioral variables from brain activation patterns better captures this structure. To cope with the high dimensionality of the data, the learning method has to be regularized. However, the spatial structure of the image is not taken into account in standard regularization methods, so that the extracted features are often hard to interpret. More informative and interpretable results can be obtained with the ℓ1 norm of the image gradient, also known as its total variation (TV), as regularization. We apply for the first time this method to fMRI data, and show that TV regularization is well suited to the purpose of brain mapping while being a powerful tool for brain decoding. Moreover, this article presents the first use of TV regularization for classification.",
The Weight Distributions of the Duals of Cyclic Codes With Two Zeros,"Cyclic codes with two zeros and their dual codes have been a subject of study for many years. However, their weight distributions are known only for a few cases. In this paper, the weight distributions of the duals of the cyclic codes with two zeros are settled for a few more cases.",
Fault Detection and Mitigation in Multilevel Converter STATCOMs,"Many static synchronous compensators (STATCOMs) utilize multilevel converters due to the following: 1) lower harmonic injection into the power system; 2) decreased stress on the electronic components due to decreased voltages; and 3) lower switching losses. One disadvantage, however, is the increased likelihood of a switch failure due to the increased number of switches in a multilevel converter. A single switch failure, however, does not necessarily force an (2n + 1)-level STATCOM offline. Even with a reduced number of switches, a STATCOM can still provide a significant range of control by removing the module of the faulted switch and continuing with (2n - 1) levels. This paper introduces an approach to detect the existence of the faulted switch, identify which switch is faulty, and reconfigure the STATCOM. This approach is illustrated on an eleven-level STATCOM and the effect on the dynamic performance and the total harmonic distortion (THD) is analyzed.","Fault detection,
Automatic voltage control,
Switches,
Switching converters,
Power system harmonics,
Electrical fault detection,
Power system faults,
Stress,
Electronic components,
Switching loss"
A Relay Level Set Method for Automatic Image Segmentation,"This paper presents a new image segmentation method that applies an edge-based level set method in a relay fashion. The proposed method segments an image in a series of nested subregions that are automatically created by shrinking the stabilized curves in their previous subregions. The final result is obtained by combining all boundaries detected in these subregions. The proposed method has the following three advantages: 1) It can be automatically executed without human-computer interactions; 2) it applies the edge-based level set method with relay fashion to detect all boundaries; and 3) it automatically obtains a full segmentation without specifying the number of relays in advance. The comparison experiments illustrate that the proposed method performs better than the representative level set methods, and it can obtain similar or better results compared with other popular segmentation algorithms.","Level set,
Image segmentation,
Relays,
Equations,
Shape,
Mathematical model,
Active contours"
Comparing Hardware Accelerators in Scientific Applications: A Case Study,"Multicore processors and a variety of accelerators have allowed scientific applications to scale to larger problem sizes. We present a performance, design methodology, platform, and architectural comparison of several application accelerators executing a Quantum Monte Carlo application. We compare the application's performance and programmability on a variety of platforms including CUDA with Nvidia GPUs, Brook+ with ATI graphics accelerators, OpenCL running on both multicore and graphics processors, C++ running on multicore processors, and a VHDL implementation running on a Xilinx FPGA. We show that OpenCL provides application portability between multicore processors and GPUs, but may incur a performance cost. Furthermore, we illustrate that graphics accelerators can make simulations involving large numbers of particles feasible.",
Interference alignment in MIMO cellular networks,"We explore the feasibility of linear interference alignment (IA) in MIMO cellular networks. Each base station (BTS) has Nt transmit antennas, each mobile has Nr receive antennas, and a BTS transmits a single beam to each active user. We present a necessary Zero-Forcing (ZF) condition for zero interference in terms of the number of users, the number of cells, Nt and Nr. We then examine the performance of iterative (forward-backward) algorithms for jointly optimizing the transmit precoders with linear receivers. Modifications of the max-SINR and minimum leakage algorithms are presented, which are observed to converge to a ZF solution whenever the necessary conditions are satisfied. In contrast, convergence of the (original) max-SINR algorithm is problematic when the necessary conditions are satisfied with (near) equality. A more restrictive ZF condition is presented, which predicts when these convergence problems are unlikely to occur.","Interference,
Downlink,
MIMO,
Signal to noise ratio,
Receivers,
Mobile communication,
Equations"
Three-Dimensional Gabor Wavelets for Pixel-Based Hyperspectral Imagery Classification,"The rich information available in hyperspectral imagery not only poses significant opportunities but also makes big challenges for material classification. Discriminative features seem to be crucial for the system to achieve accurate and robust performance. In this paper, we propose a 3-D Gabor-wavelet-based approach for pixel-based hyperspectral imagery classification. A set of complex Gabor wavelets with different frequencies and orientations is first designed to extract signal variances in space, spectrum, and joint spatial/spectral domains. The magnitude of the response at each sampled location (x, y) for spectral band b contains rich information about the signal variances in the local region. Each pixel can be well represented by the rich information extracted by Gabor wavelets. A feature selection and fusion process has also been developed to reduce the redundancy among Gabor features and make the fused feature more discriminative. The proposed approach was fully tested on two real-world hyperspectral data sets, i.e., the widely used Indian Pine site and Kennedy Space Center. The results show that our method achieves as high as 96.04% and 95.36% accuracies, respectively, even when only few samples, i.e., 5% of the total samples per class, are labeled.",
Graph-Preserving Sparse Nonnegative Matrix Factorization With Application to Facial Expression Recognition,"In this paper, a novel graph-preserving sparse nonnegative matrix factorization (GSNMF) algorithm is proposed for facial expression recognition. The GSNMF algorithm is derived from the original NMF algorithm by exploiting both sparse and graph-preserving properties. The latter may contain the class information of the samples. Therefore, GSNMF can be conducted as an unsupervised or a supervised dimension reduction method. A sparse representation of the facial images is obtained by minimizing the -norm of the basis images. Furthermore, according to the graph embedding theory, the neighborhood of the samples is preserved by retaining the graph structure in the mapped space. The GSNMF decomposition transforms the high-dimensional facial expression images into a locality-preserving subspace with sparse representation. To guarantee convergence, we use the projected gradient method to calculate the nonnegative solution of GSNMF. Experiments are conducted on the JAFFE database and the Cohn-Kanade database with unoccluded and partially occluded facial images. The results show that the GSNMF algorithm provides better facial representations and achieves higher recognition rates than nonnegative matrix factorization. Moreover, GSNMF is also more robust to partial occlusions than other tested methods.",
Real time pothole detection using Android smartphones with accelerometers,The importance of the road infrastructure for the society could be compared with importance of blood vessels for humans. To ensure road surface quality it should be monitored continuously and repaired as necessary. The optimal distribution of resources for road repairs is possible providing the availability of comprehensive and objective real time data about the state of the roads. Participatory sensing is a promising approach for such data collection. The paper is describing a mobile sensing system for road irregularity detection using Android OS based smart-phones. Selected data processing algorithms are discussed and their evaluation presented with true positive rate as high as 90% using real world data. The optimal parameters for the algorithms are determined as well as recommendations for their application.,"Roads,
Sensors,
Accelerometers,
Algorithm design and analysis,
Vehicles,
Software algorithms,
Software"
Green Provisioning for Optical WDM Networks,"Since the Internet consumes a large (and increasing) amount of energy, “green” strategies are desirable to help service providers (SP) operate their networks and provision services more energy efficiently. We focus on green provisioning strategies for optical wavelength-division multiplexing networks. A number of approaches from component layer to network layer are discussed, which should help improve the energy efficiency of the networks. Then, we consider a typical optical backbone network architecture, and minimize the operational power for provisioning. Typically, operational power depends on strategy (e.g., optical bypass versus traffic grooming), operations (e.g., electronic domain versus optical domain), and route. We analyze the constituents of operational power in various scenarios, and discuss the opportunities for energy savings. We propose a novel auxiliary graph, which can capture the power consumption of each provisioning operation. Based on the auxiliary graph, we develop a power-aware provisioning scheme to minimize the total operational power. Performance evaluation shows that our scheme always needs the least operational power, with comparison to a direct-lightpath approach and a traffic-grooming approach. The result also suggests proportional power consumption by operations (network equipment) and end-node traffic grooming to fully exploit the power-saving potential of optical networks.",
Efficient information collection protocols for sensor-augmented RFID networks,"Similar to the revolutionary change that the barcode system brought to the retail industry, the RFID technologies are expected to revolutionize the warehouse and inventory management. After RFID tags are deployed to make the attached objects wirelessly identifiable, a natural next step is to invent new ways to benefit from this “infrastructure”. For example, sensors may be added to these tags to gather real-time information about the state of the objects or about the environment where these objects reside. This leads to the problem of designing efficient protocols to collect such information from the tags. It is a new problem that the existing work cannot solve well. In this paper, we first show that a straightforward polling solution will not be efficient. We then propose a single-hash information collection protocol that works much better than the polling solution. However, a wide gap still exists between the execution time of this protocol and a lower bound that we establish. Finally, we propose a multi-hash information collection protocol that further reduces the expected execution time to within 1.61 times the lower bound.",
Optimal Orthogonal Precoding for Power Leakage Suppression in DFT-Based Systems,"A solution to the power leakage minimization problem in discrete Fourier transform (DFT) based communication systems is presented. In a conventional DFT based system, modulated subcarriers exhibit high sidelobe levels, which leads to significant out-of-band power leakage. Existing techniques found in the literature either do not achieve sufficient sidelobe suppression or suffer from significant spectral efficiency loss. Precoding can be seen as a general linear processing method for power leakage reduction, however, how to design the optimal linear precoder is still an open problem. In this paper, the power leakage suppression is first treated as a matrix Frobenius norm minimization problem, and then the optimal orthogonal precoding matrix design for the power leakage suppression is proposed based on singular value decomposition (SVD). By further exploiting the extra degrees of freedom in the precoding matrix, two kinds of optimized precoding matrices, one with multi-carrier property and the other with single-carrier property, are developed to take the advantages of orthogonal frequency division multiplexing (OFDM) and single carrier frequency division multiple access (SC-FDMA), respectively. Simulation results show that both the multi-carrier and the single-carrier precoding schemes achieve significant power leakage suppression, and have similar peak-to-average power ratio (PAPR) and bit-error-rate (BER) to those of OFDM and SC-FDMA systems, respectively.","Matrix decomposition,
Peak to average power ratio,
Optimization,
Discrete Fourier transforms,
Interference,
Time domain analysis"
Robot-Assisted Needle Steering,"Needle insertion is a critical aspect of many medical treatments, diagnostic methods, and scientific studies, and is considered to be one of the simplest and most minimally invasive medical procedures. Robot-assisted needle steering has the potential to improve the effectiveness of existing medical procedures and enable new ones by allowing increased accuracy through more dexterous control of the needle-tip path and acquisition of targets not accessible by straight-line trajectories. In this article, we describe a robot-assisted needle-steering system that uses three integrated controllers: a motion planner concerned with guiding the needle around obstacles to a target in a desired plane, a planar controller that maintains the needle in the desired plane, and a torsion compensator that controls the needle-tip orientation about the axis of the needle shaft.",
Geographical Routing With Location Service in Intermittently Connected MANETs,"Combining mobile platforms such as manned or unmanned vehicles and peer-assisted wireless communication is an enabler for a vast number of applications. A key enabler for the applications is the routing protocol that directs the packets in the network. Routing packets in fully connected mobile ad hoc networks (MANETs) has been studied to a great extent, but the assumption on full connectivity is generally not valid in a real system. This case means that a practical routing protocol must handle intermittent connectivity and the absence of end-to-end connections. In this paper, we propose a geographical routing algorithm called location-aware routing for delay-tolerant networks (LAROD), enhanced with a location service, location dissemination service (LoDiS), which together are shown to suit an intermittently connected MANET (IC-MANET). Because location dissemination takes time in IC-MANETs, LAROD is designed to route packets with only partial knowledge of geographic position. To achieve low overhead, LAROD uses a beaconless strategy combined with a position-based resolution of bids when forwarding packets. LoDiS maintains a local database of node locations, which is updated using broadcast gossip combined with routing overhearing. The algorithms are evaluated under a realistic application, i.e., unmanned aerial vehicles deployed in a reconnaissance scenario, using the low-level packet simulator ns-2. The novelty of this paper is the illustration of sound design choices in a realistic application, with holistic choices in routing, location management, and the mobility model. This holistic approach justifies that the choice of maintaining a local database of node locations is both essential and feasible. The LAROD-LoDiS scheme is compared with a leading delay-tolerant routing algorithm (spray and wait) and is shown to have a competitive edge, both in terms of delivery ratio and overhead. For spray and wait, this case involved a new packet-level implementation in ns-2 as opposed to the original connection-level custom simulator.",
Computing Performance: Game Over or Next Level?,"The end of dramatic exponential growth in single-processor performance marks the end of the dominance of the single microproessor in computing. The era of sequential computing must give way to an era in which parallelism holds the forefront. Although important scientific and engineering challenges lie ahead, this is an opportune time for innovation in programming systems and computing architectures.","Program processors,
Parallel processing,
Programming,
Computational modeling,
Hardware,
Sequential analysis"
Emotion recognition using PHOG and LPQ features,"We propose a method for automatic emotion recognition as part of the FERA 2011 competition. The system extracts pyramid of histogram of gradients (PHOG) and local phase quantisation (LPQ) features for encoding the shape and appearance information. For selecting the key frames, K-means clustering is applied to the normalised shape vectors derived from constraint local model (CLM) based face tracking on the image sequences. Shape vectors closest to the cluster centers are then used to extract the shape and appearance features. We demonstrate the results on the SSPNET GEMEP-FERA dataset. It comprises of both person specific and person independent partitions. For emotion classification we use support vector machine (SVM) and largest margin nearest neighbour (LMNN) and compare our results to the pre-computed FERA 2011 emotion challenge baseline.","Face,
Shape,
Feature extraction,
Image sequences,
Support vector machines,
Databases,
Accuracy"
Nonlinear Unsharp Masking for Mammogram Enhancement,"This paper introduces a new unsharp masking (UM) scheme, called nonlinear UM (NLUM), for mammogram enhancement. The NLUM offers users the flexibility 1) to embed different types of filters into the nonlinear filtering operator; 2) to choose different linear or nonlinear operations for the fusion processes that combines the enhanced filtered portion of the mammogram with the original mammogram; and 3) to allow the NLUM parameter selection to be performed manually or by using a quantitative enhancement measure to obtain the optimal enhancement parameters. We also introduce a new enhancement measure approach, called the second-derivative-like measure of enhancement, which is shown to have better performance than other measures in evaluating the visual quality of image enhancement. The comparison and evaluation of enhancement performance demonstrate that the NLUM can improve the disease diagnosis by enhancing the fine details in mammograms with no a priori knowledge of the image contents. The human-visual-system-based image decomposition is used for analysis and visualization of mammogram enhancement.",
Autonomous MAV flight in indoor environments using single image perspective cues,"We consider the problem of autonomously flying Miniature Aerial Vehicles (MAVs) in indoor environments such as home and office buildings. The primary long range sensor in these MAVs is a miniature camera. While previous approaches first try to build a 3D model in order to do planning and control, our method neither attempts to build nor requires a 3D model. Instead, our method first classifies the type of indoor environment the MAV is in, and then uses vision algorithms based on perspective cues to estimate the desired direction to fly. We test our method on two MAV platforms: a co-axial miniature helicopter and a toy quadrotor. Our experiments show that our vision algorithms are quite reliable, and they enable our MAVs to fly in a variety of corridors and staircases.","Cameras,
Indoor environments,
Navigation,
Three dimensional displays,
Robot vision systems"
Schedule Optimization of Time-Triggered Systems Communicating Over the FlexRay Static Segment,"FlexRay is a new high-bandwidth communication protocol for the automotive domain, providing support for the transmission of time-critical periodic frames in a static segment and priority-based scheduling of event-triggered frames in a dynamic segment. The design of a system scheduling with communication over the FlexRay static segment is not an easy task because of protocol constraints and the demand for extensibility and flexibility. We study the problem of the ECU and FlexRay bus scheduling synthesis from the perspective of the application designer, interested in optimizing the scheduling subject to timing constraints with respect to latency- or extensibility-related metric functions. We provide solutions for a task and signal scheduling problem, including different task scheduling policies based on existing industry standards. The solutions are based on the Mixed-Integer Linear Programming optimization framework. We show the results of the application of the method to case studies consisting of an X-by-wire system on actual prototype vehicles.","Synchronization,
Optimal scheduling,
Schedules,
Job shop scheduling,
Delay"
"A comparative study of physicochemical, dielectric and thermal properties of pressboard insulation impregnated with natural ester and mineral oil","Natural ester is considered to be a substitute of mineral oil in the future. To apply natural ester in large transformers safely, natural ester impregnated solid insulation should be proved to have comparable dielectric strength and thermal stability to mineral oil impregnated solid insulation. This paper mainly focuses on a comparative study of physicochemical, ac breakdown strength and thermal stability behavior of BIOTEMP natural ester/pressboard insulation and Karamay 25# naphthenic mineral oil/pressboard insulation after long term thermal ageing. The physicochemical and dielectric parameters including moisture, acids and the ac breakdown strength of these two oil/pressboard insulation systems at different ageing status were compared. The permittivity and ac breakdown strength of these two oil/pressboard insulation systems at different temperatures were also investigated. And a comparative result of the thermal stability behavior of these two oil/pressboard insulation systems with different ageing status was provided at last. Results show that though natural ester has higher absolute humidity and acidity during the long ageing period, the lower relative humidity of natural ester helps to keep its ac breakdown strength higher than mineral oil. The pressboard aged in natural ester also has higher ac breakdown strength than that aged in mineral oil. The lower relative permittivity ratio of natural ester impregnated paper to natural ester is beneficial to its dielectric strength. Using natural ester in transformer, the resistance to thermal decomposition of the oil/pressboard insulation system could be also effectively improved.",
Global Localization of Objects via Touch,"Humans are capable of manipulating objects based solely on the sense of touch. For robots to achieve the same feat in unstructured environments, global localization of objects via touch is required. Bayesian approaches provide the means to cope with uncertainties of the real world, but the estimation of the Bayesian posterior for the full six degrees of freedom (6-DOF) global localization problem is computationally prohibitive. We propose an efficient Bayesian approach termed Scaling Series. It is capable of solving the full problem reliably in real time. This is a Monte Carlo approach that performs a series of successive refinements coupled with annealing. We also propose an analytical measurement model, which can be computed efficiently at run time for any object represented as a polygonal mesh. Extensive empirical evaluation shows that Scaling Series drastically outperforms prior approaches. We demonstrate general applicability of the approach on five common solid objects, which are rigidly fixed during the experiments. We also consider 6-DOF localization and tracking of free-standing objects that can move during tactile exploration.","Uncertainty,
Computational modeling,
Bayesian methods,
Robot sensing systems,
Estimation,
Measurement uncertainty"
A Game Platform for Treatment of Amblyopia,"We have developed a prototype device for take-home use that can be used in the treatment of amblyopia. The therapeutic scenario we envision involves patients first visiting a clinic, where their vision parameters are assessed and suitable parameters are determined for therapy. Patients then proceed with the actual therapeutic treatment on their own, using our device, which consists of an Apple iPod Touch running a specially modified game application. Our rationale for choosing to develop the prototype around a game stems from multiple requirements that such an application satisfies. First, system operation must be sufficiently straight-forward that ease-of-use is not an obstacle. Second, the application itself should be compelling and motivate use more so than a traditional therapeutic task if it is to be used regularly outside of the clinic. This is particularly relevant for children, as compliance is a major issue for current treatments of childhood amblyopia. However, despite the traditional opinion that treatment of amblyopia is only effective in children, our initial results add to the growing body of evidence that improvements in visual function can be achieved in adults with amblyopia.","Games,
Fellows,
Visualization,
Vision defects,
Portable media players,
Prototypes,
Noise"
Biologically Inspired Features for Scene Classification in Video Surveillance,"Inspired by human visual cognition mechanism, this paper first presents a scene classification method based on an improved standard model feature. Compared with state-of-the-art efforts in scene classification, the newly proposed method is more robust, more selective , and of lower complexity. These advantages are demonstrated by two sets of experiments on both our own database and standard public ones. Furthermore, occlusion and disorder problems in scene classification in video surveillance are also first studied in this paper.","Layout,
Video surveillance,
Feature extraction,
Robustness,
Image recognition,
Image segmentation,
Laboratories,
Pattern recognition,
Humans,
Cognition"
Impact of Load Frequency Dependence on the NDZ and Performance of the SFS Islanding Detection Method,"Sandia frequency shift (SFS) falls under the active islanding detection methods that rely on frequency drift to detect an islanding condition for inverter-based distributed generation. Active islanding detection methods are commonly tested on constant RLC loads where the load's active power is directly proportional to the square of voltage and is independent on the system frequency. Since the SFS method relies primarily on frequency to detect islanding, the load's active power frequency dependence could have an impact on its performance and the nondetection zone (NDZ). In this paper, the impact of the load's active power frequency dependence on the performance of the SFS method, during an islanding condition, is analyzed. A NDZ model that takes into account the load's frequency dependence parameter is derived mathematically and validated through digital simulation. The results show that the load's frequency dependence has a significant impact on the NDZ of the SFS method and thus is an important factor to consider when designing and testing this method.",
Electric-Field Intrabody Communication Channel Modeling With Finite-Element Method,"Electric-field intrabody communication (EF-IBC) is a promising new scheme for the data exchange among wearable biomedical sensors. It uses the body as the signal transmission media. Compared with existing body area network (BAN) schemes, EF-IBC can achieve higher data rate with less transmission power. Until now, the detailed EF-IBC channel mechanism is not well understood. In this work, finite-element method (FEM) is utilized for the first time to investigate the EF-IBC channel. A circuit-coupled FEM model is established for the EF-IBC channel. The FEM model is extensively verified by experimental measurements. The new physical model enables the revelation of characteristics and effects of different components in the EF-IBC channel. The FEM investigation finds that the capacitive return path is critical to the characteristics of the EF-IBC channel. Parameters of the capacitive return path are quantitatively measured. The investigation also finds that the body plays an important role to the return path capacitance. The forward body path can be well modeled by a cascade of π-shaped circuits. Based on the FEM model of the EF-IBC channel, a simplified circuit model is derived to provide an efficient tool for the transceiver design.","Integrated circuit modeling,
Finite element methods,
Electrodes,
Capacitance,
Couplings,
Impedance,
Atmospheric modeling"
Learning hierarchical poselets for human parsing,"We consider the problem of human parsing with part-based models. Most previous work in part-based models only considers rigid parts (e.g. torso, head, half limbs) guided by human anatomy. We argue that this representation of parts is not necessarily appropriate for human parsing. In this paper, we introduce hierarchical poselets-a new representation for human parsing. Hierarchical poselets can be rigid parts, but they can also be parts that cover large portions of human bodies (e.g. torso + left arm). In the extreme case, they can be the whole bodies. We develop a structured model to organize poselets in a hierarchical way and learn the model parameters in a max-margin framework. We demonstrate the superior performance of our proposed approach on two datasets with aggressive pose variations.",
Towards Decentralization: A Topological Investigation of the Medium and Low Voltage Grids,"The traditional power grid has been designed in a hierarchical fashion, with energy pushed from the large scale production factories towards the end users. With the increasing availability of micro and medium scale generating facilities, the situation is changing. Many end users can now produce energy and share it over the power grid. Of course, end users need incentives to do so and want to act in an open decentralized energy market. In the present work, we offer a novel analysis of the medium and low voltage power grids of the North Netherlands using statistical tools from the complex network analysis field. We use a weighted model based on actual grid data and propose a set of statistical measures to evaluate the adequacy of the current infrastructure for a decentralized energy market. Further, we use the insight gained by the analysis to propose parameters that tie the statistical topological measures to economic factors that influence the attractiveness of participating in such decentralized energy market, thus identifying the important topological parameters to work on to facilitate such open decentralized markets.",
Fast Algorithms to Implement N-FINDR for Hyperspectral Endmember Extraction,"The N-finder algorithm (N-FINDR) suffers from several issues in its practical implementation. One is its search region which is usually the entire data space. Another related issue is its excessive computation. A third issue is its use of random initial conditions which causes inconsistency in final results that can not be reproducible if a search for endmembers is not exhaustive. This paper resolves the first two issues by developing two approaches to speed-up of the N-FINDR computation while implementing a recently developed random pixel purity index (RPPI) to alleviate the third issue. First of all, it narrows down the search region for the N-FINDR to a feasible range, called region of interest (ROI), where two ways are proposed, data sphering/thresholding and RPPI, to be used as a pre-processing to find a desired ROI. Second, three methods are developed to reduce computing load of simplex volume computation by simplifying matrix determinant. Third, to further reduce computational complexity three sequential N-FINDR algorithms are implemented by finding one endmember after another in sequence instead of finding all endmembers together at once. The conducted experiments demonstrate that while the proposed fast algorithms can greatly reduce computational complexity, their performance remains as good as the N-FINDR is and is not compromised by reduction of the search region to an ROI.","Algorithm design and analysis,
Indexes,
Hyperspectral imaging,
Radiation detectors,
Computational complexity,
Principal component analysis"
Energy provisioning in wireless rechargeable sensor networks,"Wireless rechargeable sensor networks (WRSNs) have emerged as an alternative to solving the challenges of size and operation time posed by traditional battery-powered systems. In this paper, we study a WRSN built from the industrial wireless identification and sensing platform (WISP) and commercial off-the-shelf RFID readers. The paper-thin WISP tags serve as sensors and can harvest energy from RF signals transmitted by the readers. This kind of WRSNs is highly desirable for indoor sensing and activity recognition, and is gaining attention in the research community. One fundamental question in WRSN design is how to deploy readers in a network to ensure that the WISP tags can harvest sufficient energy for continuous operation. We refer to this issue as the energy provisioning problem. Based on a practical wireless recharge model supported by experimental data, we investigate two forms of the problem: point provisioning and path provisioning. Point provisioning uses the least number of readers to ensure that a static tag placed in any position of the network will receive a sufficient recharge rate for sustained operation. Path provisioning exploits the potential mobility of tags (e.g., those carried by human users) to further reduce the number of readers necessary: mobile tags can harvest excess energy in power-rich regions and store it for later use in power-deficient regions. Our analysis shows that our deployment methods, by exploiting the physical characteristics of wireless recharging, can greatly reduce the number of readers compared with those assuming traditional coverage models.",
"X-ray Categorization and Retrieval on the Organ and Pathology Level, Using Patch-Based Visual Words","In this study we present an efficient image categorization and retrieval system applied to medical image databases, in particular large radiograph archives. The methodology is based on local patch representation of the image content, using a “bag of visual words” approach. We explore the effects of various parameters on system performance, and show best results using dense sampling of simple features with spatial content, and a nonlinear kernel-based support vector machine (SVM) classifier. In a recent international competition the system was ranked first in discriminating orientation and body regions in X-ray images. In addition to organ-level discrimination, we show an application to pathology-level categorization of chest X-ray data, the most popular examination in radiology. The system discriminates between healthy and pathological cases, and is also shown to successfully identify specific pathologies in a set of chest radiographs taken from a routine hospital examination. This is a first step towards similarity-based categorization, which has a major clinical implications for computer-assisted diagnostics.","Visualization,
Dictionaries,
Histograms,
Feature extraction,
Medical diagnostic imaging,
Image representation"
Microwatt Embedded Processor Platform for Medical System-on-Chip Applications,"Battery life specifications drive the power consumption requirements of integrated circuits in implantable, wearable, and portable medical devices. In this paper, we present an embedded processor platform chip using an ARM Cortex-M3 suitable for mapping medical applications requiring microwatt power consumption. Ultra-low-power operation is achieved via 0.5-1.0 V operation, a 28 fW/bit fully differential subthreshold 6T SRAM, a 90%-efficient DC-DC converter, and a 100-nJ fast Fourier transform (FFT) accelerator to reduce processor workload. Using a combination of novel circuit design, system architecture, and SoC implementation, the first sub-microwatt per channel electroencephalograph (EEG) seizure detection is demonstrated.",
Cloud Task Scheduling Based on Load Balancing Ant Colony Optimization,"The cloud computing is the development of distributed computing, parallel computing and grid computing, or defined as the commercial implementation of these computer science concepts. One of the fundamental issues in this environment is related to task scheduling. Cloud task scheduling is an NP-hard optimization problem, and many meta-heuristic algorithms have been proposed to solve it. A good task scheduler should adapt its scheduling strategy to the changing environment and the types of tasks. This paper proposes a cloud task scheduling policy based on Load Balancing Ant Colony Optimization (LBACO) algorithm. The main contribution of our work is to balance the entire system load while trying to minimizing the make span of a given tasks set. The new scheduling strategy was simulated using the CloudSim toolkit package. Experiments results showed the proposed LBACO algorithm outperformed FCFS (First Come First Serve) and the basic ACO (Ant Colony Optimization).","Processor scheduling,
Computational modeling,
Heuristic algorithms,
Load management,
Job shop scheduling,
Ant colony optimization"
Tactile-Object Recognition From Appearance Information,"This paper explores the connection between sensor-based perception and exploration in the context of haptic object identification. The proposed approach combines 1) object recognition from tactile appearance with 2) purposeful haptic exploration of unknown objects to extract appearance information. The recognition component brings to bear computer-vision techniques by viewing tactile-sensor readings as images. We present a bag-of-features framework that uses several tactile-image descriptors, some that are adapted from the vision domain and others that are novel, to estimate a probability distribution over object identity as an unknown object is explored. Haptic exploration is treated as a search problem in a continuous space to take advantage of sampling-based motion planning to explore the unknown object and construct its tactile appearance. Simulation experiments of a robot arm equipped with a haptic sensor at the end-effector provide promising validation, thereby indicating high accuracy in identifying complex shapes from tactile information gathered during exploration. The proposed approach is also validated by using readings from actual tactile sensors to recognize real objects.","Feature extraction,
Tactile sensors,
Geometry,
Surface treatment,
Haptic interfaces"
Socially Assistive Robotics,"Socially assistive robotics (SAR) aims to address critical areas and gaps in care by automating supervision, coaching, motivation, and companion ship aspects of one-on-one interactions with individuals from various large and growing populations, including stroke survivors, the elderly and individuals with dementia, and children with autism spectrum disorders (ASDs). This article examines the ethical challenges of SAR from three points of view (user, caregiver, and peer) using core principles from medical ethics (autonomy, beneficence, nonmaleficence, and justice) to determine how intended and unintended effects of SAR can impact the delivery of care.","Robots,
Human factors,
Senior citizens,
Ethics,
Medical services,
Patient rehabilitation"
"An introduction to the good, the bad, & the ugly face recognition challenge problem","The Good, the Bad, & the Ugly Face Challenge Problem was created to encourage the development of algorithms that are robust to recognition across changes that occur in still frontal faces. The Good, the Bad, & the Ugly consists of three partitions. The Good partition contains pairs of images that are considered easy to recognize. On the Good partition, the base verification rate (VR) is 0.98 at a false accept rate (FAR) of 0.001. The Bad partition contains pairs of images of average difficulty to recognize. For the Bad partition, the VR is 0.80 at a FAR of 0.001. The Ugly partition contains pairs of images considered difficult to recognize, with a VR of 0.15 at a FAR of 0.001. The base performance is from fusing the output of three of the top performers in the FRVT 2006. The design of the Good, the Bad, & the Ugly controls for pose variation, subject aging, and subject “recognizability.” Subject recognizability is controlled by having the same number of images of each subject in every partition. This implies that the differences in performance among the partitions are result of how a face is presented in each image.",
Open-Loop Spatial Multiplexing and Diversity Communications in Ad Hoc Networks,"This paper investigates the performance of open-loop multi-antenna point-to-point links in ad hoc networks with slotted ALOHA medium access control (MAC). We consider spatial multiplexing transmission with linear maximum ratio combining and zero forcing receivers, as well as orthogonal space time block coded transmission. New closed-form expressions are derived for the outage probability, throughput and transmission capacity. Our results demonstrate that both the best performing scheme and the optimum number of transmit antennas depend on different network parameters, such as the node intensity and the signal-to-interference-and-noise ratio operating value. We then compare the performance to a network consisting of single-antenna devices and an idealized fully centrally coordinated MAC. These results show that multi-antenna schemes with a simple decentralized slotted ALOHA MAC can outperform even idealized single-antenna networks in various practical scenarios.","Receivers,
Multiplexing,
Interference,
Transmitters,
Signal to noise ratio,
Ad hoc networks,
Throughput"
PACP: An Efficient Pseudonymous Authentication-Based Conditional Privacy Protocol for VANETs,"In this paper, we propose a new privacy preservation scheme, named pseudonymous authentication-based conditional privacy (PACP), which allows vehicles in a vehicular ad hoc network (VANET) to use pseudonyms instead of their true identity to obtain provably good privacy. In our scheme, vehicles interact with roadside units to help them generate pseudonyms for anonymous communication. In our setup, the pseudonyms are only known to the vehicles but have no other entities in the network. In addition, our scheme provides an efficient revocation mechanism that allows vehicles to be identified and revoked from the network if needed. Thus, we provide conditional privacy to the vehicles in the system, that is, the vehicles will be anonymous in the network until they are revoked, at which point, they cease to be anonymous.","Vehicles,
Privacy,
Protocols,
Roads,
Public key,
Encryption"
"Emergency Fall Incidents Detection in Assisted Living Environments Utilizing Motion, Sound, and Visual Perceptual Components","This paper presents the implementation details of a patient status awareness enabling human activity interpretation and emergency detection in cases, where the personal health is threatened like elder falls or patient collapses. The proposed system utilizes video, audio, and motion data captured from the patient's body using appropriate body sensors and the surrounding environment, using overhead cameras and microphone arrays. Appropriate tracking techniques are applied to the visual perceptual component enabling the trajectory tracking of persons, while proper audio data processing and sound directionality analysis in conjunction to motion information and subject's visual location can verify fall and indicate an emergency event. The postfall visual and motion behavior of the subject, which indicates the severity of the fall (e.g., if the person remains unconscious or patient recovers) is performed through a semantic representation of the patient's status, context and rules-based evaluation, and advanced classification. A number of advanced classification techniques have been examined in the framework of this study and their corresponding performance in terms of accuracy and efficiency in detecting an emergency situation has been thoroughly assessed.",
Scale invariant cosegmentation for image groups,"Our primary interest is in generalizing the problem of Cosegmentation to a large group of images, that is, concurrent segmentation of common foreground region(s) from multiple images. We further wish for our algorithm to offer scale invariance (foregrounds may have arbitrary sizes in different images) and the running time to increase (no more than) near linearly in the number of images in the set. What makes this setting particularly challenging is that even if we ignore the scale invariance desiderata, the Cosegmentation problem, as formalized in many recent papers (except), is already hard to solve optimally in the two image case. A straightforward extension of such models to multiple images leads to loose relaxations; and unless we impose a distributional assumption on the appearance model, existing mechanisms for image-pair-wise measurement of foreground appearance variations lead to significantly large problem sizes (even for moderate number of images). This paper presents a surprisingly easy to implement algorithm which performs well, and satisfies all requirements listed above (scale invariance, low computational requirements, and viability for the multiple image setting). We present qualitative and technical analysis of the properties of this framework.",
A Distributed Key Management Framework with Cooperative Message Authentication in VANETs,"In this paper, we propose a distributed key management framework based on group signature to provision privacy in vehicular ad hoc networks (VANETs). Distributed key management is expected to facilitate the revocation of malicious vehicles, maintenance of the system, and heterogeneous security policies, compared with the centralized key management assumed by the existing group signature schemes. In our framework, each road side unit (RSU) acts as the key distributor for the group, where a new issue incurred is that the semi-trust RSUs may be compromised. Thus, we develop security protocols for the scheme which are able to detect compromised RSUs and their colluding malicious vehicles. Moreover, we address the issue of large computation overhead due to the group signature implementation. A practical cooperative message authentication protocol is thus proposed to alleviate the verification burden, where each vehicle just needs to verify a small amount of messages. Details of possible attacks and the corresponding solutions are discussed. We further develop a medium access control (MAC) layer analytical model and carry out NS2 simulations to examine the key distribution delay and missed detection ratio of malicious messages, with the proposed key management framework being implemented over 802.11 based VANETs.","Vehicles,
Protocols,
Privacy,
Public key,
Roads,
Safety"
Coherent Versus Non-Coherent Decode-and-Forward Relaying Aided Cooperative Space-Time Shift Keying,"Motivated by the recent concept of Space-Time Shift Keying (STSK), we propose a novel cooperative STSK family, which is capable of achieving a flexible rate-diversity tradeoff, in the context of cooperative space-time transmissions. More specifically, we first propose a Coherent cooperative STSK (CSTSK) scheme, where each Relay Node (RN) activates Decode and-Forward (DF) transmissions, depending on the success or failure of Cyclic Redundancy Checking (CRC). We invoke a bit to-STSK mapping rule, where according to the input bits, one of the Q pre-assigned dispersion vectors is activated to implicitly convey log2 Q bits, which are transmitted in combination with the classic log2 L-bit modulated symbol. Additionally, we introduce a beneficial dispersion vector design, which enables us to dispense with symbol-level Inter-Relay Synchronization (IRS). Further more, the Destination Node (DN) is capable of jointly detecting the signals received from the source-destination and relay destination links, using a low-complexity single-stream-based Maximum Likelihood (ML) detector, which is an explicit benefit of our Inter-Element Interference (IEI)-free system model. More importantly, as a benefit of its design flexibility, our cooperative CSTSK arrangement enables us to adapt the number of the RNs, the transmission rate as well as the achievable diversity order. Moreover, we also propose a Differentially-encoded cooperative STSK (DSTSK) arrangement, which dispenses with CSI estimation at any of the nodes, while retaining the fundamental benefits of the cooperative CSTSK scheme.",
Set-Membership Constrained Particle Filter: Distributed Adaptation for Sensor Networks,"Target tracking is investigated using particle filtering of data collected by distributed sensors. In lieu of a fusion center, local measurements must be disseminated across the network for each sensor to implement a centralized particle filter (PF). However, disseminating raw measurements incurs formidable communication overhead as large volumes of data are collected by the sensors. To reduce this overhead and thus enable distributed PF implementation, the present paper develops a set-membership constrained (SMC) PF approach that i) exhibits performance comparable to the centralized PF; ii) requires only communication of particle weights among neighboring sensors; and iii) can afford both consensus-based and incremental averaging implementations. These attractive attributes are effected through a novel adaptation scheme, which is amenable to simple distributed implementation using min- and max-consensus iterations. The resultant SMC-PF exhibits high gain over the bootstrap PF when the likelihood is peaky, but not in the tail of the prior. Simulations corroborate that for a fixed number of particles, and subject to peaky likelihood conditions, SMC-PF outperforms the bootstrap PF, as well as recently developed distributed PF algorithms, by a wide margin.",
Perpetual and Fair Data Collection for Environmental Energy Harvesting Sensor Networks,"Renewable energy enables sensor networks with the capability to recharge and provide perpetual data services. Due to low recharging rates and the dynamics of renewable energy such as solar and wind power, providing services without interruptions caused by battery runouts is nontrivial. Most environment monitoring applications require data collection from all nodes at a steady rate. The objective of this paper is to design a solution for fair and high throughput data extraction from all nodes in the presence of renewable energy sources. Specifically, we seek to compute the lexicographically maximum data collection rate and routing paths for each node such that no node will ever run out of energy. We propose a centralized algorithm and two distributed algorithms. The centralized algorithm jointly computes the optimal data collection rate for all nodes along with the flows on each link, the first distributed algorithm computes the optimal rate when the routing structure is a given tree, and the second distributed algorithm, although heuristic, jointly computes a routing structure and a high lexicographic rate assignment that is nearly optimum. We prove the optimality for the centralized and the first distributed algorithm, and use real test-bed experiments and extensive simulations to evaluate both of the distributed algorithms.","Batteries,
Routing,
Distributed algorithms,
Energy harvesting,
Monitoring,
Renewable energy resources,
Resource management"
Millimeter-Wave Wafer-Scale Silicon BiCMOS Power Amplifiers Using Free-Space Power Combining,This paper presents the first millimeter-wave wafer-scale power-amplifier array implemented in a 0.13-μ m BiCMOS technology. The power combining is done in the free-space using high efficiency on-chip antennas. A 3 × 3 power-amplifier array is demonstrated with an equivalent isotropic radiated power of 33-35 dBm at 90-98 GHz. This results in a total on-chip power of 21-23 dBm and a total radiated power of 17.5-19.5 dBm. The measured patterns of the array show single-mode operation and ~100% free-space power-combining efficiency with a 3-dB beamwidth of 28° and a directivity of 15.5 dB (gain of 12 dB). The total power-combining efficiency including the antenna losses is 45±10%. The application areas are in millimeter-wave transmitters and wafer-scale phased arrays.,"Arrays,
Microstrip antenna arrays,
Silicon,
System-on-a-chip,
Coplanar waveguides,
Radio frequency"
Season: Shelving interference and joint identification in large-scale RFID systems,"Prior work on anti-collision for Radio Frequency IDentification (RFID) systems usually schedule adjacent readers to exclusively interrogate tags for avoiding reader collisions. Although such a pattern can effectively deal with collisions, the lack of readers' collaboration wastes numerous time on the scheduling process and dramatically degrades the throughput of identification. Even worse, the tags within the overlapped interrogation regions of adjacent readers (termed as contentious tags), even if the number of such tags is very small, introduce a significant delay to the identification process. In this paper, we propose a new strategy for collision resolution. First, we shelve the collisions and identify the tags that do not involve reader collisions. Second, we perform a joint identification, in which adjacent readers collaboratively identify the contentious tags. In particular, we find that neighboring readers can cause a new type of collisions, cross-tag-collision, which may impede the joint identification. We propose a protocol stack, named Season, to undertake the tasks in two phases and solve the cross-tag-collision. We conduct extensive simulations and preliminary implementation to demonstrate the efficiency of our scheme. The results show that our scheme can achieve above 6 times improvement on the identification throughput in a large-scale dense reader environment.",Probes
Weakly supervised object detector learning with model drift detection,"A conventional approach to learning object detectors uses fully supervised learning techniques which assumes that a training image set with manual annotation of object bounding boxes are provided. The manual annotation of objects in large image sets is tedious and unreliable. Therefore, a weakly supervised learning approach is desirable, where the training set needs only binary labels regarding whether an image contains the target object class. In the weakly supervised approach a detector is used to iteratively annotate the training set and learn the object model. We present a novel weakly supervised learning framework for learning an object detector. Our framework incorporates a new initial annotation model to start the iterative learning of a detector and a model drift detection method that is able to detect and stop the iterative learning when the detector starts to drift away from the objects of interest. We demonstrate the effectiveness of our approach on the challenging PASCAL 2007 dataset.","Detectors,
Training,
Measurement,
Histograms,
Adaptation models,
Object detection,
Support vector machines"
Artificial Noise Generation from Cooperative Relays for Everlasting Secrecy in Two-Hop Wireless Networks,"The secure transmission of information in wireless networks without knowledge of eavesdropper channels or locations is considered. Two key mechanisms are employed: artificial noise generation from system nodes other than the transmitter and receiver, and a form of multi-user diversity that allows message reception in the presence of the artificial noise. We determine the maximum number of independently-operating and uniformly distributed eavesdroppers that can be present while the desired secrecy is achieved with high probability in the limit of a large number of system nodes. While our main motivation is considering eavesdroppers of unknown location, we first consider the case where the path-loss is identical between all pairs of nodes. In this case, a number of eavesdroppers that is exponential in the number of systems nodes can be tolerated. In the case of uniformly distributed eavesdroppers of unknown location, any number of eavesdroppers whose growth is sub-linear in the number of system nodes can be tolerated. The proposed approach significantly outperforms a power control approach based on standard multi-user diversity.","Network security,
Protocols,
Signal to noise ratio,
Receivers,
Interference,
Military communication,
Wireless networks,
Privacy"
Impact of Traffic Influxes: Revealing Exponential Intercontact Time in Urban VANETs,"Intercontact time between moving vehicles is one of the key metrics in vehicular ad hoc networks (VANETs) and central to forwarding algorithms and the end-to-end delay. Due to prohibitive costs, little work has conducted experimental study on intercontact time in urban vehicular environments. In this paper, we carry out an extensive experiment involving thousands of operational taxies in Shanghai city. Studying the taxi trace data on the frequency and duration of transfer opportunities between taxies, we observe that the tail distribution of the intercontact time, that is, the time gap separating two contacts of the same pair of taxies, exhibits an exponential decay, over a large range of timescale. This observation is in sharp contrast to recent empirical data studies based on human mobility, in which the distribution of the intercontact time obeys a power law. By analyzing a simplified mobility model that captures the effect of hot areas in the city, we rigorously prove that common traffic influxes, where large volume of traffic converges, play a major role in generating the exponential tail of the intercontact time. Our results thus provide fundamental guidelines on design of new vehicular mobility models in urban scenarios, new data forwarding protocols and their performance analysis.","Vehicle ad hoc networks,
Urban areas,
Global Positioning System,
Analytical models,
Data analysis,
Roads"
Low-Power Ultrawideband Wireless Telemetry Transceiver for Medical Sensor Applications,"An integrated CMOS ultrawideband wireless telemetry transceiver for wearable and implantable medical sensor applications is reported in this letter. This high duty cycled, noncoherent transceiver supports scalable data rate up to 10 Mb/s with energy efficiency of 0.35 nJ/bit and 6.2 nJ/bit for transmitter and receiver, respectively. A prototype wireless capsule endoscopy using the proposed transceiver demonstrated in vivo image transmission of 640 × 480 resolution at a frame rate of 2.5 frames/s with 10 Mb/s data rate.","Transceivers,
Wireless communication,
Wireless sensor networks,
Receivers,
Transmitters,
Telemetry,
Voltage-controlled oscillators"
Single-Antenna Doppler Radars Using Self and Mutual Injection Locking for Vital Sign Detection With Random Body Movement Cancellation,"This work presents a single-antenna self-injection-locked (SIL) radar to reduce the hardware complexity of continuous-wave (CW) Doppler systems. The theory provides a basis for determining the signal-to-noise spectral density ratio (SNDR) with the effects of clutter. Experimental results agree closely with the theoretical predictions, showing that the clutter does not affect the optimal SNR performance in an SIL radar. A single-antenna SIL radar array is designed to detect vital signs with random body movement cancellation. To this end, a subject is placed between two single-antenna SIL radars to measure the rates of respiration and heartbeat using Doppler shift, and the effects of random movement of the subject are cancelled by wireless mutual injection locking (MIL) of the two radars. In an experiment, a prototype of such a two-radar array with a spacing of 2 m was implemented at 2.4 GHz, providing accurate and reliable cardiopulmonary monitoring of a subject who jogged on a treadmill with random body motion of many centimeters.",
Limitations of Linear Control Over Packet Drop Networks,"In this paper, we investigate control across stochastic dropout channels. In particular, we consider the Mean Square Stability of a SISO plant in the case there is only one channel in the feedback loop and the case where both actuator and sensor channels are present. We seek optimal networked control schemes that are memoryless functions of channel state information and for each channel state are otherwise linear and time invariant functions of channel output. We establish a fundamental limit on the dropout probability allowable for the Mean Square Stability of the closed loop system. The maximal tolerable dropout probability is only a function of the unstable eigenvalues of the plant. When either the actuator or the sensor channel is present, we propose a receiver structure that can stabilize the system under the worst dropout probability; moreover, we can simultaneously design the optimal controller and receiver and show that they can be implemented in physically separated locations (decentralized). When both actuator and sensor channels are present in the loop, the main result is a centralized stabilization technique that always achieves the fundamental bound via noiseless acknowledgement from the actuation receiver. Finally, we extend the results to the more general case where also the acknowledgements are lost with a given probability and compute how the unreliable delivery of the acknowledgements affects the minimal quality of service required of the actuator and sensor channels.","Receivers,
Actuators,
Fading,
Quality of service,
Random variables,
Channel state information,
Switches"
Self-Tuning for Maximized Lifetime Energy-Efficiency in the Presence of Circuit Aging,"This paper presents an integrated framework, together with control policies, for optimizing dynamic control of self-tuning parameters of a digital system over its lifetime in the presence of circuit aging. A variety of self-tuning parameters such as supply voltage, operating clock frequency, and dynamic cooling are considered, and jointly optimized using efficient algorithms described in this paper. Our optimized self-tuning approach satisfies performance constraints at all times, and maximizes a lifetime computational power efficiency (LCPE) metric, which is defined as the total number of clock cycles achieved over lifetime divided by the total energy consumed over lifetime. We present three control policies: 1) progressive-worst-case-aging (PWCA), which assumes worst-case aging at all times; 2) progressive-on-state-aging (POSA), which estimates aging by tracking active/sleep modes, and then assumes worst-case aging in active mode and long recovery effects in sleep mode; and 3) progressive-real-time-aging-assisted (PRTA), which acquires real-time information and initiates optimized control actions. Various flavors of these control policies for systems with dynamic voltage and frequency scaling (DVFS) are also analyzed. Simulation results on benchmark circuits, using aging models validated by 45 nm measurements, demonstrate the effectiveness and practicality of our approach in significantly improving LCPE and/or lifetime compared to traditional one-time worst-case guardbanding. We also derive system design guidelines to maximize self-tuning benefits.","Aging,
Threshold voltage,
Clocks,
Delay,
Cooling,
Logic gates,
Voltage control"
Digital Image Authentication From JPEG Headers,"It is often desirable to determine if an image has been modified in any way from its original recording. The JPEG format affords engineers many implementation trade-offs which give rise to widely varying JPEG headers. We exploit these variations for image authentication. A camera signature is extracted from a JPEG image consisting of information about quantization tables, Huffman codes, thumbnails, and exchangeable image file format (EXIF). We show that this signature is highly distinct across 1.3 million images spanning 773 different cameras and cell phones. Specifically, 62% of images have a signature that is unique to a single camera, 80% of images have a signature that is shared by three or fewer cameras, and 99% of images have a signature that is unique to a single manufacturer. The signature of Adobe Photoshop is also shown to be unique relative to all 773 cameras. These signatures are simple to extract and offer an efficient method to establish the authenticity of a digital image.","Cameras,
Quantization,
Transform coding,
Image resolution,
Software,
Discrete cosine transforms,
Authentication"
NoSQL evaluation: A use case oriented survey,"Motivated by requirements of Web 2.0 applications, a plethora of non-relational databases raised in recent years. Since it is very difficult to choose a suitable database for a specific use case, this paper evaluates the underlying techniques of NoSQL databases considering their applicability for certain requirements. These systems are compared by their data models, query possibilities, concurrency controls, partitioning and replication opportunities.","Data models,
Database languages,
Servers,
Availability,
Relational databases,
Complexity theory"
Sum Capacity of MIMO Interference Channels in the Low Interference Regime,"Using Gaussian inputs and treating interference as noise at the receivers has recently been shown to be sum capacity achieving for the two-user single-input single-output (SISO) Gaussian interference channel in a low interference regime, where the interference levels are below certain thresholds. In this paper, such a low interference regime is characterized for multiple-input multiple-output (MIMO) Gaussian interference channels. Conditions are provided on the direct and cross channel gain matrices under which using Gaussian inputs and treating interference as noise at the receivers is sum capacity achieving. For the special cases of the symmetric multiple-input single-output (MISO) and single-input multiple-output (SIMO) Gaussian interference channels, more explicit expressions for the low interference regime are derived. In particular, the threshold on the interference levels that characterize low interference regime is related to the input SNR and the angle between the direct and cross channel gain vectors. It is shown that the low interference regime can be quite significant for MIMO interference channels, with the low interference threshold being at least as large as the sine of the angle between the direct and cross channel gain vectors for the MISO and SIMO cases.","Interference channels,
MIMO,
Covariance matrix,
Noise,
Receivers,
Optimization"
Robust Model Predictive Control With Integral Sliding Mode in Continuous-Time Sampled-Data Nonlinear Systems,"This paper proposes a control strategy for nonlinear constrained continuous-time uncertain systems which combines robust model predictive control (MPC) with sliding mode control (SMC). In particular, the so-called Integral SMC approach is used to produce a control action aimed to reduce the difference between the nominal predicted dynamics of the closed-loop system and the actual one. In this way, the MPC strategy can be designed on a system with a reduced uncertainty. In order to prove the stability of the overall control scheme, some general regional input-to-state practical stability results for continuous-time systems are proved.","Uncertainty,
Robustness,
Stability analysis,
Manifolds,
Sliding mode control,
Predictive control"
Fully Gravure-Printed D Flip-Flop on Plastic Foils Using Single-Walled Carbon-Nanotube-Based TFTs,"Since D flip-flop is one of the indispensable building blocks in integrated circuit (IC) design, providing a successful way to print D flip-flop on plastic foils will be the first step to reach fully printed flexible IC. Here, the network structure of single-walled carbon nanotubes (SWNTs) as an active layer has been employed to print the driver and load thin-film transistors (TFTs) of the D flip-flop. The same physical dimensions of driver and load TFTs were first developed to fully gravure print the D flip-flop because of the advantage of tunable electrical properties of network density of SWNTs. Therefore, the circuit design and printing becomes simpler and more convenient than using general design rules. Furthermore, the SWNT network structure in the active layer can also minimize the fluctuation of threshold voltages (Vth) of SWNT-TFTs because of the use of the same physical dimensions in TFTs. The resulting gravure-printed D flip-flop shows a clock-to-output delay of 23 ms for 20-Hz clock signal. This is the first reported D flip-flop performance using all gravure-printing method yet achieved.","Thin film transistors,
Printing,
Clocks,
Plastics,
Electrodes,
Latches,
Inverters"
Compositional Modeling and Analysis of Multi-Hop Control Networks,"We propose a mathematical framework for modeling and analyzing multi-hop control networks designed for systems consisting of multiple control loops closed over a multi-hop (wireless) communication network. We separate control, topology, routing, and scheduling and propose formal syntax and semantics for the dynamics of the composed system, providing an explicit translation of multi-hop control networks to switched systems. We propose formal models for analyzing robustness of multi-hop control networks, where data is exchanged through a multi-hop communication network subject to disruptions. When communication disruptions are long, compared to the speed of the control system, we propose to model them as permanent link failures. We show that the complexity of analyzing such failures is NP-hard, and discuss a way to overcome this limitation for practical cases using compositional analysis. For typical packet transmission errors, we propose a transient error model where links fail for one time slot independently of the past and of other links. We provide sufficient conditions for almost sure stability in presence of transient link failures, and give efficient decision procedures. We deal with errors that have random time span and show that, under some conditions, the permanent failure model can be used as a reliable abstraction. Our approach is compositional, namely it addresses the problem of designing scalable scheduling and routing policies for multiple control loops closed on the same multi-hop control network. We describe how the translation of multi-hop control networks to switched systems can be automated, and use it to solve control and networking co-design challenges in some representative examples, and to propose a scheduling solution in a mineral floatation control problem that can be implemented on a time triggered communication protocols for wireless networks.","Control systems,
Spread spectrum communication,
Schedules,
Wireless sensor networks,
Sensors,
Wireless communication,
Computational modeling"
Reduced-Complexity Decoder Architecture for Non-Binary LDPC Codes,"Non-binary low-density parity-check (NB-LDPC) codes can achieve better error-correcting performance than binary LDPC codes when the code length is moderate at the cost of higher decoding complexity. The high complexity is mainly caused by the complicated computations in the check node processing and the large memory requirement. In this paper, a novel check node processing scheme and corresponding VLSI architectures are proposed for the Min-max NB-LDPC decoding algorithm. The proposed scheme first sorts out a limited number of the most reliable variable-to-check (v-to-c) messages, then the check-to-variable (c-to-v) messages to all connected variable nodes are derived independently from the sorted messages without noticeable performance loss. Compared to the previous iterative forward-backward check node processing, the proposed scheme not only significantly reduced the computation complexity, but eliminated the memory required for storing the intermediate messages generated from the forward and backward processes. Inspired by this novel c-to-v message computation method, we propose to store the most reliable v-to-c messages as “compressed” c-to-v messages. The c-to-v messages will be recovered from the compressed format when needed. Accordingly, the memory requirement of the overall decoder can be substantially reduced. Compared to the previous Min-max decoder architecture, the proposed design for a (837, 726) code over GF(25) can achieve the same throughput with only 46% of the area.","Parity check codes,
Costs,
Very large scale integration,
Computer architecture,
Iterative decoding,
Gain,
Convolutional codes,
Iterative algorithms,
Performance loss,
Throughput"
Predicting solar generation from weather forecasts using machine learning,"A key goal of smart grid initiatives is significantly increasing the fraction of grid energy contributed by renewables. One challenge with integrating renewables into the grid is that their power generation is intermittent and uncontrollable. Thus, predicting future renewable generation is important, since the grid must dispatch generators to satisfy demand as generation varies. While manually developing sophisticated prediction models may be feasible for large-scale solar farms, developing them for distributed generation at millions of homes throughout the grid is a challenging problem. To address the problem, in this paper, we explore automatically creating site-specific prediction models for solar power generation from National Weather Service (NWS) weather forecasts using machine learning techniques. We compare multiple regression techniques for generating prediction models, including linear least squares and support vector machines using multiple kernel functions. We evaluate the accuracy of each model using historical NWS forecasts and solar intensity readings from a weather station deployment for nearly a year. Our results show that SVM-based prediction models built using seven distinct weather forecast metrics are 27% more accurate for our site than existing forecast-based models.","Predictive models,
Weather forecasting,
Measurement,
Kernel,
Support vector machines,
Correlation"
Transmit-Diversity-Assisted Space-Shift Keying for Colocated and Distributed/Cooperative MIMO Elements,"Space-shift keying (SSK) modulation is a recently proposed multiple-input-multiple-output (MIMO) technique, which activates only a single transmit antenna during each time slot and uses the specific index of the activated transmit antenna to implicitly convey information. Activating a single antenna is beneficial in terms of eliminating the interchannel interference and mitigates the peak-to-mean power ratio while avoiding the need for synchronization among transmit antennas. However, this benefit is achieved at a sacrifice, because the transmit diversity gain potential of the multiple transmit antennas is not fully exploited in existing SSK-assisted systems. Furthermore, a high-SSK throughput requires the transmitter to employ a high number of transmit antennas, which is not always practical. Hence, we propose four algorithms-open-loop space-time space-shift keying (ST-SSK), closed-loop feedback-aided phase rotation, feedback-aided power allocation, and cooperative ST-SSK-to achieve a diversity gain. The performance improvements of the proposed schemes are demonstrated by Monte Carlo simulations for spatially independent Rayleigh fading channels. Their robustness to channel estimation errors is also considered. We advocate the proposed ST-SSK techniques, which can achieve a transmit diversity gain of about 10 dB at a bit error rate (BER) of 10-5, at the cost of imposing a moderate throughput loss that is dedicated to a modest feedback overhead. Furthermore, our proposed ST-SSK scheme lends itself to efficient communication, because the deleterious effects of deep shadow fading no longer impose spatial correlation on the signals that are received by the antennas, which cannot readily be avoided by colocated antenna elements.","Transmitting antennas,
Receiving antennas,
Modulation,
Antenna arrays,
Indexes,
Slot antennas"
EEG-based emotion recognition during watching movies,"This study aims at finding the relationship between EEG signals and human emotions. EEG signals are used to classify two kinds of emotions, positive and negative. First, we extracted features from original EEG data and used a linear dynamic system approach to smooth these features. An average test accuracy of 87.53% was obtained by using all of the features together with a support vector machine. Next, we reduced the dimension of features through correlation coefficients. The top 100 and top 50 subject-independent features were achieved, with average test accuracies of 89.22% and 84.94%, respectively. Finally, a manifold model was applied to find the trajectory of emotion changes.",
A SysML-Based Methodology for Manufacturing Machinery Modeling and Design,"This paper describes a modeling methodology to support the design process of complex systems. The main challenge in modern industrial applications is the sheer volume of data involved in the design process. While using high-level abstraction is necessary to manage this data and analyze the system “as a whole,” designers need also to retain all the low-level information of the system, in order to be able to perform optimizations and modifications at later times. The solution proposed here is to use a hierarchy of models, each one describing the system at different levels of abstraction, and arrange them in such a way that it is possible to easily “map” each level onto the others. The topmost layer of the system description is expressed in System Modeling Language, a general-purpose modeling language based on Unified Modeling Language.",
A Power-Efficient Neural Tissue Stimulator With Energy Recovery,"This paper presents a power-efficient neural stimulator integrated circuit, designed to take advantage of our understanding of iridium-oxide electrode impedance. It efficiently creates a programmable set of voltage supplies directly from a secondary power telemetry coil, then switches the target electrode sequentially through the voltage steps. This sequence of voltages mimics the voltage of the electrode under the constant current drive, resulting in approximately constant current without the voltage drop of the more commonly used linear current source. This method sacrifices some precision, but drastically reduces the series losses seen in traditional current sources and attains power savings of 53%-66% compared to these designs. The proof-of-concept circuit consumes 125 μW per electrode and was fabricated in a 1.5-μm CMOS process, in a die area of 4.76 mm2.",
Architectures for online error detection and recovery in multicore processors,"The huge investment in the design and production of multicore processors may be put at risk because the emerging highly miniaturized but unreliable fabrication technologies will impose significant barriers to the life-long reliable operation of future chips. Extremely complex, massively parallel, multi-core processor chips fabricated in these technologies will become more vulnerable to: (a) environmental disturbances that produce transient (or soft) errors, (b) latent manufacturing defects as well as aging/wearout phenomena that produce permanent (or hard) errors, and (c) verification inefficiencies that allow important design bugs to escape in the system. In an effort to cope with these reliability threats, several research teams have recently proposed multicore processor architectures that provide low-cost dependability guarantees against hardware errors and design bugs. This paper focuses on dependable multicore processor architectures that integrate solutions for online error detection, diagnosis, recovery, and repair during field operation. It discusses taxonomy of representative approaches and presents a qualitative comparison based on: hardware cost, performance overhead, types of faults detected, and detection latency. It also describes in more detail three recently proposed effective architectural approaches: a software-anomaly detection technique (SWAT), a dynamic verification technique (Argus), and a core salvaging methodology.","Multicore processing,
Hardware,
Program processors,
Maintenance engineering,
Built-in self-test"
Adaptive Fuzzy Interpolation,"Fuzzy interpolative reasoning strengthens the power of fuzzy inference by the enhancement of the robustness of fuzzy systems and the reduction of the systems' complexity. However, after a series of interpolations, it is possible that multiple object values for a common variable are inferred, leading to inconsistency in interpolated results. Such inconsistencies may result from defective interpolated rules or incorrect interpolative transformations. This paper presents a novel approach for identification and correction of defective rules in interpolative transformations, thereby removing the inconsistencies. In particular, an assumption-based truth-maintenance system (ATMS) is used to record dependences between interpolations, and the underlying technique that the classical general diagnostic engine (GDE) employs for fault localization is adapted to isolate possible faulty interpolated rules and their associated interpolative transformations. From this, an algorithm is introduced to allow for the modification of the original linear interpolation to become first-order piecewise linear. The approach is applied to a realistic problem, which predicates the diarrheal disease rates in remote villages, to demonstrate the potential of this study.","Interpolation,
Fuzzy sets,
Fuzzy reasoning"
Comparison of Combinational and Sequential Error Rates for a Deep Submicron Process,"It has been predicted that upsets due to Single-Event Transients (SETs) in logic circuits will increase significantly with higher operating frequency and technology scaling. For synchronous circuits manufactured at advanced technology nodes, errors due to single-event transients are expected to exceed those due to latch upsets. Experimental results presented in this paper quantify the contribution of logic errors to the total Soft-Error Rate (SER) for test circuits fabricated in a 40 nm bulk CMOS technology. These results can be used to develop guidelines to assist circuit designers adopt effective hardening strategies to reduce the SER, while meeting performance specifications for high speed logic circuits.","Single event transient,
Radiation hardening,
Logic circuits,
Error analysis,
Combinational logic circuits,
Transient analysis"
"Optimal Scheduling of Multicluster Tools With Constant Robot Moving Times, Part II: Tree-Like Topology Configurations","In this paper, we analyze optimal scheduling of a tree-like multicluster tool with single-blade robots and constant robot moving times. We present a recursive minimal cycle time algorithm to reveal a multi-unit resource cycle for multicluster tools under a given robot schedule. For a serial-cluster tool, we provide a closed-form formulation for the minimal cycle time. The formulation explicitly provides the interaction relationship among clusters. We further present decomposition conditions under which the optimal scheduling of multicluster becomes much easier and straightforward. Optimality conditions for the widely used robot pull schedule are also provided. An example from industry production is used to illustrate the analytical results. The decomposition and optimality conditions for the robot pull schedule are also illustrated by Monte Carlo simulation for the industrial example.","Optimal scheduling,
Topology,
Job shop scheduling,
Processor scheduling,
Clustering algorithms,
Service robots,
Chemical analysis,
Planarization,
Scheduling algorithm,
Industrial relations"
Evaluation of Stereoscopic Images: Beyond 2D Quality,"Perceived image quality is a standard evaluation concept for 2D imaging systems. When applied to stereoscopic 3D imaging systems, however, it does not incorporate the added value of stereoscopic depth. Higher level evaluation concepts (naturalness and viewing experience) are proposed that are sensitive to both image quality and stereoscopic depth. A 3D Quality Model is constructed in which such higher level evaluation concepts are expressed as a weighted sum of image quality and perceived depth. This model is validated by means of three experiments, in which stereoscopic depth (camera base distances and screen disparity) and image quality (white Gaussian noise and Gaussian blur) are varied. The resulting stimuli are evaluated in terms of naturalness, viewing experience, image quality and depth percept. Analysis revealed that viewing experience and naturalness incorporated variations in image quality to a similar extent, yet the added value of stereoscopic depth is incorporated significantly more by naturalness. This result classifies naturalness as the most appropriate concept to evaluate 3D quality of stereoscopic stills. The 3D Quality Model based on naturalness as evaluation concept is validly applicable to stereoscopic stills and the naturalness score is determined for approximately 75% by image quality and for approximately 25% by the added value of stereoscopic depth.","Image quality,
Three dimensional displays,
Noise,
Solid modeling,
Imaging,
Pixel,
Image color analysis"
Regularized Background Adaptation: A Novel Learning Rate Control Scheme for Gaussian Mixture Modeling,"To model a scene for background subtraction, Gaussian mixture modeling (GMM) is a popular choice for its capability of adaptation to background variations. However, GMM often suffers from a tradeoff between robustness to background changes and sensitivity to foreground abnormalities and is inefficient in managing the tradeoff for various surveillance scenarios. By reviewing the formulations of GMM, we identify that such a tradeoff can be easily controlled by adaptive adjustments of the GMM's learning rates for image pixels at different locations and of distinct properties. A new rate control scheme based on high-level feedback is then developed to provide better regularization of background adaptation for GMM and to help resolving the tradeoff. Additionally, to handle lighting variations that change too fast to be caught by GMM, a heuristic rooting in frame difference is proposed to assist the proposed rate control scheme for reducing false foreground alarms. Experiments show the proposed learning rate control scheme, together with the heuristic for adaptation of over-quick lighting change, gives better performance than conventional GMM approaches.","Pixel,
Adaptation model,
Computational modeling,
Maintenance engineering,
Sensitivity,
Feedback control,
Robustness"
Spectral Embedded Clustering: A Framework for In-Sample and Out-of-Sample Spectral Clustering,"Spectral clustering (SC) methods have been successfully applied to many real-world applications. The success of these SC methods is largely based on the manifold assumption, namely, that two nearby data points in the high-density region of a low-dimensional data manifold have the same cluster label. However, such an assumption might not always hold on high-dimensional data. When the data do not exhibit a clear low-dimensional manifold structure (e.g., high-dimensional and sparse data), the clustering performance of SC will be degraded and become even worse than K -means clustering. In this paper, motivated by the observation that the true cluster assignment matrix for high-dimensional data can be always embedded in a linear space spanned by the data, we propose the spectral embedded clustering (SEC) framework, in which a linearity regularization is explicitly added into the objective function of SC methods. More importantly, the proposed SEC framework can naturally deal with out-of-sample data. We also present a new Laplacian matrix constructed from a local regression of each pattern and incorporate it into our SEC framework to capture both local and global discriminative information for clustering. Comprehensive experiments on eight real-world high-dimensional datasets demonstrate the effectiveness and advantages of our SEC framework over existing SC methods and K-means-based clustering methods. Our SEC framework significantly outperforms SC using the Nyström algorithm on unseen data.",
Segmentation of Intra-Retinal Layers From Optical Coherence Tomography Images Using an Active Contour Approach,"Optical coherence tomography (OCT) is a noninvasive, depth-resolved imaging modality that has become a prominent ophthalmic diagnostic technique. We present a semi-automated segmentation algorithm to detect intra-retinal layers in OCT images acquired from rodent models of retinal degeneration. We adapt Chan-Vese's energy-minimizing active contours without edges for the OCT images, which suffer from low contrast and are highly corrupted by noise. A multiphase framework with a circular shape prior is adopted in order to model the boundaries of retinal layers and estimate the shape parameters using least squares. We use a contextual scheme to balance the weight of different terms in the energy functional. The results from various synthetic experiments and segmentation results on OCT images of rats are presented, demonstrating the strength of our method to detect the desired retinal layers with sufficient accuracy even in the presence of intensity inhomogeneity resulting from blood vessels. Our algorithm achieved an average Dice similarity coefficient of 0.84 over all segmented retinal layers, and of 0.94 for the combined nerve fiber layer, ganglion cell layer, and inner plexiform layer which are the critical layers for glaucomatous degeneration.","Retina,
Image segmentation,
Shape,
Erbium,
Level set,
Rodents,
Biomedical imaging"
Bayesian Nonparametric Inference of Switching Dynamic Linear Models,"Many complex dynamical phenomena can be effectively modeled by a system that switches among a set of conditionally linear dynamical modes. We consider two such models: the switching linear dynamical system (SLDS) and the switching vector autoregressive (VAR) process. Our Bayesian nonparametric approach utilizes a hierarchical Dirichlet process prior to learn an unknown number of persistent, smooth dynamical modes. We additionally employ automatic relevance determination to infer a sparse set of dynamic dependencies allowing us to learn SLDS with varying state dimension or switching VAR processes with varying autoregressive order. We develop a sampling algorithm that combines a truncated approximation to the Dirichlet process with efficient joint sampling of the mode and state sequences. The utility and flexibility of our model are demonstrated on synthetic data, sequences of dancing honey bees, the IBOVESPA stock index and a maneuvering target tracking application.","Hidden Markov models,
Switches,
Bayesian methods,
Superluminescent diodes,
Biological system modeling,
Electronic mail,
Signal processing"
Multiclass recognition and part localization with humans in the loop,"We propose a visual recognition system that is designed for fine-grained visual categorization. The system is composed of a machine and a human user. The user, who is unable to carry out the recognition task by himself, is interactively asked to provide two heterogeneous forms of information: clicking on object parts and answering binary questions. The machine intelligently selects the most informative question to pose to the user in order to identify the object's class as quickly as possible. By leveraging computer vision and analyzing the user responses, the overall amount of human effort required, measured in seconds, is minimized. We demonstrate promising results on a challenging dataset of uncropped images, achieving a significant average reduction in human effort over previous methods.","image recognition,
computer vision"
Mobility Support for Health Monitoring at Home Using Wearable Sensors,"We present a simple but effective handoff protocol that enables continuous monitoring of ambulatory patients at home by means of resource-limited sensors. Our proposed system implements a 2-tier network: one created by wearable sensors used for vital signs collection, and another by a point-to-point link established between the body sensor network coordinator device and a fixed access point (AP). Upon experiencing poor signal reception in the latter network tier when the patient moves, the AP may instruct the sensor network coordinator to forward vital signs data through one of the wearable sensor nodes acting as a temporary relay if the sensor-AP link has a stronger signal. Our practical implementation of the proposed scheme reveals that this relayed data operation decreases packet loss rate down to 20% of the value otherwise obtained when solely using the point-to-point, coordinator-AP link. In particular, the wrist location yields the best results over alternative body sensor positions when patients walk at a 0.5 m/s.","Monitoring,
Protocols,
Relays,
Medical services,
Wearable sensors,
Wireless communication"
Demand side management for Wind Power Integration in microgrid using dynamic potential game theory,"We propose a novel demand side management method to tackle the intermittency in wind power generation. Our focus is on an isolated microgrid with one wind turbine, one fast-responding conventional generator, and several users. Users act as independent decision makers in shaping their own load profiles. Using dynamic potential game theory, we analyze and coordinate the interactions among users to efficiently utilize the available renewable and conventional energy resources to minimize the total energy cost in the system. We further model the inter-temporal variations of the available wind power as a Markov chain based on field data. Using techniques from dynamic potential game theory, we first derive closed-form expressions for the best responses for the users that participate in demand side management. Then, we investigate the efficiency of the constructed game model at the equilibrium. Finally, the system performance is assessed using computer simulation. In particular, our proposed scheme saves 38% generation cost compared with the case without demand side management.",
IR-Tree: An Efficient Index for Geographic Document Search,"Given a geographic query that is composed of query keywords and a location, a geographic search engine retrieves documents that are the most textually and spatially relevant to the query keywords and the location, respectively, and ranks the retrieved documents according to their joint textual and spatial relevances to the query. The lack of an efficient index that can simultaneously handle both the textual and spatial aspects of the documents makes existing geographic search engines inefficient in answering geographic queries. In this paper, we propose an efficient index, called IR-tree, that together with a top-k document search algorithm facilitates four major tasks in document searches, namely, 1) spatial filtering, 2) textual filtering, 3) relevance computation, and 4) document ranking in a fully integrated manner. In addition, IR-tree allows searches to adopt different weights on textual and spatial relevance of documents at the runtime and thus caters for a wide variety of applications. A set of comprehensive experiments over a wide range of scenarios has been conducted and the experiment results demonstrate that IR-tree outperforms the state-of-the-art approaches for geographic document searches.","Search engines,
Joints,
Frequency measurement,
Web pages,
Indexing,
Niobium"
Ontology-Based Unified Robot Knowledge for Service Robots in Indoor Environments,"A significant obstacle for service robots is the execution of complex tasks in real environments. For example, it is not easy for service robots to find objects that are partially observable and are located at a place which is not identical but near the place where the robots saw them previously. To overcome the challenge effectively, robot knowledge represented as a semantic network can be extremely useful. This paper presents an ontology-based unified robot knowledge framework that integrates low-level data with high-level knowledge for robot intelligence. This framework consists of two sections: knowledge description and knowledge association. Knowledge description includes comprehensively integrated robot knowledge derived from low-level knowledge regarding perceptual features, part objects, metric maps, and primitive behaviors, as well as high-level knowledge about perceptual concepts, objects, semantic maps, tasks, and contexts. Knowledge association uses logical inference with both unidirectional and bidirectional rules. This characteristic enables reasoning to be performed even when only a partial information is available. The experimental results that demonstrate the advantages of using the proposed knowledge framework are also presented.",
Computerized Classification of Intraductal Breast Lesions Using Histopathological Images,"In the diagnosis of preinvasive breast cancer, some of the intraductal proliferations pose a special challenge. The continuum of intraductal breast lesions includes the usual ductal hyperplasia (UDH), atypical ductal hyperplasia (ADH), and ductal carcinoma in situ (DCIS). The current standard of care is to perform percutaneous needle biopsies for diagnosis of palpable and image-detected breast abnormalities. UDH is considered benign and patients diagnosed UDH undergo routine follow-up, whereas ADH and DCIS are considered actionable and patients diagnosed with these two subtypes get additional surgical procedures. About 250 000 new cases of intraductal breast lesions are diagnosed every year. A conservative estimate would suggest that at least 50% of these patients are needlessly undergoing unnecessary surgeries. Thus, improvement in the diagnostic reproducibility and accuracy is critically important for effective clinical management of these patients. In this study, a prototype system for automatically classifying breast microscopic tissues to distinguish between UDH and actionable subtypes (ADH and DCIS) is introduced. This system automatically evaluates digitized slides of tissues for certain cytological criteria and classifies the tissues based on the quantitative features derived from the images. The system is trained using a total of 327 regions of interest (ROIs) collected across 62 patient cases and tested with a sequestered set of 149 ROIs collected across 33 patient cases. An overall accuracy of 87.9% is achieved on the entire test data. The test accuracy of 84.6% is obtained with borderline cases (26 of the 33 test cases) only, when compared against the diagnostic accuracies of nine pathologists on the same set (81.2% average), indicates that the system is highly competitive with the expert pathologists as a stand-alone diagnostic tool and has a great potential in improving diagnostic accuracy and reproducibility when used as a “second reader” in conjunction with the pathologists.","Lesions,
Image segmentation,
Breast,
Training,
Pixel,
Accuracy,
Image color analysis"
Designing Compact and Maximally Permissive Deadlock Avoidance Policies for Complex Resource Allocation Systems Through Classification Theory: The Linear Case,"Most of the past research on the problem of deadlock avoidance for complex resource allocation systems (RAS) has acknowledged the fact that the computation of the maximally permissive deadlock avoidance policy (DAP) possesses super-polynomial complexity for most RAS classes, and therefore, it has resorted to solutions that trade off maximal permissiveness for computational tractability. In this paper, we distinguish between the off-line and the on-line computation that is required for the effective implementation of the maximally permissive DAP, and we seek to develop representations of this policy that will require minimal on-line computation. The particular representation that we adopt is that of a compact classifier that will effect the underlying dichotomy of the reachable state space into safe and unsafe subspaces. Furthermore, in this first study of the aforementioned problem, we restrict our attention to a particular RAS class that is motivated by an ongoing project of ours called Gadara, and accepts separation of the safe and unsafe subspaces of its instantiations through a set of linear inequalities. Through a series of reductions of the derived classification problem, we are also able to attain extensive reductions in the computational complexity of the off-line task of the construction of the sought classifier. We formally establish completeness and optimality properties for the proposed design procedures. We also offer heuristics that, if necessary, can alleviate the computational effort that is necessary for the construction of the sought classifier. Finally, we demonstrate the efficacy of the developed approaches through a series of computational experiments. To the best of our knowledge, these experiments also establish the ability of the proposed methodology to effectively compute tractable implementations of the maximally permissive DAP for problem instances significantly beyond the capacity of any other approach currently available in the literature.",
Parametric Methods for Anomaly Detection in Aggregate Traffic,"This paper develops parametric methods to detect network anomalies using only aggregate traffic statistics, in contrast to other works requiring flow separation, even when the anomaly is a small fraction of the total traffic. By adopting simple statistical models for anomalous and background traffic in the time domain, one can estimate model parameters in real time, thus obviating the need for a long training phase or manual parameter tuning. The proposed bivariate parametric detection mechanism (bPDM) uses a sequential probability ratio test, allowing for control over the false positive rate while examining the tradeoff between detection time and the strength of an anomaly. Additionally, it uses both traffic-rate and packet-size statistics, yielding a bivariate model that eliminates most false positives. The method is analyzed using the bit-rate signal-to-noise ratio (SNR) metric, which is shown to be an effective metric for anomaly detection. The performance of the bPDM is evaluated in three ways. First, synthetically generated traffic provides for a controlled comparison of detection time as a function of the anomalous level of traffic. Second, the approach is shown to be able to detect controlled artificial attacks over the University of Southern California (USC), Los Angeles, campus network in varying real traffic mixes. Third, the proposed algorithm achieves rapid detection of real denial-of-service attacks as determined by the replay of previously captured network traces. The method developed in this paper is able to detect all attacks in these scenarios in a few seconds or less.","Aggregates,
Feature extraction,
Computer crime,
Computational modeling,
Entropy,
Training,
Signal to noise ratio"
Normalization of Face Illumination Based on Large-and Small-Scale Features,"A face image can be represented by a combination of large-and small-scale features. It is well-known that the variations of illumination mainly affect the large-scale features (low-frequency components), and not so much the small-scale features. Therefore, in relevant existing methods only the small-scale features are extracted as illumination-invariant features for face recognition, while the large-scale intrinsic features are always ignored. In this paper, we argue that both large-and small-scale features of a face image are important for face restoration and recognition. Moreover, we suggest that illumination normalization should be performed mainly on the large-scale features of a face image rather than on the original face image. A novel method of normalizing both the Small-and Large-scale (S&L) features of a face image is proposed. In this method, a single face image is first decomposed into large-and small-scale features. After that, illumination normalization is mainly performed on the large-scale features, and only a minor correction is made on the small-scale features. Finally, a normalized face image is generated by combining the processed large-and small-scale features. In addition, an optional visual compensation step is suggested for improving the visual quality of the normalized image. Experiments on CMU-PIE, Extended Yale B, and FRGC 2.0 face databases show that by using the proposed method significantly better recognition performance and visual results can be obtained as compared to related state-of-the-art methods.","Lighting,
Face,
Feature extraction,
Face recognition,
Visualization,
Discrete cosine transforms"
Efficient Sequential Switching Hybrid-Modulation Techniques for Cascaded Multilevel Inverters,"This paper presents four different sequential switching hybrid-modulation strategies and compared for cascaded multilevel inverters. Hybrid-modulation strategies represent combinations of fundamental-frequency modulation and multilevel sinusoidal-modulation (MSPWM) strategies, and are designed for performance of the well-known alternative phase opposition disposition, phase-shifted carrier, carrier-based space-vector modulation, and single-carrier sinusoidal-modulations. The main characteristic of these modulations are the reduction of switching losses with good harmonic performance, balanced power loss dissipation among the devices with in a cell, and among the series-connected cells. MSPWM and its base modulator design are implemented on a TMS320F2407 digital signal processor (DSP). Complex programmable logic device realizes hybrid-modulation algorithm with base pulsewidth modulation (PWM) circulation, and is integrated with DSP for sequential switching hybrid PWM generation. The proposed modulations can be easily extended to three phase, and higher level inverters, operates with same physical structure of the power module. The feasibility of these hybrid modulations are verified through spectral analysis, power loss analysis, simulation, and experimental results.","Inverters,
Pulse width modulation,
Frequency modulation,
Phase modulation,
Power harmonic filters,
Harmonic analysis"
On deep generative models with applications to recognition,"The most popular way to use probabilistic models in vision is first to extract some descriptors of small image patches or object parts using well-engineered features, and then to use statistical learning tools to model the dependencies among these features and eventual labels. Learning probabilistic models directly on the raw pixel values has proved to be much more difficult and is typically only used for regularizing discriminative methods. In this work, we use one of the best, pixel-level, generative models of natural images-a gated MRF-as the lowest level of a deep belief network (DBN) that has several hidden layers. We show that the resulting DBN is very good at coping with occlusion when predicting expression categories from face images, and it can produce features that perform comparably to SIFT descriptors for discriminating different types of scene. The generative ability of the model also makes it easy to see what information is captured and what is lost at each level of representation.",
Heterojunction Vertical Band-to-Band Tunneling Transistors for Steep Subthreshold Swing and High on Current,"We propose a heterojunction vertical tunneling field-effect transistor and show using self-consistent ballistic quantum transport simulations that it can provide very steep subthreshold swings and high on current, thereby improving the scalability of TFETs for high performance. The turn-on in the pocket region of the device is dictated by the modulation of heterojunction barrier height. The steepness of turn-on is increased because of simultaneous onset of tunneling in the pocket and the region underneath and also due to the contribution of vertical tunneling in the pocket to the current. These factors can be engineered by tuning heterojunction band offsets.","Tunneling,
Logic gates,
Heterojunctions,
Transistors,
Performance evaluation,
Doping"
Securing communication in 6LoWPAN with compressed IPsec,"Real-world deployments of wireless sensor networks (WSNs) require secure communication. It is important that a receiver is able to verify that sensor data was generated by trusted nodes. It may also be necessary to encrypt sensor data in transit. Recently, WSNs and traditional IP networks are more tightly integrated using IPv6 and 6LoWPAN. Available IPv6 protocol stacks can use IPsec to secure data exchange. Thus, it is desirable to extend 6LoWPAN such that IPsec communication with IPv6 nodes is possible. It is beneficial to use IPsec because the existing end-points on the Internet do not need to be modified to communicate securely with the WSN. Moreover, using IPsec, true end-to-end security is implemented and the need for a trustworthy gateway is removed. In this paper we provide End-to-End (E2E) secure communication between IP enabled sensor networks and the traditional Internet. This is the first compressed lightweight design, implementation, and evaluation of 6LoWPAN extension for IPsec. Our extension supports both IPsec's Authentication Header (AH) and Encapsulation Security Payload (ESP). Thus, communication endpoints are able to authenticate, encrypt and check the integrity of messages using standardized and established IPv6 mechanisms.","IP networks,
Authentication,
Wireless sensor networks,
Internet,
Encoding,
Cryptography"
Addressing link-level design tradeoffs for integrated photonic interconnects,"Integrated photonic interconnects have emerged recently as a potential solution for relieving on-chip and chip-to-chip bandwidth bottlenecks for next-generation many-core processors. To help bridge the gap between device and circuit/system designers, and aid in understanding of inherent photonic link tradeoffs, we present a set of link component models for performing interconnect design-space exploration connected to the underlying device and circuit technology. To compensate for process and thermal-induced ring resonator mismatches, we take advantage of device and circuit characteristics to propose an efficient ring tuning solution. Finally, we perform optimization of a wavelength-division-multiplexed link, demonstrating the link-level interactions between components in achieving the optimal degree of parallelism and energy-efficiency.","Optical receivers,
Clocks,
Modulation,
Sensitivity,
Optical buffering,
Photonics"
Game Theoretical Approach for Channel Allocation in Wireless Sensor and Actuator Networks,"In this paper, multi-channel allocation in wireless sensor and actuator networks is formulated as an optimization problem which is NP-hard. In order to efficiently solve this problem, a distributed game based channel allocation (GBCA) Algorithm is proposed by taking into account both network topology and routing information. For both tree/forest routing and non-tree/forest routing scenarios, it is proved that there exists at least one Nash Equilibrium for the problem. Furthermore, the sub- optimality of Nash Equilibrium and the convergence of the Best Response dynamics are also analyzed. Simulation results demonstrate that GBCA significantly reduces the interference and dramatically improves the network performance in terms of delivery ratio, throughput, channel access delay, and energy consumption.","Channel allocation,
Interference,
Games,
Routing,
Receivers,
Wireless sensor networks,
Actuators"
P^{2} : Privacy-Preserving Communication and Precise Reward Architecture for V2G Networks in Smart Grid,"Vehicle-to-grid (V2G) networks are important components of the smart grid (SG) for their capability of providing better ancillary services and facilitating the adoption of renewable resources. The operation of the V2G networks is based on continuously monitoring the status of individual battery vehicle (BV) as well as a carefully designed incentive scheme to attract sufficient participating BVs. However, the close monitoring tends to raise privacy concerns from the BV owners about identity and location information leakage, which have not been considered in previous works. In this paper, we make the first attempt to identify the privacy-preserving issues and propose a precise reward scheme in V2G networks, both of which are important towards bringing the concept of V2G network into practice. In V2G networks, it is the service providers (individual BVs) who need privacy protection rather than the service consumer (power grid). This unique characteristic renders privacy protection solutions proposed for conventional network systems not directly applicable. To protect privacy of BVs in V2G networks, we present , a secure communication architecture which achieves privacy-preserving for both BVs' monitoring and rewarding processes. Extensive performance analysis shows that only incurs moderate communication and computational overheads.","Batteries,
Power grids,
Intelligent vehicles,
Incentive schemes,
Computer security"
The Capacity Region of Multiway Relay Channels Over Finite Fields With Full Data Exchange,"The multiway relay channel is a multicast network where L users exchange data through a relay. In this paper, the capacity region of a class of multiway relay channels is derived, where the channel inputs and outputs take values over finite fields. The cut-set upper bound to the capacity region is derived and is shown to be achievable by our proposed functional-decode-forward coding strategy. More specifically, for the general case where the users can transmit at possibly different rates, functional-decode-forward, combined with rate splitting and joint source-channel decoding, is proved to achieve the capacity region; while for the case where all users transmit at a common rate, rate splitting and joint source-channel decoding are not required to achieve the capacity. That the capacity-achieving coding strategies do not utilize the users' received signals in the users' encoding functions implies that feedback does not increase the capacity region of this class of multiway relay channels.",
Echocardiographic speckle reduction comparison,"In this paper, a detailed description and comparison of speckle reduction of medical ultrasound, and in particular echocardiography, is presented. Fifteen speckle reduction filters are described in a detailed fashion to facilitate implementation for research and evaluation. The filtering techniques considered include anisotropic diffusion, wavelet denoising, and local statistics. Common nomenclature and notation are adopted, to expedite comparison between approaches. Comparison of the filters is based on their application to simulated images, clinical videos, and a computational requirement analysis. The ultrasound simulation method provides a realistic model of the image acquisition process, and permits the use of a noise-free reference image for comparison. Application of objective quality metrics quantifies the preservation of image edges, overall image distortion, and improvement in image contrast. The computational analysis quantifies the number of operations required for each speckle reduction method. A speed-accuracy analysis of discretization methods for anisotropic diffusion is included. It is concluded that the optimal method is the OSRAD diffusion filter. This method is capable of strong speckle suppression, increasing the average SNRA of the simulated images by a factor of two. This method also shows favorable edge preservation and contrast improvement, and may be efficiently implemented.",
A Programmable Vision Chip Based on Multiple Levels of Parallel Processors,"This paper proposes a novel programmable vision chip based on multiple levels of parallel processors. The chip integrates CMOS image sensor, multiple-levels of SIMD parallel processors and an embedded microprocessor unit (MPU). The multiple-levels of SIMD parallel processors consist of an array processor of SIMD processing elements (PEs) and a column of SIMD row processors (RPs). The PE array and RPs have an O(N × N) parallelism and an O(N) parallelism, respectively. The PE array and RPs can be reconfigured to handle algorithms with different complexities and processing speeds. The PE array, RPs and MPU can execute low-, mid-and high-level image processing algorithms, respectively, which efficiently increases the performance of the vision chip. The vision chip can satisfy flexibly the needs of different vision applications such as image pre-processing, complicated feature extraction and over 1000 fps high-speed image capture. A prototype chip with 128 × 28 image sensor, 128 A/D converters, 32 8-bit RPs and 32 × 128 PEs is fabricated using the 0.18 μm CMOS process. Applications including target tracking, pattern extraction and image recognition are demonstrated.",
Augmented Reality for the Improvement of Remote Laboratories: An Augmented Remote Laboratory,"Augmented reality (AR) provides huge opportunities for online teaching in science and engineering, as these disciplines place emphasis on practical training and unsuited to completely nonclassroom training. This paper proposes a new concept in virtual and remote laboratories: the augmented remote laboratory (ARL). ARL is being tested in the first and second years of the new degrees in industrial engineering and computer engineering, respectively, at the School of Engineering, University of Huelva, Huelva, Spain. By means of augmented reality techniques, ARL allows the student to experience sensations and explore learning experiences that, in some cases, may exceed those offered by traditional laboratory classes. The effectiveness of this methodology for remote laboratory work is evaluated by comparing it to practical sessions in the laboratory at the university itself with the same group of students. Students completed a questionnaire after having experienced both types of practicals, and the results show that the use of ARL improves student outcomes. As discussed in the paper, the potential of AR to configure different experiments from the same physical configuration is virtually limitless.","Remote laboratories,
Education,
Cameras,
Augmented reality,
Control systems,
Materials"
Automatic Optic Disc Detection From Retinal Images by a Line Operator,"Under the framework of computer-aided eye disease diagnosis, this paper presents an automatic optic disc (OD) detection technique. The proposed technique makes use of the unique circular brightness structure associated with the OD, i.e., the OD usually has a circular shape and is brighter than the surrounding pixels whose intensity becomes darker gradually with their distances from the OD center. A line operator is designed to capture such circular brightness structure, which evaluates the image brightness variation along multiple line segments of specific orientations that pass through each retinal image pixel. The orientation of the line segment with the minimum/maximum variation has specific pattern that can be used to locate the OD accurately. The proposed technique has been tested over four public datasets that include 130, 89, 40, and 81 images of healthy and pathological retinas, respectively. Experiments show that the designed line operator is tolerant to different types of retinal lesion and imaging artifacts, and an average OD detection accuracy of 97.4% is obtained.",
"Trust, But Verify: Fast and Accurate Signal Recovery From 1-Bit Compressive Measurements","The recently emerged compressive sensing (CS) framework aims to acquire signals at reduced sample rates compared to the classical Shannon-Nyquist rate. To date, the CS theory has assumed primarily real-valued measurements; it has recently been demonstrated that accurate and stable signal acquisition is still possible even when each measurement is quantized to just a single bit. This property enables the design of simplified CS acquisition hardware based around a simple sign comparator rather than a more complex analog-to-digital converter; moreover, it ensures robustness to gross nonlinearities applied to the measurements. In this paper we introduce a new algorithm - restricted-step shrinkage (RSS) - to recover sparse signals from 1-bit CS measurements. In contrast to previous algorithms for 1-bit CS, RSS has provable convergence guarantees, is about an order of magnitude faster, and achieves higher average recovery signal-to-noise ratio. RSS is similar in spirit to trust-region methods for nonconvex optimization on the unit sphere, which are relatively unexplored in signal processing and hence of independent interest.",
Accurate Supercapacitor Modeling for Energy Harvesting Wireless Sensor Nodes,"Supercapacitors are often used in energy harvesting wireless sensor nodes (EH-WSNs) to store harvested energy. Until now, research into the use of supercapacitors in EH-WSNs has considered them to be ideal or oversimplified, with non-ideal behavior attributed to substantial leakage currents. In this brief, we show that observations previously attributed to leakage are predominantly due to redistribution of charge inside the supercapacitor. We confirm this hypothesis through the development of a circuit-based model, which accurately represents non-ideal behavior. The model correlates well with practical validations representing the operation of an EH-WSN and allows behavior to be simulated over long periods.","Supercapacitors,
Integrated circuit modeling,
Mathematical model,
Discharges,
Wireless sensor networks,
Capacitance"
Domain Structure in CoFeB Thin Films With Perpendicular Magnetic Anisotropy,"Domain structures in CoFeB-MgO thin films with a perpendicular easy magnetization axis were observed by magneto-optic Kerr-effect microscopy at various temperatures. The domain-wall surface energy was obtained by analyzing the spatial period of the stripe domains and fitting established domain models to the period. In combination with superconducting quantum interference device measurements of magnetization and anisotropy energy, this leads to an estimate of the exchange stiffness and domain-wall width in these films. These parameters are essential for determining whether domain walls will form in patterned structures and devices made of such materials.",
Broadband Design of Circularly Polarized Microstrip Patch Antenna Using Artificial Ground Structure With Rectangular Unit Cells,"This paper presents a broadband circularly polarized patch antenna using an artificial ground (AG) structure with rectangular unit cells as a reflector. The AG structure changes the reflection phase in accordance with the polarization state of the incident wave. By properly combining the transmitted wave from the antenna and the reflected wave from the AG structure, broadband circular polarization can be obtained. The AG structure and the antenna are simulated using a full-wave solver and the results show a 10 dB return loss bandwidth of 48.6% and a 3 dB axial ratio bandwidth of 20.4%. The measured results are in good agreement with the simulated results. The radiation characteristics of the antenna are almost the same as those for an antenna with a PEC reflector.","Patch antennas,
Microstrip antennas,
Bandwidth,
Impedance,
Periodic structures,
Microstrip"
Cascade Architecture for Lateral Control in Autonomous Vehicles,"Research on intelligent transport systems (ITSs) is steadily leading to safer and more comfortable control for vehicles. Systems that permit longitudinal control have already been implemented in commercial vehicles, acting on throttle and brake. Nevertheless, lateral control applications are less common in the market. Since a too-sudden turn of the steering wheel can cause an accident in a few seconds, good speed and position control of the steering wheel is essential. We present here a new cascade control architecture based on fuzzy logic controllers that emulate a human driver's behavior. The control architecture was tested on a real vehicle at different vehicle speeds. The results showed the use of a straightforward and intuitive fuzzy controller to give good performance.",
Real-Time Modeling for Direct Load Control in Cyber-Physical Power Systems,"This paper presents an innovative approach to use real-time scheduling techniques for the automation of electric loads in Cyber-Physical Power Systems. The goal is to balance the electric power usage to achieve an optimized upper bound on the power peak load, while guaranteeing specific constraints on the physical process controlled by the electric loads. Timing parameters derived from the scheduling discipline of real-time computing systems are used to model electric devices. Real-time scheduling algorithms can be exploited to achieve the upper bound by predictably and timely switching on/off the devices composing the electrical system. The paper shows the relevance of electric load balancing in power systems to motivate the use of real-time techniques to achieve predictability of electric loads scheduling. Real-Time Physical Systems (RTPS) are introduced as a novel modeling methodology of a physical system based on real-time parameters. They enable the use of traditional real-time system models and scheduling algorithms, with adequate adaptations, to manage loads activation/deactivation. The model of the physical process considered in this work is characterized by uncertainties that are compensated by a suitable feedback control policy, based on the dynamic adaptation of real-time parameter values. A number of relevant relationships between real-time and physical parameters are derived.",
Hyracks: A flexible and extensible foundation for data-intensive computing,"Hyracks is a new partitioned-parallel software platform designed to run data-intensive computations on large shared-nothing clusters of computers. Hyracks allows users to express a computation as a DAG of data operators and connectors. Operators operate on partitions of input data and produce partitions of output data, while connectors repartition operators' outputs to make the newly produced partitions available at the consuming operators. We describe the Hyracks end user model, for authors of dataflow jobs, and the extension model for users who wish to augment Hyracks' built-in library with new operator and/or connector types. We also describe our initial Hyracks implementation. Since Hyracks is in roughly the same space as the open source Hadoop platform, we compare Hyracks with Hadoop experimentally for several different kinds of use cases. The initial results demonstrate that Hyracks has significant promise as a next-generation platform for data-intensive applications.",
The Benefits of Dense Stereo for Pedestrian Detection,"This paper presents a novel pedestrian detection system for intelligent vehicles. We propose the use of dense stereo for both the generation of regions of interest and pedestrian classification. Dense stereo allows the dynamic estimation of camera parameters and the road profile, which, in turn, provides strong scene constraints on possible pedestrian locations. For classification, we extract spatial features (gradient orientation histograms) directly from dense depth and intensity images. Both modalities are represented in terms of individual feature spaces, in which discriminative classifiers (linear support vector machines) are learned. We refrain from the construction of a joint feature space but instead employ a fusion of depth and intensity on the classifier level. Our experiments involve challenging image data captured in complex urban environments (i.e., undulating roads and speed bumps). Our results show a performance improvement by up to a factor of 7.5 at the classification level and up to a factor of 5 at the tracking level (reduction in false alarms at constant detection rates) over a system with static scene constraints and intensity-only classification.","Cameras,
Feature extraction,
Stereo vision,
Intelligent vehicles,
Support vector machines"
A Novel Inpainting-Based Layered Depth Video for 3DTV,"Layered Depth Video (LDV) is recognized as a promising 3D video data representation for supporting advanced 3D video services required in Multiview Video (MVV) systems such as Three-Dimensional Television (3DTV). This representation consists of one full or central view in the form of a video-plus-depth sequence as the main layer, and additional enhancement layers including residual texture and depth data that represent side views. LDV is thus both a derivative of and an alternative to Multiview Video-plus-Depth (MVD) representation by only transmit one full view with associated residual data over the channel. There is a risk, however, of residual data information rapidly increasing as the distance between the center view and side views increases. This occurs when parts of the central view are not visible in the side views, leaving blank spots called disocclusions. These disocclusions may grow larger, which increases the amount of residual data that needs to be sent with the main layer. In this paper, we address the residual layer generation problem. We propose an inpainting-based LDV generation method to reduce the amount of residual data to send by retrieving the missing pixels from the main layer. In the proposed method, we take into account the depth information by distinguishing between foreground and background parts of the scene, at low complexity, during the texture and structure propagation stage of the inpainting process. Experimental results demonstrated the effectiveness of the proposed method.",
EHF for Satellite Communications: The New Broadband Frontier,"The exploitation of extremely high-frequency (EHF) bands (30-300 GHz) for broadband transmission over satellite links is currently a hot research topic. In particular, the Q-V band (30-50 GHz) and W-band (75-110 GHz) seem to offer very promising perspectives. This paper aims at presenting an overview of the current status of research and technology in EHF satellite communications and taking a look at future perspectives in terms of applications and services. Challenges and open issues are adequately considered together with some viable solutions and future developments. The proposed analysis highlighted the need for a reliable propagation model based on experimental data acquired in orbit. Other critical aspects should be faced at the PHY-layer level in order to manage the tradeoff between power efficiency, spectral efficiency, and robustness against link distortions. As far as networking aspects are concerned, the large bandwidth availability should be converted into increased throughput by means of suitable radio resource management and transport protocols, able to support very high data rates in long-range aerospace scenarios.","Satellite communication,
Satellite broadcasting,
Broadband communication,
Telecommunication network management,
Bandwidth,
Channel allocation,
Broadband communication"
A Survey of Research on Mobile Cloud Computing,"The rapid development of mobile computing and cloud computing trigger novel computing paradigm-----Mobile Cloud Computing. This paper review current research effort towards Mobile Computing. First, we present several challenges for the design of Mobile Cloud Computing service. Second, a concept model has been proposed to analyze related research work. Third, we survey recent Mobile Cloud Computing architecture, application partition & offloading, and context-aware service.","Mobile communication,
Cloud computing,
Context,
Mobile handsets,
Computational modeling,
Mobile computing,
Computer architecture"
Motion Planning with Complex Goals,"This article describes approach for solving motion planning problems for mobile robots involving temporal goals. Traditional motion planning for mobile robotic systems involves the construction of a motion plan that takes the system from an initial state to a set of goal states while avoiding collisions with obstacles at all times. The motion plan is also required to respect the dynamics of the system that are typically described by a set of differential equations. A wide variety of techniques have been pro posed over the last two decades to solve such problems [1], [2].",
Accurate and Efficient Optic Disc Detection and Segmentation by a Circular Transformation,"Under the framework of computer-aided diagnosis, this paper presents an accurate and efficient optic disc (OD) detection and segmentation technique. A circular transformation is designed to capture both the circular shape of the OD and the image variation across the OD boundary simultaneously. For each retinal image pixel, it evaluates the image variation along multiple evenly-oriented radial line segments of specific length. The pixels with the maximum variation along all radial line segments are determined, which can be further exploited to locate both the OD center and the OD boundary accurately. Experiments show that OD detection accuracies of 99.75%, 97.5%, and 98.77% are obtained for the STARE dataset, the ARIA dataset, and the MESSIDOR dataset, respectively, and the OD center error lies around six pixels for the STARE dataset and the ARIA dataset which is much smaller than that of state-of-the-art methods ranging 14-29 pixels. In addition, the OD segmentation accuracies of 93.4% and 91.7% are obtained for STARE dataset and ARIA dataset, respectively, that consists of many severely degraded images of pathological retinas that state-of-the-art methods cannot segment properly. Furthermore, the algorithm runs in 5 s, which is substantially faster than many of the state-of-the-art methods.","Image segmentation,
Retinal vessels,
Lesions,
Pathology,
Image analysis,
Computer aided diagnosis"
A Unified Analysis of Max-Min Weighted SINR for MIMO Downlink System,"This paper studies the max-min weighted signal-to-interference-plus-noise ratio (SINR) problem in the multiple-input-multiple-output (MIMO) downlink, where multiple users are weighted according to priority and are subject to a weighted-sum-power constraint. First, we study the multiple-input-single-output (MISO) and single-input-multiple- output (SIMO) problems using nonlinear Perron-Frobenius theory. As a by-product, we solve the open problem of convergence for a previously proposed MISO algorithm by Wiesel, Eldar, and Shamai in 2006. Furthermore, we unify our analysis with respect to the previous alternate optimization algorithm proposed by Tan, Chiang, and Srikant in 2009, by showing that our MISO result can, in fact, be derived from their algorithm. Next, we combine our MISO and SIMO results into an algorithm for the MIMO problem. We show that our proposed algorithm is optimal when the channels are rank-one, or when the network is operating in the low signal-to-noise ratio (SNR) region. Finally, we prove the parametric continuity of the MIMO problem in the power constraint, and we use this insight to propose a heuristic initialization strategy for improving the performance of our (generally) suboptimal MIMO algorithm. The proposed initialization strategy exhibits improved performance over random initialization.","Signal to noise ratio,
Interference,
MIMO,
Optimization,
Signal processing algorithms,
Downlink,
Algorithm design and analysis"
Handheld Optical Coherence Tomography Scanner for Primary Care Diagnostics,"The goal of this study is to develop an advanced point-of-care diagnostic instrument for use in a primary care office using handheld optical coherence tomography (OCT). This system has the potential to enable earlier detection of diseases and accurate image-based diagnostics. Our system was designed to be compact, portable, user-friendly, and fast, making it well suited for the primary care office setting. The unique feature of our system is a versatile handheld OCT imaging scanner which consists of a pair of computer-controlled galvanometer-mounted mirrors, interchangeable lens mounts, and miniaturized video camera. This handheld scanner has the capability to guide the physician in real time for finding suspicious regions to be imaged by OCT. In order to evaluate the performance and use of the handheld OCT scanner, the anterior chamber of a rat eye and in vivo human retina, cornea, skin, and tympanic membrane were imaged. Based on this feasibility study, we believe that this new type of handheld OCT device and system has the potential to be an efficient point-of-care imaging tool in primary care medicine.","Biomedical optical imaging,
Optical imaging,
Lenses,
Coherence,
Optical fibers,
Tomography"
Distributed Camera Networks,"Over the past decade, large-scale camera networks have become increasingly prevalent in a wide range of applications, such as security and surveillance, disaster response, and environmental modeling. In many applications, bandwidth constraints, security concerns, and difficulty in storing and analyzing large amounts of data centrally at a single location necessitate the development of distributed camera network architectures. Thus, the development of distributed scene-analysis algorithms has received much attention lately. However, the performance of these algorithms often suffers because of the inability to effectively acquire the desired images, especially when the targets are dispersed over a wide field of view (FOV). In this article, we show how to develop an end-to-end framework for integrated sensing and analysis in a distributed camera network so as to maximize various scene-understanding performance criteria (e.g., tracking accuracy, best shot, and image resolution).","Cameras,
Target tracking,
Signal processing algorithms,
Sensors,
Distributed databases,
Calibration,
Algorithm design and analysis"
Bilateral Normal Filtering for Mesh Denoising,"Decoupling local geometric features from the spatial location of a mesh is crucial for feature-preserving mesh denoising. This paper focuses on first order features, i.e., facet normals, and presents a simple yet effective anisotropic mesh denoising framework via normal field denoising. Unlike previous denoising methods based on normal filtering, which process normals defined on the Gauss sphere, our method considers normals as a surface signal defined over the original mesh. This allows the design of a novel bilateral normal filter that depends on both spatial distance and signal distance. Our bilateral filter is a more natural extension of the elegant bilateral filter for image denoising than those used in previous bilateral mesh denoising methods. Besides applying this bilateral normal filter in a local, iterative scheme, as common in most of previous works, we present for the first time a global, noniterative scheme for an isotropic denoising. We show that the former scheme is faster and more effective for denoising extremely noisy meshes while the latter scheme is more robust to irregular surface sampling. We demonstrate that both our feature-preserving schemes generally produce visually and numerically better denoising results than previous methods, especially at challenging regions with sharp features or irregular sampling.","Noise reduction,
Noise,
Mathematical model,
Equations,
Optimization,
Laplace equations,
Robustness"
Global Finite-Time Observers for Lipschitz Nonlinear Systems,"This technical note presents a global finite-time observer design for a class of systems with Lipschitz nonlinearity. By applying a finite-time stability theorem and a careful selection of the homogeneity powers and weights, the problem of global and finite-time stable observers is studied. An observer design procedure is given and a numerical example is provided to illustrate the design method.","Observers,
Nonlinear systems,
Asymptotic stability,
Riccati equations,
Observability,
Electronic mail,
Lyapunov method"
Real-Time Regularized Ultrasound Elastography,"This paper introduces two real-time elastography techniques based on analytic minimization (AM) of regularized cost functions. The first method (1D AM) produces axial strain and integer lateral displacement, while the second method (2D AM) produces both axial and lateral strains. The cost functions incorporate similarity of radio-frequency (RF) data intensity and displacement continuity, making both AM methods robust to small decorrelations present throughout the image. We also exploit techniques from robust statistics to make the methods resistant to large local decorrelations. We further introduce Kalman filtering for calculating the strain field from the displacement field given by the AM methods. Simulation and phantom experiments show that both methods generate strain images with high SNR, CNR and resolution. Both methods work for strains as high as 10% and run in real-time. We also present in vivo patient trials of ablation monitoring. An implementation of the 2D AM method as well as phantom and clinical RF-data can be downloaded.","Strain,
Equations,
Mathematical model,
Ultrasonic imaging,
Cost function,
Decorrelation,
Robustness"
A Cooperative Clustering Protocol for Energy Saving of Mobile Devices with WLAN and Bluetooth Interfaces,"One of the most widely used wireless communication standards is a Wireless Local Area Network (WLAN) (IEEE 802.11). However, WLAN has a serious power consumption problem. In this paper, we propose a novel energy saving approach that exploits the multiradio feature of recent mobile devices equipped with WLAN and Bluetooth interfaces. Unlike previous approaches, our work is based on clustering. In our work, a cluster is a Bluetooth Personal Area Network (PAN), which consists of one cluster head and several regular nodes. The cluster head acts as a gateway between the PAN and the WLAN, enabling the regular nodes to access the WLAN infrastructure via low-power Bluetooth. We present a distributed clustering protocol, Cooperative Networking protocol (CONET), which dynamically reforms clusters according to each node's bandwidth requirement, energy use, and application type. CONET does not require modifications of existing wireless infrastructures because clustering is performed independently of WLAN access points. We implemented the CONET prototype with four wearable computing devices to evaluate the performance on real hardware. We also simulated CONET for large networks of more than 100 mobile nodes. Both results demonstrate that our approach is effective in reducing the power consumption of WLAN.","Wireless LAN,
Bluetooth,
Bandwidth,
Protocols,
Mobile handsets,
Wireless communication,
Cost function"
A One-Layer Recurrent Neural Network for Pseudoconvex Optimization Subject to Linear Equality Constraints,"In this paper, a one-layer recurrent neural network is presented for solving pseudoconvex optimization problems subject to linear equality constraints. The global convergence of the neural network can be guaranteed even though the objective function is pseudoconvex. The finite-time state convergence to the feasible region defined by the equality constraints is also proved. In addition, global exponential convergence is proved when the objective function is strongly pseudoconvex on the feasible region. Simulation results on illustrative examples and application on chemical process data reconciliation are provided to demonstrate the effectiveness and characteristics of the neural network.","Recurrent neural networks,
Optimization,
Convergence,
Vectors,
Transient analysis,
Convex functions"
Decentralized Dynamic Surface Control of Large-Scale Interconnected Systems in Strict-Feedback Form Using Neural Networks With Asymptotic Stabilization,"A novel neural network (NN)-based nonlinear decentralized adaptive controller is proposed for a class of large-scale, uncertain, interconnected nonlinear systems in strict-feedback form by using the dynamic surface control (DSC) principle, thus, the “explosion of complexity” problem which is observed in the conventional backstepping approach is relaxed in both state and output feedback control designs. The matching condition is not assumed when considering the interconnection terms. Then, NNs are utilized to approximate the uncertainties in both subsystem and interconnected terms. By using novel NN weight update laws with quadratic error terms as well as proposed control inputs, it is demonstrated using Lyapunov stability that the system states errors converge to zero asymptotically with both state and output feedback controllers, even in the presence of NN approximation errors in contrast with the uniform ultimate boundedness result, which is common in the literature with NN-based DSC and backstepping schemes. Simulation results show the effectiveness of the approach.","Artificial neural networks,
Interconnected systems,
Output feedback,
Nonlinear systems,
Function approximation,
Backstepping,
Control design"
Natural image denoising: Optimality and inherent bounds,"The goal of natural image denoising is to estimate a clean version of a given noisy image, utilizing prior knowledge on the statistics of natural images. The problem has been studied intensively with considerable progress made in recent years. However, it seems that image denoising algorithms are starting to converge and recent algorithms improve over previous ones by only fractional dB values. It is thus important to understand how much more can we still improve natural image denoising algorithms and what are the inherent limits imposed by the actual statistics of the data. The challenge in evaluating such limits is that constructing proper models of natural image statistics is a long standing and yet unsolved problem. To overcome the absence of accurate image priors, this paper takes a non parametric approach and represents the distribution of natural images using a huge set of 1010 patches. We then derive a simple statistical measure which provides a lower bound on the optimal Bayesian minimum mean square error (MMSE). This imposes a limit on the best possible results of denoising algorithms which utilize a fixed support around a denoised pixel and a generic natural image prior. Our findings suggest that for small windows, state of the art denoising algorithms are approaching optimality and cannot be further improved beyond ~ 0.1dB values.","Noise reduction,
Noise measurement,
Image denoising,
PSNR,
Approximation methods,
Upper bound"
Sparsity-promoting optimal control for a class of distributed systems,"We consider a linear quadratic optimal control problem with an additional penalty on the number of communication links in the distributed controller. We reformulate this combinatorial optimization problem as a sequence of weighted l1 problems, where the weighted l1 norm approximates the counting of the communication links. We identify a class of systems for which the weighted l1 problem can be formulated as a semideflnite program and therefore its solution can be computed efficiently. Application of the developed algorithm to the optimal control of vehicular formations reveals communication topologies that become sparser as the price of inter-vehicular communications is increased.","Optimization,
Vehicles,
Optimal control,
Minimization,
Symmetric matrices,
Lead,
State feedback"
Detection of Abnormal Living Patterns for Elderly Living Alone Using Support Vector Data Description,"In this study, we developed an automated behavior analysis system using infrared (IR) motion sensors to assist the independent living of the elderly who live alone and to improve the efficiency of their healthcare. An IR motion-sensor-based activity-monitoring system was installed in the houses of the elderly subjects to collect motion signals and three different feature values, activity level, mobility level, and nonresponse interval (NRI). These factors were calculated from the measured motion signals. The support vector data description (SVDD) method was used to classify normal behavior patterns and to detect abnormal behavioral patterns based on the aforementioned three feature values. The simulation data and real data were used to verify the proposed method in the individual analysis. A robust scheme is presented in this paper for optimally selecting the values of different parameters especially that of the scale parameter of the Gaussian kernel function involving in the training of the SVDD window length, T of the circadian rhythmic approach with the aim of applying the SVDD to the daily behavior patterns calculated over 24 h. Accuracies by positive predictive value (PPV) were 95.8% and 90.5% for the simulation and real data, respectively. The results suggest that the monitoring system utilizing the IR motion sensors and abnormal-behavior-pattern detection with SVDD are effective methods for home healthcare of elderly people living alone.","Senior citizens,
Monitoring,
Hypertension,
Sensor systems,
Support vector machines"
DNA Sequence Compression Using Adaptive Particle Swarm Optimization-Based Memetic Algorithm,"With the rapid development of high-throughput DNA sequencing technologies, the amount of DNA sequence data is accumulating exponentially. The huge influx of data creates new challenges for storage and transmission. This paper proposes a novel adaptive particle swarm optimization-based memetic algorithm (POMA) for DNA sequence compression. POMA is a synergy of comprehensive learning particle swarm optimization (CLPSO) and an adaptive intelligent single particle optimizer (AdpISPO)-based local search. It takes advantage of both CLPSO and AdpISPO to optimize the design of approximate repeat vector (ARV) codebook for DNA sequence compression. ARV is first introduced in this paper to represent the repeated fragments across multiple sequences in direct, mirror, pairing, and inverted patterns. In POMA, candidate ARV codebooks are encoded as particles and the optimal solution, which covers the most approximate repeated fragments with the fewest base variations, is identified through the exploration and exploitation of POMA. In each iteration of POMA, the leader particles in the swarm are selected based on weighted fitness values and each leader particle is fine-tuned with an AdpISPO-based local search, so that the convergence of the search in local region is accelerated. A detailed comparison study between POMA and the counterpart algorithms is performed on 29 (23 basic and 6 composite) benchmark functions and 11 real DNA sequences. POMA is observed to obtain better or competitive performance with a limited number of function evaluations. POMA also attains lower bits-per-base than other state-of-the-art DNA-specific algorithms on DNA sequence data. The experimental results suggest that the cooperation of CLPSO and AdpISPO in the framework of memetic algorithm is capable of searching the ARV codebook space efficiently.",
Dynamics of Polarized Optical Injection in 1550-nm VCSELs: Theory and Experiments,"We report novel theoretical results obtained from combining the method of largest Lyapunov exponent (LLE) with the spin-flip model (SFM), including noise, to model a vertical-cavity surface emitting laser (VCSEL) subject to polarized optical injection. The LLE is applied to the numerical solutions in order to automatically calculate stability maps that characterize the dynamics. The SFM has been extended and generalized to allow for optical injection of arbitrary polarization. Measurements on a 1550-nm VCSEL have been used to estimate the values of key parameters for use in the model and with these we demonstrate excellent agreement between theory and experiment.","Vertical cavity surface emitting lasers,
Optical polarization,
Nonlinear optics,
Optical attenuators,
Stability analysis,
Mathematical model,
Laser stability"
Text From Corners: A Novel Approach to Detect Text and Caption in Videos,"Detecting text and caption from videos is important and in great demand for video retrieval, annotation, indexing, and content analysis. In this paper, we present a corner based approach to detect text and caption from videos. This approach is inspired by the observation that there exist dense and orderly presences of corner points in characters, especially in text and caption. We use several discriminative features to describe the text regions formed by the corner points. The usage of these features is in a flexible manner, thus, can be adapted to different applications. Language independence is an important advantage of the proposed method. Moreover, based upon the text features, we further develop a novel algorithm to detect moving captions in videos. In the algorithm, the motion features, extracted by optical flow, are combined with text features to detect the moving caption patterns. The decision tree is adopted to learn the classification criteria. Experiments conducted on a large volume of real video shots demonstrate the efficiency and robustness of our proposed approaches and the real-world system. Our text and caption detection system was recently highlighted in a worldwide multimedia retrieval competition, Star Challenge, by achieving the superior performance with the top ranking.",
SenGuard: Passive user identification on smartphones using multiple sensors,"User identification and access control have become a high demand feature on mobile devices because those devices are wildly used by employees in corporations and government agencies for business and store increasing amount of sensitive data. This paper describes SenGuard, a user identification framework that enables continuous and implicit user identification service for smartphone. Different from traditional active user authentication and access control, SenGuard leverages availability of multiple sensors on today's smartphones and passively use sensor inputs as sources of user authentication. It extracts sensor modality dependent user identification features from captured sensor data and performs user identification at background. SenGuard invokes active user authentication when there is a mounting evidence that the phone user has changed. In addition, SenGuard uses a novel virtualization based system architecture as a safeguard to prevent subversion of the background user identification mechanism by moving it into a privileged virtual domain. An initial prototype of SenGuard was created using four sensor modalities including, voice, location, multitouch, and locomotion. Preliminary empirical studies with a set of users indicate that those four modalities are suited as data sources for implicit mobile user identification.","Sensors,
Smart phones,
Mobile communication,
Feature extraction,
Authentication,
Accelerometers"
"RASS: A real-time, accurate and scalable system for tracking transceiver-free objects","Transceiver-free object tracking is to trace a moving object without carrying any communication device in an environment where the environment is pre-deployed with some monitoring nodes. Among all the tracking technologies, RF-based technology is an emerging research field facing many challenges. Although we proposed the original idea, until now there is no method achieving scalability without sacrificing latency and accuracy. In this paper, we put forward a real-time tracking system RASS, which can achieve this goal and is promising in the applications like the safeguard system. Our basic idea is to divide the tracking field into different areas, with adjacent areas using different communication channels. So the interference among different areas can be prevented. For each area, three communicating nodes are deployed on the ceiling as a regular triangle to monitor this area. In each triangle area, we use a Support Vector Regression (SVR) model to locate the object. This model simulates the relationship between the signal dynamics caused by the object and the object position. It not only considers the ideal case of signal dynamics caused by the object, but also utilizes their irregular information. As a result it can reach the tracking accuracy to around 1m by just using three nodes in a triangle area with 4m in each side. The experiments show that the tracking latency of the proposed RASS system is bounded by only about 0.26s. Our system scales well to a large deployment field without sacrificing the latency and accuracy.","Accuracy,
Wireless communication,
Wireless sensor networks,
Interference,
Lead,
Synchronization,
Predictive models"
Computer-Aided Decision Support Systems for Endoscopy in the Gastrointestinal Tract: A Review,"Today, medical endoscopy is a widely used procedure to inspect the inner cavities of the human body. The advent of endoscopic imaging techniques-allowing the acquisition of images or videos-created the possibility for the development of the whole new branch of computer-aided decision support systems. Such systems aim at helping physicians to identify possibly malignant abnormalities more accurately. At the beginning of this paper, we give a brief introduction to the history of endoscopy, followed by introducing the main types of endoscopes which emerged so far (flexible endoscope, wireless capsule endoscope, and confocal laser endomicroscope). We then give a brief introduction to computer-aided decision support systems specifically targeted at endoscopy in the gastrointestinal tract. Then we present general facts and figures concerning computer-aided decision support systems and summarize work specifically targeted at computer-aided decision support in the gastrointestinal tract. This summary is followed by a discussion of some common issues concerning the approaches reviewed and suggestions of possible ways to resolve them.","Endoscopes,
Pathology,
Gastrointestinal tract,
Biomedical imaging,
Decision support systems,
Wireless communication"
Robust Time-Based Localization for Asynchronous Networks,"Time-based localization approaches attract a lot of interest due to their high accuracy and potentially low cost for wireless sensor networks (WSNs). However, time-based localization is tightly coupled with clock synchronization. Thus, the reliability of timestamps in time-based localization becomes an important yet challenging task to deal with. In this paper, we propose robust time-based localization strategies to locate a target node with the help of anchors (nodes with known positions) in asynchronous networks. Two kinds of asynchronous networks are considered: one only with clock offsets, labeled quasi-synchronous networks, whereas the other with not only clock offsets but also clock skews, labeled fully asynchronous networks. A novel ranging protocol is developed for both networks, namely asymmetric trip ranging (ATR), to reduce the communication load and explore the broadcast property of WSNs. Regardless of the reliability of the timestamp report from the target node, closed-form least-squares (LS) estimators are derived to accurately estimate the target node position. As a result, we counter the uncertainties caused by the target node by ignoring the timestamps from this node. Furthermore, in order to simplify the estimator in fully asynchronous networks, localization and synchronization are decoupled. A simple yet efficient method is proposed to first Calibrate the Clock Skews of the anchors, and then Estimate the Node Position (CCS-ENP). Finally, Cramér-Rao bounds (CRBs) and simulation results corroborate the efficiency of our localization schemes.","Distance measurement,
Synchronization,
Protocols,
Clocks,
Delay,
Wireless sensor networks,
Uncertainty"
Automatic salient object extraction with contextual cue,"We present a method for automatically extracting salient object from a single image, which is cast in an energy minimization framework. Unlike most previous methods that only leverage appearance cues, we employ an auto-context cue as a complementary data term. Benefitting from a generic saliency model for bootstrapping, the segmentation of the salient object and the learning of the auto-context model are iteratively performed without any user intervention. Upon convergence, we obtain not only a clear separation of the salient object, but also an auto-context classifier which can be used to recognize the same type of object in other images. Our experiments on four benchmarks demonstrated the efficacy of the added contextual cue. It is shown that our method compares favorably with the state-of-the-art, some of which even embraced user interactions.","Computational modeling,
Context,
Minimization,
Context modeling,
Image segmentation,
Visualization,
Training"
Evaluating the viability of process replication reliability for exascale systems,"As high-end computing machines continue to grow in size, issues such as fault tolerance and reliability limit application scalability. Current techniques to ensure progress across faults, like checkpoint-restart, are increasingly problematic at these scales due to excessive overheads predicted to more than double an application's time to solution. Replicated computing techniques, particularly state machine replication, long used in distributed and mission critical systems, have been suggested as an alternative to checkpoint-restart. In this paper, we evaluate the viability of using state machine replication as the primary fault tolerance mechanism for upcoming exascale systems. We use a combination of modeling, empirical analysis, and simulation to study the costs and benefits of this approach in comparison to check-point/restart on a wide range of system parameters. These results, which cover different failure distributions, hardware mean time to failures, and I/O bandwidths, show that state machine replication is a potentially useful technique for meeting the fault tolerance demands of HPC applications on future exascale platforms.","Protocols,
Hardware,
Fault tolerance,
Fault tolerant systems,
Computer crashes,
Sockets,
Bandwidth"
Distributed cosegmentation via submodular optimization on anisotropic diffusion,"The saliency of regions or objects in an image can be significantly boosted if they recur in multiple images. Leveraging this idea, cosegmentation jointly segments common regions from multiple images. In this paper, we propose CoSand, a distributed cosegmentation approach for a highly variable large-scale image collection. The segmentation task is modeled by temperature maximization on anisotropic heat diffusion, of which the temperature maximization with finite K heat sources corresponds to a K-way segmentation that maximizes the segmentation confidence of every pixel in an image. We show that our method takes advantage of a strong theoretic property in that the temperature under linear anisotropic diffusion is a submodular function; therefore, a greedy algorithm guarantees at least a constant factor approximation to the optimal solution for temperature maximization. Our theoretic result is successfully applied to scalable cosegmentation as well as diversity ranking and single-image segmentation. We evaluate CoSand on MSRC and ImageNet datasets, and show its competence both in competitive performance over previous work, and in much superior scalability.","Image segmentation,
Optimization,
Heating,
Anisotropic magnetoresistance,
Approximation algorithms,
Temperature,
Greedy algorithms"
Enhanced Biologically Inspired Model for Object Recognition,"The biologically inspired model (BIM) proposed by Serre presents a promising solution to object categorization. It emulates the process of object recognition in primates' visual cortex by constructing a set of scale- and position-tolerant features whose properties are similar to those of the cells along the ventral stream of visual cortex. However, BIM has potential to be further improved in two aspects: mismatch by dense input and randomly feature selection due to the feedforward framework. To solve or alleviate these limitations, we develop an enhanced BIM (EBIM) in terms of the following two aspects: 1) removing uninformative inputs by imposing sparsity constraints, 2) apply a feedback loop to middle level feature selection. Each aspect is motivated by relevant psychophysical research findings. To show the effectiveness of the EBIM, we apply it to object categorization and conduct empirical studies on four computer vision data sets. Experimental results demonstrate that the EBIM outperforms the BIM and is comparable to state-of-the-art approaches in terms of accuracy. Moreover, the new system is about 20 times faster than the BIM.","Support vector machines,
Visualization,
Feedforward neural networks,
Training,
Object recognition,
Computer vision,
Feedback loop"
Decision Trees for Uncertain Data,"Traditional decision tree classifiers work with data whose values are known and precise. We extend such classifiers to handle data with uncertain information. Value uncertainty arises in many applications during the data collection process. Example sources of uncertainty include measurement/quantization errors, data staleness, and multiple repeated measurements. With uncertainty, the value of a data item is often represented not by one single value, but by multiple values forming a probability distribution. Rather than abstracting uncertain data by statistical derivatives (such as mean and median), we discover that the accuracy of a decision tree classifier can be much improved if the ""complete information"" of a data item (taking into account the probability density function (pdf)) is utilized. We extend classical decision tree building algorithms to handle data tuples with uncertain values. Extensive experiments have been conducted which show that the resulting classifiers are more accurate than those using value averages. Since processing pdfs is computationally more costly than processing single values (e.g., averages), decision tree construction on uncertain data is more CPU demanding than that for certain data. To tackle this problem, we propose a series of pruning techniques that can greatly improve construction efficiency.","Decision trees,
Classification tree analysis,
Probability distribution,
Measurement errors,
Ear,
Temperature measurement,
Temperature sensors,
Computer science,
Buildings,
Uncertainty"
Design of SIW Cavity-Backed Circular-Polarized Antennas Using Two Different Feeding Transitions,"Two circular-polarized circular patch antennas which have novel feeding structures such as a substrate integrated waveguide (SIW), a cavity-backed resonator and two different feeding transitions, are proposed and experimentally investigated in terms of electrical performances, including reflection coefficients, optimized parameter values, circular polarized antenna gain, axial ratios and radiation patterns. By inserting asymmetrical inductive via arrays into the interface region between the circular patch and SIW feeding structure, it is found that an enhancement of input impedance bandwidth has been achieved. In addition, in order to check the effects of feeding transition types on the electrical performances of the main radiator, two different feeding transitions, namely microstrip-to-SIW and coax-to-SIW, have been studied by considering reflection coefficients, gain, axial ratios and radiation patterns. As a result, it is experimentally proved that a broadband impedance bandwidth of 17.32% and 14.42% under the criteria of less than VSWR 2:1 and 1.5:1, respectively, have been obtained and an RHCP axial ratio of 2.34% with a maximum gain of 7.79 dBic has been accomplished by using the proposed antenna with coax-to-SIW transition operating at the X-band of 10 GHz center frequency.","Microstrip antennas,
Antenna radiation patterns,
Microstrip,
Impedance,
Antenna feeds,
Bandwidth,
Antenna measurements"
Accurate Outage Analysis of Incremental Decode-and-Forward Opportunistic Relaying,"In this paper, we investigate a dual-hop decode-and-forward opportunistic relaying scheme where the selected relay chooses to cooperate only if the source-destination channel is of an unacceptable quality. We first derive the exact statistics of received signal-to-noise (SNR) over each hop with co-located relays, in terms of probability density function (PDF). Then, the PDFs are used to determine very accurate closed-form expression for the outage probability for a transmission rate R. Furthermore, we perform asymptotic analysis and we deduce the diversity order of the scheme. We validate our analysis by showing that performance simulation results coincide with our analytical results over different network architectures.","Relays,
Signal to noise ratio,
Wireless communication,
Probability density function,
Protocols,
Wireless sensor networks,
Conferences"
Quickest Search Over Multiple Sequences,"The problem of sequentially finding an independent and identically distributed sequence that is drawn from a probability distribution Q1 by searching over multiple sequences, some of which are drawn from Q1 and the others of which are drawn from a different distribution Q0, is considered. In the problem considered, the number of sequences with distribution Q1 is assumed to be a random variable whose value is unknown. Within a Bayesian formulation, a sequential decision rule is derived that optimizes a trade-off between the probability of false alarm and the number of samples needed for the decision. In the case in which one can observe one sequence at a time, it is shown that the cumulative sum (CUSUM) test, which is well-known to be optimal for a non-Bayesian statistical change-point detection formulation, is optimal for the problem under study. Specifically, the CUSUM test is run on the first sequence. If a reset event occurs in the CUSUM test, then the sequence under examination is abandoned and the rule switches to the next sequence. If the CUSUM test stops, then the rule declares that the sequence under examination when the test stops is generated by Q1 . The result is derived by assuming that there are infinitely many sequences so that a sequence that has been examined once is not retested. If there are finitely many sequences, the result is also valid under a memorylessness condition. Expressions for the performance of the optimal sequential decision rule are also developed. The general case in which multiple sequences can be examined simultaneously is considered. The optimal solution for this general scenario is derived.","Markov processes,
Error probability,
Optimization,
Delay,
Testing,
Switches,
Search problems"
Ultralow-Latency Hardware-in-the-Loop Platform for Rapid Validation of Power Electronics Designs,"This paper introduces a unified approach to the validation of power-electronics (PE) control hardware, firmware, and software designs. It is based on a scalable application-specific ultralow-latency (ULL) digital processor core. The proposed ULL processor core simulates PE converters and systems comprising multiple power converters with a fixed 1-μs simulation time step and latency, regardless of the size of the system. Owing to its ULL, the proposed platform enables the fully automatic testing and validation of the complete PE design comprising component safe-operating-area validation, system protection, firmware, and software implementation as well as overall system performance optimization.",
A Novel Scheme for WSAN Sink Mobility Based on Clustering and Set Packing Techniques,"Advances in technologies such as micro electro mechanical systems (MEMS) have empowered more efficient and smaller digital devices, which can be deployed in WSNs (wireless sensor networks) to gather useful information pertaining to a particular environment. In order to control effectively the physical system in a WSN, actuators may be employed to integrate such environmental information into the automation control system. Indeed, sophisticated entities deployed in wireless sensor and actuator networks (WSANs) act as functional robots. The approach of using the mobile sink, as an example of the actuator to control the movement of a sink, has been adopted by researchers in the past to achieve high efficiency in terms of gathering data from the sensors. This is due to the fact that in general, the sensors alone are unable to control the sink and need to send or relay a smaller amount of packet data. Although a number of methods exist in literature to utilize mobile sinks as actuators, most of these techniques are unable to guarantee data gathering from all of the sensors. As a consequence, more research effort is needed to improve the efficiency as well as fairness of data gathering. In WSANs, sinks and sensor entities should be actively controllable by the administrator. Therefore, we must consider an efficient way to access all nodes in the target networks. In this paper, we propose a novel method, based on the set packing algorithm and traveling salesman problem, to accomplish this goal. The effectiveness of our envisioned method is demonstrated through extensive computer-simulations.",
A Novel Architecture for Reduction of Delay and Queueing Structure Complexity in the Back-Pressure Algorithm,"The back-pressure algorithm is a well-known throughput-optimal algorithm. However, its implementation requires that each node has to maintain a separate queue for each commodity in the network, and only one queue is served at a time. This fact may lead to a poor delay performance even when the traffic load is not close to network capacity. Also, since the number of commodities in the network is usually very large, the queueing data structure that has to be maintained at each node is respectively complex. In this paper, we present a solution to address both of these issues in the case of a fixed-routing network scenario where the route of each flow is chosen upon arrival. Our proposed architecture allows each node to maintain only per-neighbor queues and, moreover, improves the delay performance of the back-pressure algorithm.","Delay,
Resource management,
Queueing analysis,
Schedules,
Complexity theory,
Radiation detectors,
Stability analysis"
Single-ZnO-Nanowire Memory,"Single-ZnO-nanowire (NW) memory based on resistive switching is demonstrated for the first time. The NW memory is stable, rewritable, and nonvolatile with on/off ratio up to 7.7 × 105. The O vacancies at the surfaces of ZnO NWs and around the interface of Ti/ZnO NWs observed using X-ray phototelectron spectroscopy, transmission electron microscopy (TEM), selected-area electron diffraction, and high-resolution TEM might play a role in the resistive switching behavior. The endurance of resistive switching can be enhanced by further increasing the sweeping voltage. This paper brings an exciting possibility of building next-generation memory devices based on NWs.","Zinc oxide,
Resistance,
Nanowires,
Optical switches,
Nonvolatile memory,
Materials"
Repair optimal erasure codes through hadamard designs,"In distributed storage systems that employ erasure coding, the issue of minimizing the total communication required to exactly rebuild a storage node after a failure arises. This repair bandwidth depends on the structure of the storage code and the repair strategies used to restore the lost data. Designing high-rate maximum-distance separable (MDS) codes that achieve the optimum repair communication has been a well-known open problem. In this work, we use Hadamard matrices to construct the first explicit 2-parity MDS storage code with optimal repair properties for all single node failures, including the parity nodes. Our construction relies on a novel method of achieving perfect interference alignment over finite fields with a finite file size, or number of symbol extensions.",
Fast identification of the missing tags in a large RFID system,"RFID (radio-frequency identification) is an emerging technology with extensive applications such as transportation and logistics, object tracking, and inventory management. How to quickly identify the missing RFID tags and thus their associated objects is a practically important problem in many large-scale RFID systems. This paper presents three novel methods to quickly identify the missing tags in a large-scale RFID system of thousands of tags. Our protocols can reduce the time for identifying all the missing tags by up to 75% in comparison to the state of art.","Protocols,
Servers,
Monitoring,
RFID tags,
Wireless communication,
Wireless sensor networks"
Opportunistic Access to Spectrum Holes Between Packet Bursts: A Learning-Based Approach,"We present a cognitive radio (CR) mechanism for opportunistic access to the frequency bands licensed to a data-centric primary user (PU) network. Secondary users (SUs) aim to exploit the short-lived spectrum holes (or opportunities) created between packet bursts in the PU network. The PU traffic pattern changes over both time and frequency according to upper layer events in the PU network, and fast variation in PU activity may cause high sensing error probability and low spectrum utilization in dynamic spectrum access. The proposed mechanism learns a PU traffic pattern in real-time and uses the acquired information to access the frequency channel in an efficient way while limiting the probability of collision with the PUs below a target limit. To design the channel learning algorithm, we model the CR system as a hidden Markov model (HMM) and present a gradient method to find the underlying PU traffic pattern. We also analyze the identifiability of the proposed HMM to provide a condition for the convergence of the proposed learning algorithm. Simulation results show that the proposed algorithm greatly outperforms the traditional listen-before-talk algorithm which does not possess any learning functionality.","Sensors,
Hidden Markov models,
Channel estimation,
Markov processes,
Signal to noise ratio,
Algorithm design and analysis,
Data communication"
A Survey on Applications of Agent Technology in Industrial Process Control,"The agents and multiagent systems technology is actively researched by the academia and industrial community. However, the technology is particularly popular in the manufacturing domain, while the applications in other domains of industrial control are scarce. This survey focuses exclusively on the technology applications in the automation of continuous industrial processes, as the differences in the technology adoption between the process automation and manufacturing are significant. A large part of the literature on the subject is reviewed. The analysis of the literature is provided from several points of view, the main trends of research are described, including the shift of the researchers' interest from the agent-based supervisory control to the low-level agent-based control algorithms. Conclusions are provided regarding the lack of the technology support on the part of control instrumentation vendors; probable directions of the development are indicated, which turn out to be especially promising in the domain of biotechnological processes.",
Security Issues in Online Social Networks,"This article surveys the current state of security issues and available defense mechanisms regarding popular online social networks. It covers a wide variety of attacks and the corresponding defense mechanisms, if available. The authors organize these attacks into four categories - privacy breaches, viral marketing, network structural attacks, and malware attacks - and focus primarily on privacy concerns. They offer an in-depth discussion of each category and analyze the connections among the different security issues involved.","Facebook,
Privacy,
Malware,
Social network services,
Web sites,
Data security"
Long-term spectral occupancy findings in Chicago,"This paper summarizes some of the results of measurements and related analysis efforts at the Illinois Institute of Technology (IIT) Spectrum Observatory in Chicago over the past three years. The results are unique in the sense that the spectral occupancy estimates are based on multiple years of observations, whereas previous studies produced occupancy numbers based on short term snapshot measurements, often of a few hours duration or at most spanning a few days or weeks. The measurements are also presented in a novel way: the occupancy data in a band of interest during a one year span is graphed as a 2-dimensional image that visually reveals daily, weekly, and yearly trends and anomalies. The main objective of this paper is to present year by year first-order statistics about the spectral occupancy across multiple bands, but more details are presented about radio usage in a few bands like the TV band. In particular, we examine the spectral opportunities that are seen in the newly available “TV White Space”. The results illustrate occupancy trends and notable spectral events, such as the 2009 broadcast television transition and the related vacating of the 700 MHz band, which have created significant spectrum opportunities in the 30-1000 MHz region. The trends reported are applicable to long term spectrum modeling, spectrum planning, and regulatory decision-making efforts applicable to dynamic spectrum access networks.","TV,
Observatories,
White spaces,
Wireless communication,
Global Positioning System,
Frequency measurement,
FCC"
Can Junction Temperature Alone Characterize Thermal Performance of White LED Emitters?,"Thermal performance of phosphor-based white light emitting diodes (LEDs) under an input current of 350 mA is investigated by finite-element simulation in which the thermal and optical interactions are considered. It is demonstrated that the temperature of the phosphor particles, regardless of phosphor placement, is always higher than the junction temperature. It is concluded that the junction temperature, which characterizes the thermal behavior of monotonic color LED emitters, cannot be used alone for characterizing the thermal behavior of white LED emitters. In fact, the phosphor temperature is critical in determining the lumen performance and reliability of white LED emitters. In addition, the phosphor temperature is effectively reduced by coating the phosphors directly on the chip and maintaining a relatively higher phosphor concentration (above 60 wt.%) in the phosphor-silicone mixture layer.","Phosphors,
Light emitting diodes,
Junctions,
Coatings,
Heating,
Temperature measurement,
Thermal conductivity"
Python: An Ecosystem for Scientific Computing,"As the relationship between research and computing evolves, new tools are required to not only treat numerical problems, but also to solve various problems that involve large datasets in different formats, new algorithms, and computational systems such as databases and Internet servers. Python can help develop these computational research tools by providing a balance of clarity and flexibility without sacrificing performance.","Scientific computing,
Research and development,
Numerical analysis,
Algorithms"
Digital Fractional Order Savitzky-Golay Differentiator,"This brief proposes a design method for a digital fractional order Savitzky-Golay differentiator (DFOSGD), which generalizes the Savitzky-Golay filter from the integer order to the fractional order for estimating the fractional order derivative of the contaminated signal. The proposed method calculates the moving window's weights using the polynomial least-squares method and the Riemann-Liouville fractional order derivative definition, and then computes the fractional order derivative of the given signal using the convolution between the weights and the signal, instead of the complex mathematical deduction. Hence, the computation time is greatly improved. Frequency-domain analysis reveals that the proposed differentiator is essentially a fractional order low-pass filter. Experiments demonstrate that the proposed DFOSGD can accurately estimate the fractional order derivatives of both noise-free signal and contaminated signal.","Least squares methods,
Noise measurement,
Frequency response,
Filtering theory,
Differential equations,
Smoothing methods"
Transforming Complete Coverage Algorithms to Partial Coverage Algorithms for Wireless Sensor Networks,"The complete area coverage problem in Wireless Sensor Networks (WSNs) has been extensively studied in the literature. However, many applications do not require complete coverage all the time. For such applications, one effective method to save energy and prolong network lifetime is to partially cover the area. This method for prolonging network lifetime recently attracts much attention. However, due to the hardness of verifying the coverage ratio, all the existing centralized or distributed but nonparallel algorithms for partial coverage have very high time complexities. In this work, we propose a framework which can transform almost any existing complete coverage algorithm to a partial coverage one with any coverage ratio by running a complete coverage algorithm to find full coverage sets with virtual radii and converting the coverage sets to partial coverage sets via adjusting sensing radii. Our framework can preserve the characteristics of the original algorithms and the conversion process has low time complexity. The framework also guarantees some degree of uniform partial coverage of the monitored area.","Wireless sensor networks,
Monitoring,
Energy efficiency,
Fires,
Computer science,
Mathematics,
Statistics,
Electronic mail"
Optimizing a Tone Curve for Backward-Compatible High Dynamic Range Image and Video Compression,"For backward compatible high dynamic range (HDR) video compression, the HDR sequence is reconstructed by inverse tone-mapping a compressed low dynamic range (LDR) version of the original HDR content. In this paper, we show that the appropriate choice of a tone-mapping operator (TMO) can significantly improve the reconstructed HDR quality. We develop a statistical model that approximates the distortion resulting from the combined processes of tone-mapping and compression. Using this model, we formulate a numerical optimization problem to find the tone-curve that minimizes the expected mean square error (MSE) in the reconstructed HDR sequence. We also develop a simplified model that reduces the computational complexity of the optimization problem to a closed-form solution. Performance evaluations show that the proposed methods provide superior performance in terms of HDR MSE and SSIM compared to existing tone-mapping schemes. It is also shown that the LDR image quality resulting from the proposed methods matches that produced by perceptually-based TMOs.","Image coding,
Image reconstruction,
Pixel,
Image color analysis,
Encoding,
Optimization,
Automatic voltage control"
An Autocalibrated All-Digital Temperature Sensor for On-Chip Thermal Monitoring,"This brief presents an autocalibrated all-digital temperature sensor circuit for use with on-chip thermal sensing applications. The proposed temperature sensor eliminates the need for two-temperature-point calibration in prior temperature sensors. Therefore, temperature sensor calibration efforts in high-volume production can be significantly reduced. The proposed design uses reference clock period information to perform self-calibration, and thus, effects of process variation can be removed. Subsequently, the accuracy of the proposed temperature sensor can be improved with very small area cost and low power consumption. The temperature sensor is implemented with a standard performance 65-nm complementary metal-oxide-semiconductor technology. The core area is 0.01 mm2, and the power consumption of the proposed circuit is 150 μW with a 1-V supply. Since the proposed temperature sensor can be easily calibrated with a reference clock, the proposed design is very suitable for dynamic thermal management applications in a system-on-a-chip era.",
Online Sparse Gaussian Process Regression and Its Applications,"We present a new Gaussian process (GP) inference algorithm, called online sparse matrix Gaussian processes (OSMGP), and demonstrate its merits by applying it to the problems of head pose estimation and visual tracking. The OSMGP is based upon the observation that for kernels with local support, the Gram matrix is typically sparse. Maintaining and updating the sparse Cholesky factor of the Gram matrix can be done efficiently using Givens rotations. This leads to an exact, online algorithm whose update time scales linearly with the size of the Gram matrix. Further, we provide a method for constant time operation of the OSMGP using matrix downdates. The downdates maintain the Cholesky factor at a constant size by removing certain rows and columns corresponding to discarded training examples. We demonstrate that, using these matrix downdates, online hyperparameter estimation can be included at cost linear in the number of total training examples. We describe a robust appearance-based head pose estimation system based upon the OSMGP. Numerous experiments and comparisons with existing methods using a large dataset system demonstrate the efficiency and accuracy of our system. Further, to showcase the applicability of OSMGP to a wide variety of problems, we also describe a regression-based visual tracking method. Experiments show that our OSMGP algorithm generalizes well using online learning.","Gaussian processes,
Sparse matrices,
Kernel,
Inference algorithms,
Magnetic heads,
Bayesian methods,
Training data,
Costs,
Robustness,
Statistical learning"
Maximum Efficiency Trajectories of a Two-Axis Sun Tracking System Determined Considering Tracking System Consumption,"This paper deals with the two-axis sun tracking system for a photovoltaic system. The trajectories of the sun tracking system are determined in an optimization procedure. The optimization goal is maximization of an electric energy production in the photovoltaic system considering the tracking system consumption. Determination of the tilt angle and azimuth angle trajectories is described as a nonlinear and bounded optimization problem, where the objective function is not available in the explicit form. A stochastic search algorithm called Differential Evolution is used as an optimization tool. In the optimization procedure, the objective function is evaluated by using the models of available solar radiation, tracking system consumption, and the efficiency of solar cells with the appropriate dc/dc converters. The problem bounds are given in the form of lower and upper bounds for both angles and time and angle quantization. The results presented in the paper show, that the optimal trajectories for the tilt and azimuth angle depend on the available solar radiation, solar cell efficiency, tracking system consumption and the optimization bounds.","Solar radiation,
Sun,
Optimization,
Trajectory,
Azimuth,
Photovoltaic cells,
Production"
Intelligent management of virtualized resources for database systems in cloud environment,"In a cloud computing environment, resources are shared among different clients. Intelligently managing and allocating resources among various clients is important for system providers, whose business model relies on managing the infrastructure resources in a cost-effective manner while satisfying the client service level agreements (SLAs). In this paper, we address the issue of how to intelligently manage the resources in a shared cloud database system and present SmartSLA, a cost-aware resource management system. SmartSLA consists of two main components: the system modeling module and the resource allocation decision module. The system modeling module uses machine learning techniques to learn a model that describes the potential profit margins for each client under different resource allocations. Based on the learned model, the resource allocation decision module dynamically adjusts the resource allocations in order to achieve the optimum profits. We evaluate SmartSLA by using the TPC-W benchmark with workload characteristics derived from real-life systems. The performance results indicate that SmartSLA can successfully compute predictive models under different hardware resource allocations, such as CPU and memory, as well as database specific resources, such as the number of replicas in the database systems. The experimental results also show that SmartSLA can provide intelligent service differentiation according to factors such as variable workloads, SLA levels, resource costs, and deliver improved profit margins.","Databases,
Resource management,
Machine learning,
Linear regression,
System performance,
Regression tree analysis,
Time factors"
A Quasi-Distributed Sensing Network With Time-Division-Multiplexed Fiber Bragg Gratings,"We propose a serial time-division-multiplexing sensor network based on ultraweak fiber Bragg gratings (FBGs). Twelve ultraweak FBGs are distinguished with a spatial resolution of about 0.2 m, and their spectra are resolved with an accuracy of about 10 pm. The low crosstalk of the gratings makes it possible to multiplex over 1000 gratings along a single optical fiber.","Fiber gratings,
Time division multiplexing,
Arrays,
Optical fiber sensors,
Crosstalk"
A Fast Cluster-Assumption Based Active-Learning Technique for Classification of Remote Sensing Images,"In this paper, we propose a simple, fast, and reliable active-learning technique for solving remote sensing image classification problems with support vector machine (SVM) classifiers. The main property of the proposed technique consists in its robustness to biased (poor) initial training sets. The presented method considers the 1-D output space of the classifier to identify the most uncertain samples whose labeling and inclusion in the training set involve a high probability to improve the classification results. A simple histogram-thresholding algorithm is used to find out the low-density (i.e., under the cluster assumption, the most uncertain) region in the 1-D SVM output space. To assess the effectiveness of the proposed method, we compared it with other active-learning techniques proposed in the remote sensing literature using multispectral and hyperspectral data. Experimental results confirmed that the proposed technique provided the best tradeoff among robustness to biased (poor) initial training samples, computational complexity, classification accuracy, and the number of new labeled samples necessary to reach convergence.","Support vector machines,
Training,
Histograms,
Entropy,
Kernel,
Hyperspectral imaging"
Ubiquitous data collection for mobile users in wireless sensor networks,"We study the ubiquitous data collection for mobile users in wireless sensor networks. People with handheld devices can easily interact with the network and collect data. We propose a novel approach for mobile users to collect the network-wide data. The routing structure of data collection is additively updated with the movement of the mobile user. With this approach, we only perform a local modification to update the routing structure while the routing performance is bounded and controlled compared to the optimal performance. The proposed protocol is easy to implement. Our analysis shows that the proposed approach is scalable in maintenance overheads, performs efficiently in the routing performance, and provides continuous data delivery during the user movement. We implement the proposed protocol in a prototype system and test its feasibility and applicability by a 49-node testbed. We further conduct extensive simulations to examine the efficiency and scalability of our protocol with varied network settings.",
Efficient continuously moving top-k spatial keyword query processing,"Web users and content are increasingly being geo-positioned. This development gives prominence to spatial keyword queries, which involve both the locations and textual descriptions of content. We study the efficient processing of continuously moving top-k spatial keyword (MkSK) queries over spatial keyword data. State-of-the-art solutions for moving queries employ safe zones that guarantee the validity of reported results as long as the user remains within a zone. However, existing safe zone methods focus solely on spatial locations and ignore text relevancy. We propose two algorithms for computing safe zones that guarantee correct results at any time and that aim to optimize the computation on the server as well as the communication between the server and the client. We exploit tight and conservative approximations of safe zones and aggressive computational space pruning. Empirical studies with real data suggest that our proposals are efficient.",
Application-Aware Topology Reconfiguration for On-Chip Networks,"In this paper, we present a reconfigurable architecture for networks-on-chip (NoC) on which arbitrary application-specific topologies can be implemented. When a new application starts, the proposed NoC tailors its topology to the application traffic pattern by changing the inter-router connections to some predefined configuration corresponding to the application. It addresses one of the main drawbacks of the existing application-specific NoC optimization methods, i.e., optimization of NoCs based on the traffic pattern of a single application. Supporting multiple applications is a critical feature of an NoC when several different applications are integrated into a single modern and complex multicore system-on-chip or chip multiprocessor. The proposed reconfigurable NoC architecture supports multiple applications by appropriately configuring itself to a topology that matches the traffic pattern of the currently running application. This paper first introduces the proposed reconfigurable topology and then addresses the problems of core to network mapping and topology exploration. Further on, we evaluate the impact of different architectural attributes on the performance of the proposed NoC. Evaluations consider network latency, power consumption, and area complexity.","Topology,
Network topology,
System-on-a-chip,
Switches,
Power demand,
Computer architecture,
Routing"
Semisupervised Dimensionality Reduction and Classification Through Virtual Label Regression,"Semisupervised dimensionality reduction has been attracting much attention as it not only utilizes both labeled and unlabeled data simultaneously, but also works well in the situation of out-of-sample. This paper proposes an effective approach of semisupervised dimensionality reduction through label propagation and label regression. Different from previous efforts, the new approach propagates the label information from labeled to unlabeled data with a well-designed mechanism of random walks, in which outliers are effectively detected and the obtained virtual labels of unlabeled data can be well encoded in a weighted regression model. These virtual labels are thereafter regressed with a linear model to calculate the projection matrix for dimensionality reduction. By this means, when the manifold or the clustering assumption of data is satisfied, the labels of labeled data can be correctly propagated to the unlabeled data; and thus, the proposed approach utilizes the labeled and the unlabeled data more effectively than previous work. Experimental results are carried out upon several databases, and the advantage of the new approach is well demonstrated.",
Multiple Player Tracking in Sports Video: A Dual-Mode Two-Way Bayesian Inference Approach With Progressive Observation Modeling,"Multiple object tracking (MOT) is a very challenging task yet of fundamental importance for many practical applications. In this paper, we focus on the problem of tracking multiple players in sports video which is even more difficult due to the abrupt movements of players and their complex interactions. To handle the difficulties in this problem, we present a new MOT algorithm which contributes both in the observation modeling level and in the tracking strategy level. For the observation modeling, we develop a progressive observation modeling process that is able to provide strong tracking observations and greatly facilitate the tracking task. For the tracking strategy, we propose a dual-mode two-way Bayesian inference approach which dynamically switches between an offline general model and an online dedicated model to deal with single isolated object tracking and multiple occluded object tracking integrally by forward filtering and backward smoothing. Extensive experiments on different kinds of sports videos, including football, basketball, as well as hockey, demonstrate the effectiveness and efficiency of the proposed method.",
Structural Regularized Support Vector Machine: A Framework for Structural Large Margin Classifier,"Support vector machine (SVM), as one of the most popular classifiers, aims to find a hyperplane that can separate two classes of data with maximal margin. SVM classifiers are focused on achieving more separation between classes than exploiting the structures in the training data within classes. However, the structural information, as an implicit prior knowledge, has recently been found to be vital for designing a good classifier in different real-world problems. Accordingly, using as much prior structural information in data as possible to help improve the generalization ability of a classifier has yielded a class of effective structural large margin classifiers, such as the structured large margin machine (SLMM) and the Laplacian support vector machine (LapSVM). In this paper, we unify these classifiers into a common framework from the concept of “structural granularity” and the formulation for optimization problems. We exploit the quadratic programming (QP) and second-order cone programming (SOCP) methods, and derive a novel large margin classifier, we call the new classifier the structural regularized support vector machine (SRSVM). Unlike both SLMM at the cross of the cluster granularity and SOCP and LapSVM at the cross of the point granularity and QP, SRSVM is located at the cross of the cluster granularity and QP and thus follows the same optimization formulation as LapSVM to overcome large computational complexity and non-sparse solution in SLMM. In addition, it integrates the compactness within classes with the separability between classes simultaneously. Furthermore, it is possible to derive generalization bounds for these algorithms by using eigenvalue analysis of the kernel matrices. Experimental results demonstrate that SRSVM is often superior in classification and generalization performances to the state-of-the-art algorithms in the framework, both with the same and different structural granularities.","Support vector machines,
Optimization,
Ellipsoids,
Covariance matrix,
Clustering algorithms,
Manifolds,
Kernel"
Improving energy efficiency of Wi-Fi sensing on smartphones,"Mobile data usage over cellular networks has been dramatically increasing over the past years. Wi-Fi based wireless networks offer a high-bandwidth alternative for offloading such data traffic. However, intermittent connectivity, and battery power drain in mobile devices, inhibits always-on connectivity even in areas with good Wi-Fi coverage. This paper presents WiFisense, a system that employs user mobility information retrieved from low-power sensors (e.g., accelerometer) in smartphones, and further includes adaptive Wi-Fi sensing algorithms, to conserve battery power while improving Wi-Fi usage. We implement the proposed system in Android-based smartphones and evaluate the implementation in both indoor and outdoor Wi-Fi networks. Our evaluation results show that WiFisense saves energy consumption for scans by up to 79% and achieves considerable increase in Wi-Fi usage for various scenarios.","IEEE 802.11 Standards,
Sensors,
Mobile communication,
Smart phones,
Accelerometers,
Monitoring"
Dual-Band Printed Fractal Monopole Antenna for LTE Applications,"In this letter, a dual-band fractal monopole antenna suitable for Long Term Evolution (LTE) standard is proposed. The antenna geometry is based on a perturbed planar Sierpinski fractal shape, whose geometrical descriptors are determined by means of a particle swarm optimization (PSO). The optimized antenna exhibits a good impedance matching within the LTE bands at 700 and 2600 MHz as well as a 24% size reduction with respect to a standard quarter-wave resonant monopole. The efficiency of the proposed antenna is assessed by means of both simulations and measurements.","Fractals,
Antenna measurements,
Antenna radiation patterns,
Frequency measurement,
Dual band"
Blind Forensics of Median Filtering in Digital Images,"Exposing the processing history of a digital image is an important problem for forensic analyzers and steganalyzers. As the median filter is a popular nonlinear denoising operator, the blind forensics of median filtering is particularly interesting. This paper proposes a novel approach for detecting median filtering in digital images, which can 1) accurately detect median filtering in arbitrary images, even reliably detect median filtering in low-resolution and JPEG compressed images; and 2) reliably detect tampering when part of a median-filtered image is inserted into a nonmedian-filtered image, or vice versa. The effectiveness of the proposed approach is exhaustively evaluated in five different image databases.","Filtering,
Digital forensics,
Digital images,
Transform coding,
Image coding,
Image databases,
Noise reduction"
Band-Notched UWB Antenna Incorporating a Microstrip Open-Loop Resonator,"Ultrawideband (UWB) systems require band notch filters in order to prevent sensitive components, within the front-end of the receiver, from being overloaded by strong signals. Recently, it has been shown that these filters can be integrated into the UWB antenna, to great advantage. This communication presents a new method for forming a notch band within the frequency response of a UWB antenna. An open loop notch band resonator is located on the back of the substrate, used to support the UWB monopole. The act of separating the resonator from the antenna means that they can now be designed in isolation, using the standard approach described in the literature, and then combined. A prototype was constructed and good agreement has been obtained between simulation and measurement. The radiation patterns are consistent over the frequency range of interest.","Ultra wideband antennas,
Mathematical model,
Resonant frequency,
Antenna radiation patterns,
Resonator filters"
Online learning in opportunistic spectrum access: A restless bandit approach,"We consider an opportunistic spectrum access (OSA) problem where the time-varying condition of each channel (e.g., as a result of random fading or certain primary users' activities) is modeled as an arbitrary finite-state Markov chain. At each instance of time, a (secondary) user probes a channel and collects a certain reward as a function of the state of the channel (e.g., good channel condition results in higher data rate for the user). Each channel has potentially different state space and statistics, both unknown to the user, who tries to learn which one is the best as it goes and maximizes its usage of the best channel. The objective is to construct a good online learning algorithm so as to minimize the difference between the user's performance in total rewards and that of using the best channel (on average) had it known which one is the best from a priori knowledge of the channel statistics (also known as the regret). This is a classic exploration and exploitation problem and results abound when the reward processes are assumed to be iid. Compared to prior work, the biggest difference is that in our case the reward process is assumed to be Markovian, of which iid is a special case. In addition, the reward processes are restless in that the channel conditions will continue to evolve independent of the user's actions. This leads to a restless bandit problem, for which there exists little result on either algorithms or performance bounds in this learning context to the best of our knowledge. In this paper we introduce an algorithm that utilizes regenerative cycles of a Markov chain and computes a samplemean based index policy, and show that under mild conditions on the state transition probabilities of the Markov chains this algorithm achieves logarithmic regret uniformly over time, and that this regret bound is also optimal. We numerically examine the performance of this algorithm along with a few other learning algorithms in the case of an OSA problem with Gilbert-Elliot channel models, and discuss how this algorithm may be further improved (in terms of its constant) and how this result may lead to similar bounds for other algorithms.","Markov processes,
Indexes,
Silicon,
Fading,
Eigenvalues and eigenfunctions,
Context,
Probability"
Heterogeneous image feature integration via multi-modal spectral clustering,"In recent years, more and more visual descriptors have been proposed to describe objects and scenes appearing in images. Different features describe different aspects of the visual characteristics. How to combine these heterogeneous features has become an increasing critical problem. In this paper, we propose a novel approach to unsupervised integrate such heterogeneous features by performing multi-modal spectral clustering on unlabeled images and unsegmented images. Considering each type of feature as one modal, our new multi-modal spectral clustering (MMSC) algorithm is to learn a commonly shared graph Laplacian matrix by unifying different modals (image features). A non-negative relaxation is also added in our method to improve the robustness and efficiency of image clustering. We applied our MMSC method to integrate five types of popularly used image features, including SIFT, HOG, GIST, LBP, CENTRIST and evaluated the performance by two benchmark data sets: Caltech-101 and MSRC-v1. Compared with existing unsupervised scene and object categorization methods, our approach always achieves superior performances measured by three standard clustering evaluation metrices.",
Boosted local structured HOG-LBP for object localization,"Object localization is a challenging problem due to variations in object's structure and illumination. Although existing part based models have achieved impressive progress in the past several years, their improvement is still limited by low-level feature representation. Therefore, this paper mainly studies the description of object structure from both feature level and topology level. Following the bottom-up paradigm, we propose a boosted Local Structured HOG-LBP based object detector. Firstly, at feature level, we propose Local Structured Descriptor to capture the object's local structure, and develop the descriptors from shape and texture information, respectively. Secondly, at topology level, we present a boosted feature selection and fusion scheme for part based object detector. All experiments are conducted on the challenging PASCAL VOC2007 datasets. Experimental results show that our method achieves the state-of-the-art performance.",
Variational Inference for Infinite Mixtures of Gaussian Processes With Applications to Traffic Flow Prediction,"This paper proposes a new variational approximation for infinite mixtures of Gaussian processes. As an extension of the single Gaussian process regression model, mixtures of Gaussian processes can characterize varying covariances or multimodal data and reduce the deficiency of the computationally cubic complexity of the single Gaussian process model. The infinite mixture of Gaussian processes further integrates a Dirichlet process prior to allowing the number of mixture components to automatically be determined from data. We use variational inference and a truncated stick-breaking representation of the Dirichlet process to approximate the posterior of hidden variables involved in the model. To fix the hyperparameters of the model, the variational EM algorithm and a greedy algorithm are employed. In addition to presenting the variational infinite-mixture model, we apply it to the problem of traffic flow prediction. Experiments with comparisons to other approaches show the effectiveness of the proposed model.",
Wireless link scheduling under physical interference model,"Link scheduling is a fundamental problem in multihop wireless networks because the capacities of the communication links in multihop wireless networks, rather than being fixed, vary with the underlying link schedule subject to the wireless interference constraint. The majority of algorithmic works on link scheduling in multihop wireless networks assume binary interference models such as the 802.11 interference model and the protocol interference model, which often put severe restrictions on interference constraints for practical applicability of the link schedules. On the other hand, while the physical interference model is much more realistic, the link scheduling problem under physical interference model is notoriously hard to resolve and been studied only recently by a few works. This paper conducts a full-scale algorithmic study of link scheduling for maximizing throughput capacity or minimizing the communication latency in multihop wireless networks under the physical interference model. We build a unified algorithmic framework and develop approximation algorithms for link scheduling with or without power control.",
Aggregating gradient distributions into intensity orders: A novel local image descriptor,"A novel local image descriptor is proposed in this paper, which combines intensity orders and gradient distributions in multiple support regions. The novelty lies in three aspects: 1) The gradient is calculated in a rotation invariant way in a given support region; 2) The rotation invariant gradients are adaptively pooled spatially based on intensity orders in order to encode spatial information; 3) Multiple support regions are used for constructing descriptor which further improves its discriminative ability. Therefore, the proposed descriptor encodes not only gradient information but also information about relative relationship of intensities as well as spatial information. In addition, it is truly rotation invariant in theory without the need of computing a dominant orientation which is a major error source of most existing methods, such as SIFT. Results on the standard Oxford dataset and 3D objects have shown a significant improvement over the state-of-the-art methods under various image transformations.",
To preempt or not: Tackling bid and time-based cheating in online spectrum auctions,"Online spectrum auctions offer ample flexibility for bidders to request and obtain spectrum on-the-fly. Such flexibility, however, opens up new vulnerabilities to bidder manipulation. Aside from rigging their bids, selfish bidders can falsely report their arrival time to game the system and obtain unfair advantage over others. Such time-based cheating is easy to perform yet produces severe damage to auction performance. We propose Topaz, a truthful online spectrum auction design that distributes spectrum efficiently while discouraging bidders from misreporting their bids or time report. Topaz makes three key contributions. First, Topaz applies a 3D bin packing mechanism to distribute spectrum across time, space and frequency, exploiting spatial and time reuse to improve allocation efficiency. Second, Topaz enforces truthfulness using a novel temporal-smoothed critical value based pricing. Capturing the temporal and spatial dependency among bidders who arrive subsequently, this pricing effectively diminishes gain from bid and/or time-cheating. Finally, Topaz offers a “scalable” winner preemption to address the uncertainty of future arrivals at each decision time, which significantly boosts auction revenue. We analytically prove Topaz's truthfulness, which does not require any knowledge of bidder behavior, or an optimal spectrum allocation to enforce truthfulness. Using empirical arrival and bidding models, we perform simulations to demonstrate the efficiency of Topaz. We show that proper winner preemption improves auction revenue by 45-65% at a minimum cost of spectrum utilization.","Resource management,
Pricing,
Resists,
Three dimensional displays,
Uncertainty,
Time frequency analysis,
Delay"
Improving the Performance of Wireless Ad Hoc Networks Through MAC Layer Design,"In this paper, the performance of the ALOHA and CSMA MAC protocols are analyzed in spatially distributed wireless networks. The main system objective is correct reception of packets, and thus the analysis is performed in terms of outage probability. In our network model, packets belonging to specific transmitters arrive randomly in space and time according to a 3-D Poisson point process, and are then transmitted to their intended destinations using a fully-distributed MAC protocol. A packet transmission is considered successful if the received SINR is above a predefined threshold for the duration of the packet. Accurate bounds on the outage probabilities are derived as a function of the transmitter density, the number of backoffs and retransmissions, and in the case of CSMA, also the sensing threshold. The analytical expressions are validated with simulation results. For continuous-time transmissions, CSMA with receiver sensing (which involves adding a feedback channel to the conventional CSMA protocol) is shown to yield the best performance. Moreover, the sensing threshold of CSMA is optimized. It is shown that introducing sensing for lower densities (i.e., in sparse networks) is not beneficial, while for higher densities (i.e., in dense networks), using an optimized sensing threshold provides significant gain.","Multiaccess communication,
Interference,
Sensors,
Signal to noise ratio,
Media Access Protocol,
Ad hoc networks"
PET Image Reconstruction Using Information Theoretic Anatomical Priors,"We describe a nonparametric framework for incorporating information from co-registered anatomical images into positron emission tomographic (PET) image reconstruction through priors based on information theoretic similarity measures. We compare and evaluate the use of mutual information (MI) and joint entropy (JE) between feature vectors extracted from the anatomical and PET images as priors in PET reconstruction. Scale-space theory provides a framework for the analysis of images at different levels of detail, and we use this approach to define feature vectors that emphasize prominent boundaries in the anatomical and functional images, and attach less importance to detail and noise that is less likely to be correlated in the two images. Through simulations that model the best case scenario of perfect agreement between the anatomical and functional images, and a more realistic situation with a real magnetic resonance image and a PET phantom that has partial volumes and a smooth variation of intensities, we evaluate the performance of MI and JE based priors in comparison to a Gaussian quadratic prior, which does not use any anatomical information. We also apply this method to clinical brain scan data using Fallypride, a tracer that binds to dopamine receptors and therefore localizes mainly in the striatum. We present an efficient method of computing these priors and their derivatives based on fast Fourier transforms that reduce the complexity of their convolution-like expressions. Our results indicate that while sensitive to initialization and choice of hyperparameters, information theoretic priors can reconstruct images with higher contrast and superior quantitation than quadratic priors.","Positron emission tomography,
Joints,
Entropy,
Feature extraction,
Image reconstruction,
Equations,
Measurement"
Localizing WiFi Access Points Using Signal Strength,"When estimating the location of WiFi access points (AP) in an anonymous environment, the required parameters of the radio propagation model are not readily obtainable. This letter investigates the use of received signal strength (RSS) for range-based AP localization when no information on the radio propagation model is provided. To achieve this goal, we linearly approximate the exponential relationship between RSS and distance, and apply a multilateration technique. Our simulation results validate that estimation of an AP location is possible given four or more RSS measurements at different locations.",
Experimental Demonstration of an Impairment Aware Network Planning and Operation Tool for Transparent/Translucent Optical Networks,"Core optical networks using reconfigurable optical switches and tunable lasers appear to be on the road towards widespread deployment and could evolve to all-optical mesh networks in the coming future. Considering the impact of physical layer impairments in the planning and operation of all-optical (and translucent) networks is the main focus of the Dynamic Impairment Constraint Optical Networking (DICONET) project. The impairment aware network planning and operation tool (NPOT) is the main outcome of DICONET project, which is explained in detail in this paper. The key building blocks of the NPOT, consisting of network description repositories, the physical layer performance evaluator, the impairment aware routing and wavelength assignment engines, the component placement modules, failure handling, and the integration of NPOT in the control plane are the main contributions of this study. Besides, the experimental result of DICONET proposal for centralized and distributed control plane integration schemes and the performance of the failure handling in terms of restoration time is presented in this study.","Optical fiber networks,
Planning,
Repeaters,
Protocols,
Engines,
Modulation,
Noise"
Abandoning Objectives: Evolution Through the Search for Novelty Alone,"In evolutionary computation, the fitness function normally measures progress toward an objective in the search space, effectively acting as an objective function. Through deception, such objective functions may actually prevent the objective from being reached. While methods exist to mitigate deception, they leave the underlying pathology untreated: Objective functions themselves may actively misdirect search toward dead ends. This paper proposes an approach to circumventing deception that also yields a new perspective on open-ended evolution. Instead of either explicitly seeking an objective or modeling natural evolution to capture open-endedness, the idea is to simply search for behavioral novelty. Even in an objective-based problem, such novelty search ignores the objective. Because many points in the search space collapse to a single behavior, the search for novelty is often feasible. Furthermore, because there are only so many simple behaviors, the search for novelty leads to increasing complexity. By decoupling open-ended search from artificial life worlds, the search for novelty is applicable to real world problems. Counterintuitively, in the maze navigation and biped walking tasks in this paper, novelty search significantly outperforms objective-based search, suggesting the strange conclusion that some problems are best solved by methods that ignore the objective. The main lesson is the inherent limitation of the objective-based paradigm and the unexploited opportunity to guide search through other means.","neuroevolution,
Evolutionary algorithms,
deception,
novelty search,
open-ended evolution"
Robust and resilient control design for cyber-physical systems with an application to power systems,"The tradeoff between robustness and resilience is a pivotal design issue for modern industrial control systems. The trend of integrating information technologies into control system infrastructure has made resilience an important dimension of the critical infrastructure protection mission. It is desirable that systems support state awareness of threats and anomalies, and maintain acceptable levels of operation or service in the face of unanticipated or unprecedented incidents. In this paper, we propose a hybrid theoretical framework for robust and resilient control design in which the stochastic switching between structure states models unanticipated events and deterministic uncertainties in each structure represent the known range of disturbances. We propose a set of coupled optimality criteria for a holistic robust and resilient design for cyber-physical systems. We apply this method to a voltage regulator design problem for a synchronous machine with infinite bus and illustrate the solution methodology with numerical examples.","Robustness,
Games,
Uncertainty,
Generators,
Resilience,
Control design"
Novel Single-Stage Self-Oscillating Dimmable Electronic Ballast With High Power Factor Correction,"A novel self-oscillating electronic ballast with dimming capability and high power factor correction (PFC) is proposed in this paper. The single-stage electronic ballast integrates a buck-boost PFC stage with a half-bridge LCC series-parallel resonant inverter. The buck-boost semistage operating in discontinuous conduction mode inherently has high PFC. The inverter is dimmable in self-oscillation mode, which is achieved using pulsewidth modulation and variable-frequency controls. The dimming circuit is simple and low cost. The self-sustained oscillation of the dimmable electronic ballast for fluorescent lamps was verified using the dual-input describing function method. A prototype of a 10-W dimmable electronic ballast was implemented to verify the theoretical analysis.","Electronic ballasts,
Power factor correction,
Pulse width modulation inverters,
Resonant inverters,
Electric variables control,
Circuits,
Reactive power,
Switches,
Prototypes,
Pulse width modulation"
Motion Planning,"This is the first installment of a two-part tutorial. The goal of the first part is to give the reader a basic understanding of the technical issues and types of approaches in solving the basic path-planning or obstacle-avoidance problem. The second installment will cover more advanced issues, including feedback, differential constraints, and uncertainty. Note that this is a brief tutorial rather than a comprehensive survey of methods. For the lat ter, consult some of the recent textbooks. Motion planning involves getting a robot to automatically determine how to move while avoiding collisions with obstacles. Its original formulation, called the piano mov er's problem, is imagined as determining how to move a complicated piece of furniture through a cluttered house. Have you ever argued about how to move a sofa up a stairwell? It has been clear for several decades that getting robots to reason geometrically about their environments and synthesize such plans is a fundamental difficulty that recurs all over robotics.","Tutorials,
Motion planning,
Motion control,
Path planning,
Collision avoidance"
Passivity and Stability Analysis of Reaction-Diffusion Neural Networks With Dirichlet Boundary Conditions,"This paper is concerned with the passivity and stability problems of reaction-diffusion neural networks (RDNNs) in which the input and output variables are varied with the time and space variables. By utilizing the Lyapunov functional method combined with the inequality techniques, some sufficient conditions ensuring the passivity and global exponential stability are derived. Furthermore, when the parameter uncertainties appear in RDNNs, several criteria for robust passivity and robust global exponential stability are also presented. Finally, a numerical example is provided to illustrate the effectiveness of the proposed criteria.",
Improved Capacity Scaling in Wireless Networks With Infrastructure,"This paper analyzes the impact and benefits of infrastructure support in improving the throughput scaling in networks of n randomly located wireless nodes. The infrastructure uses multiantenna base stations (BSs), in which the number of BSs and the number of antennas at each BS can scale at arbitrary rates relative to n. Under the model, capacity scaling laws are analyzed for both dense and extended networks. Two BS-based routing schemes are first introduced in this study: an infrastructure-supported single-hop (ISH) routing protocol with multiple-access uplink and broadcast downlink and an infrastructure-supported multihop (IMH) routing protocol. Then, their achievable throughput scalings are analyzed. These schemes are compared against two conventional schemes without BSs: the multihop (MH) transmission and hierarchical cooperation (HC) schemes. It is shown that a linear throughput scaling is achieved in dense networks, as in the case without help of BSs. In contrast, the proposed BS-based routing schemes can, under realistic network conditions, improve the throughput scaling significantly in extended networks. The gain comes from the following advantages of these BS-based protocols. First, more nodes can transmit simultaneously in the proposed scheme than in the MH scheme if the number of BSs and the number of antennas are large enough. Second, by improving the long-distance signal-to-noise ratio (SNR), the received signal power can be larger than that of the HC, enabling a better throughput scaling under extended networks. Furthermore, by deriving the corresponding information-theoretic cut-set upper bounds, it is shown under extended networks that a combination of four schemes IMH, ISH, MH, and HC is order-optimal in all operating regimes.","Throughput,
Protocols,
Upper bound,
Antennas,
Routing,
Wireless communication,
Ad hoc networks"
Series Voltage Compensation for DFIG Wind Turbine Low-Voltage Ride-Through Solution,"This paper introduces a new solution for doubly fed induction generators to stay connected to the grid during voltage sags. The main idea is to increase the stator voltage to a level that creates the required flux to keep the rotor side converter current below its transient rating. To accomplish this goal, a series compensator is added to inject voltage in series to the stator side line. The series converter monitors the grid voltage and provides compensation accordingly to accomplish this aim. Since the turbine and converter stay connected, the synchronization of operation remains established during and after the fault and normal operation can be resumed immediately after the fault is cleared. To keep the current at its minimum, a control strategy has been developed to keep the injected voltage and line voltage in phase during and after the fault.","Rotors,
Converters,
Stator windings,
Wind turbines,
Generators,
Transient analysis"
Contact duration aware data replication in Delay Tolerant Networks,"The recent popularization of hand-held mobile devices, such as smartphones, enables the inter-connectivity among mobile users without the support of Internet infrastructure. When mobile users move and contact each other opportunistically, they form a Delay Tolerant Network (DTN), which can be exploited to share data among them. Data replication is one of the common techniques for such data sharing. However, the unstable network topology and limited contact duration in DTNs make it difficult to directly apply traditional data replication schemes. Although there are a few existing studies on data replication in DTNs, they generally ignore the contact duration limits. In this paper, we recognize the deficiency of existing data replication schemes which treat the complete data item as the replication unit, and propose to replicate data at the packet level. We analytically formulate the contact duration aware data replication problem and give a centralized solution to better utilize the limited storage buffers and the contact opportunities. We further propose a practical contact Duration Aware Replication Algorithm (DARA) which operates in a fully distributed manner and reduces the computational complexity. Extensive simulations on both synthetic and realistic traces show that our distributed scheme achieves close-to-optimal performance, and outperforms other existing replication schemes.",
Compensation of Modelling Errors Due to Unknown Domain Boundary in Electrical Impedance Tomography,"Electrical impedance tomography is a highly unstable problem with respect to measurement and modeling errors. This instability is especially severe when absolute imaging is considered. With clinical measurements, accurate knowledge about the body shape is usually not available, and therefore an approximate model domain has to be used in the computational model. It has earlier been shown that large reconstruction artefacts result if the geometry of the model domain is incorrect. In this paper, we adapt the so-called approximation error approach to compensate for the modeling errors caused by inaccurately known body shape. This approach has previously been shown to be applicable to a variety of modeling errors, such as coarse discretization in the numerical approximation of the forward model and domain truncation. We evaluate the approach with a simulated example of thorax imaging, and also with experimental data from a laboratory setting, with absolute imaging considered in both cases. We show that the related modeling errors can be efficiently compensated for by the approximation error approach. We also show that recovery from simultaneous discretization related errors is feasible, allowing the use of computationally efficient reduced order models.","Computational modeling,
Conductivity,
Tomography,
Approximation error,
Shape"
Tensor Discriminant Color Space for Face Recognition,"Recent research efforts reveal that color may provide useful information for face recognition. For different visual tasks, the choice of a color space is generally different. How can a color space be sought for the specific face recognition problem? To address this problem, this paper represents a color image as a third-order tensor and presents the tensor discriminant color space (TDCS) model. The model can keep the underlying spatial structure of color images. With the definition of n-mode between-class scatter matrices and within-class scatter matrices, TDCS constructs an iterative procedure to obtain one color space transformation matrix and two discriminant projection matrices by maximizing the ratio of these two scatter matrices. The experiments are conducted on two color face databases, AR and Georgia Tech face databases, and the results show that both the performance and the efficiency of the proposed method are better than those of the state-of-the-art color image discriminant model, which involve one color space transformation matrix and one discriminant projection matrix, specifically in a complicated face database with various pose variations.","Image color analysis,
Tensile stress,
Color,
Face recognition,
Face,
Mathematical model,
Databases"
Adaptive Fuzzy Decentralized Control for Large-Scale Nonlinear Systems With Time-Varying Delays and Unknown High-Frequency Gain Sign,"In this paper, an adaptive fuzzy decentralized robust output feedback control approach is proposed for a class of large-scale strict-feedback nonlinear systems without the measurements of the states. The nonlinear systems in this paper are assumed to possess unstructured uncertainties, time-varying delays, and unknown high-frequency gain sign. Fuzzy logic systems are used to approximate the unstructured uncertainties, K-filters are designed to estimate the unmeasured states, and a special Nussbaum gain function is introduced to solve the problem of unknown high-frequency gain sign. Combining the backstepping technique with adaptive fuzzy control theory, an adaptive fuzzy decentralized robust output feedback control scheme is developed. In order to obtain the stability of the closed-loop system, a new lemma is given and proved. Based on this lemma and Lyapunov-Krasovskii functions, it is proved that all the signals in the closed-loop system are uniformly ultimately bounded and that the tracking errors can converge to a small neighborhood of the origin. The effectiveness of the proposed approach is illustrated from simulation results.",
Processing private queries over untrusted data cloud through privacy homomorphism,"Query processing that preserves both the data privacy of the owner and the query privacy of the client is a new research problem. It shows increasing importance as cloud computing drives more businesses to outsource their data and querying services. However, most existing studies, including those on data outsourcing, address the data privacy and query privacy separately and cannot be applied to this problem. In this paper, we propose a holistic and efficient solution that comprises a secure traversal framework and an encryption scheme based on privacy homomorphism. The framework is scalable to large datasets by leveraging an index-based approach. Based on this framework, we devise secure protocols for processing typical queries such as k-nearest-neighbor queries (kNN) on R-tree index. Moreover, several optimization techniques are presented to improve the efficiency of the query processing protocols. Our solution is verified by both theoretical analysis and performance study.","Encryption,
Indexes,
Query processing,
Data privacy,
Protocols,
Privacy"
Semisupervised Dimensionality Reduction With Pairwise Constraints for Hyperspectral Image Classification,"Dimensionality reduction is an important task in the analysis of hyperspectral image data. While traditional dimensionality reduction methods use class labels as prior information, this letter presents a general semisupervised dimensionality reduction framework for hyperspectral image classification based on new prior information, i.e., pairwise constraints which specify whether a pair of examples belongs to the same class or not. The proposed semisupervised dimensionality reduction framework contains two terms: 1) a discrimination term that assesses the separability between classes; and 2) a regularization term that characterizes some property of the original data set. Furthermore, a novel semisupervised dimensionality reduction method is derived from the framework based on sparse representation. Experimental results on two hyperspectral image data sets show that the proposed algorithms are remarkably effective in comparison to traditional dimensionality reduction methods.","Hyperspectral imaging,
Principal component analysis,
Accuracy,
Support vector machines,
Feature extraction"
Tactile Sensing for Mobile Manipulation,"Tactile information is valuable in determining properties of objects that are inaccessible from visual perception. In this paper, we present a tactile perception strategy that allows a mobile robot with tactile sensors in its gripper to measure a generic set of tactile features while manipulating an object. We propose a switching velocity-force controller that grasps an object safely and reveals, at the same time, its deformation properties. By gently rolling the object, the robot can extract additional information about the contents of the object. As an application, we show that a robot can use these features to distinguish the internal state of bottles and cans-purely from tactile sensing-from a small training set. The robot can distinguish open from closed bottles and cans and full ones from empty ones. We also show how the high-frequency component in tactile information can be used to detect movement inside a container, e.g., in order to detect the presence of liquid. To prove that this is a hard recognition problem, we also conducted a comparative study with 17 human test subjects. The recognition rates of the human subjects were comparable with that of the robot.","Force,
Grippers,
Tactile sensors,
Humans"
A Nonrigid Registration Framework Using Spatially Encoded Mutual Information and Free-Form Deformations,"Mutual information (MI) registration including spatial information has been shown to perform better than the traditional MI measures for certain nonrigid registration tasks. In this work, we first provide new insight to problems of the MI-based registration and propose to use the spatially encoded mutual information (SEMI) to tackle these problems. To encode spatial information, we propose a hierarchical weighting scheme to differentiate the contribution of sample points to a set of entropy measures, which are associated to spatial variable values. By using free-form deformations (FFDs) as the transformation model, we can first define the spatial variable using the set of FFD control points, and then propose a local ascent optimization scheme for nonrigid SEMI registration. The proposed SEMI registration can improve the registration accuracy in the nonrigid cases where the traditional MI is challenged due to intensity distortion, contrast enhancement, or different imaging modalities. It also has a similar computation complexity to the registration using traditional MI measures, improving up to two orders of magnitude of computation time compared to the traditional schemes. We validate our algorithms using phantom brain MRI, simulated dynamic contrast enhanced mangetic resonance imaging (MRI) of the liver, and in vivo cardiac MRI. The results show that the SEMI registration significantly outperforms the traditional MI registration.",
Symmetric Nonnegative Matrix Factorization: Algorithms and Applications to Probabilistic Clustering,"Nonnegative matrix factorization (NMF) is an unsupervised learning method useful in various applications including image processing and semantic analysis of documents. This paper focuses on symmetric NMF (SNMF), which is a special case of NMF decomposition. Three parallel multiplicative update algorithms using level 3 basic linear algebra subprograms directly are developed for this problem. First, by minimizing the Euclidean distance, a multiplicative update algorithm is proposed, and its convergence under mild conditions is proved. Based on it, we further propose another two fast parallel methods: α-SNMF and β -SNMF algorithms. All of them are easy to implement. These algorithms are applied to probabilistic clustering. We demonstrate their effectiveness for facial image clustering, document categorization, and pattern clustering in gene expression.","Symmetric matrices,
Clustering algorithms,
Algorithm design and analysis,
Probabilistic logic,
Convergence,
MATLAB,
Linear algebra"
Detection of New Vessels on the Optic Disc Using Retinal Photographs,"Proliferative diabetic retinopathyis a rare condition likely to lead to severe visual impairment. It is characterized by the development of abnormal new retinal vessels. We describe a method for automatically detecting new vessels on the optic disc using retinal photography. Vessel-like candidate segments are first detected using a method based on watershed lines and ridge strength measurement. Fifteen feature parameters, associated with shape, position, orientation, brightness, contrast and line density are calculated for each candidate segment. Based on these features, each segment is categorized as normal or abnormal using a support vector machine (SVM) classifier. The system was trained and tested by cross-validation using 38 images with new vessels and 71 normal images from two diabetic retinal screening centers and one hospital eye clinic. The discrimination performance of the fifteen features was tested against a clinical reference standard. Fourteen features were found to be effective and used in the final test. The area under the receiver operator characteristic curve was 0.911 for detecting images with new vessels on the disc. This accuracy may be sufficient for it to play a useful clinical role in an automated retinopathy analysis system.","Image segmentation,
Pixel,
Retina,
Support vector machines,
Retinopathy,
Diabetes,
Optical imaging"
Accurate and Conforming Mixed Discretization of the MFIE,"In this letter, a novel discretization scheme for the magnetic field integral equation is presented. The new scheme is designated “mixed” because it uses Rao-Wilton-Glisson functions to expand the current density and Buffa-Christiansen functions to test the magnetic field radiated by the candidate solution. The convergent nature of the proposed mixed MFIE is theoretically proven, and numerical results showing that the proposed method yields more accurate results than the classical one are presented.","Testing,
Integral equations,
Antennas,
Mathematical model,
Equations,
Scattering,
Moment methods"
Utilizing shared vehicle trajectories for data forwarding in vehicular networks,"Vehicular ad hoc networks (VANETs) represent promising technologies for improving driving safety and efficiency. Due to the highly dynamic driving patterns of vehicles, it has been a challenging research problem to achieve effective and time-sensitive data forwarding in vehicular networks. In this paper, a Shared-Trajectory-based Data Forwarding Scheme (STDFS) is proposed, which utilizes shared vehicle trajectory information to address this problem. With access points sparsely deployed to disseminate vehicles' trajectory information, the encounters between vehicles can be predicted by the vehicle that has data to send, and an encounter graph is then constructed to aid packet forwarding. This paper focuses on the specific issues of STDFS such as encounter prediction, encounter graph construction, forwarding sequence optimization and the data forwarding process. Simulation results demonstrate the effectiveness of the proposed scheme.",
Nanoscale Bipolar and Complementary Resistive Switching Memory Based on Amorphous Carbon,"There has been a strong demand for developing an ultradense and low-power nonvolatile memory technology. In this paper, we present a carbon-based resistive random access memory device with a carbon nanotube (CNT) electrode. An amorphous carbon layer is sandwiched between the fast-diffusing top metal electrode and the bottom CNT electrode, exhibiting a bipolar switching behavior. The use of the CNT electrode can substantially reduce the size of the active device area. We also demonstrate a carbon-based complementary resistive switch (CRS) consisting of two back-to-back connected memory cells, providing a route to reduce the sneak current in the cross-point memory. The bit information of the CRS cell is stored in a high-resistance state, thus reducing the power consumption of the CRS memory cell. This paper provides valuable early data on the effect of electrode size scaling down to nanometer size.",
Binary-Partition-Assisted MAC-Layer Broadcast for Emergency Message Dissemination in VANETs,"Vehicular ad hoc networks (VANETs) have recently been considered as an attractive network architecture to provide various services ranging from road safety to entertainment applications. In this paper, we propose an IEEE-802.11-based multihop broadcast protocol to address the issue of emergency message dissemination in VANETs. The protocol adopts a binary-partition-based approach to repetitively divide the area inside the transmission range to obtain the furthest possible segment. The forwarding duty is then delegated to a vehicle chosen in that segment. Aside from accomplishing directional broadcast for highway scenario, the protocol also exhibits good adaptation to complex road structures. The main focus of the paper lies in reducing broadcast delay, which is an important factor for time-critical safety applications. Most importantly, the contention delay remains almost constant, irrespective of vehicle density. Mathematical analysis is performed to assess the effectiveness of the protocol. Simulation results demonstrate that the proposed protocol imparts greater performance in terms of latency and message progress when compared with contemporary multihop broadcast protocols for VANETs.",
Large vocabulary continuous speech recognition with context-dependent DBN-HMMS,"The context-independent deep belief network (DBN) hidden Markov model (HMM) hybrid architecture has recently achieved promising results for phone recognition. In this work, we propose a context-dependent DBN-HMM system that dramatically outperforms strong Gaussian mixture model (GMM)-HMM baselines on a challenging, large vocabulary, spontaneous speech recognition dataset from the Bing mobile voice search task. Our system achieves absolute sentence accuracy improvements of 5.8% and 9.2% over GMM-HMMs trained using the minimum phone error rate (MPE) and maximum likelihood (ML) criteria, respectively, which translate to relative error reductions of 16.0% and 23.2%.","Hidden Markov models,
Training,
Accuracy,
Speech recognition,
Artificial neural networks,
Vocabulary,
Acoustics"
Partial discharge behavior within a spherical cavity in a solid dielectric material as a function of frequency and amplitude of the applied voltage,"Modeling of the partial discharge (PD) process allows a better understanding of the phenomena. In this paper, a simulation model for spherical cavities within a homogeneous dielectric material has been developed. The model is implemented using Finite Element Analysis (FEA) software in parallel with a mathematical package. This method provides many advantages over previous PD models because discharge events can be simulated dynamically and the electric field in the cavity can be calculated numerically. The model has been used to study the effect of different amplitudes and frequencies of the applied voltage and simulation results have been compared with experimental measurement results. It is found that certain model parameters are dependent on the applied stress and parameters that clearly affect PD activity can be readily identified, these parameters include; the electron detrapping time constant, the cavity surface conductivity, the initial electron generation rate and the extinction voltage. The influence of surface charge decay through conduction along the cavity wall on PD activity has also been studied.","Cavity resonators,
Partial discharges,
Mathematical model,
Discharges,
Surface discharges,
Electric fields,
Surface treatment"
A Hybrid Multiobjective Evolutionary Approach for Improving the Performance of Wireless Sensor Networks,"The increasing in the demand for Wireless Sensor Networks (WSNs) has intensified studies which are dedicated to obtain more energy-efficient solutions, since the energy storage limitation is critical in those systems. Additionally, there are other aspects which usually must be ensured in order to get an acceptable performance of WSNs, such as area coverage and network connectivity. This paper proposes a procedure for enhancing the performance of WSNs: a multiobjective hybrid optimization algorithm is employed for solving the Dynamic Coverage and Connectivity Problem (DCCP) in flat WSNs subjected to node failures. This method combines a multiobjective global on-demand algorithm (MGoDA), which improves the current DCCP solution using a Genetic Algorithm, with a local on line algorithm (LoA), which is intended to restore the network coverage soon after any failure. The proposed approach is compared with an Integer Linear Programming (ILP)-based approach and a similar mono-objective approach with regard to coverage, network lifetime and required running time for achieving the optimal solution provided by each method. Results achieved for a test instance show that the hybrid approach presented can improve the performance of the WSN obtaining good solutions with a considerably smaller computational time than ILP. The multiobjective approach still provides a feasible method for extending WSNs lifetime with slight decreasing in the network mean coverage.","Wireless sensor networks,
Postal services,
Mathematics,
Energy storage,
Genetic algorithms,
Integer linear programming,
MONOS devices,
Testing,
Evolutionary computation,
Wireless communication"
More Balanced Boolean Functions With Optimal Algebraic Immunity and Good Nonlinearity and Resistance to Fast Algebraic Attacks,"In this paper, three constructions of balanced Boolean functions with optimal algebraic immunity are proposed. It is checked that, at least for small numbers of input variables, these functions have good behavior against fast algebraic attacks as well. Other cryptographic properties such as algebraic degree and nonlinearity of the constructed functions are also analyzed. Lower bounds on the nonlinearity are proved, which are similar to the best bounds obtained for known Boolean functions resisting algebraic attacks and fast algebraic attacks. Moreover, it is checked that for the number n of variables with 5 ≤ n ≤ 19, the proposed n-variable Boolean functions have in fact very good nonlinearity.","Boolean functions,
Polynomials,
Cryptography,
Hamming weight,
Resistance,
Resists,
Generators"
Compact Low-Loss Integration of High- Q 3-D Filters With Highly Efficient Antennas,"A novel synthesis technique to integrate high-Q 3-D filters with highly efficient slot antennas is presented in this paper. This technique allows for compact integration of 3-D filters and antennas with very high antenna efficiency and significantly reduced form factor of integrated RF front ends. Prototype four-pole Chebyshev cavity filters integrated with slot antennas are demonstrated at X-band using both coaxial and coplanar waveguide feeding. The center frequency and fractional bandwidth of the filter/antenna system with coaxial feeding are 9.96 GHz and 6.0%, respectively. Due to the high-Q factor (~850) of the cavity resonator, the efficiency of this filter/antenna system is measured to be 89%, compared with the measured S21 of -0.5 dB (89%) for an identical filter. This means a near 100% efficient slot antenna is achieved within this integrated filter/antenna system. The measured impedance matching, efficiency, gain, and radiation pattern closely agree with simulation results. Equivalent-circuit models of the integrated filter/antenna system are developed and verified with full-wave simulations. This technique can be applied for filter/antenna integration in all microwave, millimeter-wave, and submillimeter-wave frequency regions.","Slot antennas,
Couplings,
Bandwidth,
Cavity resonators,
Integrated circuit modeling,
Resonant frequency"
Effective Pseudonoise Sequence and Decoding Function for Imperceptibility and Robustness Enhancement in Time-Spread Echo-Based Audio Watermarking,"This paper proposes an effective pseudonoise (PN) sequence and the corresponding decoding function for time-spread echo-based audio watermarking. Different from the traditional PN sequence used in time-spread echo hiding, the proposed PN sequence has two features. Firstly, the echo kernel resulting from the new PN sequence has frequency characteristics with smaller magnitudes in perceptually significant region. This leads to higher perceptual quality. Secondly, the correlation function of the new PN sequence has three times more large peaks than that of the existing PN sequence. Based on this feature, we propose a new decoding function to improve the robustness of time-spread echo-based audio watermarking. The effectiveness of the proposed PN sequence and decoding function is illustrated by theoretical analysis, simulation examples, and listening test.","Watermarking,
Decoding,
Kernel,
Robustness,
Encoding,
Resonant frequency"
Super-Resolution Method for Face Recognition Using Nonlinear Mappings on Coherent Features,"Low-resolution (LR) of face images significantly decreases the performance of face recognition. To address this problem, we present a super-resolution method that uses nonlinear mappings to infer coherent features that favor higher recognition of the nearest neighbor (NN) classifiers for recognition of single LR face image. Canonical correlation analysis is applied to establish the coherent subspaces between the principal component analysis (PCA) based features of high-resolution (HR) and LR face images. Then, a nonlinear mapping between HR/LR features can be built by radial basis functions (RBFs) with lower regression errors in the coherent feature space than in the PCA feature space. Thus, we can compute super-resolved coherent features corresponding to an input LR image according to the trained RBF model efficiently and accurately. And, face identity can be obtained by feeding these super-resolved features to a simple NN classifier. Extensive experiments on the Facial Recognition Technology, University of Manchester Institute of Science and Technology, and Olivetti Research Laboratory databases show that the proposed method outperforms the state-of-the-art face recognition algorithms for single LR image in terms of both recognition rate and robustness to facial variations of pose and expression.",
Image compression using learned dictionaries by RLS-DLA and compared with K-SVD,"The recently presented recursive least squares dictionary learning algorithm (RLS-DLA) is tested in a general image compression application. Dictionaries are learned in the pixel domain and in the 9/7 wavelet domain, and then tested in a straightforward compression scheme. Results are compared with state-of-the-art compression methods. The proposed compression scheme using RLS DLA learned dictionaries in the 9/7 wavelet domain per forms better than using dictionaries learned by other methods. The compression rate is just below the JPEG 2000 rate which is promising considering the simple entropy coding used.","Dictionaries,
Image coding,
Training,
Wavelet domain,
Discrete cosine transforms,
PSNR,
Transform coding"
Remote Sensing of Heart Rate and Patterns of Respiration on a Stationary Subject Using 94-GHz Millimeter-Wave Interferometry,"Using continuous wave, 94-GHz millimeter-wave interferometry, a signal representing chest wall motion can be obtained that contains both the heart rate and respiration patterns of a human subject. These components have to be separated from each other in the received signal. Our method was to use the quadrature and in-phase components of the signal, after removing the mean of each, to find the phase, unwrap it, and convert it to a displacement measurement. Using this, the power spectrum was examined for peaks, which corresponded to the heart rate and respiration rate. The displacement waveform of the chest was also analyzed for discrete heartbeats using a novel wavelet decomposition technique.",
Spectral Clustering on Multiple Manifolds,"Spectral clustering (SC) is a large family of grouping methods that partition data using eigenvectors of an affinity matrix derived from the data. Though SC methods have been successfully applied to a large number of challenging clustering scenarios, it is noteworthy that they will fail when there are significant intersections among different clusters. In this paper, based on the analysis that SC methods are able to work well when the affinity values of the points belonging to different clusters are relatively low, we propose a new method, called spectral multi-manifold clustering (SMMC), which is able to handle intersections. In our model, the data are assumed to lie on or close to multiple smooth low-dimensional manifolds, where some data manifolds are separated but some are intersecting. Then, local geometric information of the sampled data is incorporated to construct a suitable affinity matrix. Finally, spectral method is applied to this affinity matrix to group the data. Extensive experiments on synthetic as well as real datasets demonstrate the promising performance of SMMC.","Manifolds,
Euclidean distance,
Clustering methods,
Learning systems,
Tuning,
Covariance matrix,
Estimation"
Viewpoint-aware object detection and pose estimation,"We describe an approach to category-level detection and viewpoint estimation for rigid 3D objects from single 2D images. In contrast to many existing methods, we directly integrate 3D reasoning with an appearance-based voting architecture. Our method relies on a nonparametric representation of a joint distribution of shape and appearance of the object class. Our voting method employs a novel parametrization of joint detection and viewpoint hypothesis space, allowing efficient accumulation of evidence. We combine this with a re-scoring and refinement mechanism, using an ensemble of view-specific Support Vector Machines. We evaluate the performance of our approach in detection and pose estimation of cars on a number of benchmark datasets.",
A Reliability-Oriented Transmission Service in Wireless Sensor Networks,"Reliable communications are essential for most applications in wireless sensor networks (WSNs). In traditional approaches, the per-hop and end-to-end (E2E) recovery schemes are widely used. These schemes, however, suffer from low E2E success rate and poor energy efficiency in large-scale real environments. Through empirical studies, in this paper we identify three major problems that hinder the efficient and reliable communications. To address these problems, we propose a novel in-middle recovery scheme and realize it by designing and implementing a proliferation routing. Proliferation routing integrates three core technologies, namely, capability-based path finder, a randomized dispersity, and reproduction. Proliferation routing offers great flexibilities for transmissions. It cannot only be applied with any Medium Access Control (MAC) protocols and routing metrics, but also obtains a desired service quality (i.e., transmission success rate, energy cost, etc.) by controlling the system parameters. To demonstrate the effectiveness of proliferation routing, we thoroughly analyze its performance. We also conduct performance evaluations through implementation experiments as well as simulations. In a specific experimental setup, proliferation routing can increase the E2E transmission success rate up to 80 percent compared with the well-known hop-based routing and flooding.","Network routing,
Wireless sensor networks,
Media Access Protocol,
Wireless communication,
Algorithm design and analysis,
Network topology"
Deformable Registration of Glioma Images Using EM Algorithm and Diffusion Reaction Modeling,"This paper investigates the problem of atlas registration of brain images with gliomas. Multiparametric imaging modalities (T1, T1-CE, T2, and FLAIR) are first utilized for segmentations of different tissues, and to compute the posterior probability map (PBM) of membership to each tissue class, using supervised learning. Similar maps are generated in the initially normal atlas, by modeling the tumor growth, using reaction-diffusion equation. Deformable registration using a demons-like algorithm is used to register the patient images with the tumor bearing atlas. Joint estimation of the simulated tumor parameters (e.g., location, mass effect and degree of infiltration), and the spatial transformation is achieved by maximization of the log-likelihood of observation. An expectation-maximization algorithm is used in registration process to estimate the spatial transformation and other parameters related to tumor simulation are optimized through asynchronous parallel pattern search (APPSPACK). The proposed method has been evaluated on five simulated data sets created by statistically simulated deformations (SSD), and fifteen real multichannel glioma data sets. The performance has been evaluated both quantitatively and qualitatively, and the results have been compared to ORBIT, an alternative method solving a similar problem. The results show that our method outperforms ORBIT, and the warped templates have better similarity to patient images.","Tumors,
Computational modeling,
Mathematical model,
Biological system modeling,
Equations,
Support vector machines,
Orbits"
An All-Digital 12 pJ/Pulse IR-UWB Transmitter Synthesized From a Standard Cell Library,"This paper presents an all-digital impulse radio ultra-wideband (IR-UWB) transmitter. All functional blocks in the transmitter are implemented with digital standard cells and automatically place-and-routed by design tools. The center frequency and the bandwidth of the UWB pulses are digitally tuned to compensate for variations, or target different applications. This paper also proposes a calibration scheme and modeling of a cell-based digitally controlled oscillator (DCO), which takes systematic mismatch from automatic place-and-route into account. The transmitter is fabricated in a 65 nm CMOS process, and occupies a core area of 0.032 mm2. The transmitter operates in the 3.1-5.0 GHz UWB band with leakage power of 170 μW and active energy consumption ranges from 8 pJ/pulse to 16 pJ/pulse, which combine to a total minimum energy/pulse of 12 pJ/pulse at 50 Mb/s.",
Bringing clothing into desired configurations with limited perception,"We consider the problem of autonomously bringing an article of clothing into a desired configuration using a general-purpose two-armed robot. We propose a hidden Markov model (HMM) for estimating the identity of the article and tracking the article's configuration throughout a specific sequence of manipulations and observations. At the end of this sequence, the article's configuration is known, though not necessarily desired. The estimated identity and configuration of the article are then used to plan a second sequence of manipulations that brings the article into the desired configuration. We propose a relaxation of a strain limiting finite element model for cloth simulation that can be solved via convex optimization; this serves as the basis of the transition and observation models of the HMM. The observation model uses simple perceptual cues consisting of the height of the article when held by a single gripper and the silhouette of the article when held by two grippers. The model accurately estimates the identity and configuration of clothing articles, enabling our procedure to autonomously bring a variety of articles into desired configurations that are useful for other tasks, such as folding.","Hidden Markov models,
Grippers,
Clothing,
Grasping,
Robot kinematics,
Planning"
Feasibility Analysis of the Positioning of Superconducting Fault Current Limiters for the Smart Grid Application Using Simulink and SimPowerSystem,"One of the most important topics regarding the application of superconducting fault current limiters (SFCL) for upcoming smart grid is related to its possible effect on the reduction of abnormal fault current and the suitable location in the micro grids. Due to the grid connection of the micro grids with the current power grids, excessive fault current is a serious problem to be solved for successful implementation of micro grids. However, a shortage of research concerning the location of SFCL in micro grid is felt. In this work, a resistive type SFCL model was implemented by integrating Simulink and SimPowerSystem blocks in Matlab. The designed SFCL model could be easily utilized for determining an impedance level of SFCL according to the fault-current-limitation requirements of various kinds of the smart grid system. In addition, typical smart grid model including generation, transmission and distribution network with dispersed energy resource was modeled to determine the location and the performance of the SFCL. As for a dispersed energy resource, 10 MVA wind farm was considered for the simulation. Three phase faults have been simulated at different locations in smart grid and the effect of the SFCL and its location on the wind farm fault current was evaluated. Consequently, the optimum arrangement of the SFCL location in Smart Grid with renewable resources has been proposed and its remarkable performance has been suggested.","Fault currents,
Wind farms,
Smart grids,
Mathematical model,
Power transmission lines"
Scheduling for Optimal Rate Allocation in Ad Hoc Networks With Heterogeneous Delay Constraints,"This paper studies the problem of scheduling in single-hop wireless networks with real-time traffic, where every packet arrival has an associated deadline and a minimum fraction of packets must be transmitted before the end of the deadline. Using optimization and stochastic network theory we study the problem of scheduling to meet quality of service (QoS) requirements under heterogeneous delay constraints and time-varying channel conditions. Our analysis results in an optimal scheduling algorithm which fairly allocates data rates to all flows while meeting long-term delay demands. We also prove that under a simplified scenario our solution translates into a greedy strategy that makes optimal decisions with low complexity.",
Proportionate Affine Projection Sign Algorithms for Network Echo Cancellation,"Two proportionate affine projection sign algorithms (APSAs) are proposed for network echo cancellation (NEC) applications where the impulse response is often real-valued with sparse coefficients and long filter length. The proposed proportionate-type algorithms can achieve fast convergence and low steady-state misalignment by adopting a proportionate regularization matrix to the APSA. Benefiting from the characteristics of l1-norm optimization, affine projection, and proportionate matrix, the new algorithms are more robust to impulsive interferences and colored input than the proportionate least mean squares (PNLMS) algorithm and the robust proportionate affine projection algorithm (Robust PAPA). The new algorithms also achieve much faster convergence rate in sparse impulse responses than the original APSA and the normalized sign algorithm (NSA). The new algorithms are robust to all types of NEC impulse response with different sparseness without the need to change parameters or estimate the sparseness of the impulse response. The computational complexity of the new algorithms is lower than the affine projection algorithm (APA) family due to the elimination of the matrix inversion.",
Voice Pathology Detection and Discrimination Based on Modulation Spectral Features,"In this paper, we explore the information provided by a joint acoustic and modulation frequency representation, referred to as modulation spectrum, for detection and discrimination of voice disorders. The initial representation is first transformed to a lower dimensional domain using higher order singular value decomposition (HOSVD). From this dimension-reduced representation a feature selection process is suggested using an information-theoretic criterion based on the mutual information between voice classes (i.e., normophonic/dysphonic) and features. To evaluate the suggested approach and representation, we conducted cross-validation experiments on a database of sustained vowel recordings from healthy and pathological voices, using support vector machines (SVMs) for classification. For voice pathology detection, the suggested approach achieved a classification accuracy of 94.1±0.28% (95% confidence interval), which is comparable to the accuracy achieved using cepstral-based features. However, for voice pathology classification the suggested approach significantly outperformed the performance of cepstral-based features.","Frequency modulation,
Pathology,
Acoustics,
Speech,
Mutual information,
Harmonic analysis"
"Static facial expression analysis in tough conditions: Data, evaluation protocol and benchmark","Quality data recorded in varied realistic environments is vital for effective human face related research. Currently available datasets for human facial expression analysis have been generated in highly controlled lab environments. We present a new static facial expression database Static Facial Expressions in the Wild (SFEW) extracted from a temporal facial expressions database Acted Facial Expressions in the Wild (AFEW) [9], which we have extracted from movies. In the past, many robust methods have been reported in the literature. However, these methods have been experimented on different databases or using different protocols within the same databases. The lack of a standard protocol makes it difficult to compare systems and acts as a hindrance in the progress of the field. Therefore, we propose a person independent training and testing protocol for expression recognition as part of the BEFIT workshop. Further, we compare our dataset with the JAFFE and Multi-PIE datasets and provide baseline results.","Databases,
Face,
Protocols,
Accuracy,
Humans,
Motion pictures,
Conferences"
Preamble Design Using Embedded Signaling for OFDM Broadcast Systems Based on Reduced-Complexity Distance Detection,"The second-generation digital terrestrial television broadcasting standard adopts the so-called P1 symbol as the preamble for initial synchronization. The P1 symbol also carries a number of basic transmission parameters, including the fast Fourier transform size and the single-input/single-output as well as multiple-input/single-output mode, to appropriately configure the receiver for carrying out the subsequent processing. In this paper, an improved preamble design is proposed, where a pair of training sequences is inserted in the frequency domain, and their distance is used for transmission parameter signaling. At the receiver, only a low-complexity correlator is required for the detection of the signaling. Both the coarse carrier frequency offset and the signaling can simultaneously be estimated by detecting the aforementioned correlation. Compared with the standardized P1 symbol, the proposed preamble design significantly reduces the complexity of the receiver while retaining high robustness in frequency-selective fading channels. Furthermore, we demonstrate that the proposed preamble design achieves better signaling performance than the standardized P1 symbol despite reducing the numbers of multiplications and additions by about 40% and 20%, respectively.","Correlation,
OFDM,
Digital video broadcasting,
Receivers,
Training,
Signal to noise ratio,
AWGN channels"
An Efficient Gate Library for Ambipolar CNTFET Logic,"Recently, several emerging technologies have been reported as potential candidates for controllable ambipolar devices. Controllable ambipolarity is a desirable property that enables the on-line configurability of n-type and p-type device polarity. In this paper, we introduce a new design methodology for logic gates based on controllable ambipolar devices, with an emphasis on carbon nanotubes as the candidate technology. Our technique results in ambipolar gates with a higher expressive power than conventional complementary metal-oxidesemiconductor (CMOS) libraries. We propose a library of static ambipolar carbon nanotube field effect transistor (CNTFET) gates based on generalized NOR-NAND-AOI-OAI primitives, which efficiently implements XOR-based functions. Technology mapping of several multi-level logic benchmarks that extensively use the XOR function, including multipliers, adders, and linear circuits, with ambipolar CNTFET logic gates indicates that on average, it is possible to reduce the number of logic levels by 42%, the delay by 26%, and the power consumption by 32%, resulting in a energy-delay-product (EDP) reduction of 59 % over the same circuits mapped with unipolar CNTFET logic gates. Based on the projections in [1], where it is stated that defectfree CNTFETs will provide a 5x performance improvement over metal-oxide-semiconductor field effect transistors, the ambipolar library provides a performance improvement of 7x, a 57% reduction in power consumption, and a 20x improvement in EDP over the CMOS library.","Logic gates,
CNTFETs,
Libraries,
CMOS integrated circuits,
Power demand,
Delay"
THz Metrology and Instrumentation,"This paper gives an overview of measurement techniques used in the THz region of the electromagnetic spectrum, from about 100 GHz to several THz. Currently available components necessary for THz metrology, such as sources, detectors and passives, are briefly described. A discussion of power measurements, vector network analysis and antenna measurements as well as the limitations of these measurements at THz frequencies is given. The paper concludes with a summary of available components and instrumentation for THz metrology at the time of writing.","Power measurement,
Instruments,
Metrology,
Detectors,
Noise,
Antenna measurements,
Microwave radiometry"
Bio-Inspired Relay Node Placement Heuristics for Repairing Damaged Wireless Sensor Networks,"Due to the harsh surroundings and violent nature of wireless sensor network (WSN) applications, the network sometimes suffers a large-scale damage that involves several nodes and would thus create multiple disjoint partitions. This paper investigates a strategy for recovering from such damage through the placement of relay nodes (RNs) and promotes a novel approach. The proposed approach opts to reestablish connectivity (i.e., 1-vertex connectivity) using the least number of relays while ensuring a certain quality in the formed topology. Unlike contemporary schemes that often form a minimum spanning tree among the isolated segments, the proposed approach establishes a topology that resembles a spider web, for which the segments are situated at the perimeter. Such a topology not only exhibits stronger connectivity than a minimum spanning tree but achieves better sensor coverage and enables balanced distribution of traffic load among the employed relays as well. To further increase the robustness of the formed topology, the SpiderWeb approach is further extended so that the final topology is guaranteed to be 2-vertex connected. Both centralized and distributed implementations of the SpiderWeb approach are discussed. The simulation results demonstrate the effectiveness of the proposed recovery algorithm.","Relays,
Sensors,
Topology,
Network topology,
Wireless sensor networks,
Partitioning algorithms,
Complexity theory"
Joint Pricing and Power Allocation for Dynamic Spectrum Access Networks with Stackelberg Game Model,"In this work we study joint pricing and power allocation for Dynamic Spectrum Access (DSA) networks with Stackelberg game. In our model, Primary User (PU) is the game leader and jointly determines its power allocation (to guarantee its QoS requirement) and the interference price charged to Secondary User (SU) (to reap revenue). Meanwhile, SU is the game follower and determines its power demand in response to PU's decisions. We quantify PU's and SU's benefit from the channel sharing model by deriving the Stackelberg equilibrium. Our results show that PU's equilibrium profit is asymptotically upper bounded with its marginal power cost and rate requirement. A distributed algorithm is proposed to find the equilibrium. We also propose an incentive-compatible mechanism for PU and SU to keep the social welfare optimum cooperatively. We extend our Stackelberg game to the multiple SUs scenario, where the interference among SUs results in a noncooperative power demand subgame. We propose a low-complexity heuristic algorithm for PU to maximize its profit. Our results show that PU can benefit by selecting multiple SUs to share its channel if SUs' mutual interference is limited.","Resource management,
Power demand,
Games,
Interference,
Pricing,
Convergence,
Joints"
On integrating orthogonal information retrieval methods to improve traceability recovery,"Different Information Retrieval (IR) methods have been proposed to recover traceability links among software artifacts. Until now there is no single method that sensibly outperforms the others, however, it has been empirically shown that some methods recover different, yet complementary traceability links. In this paper, we exploit this empirical finding and propose an integrated approach to combine orthogonal IR techniques, which have been statistically shown to produce dissimilar results. Our approach combines the following IR-based methods: Vector Space Model (VSM), probabilistic Jensen and Shannon (JS) model, and Relational Topic Modeling (RTM), which has not been used in the context of traceability link recovery before. The empirical case study conducted on six software systems indicates that the integrated method outperforms stand-alone IR methods as well as any other combination of non-orthogonal methods with a statistically significant margin.","Unified modeling language,
Vocabulary,
Measurement,
Accuracy"
Iris Matching Based on Personalized Weight Map,"Iris recognition typically involves three steps, namely, iris image preprocessing, feature extraction, and feature matching. The first two steps of iris recognition have been well studied, but the last step is less addressed. Each human iris has its unique visual pattern and local image features also vary from region to region, which leads to significant differences in robustness and distinctiveness among the feature codes derived from different iris regions. However, most state-of-the-art iris recognition methods use a uniform matching strategy, where features extracted from different regions of the same person or the same region for different individuals are considered to be equally important. This paper proposes a personalized iris matching strategy using a class-specific weight map learned from the training images of the same iris class. The weight map can be updated online during the iris recognition procedure when the successfully recognized iris images are regarded as the new training data. The weight map reflects the robustness of an encoding algorithm on different iris regions by assigning an appropriate weight to each feature code for iris matching. Such a weight map trained by sufficient iris templates is convergent and robust against various noise. Extensive and comprehensive experiments demonstrate that the proposed personalized iris matching strategy achieves much better iris recognition performance than uniform strategies, especially for poor quality iris images.","Iris recognition,
Hamming distance,
Eyelashes,
Eyelids,
Feature extraction"
MUSTER: Adaptive Energy-Aware Multisink Routing in Wireless Sensor Networks,"Wireless sensor networks (WSNs) are increasingly proposed for applications characterized by many-to-many communication, where multiple sources report their data to multiple sinks. Unfortunately, mainstream WSN collection protocols are generally designed to account for a single sink and, dually, WSN multicast protocols optimize communication from a single source. In this paper, we present MUSTER, a routing protocol expressly designed for many-to-many communication. First, we devise an analytical model to compute, in a centralized manner, the optimal solution to the problem of simultaneously routing from multiple sources to multiple sinks. Next, we illustrate heuristics approximating the optimal solution in a distributed setting, and their implementation in MUSTER. To increase network lifetime, MUSTER minimizes the number of nodes involved in many-to-many routing and balances their forwarding load. We evaluate MUSTER in emulation and in a real WSN testbed. Results indicate that our protocol builds near-optimal routing paths, doubles the WSN lifetime, and overall delivers to the user 2.5 times the amount of raw data w.r.t. mainstream protocols. Moreover, MUSTER is intrinsically amenable to in-network aggregation, pushing the improvements up to a 180 percent increase in lifetime and a four-time increase in data yield.","Distributed processing,
Wireless sensor networks,
Batteries,
Performance evaluation,
Network topology"
Cyber-Individual Meets Brain Informatics,"To help people live better in today's digitally explosive environment, the authors envision a Cyber-Individual (Cyber-I) that is the counterpart of a real individual in the physical world.","Informatics,
Bioinformatics,
Information processing,
Brain models,
Digital images,
Solid modeling"
Prediction of Radiated Emissions Using Near-Field Measurements,"A procedure is developed to predict electromagnetic interference from electronic products using near-field scan data. Measured near-field data are used to define equivalent electric and magnetic current sources characterizing the electromagnetic emissions from an electronic circuit. Reconciliation of the equivalent sources is performed to allow the sources to be accurately applied within full-wave numerical modeling tools like finite-difference time domain (FDTD). Results show that the radiated fields must typically be represented by both electric and magnetic current sources if scattering and multiple-reflections from nearby objects are to be taken into account. The accuracy of the approach is demonstrated by predicting the fields generated by a microstrip trace within and outside of a slotted enclosure, and by predicting the fields generated by the microstrip trace close to a long wire. Values predicted from near-field scan data match those from full-wave simulations or measurements within 6 dB.","Magnetic domains,
Microstrip,
Electric variables measurement,
Antennas,
Probes,
Magnetic field measurement,
Time domain analysis"
Characterization and Implementation of Fault-Tolerant Vertical Links for 3-D Networks-on-Chip,"Through silicon vias (TSVs) provide an efficient way to support vertical communication among different layers of a vertically stacked chip, enabling scalable 3-D networks-on-chip (NoC) architectures. Unfortunately, low TSV yields significantly impact the feasibility of high-bandwidth vertical connectivity. In this paper, we present a semi-automated design flow for 3-D NoCs including a defect-tolerance scheme to increase the global yield of 3-D stacked chips. Starting from an accurate physical and geometrical model of TSVs: 1) we extract a circuit-level model for vertical interconnections; 2) we use it to evaluate the design implications of extending switch architectures with ports in the vertical direction; moreover, 3) we present a defect-tolerance technique for TSV-based multi-bit links through an effective use of redundancy; and finally, 4) we present a design flow allowing for post-layout simulation of NoCs with links in all three physical dimensions. Experimental results show that a 3-D NoC implementation yields around 10% frequency improvement over a 2-D one, thanks to the propagation delay advantage of TSVs and the shorter links. In addition, the adopted fault tolerance scheme demonstrates a significant yield improvement, ranging from 66% to 98%, with a low area cost (20.9% on a vertical link in a NoC switch, which leads a modest 2.1% increase in the total switch area) in 130 nm technology, with minimal impact on very large-scale integrated design and test flows.","Switches,
Through-silicon vias,
Capacitance,
Integrated circuit interconnections,
Timing,
Routing,
Metals"
Geometric Invariant Audio Watermarking Based on an LCM Feature,"The development of a geometric invariant audio watermarking scheme without degrading acoustical quality is challenging work. This paper proposes a multi-bit spread-spectrum audio watermarking scheme based on a geometric invariant log coordinate mapping (LCM) feature. The LCM feature is very robust to audio geometric distortions. The watermark is embedded in the LCM feature, but it is actually embedded in the Fourier coefficients which are mapped to the feature via LCM, so the embedding is actually performed in the DFT domain without interpolation, thus eliminating completely the severe distortion resulted from the non-uniform interpolation mapping. The watermarked audio achieves high auditory quality in both objective and subjective quality assessments. A mixed correlation between the LCM feature and a key-generated PN tracking sequence is proposed to align the log-coordinate mapping, thus synchronizing the watermark efficiently with only one FFT and one IFFT. Both the theoretical analysis and experimental results show that the proposed audio watermarking scheme is not only resilient against common signal processing operations, including low-pass filtering, MP3 recompression, echo addition, volume change, normalization, test functions in the Stirmark benchmark, and DA/AD conversion, but also has conquered the challenging audio geometric distortion and achieves the best robustness against simultaneous geometric distortions, such as pitch invariant time-scale modification (TSM) by ±20%, tempo invariant pitch shifting by 20%, resample TSM with scaling factors between 75% and 140%, and random cropping by 95%. This is mainly contributed by the proposed geometric invariant LCM feature. To our best knowledge, audio watermarking based on LCM has not been reported before.",
A Generalized Accelerated Proximal Gradient Approach for Total-Variation-Based Image Restoration,"This paper proposes a generalized accelerated proximal gradient (GAPG) approach for solving total variation (TV)-based image restoration problems. The GAPG algorithm generalizes the original APG algorithm by replacing the Lipschitz constant with an appropriate positive-definite matrix, resulting in faster convergence. For TV-based image restoration problems, we further introduce two auxiliary variables that approximate the partial derivatives. Constraints on the variables can easily be imposed without modifying the algorithm much, and the TV regularization can be either isotropic or anisotropic. As compared with the recently developed APG-based methods for TV-based image restoration, i.e., monotone version of the two-step iterative shrinkage/thresholding algorithm (MTwIST) and monotone version of the fast IST algorithm (MFISTA), our GAPG is much simpler as it does not require to solve an image denoising subproblem. Moreover, the convergence rate of O(k-2) is maintained by our GAPG, where k is the number of iterations; the cost of each iteration in GAPG is also lower. As a result, in our experiments, our GAPG approach can be much faster than MTwIST and MFISTA. The experiments also verify that our GAPG converges faster than the original APG and MTwIST when they solve identical problems.","Image restoration,
Convergence,
Image denoising,
TV,
Acceleration,
Approximation algorithms,
Iterative algorithm"
Automated Measurement of the Arteriolar-to-Venular Width Ratio in Digital Color Fundus Photographs,"A decreased ratio of the width of retinal arteries to veins [arteriolar-to-venular diameter ratio (AVR)], is well established as predictive of cerebral atrophy, stroke and other cardiovascular events in adults. Tortuous and dilated arteries and veins, as well as decreased AVR are also markers for plus disease in retinopathy of prematurity. This work presents an automated method to estimate the AVR in retinal color images by detecting the location of the optic disc, determining an appropriate region of interest (ROI), classifying vessels as arteries or veins, estimating vessel widths, and calculating the AVR. After vessel segmentation and vessel width determination, the optic disc is located and the system eliminates all vessels outside the AVR measurement ROI. A skeletonization operation is applied to the remaining vessels after which vessel crossings and bifurcation points are removed, leaving a set of vessel segments consisting of only vessel centerline pixels. Features are extracted from each centerline pixel in order to assign these a soft label indicating the likelihood that the pixel is part of a vein. As all centerline pixels in a connected vessel segment should be the same type, the median soft label is assigned to each centerline pixel in the segment. Next, artery vein pairs are matched using an iterative algorithm, and the widths of the vessels are used to calculate the AVR. We trained and tested the algorithm on a set of 65 high resolution digital color fundus photographs using a reference standard that indicates for each major vessel in the image whether it is an artery or vein. We compared the AVR values produced by our system with those determined by a semi-automated reference system. We obtained a mean unsigned error of 0.06 (SD 0.04) in 40 images with a mean AVR of 0.67. A second observer using the semi-automated system obtained the same mean unsigned error of 0.06 (SD 0.05) on the set of images with a mean AVR of 0.66. The testing data and reference standard used in this study has been made publicly available.",
Robust System Design to Overcome CMOS Reliability Challenges,"Today's mainstream electronic systems typically assume that transistors and interconnects operate correctly over their useful lifetime. With enormous complexity and significantly increased vulnerability to failures compared to the past, future system designs cannot rely on such assumptions. For coming generations of silicon technologies, several causes of hardware reliability failures, largely benign in the past, are becoming significant at the system level. Robust system design is essential to ensure that future systems perform correctly despite rising complexity and increasing disturbances. This paper describes three techniques that can enable a sea change in robust system design through cost-effective tolerance and prediction of failures in hardware during system operation: 1) efficient soft error resilience; 2) circuit failure prediction; and 3) effective on-line self-test and diagnostics. The need for global optimization across multiple abstraction layers is also demonstrated.","Resilience,
Robustness,
Transistors,
CMOS integrated circuits,
Layout,
Hardware"
Permutation code: Optimal exact-repair of a single failed node in MDS code based distributed storage systems,"We consider exact repair of failed nodes in maximum distance separable (MDS) code based distributed storage systems. It is well known that an (n, k) MDS code can tolerate failure (erasure) of up to n - k storage disks, when the code is used to store k information elements over n distributed storage disks. The focus of this paper is optimal recovery, in terms of repair bandwidth - the amount of data to be downloaded to repair a failed node - for a single failed node. When a single node fails, it has been previously shown by Dimakis et. al. that the amount of repair bandwidth is at least equation units, when each storage disk stores ℒ units of data. The achievability of this lower bound of equation units, for arbitrary values of (n, k); has been shown previously using asymptotic code constructions based on asymptotic interference alignment. However, the existence of finite codes satisfying this lower bound has been shown only for specific regimes of (n, k) and their existence for arbitrary values of (n, k) remained open. In this paper, we provide the first known construction of a finite code for arbitrary (n, k), which can repair a single failed systematic node by downloading exactly equation units of data. The code that we construct is based on permutation matrices and hence termed the Permutation Code.",
Breakdown Current Density of CVD-Grown Multilayer Graphene Interconnects,"Graphene wires have been fabricated from large-area multilayer graphene sheets grown by chemical vapor deposition. As the methane concentration increases, a larger percentage of thicker graphene layers are grown. The multilayer graphene sheets have an average thickness of 10-20 nm with sheet resistances between 500 and 1000 Ω/sq. The sheet resistance shows a strong correlation with the average surface roughness. This letter reports measured breakdown current densities up to 4×107 A/cm2, where resistive heating is proposed as the main breakdown mechanism. Increasing the uniformity of the graphene layers is important in achieving a higher breakdown current density.","Wires,
Electric breakdown,
Conductivity,
Current density,
Electrical resistance measurement,
Nonhomogeneous media,
Resistance"
Medical Image Registration Using Evolutionary Computation: An Experimental Survey,"In the last few decades, image registration (IR) has been established as a very active research area in computer vision. Over the years, IR's applications cover a broad range of real-world problems including remote sensing, medical imaging, artificial vision, and computer-aided design. In particular, medical IR is a mature research field with theoretical support and two decades of practical experience. Traditionally, medical IR has been tackled by iterative approaches considering numerical optimization methods which are likely to get stuck in local optima. Recently, a large number of medical IR methods based on the use of metaheuristics such as evolutionary algorithms have been proposed providing outstanding results. The success of the latter modern search methods is related to their ability to perform an effective and efficient global search in complex solution spaces like those tackled in the IR discipline. In this contribution, we aim to develop an experimental survey of the most recognized feature-based medical IR methods considering evolutionary algorithms and other metaheuristics. To do so, the generic IR framework is first presented by providing a deep description of the involved components. Then, a large number of the latter proposals are reviewed. Finally, the most representative methods are benchmarked on two real-world medical scenarios considering two data sets of three-dimensional images with different modalities.","Biomedical imaging,
Feature extraction,
Medical image processing,
Image registration,
Evolutionary computation,
Three dimensional displays,
Computational modeling"
Salient Feature Region: A New Method for Retinal Image Registration,"Retinal image registration is crucial for the diagnoses and treatments of various eye diseases. A great number of methods have been developed to solve this problem; however, fast and accurate registration of low-quality retinal images is still a challenging problem since the low content contrast, large intensity variance as well as deterioration of unhealthy retina caused by various pathologies. This paper provides a new retinal image registration method based on salient feature region (SFR). We first propose a well-defined region saliency measure that consists of both local adaptive variance and gradient field entropy to extract the SFRs in each image. Next, an innovative local feature descriptor that combines gradient field distribution with corresponding geometric information is then computed to match the SFRs accurately. After that, normalized cross-correlation-based local rigid registration is performed on those matched SFRs to refine the accuracy of local alignment. Finally, the two images are registered by adopting high-order global transformation model with locally well-aligned region centers as control points. Experimental results show that our method is quite effective for retinal image registration.","Feature extraction,
Retina,
Image registration,
Entropy,
Pathology,
Pixel,
Robustness"
Efficient Sparse Generalized Multiple Kernel Learning,"Kernel methods have been successfully applied in various applications. To succeed in these applications, it is crucial to learn a good kernel representation, whose objective is to reveal the data similarity precisely. In this paper, we address the problem of multiple kernel learning (MKL), searching for the optimal kernel combination weights through maximizing a generalized performance measure. Most MKL methods employ the -norm simplex constraints on the kernel combination weights, which therefore involve a sparse but non-smooth solution for the kernel weights. Despite the success of their efficiency, they tend to discard informative complementary or orthogonal base kernels and yield degenerated generalization performance. Alternatively, imposing the -norm constraint on the kernel weights will keep all the information in the base kernels. This leads to non-sparse solutions and brings the risk of being sensitive to noise and incorporating redundant information. To tackle these problems, we propose a generalized MKL (GMKL) model by introducing an elastic-net-type constraint on the kernel weights. More specifically, it is an MKL model with a constraint on a linear combination of the -norm and the squared -norm on the kernel weights to seek the optimal kernel combination weights. Therefore, previous MKL problems based on the -norm or the -norm constraints can be regarded as special cases. Furthermore, our GMKL enjoys the favorable sparsity property on the solution and also facilitates the grouping effect. Moreover, the optimization of our GMKL is a convex optimization problem, where a local solution is the global optimal solution. We further derive a level method to efficiently solve the optimization problem. A series of experiments on both synthetic and real-world datasets have been conducted to show the effectiveness and efficiency of our GMKL.",
Spoken Language Derived Measures for Detecting Mild Cognitive Impairment,"Spoken responses produced by subjects during neuropsychological exams can provide diagnostic markers beyond exam performance. In particular, characteristics of the spoken language itself can discriminate between subject groups. We present results on the utility of such markers in discriminating between healthy elderly subjects and subjects with mild cognitive impairment (MCI). Given the audio and transcript of a spoken narrative recall task, a range of markers are automatically derived. These markers include speech features such as pause frequency and duration, and many linguistic complexity measures. We examine measures calculated from manually annotated time alignments (of the transcript with the audio) and syntactic parse trees, as well as the same measures calculated from automatic (forced) time alignments and automatic parses. We show statistically significant differences between clinical subject groups for a number of measures. These differences are largely preserved with automation. We then present classification results, and demonstrate a statistically significant improvement in the area under the ROC curve (AUC) when using automatic spoken language derived features in addition to the neuropsychological test scores. Our results indicate that using multiple, complementary measures can aid in automatic detection of MCI.","Speech,
Complexity theory,
Pragmatics,
Syntactics,
Dementia,
Manuals"
Textual and Visual Content-Based Anti-Phishing: A Bayesian Approach,"A novel framework using a Bayesian approach for content-based phishing web page detection is presented. Our model takes into account textual and visual contents to measure the similarity between the protected web page and suspicious web pages. A text classifier, an image classifier, and an algorithm fusing the results from classifiers are introduced. An outstanding feature of this paper is the exploration of a Bayesian model to estimate the matching threshold. This is required in the classifier for determining the class of the web page and identifying whether the web page is phishing or not. In the text classifier, the naive Bayes rule is used to calculate the probability that a web page is phishing. In the image classifier, the earth mover's distance is employed to measure the visual similarity, and our Bayesian model is designed to determine the threshold. In the data fusion algorithm, the Bayes theory is used to synthesize the classification results from textual and visual content. The effectiveness of our proposed approach was examined in a large-scale dataset collected from real phishing cases. Experimental results demonstrated that the text classifier and the image classifier we designed deliver promising results, the fusion algorithm outperforms either of the individual classifiers, and our model can be adapted to different phishing cases.","Web pages,
Visualization,
Bayesian methods,
Feature extraction,
Vocabulary,
Image color analysis"
Salient Motion Features for Video Quality Assessment,"Design of algorithms that are able to estimate video quality as perceived by human observers is of interest for a number of applications. Depending on the video content, the artifacts introduced by the coding process can be more or less pronounced and diversely affect the quality of videos, as estimated by humans. While it is well understood that motion affects both human attention and coding quality, this relationship has only recently started gaining attention among the research community, when video quality assessment (VQA) is concerned. In this paper, the effect of calculating several objective measure features, related to video coding artifacts, separately for salient motion and other regions of the frames of the sequence is examined. In addition, we propose a new scheme for quality assessment of coded video streams, which takes into account salient motion. Standardized procedure has been used to calculate the Mean Opinion Score (MOS), based on experiments conducted with a group of non-expert observers viewing standard definition (SD) sequences. MOS measurements were taken for nine different SD sequences, coded using MPEG-2 at five different bit-rates. Eighteen different published approaches related to measuring the amount of coding artifacts objectively on a single-frame basis were implemented. Additional features describing the intensity of salient motion in the frames, as well as the intensity of coding artifacts in the salient motion regions were proposed. Automatic feature selection was performed to determine the subset of features most correlated to video quality. The results show that salient-motion-related features enhance prediction and indicate that the presence of blocking effect artifacts and blurring in the salient regions and variance and intensity of temporal changes in non-salient regions influence the perceived video quality.","Visualization,
Computational modeling,
Quality assessment,
Humans,
Transform coding,
Image coding,
Pixel"
Cooperative Transmission for Relay Networks Based on Second-Order Statistics of Channel State Information,"Cooperative transmission in relay networks is considered, in which a source transmits to its destination with the help of a set of cooperating nodes. The source first transmits locally. The cooperating nodes that receive the source signal retransmit a weighted version of it in an amplify-and-forward (AF) fashion. Assuming knowledge of the second-order statistics of the channel state information, beamforming weights are determined so that the signal-to-noise ratio (SNR) at the destination is maximized subject to two different power constraints, i.e., a total (source and relay) power constraint, and individual relay power constraints. For the former constraint, the original problem is transformed into a problem of one variable, which can be solved via Newton's method. For the latter constraint, this problem is solved completely. It is shown that the semidefinite programming (SDP) relaxation of the original problem always has a rank one solution, and hence the original problem is equivalent to finding the rank one solution of the SDP problem. An explicit construction of such a rank one solution is also provided. Numerical results are presented to illustrate the proposed theoretical findings.","Relays,
Array signal processing,
Signal to noise ratio,
Channel state information,
Programming,
Materials,
Newton method"
Depth No-Synthesis-Error Model for View Synthesis in 3-D Video,"Currently, 3-D Video targets at the application of disparity-adjustable stereoscopic video, where view synthesis based on depth-image-based rendering (DIBR) is employed to generate virtual views. Distortions in depth information may introduce geometry changes or occlusion variations in the synthesized views. In practice, depth information is stored in 8-bit grayscale format, whereas the disparity range for a visually comfortable stereo pair is usually much less than 256 levels. Thus, several depth levels may correspond to the same integer (or sub-pixel) disparity value in the DIBR-based view synthesis such that some depth distortions may not result in geometry changes in the synthesized view. From this observation, we develop a depth no-synthesis-error (D-NOSE) model to examine the allowable depth distortions in rendering a virtual view without introducing any geometry changes. We further show that the depth distortions prescribed by the proposed D-NOSE profile also do not compromise the occlusion order in view synthesis. Therefore, a virtual view can be synthesized losslessly if depth distortions follow the D-NOSE specified thresholds. Our simulations validate the proposed D-NOSE model in lossless view synthesis and demonstrate the gain with the model in depth coding.","Pixel,
Cameras,
Filling,
Numerical models,
Merging,
Three dimensional displays,
Encoding"
"Optimal Filter Framework for Automated, Instantaneous Detection of Lesions in Retinal Images","Automated detection of lesions in retinal images is a crucial step towards efficient early detection, or screening, of large at-risk populations. In particular, the detection of microaneurysms, usually the first sign of diabetic retinopathy (DR), and the detection of drusen, the hallmark of age-related macular degeneration (AMD), are of primary importance. In spite of substantial progress made, detection algorithms still produce 1) false positives - target lesions are mixed up with other normal or abnormal structures in the eye, and 2) false negatives - the large variability in the appearance of the lesions causes a subset of these target lesions to be missed. We propose a general framework for detecting and characterizing target lesions almost instantaneously. This framework relies on a feature space automatically derived from a set of reference image samples representing target lesions, including atypical target lesions, and those eye structures that are similar looking but are not target lesions. The reference image samples are obtained either from an expert- or a data-driven approach. Factor analysis is used to derive the filters generating this feature space from reference samples. Previously unseen image samples are then classified in this feature space. We tested this approach by training it to detect microaneurysms. On a set of images from 2739 patients including 67 with referable DR, DR detection area under the receiver-operating characteristic curve (AUC) was comparable (AUC=0.927) to our previously published red lesion detection algorithm (AUC=0.929). We also tested the approach on the detection of AMD, by training it to differentiate drusen from Stargardt's disease lesions, and achieved an AUC=0.850 on a set of 300 manually detected drusen and 300 manually detected flecks. The entire image processing sequence takes less than a second on a standard PC compared to minutes in our previous approach, allowing instantaneous detection. Free-response receiver-operating characteristic analysis showed the superiority of this approach over a framework where false positives and the atypical lesions are not explicitly modeled. A greater performance was achieved by the expert-driven approach for DR detection, where the designer had sound expert knowledge. However, for both problems, a comparable performance was obtained for both expert- and data-driven approaches. This indicates that annotation of a limited number of lesions suffices for building a detection system for any type of lesion in retinal images, if no expert-knowledge is available. We are studying whether the optimal filter framework also generalizes to the detection of any structure in other domains.","Lesions,
Mathematical model,
Image color analysis,
Diseases,
Retina,
Aneurysms"
Energy-Efficient Multicasting of Scalable Video Streams Over WiMAX Networks,"The Multicast/Broadcast Service (MBS) feature of mobile WiMAX network is a promising technology for providing wireless multimedia, because it allows the delivery of multimedia content to large-scale user communities in a cost-efficient manner. In this paper, we consider WiMAX networks that transmit multiple video streams encoded in scalable manner to mobile receivers using the MBS feature. We focus on two research problems in such networks: 1) maximizing the video quality and 2) minimizing energy consumption for mobile receivers. We formulate and solve the substream selection problem to maximize the video quality, which arises when multiple scalable video streams are broadcast to mobile receivers with limited resources. We show that this problem is NP-Complete, and design a polynomial time approximation algorithm to solve it. We prove that the solutions computed by our algorithm are always within a small constant factor from the optimal solutions. In addition, we extend our algorithm to reduce the energy consumption of mobile receivers. This is done by transmitting the selected substreams in bursts, which allows mobile receivers to turn off their wireless interfaces to save energy. We show how our algorithm constructs burst transmission schedules that reduce energy consumption without sacrificing the video quality. Using extensive simulation and mathematical analysis, we show that the proposed algorithm: 1) is efficient in terms of execution time, 2) achieves high radio resource utilization, 3) maximizes the received video quality, and 4) minimizes the energy consumption for mobile receivers.",
A Memetic Algorithm for Periodic Capacitated Arc Routing Problem,"This paper investigates the Periodic Capacitated Arc Routing Problem (PCARP), which is often encountered in the waste collection application. PCARP is an extension of the well-known Capacitated Arc Routing Problem (CARP) from a single period to a multi-period horizon. PCARP is a hierarchical optimization problem which has a primary objective (minimizing the number of vehicles ) and a secondary objective (minimizing the total cost ). An important factor that makes PCARP challenging is that its primary objective is little affected by existing operators and thus difficult to improve. We propose a new Memetic Algorithm (MA) for solving PCARP. The MA adopts a new solution representation scheme and a novel crossover operator. Most importantly, a Route-Merging (RM) procedure is devised and embedded in the algorithm to tackle the insensitive objective . The MA with RM (MARM) has been compared with existing meta-heuristic approaches on two PCARP benchmark sets and a real-world data set. The experimental results show that MARM obtained better solutions than the compared algorithms in much less time, and even updated the best known solutions of all the benchmark instances. Further study reveals that the RM procedure plays a key role in the superior performance of MARM.","Combinatorial mathematics,
Algorithm design and analysis,
Routing,
Evolutionary computation,
Optimization,
Logistics,
Transportation"
A three-port Photovoltaic (PV) micro-inverter with power decoupling capability,"This paper presents a new micro-inverter topology that is intended for single-phase grid-connected PV systems. The features of the proposed topology are: (1) eliminating the double-frequency power ripple using small film capacitor; (2) improving the maximum-power-point tracking (MPPT) performance; (3) using long life-time film capacitors, which will improve the reliability of the inverter; and (4) requiring no additional circuitry to manage the transformer leakage energy.","Capacitors,
Topology,
Switches,
Magnetic circuits,
Inductance,
Power generation,
Inverters"
A Simple Model for Chunk-Scheduling Strategies in P2P Streaming,"Peer-to-peer (P2P) streaming tries to achieve scalability (like P2P file distribution) and at the same time meet real-time playback requirements. It is a challenging problem still not well understood. In this paper, we describe a simple stochastic model that can be used to compare different downloading strategies to random peer selection. Based on this model, we study the tradeoffs between supported peer population, buffer size, and playback continuity. We first study two simple strategies: Rarest First (RF) and Greedy. The former is a well-known strategy for P2P file sharing that gives good scalability by trying to propagate the chunks of a file to as many peers as quickly as possible. The latter is an intuitively reasonable strategy to get urgent chunks first to maximize playback continuity from a peer's local perspective. Yet in reality, both scalability and urgency should be taken care of. With this insight, we propose a Mixed strategy that achieves the best of both worlds. Furthermore, the Mixed strategy comes with an adaptive algorithm that can adapt its buffer setting to dynamic peer population. We validate our analytical model with simulation. Finally, we also discuss the modeling assumptions and the model's sensitivity to different parameters and show that our model is robust.","Servers,
Peer to peer computing,
Algorithm design and analysis,
Delay,
Streaming media,
Sensitivity,
Radio frequency"
Towards printable robotics: Origami-inspired planar fabrication of three-dimensional mechanisms,"This work presents a technique which allows the application of 2-D fabrication methods to build 3-D robotic systems. The ability to print robots introduces a fast and low-cost fabrication method to modern, real-world robotic applications. To this end, we employ laser-engraved origami patterns to build a new class of robotic systems for mobility and manipulation. Origami is suitable for printable robotics as it uses only a flat sheet as the base structure for building complicated functional shapes, which can be utilized as robot bodies. An arbitrarily complex folding pattern can be used to yield an array of functionalities, in the form of actuated hinges or active spring elements. For actuation, we use compact NiTi coil actuators placed on the body to move parts of the structure on-demand. We demonstrate, as a proof-of-concept case study, the end-to-end fabrication and assembly of a simple mobile robot that can undergo worm-like peristaltic locomotion.","Robots,
Actuators,
Fabrication,
Springs,
Materials,
Shape,
Contracts"
The truth about cats and dogs,"Template-based object detectors such as the deformable parts model of Felzenszwalb et al. [11] achieve state-of-the-art performance for a variety of object categories, but are still outperformed by simpler bag-of-words models for highly flexible objects such as cats and dogs. In these cases we propose to use the template-based model to detect a distinctive part for the class, followed by detecting the rest of the object via segmentation on image specific information learnt from that part. This approach is motivated by two observations: (i) many object classes contain distinctive parts that can be detected very reliably by template-based detectors, whilst the entire object cannot; (ii) many classes (e.g. animals) have fairly homogeneous coloring and texture that can be used to segment the object once a sample is provided in an image. We show quantitatively that our method substantially outperforms whole-body template-based detectors for these highly deformable object categories, and indeed achieves accuracy comparable to the state-of-the-art on the PASCAL VOC competition, which includes other models such as bag-of-words.",
Threshold Anonymous Announcement in VANETs,"Vehicular ad hoc networks (VANETs) allow wireless communications between vehicles without the aid of a central server. Reliable exchanges of information about road and traffic conditions allow a safer and more comfortable travelling environment. However, such profusion of information may allow unscrupulous parties to violate user privacy. On the other hand, a degree of auditability is desired for law enforcement and maintenance purposes. In this paper we propose a Threshold Anonymous Announcement service using direct anonymous attestation and one-time anonymous authentication to simultaneously achieve the seemingly contradictory goals of reliability, privacy and auditability.","Vehicles,
Privacy,
IEEE news,
Protocols,
Public key,
Reliability,
Authentication"
Optimum Two-Dimensional Uniform Spatial Sampling for Microwave SAR-Based NDE Imaging Systems,"Microwave imaging systems for nondestructive evaluation, based on 3-D synthetic aperture radar (SAR) techniques, utilize either a real aperture, composed of many antennas mounted next to one another, or a synthetic aperture, generated by raster scanning a single antenna. To obtain a quality SAR image, the spatial sampling must be dense enough to accurately sample the electric field reflected from a target. Conversely, the quantity of spatial samples may be optimally reduced, resulting in reduced system complexity and required resources for systems employing real apertures and reduced imaging time for synthetic aperture systems. In the literature, it has been reported that the optimum sampling step size is equal to the theoretical resolution, as per the Nyquist rate. It has also been reported that an image generated using a sampling step size equal to the theoretical resolution may not possess the same spatial resolution as predicted. Also, as expected and reported, resolution is dependent upon the distance between the target and the aperture, aperture dimensions, and antenna beamwidth. However, existing formulations of SAR resolution do not account for all of the physical characteristics of a measurement (e.g., 2-D limited-size aperture, electric field decreasing with distance from the measuring antenna, etc.). This paper presents a theoretical formulation of resolution and a study into optimum uniform spatial sampling by analyzing simulated 3-D SAR images according to metrics representing image quality, namely, half-power resolution and RMS error between practically sampled images and an ideally sampled image. The results of this simulation demonstrate optimum sampling given design requirements that fully explain resolution dependence on sampling step size. Also, it is found that there is additional widening of the 2-D spectral estimation of the data due to the aperture-limited nature of the measurements, which further influences the choice of sampling step size. Subsequently, the simulated results are compared to experimental results corroborating the efficacy of the formulation. Finally, design curves and procedures are proposed for selecting sampling step size as per resolution requirements.",
Blurred target tracking by Blur-driven Tracker,"Visual tracking plays an important role in many computer vision tasks. A common assumption in previous methods is that the video frames are blur free. In reality, motion blurs are pervasive in the real videos. In this paper we present a novel BLUr-driven Tracker (BLUT) framework for tracking motion-blurred targets. BLUT actively uses the information from blurs without performing debluring. Specifically, we integrate the tracking problem with the motion-from-blur problem under a unified sparse approximation framework. We further use the motion information inferred by blurs to guide the sampling process in the particle filter based tracking. To evaluate our method, we have collected a large number of video sequences with significant motion blurs and compared BLUT with state-of-the-art trackers. Experimental results show that, while many previous methods are sensitive to motion blurs, BLUT can robustly and reliably track severely blurred targets.","Estimation,
Robots,
Tracking"
From Local Pixel Structure to Global Image Super-Resolution: A New Face Hallucination Framework,"We have developed a new face hallucination framework termed from local pixel structure to global image super-resolution (LPS-GIS). Based on the assumption that two similar face images should have similar local pixel structures, the new framework first uses the input low-resolution (LR) face image to search a face database for similar example high-resolution (HR) faces in order to learn the local pixel structures for the target HR face. It then uses the input LR face and the learned pixel structures as priors to estimate the target HR face. We present a three-step implementation procedure for the framework. Step 1 searches the database for example faces that are the most similar to the input, and then warps the example images to the input using optical flow. Step 2 uses the warped HR version of the example faces to learn the local pixel structures for the target HR face. An effective method for learning local pixel structures from an individual face, and an adaptive procedure for fusing the local pixel structures of different example faces to reduce the influence of warping errors, have been developed. Step 3 estimates the target HR face by solving a constrained optimization problem by means of an iterative procedure. Experimental results show that our new method can provide good performances for face hallucination, both in terms of reconstruction error and visual quality; and that it is competitive with existing state-of-the-art methods.","Pixel,
Image resolution,
Image databases,
Image reconstruction,
Signal processing,
Strontium,
Signal resolution,
Permission,
Nearest neighbor searches,
Optical signal processing"
Describing and forecasting video access patterns,"Computer systems are increasingly driven by workloads that reflect large-scale social behavior, such as rapid changes in the popularity of media items like videos. Capacity planners and system designers must plan for rapid, massive changes in workloads when such social behavior is a factor. In this paper we make two contributions intended to assist in the design and provisioning of such systems.We analyze an extensive dataset consisting of the daily access counts of hundreds of thousands of YouTube videos. In this dataset, we find that there are two types of videos: those that show rapid changes in popularity, and those that are consistently popular over long time periods. We call these two types rarely-accessed and frequently-accessed videos, respectively. We observe that most of the videos in our data set clearly fall in one of these two types. In this work, we study the frequently-accessed videos by asking two questions: first, is there a relatively simple model that can describe its daily access patterns? And second, can we use this simple model to predict the number of accesses that a video will have in the near future, as a tool for capacity planning? To answer these questions we develop a framework for characterization and forecasting of access patterns. We show that for frequently-accessed videos, daily access patterns can be extracted via principal component analysis, and used efficiently for forecasting.",
Quaternion ICA From Second-Order Statistics,"This paper addresses the independent component analysis (ICA) of quaternion random vectors. In particular, we focus on the Gaussian case and therefore only consider the quaternion second-order statistics (SOS), which are given by the covariance matrix and three complementary covariance matrices. First, we derive the necessary and sufficient conditions for the identifiability of the quaternion ICA model, which are based on the definition of the properness profile of a quaternion random variable and more specifically on the concept of rotationally equivalent properness profiles. Second, we show that the maximum-likelihood (ML) approach to the quaternion ICA problem reduces to the approximated joint diagonalization (AJD) of the sample-mean estimates of the covariance and complementary covariance matrices. Unlike the complex case, these four matrices cannot be simultaneously diagonalized in general, and we have to resort to a particular AJD algorithm. The proposed technique, which can be seen as a quasi-Newton method, is based on the local approximation of the nonconvex ML-ICA cost function (a measure of the entropy loss due to the residual correlation among the estimated quaternion sources), and it provides a satisfactory solution of the quaternion ICA model. The performance of the proposed quaternion ML-ICA algorithm, as well as its relationship to the identifiability conditions, are illustrated by means of several numerical examples.","Quaternions,
Signal processing algorithms,
Cost function,
Covariance matrix,
Approximation algorithms,
Vectors,
Correlation"
V-PADA: Vehicle-Platoon-Aware Data Access in VANETs,"The high mobility of vehicles and the unreliable wireless communication significantly degrade the performance of data access in vehicular ad hoc networks (VANETs). To address this problem, we propose a novel vehicle-platoon-aware data access solution called V-PADA. In V-PADA, vehicles contribute part of their buffers to replicate data for others in the same platoon and share data with them. When a vehicle leaves the platoon, it prefetches interested data and transfers its buffered data to other vehicles in advance so that they can still access the data after it leaves. To achieve this goal, V-PADA consists of two components: First, a vehicle-platooning protocol is designed to identify platoon formation and predict platoon splits. We use stochastic time series analysis to detect platoon and mobility anomalies and further introduce a two-step split prediction method to reduce the false alarm rate due to road curves. Second, a data management component is designed to guide platoon members to replicate and prefetch the most suitable data so that both high data availability and low data access overhead can be achieved. Extensive simulation results show that V-PADA can effectively improve the data access performance in VANETs.","Vehicles,
Monitoring,
Prefetching,
Availability,
Roads,
Protocols,
Forecasting"
A short survey of methods for voltage instability detection,"This paper shortly surveys existing and proposed methods for voltage instability detection. The emphasis is on methods relying on real-time measurements as well as on long-term voltage instability. Methods are classified according to the required measurement configuration: local vs. wide-area, standard SCADA-type vs. synchronized phasor measurements, etc. In the various categories, some of the features are summarized, and what appears to the authors as advantages or limitations is shortly discussed. An important feature is the ability to anticipate instability. Some tracks for further work on the subject are also outlined.","Reactive power,
Monitoring,
Generators,
Voltage measurement,
Phasor measurement units,
Impedance measurement,
Real time systems"
Robust Data-Driven Modeling Approach for Real-Time Final Product Quality Prediction in Batch Process Operation,"Making on-specification products is a primary goal, and also a challenge in chemical batch process operation. Due to the uncertainty of raw materials and instability of operating conditions, it may not produce the desired on-spec final product. It would be helpful if one can predict the product quality during each operation, so that one can make adjustments to process conditions in order to make on-spec product. This paper addresses the issue of real-time prediction of final product quality during a batch operation. First, a data-driven modeling approach is presented. This multimodel approach uses available process information up to the current points to capture their time-varying relationships with the final product quality during the course of operation, so that the prognosis of product quality can be obtained in real-time. Then, due to its data-driven nature, the focus is given on how to make the models robust in order to eliminate the effect of noise, especially, outliers in the data. A model-based outlier detection method is presented. The proposed approach is applied to a generic chemical batch case study, with its prediction performance being evaluated.",
Zhang Neural Network Versus Gradient Neural Network for Solving Time-Varying Linear Inequalities,"By following Zhang design method, a new type of recurrent neural network [i.e., Zhang neural network (ZNN)] is presented, investigated, and analyzed for online solution of time-varying linear inequalities. Theoretical analysis is given on convergence properties of the proposed ZNN model. For comparative purposes, the conventional gradient neural network is developed and exploited for solving online time-varying linear inequalities as well. Computer simulation results further verify and demonstrate the efficacy, novelty, and superiority of such a ZNN model and its method for solving time-varying linear inequalities.","Computational modeling,
Convergence,
Mathematical model,
Analytical models,
Vectors,
Linear matrix inequalities,
Recurrent neural networks"
Inertial Sensor-Based Indoor Pedestrian Localization with Minimum 802.15.4a Configuration,"Available techniques for indoor object locating systems, such as inertial sensor-based system or radio fingerprinting, hardly satisfy both cost-effectiveness and accuracy. In particular, inertial sensor-based locating systems are often supplemented with radio signals to improve localization accuracy. A radio-assisted localization system is still costly due to the infrastructure requirements and management overheads. In this paper, we propose a low-cost and yet accurate indoor pedestrian localization scheme with a small number of radio beacons whose location information is unknown. Our scheme applies the Simultaneous Location and Mapping (SLAM) technique used in robotics to mobile device, which is equipped with both inertial sensors and the IEEE802.15.4a Chirp Spread Spectrum (CSS) radio, to obtain accurate locations of pedestrians in indoor environment. The proposed system is validated with real implementations. The experiment results show approximately 1.5 m mean error observed during 276 m of pedestrian moving in a 380 m2 indoor environment with five position-unknown beacons.","Distance measurement,
Cascading style sheets,
Noise,
Accuracy,
Magnetometers,
Simultaneous localization and mapping"
Gain-Scheduling-Based State Feedback Integral Control for Networked Control Systems,"This paper presents a new controller design method for networked control systems (NCSs), which is motivated by that static state feedback control (SSFC) shows an offset in the plant output when there is nonzero disturbance. Different from the existing SSFC results, the proposed method constructs a gain-scheduling-based state feedback integral controller, where an integral action is introduced to address the nonzero disturbance issue, and most especially, a gain scheduling strategy is employed to improve the control performance of NCSs. Moreover, the obtained results are also extended to the output feedback case. Simulation and experimental results are given to demonstrate the effectiveness of the proposed approach.","Delay effects,
Sensors,
Actuators,
State feedback,
Optimization,
Observers,
Sun"
Experimental Demonstrations and Extensive Comparisons of End-to-End Real-Time Optical OFDM Transceivers With Adaptive Bit and/or Power Loading,"Experimental demonstrations are reported for end-to-end real-time optical orthogonal frequency division multiplexing (OOFDM) transceivers incorporating three widely adopted adaptive loading techniques, namely, power loading (PL), bit loading (BL), and bit-and-power loading (BPL). In directly modulated distributed-feedback (DFB) laser-based, intensity-modulation, and direct-detection (IMDD) transmission systems consisting of up to 35-km single-mode fibers (SMFs), extensive experimental comparisons between these adaptive loading techniques are made in terms of maximum achievable signal bit rate, optical power budget, and digital signal processing (DSP) resource usage. It is shown that BPL is capable of supporting end-to-end real-time OOFDM transmission of 11.75 Gb/s over 25-km SMFs in the aforementioned systems at sampling speeds as low as 4 GS/s. In addition, experimental measurements also show that BPL (PL) offers the highest (lowest) signal bit rate, and their optical power budgets are similar. The observed signal bit rate difference between BPL and PL is almost independent of sampling speed and transmission distance. All the aforementioned key features agree very well with numerical simulations. On the other hand, BPL-consumed DSP resources are approximately three times higher than those required by PL. The results indicate that PL is a preferred choice for cost-effective OOFDM transceiver design.","Loading,
Optical fibers,
Modulation,
Optical attenuators,
Transceivers,
OFDM"
A Positive and Unlabeled Learning Algorithm for One-Class Classification of Remote-Sensing Data,"In remote-sensing classification, there are situations when users are only interested in classifying one specific land-cover type, without considering other classes. These situations are referred to as one-class classification. Traditional supervised learning is inefficient for one-class classification because it requires all classes that occur in the image to be exhaustively assigned labels. In this paper, we investigate a new positive and unlabeled learning (PUL) algorithm, applying it to one-class classifications of two scenes of a high-spatial-resolution aerial photograph. The PUL algorithm trains a classifier on positive and unlabeled data, estimates the probability that a positive training sample has been labeled, and generates binary predictions for test samples using an adjusted threshold. Experimental results indicate that the new algorithm provides high classification accuracy, outperforming the biased support-vector machine (SVM), one-class SVM, and Gaussian domain descriptor methods. The advantages of the new algorithm are that it can use unlabeled data to help build classifiers, and it requires only a small set of positive data to be labeled by hand. Therefore, it can significantly reduce the effort of assigning labels to training data without losing predictive accuracy.","Training,
Pixel,
Support vector machines,
Remote sensing,
Training data,
Kernel,
Accuracy"
Recommend-As-You-Go: A Novel Approach Supporting Services-Oriented Scientific Workflow Reuse,"Services computing technology enables scientists to expose data and computational resources wrapped as publicly accessible Web services. However, our study indicates that scientific services are currently poorly reused in an ad hoc style. This project aims to help domain scientists find interested services and reuse successful processes to attain their research purposes in the form of workflows. In contrast to existing interface-based services discovery approaches, this paper proposes a novel approach of proactively recommending services in a workflow composition process, based on service usage history. The underpinning is a People-Service-Workflow (PSW) network that models existing scientific artifacts, services and workflows, and their past usage relationships into a social network. Various social network analysis techniques are applied to discover hidden knowledge accrued. A prototyping search engine has been developed as a proof of concept, and is seamlessly integrated as a plug-in into the Tavern a workbench, a widely used scientific workflow management tool.","Computer aided software engineering,
Social network services,
Knowledge engineering,
Web services,
Measurement,
Buildings,
Data visualization"
"Content, connectivity, and cloud: ingredients for the network of the future","A new network architecture for the Internet needs ingredients from three approaches: information- centric networking, cloud computing integrated with networking, and open connectivity. Information-centric networking considers pieces of information as first-class entities of a networking architecture, rather than only indirectly identifying and manipulating them via a node hosting that information; this way, information becomes independent from the devices they are stored in, enabling efficient and application- independent information caching in the network. Cloud networking offers a combination and integration of cloud computing and virtual networking. It is a solution that distributes the benefits of cloud computing more deeply into the network, and provides a tighter integration of virtualization features at computing and networking levels. To support these concepts, open connectivity services need to provide advanced transport and networking mechanisms, making use of network and path diversity (even leveraging direct optical paths) and encoding techniques, and dealing with ubiquitous mobility of user, content and information objects in a unified way.","Cloud computing,
Streaming media,
Routing,
Computer architecture,
Protocols,
Internetworking,
Virtual private networks,
Information processing"
Licklider Transmission Protocol (LTP)-Based DTN for Cislunar Communications,"Delay/disruption-tolerant networking (DTN) technology offers a new solution to highly stressed communications in space environments, especially those with long link delay and frequent link disruptions in deep-space missions. To date, little work has been done in evaluating the performance of the available “convergence layer” protocols of DTN, especially the Licklider Transmission Protocol (LTP), when they are applied to an interplanetary Internet (IPN). In this paper, we present an experimental evaluation of the Bundle Protocol (BP) running over various “convergence layer” protocols in a simulated cislunar communications environment characterized by varying degrees of signal propagation delay and data loss. We focus on the LTP convergence layer (LTPCL) adapter running on top of UDP/IP (i.e., BP/LTPCL/UDP/IP). The performance of BP/LTPCL/UDP/IP in realistic file transfers over a PC-based network test bed is compared to that of two other DTN protocol stack options, BP/TCPCL/TCP/IP and BP/UDPCL/UDP/IP. A statistical method of t-test is also used for analysis of the experimental results. The experiment results show that LTPCL has a significant performance advantage over Transmission Control Protocol convergence layer (TCPCL) for link delays longer than 4000 ms regardless of the bit error rate (BER). For a very lossy channel with a BER of around 10-5, LTPCL has a significant goodput advantage over TCPCL at all the link delay levels studied, with an advantage of around 3000 B/s for delays longer than 1500 ms. LTPCL has a consistently significant goodput advantage over UDPCL, around 2500-3000 B/s, at all levels of link delays and BERs.","Protocols,
Delay,
IP networks,
Moon,
Convergence,
Relays,
Internet"
Graph Run-Length Matrices for Histopathological Image Segmentation,"The histopathological examination of tissue specimens is essential for cancer diagnosis and grading. However, this examination is subject to a considerable amount of observer variability as it mainly relies on visual interpretation of pathologists. To alleviate this problem, it is very important to develop computational quantitative tools, for which image segmentation constitutes the core step. In this paper, we introduce an effective and robust algorithm for the segmentation of histopathological tissue images. This algorithm incorporates the background knowledge of the tissue organization into segmentation. For this purpose, it quantifies spatial relations of cytological tissue components by constructing a graph and uses this graph to define new texture features for image segmentation. This new texture definition makes use of the idea of gray-level run-length matrices. However, it considers the runs of cytological components on a graph to form a matrix, instead of considering the runs of pixel intensities. Working with colon tissue images, our experiments demonstrate that the texture features extracted from “graph run-length matrices” lead to high segmentation accuracies, also providing a reasonable number of segmented regions. Compared with four other segmentation algorithms, the results show that the proposed algorithm is more effective in histopathological image segmentation.","Image segmentation,
Pixel,
Colon,
Image color analysis,
Cancer,
Image edge detection,
Glands"
A Two-Stage Online Prediction Method for a Blast Furnace Gas System and Its Application,"The byproduct gas in steel industry is one of the most significant energy resources of an enterprise. Due to the large quantity of yield, fluctuation, and various categories of users encountered in a blast furnace gas (BFG) system, it is very difficult to accurately predict the amount of gas to be generated and forecast the users' consumption demand. In this paper, a two-stage online prediction method based on an improved echo state network (ESN) is proposed to realize forecasting in the BFG system. In this method, one completes the prediction realized at the levels of BFG generation and consumption using a class of ESN with input compensation and parameter optimization. At the second stage, to predict gas holder level of the BFG system, the energy flows being predicted at the first stage are denoised, and their correlation with the holder level are determined by using a concept of grey correlation with time delay. Then the effect factors exhibiting high correlation levels are extracted to construct the model of the gas holder. The prediction system designed in this manner is applied in the Energy Center of Baosteel Co., Ltd, China. The results demonstrate that the prediction system exhibits high accuracy and can provide an effective guidance for balancing and scheduling of the byproduct energy.","Prediction methods,
Blast furnaces,
Production,
Steel,
Energy resources,
Fluctuations,
Demand forecasting,
Power generation,
Humans,
Metals industry"
Characterization of Lead-Free Solder and Sintered Nano-Silver Die-Attach Layers Using Thermal Impedance,"Since a die-attach layer has a significant impact on the thermal performance of a power module, its quality can be characterized using thermal performance. In this paper, a measurement system for thermal impedance is developed to evaluate three die-attach materials. Thanks to its high temperature sensitivity (10 mV/°C), the gate-emitter voltage of an insulated gate bipolar transistor (IGBT) is used as the temperature-sensitive parameter. The power dissipation in the IGBT remains constant by a feedback loop, regardless of the junction temperature. Experimental results show that the sample using sintered nano-silver for the die-attach has 12.1% lower thermal impedance than the samples using SAC305 and SN100C solders. To check the degradation of the die-attachment, six samples using three die-attach materials were thermally cycled from -40 to 125°C. The experimental results show that, after 500 cycles, the thermal impedance of SAC305 samples and SN100C samples is increased by 12.9% and 13.3%, respectively, which are much higher than that of the sample using the sintered nano-silver for the die-attach (3.1%).","Insulated gate bipolar transistors,
Temperature measurement,
Heating,
Impedance measurement,
Semiconductor device measurement,
Impedance,
Logic gates"
Evolutionary Improvement of Programs,"Most applications of genetic programming (GP) involve the creation of an entirely new function, program or expression to solve a specific problem. In this paper, we propose a new approach that applies GP to improve existing software by optimizing its non-functional properties such as execution time, memory usage, or power consumption. In general, satisfying non-functional requirements is a difficult task and often achieved in part by optimizing compilers. However, modern compilers are in general not always able to produce semantically equivalent alternatives that optimize non-functional properties, even if such alternatives are known to exist: this is usually due to the limited local nature of such optimizations. In this paper, we discuss how best to combine and extend the existing evolutionary methods of GP, multiobjective optimization, and coevolution in order to improve existing software. Given as input the implementation of a function, we attempt to evolve a semantically equivalent version, in this case optimized to reduce execution time subject to a given probability distribution of inputs. We demonstrate that our framework is able to produce non-obvious optimizations that compilers are not yet able to generate on eight example functions. We employ a coevolved population of test cases to encourage the preservation of the function's semantics. We exploit the original program both through seeding of the population in order to focus the search, and as an oracle for testing purposes. As well as discussing the issues that arise when attempting to improve software, we employ rigorous experimental method to provide interesting and practical insights to suggest how to address these issues.","Optimization,
Semantics,
Evolutionary computation,
Sorting,
Genetic programming,
Program processors"
"Robust Statistical Label Fusion Through Consensus Level, Labeler Accuracy, and Truth Estimation (COLLATE)","Segmentation and delineation of structures of interest in medical images is paramount to quantifying and characterizing structural, morphological, and functional correlations with clinically relevant conditions. The established gold standard for performing segmentation has been manual voxel-by-voxel labeling by a neuroanatomist expert. This process can be extremely time consuming, resource intensive and fraught with high inter-observer variability. Hence, studies involving characterizations of novel structures or appearances have been limited in scope (numbers of subjects), scale (extent of regions assessed), and statistical power. Statistical methods to fuse data sets from several different sources (e.g., multiple human observers) have been proposed to simultaneously estimate both rater performance and the ground truth labels. However, with empirical datasets, statistical fusion has been observed to result in visually inconsistent findings. So, despite the ease and elegance of a statistical approach, single observers and/or direct voting are often used in practice. Hence, rater performance is not systematically quantified and exploited during label estimation. To date, statistical fusion methods have relied on characterizations of rater performance that do not intrinsically include spatially varying models of rater performance. Herein, we present a novel, robust statistical label fusion algorithm to estimate and account for spatially varying performance. This algorithm, COnsensus Level, Labeler Accuracy and Truth Estimation (COLLATE), is based on the simple idea that some regions of an image are difficult to label (e.g., confusion regions: boundaries or low contrast areas) while other regions are intrinsically obvious (e.g., consensus regions: centers of large regions or high contrast edges). Unlike its predecessors, COLLATE estimates the consensus level of each voxel and estimates differing models of observer behavior in each region. We show that COLLATE provides significant improvement in label accuracy and rater assessment over previous fusion methods in both simulated and empirical datasets.","Estimation,
Humans,
Image segmentation,
Accuracy,
Labeling,
Robustness,
Statistical analysis"
Energy efficient clustering for WSN-based structural health monitoring,"In recent years, research on using wireless sensor networks (WSNs) for structural health monitoring (SHM) has attracted increasing attention. Unlike other monitoring applications, detection of possible structure damage requires significant amount of domain knowledge that computer science researchers are usually unfamiliar with. As a result, most previous work in WSN-based SHM was done by researchers in civil engineering. However, civil researchers often tend to solve practical engineering problems but rarely consider designing a system in an optimal way, particularly when the limited wireless bandwidth and restricted resources of WSNs need to be addressed. Through the collaboration with civil researchers, we demonstrate that optimization design can significantly help improve the performance of a WSN-based SHM system. We consider a fundamental problem in SHM: modal analysis, which is used to obtain the dynamic structural vibration characteristics. Cluster-based modal analysis approach is adopted. In each cluster, the vibration characteristics are identified and then are assembled together. Different from other applications, clustering in this approach should meet some extra requirements of modal analysis. Moreover, cluster size should be optimized to minimize the total energy consumption. This clustering problem is formally formulated and proven to be NP complete. Two centralized and one distributed algorithms are proposed to solve the problem. The effectiveness and efficiency of the proposed cluster-based modal analysis along with the clustering algorithms are evaluated using both simulation and experiments.","Modal analysis,
Shape,
Wireless sensor networks,
Energy consumption,
Vibrations,
Monitoring,
Computer science"
Vessel Boundary Delineation on Fundus Images Using Graph-Based Approach,"This paper proposes an algorithm to measure the width of retinal vessels in fundus photographs using graph-based algorithm to segment both vessel edges simultaneously. First, the simultaneous two-boundary segmentation problem is modeled as a two-slice, 3-D surface segmentation problem, which is further converted into the problem of computing a minimum closed set in a node-weighted graph. An initial segmentation is generated from a vessel probability image. We use the REVIEW database to evaluate diameter measurement performance. The algorithm is robust and estimates the vessel width with subpixel accuracy. The method is used to explore the relationship between the average vessel width and the distance from the optic disc in 600 subjects.","Pixel,
Image segmentation,
Observers,
Retina,
Biomedical imaging,
Image edge detection,
Blood vessels"
High-endurance and performance-efficient design of hybrid cache architectures through adaptive line replacement,"In this paper, we propose a run-time strategy for managing writes onto last level cache in chip multiprocessors where STT-RAM memory is used as baseline technology. To this end, we assume that each cache set is decomposed into limited SRAM lines and large number of STT-RAM lines. SRAM lines are target of frequently-written data and rarely-written or read-only ones are pushed into STT-RAM. As a novel contribution, a low-overhead, fully-hardware technique is utilized to detect write-intensive data blocks of working set and place them into SRAM lines while the remaining data blocks are candidates to be remapped onto STT-RAM blocks during system operation. Therefore, the achieved cache architecture has large capacity and consumes near zero leakage energy using STT-RAM array; while dynamic write energy, acceptable write latency, and long lifetime is guaranteed via SRAM array. Results of full-system simulation for a quad-core CMP running PARSEC-2 benchmark suit confirm an average of 49 times improvement in cache lifetime and more than 50% reduction in cache power consumption when compared to baseline configurations.","Random access memory,
Computer architecture,
Radiation detectors,
Microprocessors,
Indexes,
Integrated circuit modeling,
Magnetic tunneling"
Bounds on Secrecy Capacity Over Correlated Ergodic Fading Channels at High SNR,"We investigate the secrecy capacity of an ergodic fading wiretap channel when the main and eavesdropper channels are correlated. Assuming that the transmitter knows the full channel state information (CSI) (i.e., the channel gains from the transmitter to the legitimate receiver and eavesdropper), we quantify the loss of the secrecy capacity due to the correlation and investigate the asymptotic behavior of the secrecy capacity in the high signal-to-noise ratio (SNR) regime. While the ergodic capacity of fading channels grows logarithmically with SNR in general, we have found that the secrecy capacity converges to an upper-bound (a closed-form expression is derived) that will be shown to be a function of two channel parameters; the correlation coefficient and the ratio of the main to eavesdropper channel gains. From this, we are able to see how the two channel parameters affect the secrecy capacity and conclude that the excessively large signal power does not help to improve the secrecy capacity and the loss due to the correlation could be significant especially when the ratio of the main to eavesdropper channel gains is low.","Fading,
Correlation,
Signal to noise ratio,
Receivers,
Upper bound,
Channel models,
Channel capacity"
Feature Selection for Accelerometer-Based Posture Analysis in Parkinson's Disease,"Posture analysis in quiet standing is a key component of the clinical evaluation of Parkinson's disease (PD), postural instability being one of PD's major symptoms. The aim of this study was to assess the feasibility of using accelerometers to characterize the postural behavior of early mild PD subjects. Twenty PD and 20 control subjects, wearing an accelerometer on the lower back, were tested in five conditions characterized by sensory and attentional perturbation. A total of 175 measures were computed from the signals to quantify tremor, acceleration, and displacement of body sway. Feature selection was implemented to identify the subsets of measures that better characterize the distinctive behavior of PD and control subjects. It was based on different classifiers and on a nested cross validation, to maximize robustness of selection with respect to changes in the training set. Several subsets of three features achieved misclassification rates as low as 5%. Many of them included a tremor-related measure, a postural measure in the frequency domain, and a postural displacement measure. Results suggest that quantitative posture analysis using a single accelerometer and a simple test protocol may provide useful information to characterize early PD subjects. This protocol is potentially usable to monitor the disease's progression.","Displacement measurement,
Acceleration,
Time measurement,
Time frequency analysis,
Frequency conversion"
A Game Theory Approach to Target Tracking in Sensor Networks,"In this paper, we investigate a moving-target tracking problem with sensor networks. Each sensor node has a sensor to observe the target and a processor to estimate the target position. It also has wireless communication capability but with limited range and can only communicate with neighbors. The moving target is assumed to be an intelligent agent, which is “smart” enough to escape from the detection by maximizing the estimation error. This adversary behavior makes the target tracking problem more difficult. We formulate this target estimation problem as a zero-sum game in this paper and use a minimax filter to estimate the target position. The minimax filter is a robust filter that minimizes the estimation error by considering the worst case noise. Furthermore, we develop a distributed version of the minimax filter for multiple sensor nodes. The distributed computation is implemented via modeling the information received from neighbors as measurements in the minimax filter. The simulation results show that the target tracking algorithm proposed in this paper provides a satisfactory result.","Game theory,
Target tracking,
Filters,
Minimax techniques,
Intelligent sensors,
Estimation error,
Wireless communication,
Intelligent agent,
Noise robustness,
Distributed computing"
Automated Mitosis Detection of Stem Cell Populations in Phase-Contrast Microscopy Images,"Due to the enormous potential and impact that stem cells may have on regenerative medicine, there has been a rapidly growing interest for tools to analyze and characterize the behaviors of these cells in vitro in an automated and high throughput fashion. Among these behaviors, mitosis, or cell division, is important since stem cells proliferate and renew themselves through mitosis. However, current automated systems for measuring cell proliferation often require destructive or sacrificial methods of cell manipulation such as cell lysis or in vitro staining. In this paper, we propose an effective approach for automated mitosis detection using phase-contrast time-lapse microscopy, which is a nondestructive imaging modality, thereby allowing continuous monitoring of cells in culture. In our approach, we present a probabilistic model for event detection, which can simultaneously 1) identify spatio-temporal patch sequences that contain a mitotic event and 2) localize a birth event, defined as the time and location at which cell division is completed and two daughter cells are born. Our approach significantly outperforms previous approaches in terms of both detection accuracy and computational efficiency, when applied to multipotent C3H10T1/2 mesenchymal and C2C12 myoblastic stem cell populations.","Microscopy,
Feature extraction,
Hidden Markov models,
Computational modeling,
Stem cells,
Cells (biology),
Training"
Learning Adaptive Metric for Robust Visual Tracking,"Matching the visual appearances of the target over consecutive image frames is the most critical issue in video-based object tracking. Choosing an appropriate distance metric for matching determines its accuracy and robustness, and thus significantly influences the tracking performance. Most existing tracking methods employ fixed pre-specified distance metrics. However, this simple treatment is problematic and limited in practice, because a pre-specified metric does not likely to guarantee the closest match to be the true target of interest. This paper presents a new tracking approach that incorporates adaptive metric learning into the framework of visual object tracking. Collecting a set of supervised training samples on-the-fly in the observed video, this new approach automatically learns the optimal distance metric for more accurate matching. The design of the learned metric ensures that the closest match is very likely to be the true target of interest based on the supervised training. Such a learned metric is discriminative and adaptive. This paper substantializes this new approach in a solid case study of adaptive-metric differential tracking, and obtains a closed-form analytical solution to motion estimation and visual tracking. Moreover, this paper extends the basic linear distance metric learning method to a more powerful nonlinear kernel metric learning method. Extensive experiments validate the effectiveness of the proposed approach, and demonstrate the improved performance of the proposed new tracking method.","Target tracking,
Training,
Learning systems,
Visualization,
Transforms"
A New Automatic Parameter Setting Method of a Simplified PCNN for Image Segmentation,"An automatic parameter setting method of a simplified pulse coupled neural network (SPCNN) is proposed here. Our method successfully determines all the adjustable parameters in SPCNN and does not need any training and trials as required by previous methods. In order to achieve this goal, we try to derive the general formulae of dynamic threshold and internal activity of the SPCNN according to the dynamic properties of neurons, and then deduce the sub-intensity range expression of each segment based on the general formulae. Besides, we extract information from an input image, such as the standard deviation and the optimal histogram threshold of the image, and attempt to build a direct relation between the dynamic properties of neurons and the static properties of each input image. Finally, the experimental segmentation results of the gray natural images from the Berkeley Segmentation Dataset, rather than synthetic images, prove the validity and efficiency of our proposed automatic parameter setting method of SPCNN.","Neurons,
Image segmentation,
Joining processes,
Training,
Pixel,
Computational modeling"
Framelet Algorithms for De-Blurring Images Corrupted by Impulse Plus Gaussian Noise,"This paper studies a problem of image restoration that observed images are contaminated by Gaussian and impulse noise. Existing methods for this problem in the literature are based on minimizing an objective functional having the l1 fidelity term and the Mumford-Shah regularizer. We present an algorithm on this problem by minimizing a new objective functional. The proposed functional has a content-dependent fidelity term which assimilates the strength of fidelity terms measured by the l1 and l2 norms. The regularizer in the functional is formed by the l1 norm of tight framelet coefficients of the underlying image. The selected tight framelet filters are able to extract geometric features of images. We then propose an iterative framelet-based approximation/sparsity deblurring algorithm (IFASDA) for the proposed functional. Parameters in IFASDA are adaptively varying at each iteration and are determined automatically. In this sense, IFASDA is a parameter-free algorithm. This advantage makes the algorithm more attractive and practical. The effectiveness of IFASDA is experimentally illustrated on problems of image deblurring with Gaussian and impulse noise. Improvements in both PSNR and visual quality of IFASDA over a typical existing method are demonstrated. In addition, Fast_IFASDA, an accelerated algorithm of IFASDA, is also developed.","Noise,
Approximation methods,
Pixel,
Noise measurement,
Hafnium,
Image restoration,
Mathematical model"
Improving Fingerprint Orientation Extraction,"Computation of local orientations is a primary step in fingerprint recognition. A large number of approaches have been proposed in the literature, but no systematic quantitative evaluations have been done yet. We implemented and tested several well know methods and a plethora of their variants over a novel, specifically designed, benchmark, made available in the FVC-onGoing framework. We proved that parameter optimizations, pre- and post-processing stages can markedly improve accuracy of the baseline methods on bad quality fingerprints. Finally, in this paper we propose a novel adaptive method which selectively exploits accuracy of local-based analysis and learning-based global methods, thus achieving the overall best performance on a challenging dataset.","Fingerprint recognition,
Benchmark testing,
Feature extraction,
Estimation,
Accuracy,
Optimization,
Smoothing methods"
Iterative Learning Control for Multiple Point-to-Point Tracking Application,"This paper considers a general class of linear iterative learning control (ILC) algorithm applied to tracking tasks which require the plant output to reach given points at predetermined time instants, without the specification of intervening reference points. A framework is developed in the frequency-domain in which the reference is updated between trials. It is shown that superior convergence and robustness properties are obtained compared with those associated with using the original class of ILC algorithm to track a prescribed arbitrary reference trajectory satisfying the point-to-point output constraints. Experimental results using a non-minimum phase test facility are presented to illustrate the theoretical findings.","Motion control,
Robotics and automation,
Iterative algorithms,
Convergence,
Robustness,
Trajectory,
Test facilities,
Position control,
Vibration control,
Shape control"
Generating Grid Multiwing Chaotic Attractors by Constructing Heteroclinic Loops Into Switching Systems,"Over the last two decades, multiwing chaos generation has seen promising advances and becomes an active research field today. It is well known that there is a gap between theoretical design and engineering applications in multiwing chaos generation. That is, most theoretical designs of multiwing chaotic attractors with mathematical proofs or numerical verification have rather complex expressions; however, most engineering applications of multiwing chaotic attractors without theoretical supports have simple expressions. To bridge the gap between theoretical design and engineering applications in multiwing chaos generation, this paper introduces a novel practical approach for generating grid multiwing butterfly chaotic attractors from the multipiecewise Lü system by constructing heteroclinic loops. It should be particularly pointed out that the designed multiwing chaotic attractors exhibit typical heteroclinic chaos from the heteroclinic Shil'nikov theorem and also have clear potential engineering applications. The proposed method can be easily extended to the generalized Lorenz system family.","Chaotic communication,
Switches,
Linear systems,
Bifurcation,
Orbits"
Mobile Sensor Network Navigation Using Gaussian Processes With Truncated Observations,"In this paper, we consider mobile sensor networks that use spatiotemporal Gaussian processes to predict a wide range of spatiotemporal physical phenomena. Nonparametric Gaussian process regression that is based on truncated observations is proposed for mobile sensor networks with limited memory and computational power. We first provide a theoretical foundation of Gaussian process regression with truncated observations. In particular, we demonstrate that prediction using all observations can be well approximated by prediction using truncated observations under certain conditions. Inspired by the analysis, we then propose a centralized navigation strategy for mobile sensor networks to move in order to reduce prediction error variances at points of interest. For the case in which each agent has a limited communication range, we propose a distributed navigation strategy. Particularly, we demonstrate that mobile sensing agents with the distributed navigation strategy produce an emergent, swarming-like, collective behavior for communication connectivity and are coordinated to improve the quality of the collective prediction capability.","Gaussian processes,
Robot sensing systems,
Mobile communication,
Mobile computing,
Spatiotemporal phenomena"
An Area and Power-Efficient Analog Li-Ion Battery Charger Circuit,"The demand for greater battery life in low-power consumer electronics and implantable medical devices presents a need for improved energy efficiency in the management of small rechargeable cells. This paper describes an ultra-compact analog lithium-ion (Li-ion) battery charger with high energy efficiency. The charger presented here utilizes the tanh basis function of a subthreshold operational transconductance amplifier to smoothly transition between constant-current and constant-voltage charging regimes without the need for additional area- and power-consuming control circuitry. Current-domain circuitry for end-of-charge detection negates the need for precision-sense resistors in either the charging path or control loop. We show theoretically and experimentally that the low-frequency pole-zero nature of most battery impedances leads to inherent stability of the analog control loop. The circuit was fabricated in an AMI 0.5-μm complementary metal-oxide semiconductor process, and achieves 89.7% average power efficiency and an end voltage accuracy of 99.9% relative to the desired target 4.2 V, while consuming 0.16 mm2 of chip area. To date and to the best of our knowledge, this design represents the most area-efficient and most energy-efficient battery charger circuit reported in the literature.","Batteries,
Resistors,
Detectors,
Temperature measurement,
Temperature distribution,
Photonic band gap,
Feedback loop"
Shared last-level TLBs for chip multiprocessors,"Translation Lookaside Buffers (TLBs) are critical to processor performance. Much past research has addressed uniprocessor TLBs, lowering access times and miss rates. However, as chip multiprocessors (CMPs) become ubiquitous, TLB design must be re-evaluated. This paper is the first to propose and evaluate shared last-level (SLL) TLBs as an alternative to the commercial norm of private, per-core L2 TLBs. SLL TLBs eliminate 7-79% of system-wide misses for parallel workloads. This is an average of 27% better than conventional private, per-core L2 TLBs, translating to notable runtime gains. SLL TLBs also provide benefits comparable to recently-proposed Inter-Core Cooperative (ICC) TLB prefetchers, but with considerably simpler hardware. Furthermore, unlike these prefetchers, SLL TLBs can aid sequential applications, eliminating 35-95% of the TLB misses for various multiprogrammed combinations of sequential applications. This corresponds to a 21% average increase in TLB miss eliminations compared to private, per-core L2 TLBs. Because of their benefits for parallel and sequential applications, and their readily-implementable hardware, SLL TLBs hold great promise for CMPs.",
Topological Detection on Wormholes in Wireless Ad Hoc and Sensor Networks,"Wormhole attack is a severe threat to wireless ad hoc and sensor networks. Most existing countermeasures either require specialized hardware devices or make strong assumptions on the network in order to capture the specific (partial) symptom induced by wormholes. Those requirements and assumptions limit the applicability of previous approaches. In this paper, we present our attempt to understand the impact and inevitable symptom of wormholes and develop distributed detection methods by making as few restrictions and assumptions as possible. We fundamentally analyze the wormhole problem using a topology methodology and propose an effective distributed approach, which relies solely on network connectivity information, without any requirements on special hardware devices or any rigorous assumptions on network properties. We formally prove the correctness of this design in continuous geometric domains and extend it into discrete domains. We evaluate its performance through extensive simulations.","Topology,
Network topology,
Ad hoc networks,
Wireless communication,
Wireless sensor networks,
Hardware,
Surface roughness"
Verification and validation of simulation models,"In this paper we discuss verification and validation of simulation models. Four different approaches to deciding model validity are described, a graphical paradigm that relates verification and validation to the model development process is presented, and various validation techniques are defined. Conceptual model validity, model verification, operational validity, and data validity are discussed and a way to document results is given. A recommended procedure for model validation is presented and model accreditation is briefly discussed.","Computational modeling,
Biological system modeling,
Analytical models,
Data models,
Mathematical model,
Accuracy,
Integrated circuit modeling"
HMM-Based Multipitch Tracking for Noisy and Reverberant Speech,"Multipitch tracking in real environments is critical for speech signal processing. Determining pitch in reverberant and noisy speech is a particularly challenging task. In this paper, we propose a robust algorithm for multipitch tracking in the presence of both background noise and room reverberation. An auditory front-end and a new channel selection method are utilized to extract periodicity features. We derive pitch scores for each pitch state, which estimate the likelihoods of the observed periodicity features given pitch candidates. A hidden Markov model integrates these pitch scores and searches for the best pitch state sequence. Our algorithm can reliably detect single and double pitch contours in noisy and reverberant conditions. Quantitative evaluations show that our approach outperforms existing ones, particularly in reverberant conditions.",
4-dimensional local spatio-temporal features for human activity recognition,"Recognizing human activities from common color image sequences faces many challenges, such as complex backgrounds, camera motion, and illumination changes. In this paper, we propose a new 4-dimensional (4D) local spatio-temporal feature that combines both intensity and depth information. The feature detector applies separate filters along the 3D spatial dimensions and the 1D temporal dimension to detect a feature point. The feature descriptor then computes and concatenates the intensity and depth gradients within a 4D hyper cuboid, which is centered at the detected feature point, as a feature. For recognizing human activities, Latent Dirichlet Allocation with Gibbs sampling is used as the classifier. Experiments are performed on a newly created database that contains six human activities, each with 33 samples with complex variations. Experimental results demonstrate the promising performance of the proposed features for the task of human activity recognition.","Feature extraction,
Humans,
Three dimensional displays,
Videos,
Cameras,
Vectors,
Databases"
On the Degrees of Freedom of Finite State Compound Wireless Networks,"We explore the degrees of freedom (DoF) of three classes of finite state compound wireless networks in this paper. First, we study the multiple-input single-output (MISO) finite state compound broadcast channel (BC) with arbitrary number of users and antennas at the transmitter. In prior work, Weingarten have found inner and outer bounds on the DoF with 2 users. The bounds have a different character. While the inner bound collapses to unity as the number of states increases, the outer bound does not diminish with the increasing number of states beyond a threshold value. It has been conjectured that the outer bound is loose and the inner bound represents the actual DoF. In the complex setting (all signals, noise, and channel coefficients are complex variables), we solve a few cases to find that the outer bound - and not the inner bound - of Weingarten is tight. For the real setting (all signals, noise, and channel coefficients are real variables), we completely characterize the DoF, once again proving that the outer bound of Weingarten is tight. We also extend the results to arbitrary number of users. Second, we characterize the DoF of finite state scalar (single antenna nodes) compound X networks with arbitrary number of users in the real setting. Third, we characterize the DoF of finite state scalar compound interference networks with arbitrary number of users in both the real and complex setting. The key finding is that scalar interference networks and (real) X networks do not lose any DoF due to channel uncertainty at the transmitter in the finite state compound setting. The finite state compound MISO BC does lose DoF relative to the perfect CSIT scenario. However, what is lost is only the DoF benefit of joint processing at transmit antennas, without which the MISO BC reduces to an X network.","Compounds,
Interference,
Transmitting antennas,
Receiving antennas,
MIMO"
Channel Estimation and Training Design for Two-Way Relay Networks in Time-Selective Fading Environments,"In this paper, channel estimation and training sequence design are considered for amplify-and-forward (AF)-based two-way relay networks (TWRNs) in a time-selective fading environment. A new complex-exponential basis expansion model (CE-BEM) is proposed to represent the mobile-to-mobile time-varying channels. To estimate such channels, a novel pilot symbol-aided transmission scheme is developed such that a low complex linear approach can estimate the BEM coefficients of the convoluted channels. More essentially, two algorithms are designed to extract the BEM coefficients of the individual channels. The optimal training parameters, including the number of the pilot symbols, the placement of the pilot symbols, and the power allocation to the pilot symbols, are derived by minimizing the channel mean-square error (MSE). The selections of the system parameters are thoroughly discussed in order to guide practical system design. Finally, extensive numerical results are provided to corroborate the proposed studies.","Channel estimation,
Training,
Relays,
Time-varying channels,
Fading,
Indexes,
Estimation"
In Vivo Micro-Image Mosaicing,"Recent advances in optical imaging have led to the development of miniature microscopes that can be brought to the patient for visualizing tissue structures in vivo. These devices have the potential to revolutionize health care by replacing tissue biopsy with in vivo pathology. One of the primary limitations of these microscopes, however, is that the constrained field of view can make image interpretation and navigation difficult. In this paper, we show that image mosaicing can be a powerful tool for widening the field of view and creating image maps of microanatomical structures. First, we present an efficient algorithm for pairwise image mosaicing that can be implemented in real time. Then, we address two of the main challenges associated with image mosaicing in medical applications: cumulative image registration errors and scene deformation. To deal with cumulative errors, we present a global alignment algorithm that draws upon techniques commonly used in probabilistic robotics. To accommodate scene deformation, we present a local alignment algorithm that incorporates deformable surface models into the mosaicing framework. These algorithms are demonstrated on image sequences acquired in vivo with various imaging devices including a hand-held dual-axes confocal microscope, a miniature two-photon microscope, and a commercially available confocal microendoscope.","Microscopy,
In vivo,
Optimization,
Optical microscopy,
Image registration,
Optical imaging"
A segmentation-aware object detection model with occlusion handling,"The bounding box representation employed by many popular object detection models [3, 6] implicitly assumes all pixels inside the box belong to the object. This assumption makes this representation less robust to the object with occlusion [16]. In this paper, we augment the bounding box with a set of binary variables each of which corresponds to a cell indicating whether the pixels in the cell belong to the object. This segmentation-aware representation explicitly models and accounts for the supporting pixels for the object within the bounding box thus more robust to occlusion. We learn the model in a structured output framework, and develop a method that efficiently performs both inference and learning using this rich representation. The method is able to use segmentation reasoning to achieve improved detection results with richer output (cell level segmentation) on the Street Scenes and Pascal VOC 2007 datasets. Finally, we present a globally coherent object model using our rich representation to account for object-object occlusion resulting in a more coherent image understanding.","Mathematical model,
Image segmentation,
Equations,
Detectors,
Joints,
Inference algorithms,
Object detection"
SEU Prediction From SET Modeling Using Multi-Node Collection in Bulk Transistors and SRAMs Down to the 65 nm Technology Node,A new methodology of prediction for SEU is proposed based on SET modeling. The modeling of multi-node charge collection is performed using the ADDICT model for predicting single event transients and upsets in bulk transistors and SRAMs down to 65 nm. The predicted single event upset cross sections agree well with experimental data for SRAMs.,"Transient analysis,
MOSFETs,
Predictive models,
Capacitance,
Current measurement,
Junctions"
Computational Cameras: Convergence of Optics and Processing,"A computational camera uses a combination of optics and processing to produce images that cannot be captured with traditional cameras. In the last decade, computational imaging has emerged as a vibrant field of research. A wide variety of computational cameras has been demonstrated to encode more useful visual information in the captured images, as compared with conventional cameras. In this paper, we survey computational cameras from two perspectives. First, we present a taxonomy of computational camera designs according to the coding approaches, including object side coding, pupil plane coding, sensor side coding, illumination coding, camera arrays and clusters, and unconventional imaging systems. Second, we use the abstract notion of light field representation as a general tool to describe computational camera designs, where each camera can be formulated as a projection of a high-dimensional light field to a 2-D image sensor. We show how individual optical devices transform light fields and use these transforms to illustrate how different computational camera designs (collections of optical devices) capture and encode useful visual information.","Cameras,
Lenses,
Image coding,
Optical devices,
Detectors"
"Sensitivity of Photon-Counting Based
K
-Edge Imaging in X-ray Computed Tomography","The feasibility of K-edge imaging using energy-resolved, photon-counting transmission measurements in X-ray computed tomography (CT) has been demonstrated by simulations and experiments. The method is based on probing the discontinuities of the attenuation coefficient of heavy elements above and below the K-edge energy by using energy-sensitive, photon counting X-ray detectors. In this paper, we investigate the dependence of the sensitivity of K-edge imaging on the atomic number Z of the contrast material, on the object diameter D , on the spectral response of the X-ray detector and on the X-ray tube voltage. We assume a photon-counting detector equipped with six adjustable energy thresholds. Physical effects leading to a degradation of the energy resolution of the detector are taken into account using the concept of a spectral response function R(E,U) for which we assume four different models. As a validation of our analytical considerations and in order to investigate the influence of elliptically shaped phantoms, we provide CT simulations of an anthropomorphic Forbild-Abdomen phantom containing a gold-contrast agent. The dependence on the values of the energy thresholds is taken into account by optimizing the achievable signal-to-noise ratios (SNR) with respect to the threshold values. We find that for a given X-ray spectrum and object size the SNR in the heavy element's basis material image peaks for a certain atomic number Z. The dependence of the SNR in the high-Z basis-material image on the object diameter is the natural, exponential decrease with particularly deteriorating effects in the case where the attenuation from the object itself causes a total signal loss below the K-edge. The influence of the energy-response of the detector is very important. We observed that the optimal SNR values obtained with an ideal detector and with a CdTe pixel detector whose response, showing significant tailing, has been determined at a synchrotron differ by factors of about two to three. The potentially very important impact of scattered X-ray radiation and pulse pile-up occurring at high photon rates on the sensitivity of the technique is qualitatively discussed.","Detectors,
Computed tomography,
Signal to noise ratio,
Photonics,
X-ray imaging,
Materials"
iSAM2: Incremental smoothing and mapping with fluid relinearization and incremental variable reordering,"We present iSAM2, a fully incremental, graph-based version of incremental smoothing and mapping (iSAM). iSAM2 is based on a novel graphical model-based interpretation of incremental sparse matrix factorization methods, afforded by the recently introduced Bayes tree data structure. The original iSAM algorithm incrementally maintains the square root information matrix by applying matrix factorization updates. We analyze the matrix updates as simple editing operations on the Bayes tree and the conditional densities represented by its cliques. Based on that insight, we present a new method to incrementally change the variable ordering which has a large effect on efficiency. The efficiency and accuracy of the new method is based on fluid relinearization, the concept of selectively relinearizing variables as needed. This allows us to obtain a fully incremental algorithm without any need for periodic batch steps. We analyze the properties of the resulting algorithm in detail, and show on various real and simulated datasets that the iSAM2 algorithm compares favorably with other recent mapping algorithms in both quality and efficiency.","Simultaneous localization and mapping,
Graphical models,
Smoothing methods,
Sparse matrices,
Accuracy,
Trajectory"
"Atherosclerotic Plaque Ultrasound Video Encoding, Wireless Transmission, and Quality Assessment Using H.264","We propose a unifying framework for efficient encoding, transmission, and quality assessment of atherosclerotic plaque ultrasound video. The approach is based on a spatially varying encoding scheme, where video-slice quantization parameters are varied as a function of diagnostic significance. Video slices are automatically set based on a segmentation algorithm. They are then encoded using a modified version of H.264/AVC flexible macroblock ordering (FMO) technique that allows variable quality slice encoding and redundant slices (RSs) for resilience over error-prone transmission channels. We evaluate our scheme on a representative collection of ten ultrasound videos of the carotid artery for packet loss rates up to 30%. Extensive simulations incorporating three FMO encoding methods, different quantization parameters, and different packet loss scenarios are investigated. Quality assessment is based on a new clinical rating system that provides independent evaluations of the different parts of the video (subjective). We also use objective video-quality assessment metrics and estimate their correlation to the clinical quality assessment of plaque type. We find that some objective quality assessment measures computed over the plaque video slices gave very good correlations to mean opinion scores (MOSs). Here, MOSs were computed using two medical experts. Experimental results show that the proposed method achieves enhanced performance in noisy environments, while at the same time achieving significant bandwidth demands reductions, providing transmission over 3G (and beyond) wireless networks.","Encoding,
Streaming media,
Quality assessment,
Medical diagnostic imaging,
Ultrasonic imaging,
Quantization"
AdaMS: Adaptive MLC/SLC phase-change memory design for file storage,"Phase-change memory (PCM) is an emerging memory technology that has made rapid progress in the recent years, and surpasses other technologies such as FeRAM and MRAM in terms of scalability. Recently, the feasibility of multi-level cell (MLC) for PCM, which enables a cell to store more than one bit of digital data, has also been shown. This new property makes PCM more competitive and considered as the successor of the NAND flash technology, which also has the MLC capability but does not have an easy scaling path to reach higher densities. However, the MLC capability of PCM comes with the penalty of longer programming time and shortened cell lifetime compared to its single-level cell (SLC) mode. Therefore, it suggests an adaptive MLC/SLC reconfigurable PCM design that can exploit the fast SLC access speed and the large MLC capacity with the awareness of workload characteristics and lifetime requirements. In this work, a circuit-level adaptive MLC/SLC PCM array is designed at first, the management policy of MLC/SLC mode is proposed, and finally the performance and lifetime of a novel PCM-based SSD with run-time MLC/SLC reconfiguration ability is evaluated.","Phase change materials,
Resistance,
Throughput,
Writing,
Ash,
Arrays,
Performance evaluation"
Statistical Interior Tomography,"This paper presents a statistical interior tomography (SIT) approach making use of compressed sensing (CS) theory. With the projection data modeled by the Poisson distribution, an objective function with a total variation (TV) regularization term is formulated in the maximization of a posteriori (MAP) framework to solve the interior problem. An alternating minimization method is used to optimize the objective function with an initial image from the direct inversion of the truncated Hilbert transform. The proposed SIT approach is extensively evaluated with both numerical and real datasets. The results demonstrate that SIT is robust with respect to data noise and down-sampling, and has better resolution and less bias than its deterministic counterpart in the case of low count data.","Image reconstruction,
TV,
Transforms,
Algorithm design and analysis,
Minimization,
Computed tomography"
Nonlinear Dynamics of Spring Softening and Hardening in Folded-MEMS Comb Drive Resonators,"This paper studies analytically and numerically the spring softening and hardening phenomena that occur in electrostatically actuated microelectromechanical systems comb drive resonators utilizing folded suspension beams. An analytical expression for the electrostatic force generated between the combs of the rotor and the stator is derived and takes into account both the transverse and longitudinal capacitances present. After formulating the problem, the resulting stiff differential equations are solved analytically using the method of multiple scales, and a closed-form solution is obtained. Furthermore, the nonlinear boundary value problem that describes the dynamics of inextensional spring beams is solved using straightforward perturbation to obtain the linear and nonlinear spring constants of the beam. The analytical solution is verified numerically using a Matlab/Simulink environment, and the results from both analyses exhibit excellent agreement. Stability analysis based on phase plane trajectory is also presented and fully explains previously reported empirical results that lacked sufficient theoretical description. Finally, the proposed solutions are, once again, verified with previously published measurement results. The closed-form solutions provided are easy to apply and enable predicting the actual behavior of resonators and gyroscopes with similar structures.","Springs,
Softening,
Capacitance,
Electrostatics,
Mathematical model,
Equations,
Resonant frequency"
Novo-G: At the Forefront of Scalable Reconfigurable Supercomputing,"The Novo-G supercomputer's architecture can adapt to match each application/s unique needs and thereby attain more performance with less energy than conventional machines. Reconfigurable computing can provide solutions for domain scientists at a fraction of the time and cost of traditional servers or supercomputers. As we describe here, the Novo-G machine, applications, research forum, and preliminary results are helping to pave the way for scalable reconfigurable computing.","Field programmable gate arrays,
Program processors,
Supercomputers,
Computer architecture,
Neodymium,
Bioinformatics,
Runtime"
Exploring the optimal replication strategy in P2P-VoD systems: Characterization and evaluation,"Content providers of P2P-Video-on-Demand (P2P-VoD) services aim to provide a high quality, scalable service to users, and at the same time, operate the system with a manageable operating cost. Given the volume-based charging model by ISPs, it is to the best interest of the P2P-VoD content providers to reduce peers' access to the content server so as to reduce the operating cost. In this paper, we address an important open problem: what is the “optimal replication ratio” in a P2P-VoD system such that peers will receive service from each other and at the same time, reduce the traffic to the content server. We address two fundamental problems: (1) what is the optimal replication ratio of a movie given its popularity, and (2) how to achieve the optimal ratios in a distributed and dynamic fashion. We formally show how movie popularities can impact server's workload, and formulate the video replication as an optimization problem. We show that the conventional wisdom of using the proportional replication strategy is non-optimal, and expand the design space to both passive replacement policy and active push policy to achieve the optimal replication ratios. We consider practical implementation issues, evaluate the performance of P2P-VoD systems and show that our algorithms can greatly reduce server's workload and improve streaming quality.","Motion pictures,
Servers,
Bandwidth,
Software,
Peer to peer computing,
Algorithm design and analysis,
Optimization"
Adaptive Output Feedback NN Control of a Class of Discrete-Time MIMO Nonlinear Systems With Unknown Control Directions,"In this paper, adaptive neural network (NN) control is investigated for a class of block triangular multiinput-multioutput nonlinear discrete-time systems with each subsystem in pure-feedback form with unknown control directions. These systems are of couplings in every equation of each subsystem, and different subsystems may have different orders. To avoid the noncausal problem in the control design, the system is transformed into a predictor form by rigorous derivation. By exploring the properties of the block triangular form, implicit controls are developed for each subsystem such that the couplings of inputs and states among subsystems have been completely decoupled. The radial basis function NN is employed to approximate the unknown control. Each subsystem achieves a semiglobal uniformly ultimately bounded stability with the proposed control, and simulation results are presented to demonstrate its efficiency.","Artificial neural networks,
MIMO,
Mathematical model,
Equations,
Couplings,
Nonlinear systems,
Adaptive systems"
A CMOS Single-Chip Gas Recognition Circuit for Metal Oxide Gas Sensor Arrays,"This paper presents a CMOS single-chip gas recognition circuit, which encodes sensor array outputs into a unique sequence of spikes with the firing delay mapping the strength of the stimulation across the array. The proposed gas recognition circuit examines the generated spike pattern of relative excitations across the population of sensors and looks for a match within a library of 2-D spatio-temporal spike signatures. Each signature is drift insensitive, concentration invariant and is also a unique characteristic of the target gas. This VLSI friendly approach relies on a simple spatio-temporal code matching instead of existing computationally expensive pattern matching statistical techniques. In addition, it relies on a novel sensor calibration technique that does not require control or prior knowledge of the gas concentration. The proposed gas recognition circuit was implemented in a 0.35 μm CMOS process and characterized using an in-house fabricated 4 × 4 tin oxide gas sensor array. Experimental results show a correct detection rate of 94.9% when the gas sensor array is exposed to propane, ethanol and carbon monoxide.","Sensor arrays,
Gas detectors,
Resistance,
Metals,
CMOS integrated circuits,
Fabrication"
Weakly Supervised Recognition of Daily Life Activities with Wearable Sensors,"This paper considers scalable and unobtrusive activity recognition using on-body sensing for context awareness in wearable computing. Common methods for activity recognition rely on supervised learning requiring substantial amounts of labeled training data. Obtaining accurate and detailed annotations of activities is challenging, preventing the applicability of these approaches in real-world settings. This paper proposes new annotation strategies that substantially reduce the required amount of annotation. We explore two learning schemes for activity recognition that effectively leverage such sparsely labeled data together with more easily obtainable unlabeled data. Experimental results on two public data sets indicate that both approaches obtain results close to fully supervised techniques. The proposed methods are robust to the presence of erroneous labels occurring in real-world annotation data.","Wearable computers,
Training,
Supervised learning"
Scalable Carbon Nanotube Computational and Storage Circuits Immune to Metallic and Mispositioned Carbon Nanotubes,"We present a new very large scale integration (VLSI)-compatible metallic carbon nanotube (CNT) removal technique called VLSI-compatible metallic CNT removal (VMR) that overcomes challenges of existing techniques by combining design and processing to create carbon nanotube field effect transistors (CNFET) circuits immune to CNT imperfections such as metallic and mispositioned CNTs. Using VMR, we experimentally demonstrate combinational and sequential CNFET logic circuits such as half-adder sum generators and D-latches. These circuits form the fundamental building blocks of VLSI digital systems.",
Socially Optimal Queuing Control in Cognitive Radio Networks Subject to Service Interruptions: To Queue or Not to Queue?,"The main challenge to cognitive radio is the emergence of primary users, which can be considered as the service interruptions in a queuing system. The service interruption can incur significant delays for secondary users' data packets which are considered as secondary customers. Therefore, a secondary customer needs to decide whether to join the queue or leave for other means of transmission. It is shown that the individually optimal strategy for joining the queue is characterized by a threshold of queue length. When the current queue length is above this threshold, the secondary customer should leave; otherwise it should join the queue. The socially optimal threshold of queue length is also obtained and is numerically shown to be smaller than the individually optimal one, which implies that the individually optimal strategy does not yield the socially optimal one. To bridge the gap between the individually and socially optimal strategies, a pricing mechanism is proposed to toll the service of each secondary customer, thus equalizing the two optimal strategies. When the channel statistics are unknown, an online learning procedure, based on the Kiefer-Wolfowitz algorithm, is proposed. The proposed algorithms are then demonstrated using numerical simulations.","Cognitive radio,
Servers,
Queueing analysis,
Pricing,
Delay,
Wireless networks,
Numerical models"
On the Selection of Optimal Feature Region Set for Robust Digital Image Watermarking,"A novel feature region selection method for robust digital image watermarking is proposed in this paper. This method aims to select a nonoverlapping feature region set, which has the greatest robustness against various attacks and can preserve image quality as much as possible after watermarked. It first performs a simulated attacking procedure using some predefined attacks to evaluate the robustness of every candidate feature region. According to the evaluation results, it then adopts a track-with-pruning procedure to search a minimal primary feature set which can resist the most predefined attacks. In order to enhance its resistance to undefined attacks under the constraint of preserving image quality, the primary feature set is then extended by adding into some auxiliary feature regions. This work is formulated as a multidimensional knapsack problem and solved by a genetic algorithm based approach. The experimental results for StirMark attacks on some benchmark images support our expectation that the primary feature set can resist all the predefined attacks and its extension can enhance the robustness against undefined attacks. Comparing with some well-known feature-based methods, the proposed method exhibits better performance in robust digital watermarking.","Watermarking,
Robustness,
Feature extraction,
Resists,
Detectors,
Resistance,
Transform coding"
Observability of Boolean Control Networks With State Time Delays,"This brief deals with the problem of the observability for the Boolean control networks with time delays in states. First, using semi-tensor product of matrices and the matrix expression of logic, the Boolean control networks with state delays can be converted into discrete time delay dynamics. Then, the observability of the Boolean control networks via two kinds of inputs is investigated by giving necessary and sufficient conditions. Finally, examples are given to illustrate the efficiency of the obtained results.","Observability,
Delay effects,
Matrix converters,
Delay,
Systems biology,
Biological systems,
Systematics"
"Computer-Assisted Planning and Navigation for Corrective Distal Radius Osteotomy, Based on Pre- and Intraoperative Imaging","Malunion after a distal radius fracture is very common and if symptomatic, is treated with a so-called corrective osteotomy. In a traditional distal radius osteotomy, the radius is cut at the fracture site and a wedge is inserted in the osteotomy gap to correct the distal radius pose. The standard procedure uses two orthogonal radiographs to estimate the two inclination angles and the dimensions of the wedge to be inserted into the osteotomy gap. However, optimal correction in 3-Dspace requires restoring three angles and three displacements. This paper introduces a new technique that uses preoperative planning based on 3-D images. Intraoperative 3-D imaging is also used after inserting pins with marker tools in the proximal and distal part of the radius and before the osteotomy. Positioning tools are developed to correct the distal radius pose in six degrees of freedom by navigating the pins. The method is accurate (derr <; 1.2 mm, φerr <; 0.9°, mTRE = 1.7 mm), highly reproducible (SEd <; 1.0 mm, SEφ ≤ 1.4°, SEmTRE = 0.7 mm), and allows intraoperative evaluation of the end result. Small incisions for pin placement and for the osteotomy render the method minimally invasive.","Manipulators,
Computed tomography,
Accuracy,
Bones,
Pins,
Image segmentation,
Planning"
Performance Optimal Online DVFS and Task Migration Techniques for Thermally Constrained Multi-Core Processors,"Extracting high performance from multi-core processors requires increased use of thermal management techniques. In contrast to offline thermal management techniques, online techniques are capable of sensing changes in the workload distribution and setting the processor controls accordingly. Hence, online solutions are more accurate and are able to extract higher performance than the offline techniques. This paper presents performance optimal online thermal management techniques for multicore processors. The techniques include dynamic voltage and frequency scaling and task-to-core allocation or task migration. The problem formulation includes accurate power and thermal models, as well as leakage dependence on temperature. This paper provides a theoretical basis for deriving the optimal policies and computationally efficient implementations. The effectiveness of our DVFS and task-to-core allocation techniques are demonstrated by numerical simulations. The proposed task-to-core allocation method showed a 20.2% improvement in performance over a power-based thread migration approach. The techniques have been incorporated in a thermal-aware architectural-level simulator called MAGMA that allows for design space exploration, offline, and online dynamic thermal management. The simulator is capable of handling simulations of hundreds of cores within reasonable time.","Thermal management,
Resource management,
Voltage control,
Multicore processing,
Temperature dependence,
Thermal analysis,
Process control"
Positional Uncertainty of Isocontours: Condition Analysis and Probabilistic Measures,"Uncertainty is ubiquitous in science, engineering and medicine. Drawing conclusions from uncertain data is the normal case, not an exception. While the field of statistical graphics is well established, only a few 2D and 3D visualization and feature extraction methods have been devised that consider uncertainty. We present mathematical formulations for uncertain equivalents of isocontours based on standard probability theory and statistics and employ them in interactive visualization methods. As input data, we consider discretized uncertain scalar fields and model these as random fields. To create a continuous representation suitable for visualization we introduce interpolated probability density functions. Furthermore, we introduce numerical condition as a general means in feature-based visualization. The condition number-which potentially diverges in the isocontour problem-describes how errors in the input data are amplified in feature computation. We show how the average numerical condition of isocontours aids the selection of thresholds that correspond to robust isocontours. Additionally, we introduce the isocontour density and the level crossing probability field; these two measures for the spatial distribution of uncertain isocontours are directly based on the probabilistic model of the input data. Finally, we adapt interactive visualization methods to evaluate and display these measures and apply them to 2D and 3D data sets.","Uncertainty,
Measurement uncertainty,
Isosurfaces,
Level set,
Random variables,
Systematics"
User-Friendly Random-Grid-Based Visual Secret Sharing,"Recently, the visual secret sharing (VSS) technique based on a random-grid algorithm (RGVSS), proposed by Kafri and Keren in 1987, has drawn attention in academia again. However, Kafri and Keren's scheme is not participant-friendly; that is to say, the generated shared images are meaningless, so users feel that this huge amount of data is hard to manage. The literature has illustrated the concept of creating meaningful shared images, in which some shape or information appears for easing management, for VSS technique by visual cryptography (VCVSS). Those friendly VCVSS schemes are not directly suitable for RGVSS. Instead, a new friendly RGVSS must be designed. Most friendly VCVSS schemes worsen the pixel expansion problem, in which the size of shared images is larger than that of the original secret image, to achieve the goal of generic meaningful shares. As a result, in this paper we have focused on proposing a novel RGVSS scheme by skillfully designing a procedure of distinguishing different light transmissions on shared images based on the pixel values of the logo image with two primary advantages: no pixel expansion, and being user-friendly. In order to illustrate the correctness, the formal analysis is demonstrated while the experimental results show the proposed schemes do work.","Pixel,
Visualization,
Frequency modulation,
Cryptography,
Image color analysis,
Image reconstruction,
Decoding"
Automatic Segmentation of Intracochlear Anatomy in Conventional CT,"Cochlear implant surgery is a procedure performed to treat profound hearing loss. Clinical results suggest that implanting the electrode in the scala tympani, one of the two principal cavities inside the cochlea, may result in better hearing restoration. Segmentation of intracochlear cavities could thus aid the surgeon to choose the point of entry and angle of approach that maximize the likelihood of successful implant insertion, which may lead to more substantial hearing restoration. However, because the membrane that separates the intracochlear cavities is too thin to be seen in conventional in vivo imaging, traditional segmentation techniques are inadequate. In this paper, we circumvent this problem by creating an active shape model with micro CT (μCT) scans of the cochlea acquired ex vivo. We then use this model to segment conventional CT scans. The model is fitted to the partial information available in the conventional scans and used to estimate the position of structures not visible in these images. Quantitative evaluation of our method, made possible by the set of μCTs, results in Dice similarity coefficients averaging 0.75. Mean and maximum surface errors average 0.21 and 0.80 mm.","Shape,
Image segmentation,
Computational modeling,
Training,
Computed tomography,
Surgery,
Active shape model"
APPLAUS: A Privacy-Preserving Location Proof Updating System for location-based services,"Today's location-sensitive service relies on user's mobile device to determine its location and send the location to the application. This approach allows the user to cheat by having his device transmit a fake location, which might enable the user to access a restricted resource erroneously or provide bogus alibis. To address this issue, we propose A Privacy-Preserving LocAtion proof Updating System (APPLAUS) in which co-located Bluetooth enabled mobile devices mutually generate location proofs, and update to a location proof server. Periodically changed pseudonyms are used by the mobile devices to protect source location privacy from each other, and from the untrusted location proof server. We also develop user-centric location privacy model in which individual users evaluate their location privacy levels in real-time and decide whether and when to accept a location proof exchange request based on their location privacy levels. APPLAUS can be implemented with the existing network infrastructure and the current mobile devices, and can be easily deployed in Bluetooth enabled mobile devices with little computation or power cost. Extensive experimental results show that our scheme, besides providing location proofs effectively, can significantly preserve the source location privacy.","Privacy,
Servers,
Mobile communication,
Peer to peer computing,
Position measurement,
Bluetooth,
Mobile handsets"
Active Sensing of Target Location Encoded by Cortical Microstimulation,"Cortical microstimulation has been proposed as a method to deliver sensory percepts to circumvent damaged sensory receptors or pathways. However, much of perception involves the active movement of sensory organs and the integration of information across sensory and motor modalities. The efficacy of cortical microstimulation in such an active sensing paradigm has not been demonstrated. We report a novel behavioral paradigm which delivers microstimulation in real-time based on a rat's movements and show that rats can perform sensorimotor integration with electrically delivered stimuli. Using a real-time whisker tracking system, we delivered microstimulation in barrel cortex of actively whisking rats when their whisker crossed a particular spatial location which defined the target. Rats learned to integrate microstimulation cues with their knowledge of whisker position to infer target location along the rostro-caudal axis in less than 200 ms. In a separate experiment, we found that rats trained to respond to cortical microstimulation responded similarly to whisker deflections while ignoring auditory distracters, suggesting that barrel cortex stimulation may be perceptually similar to somatosensory stimuli. This ability to deliver sensory percepts using cortical microstimulation in an active sensing system might have significant implications for the development of sensorimotor neuroprostheses.","Rats,
Sensors,
Correlation,
Arrays,
Timing,
Magnetic heads"
Genetic Algorithms With Guided and Local Search Strategies for University Course Timetabling,"The university course timetabling problem (UCTP) is a combinatorial optimization problem, in which a set of events has to be scheduled into time slots and located into suitable rooms. The design of course timetables for academic institutions is a very difficult task because it is an NP-hard problem. This paper investigates genetic algorithms (GAs) with a guided search strategy and local search (LS) techniques for the UCTP. The guided search strategy is used to create offspring into the population based on a data structure that stores information extracted from good individuals of previous generations. The LS techniques use their exploitive search ability to improve the search efficiency of the proposed GAs and the quality of individuals. The proposed GAs are tested on two sets of benchmark problems in comparison with a set of state-of-the-art methods from the literature. The experimental results show that the proposed GAs are able to produce promising results for the UCTP.","Genetic algorithms,
Data structures,
Resource management,
NP-hard problem,
Data mining,
Benchmark testing,
Polynomials,
Councils,
Information systems,
Computer science"
KIPDA: k-indistinguishable privacy-preserving data aggregation in wireless sensor networks,"When wireless sensor networks accumulate sensitive or confidential data, privacy becomes an important concern. Sensors are often resource-limited and power-constrained, and data aggregation is commonly used to address these issues. However, providing privacy without disrupting in-network data aggregation is challenging. Although privacy-preserving data aggregation for additive and multiplicative aggregation functions has been studied, nonlinear aggregation functions such as maximum and minimum have not been well addressed. We present KIPDA, a privacy-preserving aggregation method, which we specialize for maximum and minimum aggregation functions. KIPDA obfuscates sensitive measurements by hiding them among a set of camouflage values, enabling k-indistinguishability for data aggregation. In principle, KIPDA can be used to hide a wide range of aggregation functions, although this paper considers only maximum and minimum. Because the sensitive data are not encrypted, it is easily and efficiently aggregated with minimal in-network processing delay. We quantify the efficiency of KIPDA in terms of power consumption and time delay, studying tradeoffs between the protocol's effectiveness and its resilience against collusion.","Base stations,
Sensors,
Wireless sensor networks,
Encryption,
Data privacy,
Indexes,
Privacy"
Sharing features between objects and their attributes,"Visual attributes expose human-defined semantics to object recognition models, but existing work largely restricts their influence to mid-level cues during classifier training. Rather than treat attributes as intermediate features, we consider how learning visual properties in concert with object categories can regularize the models for both. Given a low-level visual feature space together with attribute-and object-labeled image data, we learn a shared lower-dimensional representation by optimizing a joint loss function that favors common sparsity patterns across both types of prediction tasks. We adopt a recent kernelized formulation of convex multi-task feature learning, in which one alternates between learning the common features and learning task-specific classifier parameters on top of those features. In this way, our approach discovers any structure among the image descriptors that is relevant to both tasks, and allows the top-down semantics to restrict the hypothesis space of the ultimate object classifiers. We validate the approach on datasets of animals and outdoor scenes, and show significant improvements over traditional multi-class object classifiers and direct attribute prediction models.","Training,
Vectors,
Visualization,
Kernel,
Predictive models,
Animals,
Optimization"
Joint CFO and Channel Estimation for OFDM-Based Two-Way Relay Networks,"Joint estimation of the carrier frequency offset (CFO) and the channel is developed for a two-way relay network (TWRN) that comprises two source terminals and an amplify-and-forward (AF) relay. The terminals use orthogonal frequency division multiplexing (OFDM). New zero-padding (ZP) and cyclic-prefix (CP) transmission protocols, which maintain the carrier orthogonality and ensure low estimation and detection complexity, are proposed. Both protocols lead to the same estimation problem which can be solved by the nulling-based least square (LS) algorithm and perform identically when the block length is large. We present detailed performance analysis by proving the unbiasedness of the LS estimators at high signal-to-noise ratio (SNR) and by deriving the closed-form expression of the mean-square-error (MSE). Simulation results are provided to corroborate our findings.","OFDM,
Relays,
Channel estimation,
Estimation,
Protocols,
Joints,
Noise"
Solving Connectivity Problems Parameterized by Treewidth in Single Exponential Time,"For the vast majority of local problems on graphs of small tree width (where by local we mean that a solution can be verified by checking separately the neighbourhood of each vertex), standard dynamic programming techniques give ctw |V|O(1) time algorithms, where tw is the tree width of the input graph G = (V, E) and c is a constant. On the other hand, for problems with a global requirement (usually connectivity) the best-known algorithms were naive dynamic programming schemes running in at least twtw time. We breach this gap by introducing a technique we named Cut&Count that allows to produce ctw |V|O(1) time Monte Carlo algorithms for most connectivity-type problems, including Hamiltonian Path, Steiner Tree, Feedback Vertex Set and Connected Dominating Set. These results have numerous consequences in various fields, like parameterized complexity, exact and approximate algorithms on planar and H-minor-free graphs and exact algorithms on graphs of bounded degree. The constant c in our algorithms is in all cases small, and in several cases we are able to show that improving those constants would cause the Strong Exponential Time Hypothesis to fail. In contrast to the problems aiming to minimize the number of connected components that we solve using Cut&Count as mentioned above, we show that, assuming the Exponential Time Hypothesis, the aforementioned gap cannot be breached for some problems that aim to maximize the number of connected components like Cycle Packing.","Approximation algorithms,
Heuristic algorithms,
Dynamic programming,
Educational institutions,
Steiner trees,
Monte Carlo methods,
Polynomials"
Adaptively Learning Local Shape Statistics for Prostate Segmentation in Ultrasound,"Automatic segmentation of the prostate from 2-D transrectal ultrasound (TRUS) is a highly desired tool in many clinical applications. However, it is a very challenging task, especially for segmenting the base and apex of the prostate due to the large shape variations in those areas compared to the midgland, which leads many existing segmentation methods to fail. To address the problem, this paper presents a novel TRUS video segmentation algorithm using both global population-based and patient-specific local shape statistics as shape constraint. By adaptively learning shape statistics in a local neighborhood during the segmentation process, the algorithm can effectively capture the patient-specific shape statistics and quickly adapt to the local shape changes in the base and apex areas. The learned shape statistics is then used as the shape constraint in a deformable model for TRUS video segmentation. The proposed method can robustly segment the entire gland of the prostate with significantly improved performance in the base and apex regions, compared to other previously reported methods. Our method was evaluated using 19 video sequences obtained from different patients and the average mean absolute distance error was 1.65 0.47 mm.","Shape,
Image segmentation,
Training,
Video sequences,
Ultrasonic imaging,
Motion segmentation,
Probes"
A System for the Estimation of Single-Tree Stem Diameter and Volume Using Multireturn LIDAR Data,"Forest inventories are important tools for the management of forests. In this context, the estimation of the tree stem volume is a key issue. In this paper, we present a system for the estimation of forest stem diameter and volume at individual tree level from multireturn light detection and ranging (LIDAR) data. The proposed system is made up of a preprocessing module, a LIDAR segmentation algorithm (aimed at retrieving tree crowns), a variable extraction and selection procedure, and an estimation module based on support vector regression (SVR) (which is compared with a multiple linear regression technique). The variables derived from LIDAR data are computed from both the intensity and elevation channels of all available returns. Three different methods of variable selection are analyzed, and the sets of variables selected are used in the estimation phase. The stem volume is estimated with two methods: 1) direct estimation from the LIDAR variables and 2) combination of diameters and heights estimated from LIDAR variables with the species information derived from a classification map according to standard height/diameter relationships. Experimental results show that the system proposed is effective and provides high accuracies in both the stem volume and diameter estimations. Moreover, this paper provides useful indications on the effectiveness of SVR with LIDAR in forestry problems.","Estimation,
Laser radar,
Input variables,
Pixel,
Training,
Shape,
Data mining"
OpenSees: A Framework for Earthquake Engineering Simulation,"Structural engineers face many challenges in attempting to analyze and design structures that can withstand the devastating effects of earthquakes. The OpenSees software framework seeks to aid in this challenging task by letting earthquake engineers develop finite-element and finite-element-reliability applications for use in sequential, high-performance, and distributed processing environments.","Earthquakes,
Computational modeling,
Design engineering,
Structural engineering"
On the degrees of freedom achievable through interference alignment in a MIMO interference channel,"Consider a K-user flat fading MIMO interference channel where the k-th transmitter (or receiver) is equipped with Mk (respectively Nk) antennas. If a large number of statistically independent channel extensions are allowed either across time or frequency, the recent work suggests that the total achievable degrees of freedom (DoF) can be maximized via interference alignment, resulting in a total DoF that grows linearly with K even if Mk and Nk are bounded. In this work we consider the case where no channel extension is allowed, and establish a general condition that must be satisfied by any degrees of freedom tuple achievable through linear interference alignment. When Mk = M and Nk = N for all k, this condition implies that the total achievable DoF cannot grow linearly with K, and is in fact no more than M + N -1. If, in addition, all users have the same DoF d = 1, then this upper bound on the total DoF is actually tight for almost all MIMO interference channels.","MIMO,
Interference channels,
Polynomials,
Receiving antennas,
Transmitters"
On the design and analysis of fault tolerant NoC architecture using spare routers,"The aggressive advent in VLSI manufacturing technology has made dramatic impacts on the dependability of devices and interconnects. In the modern manycore system, mesh based Networks-on-Chip (NoC) is widely adopted as on chip communication infrastructure. It is critical to provide an effective fault tolerance scheme on mesh based NoC. A faulty router or broken link isolates a well functional processing element (PE). Also, a set of faulty routers form faulty regions which may break down the whole design. To address these issues, we propose an innovative router-level fault tolerance scheme with spare routers which is different from the traditional microarchitecture-level approach. The spare routers not only provide redundancies but also diversify connection paths between adjacent routers. To exploit these valuable resources on fault tolerant capabilities, two configuration algorithms are demonstrated. One is shift-and-replace-allocation (SARA) and the other is defect-awareness-path-allocation (DAPA) that takes advantage of path diversity in our architecture. The proposed design is transparent to any routing algorithm since the output topology is consistent to the original mesh. Experimental results show that our scheme has remarkable improvements on fault tolerant metrics including reliability, mean time to failure (MTTF), and yield. In addition, the performance of spare router increases with the growth of NoC size but the relative connection cost decreases at the same time. This rare and valuable characteristic makes our solution suitable for large scale NoC design.","Circuit faults,
Fault tolerant systems,
Redundancy,
Algorithm design and analysis,
Routing"
Incremental Learning From Stream Data,"Recent years have witnessed an incredibly increasing interest in the topic of incremental learning. Unlike conventional machine learning situations, data flow targeted by incremental learning becomes available continuously over time. Accordingly, it is desirable to be able to abandon the traditional assumption of the availability of representative training data during the training period to develop decision boundaries. Under scenarios of continuous data flow, the challenge is how to transform the vast amount of stream raw data into information and knowledge representation, and accumulate experience over time to support future decision-making process. In this paper, we propose a general adaptive incremental learning framework named ADAIN that is capable of learning from continuous raw data, accumulating experience over time, and using such knowledge to improve future learning and prediction performance. Detailed system level architecture and design strategies are presented in this paper. Simulation results over several real-world data sets are used to validate the effectiveness of this method.",
A Tunable Microstrip Bandpass Filter With Two Independently Adjustable Transmission Zeros,"In this letter, a tunable microstrip bandpass filter (BPF) with two independently adjustable transmission zeros (TZs) is reported. By introducing two microwave varactors to tune the TZs, the center frequency and the bandwidth of the BPF can be separately adjusted within a broad tuning range by varying the dc bias voltages applied to the varactors. Theoretical analysis and design approach are described. The experimental result of a demonstrative BPF shows that a less than 4 dB insertion loss, a relative bandwidth of 9% and a center frequency tunable from 1.4 to 2 GHz are obtained. The measured performance of the fabricated filter shows good agreement with the proposed theory.","Band pass filters,
Varactors,
Microwave filters,
Couplings,
Bandwidth,
Microwave communication"
Generalizing Common Tasks in Automated Skin Lesion Diagnosis,"We present a general model using supervised learning and MAP estimation that is capable of performing many common tasks in automated skin lesion diagnosis. We apply our model to segment skin lesions, detect occluding hair, and identify the dermoscopic structure pigment network. Quantitative results are presented for segmentation and hair detection and are competitive when compared to other specialized methods. Additionally, we leverage the probabilistic nature of the model to produce receiver operating characteristic curves, show compelling visualizations of pigment networks, and provide confidence intervals on segmentations.","Lesions,
Image segmentation,
Hair,
Pigments,
Pixel,
Supervised learning,
Training"
A Petri Net Approach to Analyzing Behavioral Compatibility and Similarity of Web Services,"Web services have become the technology of choice for service-oriented computing implementation, where Web services can be composed in response to some users' needs. It is critical to verify the compatibility of component Web services to ensure the correctness of the whole composition in which these components participate. Traditionally, two conditions need to be satisfied during the verification of compatibility: reachable termination and proper termination. Unfortunately, it is complex and time consuming to verify those two conditions. To reduce the complexity of this verification, we model Web services using colored Petri nets (PNs) so that a specific property of their structures is looked into, namely, well structuredness. We prove that only reachable termination needs to be satisfied when verifying behavioral compatibility among well-structured Web services. When a composition is declared as valid and in the case where one of its component Web services fails at run time, an alternative one with similar behavior needs to come into play as a substitute. Thus, it is important to develop effective approaches that permit one to analyze the similarity of Web services. Although many existing approaches utilize PNs to analyze behavioral compatibility, few of them explore further appropriate definitions of behavioral similarity and provide a user-friendly tool with automatic verification. In this paper, we introduce a formal definition of context-independent similarity and show that a Web service can be substituted by an alternative peer of similar behavior without intervening other Web services in the composition. Therefore, the cost of verifying service substitutability is largely reduced. We also provide an algorithm for the verification and implement it in a tool. Using the tool, the verification of behavioral similarity of Web services can be performed in an automatic way.","Web services,
Integrated circuits,
Joints,
Color,
Semantics,
System recovery,
Business"
Low-Power Wireless Micromanometer System for Acute and Chronic Bladder-Pressure Monitoring,"This letter describes the design, fabrication, and testing of a wireless bladder-pressure-sensing system for chronic, point-of-care applications, such as urodynamics or closed-loop neuromodulation. The system consists of a miniature implantable device and an external RF receiver and wireless battery charger. The implant is small enough to be cystoscopically implanted within the bladder wall, where it is securely held and shielded from the urine stream. The implant consists of a custom application-specific integrated circuit (ASIC), a pressure transducer, a rechargeable battery, and wireless telemetry and recharging antennas. The ASIC includes instrumentation, wireless transmission, and power-management circuitry, and on an average draws less than 9 μA from the 3.6-V battery. The battery charge can be wirelessly replenished with daily 6-h recharge periods that can occur during the periods of sleep. Acute in vivo evaluation of the pressure-sensing system in canine models has demonstrated that the system can accurately capture lumen pressure from a submucosal implant location.","Bladder,
Implants,
Wireless communication,
Wireless sensor networks,
Telemetry,
Application specific integrated circuits,
Batteries"
Saturated Power Amplifier Optimized for Efficiency Using Self-Generated Harmonic Current and Voltage,"A saturated power amplifier (PA) optimized for efficiency is described. As a PA is driven into saturated operation, the current source of the device generates a large third harmonic current, which creates a quasi-rectangular current waveform. The large nonlinear output capacitor of the transistor generates a second harmonic voltage with a very small third harmonic component. The second harmonic voltage is in-phase with the fundamental voltage, making a half-sine wave voltage waveform with voltage peaking. These waveforms are similar to those of a class F-1 . The fundamental load at the intrinsic device is resistive with the output capacitance tuned out, which is identical to the class F-1 case. However, the required harmonic impedances are just larger than the impedance levels of the output capacitance for both the second and third harmonics. Therefore, the circuit topology is similar to that of a class E amplifier, which is very simple. The PA implemented using a GaN HEMT delivers the expected good performance using the simple circuit topology.","Harmonic analysis,
Impedance,
Load modeling,
Power system harmonics,
Capacitance,
Capacitors,
Computer aided software engineering"
Quasi-Static Modeling of Human Limb for Intra-Body Communications With Experiments,"In recent years, the increasing number of wearable devices on human has been witnessed as a trend. These devices can serve for many purposes: personal entertainment, communication, emergency mission, health care supervision, delivery, etc. Sharing information among the devices scattered across the human body requires a body area network (BAN) and body sensor network (BSN). However, implementation of the BAN/BSN with the conventional wireless technologies cannot give optimal result. It is mainly because the high requirements of light weight, miniature, energy efficiency, security, and less electromagnetic interference greatly limit the resources available for the communication modules. The newly developed intra-body communication (IBC) can alleviate most of the mentioned problems. This technique, which employs the human body as a communication channel, could be an innovative networking method for sensors and devices on the human body. In order to encourage the research and development of the IBC, the authors are favorable to lay a better and more formal theoretical foundation on IBC. They propose a multilayer mathematical model using volume conductor theory for galvanic coupling IBC on a human limb with consideration on the inhomogeneous properties of human tissue. By introducing and checking with quasi-static approximation criteria, Maxwell's equations are decoupled and capacitance effect is included to the governing equation for further improvement. Finally, the accuracy and potential of the model are examined from both in vitro and in vivo experimental results.","Mathematical model,
Body area networks,
Electrodes,
Phantoms,
Frequency measurement,
Medical services"
A 2-DOF MEMS Ultrasonic Energy Harvester,"This paper reports a novel ultrasonic-based wireless power transmission technique that has the potential to drive implantable biosensors. Compared with commonly used radio-frequency (RF) radiation methods, the ultrasonic power transmission is relatively safe for the human body and does not cause electronic interference with other electronic circuits. To extract ambient kinetic energy with arbitrary in-plane motion directions, a novel 2-D MEMS power harvester has been designed with resonance frequencies of 38520 and 38725 Hz. Frequency-response characterization results verify that the device can extract energy from the directions of X, Y, and diagonals. Working in the diagonal direction, the device has a bandwidth of 302 Hz, which is twice wider than a comparable 1-D resonator device. A 1- storage capacitor is charged up from 0.51 to 0.95 V in 15 s, when the harvester is driven by an ultrasonic transducer at a distance of 0.5 cm in the X-direction, and is biased by 60 Vdc, indicating the energy harvesting capability of 21.4 nW in the X-direction. When excited along the Y-axis, the harvester has an energy-harvesting capacity of 22.7 nW. The harvester was modeled and simulated using an equivalent electrical circuit model in Saber, and the simulation results showed good agreement with the experimental results. The ultrasonic energy harvesting was also investigated using a 1-D piezoelectric micro-cantilever.","Capacitors,
Acoustics,
Resonant frequency,
Integrated circuit modeling,
Micromechanical devices,
Energy harvesting,
Vibrations"
Synchronization of Continuous Dynamical Networks With Discrete-Time Communications,"In this paper, synchronization of continuous dynamical networks with discrete-time communications is studied. Though the dynamical behavior of each node is continuous-time, the communications between every two different nodes are discrete-time, i.e., they are active only at some discrete time instants. Moreover, the communication intervals between every two communication instants can be uncertain and variable. By choosing a piecewise Lyapunov-Krasovskii functional to govern the characteristics of the discrete communication instants and by utilizing a convex combination technique, a synchronization criterion is derived in terms of linear matrix inequalities with an upper bound for the communication intervals obtained. The results extend and improve upon earlier work. Simulation results show the effectiveness of the proposed communication scheme. Some relationships between the allowable upper bound of communication intervals and the coupling strength of the network are illustrated through simulations on a fully connected network, a star-like network, and a nearest neighbor network.","Synchronization,
Couplings,
Delay,
Upper bound,
Chaotic communication,
Linear matrix inequalities"
Investigation on Capacitor Voltage Regulation in Cascaded H-Bridge Multilevel Converters With Fundamental Frequency Switching,"Multilevel power electronic converters have gained popularity in high-power applications due to their lower switch voltage stress and modularity. Cascaded H-bridge converters are a promising breed of multilevel converters which generally require several separate dc voltage sources. By utilizing the redundant switching states, it is possible to replace the separate dc voltage sources with capacitors and keep only the one with the highest voltage level. Redundancy in the charge and discharge modes of the capacitors is assumed to be adequate for their voltage regulation. However, the effects of the output current of the converter as well as the time duration of the redundant switching states have been neglected. In this paper, the impacts of the connected load to the cascaded H-bridge converter as well as the switching angles on the voltage regulation of the capacitors are studied. This paper proves that voltage regulation is only attainable in a much limited operating conditions that it was originally reported. In addition, based on the analysis of the converter, a simplified formula is found which can be used to find those modulation indices that regulate the voltage of the capacitor. This formula can be used in harmonic minimization problems while capacitor voltage regulation is ensured. Simulation and laboratory results are provided to confirm the analysis.",
Retroactivity Attenuation in Bio-Molecular Systems Based on Timescale Separation,"As with several engineering systems, bio-molecular systems display impedance-like effects at interconnections, called retroactivity. In this paper, we propose a mechanism that exploits the natural timescale separation present in bio-molecular systems to attenuate retroactivity. Retroactivity enters the dynamics of a bio-molecular system as a state dependent disturbance multiplied by gains that can be very large. By virtue of the system structure, retroactivity can be arbitrarily attenuated by internal system gains even when these are much smaller than the gains multiplying retroactivity terms. This result is obtained by employing a suitable change of coordinates and a nested application of the singular perturbation theorem on the finite time interval. As an application example, we show that two modules extracted from natural signal transduction pathways have a remarkable capability of attenuating retroactivity, which is certainly desirable in any (engineered or natural) signal transmission system.","Attenuation,
Equations,
Proteins,
Biological system modeling,
Modeling,
Impedance,
Systems biology"
Through-Silicon Via Planning in 3-D Floorplanning,"In this paper, we will study floorplanning in 3-D integrated circuits (3D-ICs). Although literature is abundant on 3D-IC floorplanning, none of them consider the areas and positions of signal through-silicon vias (TSVs). In previous research, signal TSVs are viewed as points during the floorplanning stage. Ignoring the areas, positions and connections of signal TSVs, previous research estimates wirelength by measuring the half-perimeter wirelength of pins in a net only. Experimental results reveal that 29.7% of nets possess signal TSVs that cannot be put into the white space within the bounding boxes of pins. Moreover, the total wirelength is underestimated by 26.8% without considering the positions of signal TSVs. The considerable error in wirelength estimation severely degrades the optimality of the floorplan result. Therefore, in this paper, we will propose a two-stage 3-D fixed-outline floorplaning algorithm. Stage one simultaneously plans hard macros and TSV-blocks for wirelength reduction. Stage two improves the wirelength by reassigning signal TSVs. Experimental results show that stage one outperforms a post-processing TSV planning algorithm in successful rate by 57%. Compared to the post-processing TSV planning algorithm, the average wirelength of our result is shorter by 22.3%. In addition, stage two further reduces the wirelength by 3.45% without any area overhead.","Through-silicon vias,
Three-dimensional integrated circuits,
Stacking,
Routing,
White spaces,
Pins,
Degradation,
Area measurement,
Position measurement,
Integrated circuit measurements"
Supervisor Optimization for Deadlock Resolution in Automated Manufacturing Systems With Petri Nets,"For automated manufacturing systems (AMSs), deadlock resolution in terms of Petri nets remains an attractive topic to which many approaches are dedicated. However, few of them can quantitatively optimize certain indices during their supervisor synthesis process. This causes unnecessary control limitations and often leads to high implementation cost. In the framework of Petri nets, this paper proposes a method to synthesize a cost-effective supervisor with the aid of a set of mathematical programming formulations. Along the same vein, we also show some results by investigating timed Petri nets, which can be utilized to make a good tradeoff between implementation cost and system cycle time. Examples are used to validate the effectiveness of our result.","Petri nets,
Mathematical programming,
Manufacturing systems,
Optimization,
Supervisory control"
Power System Stabilization Using Adaptive Neural Network-Based Dynamic Surface Control,"In this paper, the power system with an excitation controller is represented as a class of large-scale, uncertain, interconnected nonlinear continuous-time system in strict-feedback form. Subsequently, dynamic surface control (DSC)-based adaptive neural network (NN) controller is designed to overcome the repeated differentiation of the control input that is observed in the conventional backstepping approach. The NNs are utilized to approximate the unknown subsystem and the interconnection dynamics. By using novel online NN weight update laws with quadratic error terms, the closed-loop signals are shown to be locally asymptotically stable via Lyapunov stability analysis, even in the presence of NN approximation errors in contrast with other NN techniques where a bounded stability is normally assured. Simulation results on the IEEE 14-bus power system with generator excitation control are provided to show the effectiveness of the approach in damping oscillations that occur after disturbances are removed. The end result is a nonlinear decentralized adaptive state-feedback excitation controller for damping power systems oscillations in the presence of uncertain interconnection terms.","Power system dynamics,
Generators,
Artificial neural networks,
Mathematical model,
Power system stability,
Asymptotic stability"
Exploring Reliable Strategies for Defending Power Systems Against Targeted Attacks,"Recently, game theory has been used to design optimized strategies for defending an electric power system against deliberate attacks. In this paper, we extend the current static model to a more generalized framework which includes several interaction models between defenders and attackers. A new criterion of reliable strategies for defending power systems has been derived. In addition, two allocation algorithms have been developed to seek reliable strategies for two types of defense tasks. The new criterion and algorithms are complementary to current security criteria and can provide useful information for decision-makers to protect their power systems against possible targeted attacks. Numerical simulation examples using the proposed methods are given as well.","Games,
Power system reliability,
Power system dynamics,
Terrorism,
Resource management,
Programming"
Cooperative multi-residence demand response scheduling,"This paper is concerned with scheduling of demand response among different residences and a utility company. The utility company has a cost function representing the cost of providing energy to end-users, and this cost can be varying across the scheduling horizon. Each end-user has a “must-run” load, and two types of adjustable loads. The first type must consume a specified total amount of energy over the scheduling horizon, but the consumption can be adjusted across different slots. The second type of load has adjustable power consumption without a total energy requirement, but operation of the load at reduced power results in dissatisfaction of the end-user. The problem amounts to minimizing the total cost electricity plus the total user dissatisfaction (social welfare), subject to the individual load consumption constraints. The problem is convex and can be solved by a distributed subgradient method. The utility company and the end-users exchange Lagrange multipliers-interpreted as pricing signals-and hourly consumption data through the Advanced Metering Infrastructure, in order to converge to the optimal amount of electricity production and the optimal power consumption schedule.","Power demand,
Companies,
Electricity,
Optimal scheduling,
Minimization,
Load management,
Scheduling"
SMALL: A Strategy-proof Mechanism for radio spectrum allocation,"With the growing deployment of wireless communication technologies, radio spectrum is becoming a scarce resource. Thus mechanisms to efficiently allocate the available spectrum are of interest. In this paper, we model the radio spectrum allocation problem as a sealed-bid reserve auction, and propose SMALL, which is a Strategy-proof Mechanism for radio spectrum ALLocation. Furthermore, we extend SMALL to adapt to multi-radio spectrum buyers, which can bid for more than one radio.","radio spectrum management,
channel allocation"
Systematic Design of RSA Processors Based on High-Radix Montgomery Multipliers,"This paper presents a systematic design approach to provide the optimized Rivest-Shamir-Adleman (RSA) processors based on high-radix Montgomery multipliers satisfying various user requirements, such as circuit area, operating time, and resistance against side-channel attacks. In order to involve the tradeoff between the performance and the resistance, we apply four types of exponentiation algorithms: two variants of the binary method with/without Chinese Remainder Theorem (CRT). We also introduces three multiplier-based datapath-architectures using different intermediate data forms: 1) single form, 2) semi carry-save form, and 3) carry-save form, and combined them with a wide variety of arithmetic components. Their radices are parameterized from 28 to 2128. A total of 242 datapaths for 1024-bit RSA processors were obtained for each radix. The potential of the proposed approach is demonstrated through an experimental synthesis of all possible processors with a 90-nm CMOS standard cell library. As a result, the smallest design of 861 gates with 118.47 ms/RSA to the fastest design of 0.67 ms/RSA at 153\thinspace 862 gates were obtained. In addition, the use of the CRT technique reduced the RSA operation time of the fastest design to 0.24 ms. Even if we employed the exponentiation algorithm resistant to typical side-channel attacks, the fastest design can perform the RSA operation in less than 1.0 ms.","Process design,
Cryptography,
Computer architecture,
Hardware,
Design optimization,
Circuits,
Arithmetic,
Cathode ray tubes,
CMOS process,
Libraries"
A new benchmark for stereo-based pedestrian detection,"Pedestrian detection is a rapidly evolving area in the intelligent vehicles domain. Stereo vision is an attractive sensor for this purpose. But unlike for monocular vision, there are no realistic, large scale benchmarks available for stereo-based pedestrian detection, to provide a common point of reference for evaluation. This paper introduces the Daimler Stereo-Vision Pedestrian Detection benchmark, which consists of several thousands of pedestrians in the training set, and a 27-min test drive through urban environment and associated vehicle data. The data, including ground truth, is made publicly available for non-commercial purposes. The paper furthermore quantifies the benefit of stereo vision for ROI generation and localization; at equal detection rates, false positives are reduced by a factor of 4-5 with stereo over mono, using the same HOG/linSVM classification component.","Vehicles,
Training,
Benchmark testing,
Three dimensional displays,
Shape,
Detectors"
Power Control and Beamforming for Femtocells in the Presence of Channel Uncertainty,"Femtocells that are installed in existing macrocellular networks form a two-tiered heterogeneous network, yielding an interference problem between the two layers. How we can mitigate the interference is of great concern for the deployment of femtocells. When the femto base station has perfect channel information, it can mitigate the interference through transmit power control and beamforming. However, it may not be feasible to get perfect channel information due to unavoidable impairments such as channel estimation, quantization, and feedback delay. In the presence of such channel uncertainty, we consider the combined use of transmit power control and beamforming for femtocells in heterogeneous wireless communication environments. By analyzing the effect of channel uncertainty parameters on the performance, we determine the transmit power level to provide the desired signal-to-interference-plus-noise ratio (SINR) of the indoor cell edge femtouser and the beam weight to maximize the output SINR of the macrousers and femtousers by mitigating interference in a collaborate manner. Finally, simulation results show that the proposed scheme is quite effective in the presence of channel uncertainty.","Interference,
Array signal processing,
Channel estimation,
Signal to noise ratio,
Femtocells,
Uncertainty,
Power control"
The impact of Electric Vehicle battery charging on distribution transformers,"Electric Vehicles (EV) and Plug-in Hybrid Electric Vehicles (PHEV) have a limited share of the current market. However, it is widely expected that the situation will change in the near future and the penetration of battery-operated vehicles will increase significantly. This paper addresses the impact of the mass operation and electricity consumption of EVs and PHEVs on the distribution utility and more specifically on distribution transformers. The charging effect of various types of EV batteries on the life of distribution transformers is analyzed. A typical annual base-load on the distribution transformer is considered and compared with different battery charging load scenarios. Simulation results show that distributing the load profile of the battery charging helps to decrease the distribution transformer loss of life. In addition, power management of the EV and PHEV battery charging and the interface with the Smart-Grid is explained.","Batteries,
Power transformer insulation,
Oil insulation,
FAA,
Vehicles,
Aging,
Load modeling"
Bounding the error of path loss models,"In this paper we analyze the efficacy of basic path loss models at predicting median path loss in urban environments. We attempt to bound the practical error of these models and look at how they may hinder practical wireless applications, and in particular dynamic spectrum access networks. This analysis is made using a large set of measurements from production networks in two US cities. We are able to show quantitatively what many experienced radio engineers understand: these models perform poorly at predicting path loss in even relatively simple outdoor environments and are of little practical use aside from making crude estimates of coverage in the least demanding applications. As a solution, we advocate a renewed focus on measurement-based, adaptive path loss models built on appropriate statistical methods.","Predictive models,
Loss measurement,
Mathematical model,
Antenna measurements,
Analytical models,
Mobile communication,
Wireless communication"
Distributed Scalar Quantization for Computing: High-Resolution Analysis and Extensions,"Communication of quantized information is frequently followed by a computation. We consider situations of distributed functional scalar quantization: distributed scalar quantization of (possibly correlated) sources followed by centralized computation of a function. Under smoothness conditions on the sources and function, companding scalar quantizer designs are developed to minimize mean-squared error (MSE) of the computed function as the quantizer resolution is allowed to grow. Striking improvements over quantizers designed without consideration of the function are possible and are larger in the entropy-constrained setting than in the fixed-rate setting. As extensions to the basic analysis, we characterize a large class of functions for which regular quantization suffices, consider certain functions for which asymptotic optimality is achieved without arbitrarily fine quantization, and allow limited collaboration between source encoders. In the entropy-constrained setting, a single bit per sample communicated between encoders can have an arbitrarily large effect on functional distortion. In contrast, such communication has very little effect in the fixed-rate setting.","Quantization,
Approximation methods,
Source coding,
Distortion measurement,
Entropy,
Density functional theory"
Matrix Codes for Reliable and Cost Efficient Memory Chips,"This paper presents a method to protect memories against multiple bit upsets and to improve manufacturing yield. The proposed method, called a Matrix code, combines Hamming and Parity codes to assure the improvement of reliability and yield of the memory chips in the presence of high defects and multiple bit-upsets. The method is evaluated using fault injection experiments. The results are compared to well-known techniques such as Reed-Muller and Hamming codes. The proposed technique performs better than the Hamming codes and achieves comparable performance with Reed-Muller codes with very favorable implementation gains such as 25% reduction in area and power consumption. It also achieves reliability increase by more than 50% in some cases. Further, the yield benefits provided by the proposed method, measured by the yield improvements per cost metric, is up to 300% better than the ones provided by Reed-Muller codes.","Costs,
Protection,
Integrated circuit yield,
Error correction codes,
Circuit faults,
Energy consumption,
Integrated circuit reliability,
CMOS technology,
Integrated circuit technology,
Single event transient"
Sparse Brain Network Recovery Under Compressed Sensing,"Partial correlation is a useful connectivity measure for brain networks, especially, when it is needed to remove the confounding effects in highly correlated networks. Since it is difficult to estimate the exact partial correlation under the small-n large-p situation, a sparseness constraint is generally introduced. In this paper, we consider the sparse linear regression model with a l1-norm penalty, also known as the least absolute shrinkage and selection operator (LASSO), for estimating sparse brain connectivity. LASSO is a well-known decoding algorithm in the compressed sensing (CS). The CS theory states that LASSO can reconstruct the exact sparse signal even from a small set of noisy measurements. We briefly show that the penalized linear regression for partial correlation estimation is related to CS. It opens a new possibility that the proposed framework can be used for a sparse brain network recovery. As an illustration, we construct sparse brain networks of 97 regions of interest (ROIs) obtained from FDG-PET imaging data for the autism spectrum disorder (ASD) children and the pediatric control (PedCon) subjects. As validation, we check the network reproducibilities by leave-one-out cross validation and compare the clustered structures derived from the brain networks of ASD and PedCon.",
Security aspects of the in-vehicle network in the connected car,"In this paper, we briefly survey the research with respect to the security of the connected car, and in particular its in-vehicle network. The aim is to highlight the current state of the research; which are the problems found, and what solutions have been suggested. We have structured our investigation by categorizing the research into the following five categories: problems in the in-vehicle network, architectural security features, intrusion detection systems, honeypots, and threats and attacks. We conclude that even though quite some effort has already been expended in the area, most of it has been directed towards problem definition and not so much towards security solutions. We also highlight a few areas that we believe are of immediate concern.","Vehicles,
Protocols,
Authentication,
Logic gates,
Taxonomy,
Intrusion detection"
A Simple Tactile Probe for Surface Identification by Mobile Robots,"This paper describes a tactile probe designed for surface identification in a context of all-terrain low-velocity mobile robotics. The proposed tactile probe is made of a small metallic rod with a single-axis accelerometer attached near its tip. Surface identification is based on analyzing acceleration patterns induced at the tip of this mechanically robust tactile probe, while it is passively dragged along a surface. A training dataset was collected over ten different indoor and outdoor surfaces. Classification results for an artificial neural network were positive, with an 89.9% and 94.6% success rate for 1- and 4-s time windows of data, respectively. We also demonstrated that the same tactile probe can be used for unsupervised learning of terrains. For 1-s time windows of data, the classification success rate was only reduced to 74.1%. Finally, a blind mobile robot, performing real-time classification of surfaces, demonstrated the feasibility of this tactile probe as a guidance mechanism.","Probes,
Robot sensing systems,
Accelerometers,
Transducers,
Mobile robots"
Grasping with application to an autonomous checkout robot,"In this paper, we present a novel grasp selection algorithm to enable a robot with a two-fingered end-effector to autonomously grasp unknown objects. Our approach requires as input only the raw depth data obtained from a single frame of a 3D sensor. Additionally, our approach uses no explicit models of the objects and does not require a training phase. We use the grasping capability to demonstrate the application of a robot as an autonomous checkout clerk. To perform this task, the robot must identify how to grasp an object, locate the barcode on the object and read the numeric code. We evaluate our grasping algorithm in experiments where the robot was required to autonomously grasp unknown objects. The robot achieved a success of 91.6%in grasping novel objects. We performed two sets of experiments to evaluate the checkout robot application. In the first set, the objects were placed in many orientations in front of the robot one at a time. In the second set, the objects were placed several at a time with varying amounts of clutter. The robot was able to autonomously grasp and scan the objects in 49/50 of the single-object trials and 46/50 of the cluttered trials.",
Pixel Unmixing in Hyperspectral Data by Means of Neural Networks,"Neural networks (NNs) are recognized as very effective techniques when facing complex retrieval tasks in remote sensing. In this paper, the potential of NNs has been applied in solving the unmixing problem in hyperspectral data. In its complete form, the processing scheme uses an NN architecture consisting of two stages: the first stage reduces the dimension of the input vector, while the second stage performs the mapping from the reduced input vector to the abundance percentages. The dimensionality reduction is performed by the so-called autoassociative NNs, which yield a nonlinear principal component analysis of the data. The evaluation of the whole performance is carried out for different sets of experimental data. The first one is provided by the Airborne Hyperspectral Scanner. The second set consists of images from the Compact High-Resolution Imaging Spectrometer on board the Project for On-Board Autonomy satellite, and it includes multiangle and multitemporal acquisitions. The third set is represented by Airborne Visible/InfraRed Imaging Spectrometer measurements. A quantitative performance analysis has been carried out in terms of effectiveness in the dimensionality reduction phase and in terms of the accuracy in the final estimation. The results obtained, when compared with those produced by appropriate benchmark techniques, show the advantages of this approach.","Artificial neural networks,
Pixel,
Training,
Hyperspectral imaging,
Principal component analysis,
Topology"
An End-to-End Virtual Path Construction System for Stable Live Video Streaming over Heterogeneous Wireless Networks,"In this paper, we propose an effective end-to-end virtual path construction system, which exploits path diversity over heterogeneous wireless networks. The goal of the proposed system is to provide a high quality live video streaming service over heterogeneous wireless networks. First, we propose a packetization-aware fountain code to integrate multiple physical paths efficiently and increase the fountain decoding probability over wireless packet switching networks. Second, we present a simple but effective physical path selection algorithm to maximize the effective video encoding rate while satisfying delay and fountain decoding failure rate constraints. The proposed system is fully implemented in software and examined over real WLAN and HSDPA networks.","Encoding,
Streaming media,
Wireless networks,
Decoding,
Delay,
Artificial neural networks"
Modeling and understanding TCP incast in data center networks,"Recently, TCP incast problem attracts increasing attention since the receiver suffers drastic goodput drop when it simultaneously strips data over multiple servers. Lots of attempts have been made to address the problem through experiments and simulations. However, to the best of our knowledge, few solutions can solve it fundamentally at low cost. In this paper, a goodput model of TCP incast is built to understand why goodput collapse occurs. We conclude that TCP incast goodput deterioration is mainly caused by two types of timeouts, one happens at the tail of a data block and dominates the goodput when the number of senders is small, while the other one at the head of a data block and governs the goodput when the number of senders is large. The proposed model describes the causes of these two types of timeouts which are related to the incast communication pattern, block size, bottleneck buffer and so on. We validate the proposed model by comparing with simulation data, finding that it can well characterize the features of TCP incast. We also discuss the impact of most parameters on the goodput of TCP incast.",US Department of Defense
Self-Controlled Writing and Erasing in a Memristor Crossbar Memory,"The memristor device technology has created waves in the research community and led to the consideration of using the device in multiple avenues. The most likely candidate for early adoption is the nonvolatile memory due to the small cell size (increased scaling potential), increased density as compared to flash, and ability to stack these devices in a crossbar structure. This paper analyzes the feasibility of a memristor memory and introduces an adaptive read, write, and erase method that may be used to realize a more resilient memory system in the face of low yield in the nanotechnology regime. The proposed method is evaluated in simulation program with integrated circuit emphasis (SPICE) and a hand analysis model is extracted to help explain the sources of power and energy consumption. Finally, the power metrics are compared to flash memory technology, and the memristor memory is shown to have an energy per bit consumption about one-tenth that of flash when programming, comparable to flash when erasing, and about one-fourth of flash when reading.","Memristors,
Resistance,
Random access memory,
Adaptation models"
Model Construction of Boolean Network via Observed Data,"In this paper, a set of data is assumed to be obtained from an experiment that satisfies a Boolean dynamic process. For instance, the dataset can be obtained from the diagnosis of describing the diffusion process of cancer cells. With the observed datasets, several methods to construct the dynamic models for such Boolean networks are proposed. Instead of building the logical dynamics of a Boolean network directly, its algebraic form is constructed first and then is converted back to the logical form. Firstly, a general construction technique is proposed. To reduce the size of required data, the model with the known network graph is considered. Motivated by this, the least in-degree model is constructed that can reduce the size of required data set tremendously. Next, the uniform network is investigated. The number of required data points for identification of such networks is independent of the size of the network. Finally, some principles are proposed for dealing with data with errors.","Data models,
Mathematical model,
Manganese,
Heuristic algorithms,
Equations,
Inference algorithms,
Matrix converters"
Distributed Access Control with Privacy Support in Wireless Sensor Networks,"A distributed access control module in wireless sensor networks (WSNs) allows the network to authorize and grant user access privileges for in-network data access. Prior research mainly focuses on designing such access control modules for WSNs, but little attention has been paid to protect user's identity privacy when a user is verified by the network for data accesses. Often, a user does not want the WSN to associate his identity to the data he requests. In this paper, we present the design, implementation, and evaluation of a novel approach, Priccess, to ensure distributed privacy-preserving access control. In Priccess, users who have similar access privileges are organized into the same group by the network owner. A network user signs a query command on behalf of his group and then sends the signed query to the sensor nodes of his interest. The signature can be verified by its recipient as coming from someone authorized without exposing the actual signer. In addition to the theoretical analysis that demonstrates the security properties of Priccess, this paper also reports the experimental results of Priccess in a network of Imote2 motes, which show the efficiency of Priccess in practice.","Access control,
Wireless sensor networks,
Public key,
Protocols,
Data privacy"
Support Vector Machine Active Learning Through Significance Space Construction,"Active learning is showing to be a useful approach to improve the efficiency of the classification process for remote sensing images. This letter introduces a new active learning strategy specifically developed for support vector machine (SVM) classification. It relies on the idea of the following: 1) reformulating the original classification problem into a new problem where it is needed to discriminate between significant and nonsignificant samples, according to a concept of significance which is proper to the SVM theory; and 2) constructing the corresponding significance space to suitably guide the selection of the samples potentially useful to better deal with the original classification problem. Experiments were conducted on both multi- and hyperspectral images. Results show interesting advantages of the proposed method in terms of convergence speed, stability, and sparseness.","Training,
Support vector machines,
Accuracy,
Learning systems,
Machine learning,
Hyperspectral imaging"
A Multi-Gesture Interaction System Using a 3-D Iris Disk Model for Gaze Estimation and an Active Appearance Model for 3-D Hand Pointing,"In this paper, we present a vision-based human-computer interaction system, which integrates control components using multiple gestures, including eye gaze, head pose, hand pointing, and mouth motions. To track head, eye, and mouth movements, we present a two-camera system that detects the face from a fixed, wide-angle camera, estimates a rough location for the eye region using an eye detector based on topographic features, and directs another active pan-tilt-zoom camera to focus in on this eye region. We also propose a novel eye gaze estimation approach for point-of-regard (POR) tracking on a viewing screen. To allow for greater head pose freedom, we developed a new calibration approach to find the 3-D eyeball location, eyeball radius, and fovea position. Moreover, in order to get the optical axis, we create a 3-D iris disk by mapping both the iris center and iris contour points to the eyeball sphere. We then rotate the fovea accordingly and compute the final, visual axis gaze direction. This part of the system permits natural, non-intrusive, pose-invariant POR estimation from a distance without resorting to infrared or complex hardware setups. We also propose and integrate a two-camera hand pointing estimation algorithm for hand gesture tracking in 3-D from a distance. The algorithms of gaze pointing and hand finger pointing are evaluated individually, and the feasibility of the entire system is validated through two interactive information visualization applications.","Iris,
Three dimensional displays,
Cameras,
Estimation,
Calibration,
Face,
Adaptive optics"
Efficient core decomposition in massive networks,"The k-core of a graph is the largest subgraph in which every vertex is connected to at least k other vertices within the subgraph. Core decomposition finds the k-core of the graph for every possible k. Past studies have shown important applications of core decomposition such as in the study of the properties of large networks (e.g., sustainability, connectivity, centrality, etc.), for solving NP-hard problems efficiently in real networks (e.g., maximum clique finding, densest subgraph approximation, etc.), and for large-scale network fingerprinting and visualization. The k-core is a well accepted concept partly because there exists a simple and efficient algorithm for core decomposition, by recursively removing the lowest degree vertices and their incident edges. However, this algorithm requires random access to the graph and hence assumes the entire graph can be kept in main memory. Nevertheless, real-world networks such as online social networks have become exceedingly large in recent years and still keep growing at a steady rate. In this paper, we propose the first external-memory algorithm for core decomposition in massive graphs. When the memory is large enough to hold the graph, our algorithm achieves comparable performance as the in-memory algorithm. When the graph is too large to be kept in the memory, our algorithm requires only O(kmax) scans of the graph, where kmax is the largest core number of the graph. We demonstrate the efficiency of our algorithm on real networks with up to 52.9 million vertices and 1.65 billion edges.","Upper bound,
Partitioning algorithms,
Algorithm design and analysis,
Estimation,
Approximation algorithms,
Memory management,
Clustering algorithms"
Optimal Periodic Sensor Scheduling With Limited Resources,"In this technical note, we consider the problem of periodic sensor scheduling with limited resources. Two sensors are used to measure the state of a discrete-time linear process. We assume that each sensor has a maximum duty cycle and at most one sensor can communicate with a remote estimator at each time step due to the limited communication bandwidth. When a sensor is scheduled to send data, it sends the most recent D measurement data to the estimator. Upon receiving the measurement data from the sensors, the estimator computes the optimal estimate of the state of the process. We first present a necessary condition for a periodic sensor schedule to be optimal. Based on this necessary condition, we construct an optimal periodic schedule that minimizes the estimation error at the estimator and at the same time satisfies the energy and communication bandwidth constraints. Examples are provided throughout the technical note to demonstrate the results developed.","Schedules,
Optimal scheduling,
Estimation error,
Bandwidth,
Tin,
Equations"
Hybrid Genetic and Variational Expectation-Maximization Algorithm for Gaussian-Mixture-Model-Based Brain MR Image Segmentation,"The expectation-maximization (EM) algorithm has been widely applied to the estimation of Gaussian mixture model (GMM) in brain MR image segmentation. However, the EM algorithm is deterministic and intrinsically prone to overfitting the training data and being trapped in local optima. In this paper, we propose a hybrid genetic and variational EM (GA-VEM) algorithm for brain MR image segmentation. In this approach, the VEM algorithm is performed to estimate the GMM, and the GA is employed to initialize the hyperparameters of the conjugate prior distributions of GMM parameters involved in the VEM algorithm. Since GA has the potential to achieve global optimization and VEM can steadily avoid overfitting, the hybrid GA-VEM algorithm is capable of overcoming the drawbacks of traditional EM-based methods. We compared our approach to the EM-based, VEM-based, and GA-EM based segmentation algorithms, and the segmentation routines used in the statistical parametric mapping package and FMRIB Software Library in 20 low-resolution and 17 high-resolution brain MR studies. Our results show that the proposed approach can improve substantially the performance of brain MR image segmentation.","Image segmentation,
Gallium,
Image resolution,
Genetic algorithms,
Information technology,
Estimation,
Brain modeling"
Labeling of Lumbar Discs Using Both Pixel- and Object-Level Features With a Two-Level Probabilistic Model,"Backbone anatomical structure detection and labeling is a necessary step for various analysis tasks of the vertebral column. Appearance, shape and geometry measurements are necessary for abnormality detection locally at each disc and vertebrae (such as herniation) as well as globally for the whole spine (such as spinal scoliosis). We propose a two-level probabilistic model for the localization of discs from clinical magnetic resonance imaging (MRI) data that captures both pixel- and object-level features. Using a Gibbs distribution, we model appearance and spatial information at the pixel level, and at the object level, we model the spatial distribution of the discs and the relative distances between them. We use generalized expectation-maximization for optimization, which achieves efficient convergence of disc labels. Our two-level model allows the assumption of conditional independence at the pixel-level to enhance efficiency while maintaining robustness. We use a dataset that contains 105 MRI clinical normal and abnormal cases for the lumbar area. We thoroughly test our model and achieve encouraging results on normal and abnormal cases.","Labeling,
Spine,
Structural discs,
Electrical capacitance tomography,
Anatomical structure,
Magnetic resonance imaging,
Shape measurement,
Permission,
Geometry,
Convergence"
Optimal Cooperative Sensing Scheduling for energy-efficient Cognitive Radio Networks,"Due to the problem of spectrum scarcity and large energy consumption in wireless communications, designing energy-efficient Cognitive Radio Networks (CRNs) becomes important and necessary. In this paper, we consider the problem of optimal Cooperative Sensing Scheduling (CSS) and parameter design to achieve energy efficiency in CRNs using the framework of Partially Observable Markov Decision Process (POMDP). In particular, we consider the CSS problem for a CRN with M Secondary Users (SUs) and N primary channels to determine how many SUs should be assigned to sense each channel in order to maximize the objective function that is related to energy efficiency. By assigning more SUs to sense one channel, higher sensing accuracy can be gained; however, by spreading out the SUs to sense more channels, spectrum opportunities can be better exploited. The CSS problem is formulated as a combinatorial optimization problem. While such problem is generally hard and can only be solved by numerical methods with high computation complexity, in this paper we provide a detailed analysis and the analytical results provide useful and interesting insights. The optimality of the myopic CSS is proved for the case of two channels, and it is also conjectured for the general case. We also study the tradeoff between the sensing and transmission durations. In addition, the structure of the optimal sensing time that maximizes the energy efficiency objective is also analyzed, the condition for the optimality of the myopic sensing time is obtained, and the performance upper bound of the myopic policy is derived. Based on the numerical results, we show that by carefully tuning a punishment parameter, better energy efficiency can be achieved.",
The role of co-located storage for wind power producers in conventional electricity markets,"In this paper we study the problem of optimizing contract offerings for an independent wind power producer (WPP) participating in conventional day-ahead forward electricity markets for energy. As wind power is an inherently variable source of energy and is difficult to predict, we explore the extent to which co-located energy storage can be used to improve expected profit and mitigate the the financial risk associated with shorting on the offered contracts. Using a simple stochastic model for wind power production and a model for the electricity market, we show that the problem of determining optimal contract offerings for a WPP with co-located energy storage can be solved using convex programming.","Contracts,
Energy storage,
Wind power generation,
Portfolios,
Electricity supply industry,
Schedules,
Production"
An Ultrasonically Powered Implantable Micro-Oxygen Generator (IMOG),"In this paper, we present an ultrasonically powered implantable micro-oxygen generator (IMOG) that is capable of in situ tumor oxygenation through water electrolysis. Such active mode of oxygen generation is not affected by increased interstitial pressure or abnormal blood vessels that typically limit the systemic delivery of oxygen to hypoxic regions of solid tumors. Wireless ultrasonic powering (2.15 MHz) was employed to increase the penetration depth and eliminate the directional sensitivity associated with magnetic methods. In addition, ultrasonic powering allowed for further reduction in the total size of the implant by eliminating the need for a large area inductor. IMOG has an overall dimension of 1.2 mm × 1.3 mm × 8 mm, small enough to be implanted using a hypodermic needle or a trocar. In vitro and ex vivo experiments showed that IMOG is capable of generating more than 150 μA which, in turn, can create 0.525 μL/min of oxygen through electrolytic disassociation. In vivo experiments in a well-known hypoxic pancreatic tumor models (1 cm3 in size) also verified adequate in situ tumor oxygenation in less than 10 min.","Acoustics,
Tumors,
Electrodes,
Biomembranes,
Transmitters,
Receivers"
Consensus-based distributed unscented particle filter,"In this paper, we propose a consensus-based, distributed implementation of the unscented particle filter (CD/UPF) that extends the distributed Kalman filtering framework to non-linear, distributed dynamical systems with non-Gaussian excitations. Compared to the existing distributed implementations of the particle filter, the CD/UPF offers two advantages. First, it uses all available local observations including the most recent ones in deriving the proposal distribution. Second, computation of global estimates from local estimates during the consensus step is based on an optimal fusion rule. In our bearing-only tracking simulations, the performance of the proposed CD/UPF is virtually indistinguishable from its centralized counterpart.","Proposals,
Target tracking,
Kalman filters,
Estimation,
Complexity theory,
Particle filters,
Monte Carlo methods"
Diagnosis of Cardiovascular Abnormalities From Compressed ECG: A Data Mining-Based Approach,"Usage of compressed ECG for fast and efficient telecardiology application is crucial, as ECG signals are enormously large in size. However, conventional ECG diagnosis algorithms require the compressed ECG packets to be decompressed before diagnosis can be performed. This added step of decompression before performing diagnosis for every ECG packet introduces unnecessary delay, which is undesirable for cardiovascular diseased (CVD) patients. In this paper, we are demonstrating an innovative technique that performs real-time classification of CVD. With the help of this real-time classification of CVD, the emergency personnel or the hospital can automatically be notified via SMS/MMS/e-mail when a life-threatening cardiac abnormality of the CVD affected patient is detected. Our proposed system initially uses data mining techniques, such as attribute selection (i.e., selects only a few features from the compressed ECG) and expectation maximization (EM)-based clustering. These data mining techniques running on a hospital server generate a set of constraints for representing each of the abnormalities. Then, the patient's mobile phone receives these set of constraints and employs a rule-based system that can identify each of abnormal beats in real time. Our experimentation results on 50 MIT-BIH ECG entries reveal that the proposed approach can successfully detect cardiac abnormalities (e.g., ventricular flutter/fibrillation, premature ventricular contraction, atrial fibrillation, etc.) with 97% accuracy on average. This innovative data mining technique on compressed ECG packets enables faster identification of cardiac abnormality directly from the compressed ECG, helping to build an efficient telecardiology diagnosis system.",
On the complementary Index Coding problem,"The Index Coding problem is one of the basic problems in wireless network coding. In this problem, a server needs to deliver a set P of packets to several clients through a noiseless broadcast channel. Each client needs to obtain a certain subset of P and has prior side information about a different subset of P. The objective is to satisfy the requirements of all clients with the minimum number of transmissions. Recently, it was shown that the Index Coding problem is NP-hard. Furthermore, this problem was shown to be hard to approximate under a widely accepted complexity assumption. In this paper, we consider a complementary problem whose goal is to maximize the number of saved transmissions, i.e., the number of transmissions that are saved by combining packets compared to the solution that does not involve coding. We refer to this problem as the the Complementary Index Coding problem. It turns out that the complementary problem can be approximated in certain cases of practical importance. We consider the multiple unicast and multiple multicast scenarios. In the multiple unicast scenario, each packet is requested by a single client; while in the multiple multicast scenario, each packet can be requested by several clients. For the multiple unicast scenario, we present approximation algorithms for finding scalar and vector linear solutions. For the multiple multicast scenario, we show that finding an approximation solution is NP-hard.",
A Detailed Study of the Forming Stage of an Electrochemical Resistive Switching Memory by KMC Simulation,"The forming stage characteristics of electrochemical-metallization resistive-switching-random-access-memory cells are studied with an improved kinetic Monte Carlo simulator. The filament topographies obtained at different forming voltage levels and the relationship between forming time and filament topographies are investigated in detail. The so-called “voltage-time dilemma” is simulated and studied. In addition, the various chemical and physical processes that produce these results are discussed. Finally, the simulated pattern is compared with experiments conducted on Cu/H2O and Ag/Ag2S systems.","Copper,
Surface topography,
Anodes,
Cathodes,
Switches,
Surface treatment"
On-demand time synchronization with predictable accuracy,"Time synchronization remains as a challenging task in wireless sensor networks that face severe resource constraints. Unlike previous work's aiming at pure clock accuracy, this paper proposes On-Demand Synchronization (ODS), a design to achieve efficient clock synchronization with customized performance. By carefully modeling the error uncertainty of skew detection and its propagation over time, ODS develops a novel uncertainty-driven mechanism to adaptively adjust each clock calibration interval individually rather than traditional periodic synchronization, for minimum communication overhead while satisfying the desired accuracy. Besides, ODS provides a nice feature of predictable accuracy, allowing nodes to acquire the useful information about real-time qualities of their synchronization. We implemented ODS on the MICAz mote platform, and evaluated it through test-bed experiments with 33 nodes as well as simulations obeying real world conditions. Results show that ODS is practical, flexible, and quickly adapts to varying accuracy requirements and different traffic load in the network for improved system efficiency.",
Efficient Feature Detection and Effective Post-Verification for Large Scale Near-Duplicate Image Search,"State-of-the-art near-duplicate image search systems mostly build on the bag-of-local features (BOF) representation. While favorable for simplicity and scalability, these systems have three shortcomings: 1) high time complexity of the local feature detection; 2) discriminability reduction of local descriptors due to BOF quantization; and 3) neglect of the geometric relationships among local features after BOF representation. To overcome these shortcomings, we propose a novel framework by using graphics processing units (GPU). The main contributions of our method are: 1) a new fast local feature detector coined Harris-Hessian (H-H) is designed according to the characteristics of GPU to accelerate the local feature detection; 2) the spatial information around each local feature is incorporated to improve its discriminability, supplying semi-local spatial coherent verification (LSC); and 3) a new pairwise weak geometric consistency constraint (P-WGC) algorithm is proposed to refine the search result. Additionally, part of the system is implemented on GPU to improve efficiency. Experiments conducted on reference datasets and a dataset of one million images demonstrate the effectiveness and efficiency of H-H, LSC, and P-WGC.","Graphics processing unit,
Feature extraction,
Detectors,
Robustness,
Complexity theory,
Accuracy"
Reducing Common-Mode Voltage in Three-Phase Sine-Triangle PWM With Interleaved Carriers,"Interleaving pulse width modulation (PWM) waveforms is a proven method to reduce ripple in dc-dc converters. The present study explores interleaving for three-phase motor drives. Fourier analysis shows that interleaving the carriers in conventional uniform PWM significantly reduces the common-mode voltage. New digital signal processor (DSP) hardware supports interleaving directly with changes to just two registers at setup time, so no additional computation time is needed during operation. The common-mode voltage reduction ranges from 36% at full modulation to 67% when idling with zero modulation. Third-harmonic injection slightly reduces the advantage (to 25% at full modulation). However, the maximum RMS common-mode voltage is still less than 20% of the bus voltage under all conditions. The disadvantage of the proposed approach is an increase in current ripple at the switching frequency. Simulations verify the findings. Experiments on a motor drive that uses a commercially available motor-control DSP, connected to a 5 hp motor, agree well with calculations and simulations.","Pulse width modulation,
Harmonic analysis,
Motor drives,
Frequency modulation,
Inverters,
Support vector machines"
Efficient Partial-Parallel Decoder Architecture for Quasi-Cyclic Nonbinary LDPC Codes,"Nonbinary low-density parity-check (NB-LDPC) codes constructed over GF(q) (q >; 2) can achieve higher coding gain than binary LDPC codes when the code length is moderate. A complete partial-parallel decoder architecture based on the Min-max algorithm is proposed for quasi-cyclic NB-LDPC codes in this paper. A novel scheme and corresponding architecture are developed to implement the elementary step of the check node processing. In our design, layered decoding is applied and only nm <; q messages are kept on each edge of the associated Tanner graph. The computation units and the scheduling of the computations are optimized in the context of layered decoding to reduce the area requirement and increase the speed. This paper also introduces an overlapped method for the check node processing among different layers to further speed up the decoding. From complexity and latency analysis, our design is much more efficient than any previous design. Our proposed decoder for a (744, 653) code over GF(25) has also been synthesized on a Xilinx Virtex-2 Pro FPGA device. It can achieve a throughput of 9.30 Mbps when 15 decoding iterations are carried out.","Decoding,
Iterative decoding,
Memory management,
Medical services,
Algorithm design and analysis"
Compressive Diffuse Optical Tomography: Noniterative Exact Reconstruction Using Joint Sparsity,"Diffuse optical tomography (DOT) is a sensitive and relatively low cost imaging modality that reconstructs optical properties of a highly scattering medium. However, due to the diffusive nature of light propagation, the problem is severely ill-conditioned and highly nonlinear. Even though nonlinear iterative methods have been commonly used, they are computationally expensive especially for three dimensional imaging geometry. Recently, compressed sensing theory has provided a systematic understanding of high resolution reconstruction of sparse objects in many imaging problems; hence, the goal of this paper is to extend the theory to the diffuse optical tomography problem. The main contributions of this paper are to formulate the imaging problem as a joint sparse recovery problem in a compressive sensing framework and to propose a novel noniterative and exact inversion algorithm that achieves the l0 optimality as the rank of measurement increases to the unknown sparsity level. The algorithm is based on the recently discovered generalized MUSIC criterion, which exploits the advantages of both compressive sensing and array signal processing. A theoretical criterion for optimizing the imaging geometry is provided, and simulation results confirm that the new algorithm outperforms the existing algorithms and reliably reconstructs the optical inhomogeneities when we assume that the optical background is known to a reasonable accuracy.","Multiple signal classification,
Optical imaging,
Optical scattering,
Optical sensors,
Nonlinear optics,
Optical signal processing"
MIMO Interference Channel With Confidential Messages: Achievable Secrecy Rates and Precoder Design,"We study the achievable rate regions of the multiple-input multiple-output (MIMO) interference channel with confidential messages sent to two receivers, assuming the transmitters use linear precoding. Each receiver is assumed to be an eavesdropper for the other link, and the transmitters employ various techniques to increase the secrecy rate of their own link or that of the network. We describe both cooperative and noncooperative transmission schemes for Gaussian interference channels, and derive their achievable secrecy rate regions. Cooperation is made possible if the transmitters share a portion of their channel state information, allowing them to appropriately adjust their precoders and improve the overall secrecy performance of the network. A game-theoretic formulation of the problem is adopted to allow the transmitters to find an operating point that balances network performance and fairness. The benefit of cooperation is demonstrated via several numerical examples.","Transmitters,
MIMO,
Receivers,
Interference channels,
Helium,
Signal to noise ratio,
Random variables"
Efficient Multipath Communication for Time-Critical Applications in Underwater Acoustic Sensor Networks,"Due to the long propagation delay and high error rate of acoustic channels, it is very challenging to provide reliable data transfer for time-critical applications in an energy-efficient way. On the one hand, traditional retransmission upon failure usually introduces very large end-to-end delay and is thus not proper for time-critical services. On the other hand, common approaches without retransmission consume lots of energy. In this paper, we propose a new multipath power-control transmission (MPT) scheme, which can guarantee certain end-to-end packet error rate while achieving a good balance between the overall energy efficiency and the end-to-end packet delay. MPT smartly combines power control with multipath routing and packet combining at the destination. With carefully designed power-control strategies, MPT consumes much less energy than the conventional one-path transmission scheme without retransmission. Besides, since no hop-by-hop retransmission is allowed, MPT introduces much shorter delays than the traditional one-path scheme with retransmission. We conduct extensive simulations to evaluate the performance of MPT. Our results show that MPT is highly energy-efficient with low end-to-end packet delays.",
Live Virtual Machine Migration via Asynchronous Replication and State Synchronization,"Live migration of virtual machines (VM) across physical hosts provides a significant new benefit for administrators of data centers and clusters. Previous memory-to-memory approaches demonstrate the effectiveness of live VM migration in local area networks (LAN), but they would cause a long period of downtime in a wide area network (WAN) environment. This paper describes the design and implementation of a novel approach, namely, CR/TR-Motion, which adopts checkpointing/recovery and trace/replay technologies to provide fast, transparent VM migration for both LAN and WAN environments. With execution trace logged on the source host, a synchronization algorithm is performed to orchestrate the running source and target VMs until they reach a consistent state. CR/TR-Motion can greatly reduce the migration downtime and network bandwidth consumption. Experimental results show that the approach can drastically reduce migration overheads compared with memory-to-memory approach in a LAN: up to 72.4 percent on application observed downtime, up to 31.5 percent on total migration time, and up to 95.9 percent on the data to synchronize the VM state. The application performance overhead due to migration is kept within 8.54 percent on average. The results also show that for a variety of workloads migrated across WANs, the migration downtime is less than 300 milliseconds.","Synchronization,
Algorithm design and analysis,
Wide area networks,
Local area networks,
Virtual machining,
Checkpointing"
High-Accuracy Fixed-Width Modified Booth Multipliers for Lossy Applications,"The fixed-width multiplier is attractive to many multimedia and digital signal processing systems which are desirable to maintain a fixed format and allow a little accuracy loss to output data. This paper presents the design of high-accuracy fixed-width modified Booth multipliers. To reduce the truncation error, we first slightly modify the partial product matrix of Booth multiplication and then derive an effective error compensation function that makes the error distribution be more symmetric to and centralized in the error equal to zero, leading the fixed-width modified Booth multiplier to very small mean and mean-square errors. In addition, a simple compensation circuit mainly composed of the simplified sorting network is also proposed. Compared to the previous circuits, the proposed error compensation circuit can achieve a tiny mean error and a significant reduction in mean-square error (e.g., at least 12.3% reduction for the 16-bit fixed-width multiplier) while maintaining the approximate hardware overhead. Furthermore, experimental results on two real-life applications also demonstrate that the proposed fixed-width multipliers can improve the average peak signal-to-noise ratio of output images by at least 2.0 dB and 1.1 dB, respectively.","Error compensation,
Finite wordlength effects,
Circuits,
Digital signal processing,
Hardware,
Adders,
Multimedia systems,
Symmetric matrices,
Sorting,
PSNR"
"Database-assisted multi-AP network on TV white spaces: Architecture, spectrum allocation and AP discovery","According to the FCC's final rule for the unlicensed use of TV white spaces, secondary users are required to query a geo-location database to determine whether a spectrum band is occupied or not. However, how to design a multi-cell infrastructure-based secondary network to dynamically access TV white spaces with the help of database is still an open issue. In this paper, we present the design and implementation of WhiteNet, a multi-cell infrastructure-based dynamic spectrum access system on TV white spaces. WhiteNet is compatible with the FCC's database architecture. In WhiteNet, the geo-location database is exploited to assist multi-AP coordination. A low-overhead distributed spectrum allocation algorithm is proposed to allocate spectrum among multiple APs in WhiteNet, considering the heterogeneous propagation property among various spectrum bands throughout TV white spaces. A novel AP discovery scheme is designed to enable users to discover and select the best access point to connect. We implement WhiteNet in a 7-node GNU Radio testbed, which demonstrates the feasibility of our system. Evaluation results show that our spectrum allocation algorithm can significantly increase total network throughput, besides, the AP discovery scheme is reliable and efficient.","Databases,
White spaces,
TV,
Resource management,
Interference,
Bandwidth,
Algorithm design and analysis"
From Internet of Things towards cloud of things,"Since the late 1980s the world is working towards connectivity and convergence. In the last three decades, the convergence of information resources has happened. However to achieve a true convergence the information assets have to be shared, used and executed fruitfully by the various gadgets which we use in our daily lives. Internet of Things is a concept which leverages on the power of networks to create ubiquitous sensor-actuator networks. With the advent of the cloud technologies, the concept of IOTs can be integrated with even the basic elements having limited computing power. This paper aims to evaluate the possibilities offered by integrating the two concepts of IOTs and Cloud Computing.","Cloud computing,
Sensors,
Clouds,
Convergence,
Logic gates"
Weighted Fuzzy Rule Interpolation Based on GA-Based Weight-Learning Techniques,"In this paper, we propose a weighted fuzzy interpolative reasoning method for sparse fuzzy rule-based systems. It is based on a genetic algorithm (GA)-based weight-learning technique. The proposed method can deal with fuzzy rule interpolation with weighted antecedent variables. It also can deal with fuzzy rule interpolation based on polygonal membership functions and bell-shaped membership functions. We also propose a GA-based weight-learning algorithm to automatically learn the optimal weights of the antecedent variables of the fuzzy rules. Furthermore, we apply the proposed weighted fuzzy interpolative reasoning method and the proposed GA-based weight-learning algorithm to deal with the truck backer-upper control problem, the computer activity prediction problem, multivariate regression problems, and time series prediction problems. Based on statistical analysis techniques, the experimental results show that the proposed weighted fuzzy interpolative reasoning method by the use of the optimally learned weights that were obtained by the proposed GA-based weight-learning algorithm has statistically significantly smaller error rates than the existing methods.",
Twinkle: A fast resource provisioning mechanism for internet services,"A key benefit of Amazon EC2-style cloud computing service is the ability to instantiate a large number of virtual machines (VMs) on the fly during flash crowd events. Most existing research focuses on the policy decision such as when and where to start a VM for an application. In this paper, we study a different problem: how can the VMs and the applications inside be brought up as quickly as possible? This problem has not been solved satisfactorily in existing cloud services. We develop a fast start technique for cloud applications by restoring previously created VM snapshots of fully initialized application. We propose a set of optimizations, including working set estimation, demand prediction, and free page avoidance, that allow an application to start running with only partially loaded memory, yet without noticeable performance penalty during its subsequent execution. We implement our system, called Twinkle, in the Xen hypervisor and employ the two-dimensional page walks supported by the latest virtualization technology. We use the RUBiS and TPC-W benchmarks to evaluate its performance under flash crowd and failure over scenarios. The results indicate that Twinkle can provision VMs and restore the QoS significantly faster than the current approaches.","Servers,
Virtual machine monitors,
Web and internet services,
Ash,
Image storage,
Operating systems,
Random access memory"
Sum-product networks: A new deep architecture,"The key limiting factor in graphical model inference and learning is the complexity of the partition function. We thus ask the question: what are the most general conditions under which the partition function is tractable? The answer leads to a new kind of deep architecture, which we call sum product networks (SPNs) and will present in this abstract. The key idea of SPNs is to compactly represent the partition function by introducing multiple layers of hidden variables. An SPN is a rooted directed acyclic graph with variables as leaves, sums and products as internal nodes, and weighted edges.",
Degrees of Freedom Region of a Class of Multisource Gaussian Relay Networks,"We study a layered K-user M-hop Gaussian relay network consisting of Km nodes in the mth layer, where M ≥ 2 and K=K1=KM+1. We observe that the time-varying nature of wireless channels or fading can be exploited to mitigate the interuser interference. The proposed amplify-and-forward relaying scheme exploits such channel variations and works for a wide class of channel distributions including Rayleigh fading. We show a general achievable degrees of freedom (DoF) region for this class of Gaussian relay networks. Specifically, the set of all (d1,..., dK) such that di ≤ 1 for all i and Σ i=1K di ≤ KΣ is achievable, where di is the DoF of the ith source-destination pair and KΣ is the maximum integer such that KΣ ≤ minm{Km} and M/KΣ is an integer. We show that surprisingly the achievable DoF region coincides with the cut-set outer bound if M/ minm{Km} is an integer; thus, interference-free communication is possible in terms of DoF. We further characterize an achievable DoF region assuming multi-antenna nodes and general message set, which again coincides with the cut-set outer bound for a certain class of networks.",
QLMOR: A Projection-Based Nonlinear Model Order Reduction Approach Using Quadratic-Linear Representation of Nonlinear Systems,"We present a projection-based nonlinear model order reduction method, named model order reduction via quadratic-linear systems (QLMOR). QLMOR employs two novel ideas: 1) we show that nonlinear ordinary differential equations, and more generally differential-algebraic equations (DAEs) with many commonly encountered nonlinear kernels can be rewritten equivalently in a special representation, quadratic-linear differential algebraic equations (QLDAEs), and 2) we perform a Volterra analysis to derive the Volterra kernels, and we adapt the moment-matching reduction technique of nonlinear model order reduction method (NORM) [1] to reduce these QLDAEs into QLDAEs of much smaller size. Because of the generality of the QLDAE representation, QLMOR has significantly broader applicability than Taylor-expansion-based methods [1]-[3] since there is no approximation involved in the transformation from original DAEs to QLDAEs. Because the reduced model has only quadratic nonlinearities, its computational complexity is less than that of similar prior methods. In addition, QLMOR, unlike NORM, totally avoids explicit moment calculations, hence it has improved numerical stability properties as well. We compare QLMOR against prior methods [1]-[3] on a circuit and a biochemical reaction-like system, and demonstrate that QLMOR-reduced models retain accuracy over a significantly wider range of excitation than Taylor-expansion-based methods [1]-[3]. QLMOR, therefore, demonstrates that Volterra-kernel based nonlinear MOR techniques can in fact have far broader applicability than previously suspected, possibly being competitive with trajectory-based methods (e.g., trajectory piece-wise linear reduced order modeling [4]) and nonlinear-projection based methods (e.g., maniMOR [5]).","Polynomials,
Mathematical model,
Computational modeling,
Nonlinear systems,
Integrated circuit modeling,
Differential equations"
Reconstructing the 3D Shape and Bone Mineral Density Distribution of the Proximal Femur From Dual-Energy X-Ray Absorptiometry,"The accurate diagnosis of osteoporosis has gained increasing importance due to the aging of our society. Areal bone mineral density (BMD) measured by dual-energy X-ray absorptiometry (DXA) is an established criterion in the diagnosis of osteoporosis. This measure, however, is limited by its two-dimensionality. This work presents a method to reconstruct both the 3D bone shape and 3D BMD distribution of the proximal femur from a single DXA image used in clinical routine. A statistical model of the combined shape and BMD distribution is presented, together with a method for its construction from a set of quantitative computed tomography (QCT) scans. A reconstruction is acquired in an intensity based 3D-2D registration process whereby an instance of the model is found that maximizes the similarity between its projection and the DXA image. Reconstruction experiments were performed on the DXA images of 30 subjects, with a model constructed from a database of QCT scans of 85 subjects. The accuracy was evaluated by comparing the reconstructions with the same subject QCT scans. The method presented here can potentially improve the diagnosis of osteoporosis and fracture risk assessment from the low radiation dose and low cost DXA devices currently used in clinical routine.","Active shape model,
Image reconstruction,
Bones,
Three dimensional displays,
Deformable models,
Computed tomography,
Image registration,
Active appearance model"
An overview of generic battery models,"Battery performance prediction is crucial in many applications. A good prediction mechanism of the battery performance has many advantages. For example, it increases the battery lifetime by preventing over (dis)charging the battery, it allows utilizing the entire capacity of the battery, and it offers an access to the user to know the amount of energy in the battery pack. In this paper, some battery models are derived and tested on a commercial Lithium battery cell. The results show the capabilities of these models under different tests.","System-on-a-chip,
Mathematical model,
Batteries,
Predictive models,
Discharges,
Integrated circuit modeling,
Equations"
WYSIWYG (What You See is What You Get) Volume Visualization,"In this paper, we propose a volume visualization system that accepts direct manipulation through a sketch-based What You See Is What You Get (WYSIWYG) approach. Similar to the operations in painting applications for 2D images, in our system, a full set of tools have been developed to enable direct volume rendering manipulation of color, transparency, contrast, brightness, and other optical properties by brushing a few strokes on top of the rendered volume image. To be able to smartly identify the targeted features of the volume, our system matches the sparse sketching input with the clustered features both in image space and volume space. To achieve interactivity, both special algorithms to accelerate the input identification and feature matching have been developed and implemented in our system. Without resorting to tuning transfer function parameters, our proposed system accepts sparse stroke inputs and provides users with intuitive, flexible and effective interaction during volume data exploration and visualization.","Transfer functions,
Rendering (computer graphics),
Image color analysis,
Data visualization,
Real time systems,
Semantics"
Information Equals Amortized Communication,"We show how to efficiently simulate the sending of a message to a receiver who has partial information about the message, so that the expected number of bits communicated in the simulation is close to the amount of additional information that the message reveals to the receiver who has some information about the message. This is a generalization and strengthening of the Slepian Wolf theorem, which shows how to carry out such a simulation with low amortized communication in the case that the message is a deterministic function of an input. A caveat is that our simulation is interactive. As a consequence, we prove that the internal information cost(namely the information revealed to the parties) involved in computing any relation or function using a two party interactive protocol is exactly equal to the amortized communication complexity of computing independent copies of the same relation or function. We also show that the only way to prove a strong direct sum theorem for randomized communication complexity is by solving a particular variant of the pointer jumping problem that we define. Our work implies that a strong direct sum theorem for communication complexity holds if and only if efficient compression of communication protocols is possible.","Protocols,
Complexity theory,
Receivers,
Entropy,
Random variables,
Mutual information"
Privacy-Preserving Universal Authentication Protocol for Wireless Communications,"Seamless roaming over wireless networks is highly desirable to mobile users, and security such as authentication of mobile users is challenging. In this paper, we propose a privacy-preserving universal authentication protocol, called Priauth, which provides strong user anonymity against both eavesdroppers and foreign servers, session key establishment, and achieves efficiency. Most importantly, Priauth provides an efficient approach to tackle the problem of user revocation while supporting strong user untraceability.","Servers,
Protocols,
Authentication,
Public key,
Roaming,
Mobile communication"
State Observability and Observers of Linear-Time-Invariant Systems Under Irregular Sampling and Sensor Limitations,"State observability and observer designs are investigated for linear-time-invariant systems in continuous time when the outputs are measured only at a set of irregular sampling time sequences. The problem is primarily motivated by systems with limited sensor information in which sensor switching generates irregular sampling sequences. State observability may be lost and the traditional observers may fail in general, even if the system has a full-rank observability matrix. It demonstrates that if the original system is observable, the irregularly sampled system will be observable if the sampling density is higher than some critical frequency, independent of the actual time sequences. This result extends Shannon's sampling theorem for signal reconstruction under periodic sampling to system observability under arbitrary sampling sequences. State observers and recursive algorithms are developed whose convergence properties are derived under potentially dependent measurement noises. Persistent excitation conditions are validated by designing sampling time sequences. By generating suitable switching time sequences, the designed state observers are shown to be convergent in mean square, with probability one, and with exponential convergence rates. Schemes for generating desired sampling sequences are summarized.","Observers,
Manganese,
Convergence,
Observability,
Noise,
Eigenvalues and eigenfunctions"
Semisupervised Band Clustering for Dimensionality Reduction of Hyperspectral Imagery,"Band clustering is applied to dimensionality reduction of hyperspectral imagery. Different from unsupervised clustering using all the pixels or supervised clustering requiring labeled pixels, the proposed semisupervised band clustering needs class spectral signatures only. After clustering, a cluster selection step is applied to select clusters to be used in the following data analysis. Initial conditions and distance metrics are also investigated to improve the clustering performance. The experimental results show that the proposed algorithm can outperform other existing methods with lower computational cost.","Clustering algorithms,
Hyperspectral imaging,
Pixel,
Accuracy,
Measurement"
Opportunities and Challenges in Running Scientific Workflows on the Cloud,"Cloud computing is gaining tremendous momentum in both academia and industry. The application of Cloud computing, however, has mostly focused on Web applications and business applications; while the recognition of using Cloud computing to support large-scale workflows, especially data-intensive scientific workflows on the Cloud is still largely overlooked. We coin the term ""Cloud Workflow"", to refer to the specification, execution, provenance tracking of large-scale scientific workflows, as well as the management of data and computing resources to enable the execution of scientific workflows on the Cloud. In this paper, we analyze why there has been such a gap between the two technologies, and what it means to bring Cloud and workflow together; we then present the key challenges in running Cloud workflow, and discuss the research opportunities in realizing workflows on the Cloud.","Cloud computing,
Computational modeling,
Computer architecture,
Engines,
Scalability,
Monitoring,
Programming"
A dual-phase-shift control strategy for dual-active-bridge DC-DC converter in wide voltage range,"This paper analyzes the dual-phase-shift (DPS) control strategy for a dual-active-bridge (DAB) converter in whole operation range. The DPS has two degree of freedom to control the transferring power, which can improve the performance of the DAB converter than single-phase-shift (SPS) control strategy. This paper derives the reactive power, the rms and the peak current flowing on the transformer and the zero-voltage-switching (ZVS) condition according to the operating conditions. Using this analysis and simulation results, a suitable control strategy for DAB converter is obtained. Experiments are performed to verify the proposed control strategy and to compare with the conventional SPS control strategy. The experimental results show that the proposed method can enhance the overall efficiency and expand the ZVS operation range.","Power generation,
Zero voltage switching,
Reactive power,
Switches,
Leg,
Performance analysis,
Trajectory"
Temperature-Aware Scheduling and Assignment for Hard Real-Time Applications on MPSoCs,"Increasing integrated circuit (IC) power densities and temperatures may hamper multiprocessor system-on-chip (MPSoC) use in hard real-time systems. This paper formalizes the temperature-aware real-time MPSoC assignment and scheduling problem and presents an optimal phased steady-state mixed integer linear programming-based solution that considers the impact of scheduling and assignment decisions on MPSoC thermal profiles to directly minimize the chip peak temperature. We also introduce a flexible heuristic framework for task assignment and scheduling that permits system designers to trade off accuracy for running time when solving large problem instances. Finally, for task sets with sufficient slack, we show that inserting idle times between task executions can further reduce the peak temperature of the MPSoC quite significantly.","Magnetic cores,
Real time systems,
Heating,
Program processors,
Thermal analysis,
Power demand,
Minimization"
Radar HRRP Statistical Recognition With Local Factor Analysis by Automatic Bayesian Ying-Yang Harmony Learning,"Radar high-resolution range profiles (HRRPs) are typical high-dimensional, non-Gaussian and interdimension dependently distributed data, the statistical modelling of which is a challenging task for HRRP based target recognition. Assuming the HRRP data follow interdimension dependent Gaussian distribution, factor analysis (FA) was recently applied to describe radar HRRPs and a two-phase procedure was used for model selection, showing promising recognition results. Besides the interdimensional dependence, this paper further models the non-Gaussianity of the radar HRRP data by local factor analysis (LFA). Moreover, since the two-phase procedure suffers from extensive computation and inaccurate evaluation on high-dimensional finite HRRPs, we adopt an automatic Bayesian Ying-Yang (BYY) harmony learning, which determines the component number and the hidden dimensionalities of LFA automatically during parameter learning. Experimental results show incremental improvements on recognition accuracy by three implementations, progressively from a two-phase FA, to a two-phase LFA, and then to an automatically learned LFA by BYY harmony learning.","Radar,
Target recognition,
Bayesian methods,
Radar scattering,
Sensitivity,
Data models,
Analytical models"
Link-State Routing With Hop-by-Hop Forwarding Can Achieve Optimal Traffic Engineering,"This paper settles an open question with a positive answer: Optimal traffic engineering (or optimal multicommodity flow) can be realized using just link-state routing protocols with hop-by-hop forwarding. Today's typical versions of these protocols, Open Shortest Path First (OSPF) and Intermediate System-Intermediate System (IS-IS), split traffic evenly over shortest paths based on link weights. However, optimizing the link weights for OSPF/IS-IS to the offered traffic is a well-known NP-hard problem, and even the best setting of the weights can deviate significantly from an optimal distribution of the traffic. In this paper, we propose a new link-state routing protocol, PEFT, that splits traffic over multiple paths with an exponential penalty on longer paths. Unlike its predecessor, DEFT, our new protocol provably achieves optimal traffic engineering while retaining the simplicity of hop-by-hop forwarding. The new protocol also leads to a significant reduction in the time needed to compute the best link weights. Both the protocol and the computational methods are developed in a conceptual framework, called Network Entropy Maximization, that is used to identify the traffic distributions that are not only optimal, but also realizable by link-state routing.","Routing,
Routing protocols,
Entropy,
Algorithm design and analysis,
Optimization,
Topology"
The Singular Value Filter: A General Filter Design Strategy for PCA-Based Signal Separation in Medical Ultrasound Imaging,"A general filtering method, called the singular value filter (SVF), is presented as a framework for principal component analysis (PCA) based filter design in medical ultrasound imaging. The SVF approach operates by projecting the original data onto a new set of bases determined from PCA using singular value decomposition (SVD). The shape of the SVF weighting function, which relates the singular value spectrum of the input data to the filtering coefficients assigned to each basis function, is designed in accordance with a signal model and statistical assumptions regarding the underlying source signals. In this paper, we applied SVF for the specific application of clutter artifact rejection in diagnostic ultrasound imaging. SVF was compared to a conventional PCA-based filtering technique, which we refer to as the blind source separation (BSS) method, as well as a simple frequency-based finite impulse response (FIR) filter used as a baseline for comparison. The performance of each filter was quantified in simulated lesion images as well as experimental cardiac ultrasound data. SVF was demonstrated in both simulation and experimental results, over a wide range of imaging conditions, to outperform the BSS and FIR filtering methods in terms of contrast-to-noise ratio (CNR) and motion tracking performance. In experimental mouse heart data, SVF provided excellent artifact suppression with an average CNR improvement of 1.8 dB (P <; 0.05) with over 40% reduction (P <; 0.05) in displacement tracking error. It was further demonstrated from simulation and experimental results that SVF provided superior clutter rejection, as reflected in larger CNR values, when filtering was achieved using complex pulse-echo received data and non-binary filter coefficients.","Cardiology,
Ultrasonic imaging,
Principal component analysis,
Finite impulse response filter,
Biomedical imaging"
A noncooperative game for double auction-based energy trading between PHEVs and distribution grids,"Plug-in hybrid electric vehicles (PHEVs) will constitute a key element in the emerging smart grid system. In this paper, the complex decision making processes of a number of PHEV groups seeking to sell part of their stored energy in a power market are studied using noncooperative games and double auctions. In particular, a noncooperative game is formulated between the PHEV groups. In this game, each PHEV group can make a decision on the maximum amount of energy surplus that it is willing to sell so as to maximize a utility function that captures the tradeoff between the economical benefits from energy trading and the associated costs. The trading price governing the energy exchange market between the PHEVs and the smart grid network is determined using a strategy-proof double auction. For solving the game, an algorithm based on best response dynamics is proposed using which the PHEV groups can reach a Nash equilibrium point. Simulation results show how our approach allows the PHEV groups to act strategically while improving the average utility achieved per PHEV group of up to 100.2% relative to a greedy algorithm.","power markets,
electric vehicles,
energy storage,
game theory,
power distribution economics"
Cyber-Physical-Social Systems for Command and Control,"The article provides a preliminary account of the operational process of command and control based on the cyber-physical-social system (CPSS) and a self-synchronization mechanism. The proposed CPSS for command and control incorporates the essential characteristics of operational mechanism and connects the physical network, cyberspace, mental space, and social network.","Command and control systems,
Organizations,
Social factors,
Cyberspace,
Social network services"
FPGA-Based Parallel DNA Algorithm for Optimal Configurations of an Omnidirectional Mobile Service Robot Performing Fire Extinguishment,"This paper presents a coarse-grain parallel deoxyribonucleic acid (PDNA) algorithm for optimal configurations of an omnidirectional mobile robot with a five-link robotic arm. This efficient coarse-grain PDNA is proposed to search for the global optimum of the redundant inverse kinematics problem with minimal movement, thereby showing better population diversity and avoiding premature convergence. Moreover, the pipelined hardware implementation, hardware/software co-design, and System-on-a-Programmable-Chip (SoPC) technology on a field-programmable gate array (FPGA) chip are employed to realize the proposed PDNA in order to significantly shorten its processing time. Simulations and experimental results are conducted to illustrate the merit and superiority of the proposed FPGA-based PDNA algorithm in comparison with conventional genetic algorithms (GAs) for omnidirectional mobile robot performing fire extinguishment.","Service robots,
Fires,
Signal processing algorithms,
Mobile robots,
DNA computing,
Hardware,
Field programmable gate arrays,
Integrated circuit technology,
Parallel processing,
Evolution (biology)"
Approximate Capacity of a Class of Gaussian Interference-Relay Networks,"In this paper, we study a Gaussian relay-interference network, in which relay (helper) nodes are to facilitate competing information flows between different source-destination pairs. We focus on two-stage relay-interference networks where there are weak cross links, causing the networks to behave like a chain of Z Gaussian channels. Our main result is an approximate characterization of the capacity region for such ZZ and ZS networks. We propose a new interference management scheme, termed interference neutralization, which is implemented using structured lattice codes. This scheme allows for over-the-air interference removal, without the transmitters having complete access the interfering signals. This scheme in conjunction a new network decomposition technique provides the approximate characterization. Our analysis of these Gaussian networks is based on insights gained from an exact characterization of the corresponding linear deterministic model.","Relays,
Wireless networks,
Encoding,
Interference channels,
Noise"
Graph Laplace for Occluded Face Completion and Recognition,"This paper proposes a spectral-graph-based algorithm for face image repairing, which can improve the recognition performance on occluded faces. The face completion algorithm proposed in this paper includes three main procedures: 1) sparse representation for partially occluded face classification; 2) image-based data mining; and 3) graph Laplace (GL) for face image completion. The novel part of the proposed framework is GL, as named from graphical models and the Laplace equation, and can achieve a high-quality repairing of damaged or occluded faces. The relationship between the GL and the traditional Poisson equation is proven. We apply our face repairing algorithm to produce completed faces, and use face recognition to evaluate the performance of the algorithm. Experimental results verify the effectiveness of the GL method for occluded face completion.","Face,
Face recognition,
Topology,
Pixel,
Mathematical model,
Equations,
Graphics"
A Content-Based Dissemination Protocol for VANETs: Exploiting the Encounter Probability,"This paper focuses on intelligent transportation systems and, more precisely, on intervehicle ad hoc networks. A vehicular ad hoc network (VANET) is a highly dynamic network as the vehicles communicate using short-range wireless communications and can move very quickly. Thus, for example, we can only rely on short interactions between vehicles to exchange information about relevant events. In this paper, we describe in detail a dissemination protocol that vehicles can use to share information by using vehicle-to-vehicle communications. The dissemination approach considers the relevance of the data, represented by what we call encounter probability, to decide when a rediffusion is needed. The protocol is able to disseminate data about any type of event in the network (e.g., available parking spaces, accidents or obstacles in the road, information about moving objects such as emergency vehicles that should get the right of way, etc.) by setting appropriate weights for the different factors that affect the computation of the encounter probability. An extensive experimental evaluation with different types of events shows the interest of the proposal: The vehicles receive the relevant messages in time, and the network overload is limited.","Vehicles,
Protocols,
Accidents,
Driver circuits,
Roads,
Ad hoc networks,
Estimation"
Fusing generic objectness and visual saliency for salient object detection,"We present a novel computational model to explore the relatedness of objectness and saliency, each of which plays an important role in the study of visual attention. The proposed framework conceptually integrates these two concepts via constructing a graphical model to account for their relationships, and concurrently improves their estimation by iteratively optimizing a novel energy function realizing the model. Specifically, the energy function comprises the objectness, the saliency, and the interaction energy, respectively corresponding to explain their individual regularities and the mutual effects. Minimizing the energy by fixing one or the other would elegantly transform the model into solving the problem of objectness or saliency estimation, while the useful information from the other concept can be utilized through the interaction term. Experimental results on two benchmark datasets demonstrate that the proposed model can simultaneously yield a saliency map of better quality and a more meaningful objectness output for salient object detection.","Visualization,
Object detection,
Detectors,
Databases,
Computational modeling,
Image edge detection,
Shape"
PVA in VANETs: Stopped cars are not silent,"In Vehicular Ad Hoc Networks (VANETs), the major communication challenge lies in very poor connectivity, which can be caused by sparse or unbalanced traffic. Deploying supporting infrastructure could relieve this problem, but it often requires a large amount of investment and elaborate design, especially at the city scale. In this paper, we propose the idea of Parked Vehicle Assistance (PVA), which allows parked vehicles to join VANETs as static nodes. With wireless device and rechargable battery, parked vehicles can easily communicate with one another and their moving counterparts. Owing to the extensive parking in cities, parked vehicles are natural roadside nodes characterized by large number, long-time staying, wide distribution, and specific location. So parked vehicles can serve as static backbone and service infrastructure to improve connectivity. We investigate network connectivity in PVA through theoretic analysis and realistic survey and simulations. The results prove that even a small proportion of PVA vehicles could overcome sparse or unbalanced traffic, and promote network connectivity greatly. Thus, PVA enhances VANETs from down to top, and paves the way for new hybrid networks with static and mobile nodes.","Vehicles,
Cities and towns,
Roads,
Ad hoc networks,
Relays,
Delay,
Wireless communication"
The Evolution of Factory and Building Automation,"This article gives an overview of the general concepts, underlying technologies, similarities, and differences in the factory and building automation fields and explores issues and trends. Particular emphasis is put on the information aspects in automation, such as communication and integration, that used to be a central topic during the last few decades and are being addressed by maturing solutions only recently.","Construction industry,
Workstations,
Process control,
Manufacturing automation,
Production facilities,
Buildings"
Autonomous generation of complete 3D object models using next best view manipulation planning,"Recognizing and manipulating objects is an important task for mobile robots performing useful services in everyday environments. In this paper, we develop a system that enables a robot to grasp an object and to move it in front of its depth camera so as to build a 3D surface model of the object. We derive an information gain based variant of the next best view algorithm in order to determine how the manipulator should move the object in front of the camera. By considering occlusions caused by the robot manipulator, our technique also determines when and how the robot should re-grasp the object in order to build a complete model.","Manipulators,
Cameras,
Surface reconstruction,
Uncertainty,
Robot vision systems"
Efficient Periodicity Mining in Time Series Databases Using Suffix Trees,"Periodic pattern mining or periodicity detection has a number of applications, such as prediction, forecasting, detection of unusual activities, etc. The problem is not trivial because the data to be analyzed are mostly noisy and different periodicity types (namely symbol, sequence, and segment) are to be investigated. Accordingly, we argue that there is a need for a comprehensive approach capable of analyzing the whole time series or in a subsection of it to effectively handle different types of noise (to a certain degree) and at the same time is able to detect different types of periodic patterns; combining these under one umbrella is by itself a challenge. In this paper, we present an algorithm which can detect symbol, sequence (partial), and segment (full cycle) periodicity in time series. The algorithm uses suffix tree as the underlying data structure; this allows us to design the algorithm such that its worstcase complexity is O(k.n2), where k is the maximum length of periodic pattern and n is the length of the analyzed portion (whole or subsection) of the time series. The algorithm is noise resilient; it has been successfully demonstrated to work with replacement, insertion, deletion, or a mixture of these types of noise. We have tested the proposed algorithm on both synthetic and real data from different domains, including protein sequences. The conducted comparative study demonstrate the applicability and effectiveness of the proposed algorithm; it is generally more time-efficient and noise-resilient than existing algorithms.","Databases,
Time series analysis,
Pattern analysis,
Computer science,
Data analysis,
Algorithm design and analysis,
Tree data structures,
Testing,
Proteins,
Weather forecasting"
Analyses on Small-Signal Parameters and Radio-Frequency Modeling of Gate-All-Around Tunneling Field-Effect Transistors,"The small-signal parameters of gate-all-around tunneling field-effect transistors (GAA TFETs) with different gate lengths were extracted and analyzed in terms of their gate capacitance, source-drain conductance, transconductance, distributed channel resistance, and inversion layer length. Because of the unique current drive and inversion layer formation mechanisms of a TFET compared to a conventional MOSFET, the gate-bias dependence values of the primary small-signal parameters of a GAA TFET also differ. Based on understanding these parameters, the high-frequency performances of GAA TFETs were investigated using a technology computer-aided design simulation. A nonquasistatic radio-frequency model was used to extract the small-signal parameters, which were verified up to 100 GHz. The modeling results showed excellent agreement with the Y-parameters up to the cutoff frequency fT.","Logic gates,
MOSFET circuits,
Resistance,
Capacitance,
Radio frequency,
Integrated circuit modeling,
Transistors"
The Numerical Tours of Signal Processing,"The NTSP (Numerical Tours of Signal Processing) collection of Matlab/Scilab experiments guides users through the emerging jungle of advanced signal-, image-, and mesh-processing algorithms.","Signal processing,
MATLAB,
Algorithms,
Mesh networks"
A Region-Based Clustering Mechanism for Channel Access in Vehicular Ad Hoc Networks,"Several contention-based Medium Access Control (MAC) protocols have been proposed for the vehicles to gain the radio channels to distribute active safety messages timely, e.g., Safety Critical Application (SCA) information, for inter-vehicle communications in Vehicular Ad Hoc Networks (VANETs). In these MAC protocols, a contention period is introduced before the vehicle for channel access so that we may not have the timely and reliably message dissemination in VANETs. To reduce the contention period, this paper proposes a Region-based Clustering Mechanism (RCM) to be applied in these MAC protocols. We propose analytical models to investigate the performance of the RCM, which are validated by the simulation experiments.","Vehicles,
Media Access Protocol,
Analytical models,
Laplace equations,
Density functional theory,
Radio transmitters"
Millimeter-Wave Microstrip Comb-Line Antenna Using Reflection-Canceling Slit Structure,"A microstrip comb-line antenna is developed in the millimeter-wave band. When the element spacing is one guide wavelength for the broadside beam in the traveling-wave excitation, reflections from all the radiating elements are synthesized in phase. Therefore, the return loss increases significantly. Furthermore, re-radiation from elements due to the reflection wave degrades the design accuracy for the required radiation pattern. We propose the way to improve the reflection characteristic of the antenna with arbitrary beam directions including strictly a broadside direction. To suppress the reflection, we propose a reflection-canceling slit structure installed on the feeding line around each radiating element. A 27-element linear array antenna with a broadside beam is developed at 76.5 GHz. To confirm the feasibility of the simple design procedure, the performance is evaluated through the measurement in the millimeter-wave band.","Microstrip,
Arrays,
Resonant frequency,
Microstrip antennas,
Couplings,
Microstrip antenna arrays,
Propagation losses"
Lexicographic Products and the Power of Non-linear Network Coding,"We introduce a technique for establishing and amplifying gaps between parameters of network coding and index coding problems. The technique uses linear programs to establish separations between combinatorial and coding-theoretic parameters and applies hyper graph lexicographic products to amplify these separations. This entails combining the dual solutions of the lexicographic multiplicands and proving that this is a valid dual solution of the product. Our result is general enough to apply to a large family of linear programs. This blend of linear programs and lexicographic products gives a recipe for constructing hard instances in which the gap between combinatorial or coding-theoretic parameters is polynomially large. We find polynomial gaps in cases in which the largest previously known gaps were only small constant factors or entirely unknown. Most notably, we show a polynomial separation between linear and non-linear network coding rates. This involves exploiting a connection between matroids and index coding to establish a previously unknown separation between linear and non-linear index coding rates. We also construct index coding problems with a polynomial gap between the broadcast rate and the trivial lower bound for which no gap was previously known.","Encoding,
Indexes,
Network coding,
Receivers,
Vectors,
Random variables,
Entropy"
Fractional QCQP With Applications in ML Steering Direction Estimation for Radar Detection,"This paper deals with the problem of estimating the steering direction of a signal, embedded in Gaussian disturbance, under a general quadratic inequality constraint, representing the uncertainty region of the steering. We resort to the maximum likelihood (ML) criterion and focus on two scenarios. The former assumes that the complex amplitude of the useful signal component fluctuates from snapshot to snapshot. The latter supposes that the useful signal keeps a constant amplitude within all the snapshots. We prove that the ML criterion leads in both cases to a fractional quadratically constrained quadratic problem (QCQP). In order to solve it, we first relax the problem into a constrained fractional semidefinite programming (SDP) problem which is shown equivalent, via the Charnes-Cooper transformation, to an SDP problem. Then, exploiting a suitable rank-one decomposition, we show that the SDP relaxation is tight and give a procedure to construct (in polynomial time) an optimal solution of the original problem from an optimal solution of the fractional SDP. We also assess the quality of the derived estimator through a comparison between its performance and the constrained Cramer Rao lower Bound (CRB). Finally, we give two applications of the proposed theoretical framework in the context of radar detection.","Maximum likelihood estimation,
Radar detection,
Radar antennas,
Arrays,
Antenna arrays"
"Design, Modeling, and Control of a Micromachined Nanopositioner With Integrated Electrothermal Actuation and Sensing","In this paper, a real-time feedback control of a novel micromachined one-degree-of-freedom thermal nanopositioner with on-chip electrothermal position sensors is presented. The actuation works based on thermal expansion of silicon beams. The sensing mechanism works based on measuring the difference between the electrical resistances of two electrically biased identical silicon beams. The difference increases with displacement, as the heat conductance of the sensor beams varies oppositely with position, resulting in different beam temperatures and resistances. The sensor pair is operated in differential mode to reduce low-frequency drift. The nanopositioner has a nonlinear static input-output characteristic. An open-loop controller is first designed and implemented. It is experimentally shown that uncertainties and sensor drift result in an unacceptable nanopositioner performance. Hence, feedback control methods are necessary for accurate nanopositioning. A closed-loop feedback control system is designed using a proportional-integral controller together with the nonlinear compensator used for the open-loop control system. The closed-loop system provides an acceptable and robust tracking performance for a wide range of set point values. For triangular reference tracking, which is needed in raster-scanned scanning probe microscopy, the tracking performance of the closed-loop system is further improved by incorporating a feedforward controller.","Actuators,
Temperature sensors,
Resistors,
Resistance,
Nanopositioning"
Towards a practical lipreading system,"A practical lipreading system can be considered either as subject dependent (SD) or subject-independent (SI). An SD system is user-specific, i.e., customized for some particular user while an SI system has to cope with a large number of users. These two types of systems pose variant challenges and have to be treated differently. In this paper, we propose a simple deterministic model to tackle the problem. The model first seeks a low-dimensional manifold where visual features extracted from the frames of a video can be projected onto a continuous deterministic curve embedded in a path graph. Moreover, it can map arbitrary points on the curve back into the image space, making it suitable for temporal interpolation. Based on the model, we develop two separate strategies for SD and SI lipreading. The former is turned into a simple curve-matching problem while for the latter, we propose a video-normalization scheme to improve the system developed by Zhao et al. We evaluated our system on the OuluVS database and achieved recognition rates more than 20% higher than the ones reported by Zhao et al. in both SD and SI testing scenarios.","Feature extraction,
Silicon,
Visualization,
Speech recognition,
Mouth,
Hidden Markov models,
Speech"
Bernoulli Forward-Backward Smoothing for Joint Target Detection and Tracking,"In this correspondence, we derive a forward-backward smoother for joint target detection and estimation and propose a sequential Monte Carlo implementation. We model the target by a Bernoulli random finite set since the target can be in one of two “present” or “absent” modes. Finite set statistics is used to derive the smoothing recursion. Our results indicate that smoothing has two distinct advantages over just using filtering: First, we are able to more accurately identify the appearance and disappearance of a target in the scene, and second, we can provide improved state estimates when the target exists.","Smoothing methods,
Joints,
Target tracking,
Monte Carlo methods,
Clutter,
Estimation,
Time measurement"
Probability-Dependent Gain-Scheduled Filtering for Stochastic Systems With Missing Measurements,"This brief addresses the gain-scheduled filtering problem for a class of discrete-time systems with missing measurements, nonlinear disturbances, and external stochastic noise. The missing-measurement phenomenon is assumed to occur in a random way, and the missing probability is time-varying with securable upper and lower bounds that can be measured in real time. The multiplicative noise is a state-dependent scalar Gaussian white-noise sequence with known variance. The addressed gain-scheduled filtering problem is concerned with the design of a filter such that, for the admissible random missing measurements, nonlinear parameters, and external noise disturbances, the error dynamics is exponentially mean-square stable. The desired filter is equipped with time-varying gains based primarily on the time-varying missing probability and is therefore less conservative than the traditional filter with fixed gains. It is shown that the filter parameters can be derived in terms of the measurable probability via the semidefinite program method.","Stochastic systems,
Lyapunov methods,
Gain measurement,
Time varying systems,
Linear matrix inequalities,
Filtering theory,
Discrete time systems"
Reactive power operation analysis of a single-phase EV/PHEV bidirectional battery charger,"More battery powered electric vehicles (EVs) and plug-in hybrid electric vehicles (PHEVs) will be introduced to the market in 2011 and beyond. PHEVs/EVs potentially have the capability to fulfill the energy storage needs of the electric grid by supplying ancillary services such as reactive power compensation, voltage regulation, and peak shaving since they carry an on-board battery charger. However, to allow bidirectional power transfer, the PHEV battery charger should be designed to manage such reactive power capability. This study shows how bidirectional four quadrant operation affects the design stage of a conventional unidirectional charger and the operation of the battery pack. Mainly, the subjects that are discussed are the following: required topology updates, dc link capacitor (voltage and current), ac inductor (current), rectifier (power loss), and battery pack (voltage and current).","Batteries,
Reactive power,
Capacitors,
Vehicles,
AC-DC power converters,
Inductors,
System-on-a-chip"
Adaptive learning of Byzantines' behavior in cooperative spectrum sensing,"This paper considers the problem of Byzantine attacks on cooperative spectrum sensing in cognitive radio networks. Our major contribution is a technique to learn about the cognitive radio (CR) potential malicious behavior over time and thereby identifies the Byzantines and then estimates their probabilities of false alarm (Pfa) and detection (PD). We show that for a given set of data over time, the Byzantines can be identified for any a (percentage of Byzantines). It has also been shown that these estimates of Pfa and Pn of the Byzantines are asymptotically unbiased and converge to their true values at the rate of O(T-1/2). We then use these probabilities to adaptively design the fusion rule. We calculate the Probability of error (Qe) and compare it with the minimum probability of error possible.","Sensors,
Cognitive radio,
Convergence,
Joints,
Equations,
Probability,
Receiving antennas"
Thread reinforcer: Dynamically determining number of threads via OS level monitoring,"It is often assumed that to maximize the performance of a multithreaded application, the number of threads created should equal the number of cores. While this may be true for systems with four or eight cores, this is not true for systems with larger number of cores. Our experiments with PARSEC programs on a 24-core machine demonstrate this. Therefore, dynamically determining the appropriate number of threads for a multithreaded application is an important unsolved problem. In this paper we develop a simple technique for dynamically determining appropriate number of threads without recompiling the application or using complex compilation techniques or modifying Operating System policies. We first present a scalability study of eight programs from PARSEC conducted on a 24 core Dell PowerEdge R905 server running OpenSolaris.2009.06 for numbers of threads ranging from a few threads to 128 threads. Our study shows that not only does the maximum speedup achieved by these programs vary widely (from 3.6x to 21.9x), the number of threads that produce maximum speedups also vary widely (from 16 to 63 threads). By understanding the overall speedup behavior of these programs we identify the critical Operating System level factors that explain why the speedups vary with the number of threads. As an application of these observations, we develop a framework called “Thread Reinforcer” that dynamically monitors program's execution to search for the number of threads that are likely to yield best speedups. Thread Reinforcer identifies optimal or near optimal number of threads for most of the PARSEC programs studied and as well as for SPEC OMP and PBZIP2 programs.",
"Systematic, Single Limited Magnitude Error Correcting Codes for Flash Memories","A relatively new model of error correction is the limited magnitude error model. That is, it is assumed that the absolute difference between the sent and received symbols is bounded above by a certain value l. In this paper, we propose systematic codes for asymmetric limited magnitude channels that are able to correct a single error. We also show how this construction can be slightly modified to design codes that can correct a single symmetric error of limited magnitude. The designed codes achieve higher code rates than single error correcting codes previously given in the literature.","Systematics,
Error correction codes,
Parity check codes,
Ash,
Electrical engineering,
Informatics,
Indexes"
Online user survey on current mobile augmented reality applications,"Augmented reality (AR) as an emerging technology in the mobile computing domain is becoming mature enough to engender publicly available applications for end users. Various commercial applications have recently been emerging in the mobile consumer domain at an increasing pace — Layar, Junaio, Google Goggles, and Wikitude are perhaps the most prominent ones. However, the research community lacks an understanding of how well such timely applications have been accepted, what kind of user experiences they have evoked, and what the users perceive as the weaknesses of the various applications overall. During the spring of 2011 we conducted an online survey to study the overall acceptance and user experience of the mobile AR-like consumer applications currently existing on the market. This paper reports the first analyses of the qualitative and quantitative survey data of 90 respondents. We highlight an extensive set of user-oriented issues to be considered in developing the applications further, as well as in directing future user research in AR. The results indicate that the experiences have been inconsistent: generally positive evaluations are overshadowed by mentions of applications' pragmatic uselessness in everyday life and technical unreliability, as well as excessive or limited and irrelevant content.","Mobile communication,
Context,
Augmented reality,
Image recognition,
Visualization,
Browsers,
Cameras"
"Fully-3D PET Image Reconstruction Using Scanner-Independent, Adaptive Projection Data and Highly Rotation-Symmetric Voxel Assemblies","For iterative, fully 3D positron emission tomography (PET) image reconstruction intrinsic symmetries can be used to significantly reduce the size of the system matrix. The precalculation and beneficial memory-resident storage of all nonzero system matrix elements is possible where sufficient compression exists. Thus, reconstruction times can be minimized independently of the used projector and more elaborate weighting schemes, e.g., volume-of-intersection (VOI), are applicable. A novel organization of scanner-independent, adaptive 3D projection data is presented which can be advantageously combined with highly rotation-symmetric voxel assemblies. In this way, significant system matrix compression is achieved. Applications taking into account all physical lines-of-response (LORs) with individual VOI projectors are presented for the Siemens ECAT HR+ whole-body scanner and the Siemens BrainPET, the PET component of a novel hybrid-MR/PET imaging system. Measured and simulated data were reconstructed using the new method with ordered-subset-expectation-maximization (OSEM). Results are compared to those obtained by the sinogram-based OSEM reconstruction provided by the manufacturer. The higher computational effort due to the more accurate image space sampling provides significantly improved images in terms of resolution and noise.",
Efficient missing tag detection in RFID systems,"RFID tags have many important applications in automated warehouse management. One example is to monitor a set of tags and detect whether some tags are missing - the objects to which the missing tags are attached are likely to be missing, too, due to theft or administrative error. Prior research on this problem has primarily focused on efficient protocols that reduce the execution time in order to avoid disruption of normal inventory operations. This paper makes several new advances. First, we observe that the existing protocol is far from being optimal in terms of execution time. We are able to cut the execution time to a fraction of what is currently needed. Second, we study the missing-tag detection problem from a new energy perspective, which is very important when battery-powered active tags are used. The new insight provides flexibility for the practitioners to meet their energy and time requirements.","Protocols,
RFID tags,
Batteries,
Estimation,
Inventory management,
Energy consumption"
Hot data identification for flash-based storage systems using multiple bloom filters,"Hot data identification can be applied to a variety of fields. Particularly in flash memory, it has a critical impact on its performance (due to a garbage collection) as well as its life span (due to a wear leveling). Although the hot data identification is an issue of paramount importance in flash memory, little investigation has been made. Moreover, all existing schemes focus almost exclusively on a frequency viewpoint. However, recency also must be considered equally with the frequency for effective hot data identification. In this paper, we propose a novel hot data identification scheme adopting multiple bloom filters to efficiently capture finer-grained recency as well as frequency. In addition to this scheme, we propose a Window-based Direct Address Counting (WDAC) algorithm to approximate an ideal hot data identification as our baseline. Unlike the existing baseline algorithm that cannot appropriately capture recency information due to its exponential batch decay, our WDAC algorithm, using a sliding window concept, can capture very fine-grained recency information. Our experimental evaluation with diverse realistic workloads including real SSD traces demonstrates that our multiple bloom filter-based scheme outperforms the state-of-the-art scheme. In particular, ours not only consumes 50% less memory and requires less computational overhead up to 58%, but also improves its performance up to 65%.","Ash,
Radiation detectors,
Memory management,
Flash memory,
Arrays,
Aging,
Approximation algorithms"
Inferring human gaze from appearance via adaptive linear regression,"The problem of estimating human gaze from eye appearance is regarded as mapping high-dimensional features to low-dimensional target space. Conventional methods require densely obtained training samples on the eye appearance manifold, which results in a tedious calibration stage. In this paper, we introduce an adaptive linear regression (ALR) method for accurate mapping via sparsely collected training samples. The key idea is to adaptively find the subset of training samples where the test sample is most linearly representable. We solve the problem via l1-optimization and thoroughly study the key issues to seek for the best solution for regression. The proposed gaze estimation approach based on ALR is naturally sparse and low-dimensional, giving the ability to infer human gaze from variant resolution eye images using much fewer training samples than existing methods. Especially, the optimization procedure in ALR is extended to solve the subpixel alignment problem simultaneously for low resolution test eye images. Performance of the proposed method is evaluated by extensive experiments against various factors such as number of training samples, feature dimensionality and eye image resolution to verify its effectiveness.",
Behavior classification algorithms at intersections and validation using naturalistic data,"The ability to classify driver behavior lays the foundation for more advanced driver assistance systems. Improving safety at intersections has also been identified as high priority due to the large number of intersection related fatalities. This paper focuses on developing algorithms for estimating driver behavior at road intersections. It introduces two classes of algorithms that can classify drivers as compliant or violating. They are based on 1) Support Vector Machines (SVM) and 2) Hidden Markov Models (HMM), two very popular machine learning approaches that have been used extensively for classification in multiple disciplines. The algorithms are successfully validated using naturalistic intersection data collected in Christiansburg, VA, through the US Department of Transportation Cooperative Intersection Collision Avoidance System for Violations (CICAS-V) initiative.","Driver circuits,
Hidden Markov models,
Support vector machines,
Vehicles,
Trajectory,
Classification algorithms,
Training"
Minimum Variance Control Over a Gaussian Communication Channel,We consider the problem of minimizing the response of a plant output to a stochastic disturbance using a control law that relies on the output of a noisy communication channel. We discuss a lower bound on the performance achievable at a specified terminal time using nonlinear time-varying communication and control strategies and show that this bound may be achieved using strategies that are linear. We also consider strategies that are defined over an infinite horizon that may achieve better transient response that those that are optimal for the terminal time problem.,"Decoding,
Estimation error,
Random variables,
Noise measurement,
Channel estimation,
Entropy"
Understanding and improving computational science storage access through continuous characterization,"Computational science applications are driving a demand for increasingly powerful storage systems. While many techniques are available for capturing the I/O behavior of individual application trial runs and specific components of the storage system, continuous characterization of a production system remains a daunting challenge for systems with hundreds of thousands of compute cores and multiple petabytes of storage. As a result, these storage systems are often designed without a clear understanding of the diverse computational science workloads they will support.In this study, we outline a methodology for scalable, con tinuous, systemwide I/O characterization that combines storage device instrumentation, static file system analysis, and a new mechanism for capturing detailed application-level behavior. This methodology allows us to quantify systemwide trends such as the way application behavior changes with job size, the ""burstiness"" of the storage system, and the evolution of file system contents over time. The data also can be examined by application domain to determine the most prolific storage users and also investigate how their I/O strategies correlate with I/O performance. At the most detailed level, our characterization methodology can also be used to focus on individual applications and guide tuning efforts for those applications. We demonstrate the effectiveness of our methodology by performing a multilevel, two-month study of Intrepid, a 557 teraflop IBM Blue Gene/P system. During that time, we captured application-level I/O characterizations from 6,481 unique jobs spanning 38 science and engineering projects with up to 163,840 processes per job. We also captured patterns of I/O activity in over 8 petabytes of block device traffic and summarized the con tents of file systems containing over 191 million flies. We then used the results of our study to tune example applications, highlight trends that impact the design of future storage systems, and identify opportunities for improvement in I/O characterization methodology.","Instruments,
Production,
Measurement,
Lead,
Aggregates,
Scientific computing,
Benchmark testing"
Belief Propagation for Distributed Downlink Beamforming in Cooperative MIMO Cellular Networks,"We propose a new graphical model approach to cooperative multiple-input multiple-output (MIMO) cellular networks. The objective is to optimize downlink transmit beamforming at each BS in order to maximize the sum throughput over the entire network. While ideal centralized beamforming requires full channel state information (CSI) sharing among all BSs in the network and huge computational complexity for combinatorial optimization, the proposed graphical model enables distributed beamforming which requires only local CSI sharing between neighboring BSs and efficiently solves the optimization problem in a distributed manner. As distributed solvers for this problem, we derive message-passing algorithms which can be implemented with polynomial-time computational complexity. Furthermore, we make a slight approximation on the objective function to derive a simpler graphical model, providing further complexity saving. Simulation results indicate that the proposed distributed downlink beamforming achieves average cell throughput typically within just 2% of ideal centralized beamforming.","Array signal processing,
Graphical models,
MIMO,
Interference,
Throughput,
Downlink"
A revisit to cost aggregation in stereo matching: How far can we reduce its computational redundancy?,"This paper presents a novel method for performing an efficient cost aggregation in stereo matching. The cost aggregation problem is re-formulated with a perspective of a histogram, and it gives us a potential to reduce the complexity of the cost aggregation significantly. Different from the previous methods which have tried to reduce the complexity in terms of the size of an image and a matching window, our approach focuses on reducing the computational redundancy which exists among the search range, caused by a repeated filtering for all disparity hypotheses. Moreover, we also reduce the complexity of the window-based filtering through an efficient sampling scheme inside the matching window. The trade-off between accuracy and complexity is extensively investigated into parameters used in the proposed method. Experimental results show that the proposed method provides high-quality disparity maps with low complexity. This work provides new insights into complexity-constrained stereo matching algorithm design.",
Communication Requirement for Reliable and Secure State Estimation and Control in Smart Grid,"System state estimation and control are important issues to ensure the stability and reliability of the smart grid system. In this paper, the problem of how to securely estimate the system state and control the smart grid is studied. In the setup studied, the sensor(s) and the controller communicate with each other through a wireless channel subjected to monitoring by an eavesdropper. The channel capacity requirement that ensures negligible information leakage to the eavesdropper about the system state and control messages is studied from the information theoretic perspective. Two scenarios with single sensor or multiple sensors are studied. Numerical simulations are used to evaluate the capacity requirement in typical configurations of the smart grid.","Smart grids,
Entropy,
State estimation,
Security,
Measurement,
Control systems,
Linear systems"
Designing games for distributed optimization,"The central goal in multiagent systems is to design local control laws for the individual agents to ensure that the emergent global behavior is desirable with respect to a given system level objective. Ideally, a system designer seeks to satisfy this goal while conditioning each agent's control law on the least amount of information possible. Unfortunately, there are no existing methodologies for addressing this design challenge. The goal of this paper is to address this challenge using the field of game theory. Utilizing game theory for the design and control of multiagent systems requires two steps: (i) defining a local objective function for each decision maker and (ii) specifying a distributed learning algorithm to reach a desirable operating point. One of the core advantages of this game theoretic approach is that this two step process can be decoupled by utilizing specific classes of games. For example, if the designed objective functions result in a potential game then the system designer can utilize distributed learning algorithms for potential games to complete step (ii) of the design process. Unfortunately, designing agent objective functions to meet objectives such as locality of information and efficiency of resulting equilibria within the framework of potential games is fundamentally challenging and in many case impossible. In this paper we develop a systematic methodology for meeting these objectives using a broader framework of games termed state based potential games. State based potential games is an extension of potential games where an additional state variable is introduced into the game environment hence permitting more flexibility in our design space. Furthermore, state based potential games possess an underlying structure that can be exploited by distributed learning algorithms in a similar fashion to potential games hence providing a new baseline for our decomposition.","Games,
Estimation,
Algorithm design and analysis,
Multiagent systems,
Cost function,
Game theory"
Collaborative Learning Using Wiki Web Sites for Computer Science Undergraduate Education: A Case Study,"This paper proposes a collaborative approach to enhancing the student learning experience based on Web 2.0 principles. Specifically, wiki Web sites are used by students for collaboration and for publication of course assignments, which are then shared with the class. Web 2.0 principles include: the Web as platform, harnessing collective intelligence, data are the next Intel Inside, and rich user experiences. Based on a case study in a junior-level undergraduate class, this paper studies a set of six factors with comprehensive grading and evaluation criteria that are critical to make this approach successful. The six factors are knowledge base, motivation, research, social aspects, presentation, and feedback and support. The data collected show that most of the students who participated feel that this approach is exciting and rewarding, and that even some undergraduate students are able to produce original and innovative concepts. The data also show other interesting phenomena with respect to motivation, undergraduate research, and social aspects. Finally, the paper proposes a methodology of conducting a wiki project in a university class using a cyclic constant improvement process.","Web sites,
Education,
Materials,
Software,
Collaboration,
Computer science,
Blogs"
Mind the gap - robotic grasping under incomplete observation,"We consider the problem of grasp and manipulation planning when the state of the world is only partially observable. Specifically, we address the task of picking up unknown objects from a table top. The proposed approach to object shape prediction aims at closing the knowledge gaps in the robot's understanding of the world. A completed state estimate of the environment can then be provided to a simulator in which stable grasps and collision-free movements are planned. The proposed approach is based on the observation that many objects commonly in use in a service robotic scenario possess symmetries. We search for the optimal parameters of these symmetries given visibility constraints. Once found, the point cloud is completed and a surface mesh reconstructed. Quantitative experiments show that the predictions are valid approximations of the real object shape. By demonstrating the approach on two very different robotic platforms its generality is emphasized.","Robots,
Shape,
Planning,
Grasping,
Image reconstruction,
Surface reconstruction,
Approximation methods"
Multirobot Tree and Graph Exploration,"In this paper, we present an algorithm for the exploration of an unknown graph by multiple robots, which is never worse than depth-first search with a single robot. On trees, we prove that the algorithm is optimal for two robots. For k robots, the algorithm has an optimal dependence on the size of the tree but not on its radius. We believe that the algorithm performs well on any tree, and this is substantiated by simulations. For trees with e edges and radius r, the exploration time is less than 2e/k + (1 + (k/r))k-1 (2/k!)rk-1 = (2e/k) + O((k + r)k-1) (for r >; k, <; (2e/k) + 2rk-1), thereby improving a recent method with time O((e/logk) + r) [2], and almost reaching the lower bound max((2e/k), 2r). The model underlying undirected-graph exploration is a set of rooms connected by opaque passages; thus, the algorithm is appropriate for scenarios like indoor navigation or cave exploration. In this framework, communication can be realized by bookkeeping devices being dropped by the robots at explored vertices, the states of which are read and changed by further visiting robots. Simulations have been performed in both tree and graph explorations to corroborate the mathematical results.",
From partial shape matching through local deformation to robust global shape similarity for object detection,"In this paper, we propose a novel framework for contour based object detection. Compared to previous work, our contribution is three-fold. 1) A novel shape matching scheme suitable for partial matching of edge fragments. The shape descriptor has the same geometric units as shape context but our shape representation is not histogram based. 2) Grouping of partial matching hypotheses to object detection hypotheses is expressed as maximum clique inference on a weighted graph. 3) A novel local affine-transformation to utilize the holistic shape information for scoring and ranking the shape similarity hypotheses. Consequently, each detection result not only identifies the location of the target object in the image, but also provides a precise location of its contours, since we transform a complete model contour to the image. Very competitive results on ETHZ dataset, obtained in a pure shape-based framework, demonstrate that our method achieves not only accurate object detection but also precise contour localization on cluttered background.","Shape,
Image edge detection,
Object detection,
Context,
Deformable models,
Transmission line matrix methods,
Image color analysis"
A Novel Rate Control Technique for Multiview Video Plus Depth Based 3D Video Coding,"This paper presents a novel rate control technique for multiview video plus depth (MVD) based 3D video coding. In the proposed rate control technique, an image-stitching method is first utilized to simultaneously encode video and depth, and then a joint rate control algorithm for MVD is presented. The joint rate control algorithm is performed on three levels, namely view level, video/depth level and frame level. In the view level, different proportions of rates are allocated for different types of views according to the pre-statistical rate allocation. In the video/depth level, the target rates for video and depth are discriminatorily assigned to guarantee the high quality of video for the backward-compatible display. In the frame level, the hierarchical rate allocation is used to regulate the target bits for each frame. In addition to the above mentioned rate control strategies, according to the special characteristics of multiview hypothetical reference decoder (HRD), the buffer-related rate control is also considered to prevent the decoder buffer from overflow or underflow even outputting multiple views. Experimental results show that the proposed rate control technique can accurately control the bit-rate to satisfy the requirements of 3D video systems.","Streaming media,
Three dimensional displays,
Resource management,
Encoding,
Video coding,
Image coding,
Joints"
On the Hardness of Approximating the Network Coding Capacity,"This work addresses the computational complexity of achieving the capacity of a general network coding instance. It has been shown [Lehman and Lehman, SODA 2005] that determining the “scalar linear” capacity of a general network coding instance is NP-hard. In this paper we address the notion of approximation in the context of both linear and nonlinear network coding. Loosely speaking, we show that given an instance of the general network coding problem of capacity C , constructing a code of rate αC for any universal (i.e., independent of the size of the instance) constant α ≤ 1 is “hard”. Specifically, finding such network codes would solve a long standing open problem in the field of graph coloring. Our results refer to scalar linear, vector linear, and nonlinear encoding functions and are the first results that address the computational complexity of achieving the network coding capacity in both the vector linear and general network coding scenarios. In addition, we consider the problem of determining the (scalar) linear capacity of a planar network coding instance (i.e., an instance in which the underlying graph is planar). We show that even for planar networks this problem remains NP-hard.","Network coding,
Encoding,
Color,
Decoding,
Vectors,
Approximation methods,
Polynomials"
Design of a CMOS On-Chip Slot Antenna With Extremely Flat Cavity at 140 GHz,"A novel design for a fully on-chip antenna operating at 140 GHz that can be fabricated with standard CMOS technology is proposed. In addition to the traditional microstrip feeding, the slot antenna is backed with an extremely thin cavity formed by two CMOS inner metal layers and vias in between. The proposed cavity prevents radiation from going inside the lossy silicon substrate and enhances the radiation of the slot antenna. It is also shown that the antenna radiation is not affected significantly by other metallic parts on the chip. Good agreement is achieved between results from a frequency-domain solver, HFSS, and a time-domain solver, CST. The simulated gain is around -2 dBi, and the radiation efficiency is around 18%, despite ohmic losses enhanced by the extreme flatness. The input 10-dB bandwidth is around 5 GHz. The total area of this antenna is 1.2 × 0.6 mm2 (0.56 λ0 × 0.28 λ0 at 140 GHz).","Cavity resonators,
Gain,
Metals,
Slot antennas,
CMOS integrated circuits,
Substrates"
Wearable tactile keypad with stretchable artificial skin,"A hyperelastic, thin, transparent pressure sensitive keypad is fabricated by embedding a silicone rubber film with conductive liquid-filled microchannels. Applying pressure to the surface of the elastomer deforms the cross-section of underlying microchannels and changes the electrical resistance across the affected channels. Perpendicular conductive channels form a quasi-planar network within an elastomeric matrix that registers the location, intensity and duration of applied pressure. Pressing channel intersections of the keypad triggers one of twelve keys, allowing the user to write any combination of alphabetic letters. A 5% change in channel output voltage must be achieved to trigger a key. It is found that approximately 100 kPa of pressure is necessary to produce a 5% change in voltage across a conductive microchannel that is 20 microns in height and 200 microns in width. Sensitivity of the keypad is tunable via channel geometry and choice of elastomeric material.","Robot sensing systems,
Microchannel,
Silicon,
Resistance"
Cooperative spectrum management in cognitive Vehicular Ad Hoc Networks,"In recent years, Cognitive Radio (CR) technology has received significant attention from the research community as it enables on-demand spectrum utilization, based on the requests of the end-users. An interesting application area of CR technology is Vehicular Ad Hoc Networks (VANETs). In such networks, several innovative services and applications based on inter-vehicular communication have strict requirements in terms of bandwidth and delay, which might not be guaranteed by a fixed spectrum allocation paradigm. In this paper, we propose two key contributions pertaining to CR-VANETs: (i) an experimental study of the spectrum availability and sensing accuracy in a moving vehicle and (ii) a collaborative spectrum management framework (called Cog-V2V), which allows the vehicles to share spectrum information, and to detect spectrum opportunities in the licensed band. As part of this framework, we design a collaborative sensing and decision algorithm, enabling the vehicles to share spectrum information and to know in advance the spectrum availability at future locations along their motion paths. The simulation results, produced through a novel integrated simulation platform for CR networks, reveal significant improvements of Cog-V2V in sensing accuracy and pair-wise communication performance compared to classical fixed spectrum approaches.","Vehicles,
Sensors,
Availability,
Accuracy,
Urban areas,
Correlation,
Databases"
Automatic Identification of Functional Clusters in fMRI Data Using Spatial Dependence,"In independent component analysis (ICA) of functional magnetic resonance imaging (fMRI) data, extracting a large number of maximally independent components provides a detailed functional segmentation of brain. However, such high-order segmentation does not establish the relationships among different brain networks, and also studying and classifying components can be challenging. In this study, we present a multidimensional ICA (MICA) scheme to achieve automatic component clustering. In our MICA framework, stable components are hierarchically grouped into clusters based on higher order statistical dependence-mutual information-among spatial components, instead of the typically used temporal correlation among time courses. The final cluster membership is determined using a statistical hypothesis testing method. Since ICA decomposition takes into account the modulation of the spatial maps, i.e., temporal information, our ICA-based approach incorporates both spatial and temporal information effectively. Our experimental results from both simulated and real fMRI datasets show that the use of spatial dependence leads to physiologically meaningful connectivity structure of brain networks, which is consistently identified across various ICA model orders and algorithms. In addition, we observe that components related to artifacts, including cerebrospinal fluid, arteries, and large draining veins, are grouped together and encouragingly distinguished from other components of interest.","Visualization,
Reliability,
Correlation,
Mutual information,
Independent component analysis,
Integrated circuits,
Physiology"
Improvement in LEACH protocol for large-scale wireless sensor networks,"As the use of wireless sensor networks (WSNs) has grown enormously in the past few decades, the need of scalable & energy efficient routing and data aggregation protocol for large-scale deployments has also risen. LEACH is a hierarchical clustering protocol that provides an elegant solution for such protocols. One deficiency that affects the performance of the protocol is existence of very large and very small clusters in the network at the same time. This leads to the decrease in lifetime of WSNs. In this paper, we propose and analyze a new energy efficient clustering protocol (FZ-LEACH) that eliminates the above problem by forming Far-Zone. Far-Zone is a group of sensor nodes which are placed at locations where their energies are less than a threshold. The simulation results and analysis show that proposed FZ-LEACH algorithm outperforms LEACH in terms of energy consumption and network lifetime.","Protocols,
Base stations,
Wireless sensor networks,
Clustering algorithms,
Energy consumption,
Energy states,
Energy efficiency"
Human-robot proxemics: Physical and psychological distancing in human-robot interaction,"To seamlessly integrate into the human physical and social environment, robots must display appropriate proxemic behavior-that is, follow societal norms in establishing their physical and psychological distancing with people. Social-scientific theories suggest competing models of human proxemic behavior, but all conclude that individuals' proxemic behavior is shaped by the proxemic behavior of others and the individual's psychological closeness to them. The present study explores whether these models can also explain how people physically and psychologically distance themselves from robots and suggest guidelines for future design of proxemic behaviors for robots. In a controlled laboratory experiment, participants interacted with Wakamaru to perform two tasks that examined physical and psychological distancing of the participants. We manipulated the likeability (likeable/dislikeable) and gaze behavior (mutual gaze/averted gaze) of the robot. Our results on physical distancing showed that participants who disliked the robot compensated for the increase in the robot's gaze by maintaining a greater physical distance from the robot, while participants who liked the robot did not differ in their distancing from the robot across gaze conditions. The results on psychological distancing suggest that those who disliked the robot also disclosed less to the robot. Our results offer guidelines for the design of appropriate proxemic behaviors for robots so as to facilitate effective human-robot interaction.",
MRI-Compatible Intensity-Modulated Force Sensor for Cardiac Catheterization Procedures,"This paper presents a novel, magnetic resonance imaging (MRI)-compatible, force sensor suitable for cardiac catheterization procedures. The miniature, fiber-optic sensor is integrated with the tip of a catheter to allow the detection of interaction forces with the cardiac walls. The optical fiber light intensity is modulated when a force acting at the catheter tip deforms an elastic element, which, in turn, varies the distance between a reflector and the optical fiber. The tip sensor has an external diameter of 9 Fr (3 mm) and can be used during cardiac catheterization procedures. The sensor is able to measure forces in the range of 0-0.85 N, with relatively small hysteresis. A nonlinear method for calibration is used and real-time MRI in vivo experiments are carried out, to prove the feasibility of this low-cost sensor, enabling the detection of catheter-tip contact forces under dynamic conditions.",
Intrinsic images using optimization,"In this paper, we present a novel intrinsic image recovery approach using optimization. Our approach is based on the assumption of in a local window in natural images. Our method adopts a premise that neighboring pixels in a local window of a single image having similar intensity values should have similar reflectance values. Thus the intrinsic image decomposition is formulated by optimizing an energy function with adding a weighting constraint to the local image properties. In order to improve the intrinsic image extraction results, we specify local constrain cues by integrating the user strokes in our energy formulation, including constant-reflectance, constant-illumination and fixed-illumination brushes. Our experimental results demonstrate that our approach achieves a better recovery of intrinsic reflectance and illumination components than by previous approaches.",
A Robust Image Alignment Algorithm for Video Stabilization Purposes,"Today, many people in the world without any (or with little) knowledge about video recording, thanks to the widespread use of mobile devices (personal digital assistants, mobile phones, etc.), take videos. However, the unwanted movements of their hands typically blur and introduce disturbing jerkiness in the recorded sequences. Many video stabilization techniques have been hence developed with different performances but only fast strategies can be implemented on embedded devices. A fundamental issue is the overall robustness with respect to different scene contents (indoor, outdoor, etc.) and conditions (illumination changes, moving objects, etc.). In this paper, we propose a fast and robust image alignment algorithm for video stabilization purposes. Our contribution is twofold: a fast and accurate block-based local motion estimator together with a robust alignment algorithm based on voting. Experimental results confirm the effectiveness of both local and global motion estimators.","IP networks,
Robustness,
Lighting,
Motion estimation,
Complexity theory,
Mathematical model,
Cameras"
Padding for orthogonality: Efficient subspace authentication for network coding,"Network coding provides a promising alternative to traditional store-and-forward transmission paradigm. However, due to its information-mixing nature, network coding is notoriously susceptible to pollution attacks: a single polluted packet can end up corrupting bunches of good ones. Existing authentication mechanisms either incur high computation/bandwidth overheads, or cannot resist the tag pollution proposed recently. This paper presents a novel idea termed “padding for orthogonality” for network coding authentication. Inspired by it, we design a public-key based signature scheme and a symmetric-key based MAC scheme, which can both effectively contain pollution attacks at forwarders. In particular, we combine them to propose a unified scheme termed MacSig, the first hybrid-key cryptographic approach to network coding authentication. It can thwart both normal pollution and tag pollution attacks in an efficient way. Simulative results show that our MacSig scheme has a low bandwidth overhead, and a verification process 2-4 times faster than typical signature-based solutions in some circumstances.",
Generalized Tree-Based Wavelet Transform,"In this paper we propose a new wavelet transform applicable to functions defined on high dimensional data, weighted graphs and networks. The proposed method generalizes the Haar-like transform recently introduced by Gavish , and can also construct data adaptive orthonormal wavelets beyond Haar. It is defined via a hierarchical tree, which is assumed to capture the geometry and structure of the input data, and is applied to the data using a modified version of the common one-dimensional (1D) wavelet filtering and decimation scheme. The adaptivity of this wavelet scheme is obtained by permutations derived from the tree and applied to the approximation coefficients in each decomposition level, before they are filtered. We show that the proposed transform is more efficient than both the 1D and two-dimension 2D separable wavelet transforms in representing images. We also explore the application of the proposed transform to image denoising, and show that combined with a subimage averaging scheme, it achieves denoising results which are similar to those obtained with the K-SVD algorithm.",
Illumination-Sensitive Background Modeling Approach for Accurate Moving Object Detection,"Background subtraction involves generating the background model from the video sequence to detect the foreground and object for many computer vision applications, including traffic security, human-machine interaction, object recognition, and so on. In general, many background subtraction approaches cannot update the current status of the background image in scenes with sudden illumination change. This is especially true in regard to motion detection when light is suddenly switched on or off. This paper proposes an illumination-sensitive background modeling approach to analyze the illumination change and detect moving objects. For the sudden illumination change, an illumination evaluation is used to determine two background candidates, including a light background image and a dark background image. Based on the background model and illumination evaluation, the binary mask of moving objects can be generated by the proposed thresholding function. Experimental results demonstrate the effectiveness of the proposed approach in providing a promising detection outcome and low computational cost.",
"Near-Capacity Wireless Transceivers and Cooperative Communications in the MIMO Era: Evolution of Standards, Waveform Design, and Future Perspectives","Classic Shannon theory suggests that the achievable channel capacity increases logarithmically with the transmit power. By contrast, the MIMO capacity increases linearly with the number of transmit antennas, provided that the number of receive antennas is equal to the number of transmit antennas. With the further proviso that the total transmit power is increased proportionately to the number of transmit antennas, a linear capacity increase is achieved upon increasing the transmit power, which justifies the spectacular success of MIMOs. Hence we may argue that MIMO-aided transceivers and their cooperation-assisted distributed or virtual MIMO counterparts constitute power-efficient solutions. In a nutshell, since the conception of GSM in excess of three orders of magnitude bit-rate improvements were achieved in three decades, which corresponds to about a factor ten for each decade, because GSM had a data rate of 9.6 Kb/s, while HSDPA is capable of communicating at 13.7 Mb/s. However, the possible transmit power reductions remained more limited, even when using the most advanced multistage iterative detectors, since the required received signal power has not been reduced by as much as 30 dB. This plausible observation motivates the further research of advanced cooperation-aided wireless MIMO transceivers, as detailed in this treatise.","MIMO,
Multiaccess communication,
Transceivers,
Mobile communication,
GSM,
Signal to noise ratio"
Robust Methodology for Fractal Analysis of the Retinal Vasculature,"We have developed a robust method to perform retinal vascular fractal analysis from digital retina images. The technique preprocesses the green channel retina images with Gabor wavelet transforms to enhance the retinal images. Fourier Fractal dimension is computed on these preprocessed images and does not require any segmentation of the vessels. This novel technique requires human input only at a single step; the allocation of the optic disk center. We have tested this technique on 380 retina images from healthy individuals aged 50+ years, randomly selected from the Blue Mountains Eye Study population. To assess its reliability in assessing retinal vascular fractals from different allocation of optic center, we performed pair-wise Pearson correlation between the fractal dimension estimates with 100 simulated region of interest for each of the 380 images. There was Gaussian distribution variation in the optic center allocation in each simulation. The resulting mean correlation coefficient (standard deviation) was 0.93 (0.005). The repeatability of this method was found to be better than the earlier box-counting method. Using this method to assess retinal vascular fractals, we have also confirmed a reduction in the retinal vasculature complexity with aging, consistent with observations from other human organ systems.","Retina,
Fractals,
Optical imaging,
Wavelet transforms,
Adaptive optics,
Australia,
Noise"
Trimmed-Likelihood Estimation for Focal Lesions and Tissue Segmentation in Multisequence MRI for Multiple Sclerosis,"We present a new automatic method for segmentation of multiple sclerosis (MS) lesions in magnetic resonance images. The method performs tissue classification using a model of intensities of the normal appearing brain tissues. In order to estimate the model, a trimmed likelihood estimator is initialized with a hierarchical random approach in order to be robust to MS lesions and other outliers present in real images. The algorithm is first evaluated with simulated images to assess the importance of the robust estimator in presence of outliers. The method is then validated using clinical data in which MS lesions were delineated manually by several experts. Our method obtains an average Dice similarity coefficient (DSC) of 0.65, which is close to the average DSC obtained by raters (0.66).",
On Combining Computer-Aided Detection Systems,"Computer-aided detection (CAD) is increasingly used in clinical practice and for many applications a multitude of CAD systems have been developed. In practice, CAD systems have different strengths and weaknesses and it is therefore interesting to consider their combination. In this paper, we present generic methods to combine multiple CAD systems and investigate what kind of performance increase can be expected. Experimental results are presented using data from the ANODE09 and ROC09 online CAD challenges for the detection of pulmonary nodules in computed tomography scans and red lesions in retinal images, respectively. For both applications, combination results in a large and significant increase in performance when compared to the best individual CAD system.","Design automation,
Lesions,
Training,
Computed tomography,
Lungs,
Strontium,
Biomedical imaging"
Parametric Shape Representation by a Deformable NURBS Model for Cardiac Functional Measurements,"This paper proposes a method of parametric representation and functional measurement of 3-D cardiac shapes in a deformable nonuniform rational B-splines (NURBS) model. This representation makes it very easy to automatically evaluate the functional parameters and myocardial kinetics of the heart, since quantitative analysis can be followed in a simple way. In the model, local deformation and motion on the cardiac shape are expressed in adjustable parameters. Especially, an effective integral algorithm is used for volumetric measurement of a NURBS shape since the volume is the most basic parameter in cardiac functional analysis. This method promises the numerical computation to be very convenient, efficient, and accurate, in comparison with traditional methods. Practical experiments are carried out, and results show that the algorithm can get satisfactory measurement accuracy and efficiency. The parametric NURBS model in cylindrical coordinates is not only very suitable to fit the anatomical surfaces of a cardiac shape, but also easy for geometric transformation and nonrigid registration, and able to represent local dynamics and kinetics, and thus, can easily be applied for quantitative and functional analysis of the heart.","Spline,
Shape,
Surface topography,
Surface reconstruction,
Three dimensional displays,
Kinetic theory,
Heart"
Piezoresistive Strain Sensors and Multiplexed Arrays Using Assemblies of Single-Crystalline Silicon Nanoribbons on Plastic Substrates,"This paper describes the fabrication and properties of flexible strain sensors that use thin ribbons of single-crystalline silicon on plastic substrates. The devices exhibit gauge factors of 43, measured by applying uniaxial tensile strain, with good repeatability and agreement with expectation based on finite-element modeling and literature values for the piezoresistivity of silicon. Using Wheatstone bridge configurations integrated with multiplexing diodes, these devices can be integrated into large-area arrays for strain mapping. High sensitivity and good stability suggest promise for the various sensing applications.","Silicon,
Strain,
Sensors,
Substrates,
Resistors,
Multiplexing,
Piezoresistance"
Interactive Exploration and Analysis of Large-Scale Simulations Using Topology-Based Data Segmentation,"Large-scale simulations are increasingly being used to study complex scientific and engineering phenomena. As a result, advanced visualization and data analysis are also becoming an integral part of the scientific process. Often, a key step in extracting insight from these large simulations involves the definition, extraction, and evaluation of features in the space and time coordinates of the solution. However, in many applications, these features involve a range of parameters and decisions that will affect the quality and direction of the analysis. Examples include particular level sets of a specific scalar field, or local inequalities between derived quantities. A critical step in the analysis is to understand how these arbitrary parameters/decisions impact the statistical properties of the features, since such a characterization will help to evaluate the conclusions of the analysis as a whole. We present a new topological framework that in a single-pass extracts and encodes entire families of possible features definitions as well as their statistical properties. For each time step we construct a hierarchical merge tree a highly compact, yet flexible feature representation. While this data structure is more than two orders of magnitude smaller than the raw simulation data it allows us to extract a set of features for any given parameter selection in a postprocessing step. Furthermore, we augment the trees with additional attributes making it possible to gather a large number of useful global, local, as well as conditional statistic that would otherwise be extremely difficult to compile. We also use this representation to create tracking graphs that describe the temporal evolution of the features over time. Our system provides a linked-view interface to explore the time-evolution of the graph interactively alongside the segmentation, thus making it possible to perform extensive data analysis in a very efficient manner. We demonstrate our framework by extracting and analyzing burning cells from a large-scale turbulent combustion simulation. In particular, we show how the statistical analysis enabled by our techniques provides new insight into the combustion process.",
Laser- and Heavy Ion-Induced Charge Collection in Bulk FinFETs,"Through-wafer two-photon absorption laser experiments were performed on bulk FinFETs. Transients show distinct signatures for charge collection from drift and diffusion, demonstrating the contribution of charge generated in the substrate to the charge collection process. This result was validated through heavy ion testing on more advanced bulk FinFETs with fin widths as narrow as 5 nm. The drain region dominates the charge collection, with as much as 45 fC of charge collected in the drain region.",
Coding-Based Data Broadcast Scheduling in On-Demand Broadcast,"According to data broadcast, we can satisfy multiple requests for the same data item in a broadcast tick. However, there is no significant breakthrough in performance improvement until recently that some studies proposed to use network coding in data broadcast. After broadcasting an encoded packet which encodes a number of data items, multiple clients can retrieve different requested data items in a broadcast tick. This not only utilizes bandwidth more efficiently, but also improves system performance. In this work, we propose a generalized encoding framework to incorporate network coding into data scheduling algorithms for on-demand broadcast. In the framework, data scheduling can be formulated as a weighted maximum clique problem in a graph where the weight of the clique is defined according to the performance objectives of the applications. Under the proposed framework, existing data scheduling algorithms for on-demand broadcast can be migrated into their corresponding coding versions while preserving their original criteria in scheduling data items. Our simulation results using a number of representative scheduling algorithms show that significant performance improvement can be achieved with coding.","Encoding,
Servers,
Network coding,
Scheduling algorithm,
Databases,
Heuristic algorithms"
Hedging Against Uncertainty: A Tale of Internet Data Center Operations Under Smart Grid Environment,"Internet Data Center (IDC) supports the reliable operations of many important online services. As the demand of Internet services and cloud computing keep increasing in recent years, the power usage associated with IDC operations had been surging significantly. Such mass power consumption has brought heavy burden on IDC operators. Recently there are extensive research on power management for IDCs. However, one important challenge faced by IDC operators has been overlooked. How to handle the uncertainties in IDC operations is a challenging task. The uncertainties come from both the dynamic workload and time-varying electricity prices. In this paper, we systematically investigate the problem of minimizing the operation risk of IDCs against those uncertainties at the same time guaranteeing quality of service under deregulated electricity market environment. We propose a novel hedging scheme and model the operation risk minimization problem as a bilevel programming. We also design an optimal hedging algorithm. We conduct extensive evaluations based on real-life workload data from Google and electricity price data from deregulated electricity market for multiple IDC locations. Results show that our scheme can significantly reduce the operation risk by countering the uncertainties.","Electricity,
Uncertainty,
Servers,
Forward contracts,
Electricity supply industry,
Google,
Cost function"
Spatio-Temporally Consistent Novel View Synthesis Algorithm From Video-Plus-Depth Sequences for Autostereoscopic Displays,"In this paper, we propose a novel algorithm to generate multiple virtual views from a video-plus-depth sequence for modern autostereoscopic displays. To synthesize realistic content in the disocclusion regions at the virtual views is the main challenging problem for this task. Spatial coherence and temporal consistency are the two key factors to produce perceptually satisfactory virtual images. The proposed algorithm employs the spatio-temporal consistency constraint to handle the uncertain pixels in the disocclusion regions. On the one hand, regarding the spatial coherence, we incorporate the intensity gradient strength with the depth information to determine the filling priority for inpainting the disocclusion regions, so that the continuity of image structures can be preserved. On the other hand, the temporal consistency is enforced by estimating the intensities in the disocclusion regions across the adjacent frames with an optimization process. We propose an iterative re-weighted framework to jointly consider intensity and depth consistency in the adjacent frames, which not only imposes temporal consistency but also reduces noise disturbance. Finally, for accelerating the multi-view synthesis process, we apply the proposed view synthesis algorithm to generate the intensity and depth maps at the leftmost and rightmost viewpoints, so that the intermediate views are efficiently interpolated through image warping according to the associated depth maps between the two synthesized images and their corresponding symmetric depths. In the experimental validation, we perform quantitative evaluation on synthetic data as well as subjective assessment on real video data with comparison to some representative methods to demonstrate the superior performance of the proposed algorithm.","Pixel,
Three dimensional displays,
Interpolation,
Image color analysis,
Noise,
Coherence,
Observers"
On the Performance of Indirect Encoding Across the Continuum of Regularity,"This paper investigates how an evolutionary algorithm with an indirect encoding exploits the property of phenotypic regularity, an important design principle found in natural organisms and engineered designs. We present the first comprehensive study showing that such phenotypic regularity enables an indirect encoding to outperform direct encoding controls as problem regularity increases. Such an ability to produce regular solutions that can exploit the regularity of problems is an important prerequisite if evolutionary algorithms are to scale to high-dimensional real-world problems, which typically contain many regularities, both known and unrecognized. The indirect encoding in this case study is HyperNEAT, which evolves artificial neural networks (ANNs) in a manner inspired by concepts from biological development. We demonstrate that, in contrast to two direct encoding controls, HyperNEAT produces both regular behaviors and regular ANNs, which enables HyperNEAT to significantly outperform the direct encodings as regularity increases in three problem domains. We also show that the types of regularities HyperNEAT produces can be biased, allowing domain knowledge and preferences to be injected into the search. Finally, we examine the downside of a bias toward regularity. Even when a solution is mainly regular, some irregularity may be needed to perfect its functionality. This insight is illustrated by a new algorithm called HybrID that hybridizes indirect and direct encodings, which matched HyperNEAT's performance on regular problems yet outperformed it on problems with some irregularity. HybrID's ability to improve upon the performance of HyperNEAT raises the question of whether indirect encodings may ultimately excel not as stand-alone algorithms, but by being hybridized with a further process of refinement, wherein the indirect encoding produces patterns that exploit problem regularity and the refining process modifies that pattern to capture irregularities. This paper thus paints a more complete picture of indirect encodings than prior studies because it analyzes the impact of the continuum between irregularity and regularity on the performance of such encodings, and ultimately suggests a path forward that combines indirect encodings with a separate process of refinement.","Encoding,
Artificial neural networks,
Organisms,
Genomics,
Bioinformatics,
Evolution (biology),
Topology"
Emulation-Based Virtual Laboratories: A Low-Cost Alternative to Physical Experiments in Control Engineering Education,This paper argues the case for emulation-based virtual laboratories in control engineering education. It demonstrates that such emulation experiments can give students an industrially relevant educational experience at relatively low cost. The paper also describes a particular emulation-based system that has been developed with the aim of giving students an introduction to real-world control engineering design.,"Laboratories,
Emulation,
Education,
User interfaces,
Actuators,
Mathematical model"
Designing Buildings for Real Occupants: An Agent-Based Approach,"Building information modeling is only beginning to incorporate human factors, although buildings are sites where humans and technologies interact with globally significant consequences. Some buildings fail to perform as their designers intended, in part because users do not or cannot properly operate the building, and some occupants behave differently than designers expect. Innovative buildings, e.g., green buildings, are particularly susceptible to usability problems. This paper presents a framework for prospectively measuring the usability of designs before buildings are constructed, while there is still time to improve the design. The framework, which was implemented as an agent-based computer simulation model, tests how well buildings are likely to perform, given realistic occupants. An illustrative model for lighting design shows that this modeling approach has practical efficacy, demonstrating that, to the extent that users exhibit heterogeneous behaviors and preferences, designs that allow greater local control and ease of operation perform better.",
Efficient track linking methods for track graphs using network-flow and set-cover techniques,"This paper proposes novel algorithms that use network-flow and set-cover techniques to perform occlusion reasoning for a large number of small, moving objects in single or multiple views. We designed a track-linking framework for reasoning about short-term and long-term occlusions. We introduce a two-stage network-flow process to automatically construct a “track graph” that describes the track merging and splitting events caused by occlusion. To explain short-term occlusions, when local information is sufficient to distinguish objects, the process links trajectory segments through a series of optimal bipartite-graph matches. To resolve long-term occlusions, when global information is needed to characterize objects, the linking process computes a logarithmic approximation solution to the set cover problem. If multiple views are available, our method builds a track graph, independently for each view, and then simultaneously links track segments from each graph, solving a joint set cover problem for which a logarithmic approximation also exists. Through experiments on different datasets, we show that our proposed linear and integer optimization techniques make the track graph a particularly useful tool for tracking large groups of individuals in images.",
Generating Descriptive Visual Words and Visual Phrases for Large-Scale Image Applications,"Bag-of-visual Words (BoWs) representation has been applied for various problems in the fields of multimedia and computer vision. The basic idea is to represent images as visual documents composed of repeatable and distinctive visual elements, which are comparable to the text words. Notwithstanding its great success and wide adoption, visual vocabulary created from single-image local descriptors is often shown to be not as effective as desired. In this paper, descriptive visual words (DVWs) and descriptive visual phrases (DVPs) are proposed as the visual correspondences to text words and phrases, where visual phrases refer to the frequently co-occurring visual word pairs. Since images are the carriers of visual objects and scenes, a descriptive visual element set can be composed by the visual words and their combinations which are effective in representing certain visual objects or scenes. Based on this idea, a general framework is proposed for generating DVWs and DVPs for image applications. In a large-scale image database containing 1506 object and scene categories, the visual words and visual word pairs descriptive to certain objects or scenes are identified and collected as the DVWs and DVPs. Experiments show that the DVWs and DVPs are informative and descriptive and, thus, are more comparable with the text words than the classic visual words. We apply the identified DVWs and DVPs in several applications including large-scale near-duplicated image retrieval, image search re-ranking, and object recognition. The combination of DVW and DVP performs better than the state of the art in large-scale near-duplicated image retrieval in terms of accuracy, efficiency and memory consumption. The proposed image search re-ranking algorithm: DWPRank outperforms the state-of-the-art algorithm by 12.4% in mean average precision and about 11 times faster in efficiency.",
On Attracting Basins of Multiple Equilibria of a Class of Cellular Neural Networks,"In this paper, we study the distribution of attraction basins of multiple equilibrium points of cellular neural networks (CNNs). Under several conditions, the boundaries of the attracting basins of the stable equilibria of a completely stable CNN system are composed of the closures of the stable manifolds of unstable equilibria of (n - 1) dimensions. As demonstrations of this idea, under the conditions proposed in the literature which depicts stable and unstable equilibria, we identify the attraction basin of each stable equilibrium of which the boundary is composed of the stable manifolds of the unstable equilibria precisely. We also investigate the attracting basins of a simple class of symmetric 1-D CNNs via identifying the unstable equilibria of which the stable manifold is (n - 1) dimensional and the completely stable asymmetric CNNs with stable equilibria less than 2n.",
A GPU-Accelerated Wavelet Decompression System With SPIHT and Reed-Solomon Decoding for Satellite Images,"The discrete wavelet transform (DWT)-based Set Partitioning in Hierarchical Trees (SPIHT) algorithm is widely used in many image compression systems. The time-consuming computation of the 9/7 discrete wavelet decomposition is usually the bottleneck of these systems. In order to perform real-time Reed-Solomon channel decoding and SPIHT+DWT source decoding on a massive bit stream of compressed images continuously down-linked from the satellite, we propose a novel graphic processing unit (GPU)-accelerated decoding system. In this system the GPU is used to compute the time-consuming inverse DWT, while multiple CPU threads are run in parallel for the remaining part of the system. Both CPU and GPU parts were carefully designed to have approximately the same processing speed to obtain the maximum throughput via a novel pipeline structure for processing continuous satellite images. As part of the SPIHT decoding system, the GPU-based inverse DWT is about 158 times faster than its CPU counterpart. Through the pipelined CPU and GPU heterogeneous computing, the entire decoding system approaches a speedup of 83x as compared to its single-threaded CPU counterpart. The proposed channel and source decoding system is able to decompress 1024x1024 satellite images at a speed of 90 frames per second.",
Optimizing Case-Based Detection Performance in a Multiview CAD System for Mammography,"When reading mammograms, radiologists combine information from multiple views to detect abnormalities. Most computer-aided detection (CAD) systems, however, use primitive methods for inclusion of multiview context or analyze each view independently. In previous research it was found that in mammography lesion-based detection performance of CAD systems can be improved when correspondences between MLO and CC views are taken into account. However, detection at case level detection did not improve. In this paper, we propose a new learning method for multiview CAD systems, which is aimed at optimizing case-based detection performance. The method builds on a single-view lesion detection system and a correspondence classifier. The latter provides class probabilities for the various types of region pairs and correspondence features. The correspondence classifier output is used to bias the selection of training patterns for a multiview CAD system. In this way training can be forced to focus on optimization of case-based detection performance. The method is applied to the problem of detecting malignant masses and architectural distortions. Experiments involve 454 mammograms consisting of four views with a malignant region visible in at least one of the views. To evaluate performance, five-fold cross validation and FROC analysis was performed. Bootstrapping was used for statistical analysis. A significant increase of case-based detection performance was found when the proposed method was used. Mean sensitivity increased by 4.7% in the range of 0.01-0.5 false positives per image.","Design automation,
Lesions,
Correlation,
Breast,
Pixel,
Histograms,
Artificial neural networks"
DelQue: A Socially Aware Delegation Query Scheme in Delay-Tolerant Networks,"In delay-tolerant networks (DTNs), information search is a significant topic that has yet to be widely investigated. Although social-based approaches can be used to address the problem, most existing schemes employ the multihop paradigm and leave out the severe resource constraint in DTNs. In this paper, we experimentally explore several realistic data sets and then reveal that users' one-hop neighbors can cover most range of the whole network in a reasonable time period, which lays a solid fundamental for two-hop information search schemes. Therefore, we propose DelQue (delegation query), which is a novel two-hop delegation query scheme integratedly considering query and response to save network energy in terms of the number of involved relays. In DelQue, we exploit the social utility of each neighbor to represent its capability to query interesting information and then colocate with the source to respond. Furthermore, we also present a spatio-temporal prediction method of user mobility to compute neighbors' utility. Such a lightweight forecasting technique only requires network users to maintain two parameters, making it suitable for a resource-scarce mobile setting. Extensive realistic trace-driven simulations show that DelQue allows for the maintenance of a very high and steady information query ratio with extremely low energy cost and, meanwhile, achieves comparable or shorter delays compared with some existing schemes.","Relays,
Mobile communication,
Communities,
Computational modeling,
Markov processes,
Mobile computing,
Delay"
Local energy storage sizing in plug-in hybrid electric vehicle charging stations under blocking probability constraints,"Plug-in hybrid electric vehicles (PHEV) are becoming gradually more attractive than internal combustion engine vehicles, even though the current electrical grid is not potentially able to support the required power demand increase to introduce charging stations. Acknowledging that design and development of charging stations has crucial importance, this paper introduces a candidate PHEV charging station architecture, along with a quantitative stochastic model, that allows us to analyze the performance of the system by using arguments from queuing theory and economics. A relevant component of the proposed architecture is the capability of the charging stations to store excess power obtained from the grid. The goal is to design a general architecture which will be able to sustain grid stability, while providing a required level of quality of service; and to describe a general methodology to analyze the performance of such stations with respect to the traffic characteristics, energy storage size, pricing and cost parameters. Our results indicate that significant gains in net cost/profit and useful insights can be made with the right choice of storage size. Such considerations are crucial in this early stage of designing the smart grid and charging stations of the future.","Vehicles,
Energy storage,
Stochastic processes,
Power demand,
Biological system modeling,
Smart grids,
Quality of service"
Efficient Decoding With Steady-State Kalman Filter in Neural Interface Systems,"The Kalman filter is commonly used in neural interface systems to decode neural activity and estimate the desired movement kinematics. We analyze a low-complexity Kalman filter implementation in which the filter gain is approximated by its steady-state form, computed offline before real-time decoding commences. We evaluate its performance using human motor cortical spike train data obtained from an intracortical recording array as part of an ongoing pilot clinical trial. We demonstrate that the standard Kalman filter gain converges to within 95% of the steady-state filter gain in 1.5 ± 0.5 s (mean ±s.d.). The difference in the intended movement velocity decoded by the two filters vanishes within 5 s, with a correlation coefficient of 0.99 between the two decoded velocities over the session length. We also find that the steady-state Kalman filter reduces the computational load (algorithm execution time) for decoding the firing rates of 25±3 single units by a factor of 7.0±0.9. We expect that the gain in computational efficiency will be much higher in systems with larger neural ensembles. The steady-state filter can thus provide substantial runtime efficiency at little cost in terms of estimation accuracy. This far more efficient neural decoding approach will facilitate the practical implementation of future large-dimensional, multisignal neural interface systems.","Decoding,
Kalman filters,
Steady-state,
Arrays,
Training,
Hospitals,
Clinical trials"
Distinguishing identical twins by face recognition,"The paper measures the ability of face recognition algorithms to distinguish between identical twin siblings. The experimental dataset consists of images taken of 126 pairs of identical twins (252 people) collected on the same day and 24 pairs of identical twins (48 people) with images collected one year apart. In terms of both the number of paris of twins and lapsed time between acquisitions, this is the most extensive investigation of face recognition performance on twins to date. Recognition experiments are conducted using three of the top submissions to the Multiple Biometric Evaluation (MBE) 2010 Still Face Track [1]. Performance results are reported for both same day and cross year matching. Performance results are broken out by lighting conditions (studio and outside); expression (neutral and smiling); gender and age. Confidence intervals were generated by a bootstrap method. This is the most detailed covariate analysis of face recognition of twins to date.","Face,
Lighting,
Face recognition,
Mobile communication,
Algorithm design and analysis,
Iris recognition,
Error analysis"
On Routing and Transmission-Range Determination of Multi-Bit-Rate Signals Over Mixed-Line-Rate WDM Optical Networks for Carrier Ethernet,"Ethernet's success in local area networks (LANs) is fueling the efforts to extend its reach to cover metro and long-haul networks. This new Ethernet is refereed to as Carrier Ethernet. Among the various transport infrastructures for realizing Carrier Ethernet, wavelength-division multiplexing (WDM) optical network is a strong candidate for this purpose. Optical transmission rates per channel are increasing from 10 to 40 Gb/s and even 100 Gb/s, and they can also coexist in the same fiber. Along with the flexibility associated with such a network with mixed-line rates (MLR), signal-related constraints at high rates become a challenge for cost-efficient routing. Among these issues is the maximum nonregenerated optical distance that a signal can travel before its quality degrades or maximum transmission range (TR). TR is rate-dependent: The higher the rate, the shorter the range. While high-rate pipes may require signal regeneration to restore the signal's quality, they support more traffic and, hence, can save resources. We study the problem of cost-efficient routing of multi-bit-rate (1/10/40/100 Gb/s) Ethernet tunnels using MLR over a carrier's WDM optical network with signal-transmission-range constraints. We studied the effect of TR for mixed-rate signals (10/40/100 Gb/s) on the network's cost to determine the optimal TR of each bit rate. We present an analytical model based on a mixed-integer linear program (MILP) to determine the optimal TR of a small network. Since MILP has scalability constraints that makes it hard or sometimes impossible to solve for real network topologies, we propose a graph-based solution that constructs a mixed-line-rate auxiliary (MLR-AUX) graph to capture the network's heterogeneity and a weight-assignment approach that allows the routing to be cost-efficient. Our algorithms were tested on a U.S. nationwide network topology. We found that it is possible to reduce the network's cost by using short TR and that the optimal TR depends strongly on traffic characteristics and on the TR values of different bit-rate signals.","Ethernet networks,
Routing,
Mathematical model,
Optical switches,
Equations,
Wavelength division multiplexing,
Throughput"
Cost-Sensitive Multi-Label Learning for Audio Tag Annotation and Retrieval,"Audio tags correspond to keywords that people use to describe different aspects of a music clip. With the explosive growth of digital music available on the Web, automatic audio tagging, which can be used to annotate unknown music or retrieve desirable music, is becoming increasingly important. This can be achieved by training a binary classifier for each tag based on the labeled music data. Our method that won the MIREX 2009 audio tagging competition is one of this kind of methods. However, since social tags are usually assigned by people with different levels of musical knowledge, they inevitably contain noisy information. By treating the tag counts as costs, we can model the audio tagging problem as a cost-sensitive classification problem. In addition, tag correlation information is useful for automatic audio tagging since some tags often co-occur. By considering the co-occurrences of tags, we can model the audio tagging problem as a multi-label classification problem. To exploit the tag count and correlation information jointly, we formulate the audio tagging task as a novel cost-sensitive multi-label (CSML) learning problem and propose two solutions to solve it. The experimental results demonstrate that the new approach outperforms our MIREX 2009 winning method.","Tagging,
Correlation,
Feature extraction,
Support vector machines,
Training,
Electronic mail,
Measurement"
Robust Output Feedback Control of a Class of Nonlinear Systems Using a Disturbance Observer,"This paper considers the output-tracking control problem of feedback linearizable nonlinear systems in the presence of external disturbances and modeling errors. A robust output feedback nonlinear controller is designed to achieve excellent output-tracking performance. By exploiting the cascade features of backstepping design, a simple disturbance observer (DOB) is proposed to suppress the effects of the uncertainties, and a high-gain observer (HGOB) is applied to estimate the unmeasureable states of the system. Although the DOB-based controllers are usually designed according to linear control theory, in this study, strict analysis of the nonlinear control system is given. Experimental results on a magnetic levitation system are provided to support the theoretical results and to verify the advantages of the proposed controller.","Robust control,
Output feedback,
Nonlinear control systems,
Control systems,
Nonlinear systems,
Observers,
Error correction,
Backstepping,
Uncertainty,
State estimation"
Network-Based Consensus Averaging With General Noisy Channels,"This paper focuses on the consensus averaging problem on graphs under general imperfect communications. We study a particular class of distributed consensus algorithms based on damped updates, and using the ordinary differential equation method, we prove that the updates converge almost surely to the consensus average for various models of perturbation of data exchanged between nodes. The convergence is not asymptotic in the size of the network. Our analysis applies to various types of stochastic disturbances to the updates, including errors in update calculations, dithered quantization and imperfect data exchange among nodes. Under a suitable stability condition, we prove that the error between estimated and true averages is asymptotically Gaussian, and we show how the asymptotic covariance is specified by the graph Laplacian. For additive perturbations, we show how the scaling of the asymptotic MSE is controlled by the spectral gap of the Laplacian.","Convergence,
Laplace equations,
Noise,
Protocols,
Stochastic processes,
Government,
Quantization"
An adaptive coupled-layer visual model for robust visual tracking,"This paper addresses the problem of tracking objects which undergo rapid and significant appearance changes. We propose a novel coupled-layer visual model that combines the target's global and local appearance. The local layer in this model is a set of local patches that geometrically constrain the changes in the target's appearance. This layer probabilistically adapts to the target's geometric deformation, while its structure is updated by removing and adding the local patches. The addition of the patches is constrained by the global layer that probabilistically models target's global visual properties such as color, shape and apparent local motion. The global visual properties are updated during tracking using the stable patches from the local layer. By this coupled constraint paradigm between the adaptation of the global and the local layer, we achieve a more robust tracking through significant appearance changes. Indeed, the experimental results on challenging sequences confirm that our tracker outperforms the related state-of-the-art trackers by having smaller failure rate as well as better accuracy.",
Predicting Metabolic Fluxes Using Gene Expression Differences As Constraints,"A standard approach to estimate intracellular fluxes on a genome-wide scale is flux-balance analysis (FBA), which optimizes an objective function subject to constraints on (relations between) fluxes. The performance of FBA models heavily depends on the relevance of the formulated objective function and the completeness of the defined constraints. Previous studies indicated that FBA predictions can be improved by adding regulatory on/off constraints. These constraints were imposed based on either absolute or relative gene expression values. We provide a new algorithm that directly uses regulatory up/down constraints based on gene expression data in FBA optimization (tFBA). Our assumption is that if the activity of a gene drastically changes from one condition to the other, the flux through the reaction controlled by that gene will change accordingly. We allow these constraints to be violated, to account for posttranscriptional control and noise in the data. These up/down constraints are less stringent than the on/off constraints as previously proposed. Nevertheless, we obtain promising predictions, since many up/down constraints can be enforced. The potential of the proposed method, tFBA, is demonstrated through the analysis of fluxes in yeast under nine different cultivation conditions, between which approximately 5,000 regulatory up/down constraints can be defined. We show that changes in gene expression are predictive for changes in fluxes. Additionally, we illustrate that flux distributions obtained with tFBA better fit transcriptomics data than previous methods. Finally, we compare tFBA and FBA predictions to show that our approach yields more biologically relevant results.","Gene expression,
Bioinformatics,
Constraint optimization,
Communication industry,
Computer industry,
Genomics,
Biochemistry,
Biomass,
Mathematics,
Computer science"
Experimental Study and Modeling of Group Retrieval in Ants as an Approach to Collective Transport in Swarm Robotic Systems,"Group food retrieval in some ant species serves as a useful paradigm for multirobot collective transport strategies that are decentralized, scalable, and do not require a priori information about the payload. We present a comprehensive overview of group retrieval in ants and investigate this phenomenon in Aphaenogaster cockerelli in order to extract the ants' roles during transport, the rules that govern their actions, and the individual forces that they apply to guide a food item to their nest. To measure these forces, we fabricated elastic structures with calibrated stiffness properties, induced ants to retrieve the structures, and tracked the resulting deformations with a camera. We then developed a hybrid system model of the ant behaviors that were observed in the experiments. We conducted simulations of the behavioral model that incorporate a quasi-static model of planar manipulation with compliant attachment points. Our simulations qualitatively replicate individual ant activity as well as certain macroscopic features of the transport.",
Vertical interconnects squeezing in symmetric 3D mesh Network-on-Chip,"Three-dimensional (3D) integration and Network-on-Chip (NoC) are both proposed to tackle the on-chip interconnect scaling problems, and extensive research efforts have been devoted to the design challenges of combining both. Through-silicon via (TSV) is considered to be the most promising technology for 3D integration, however, TSV pads distributed across planar layers occupy significant chip area and result in routing congestions. In addition, the yield of 3D integrated circuits decreased dramatically as the number of TSVs increases. For symmetric 3D mesh NoC, we observe that the TSVs' utilization is pretty low and adjacent routers rarely transmit packets via their vertical channels (i.e. TSVs) at the same time. Based on this observation, we propose a novel TSV squeezing scheme to share TSVs among neighboring router in a time division multiplex mode, which greatly improves the utilization of TSVs. Experimental results show that the proposed method can save significant TSV footprint with negligible performance overhead.","Through-silicon vias,
Three dimensional displays,
Pipelines,
Routing,
Throughput,
Computer architecture,
System-on-a-chip"
Reliable Confidence Measures for Medical Diagnosis With Evolutionary Algorithms,"Conformal Predictors (CPs) are machine learning algorithms that can provide predictions complemented with valid confidence measures. In medical diagnosis, such measures are highly desirable, as medical experts can gain additional information for each machine diagnosis. A risk assessment in each prediction can play an important role for medical decision making, in which the outcome can be critical for the patients. Several classical machine learning methods can be incorporated into the CP framework. In this paper, we propose a CP that makes use of evolved rule sets generated by a genetic algorithm (GA). The rule-based GA has the advantage of being human readable. We apply our method on two real-world datasets for medical diagnosis, one dataset for breast cancer diagnosis, which contains data gathered from fine needle aspirate of breast mass; and one dataset for ovarian cancer diagnosis, which contains proteomic patterns identified in serum. Our results on both datasets show that the proposed method is as accurate as the classical techniques, while it provides reliable and useful confidence measures.",
CORNER: A Radio Propagation Model for VANETs in Urban Scenarios,"Advances in portable technologies and emergence of new applications stimulate interest in urban vehicular communications for commercial, military, and homeland defense applications. Simulation is an essential tool to study the behavior and evaluate the performance of protocols and applications in large-scale urban vehicular ad hoc networks (VANET). In this paper, we propose CORNER, a low computational cost yet accurate urban propagation model for mobile networks. CORNER estimates the presence of buildings and obstacles along the signal path using information extrapolated from urban digital maps. A reverse geocoding algorithm is used to classify the propagation situation of any two nodes that need to communicate starting from their geographical coordinates. We classify the relative position of the sender and the receiver as in line of sight (LOS) or nonline of sight (NLOS). Based on this classification, we apply different formulas to compute the path loss (PL) metric. CORNER has been validated through extensive on-the-road experiments, the results show high accuracy in predicting the network connectivity. In addition, on-the-road experiments suggest the need to refine the fading model to differentiate between LOS, and NLOS situations. Finally, we show the impact of CORNER on simulation results for widely used applications.",
A 25 Gb/s(/km2) urban wireless network beyond IMT-advanced,"In this article we present a survey on the technical challenges of future radio access networks beyond LTE-Advanced, which could offer very high average area throughput to support a huge demand for data traffic and high user density with energy-efficient operation. We highlight various potential enabling technologies and architectures to support the aggressive goal of average area throughput 25 Gb/s/km2 in beyond IMT-Advanced systems. Specifically, we discuss the challenges and solutions from the controlling/ processing perspective, the radio resource management perspective, and the physical layer perspective for dense urban cell deployment. Using various advanced technologies such as interference mitigation techniques, MIMO, and cooperative communications as well as cross-layer self-organizing networks, we show that future urban wireless networks could potentially offer high-quality mobile services and offer an experience similar to the wired Internet.","Computer architecture,
Microprocessors,
Interference,
Mobile computing,
Macrocell networks,
Mobile communication,
Standards"
STT-RAM based energy-efficiency hybrid cache for CMPs,"Modern high performance Chip Multiprocessor (CMP) systems rely on large on-chip cache hierarchy. As technology scales down, the leakage power of present SRAM based cache gradually dominates the on-chip power consumption, which can severely jeopardize system performance. The emerging nonvolatile Spin Transfer Torque RAM (STT-RAM) is a promising candidate for large on-chip cache because of the ultra low leakage power. However, the write operations on STT-RAM suffer from considerably higher energy as well as longer latency compared with SRAM which will make STT-RAM in trouble for write-intensive workloads. In this paper, we propose to integrate SRAM with STT-RAM to construct a novel hybrid cache architecture for CMPs. We also propose dedicated microarchitectural mechanisms to make the hybrid cache robust to workloads with different write patterns. Extensive simulation results demonstrate that the proposed hybrid scheme is adaptive to variations of workloads. Overall power consumption is reduced by 37.1% and performance is improved by 23.6% on average compared with SRAM based static NUCA under the same area configuration.","Random access memory,
Power demand,
System-on-a-chip,
Hybrid power systems,
Radiation detectors,
Computer architecture,
Benchmark testing"
Privacy-Preserving Location-Based On-Demand Routing in MANETs,"Mobile Ad-Hoc Networks (MANETs) are particularly useful and well-suited for critical scenarios, including military, law enforcement as well as emergency rescue and disaster recovery. When operating in hostile or suspicious settings, MANETs require communication security and privacy, especially, in underlying routing protocols. Unlike most networks, where communication is based on long-term identities (addresses), we argue that the location-centric communication paradigm is better-suited for privacy in suspicious MANETs. To this end, we construct an on-demand location-based anonymous MANET routing protocol (PRISM) that achieves privacy and security against both outsider and insider adversaries. We analyze the security, privacy and performance of PRISM and compare it to alternative techniques. Results show that PRISM is more efficient and offers better privacy than prior work.","Ad hoc networks,
Mobile computing,
Privacy,
Network security,
Routing protocols,
Peer to peer computing,
Military communication"
Tracking body and hands for gesture recognition: NATOPS aircraft handling signals database,"We present a unified framework for body and hand tracking, the output of which can be used for understanding simultaneously performed body-and-hand gestures. The framework uses a stereo camera to collect 3D images, and tracks body and hand together, combining various existing techniques to make tracking tasks efficient. In addition, we introduce a multi-signal gesture database: the NATOPS aircraft handling signals. Unlike previous gesture databases, this data requires knowledge about both body and hand in order to distinguish gestures. It is also focused on a clearly defined gesture vocabulary from a real-world scenario that has been refined over many years. The database includes 24 body-and-hand gestures, and provides both gesture video clips and the body and hand features we extracted.","Joints,
Databases,
Pixel,
Three dimensional displays,
Feature extraction,
Computational modeling,
Shoulder"
Development of Laguerre Neural-Network-Based Intelligent Sensors for Wireless Sensor Networks,"The node of a wireless sensor network (WSN), which contains a sensor module with one or more physical sensors, may be exposed to widely varying environmental conditions, e.g., temperature, pressure, humidity, etc. Most of the sensor response characteristics are nonlinear, and in addition to that, other environmental parameters influence the sensor output nonlinearly. Therefore, to obtain accurate information from the sensors, it is important to linearize the sensor response and compensate for the undesirable environmental influences. In this paper, we present an intelligent technique using a novel computationally efficient Laguerre neural network (LaNN) to compensate for the inherent sensor nonlinearity and the environmental influences. Using the example of a capacitive pressure sensor, we have shown through extensive computer simulations that the proposed LaNN-based sensor can provide highly linearized output, such that the maximum full-scale error remains within ± 1.0% over a wide temperature range from -50 °C to 200 °C for three different types of nonlinear dependences. We have carried out its performance comparison with a multilayer-perceptron-based sensor model. We have also proposed a reduced-complexity run-time implementation scheme for the LaNN-based sensor model, which can save about 50% of the hardware and reduce the execution time by four times, thus making it suitable for the energy-constrained WSN applications.","Wireless sensor networks,
Robot sensing systems,
Training,
Artificial neural networks,
Temperature sensors,
Temperature,
Polynomials"
Power Spectrum Blind Sampling,"Power spectrum blind sampling (PSBS) consists of a sampling procedure and a reconstruction method that is capable of perfectly reconstructing the unknown power spectrum of a signal from the obtained samples. In this letter, we propose a solution to the PSBS problem based on a periodic sampling procedure and a simple least squares (LS) reconstruction method. For this PSBS technique, we derive the lowest possible average sampling rate, which is much lower than the Nyquist rate of the signal. Note the difference with spectrum blind sampling (SBS) where the goal is to perfectly reconstruct the spectrum and not the power spectrum of the signal, in which case sub-Nyquist rate sampling is only possible if the spectrum is sparse. In the current work, we can perform sub-Nyquist rate sampling without making any constraints on the power spectrum, because we try to reconstruct the power spectrum and not the spectrum. In many applications, such as spectrum sensing for cognitive radio, the power spectrum is of interest and estimating the spectrum is basically overkill.","Wideband,
Sensors,
Reconstruction algorithms,
Materials,
Scattering,
Complexity theory,
Cognitive radio"
Improved Superconducting Magnetic Energy Storage (SMES) Controller for High-Power Utility Applications,"Superconducting magnetic energy storage (SMES) systems are getting increasing interest in applications of power flow stabilization and control in the transmission network level. This trend is mainly supported by the rising integration of large-scale renewable energy power plants into the high-power utility system and by major features of SMES units. In a SMES system, the power conditioning system (PCS) is the crucial component for controlling the power exchange between the superconducting coil and the ac system. The dynamics of the PCS directly influences the validity of the SMES in the dynamic control of the power system. This paper describes a novel PCS scheme of SMES to simultaneously perform both active and reactive power flow controls. Moreover, a detailed model of the SMES unit is derived and a three-level control scheme is designed, comprising a full decoupled current control strategy in the d-q reference frame with a novel controller to prevent PCS dc bus capacitors' voltage drift/imbalance. The dynamic performances of the proposed systems are fully validated by computer simulation.","Switches,
Choppers,
Power conversion,
Coils,
Power system dynamics,
Capacitors"
Strap-down Pedestrian Dead-Reckoning system,"This paper presents a waist-worn Pedestrian Dead Reckoning (PDR) System that requires minimal end-user calibration. The PDR system is based on an Inertial Measurement Unit (IMU) comprising of a tri-axial accelerometer, a tri-axial magnetometer and a tri-axial gyroscope. We propose a novel heading estimation scheme using a quaternion-based extended Kalman filter (EKF) that estimates magnetic disturbances and corrects for them. Accelerometer measurements are used to detect step events and to estimate step lengths. Experimental results show that a relative distance error of about 3% to 8% can be obtained using our methods.",
Schedulability Analysis of Short-Term Scheduling for Crude Oil Operations in Refinery With Oil Residency Time and Charging-Tank-Switch-Overlap Constraints,"For short-term scheduling of crude oil operations in refinery, often crude oil residency time constraint and charging-tank-switch-overlap constraint are ignored by mathematical programming models to make the problem solvable. Thus, a schedule obtained by such mathematical programming models is infeasible and cannot be deployed. To solve this problem, this work studies the short-term scheduling problem of crude oil operations in a control theory perspective. The system is modeled by a hybrid Petri net and a short-term schedule is seen as a series of control commands. With this model, schedulability analysis is carried out and schedulability conditions are presented. These conditions can be used as constraints for finding a realizable and optimal refining schedule. Moreover, based on the proposed approach, a detailed schedule can be easily obtained given a realizable refining schedule. In this way, the complexity for the short-term scheduling problem of crude oil operations in refinery is greatly reduced and effective techniques and tools for practical applications can be obtained.","Petroleum,
Schedules,
Pipelines,
Storage tanks,
Mathematical model,
Job shop scheduling,
Delay effects"
The Integrated Virtual Environment Rehabilitation Treadmill System,"Slow gait speed and interlimb asymmetry are prevalent in a variety of disorders. Current approaches to locomotor retraining emphasize the need for appropriate feedback during intensive, task-specific practice. This paper describes the design and feasibility testing of the integrated virtual environment rehabilitation treadmill (IVERT) system intended to provide real-time, intuitive feedback regarding gait speed and asymmetry during training. The IVERT system integrates an instrumented, split-belt treadmill with a front-projection, immersive virtual environment. The novel adaptive control system uses only ground reaction force data from the treadmill to continuously update the speeds of the two treadmill belts independently, as well as to control the speed and heading in the virtual environment in real time. Feedback regarding gait asymmetry is presented 1) visually as walking a curved trajectory through the virtual environment and 2) proprioceptively in the form of different belt speeds on the split-belt treadmill. A feasibility study involving five individuals with asymmetric gait found that these individuals could effectively control the speed of locomotion and perceive gait asymmetry during the training session. Although minimal changes in overground gait symmetry were observed immediately following a single training session, further studies should be done to determine the IVERT's potential as a tool for rehabilitation of asymmetric gait by providing patients with congruent visual and proprioceptive feedback.","Legged locomotion,
Belts,
Training,
Visualization,
Force,
Virtual environment,
Real time systems"
A Game-Engine-Based Platform for Modeling and Computing Artificial Transportation Systems,"A game-engine-based modeling and computing platform for artificial transportation systems (ATSs) is introduced. As an important feature, the artificial-population module (APM) is described in both its macroscopic and microcosmic aspects. In this module, each person is designed similarly to the actors in games. The traffic-simulation module (TSM) is another important module, which takes advantage of Delta3D to construct a 3-D simulation environment. All mobile actors are also managed by this module with the help of the dynamic-actor-layer (DAL) mechanism that is offered by Delta3D. The platform is designed as agent-oriented, modularized, and distributed. Both modules, together with components that are responsible for message processing, rules, network, and interactions, are organized by the game manager (GM) in a flexible architecture. With the help of the network component, the platform can be constructed to implement a distributed simulation. Finally, four experiments are introduced to show functions and features of the platform.","Engines,
Computational modeling,
Training,
Urban areas,
Intelligent transportation systems"
Efficient Data Propagation in Traffic-Monitoring Vehicular Networks,"Road congestion and traffic-related pollution have a large negative social and economic impact on several economies worldwide. We believe that investment in the monitoring, distribution, and processing of traffic information should enable better strategic planning and encourage better use of public transport, both of which would help cut pollution and congestion. This paper investigates the problem of efficiently collecting and disseminating traffic information in an urban setting. We formulate the traffic data acquisition problem and explore solutions in the mobile sensor network domain while considering realistic application requirements. By leveraging existing infrastructure such as traveling vehicles in the city, we propose traffic data dissemination schemes that operate on both the routing and the application layer; our schemes are frugal in the use of the wireless medium, rendering our system interoperable with the proliferation of competing applications. We introduce the following two routing algorithms for vehicular networks that aim at minimizing communication and, at the same time, adhering to a delay threshold set by the application: 1) delay-bounded greedy forwarding and 2) delay-bounded minimum-cost forwarding. We propose a framework that jointly optimizes the two key processes associated with monitoring traffic, i.e., data acquisition and data delivery, and provide a thorough experimental evaluation based on realistic vehicular traces on a real city map.",
An Intelligent Multifeature Statistical Approach for the Discrimination of Driving Conditions of a Hybrid Electric Vehicle,"As a new kind of vehicle with low fuel cost and low emissions, the hybrid electric vehicle (HEV) has been paid much attention in recent years. The key technique in the HEV is adopting the optimal control strategy for the best performance. As the premise, correct driving condition discrimination has an extremely important significance. This paper proposes an intelligent multifeature statistical approach to automatically discriminate the driving condition of the HEV. First, this approach periodically samples the driving cycle. Then, it extracts multiple statistical features and tests their significance by statistical analysis to select effective features. Afterward, it applies a support vector machine (SVM) and other machine-learning methods to intelligently and automatically discriminate the driving conditions. Compared with others, the proposed approach can compute fast and discriminate in real time during the whole HEV running mode. In our experiments, it reaches an accuracy value of 95%. As a result, our approach can completely mine the valid information from the data and extract multiple features that have clear meanings and significance. Finally, according to the prediction experiment by a neural network, the fitting experiment by the autoregressive moving average model, and the simulation results of the control strategy, it turns out that our proposed approach raises the efficiency of considerably controlling the HEV.","Hybrid electric vehicles,
Feature extraction,
Roads,
Acceleration,
Statistical analysis"
"Internet Protocol Television (IPTV): Architecture, Trends, and Challenges","Internet protocol television (IPTV), a technology that delivers video content over a network that uses the IP networking protocol, has been receiving a lot of attention over the last couple of years. The increasing interest in IPTV is being driven by remarkable advances in digital technologies and consumer electronic devices, broadband networking technologies, Web services, as well as more entertainment demands (enabled by decreasing costs of hardware and software technologies) from both consumers and content providers. In this paper, we briefly discuss IPTV standardization initiatives and present the design of both next-generation network (NGN)-based and non-NGN-based architectures that have been recently proposed to enable the deployment of IPTV. In addition, we describe the challenges and solutions associated with mobile IPTV and peer-to-peer IPTV systems. We Anally present some IPTV trends and identify some of the IPTV challenges that must be addressed to enable the ubiquitous deployment and adoption of IPTV.",
Guaranteed decentralized pursuit-evasion in the plane with multiple pursuers,"Pursuit-evasion games are an important problem in robotics and control, but games with many players are difficult to analyze and solve. This paper studies a game of multiple pursuers cooperating to capture a single evader in a bounded, convex, polytope in the plane. We present a decentralized control scheme based on the Voronoi partion of the game domain, where the pursuers jointly minimize the area of the evader's Voronoi cell. We prove that capturing the evader is guaranteed under this scheme regardless of the evader's actions, and show simulation results demonstrating the pursuit strategy.","Games,
Bismuth,
Simulation,
Trajectory,
Vectors,
Equations,
Educational institutions"
Who's Who with Big-Five: Analyzing and Classifying Personality Traits with Smartphones,"In this paper, we investigate the relationship between behavioral characteristics derived from rich smart phone data and self-reported personality traits. Our data stems from smart phones of a set of 83 individuals collected over a continuous period of 8 months. From the analysis, we show that aggregated features obtained from smart phone usage data can be indicators of the Big-Five personality traits. Additionally, we develop an automatic method to infer the personality type of a user based on cell phone usage using supervised learning. We show that our method performs significantly above chance and up to 75.9% accuracy. To our knowledge, this constitutes the first study on the analysis and classification of personality traits using smartphone data.","Smart phones,
Feature extraction,
Correlation,
Psychology,
Stability analysis,
Context"
Computational Acceleration for MR Image Reconstruction in Partially Parallel Imaging,"In this paper, we present a fast numerical algorithm for solving total variation and ℓ1 (TVL1) based image reconstruction with application in partially parallel magnetic resonance imaging. Our algorithm uses variable splitting method to reduce computational cost. Moreover, the Barzilai-Borwein step size selection method is adopted in our algorithm for much faster convergence. Experimental results on clinical partially parallel imaging data demonstrate that the proposed algorithm requires much fewer iterations and/or less computational cost than recently developed operator splitting and Bregman operator splitting methods, which can deal with a general sensing matrix in reconstruction framework, to get similar or even better quality of reconstructed images.",
Imaging the Social Brain by Simultaneous Hyperscanning during Subject Interaction,Advances in neuroelectric recordings and computational tools allow investigation of interactive brain activity and connectivity in a group of subjects engaged in social interactions.,"Electroencephalography,
Informatics,
Brain models,
Bioinformatics,
Biomedical image processing,
Social factors,
Neuroscience"
Peta-scale phase-field simulation for dendritic solidification on the TSUBAME 2.0 supercomputer,"The mechanical properties of metal materials largely depend on their intrinsic internal microstructures. To develop engineering materials with the expected properties, predicting patterns in solidified metals would be indispensable. The phase-field simulation is the most powerful method known to simulate the micro-scale dendritic growth during solidification in a binary alloy. To evaluate the realistic description of solidification, however, phase-field simulation requires computing a large number of complex nonlinear terms over a fine-grained grid. Due to such heavy computational demand, previous work on simulating three-dimensional solidification with phase-field methods was successful only in describing simple shapes. Our new simulation techniques achieved scales unprecedentedly large, sufficient for handling complex dendritic structures required in material science. Our simulations on the GPU-rich TSUBAME 2.0 super- computer at the Tokyo Institute of Technology have demonstrated good weak scaling and achieved 1.017 PFlops in single precision for our largest configuration, using 4,000 CPUs along with 16,000 CPU cores.","Graphics processing unit,
Computational modeling,
Instruction sets,
Supercomputers,
Kernel,
Solid modeling,
Metals"
Time and Power Allocation for Collaborative Primary-Secondary Transmission Using Superposition Coding,This letter considers applying superposition coding (SC) in collaborative primary-secondary spectrum sharing environments where the secondary transmitter acts as a relay of the primary signal and is allowed to transmit its own signal only if it is not harmful to the primary transmission. Time and power allocation is optimized and numerical comparison shows that the proposed approach makes significant improvement in the achievable secondary rate.,"Resource management,
Relays,
Collaboration,
Encoding,
Diversity reception,
Fading,
Wireless communication"
Survivable Multipath Provisioning With Differential Delay Constraint in Telecom Mesh Networks,"Survivability is a critical concern in modern telecom mesh networks because the failure of a network element may cause tremendous data and revenue loss in such networks using high-capacity optical fibers employing wavelength-division multiplexing (WDM). Multipath provisioning is a key feature of next-generation SONET/SDH networks (which can be used on top of optical WDM), and they can support virtual concatenation (VCAT); thus, multipath provisioning can significantly outperform single-path provisioning in resource efficiency, service resilience, and flexibility. However, in multipath provisioning, differential delay is an important constraint that should be considered. We investigate survivability of service paths based on differential-delay constraint (DDC) and multipath provisioning together in telecom backbone mesh networks. We propose the Shared Protection of the Largest Individual Traversed link (SPLIT) method for survivable multipath provisioning and present a DDC-based algorithm for multipath routing subject to DDC. We also compare the DDC-based algorithm with the K shortest link-disjoint paths (KDP) algorithm, using SPLIT, under dynamic service requests. We find that exploiting link-disjoint paths is very efficient for survivable multipath provisioning, and our algorithm is resource-efficient, has low signaling overhead, and has fast fault recovery for survivable multipath provisioning with DDC. For a 5-ms DDC, our algorithm can decrease the bandwidth blocking ratio (BBR) significantly in typical U.S. backbone networks.",
Distributed event-based control for interconnected linear systems,"This paper presents a distributed event-based control strategy for a networked dynamical system consisting of N linear time-invariant interconnected subsystems. Each subsystem broadcasts its state over the network according to some triggering rules which depend on local information only. The system converges to an adjustable region around the equilibrium point under the proposed control design, and the existence of a lower bound for the broadcasting period is guaranteed. The effect of the coupling terms over the region of convergence and broadcasting period lower bound is analyzed, and a novel model-based approach is derived to reduce the communications. Simulation results show the effectiveness of the proposed approaches and illustrate the theoretical results.","Eigenvalues and eigenfunctions,
Broadcasting,
Closed loop systems,
Simulation,
State estimation,
Linear systems,
Couplings"
An Efficient Predistorter Design for Compensating Nonlinear Memory High Power Amplifiers,"This contribution applies digital predistorter to compensate distortions caused by memory high power amplifiers (HPAs) which exhibit true output saturation characteristics. Particle swarm optimization is first implemented to identify the Wiener HPA's parameters. The estimated Wiener HPA model is then directly used to design the predistorter. The proposed digital predistorter solution is attractive owing to its low on-line computational complexity, small memory units required and simple VLSI hardware structure implementation. Moreover, the designed predistorter is capable of successfully compensating serious nonlinear distortions and memory effects caused by the memory HPA operating in the output saturation region. Simulation results obtained are presented to demonstrate the effectiveness of this novel digital predistorter design.","Predistortion,
Nonlinear distortion,
Polynomials,
Optimization,
Mathematical model,
Power amplifiers"
Throughput-Delay-Reliability Tradeoff with ARQ in Wireless Ad Hoc Networks,"Delay-reliability (D-R), and throughput-delay-reliability (T-D-R) tradeoffs in an ad hoc network are derived for single hop and multi-hop transmission with automatic repeat request (ARQ) on each hop. The delay constraint is modeled by assuming that each packet is allowed at most D retransmissions end-to-end, and the reliability is defined as the probability that the packet is successfully decoded in at most D retransmissions. The throughput of the ad hoc network is characterized by the transmission capacity, where the transmission capacity is defined to be the maximum density of spatial transmissions that can be simultaneously supported in an ad hoc network under quality of service (QoS) constraints (maximum retransmissions and reliability). The transmission capacity captures the T-D-R tradeoff as it incorporates the dependence between the throughput, the maximum delay, and the reliability. Given an end-to-end retransmission constraint of D, the optimal allocation of the number of retransmissions allowed at each hop is derived that maximizes a lower bound on the transmission capacity. Optimizing over the number of hops, single hop transmission is shown to be optimal for maximizing a lower bound on the transmission capacity in the sparse network regime.",
Lumped-Element Fully Tunable Bandstop Filters for Cognitive Radio Applications,"This paper presents tunable lumped-element bandstop filters for the UHF-band cognitive radio systems. The two-pole filters are implemented using lumped elements with both single- and back-to-back silicon varactor diodes. The single diode filter tunes from 470 to 730 MHz with a 16-dB rejection bandwidth of 5 MHz and a filter quality factor of 52-65. The back-to-back diode filter tunes from 511 to 745 MHz, also with a 16-dB rejection bandwidth of 5 MHz and a quality factor of 68-75. Both filters show a low insertion loss of 0.3-0.4 dB. Nonlinear measurements at the filter null with Δf = 2 MHz show that the back-to-back diode filter results in 12-dBm higher third-order intermodulation intercept point than the single diode filter. A scaling series capacitor is used in the resonator arm of the back-to-back diode filter and allows a power handling of 25 dBm at the 16-dB rejection null. The cascaded response of two tunable filters is also presented for multiband rejection applications, or for a deeper rejection null (>;36 dB with 0.6-dB loss at 600 MHz). The topology can be easily extended to higher order filters and design equations are presented.","Bandwidth,
Inverters,
Resonator filters,
Microwave filters,
Integrated circuit modeling,
Capacitors,
Filtering theory"
A Hidden Topic-Based Framework toward Building Applications with Short Web Documents,"This paper introduces a hidden topic-based framework for processing short and sparse documents (e.g., search result snippets, product descriptions, book/movie summaries, and advertising messages) on the Web. The framework focuses on solving two main challenges posed by these kinds of documents: 1) data sparseness and 2) synonyms/homonyms. The former leads to the lack of shared words and contexts among documents while the latter are big linguistic obstacles in natural language processing (NLP) and information retrieval (IR). The underlying idea of the framework is that common hidden topics discovered from large external data sets (universal data sets), when included, can make short documents less sparse and more topic-oriented. Furthermore, hidden topics from universal data sets help handle unseen data better. The proposed framework can also be applied for different natural languages and data domains. We carefully evaluated the framework by carrying out two experiments for two important online applications (Web search result classification and matching/ranking for contextual advertising) with large-scale universal data sets and we achieved significant results.","Data mining,
Advertising,
Information security,
Web search,
Text processing,
Predictive models,
Natural language processing"
On power and throughput tradeoffs of WiFi and Bluetooth in smartphones,"This paper describes a combined power and throughput performance study of WiFi and Bluetooth usage in smartphones. The study reveals several interesting phenomena and tradeoffs. The conclusions from this study suggest preferred usage patterns, as well as operative suggestions for researchers and smartphone developers.","IEEE 802.11 Standards,
Bluetooth,
Power demand,
Smart phones,
Throughput,
Ad hoc networks,
Power measurement"
MEVBench: A mobile computer vision benchmarking suite,"The growth in mobile vision applications, coupled with the performance limitations of mobile platforms, has led to a growing need to understand computer vision applications. Computationally intensive mobile vision applications, such as augmented reality or object recognition, place significant performance and power demands on existing embedded platforms, often leading to degraded application quality. With a better understanding of this growing application space, it will be possible to more effectively optimize future embedded platforms. In this work, we introduce and evaluate a custom benchmark suite for mobile embedded vision applications named MEVBench. MEVBench provides a wide range of mobile vision applications such as face detection, feature classification, object tracking and feature extraction. To better understand mobile vision processing characteristics at the architectural level, we analyze single and multithread implementations of many algorithms to evaluate performance, scalability, and memory characteristics. We provide insights into the major areas where architecture can improve the performance of these applications in embedded systems.","Feature extraction,
Benchmark testing,
Mobile communication,
Computer vision,
Vectors,
Support vector machines,
Augmented reality"
A Novel Silicon-Embedded Coreless Inductor for High-Frequency Power Management Applications,"In this letter, a novel post-CMOS silicon-embedded coreless power inductor is proposed and demonstrated. The inductor is fabricated in the thick bottom layer of a silicon substrate and connected to the front side through vias opened in the thin top layer where control circuits can be fabricated for chip area saving. A 0.8- coreless inductor fabricated using this monolithic inductor technology shows a low dc resistance of 87 and an inductance of 13.1 nH with a quality factor of 3.9 at 100 MHz. A high inductor efficiency of 93% was estimated for 2.4-1.5-V 0.6-A power conversion at 100 MHz. This technology is very suitable for power-supply-on-chip applications.","Inductors,
Resistance,
Copper,
Magnetic cores,
Inductance,
Silicon,
Converters"
Toward object discovery and modeling via 3-D scene comparison,"The performance of indoor robots that stay in a single environment can be enhanced by gathering detailed knowledge of objects that frequently occur in that environment. We use an inexpensive sensor providing dense color and depth, and fuse information from multiple sensing modalities to detect changes between two 3-D maps. We adapt a recent SLAM technique to align maps. A probabilistic model of sensor readings lets us reason about movement of surfaces. Our method handles arbitrary shapes and motions, and is robust to lack of texture. We demonstrate the ability to find whole objects in complex scenes by regularizing over surface patches.","Color,
Cameras,
Image color analysis,
Robot sensing systems,
Measurement by laser beam,
Solid modeling,
Surface reconstruction"
An Adaptive Evolutionary Multi-Objective Approach Based on Simulated Annealing,"A multi-objective optimization problem can be solved by decomposing it into one or more single objective subproblems in some multi-objective metaheuristic algorithms. Each subproblem corresponds to one weighted aggregation function. For example, MOEA/D is an evolutionary multi-objective optimization (EMO) algorithm that attempts to optimize multiple subproblems simultaneously by evolving a population of solutions. However, the performance of MOEA/D highly depends on the initial setting and diversity of the weight vectors. In this paper, we present an improved version of MOEA/D, called EMOSA, which incorporates an advanced local search technique (simulated annealing) and adapts the search directions (weight vectors) corresponding to various subproblems. In EMOSA, the weight vector of each subproblem is adaptively modified at the lowest temperature in order to diversify the search toward the unexplored parts of the Pareto-optimal front. Our computational results show that EMOSA outperforms six other well established multi-objective metaheuristic algorithms on both the (constrained) multi-objective knapsack problem and the (unconstrained) multi-objective traveling salesman problem. Moreover, the effects of the main algorithmic components and parameter sensitivities on the search performance of EMOSA are experimentally investigated.",
Broadband THz Pulse Transmission Through the Atmosphere,"We have transmitted a low-power beam of repetitive broadband THz pulses the record distance of 167 m through the atmosphere with 51% relative humidity at 21°C and have observed the broadened transmitted pulses with a signal to noise ratio greater than 200. The measured transmitted pulses reshaped from a 0.5-ps input pulse into an output pulse structure with a 5-ps symmetric pulse at the leading edge followed by a frequency-swept, rapidly oscillating trailing edge extending with increasing frequency to beyond 150 ps. The leading pulse appearing in the output pulse structure is composed of phase-locked frequency components extending from 0.07 to 0.37 THz that experienced negligible attenuation and group velocity dispersion due to transmission through water vapor. Such a stable pulse shape is suitable for the THz bit in a digital THz communications channel. Our results demonstrate a bit rate-distance product of greater than 8 (Gb/s)-km, which is comparable to an optical fiber digital communications channel.","Mirrors,
Pulse measurements,
Atmospheric measurements,
Laser beams,
Atmosphere,
Measurement by laser beam,
Laser excitation"
Electric field in polymeric cable due to space charge accumulation under DC and temperature gradient,"When power cables are loaded under high voltage direct current (HVDC), an accumulation of space charge and a radial distribution of temperature gradient are developed across the insulation material. Such existence and accumulation of space charge within the insulating material poses a threat to the reliability of the operation of dc power cables. The electric field of a practical dc power cable is affected by the conductivity of the material, which is a function of both temperature and electric field. This causes difficulties in identifying the electric field distribution. In this paper, a method of determining the electric field distribution in dc power cables was proposed by considering the influence of space charge on the conductivity of the insulating material under different temperatures. Commercial 11 kV ac cross-linked polyethylene (XLPE) power cables were used and the space charge in these cables under dc conditions was measured using a modified pulsed electroacoustic (PEA) system with an attached current transformer. Therefore, a replica of a power cable under load conditions is obtained, which allows an investigation of the formation, migration and accumulation of space charge in a power cable with and without temperature gradients across the insulating material. COMSOL Multiphysics software package was used to accurately determine the electric field distribution in the dc power cable with consideration of the influence of electric field on the conductivity of the insulating material. The numerical modelling is based on the hopping conduction mechanism and its parameters were obtained from experiments carried out on the XLPE insulation material.",
Inverse Gaussian Modeling of Turbulence-Induced Fading in Free-Space Optical Systems,"We propose the inverse Gaussian distribution, as a less complex alternative to the classical log-normal model, to describe turbulence-induced fading in free-space optical (FSO) systems operating in weak turbulence conditions and/or in the presence of aperture averaging effects. By conducting goodness of fit tests, we define the range of values of the scintillation index for various multiple-input multiple-output (MIMO) FSO configurations, where the two distributions approximate each other with a certain significance level. Furthermore, the bit error rate performance of two typical MIMO FSO systems is investigated over the new turbulence model; an intensity-modulation/direct detection MIMO FSO system with Q-ary pulse position modulation that employs repetition coding at the transmitter and equal gain combining at the receiver, and a heterodyne MIMO FSO system with differential phase-shift keying and maximal ratio combining at the receiver. Finally, numerical results are presented that validate the theoretical analysis and provide useful insights into the implications of the model parameters on the overall system performance.","Bit error rate,
MIMO,
Apertures,
Fading,
Numerical models,
Optical transmitters,
Receivers"
Editing by Viewing: Automatic Home Video Summarization by Viewing Behavior Analysis,"In this paper, we propose the Interest Meter (IM), a system making the computer conscious of user's reactions to measure user's interest and thus use it to conduct video summarization. The IM takes account of users' spontaneous reactions when they view videos. To estimate user's viewing interest, quantitative interest measures are devised based on the perspectives of attention and emotion. For estimating attention states, variations of user's eye movement, blink, and head motion are considered. For estimating emotion states, facial expression is recognized as positive or neural emotion. By combining characteristics of attention and emotion by a fuzzy fusion scheme, we transform users' viewing behaviors into quantitative interest scores, determine interesting parts of videos, and finally concatenate them as video summaries. Experimental results show that the proposed concept “editing by viewing” works well and may provide a promising direction to consider the human factor in video summarization.",
Phoenix: A Weight-Based Network Coordinate System Using Matrix Factorization,"Network coordinate (NC) systems provide a lightweight and scalable way for predicting the distances, i.e., round-trip latencies among Internet hosts. Most existing NC systems embed hosts into a low dimensional Euclidean space. Unfortunately, the persistent occurrence of Triangle Inequality Violation (TIV) on the Internet largely limits the distance prediction accuracy of those NC systems. Some alternative systems aim at handling the persistent TIV, however, they only achieve comparable prediction accuracy with Euclidean distance based NC systems. In this paper, we propose an NC system, so-called Phoenix, which is based on the matrix factorization model. Phoenix introduces a weight to each reference NC and trusts the NCs with higher weight values more than the others. The weight-based mechanism can substantially reduce the impact of the error propagation. Using the representative aggregate data sets and the newly measured dynamic data set collected from the Internet, our simulations show that Phoenix achieves significantly higher prediction accuracy than other NC systems. We also show that Phoenix quickly converges to steady state, performs well under host churn, handles the drift of the NCs successfully by using regularization, and is robust against measurement anomalies. Phoenix achieves a scalable yet accurate end-to-end distances monitoring. In addition, we study how well an NC system can characterize the TIV property on the Internet by introducing two new quantitative metrics, so-called RERPL and AERPL. We show that Phoenix is able to characterize TIV better than other existing NC systems.",
DICON: Interactive Visual Analysis of Multidimensional Clusters,"Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis.",
A CMOS Image Sensor With On-Chip Image Compression Based on Predictive Boundary Adaptation and Memoryless QTD Algorithm,"This paper presents the architecture, algorithm, and VLSI hardware of image acquisition, storage, and compression on a single-chip CMOS image sensor. The image array is based on time domain digital pixel sensor technology equipped with nondestructive storage capability using 8-bit Static-RAM device embedded at the pixel level. The pixel-level memory is used to store the uncompressed illumination data during the integration mode as well as the compressed illumination data obtained after the compression stage. An adaptive quantization scheme based on fast boundary adaptation rule (FBAR) and differential pulse code modulation (DPCM) procedure followed by an online, least storage quadrant tree decomposition (QTD) processing is proposed enabling a robust and compact image compression processor. A prototype chip including 64×64 pixels, read-out and control circuitry as well as an on-chip compression processor was implemented in 0.35 μm CMOS technology with a silicon area of 3.2×3.0 mm2 and an overall power of 17 mW. Simulation and measurements results show compression figures corresponding to 0.6-1 bit-per-pixel (BPP), while maintaining reasonable peak signal-to-noise ratio levels.","CMOS image sensors,
Image coding,
Image storage,
Sensor arrays,
CMOS technology,
Pixel,
Lighting,
Pulse modulation,
Very large scale integration,
Hardware"
"Cluster, grid and cloud computing: A detailed comparison","Cloud computing is rapidly growing as an alternative to conventional computing. However, it is based on models like cluster computing, distributed computing, utility computing and grid computing in general. This paper presents an end-to-end comparison between Cluster Computing, Grid Computing and Cloud Computing, along with the challenges they face. This could help in better understanding these models and to know how they differ from its related concepts, all in one go. It also discusses the ongoing projects and different applications that use these computing models as a platform for execution. An insight into some of the tools which can be used in the three computing models to design and develop applications is given. This could help in bringing out the innovative ideas in the field and can be explored to the needs in the computing world.","Cloud computing,
Computational modeling,
Clouds,
Grid computing,
Computers,
Europe"
Rectangular Thinned Arrays Based on McFarland Difference Sets,A new class of analytical rectangular thinned arrays with low peak sidelobe level (PSL) is introduced. The proposed synthesis technique exploits binary sequences derived from McFarland difference sets to design thinned layouts on a lattice of P × P(P+2) positions for any prime P. The pattern features of the arising massively-thinned arrangements characterized by only P × (P+1) active elements are discussed and the results of an extensive numerical analysis are presented to assess advantages and limitations of the McFarland-based arrays.,"Layout,
Gallium,
Indexes,
Apertures,
Correlation,
Decision support systems,
Lattices"
Detection of Architectural Distortion in Prior Mammograms,"We present methods for the detection of sites of architectural distortion in prior mammograms of interval-cancer cases. We hypothesize that screening mammograms obtained prior to the detection of cancer could contain subtle signs of early stages of breast cancer, in particular, architectural distortion. The methods are based upon Gabor filters, phase portrait analysis, a novel method for the analysis of the angular spread of power, fractal analysis, Laws' texture energy measures derived from geometrically transformed regions of interest (ROIs), and Haralick's texture features. With Gabor filters and phase portrait analysis, 4224 ROIs were automatically obtained from 106 prior mammograms of 56 interval-cancer cases, including 301 true-positive ROIs related to architectural distortion, and from 52 mammograms of 13 normal cases. For each ROI, the fractal dimension, the entropy of the angular spread of power, 10 Laws' measures, and Haralick's 14 features were computed. The areas under the receiver operating characteristic curves obtained using the features selected by stepwise logistic regression and the leave-one-ROI-out method are 0.76 with the Bayesian classifier, 0.75 with Fisher linear discriminant analysis, and 0.78 with a single-layer feed-forward neural network. Free-response receiver operating characteristics indicated sensitivities of 0.80 and 0.90 at 5.8 and 8.1 false positives per image, respectively, with the Bayesian classifier and the leave-one-image-out method.","Pixel,
Breast cancer,
Sensitivity,
Design automation,
Image edge detection"
"On Cooperative Settlement Between Content, Transit, and Eyeball Internet Service Providers","Internet service providers (ISPs) depend on one another to provide global network services. However, the profit-seeking nature of the ISPs leads to selfish behaviors that result in inefficiencies and disputes in the network. This concern is at the heart of the “network neutrality” debate, which also asks for an appropriate compensation structure that satisfies all types of ISPs. Our previous work showed in a general network model that the Shapley value has several desirable properties, and that if applied as the profit model, selfish ISPs would yield globally optimal routing and interconnecting decisions. In this paper, we use a more detailed and realistic network model with three classes of ISPs: content, transit, and eyeball. This additional detail enables us to delve much deeper into the implications of a Shapley settlement mechanism. We derive closed-form Shapley values for more structured ISP topologies and develop a dynamic programming procedure to compute the Shapley values under more diverse Internet topologies. We also identify the implications on the bilateral compensation between ISPs and the pricing structures for differentiated services. In practice, these results provide guidelines for solving disputes between ISPs and for establishing regulatory protocols for differentiated services and the industry.",
Smart grid communication and co-simulation,"The smart power grid will extensively rely on networked control to increase efficiency, reliability, and safety; to enable plug-and-play asset integration, such as in the case of distributed generation and alternative energy sources; to support market dynamics as well as reduce peak prices and stabilize costs when supply is limited. In turn, network control requires an advanced communication infrastructure with support for security and real-time communication. This paper reviews the major challenges in smart grid communication, and proposes PowerNet, a system of heterogeneous yet interoperable networks that provides adequate levels of realtime performance, reliability, and security, and that exploits current investments in software and hardware. Smart grid communication involves disparate designs and complex issues, and it can be effectively evaluated through co-simulation. The paper describes a co-simulator that combines extensive support for power device models and for communication models, and highlights current work in the area.","Smart grids,
Data models,
Solid modeling,
Real time systems,
Object oriented modeling,
Computational modeling,
Security"
Deterministic Sensor Data Scheduling Under Limited Communication Resource,"We consider finite time-horizon sensor data scheduling under limited communication resource. A sensor can only send d of its measurement data to a remote estimator within a time-horizon T >;>; d. When use the terminal estimation error covariance of the estimator as a performance metric, we provide an explicit form of the optimal data schedule; when use the average estimation error covariance as a performance metric, we provide a necessary condition for a schedule to be optimal for a general T . When T has a special form, the necessary condition allows us to construct an explicit optimal data schedule.",
A Small-Gain Condition for Interconnections of ISS Systems With Mixed ISS Characterizations,"We consider interconnected nonlinear systems with external inputs, where each of the subsystems is assumed to be input-to-state stable (ISS). Sufficient conditions of small-gain type are provided guaranteeing that the interconnection is ISS with respect to the external input. To this end we extend recently obtained small-gain theorems to a more general type of interconnections. The small-gain theorem provided here is applicable to situations where the ISS conditions are formulated differently for each subsystem and are either given in the maximization or the summation sense. Furthermore, it is shown that the conditions are compatible in the sense that it is always possible to transform sum formulations to maximum formulations without destroying a given small-gain condition. An example shows the advantages of our results in comparison with the known ones.",
Applications of High-Capacity Crossbar Memories in Cryptography,"This paper proposes a new approach for the construction of highly secure physical unclonable functions (PUFs). Instead of using systems with medium information content and high readout rates, we suggest to maximize the information content of the PUF while strongly reducing its readout frequency. We show that special, passive crossbar arrays with a very large random information content and inherently limited readout speed are suited to implement our approach. They can conceal sensitive information over long time periods and can be made secure against invasive physical attacks. To support our feasibility study, circuit-level simulations and experimental data are presented. Our design allows the first PUFs that are secure against computationally unrestricted adversaries, and which remain so in the face of weeks or even years of uninterrupted adversarial access. We term the new design principle a “SHIC PUF,” where the acronym SHIC stands for super high information content.","Cryptography,
Power system security,
Information security,
Electrical capacitance tomography,
Permission,
Computational modeling,
Circuit simulation,
Costs,
Computer security,
Optical sensors"
Dirichlet-Based Trust Management for Effective Collaborative Intrusion Detection Networks,"The accuracy of detecting intrusions within a Collaborative Intrusion Detection Network (CIDN) depends on the efficiency of collaboration between peer Intrusion Detection Systems (IDSes) as well as the security itself of the CIDN. In this paper, we propose Dirichlet-based trust management to measure the level of trust among IDSes according to their mutual experience. An acquaintance management algorithm is also proposed to allow each IDS to manage its acquaintances according to their trustworthiness. Our approach achieves strong scalability properties and is robust against common insider threats, resulting in an effective CIDN. We evaluate our approach based on a simulated CIDN, demonstrating its improved robustness, efficiency and scalability for collaborative intrusion detection in comparison with other existing models.","Collaboration,
Peer to peer computing,
Intrusion detection,
Mathematical model,
Equations,
Robustness,
Scalability"
Detection of Small-Scale Primary Users in Cognitive Radio Networks,"In cognitive radio networks (CRNs), detecting small-scale primary devices, such as wireless microphones, is a challenging, but very important, problem that has not yet been addressed well. Recently, cooperative sensing and sensing scheduling have been advocated as an effective MAC (medium access control) layer approach to detecting large-scale primary signals. However, it is unclear whether and how they can improve the detection of a small-scale primary signal because of (i) its small signal footprint due to the use of weak transmit-power, and (ii) the unpredictability of its spatial and temporal spectrum-usage patterns. Based on extensive analysis and simulation, we identify the data-fusion range as a key factor that enables effective cooperative sensing for detection of small-scale primary signals. In particular, we derive a closed-form expression for the optimal data-fusion range that minimizes the average detection delay. We also observe that the sensing performance is sensitive to the accuracy in estimating the primary's location and transmit-power. Based on these observations, we propose an efficient sensing framework that jointly performs Detection, LOCation estimation, and transmit-power estimation (DeLOC) for small-scale primary users. Our extensive evaluation results in a realistic CRN environment show that DeLOC achieves near-optimal detection performance, while meeting the detection requirements specified in the IEEE 802.22 standard draft. These findings provide useful insights and guidelines in designing a sensing scheme for detection of small-scale primaries in CRNs.","Sensors,
Estimation,
TV,
Delay,
Probability,
Protocols,
Transmitters"
Optimal Scheduling for Fair Resource Allocation in Ad Hoc Networks With Elastic and Inelastic Traffic,"This paper studies the problem of congestion control and scheduling in ad hoc wireless networks that have to support a mixture of best-effort and real-time traffic. Optimization and stochastic network theory have been successful in designing architectures for fair resource allocation to meet long-term throughput demands. However, to the best of our knowledge, strict packet delay deadlines were not considered in this framework previously. In this paper, we propose a model for incorporating the quality-of-service (QoS) requirements of packets with deadlines in the optimization framework. The solution to the problem results in a joint congestion control and scheduling algorithm that fairly allocates resources to meet the fairness objectives of both elastic and inelastic flows and per-packet delay requirements of inelastic flows.","Schedules,
Quality of service,
Delay,
Optimal scheduling,
Wireless networks,
Ad hoc networks"
Mining Discriminative Patterns for Classifying Trajectories on Road Networks,"Classification has been used for modeling many kinds of data sets, including sets of items, text documents, graphs, and networks. However, there is a lack of study on a new kind of data, trajectories on road networks. Modeling such data is useful with the emerging GPS and RFID technologies and is important for effective transportation and traffic planning. In this work, we study methods for classifying trajectories on road networks. By analyzing the behavior of trajectories on road networks, we observe that, in addition to the locations where vehicles have visited, the order of these visited locations is crucial for improving classification accuracy. Based on our analysis, we contend that (frequent) sequential patterns are good feature candidates since they preserve this order information. Furthermore, when mining sequential patterns, we propose to confine the length of sequential patterns to ensure high efficiency. Compared with closed sequential patterns, these partial (i.e., length-confined) sequential patterns allow us to significantly improve efficiency almost without losing accuracy. In this paper, we present a framework for frequent pattern-based classification for trajectories on road networks. Our comparative study over a broad range of classification approaches demonstrates that our method significantly improves accuracy over other methods in some synthetic and real trajectory data.",
Shannon Meets Nash on the Interference Channel,The interference channel is the simplest communication scenario where multiple autonomous users compete for shared resources. We combine game theory and information theory to define the notion of a Nash equilibrium region of the interference channel. The notion is game theoretic: it captures the selfish behavior of each user as they compete. The notion is also information theoretic: it allows each user to use arbitrary communication strategies as it optimizes its own performance. We give an exact characterization of the Nash equilibrium region of the two-user linear deterministic interference channel and an approximate characterization of the Nash equilibrium region of the two-user Gaussian interference channel to within 1 bit/s/Hz.,
Emotion recognition using dynamic grid-based HoG features,"Automatic facial expression analysis is the most commonly studied aspect of behavior understanding and human-computer interface. The main difficulty with facial emotion recognition system is to implement general expression models. The same facial expression may vary differently across humans; this can be true even for the same person when the expression is displayed in different contexts. These factors present a significant challenge for the recognition task. The method we applied, which is reminiscent of the “baseline method”, utilizes dynamic dense appearance descriptors and statistical machine learning techniques. Histograms of oriented gradients (HoG) are used to extract the appearance features by accumulating the gradient magnitudes for a set of orientations in 1-D histograms defined over a size-adaptive dense grid, and Support Vector Machines with Radial Basis Function kernels are the base learners of emotions. The overall classification performance of the emotion detection reached 70% which is better than the 56% accuracy achieved by the “baseline method” presented by the challenge organizers.","Face,
Training,
Feature extraction,
Histograms,
Support vector machines,
Face recognition,
Kernel"
Biometric identification via eye movement scanpaths in reading,"This paper presents an objective evaluation of various eye movement-based biometric features and their ability to accurately and precisely distinguish unique individuals. Eye movements are uniquely counterfeit resistant due to the complex neurological interactions and the extraocular muscle properties involved in their generation. Considered biometric candidates cover a number of basic eye movements and their aggregated scanpath characteristics, including: fixation count, average fixation duration, average saccade amplitudes, average saccade velocities, average saccade peak velocities, the velocity waveform, scanpath length, scanpath area, regions of interest, scanpath inflections, the amplitude-duration relationship, the main sequence relationship, and the pairwise distance between fixations. As well, an information fusion method for combining these metrics into a single identification algorithm is presented. With limited testing this method was able to identify subjects with an equal error rate of 27%. These results indicate that scanpath-based biometric identification holds promise as a behavioral biometric technique.","Equations,
USA Councils,
Muscles"
Monocular 3D scene understanding with explicit occlusion reasoning,"Scene understanding from a monocular, moving camera is a challenging problem with a number of applications including robotics and automotive safety. While recent systems have shown that this is best accomplished with a 3D scene model, handling of partial object occlusion is still unsatisfactory. In this paper we propose an approach that tightly integrates monocular 3D scene tracking-by-detection with explicit object-object occlusion reasoning. Full object and object part detectors are combined in a mixture of experts based on their expected visibility, which is obtained from the 3D scene model. For the difficult case of multi-people tracking, we demonstrate that our approach yields more robust detection and tracking of partially visible pedestrians, even when they are occluded over long periods of time. Our approach is evaluated on two challenging sequences recorded from a moving camera in busy pedestrian zones and outperforms several state-of-the-art approaches.","Detectors,
Three dimensional displays,
Cameras,
Solid modeling,
Support vector machines,
Humans,
Computational modeling"
Artificial Cognition in Production Systems,"Today's manufacturing and assembly systems have to be flexible to adapt quickly to an increasing number and variety of products, and changing market volumes. To manage these dynamics, several production concepts (e.g., flexible, reconfigurable, changeable or autonomous manufacturing and assembly systems) were proposed and partly realized in the past years. This paper presents the general principles of autonomy and the proposed concepts, methods and technologies to realize cognitive planning, cognitive control and cognitive operation of production systems. Starting with an introduction on the historical context of different paradigms of production (e.g., evolution of production and planning systems), different approaches for the design, planning, and operation of production systems are lined out and future trends towards fully autonomous components of an production system as well as autonomous parts and products are discussed. In flexible production systems with manual and automatic assembly tasks, human-robot cooperation is an opportunity for an ergonomic and economic manufacturing system especially for low lot sizes. The state-of-the-art and a cognitive approach in this area are outlined. Furthermore, introducing self-optimizing and self-learning control systems is a crucial factor for cognitive systems. This principles are demonstrated by a quality assurance and process control in laser welding that is used to perform improved quality monitoring. Finally, as the integration of human workers into the workflow of a production system is of the highest priority for an efficient production, worker guidance systems for manual assembly with environmentally and situationally dependent triggered paths on state-based graphs are described in this paper.","Cognition,
Production systems,
Control systems,
Production planning,
Assembly systems,
Flexible manufacturing systems,
Manufacturing systems,
Automatic control,
Computer aided manufacturing,
Quality assurance"
"A 475 mV, 4.9 GHz Enhanced Swing Differential Colpitts VCO With Phase Noise of -136 dBc/Hz at a 3 MHz Offset Frequency","A new enhanced swing differential Colpitts VCO architecture enables oscillations to go beyond both the supply voltage and ground making it suitable for low voltage operation. Analysis for the oscillation frequency, differential- and common-mode oscillations, amplitude of oscillation, and start-up condition provides insight into oscillator operation and design considerations. Operating at 4.9 GHz, the VCO consumes from 1.9 mW to 3 mW for supply voltages of 400 mV and 500 mV, respectively. The 130 nm CMOS VCO's measured phase noise ranges from -132.6 to -136.2 dBc/Hz at a 3 MHz offset frequency.",
Automatic Seizure Detection in ECoG by Differential Operator and Windowed Variance,"Differential operator has long been used in image and signal processing with great success to detect significant changes. In this paper we show that differentiation can enhance certain features of brain electrophysiological signals, contaminated with noise, artifacts, and acquisition defects, leading to efficient detection of those changes. Windowed variance method has been very successful in detecting seizure onset in the brain electrophysiological signals. In this paper we have combined these two powerful methods under the name of differential windowed variance (DWV) algorithm to automatically detect seizure onsets in almost real time, in continuous ECoG (depth-EEG) signals of epileptic patients. The main advantages of the method are simplicity of implementation and speed. We have tested the algorithm on 369 h of nonseizure ECoG as well as 59 h of seizure ECoG of 15 epileptic patients. It detected all but six seizures (91.525% accuracy) with an average delay of 9.2 s after the onset with a maximum false detection of three in 24 h of nonseizure data. Eight novel empirical measures have been introduced to avoid false detections. To ascertain the reliability of the detection method a novel methodology, called quasi-ROC (qROC) curve analysis has been introduced. DWV has been compared with a difference filter based sharp transient (ST) detection algorithm.",
Diffeomorphic Brain Registration Under Exhaustive Sulcal Constraints,"The alignment and normalization of individual brain structures is a prerequisite for group-level analyses of structural and functional neuroimaging data. The techniques currently available are either based on volume and/or surface attributes, with limited insight regarding the consistent alignment of anatomical landmarks across individuals. This article details a global, geometric approach that performs the alignment of the exhaustive sulcal imprints (cortical folding patterns) across individuals. This DIffeomorphic Sulcal-based COrtical (DISCO) technique proceeds to the automatic extraction, identification and simplification of sulcal features from T1-weighted Magnetic Resonance Image (MRI) series. These features are then used as control measures for fully-3-D diffeomorphic deformations. Quantitative and qualitative evaluations show that DISCO correctly aligns the sulcal folds and gray and white matter volumes across individuals. The comparison with a recent, iconic diffeomorphic approach (DARTEL) highlights how the absence of explicit cortical landmarks may lead to the misalignment of cortical sulci. We also feature DISCO in the automatic design of an empirical sulcal template from group data. We also demonstrate how DISCO can efficiently be combined with an image-based deformation (DARTEL) to further improve the consistency and accuracy of alignment performances. Finally, we illustrate how the optimized alignment of cortical folds across subjects improves sensitivity in the detection of functional activations in a group-level analysis of neuroimaging data.",
A Necessary and Sufficient Condition for Consensus of Continuous-Time Agents Over Undirected Time-Varying Networks,"The average consensus problem of continuous-time agents in undirected time-varying networks is studied. The network is allowed to be disconnected. A notion called infinite integral connectivity is proposed. Based on the notion, a necessary and sufficient condition for achieving consensus is given. That is, when the network topology is described by an undirected time-varying graph G(t), the agents achieve consensus if and only if the infinite integral graph of G(t) over [0,∞) is connected. This criterion does not hold for directed networks.",
Fully Homomorphic Encryption without Squashing Using Depth-3 Arithmetic Circuits,"We describe a new approach for constructing fully homomorphic encryption (FHE) schemes. Previous FHE schemes all use the same blueprint from [Gentry 2009]: First construct a somewhat homomorphic encryption (SWHE) scheme, next ""squash"" the decryption circuit until it is simple enough to be handled within the homomorphic capacity of the SWHE scheme, and finally ""bootstrap"" to get a FHE scheme. In all existing schemes, the squashing technique induces an additional assumption: that the sparse subset sum problem (SSSP) is hard. Our new approach constructs FHE as a hybrid of a SWHE and a multiplicatively homomorphic encryption (MHE) scheme, such as Elgamal. Our construction eliminates the need for the squashing step, and thereby also removes the need to assume the SSSP is hard. We describe a few concrete instantiations of the new method, including a ""simple"" FHE scheme where we replace SSSP with Decision Diffle-Hellman, an optimization of the simple scheme that let us ""compress"" the FHE ciphertext into a single Elgamal ciphertext(J), and a scheme whose security can be (quantumly) reduced to the approximate ideal-SIVP. We stress that the new approach still relies on bootstrapping, but it shows how to bootstrap without having to ""squash"" the decryption circuit. The main technique is to express the decryption function of SWHE schemes as a depth-3 Q2 (Σ Π Σ) arithmetic circuit of a particular form. When evaluating this circuit homomorphically (as needed for bootstrapping), we temporarily switch to a MHE scheme, such as Elgamal, to handle the Π part. Due to the special form of the circuit, the switch to the MHE scheme can be done without having to evaluate anything homomorphically. We then translate the result back to the SWHE scheme by homomorphically evaluating the decryption function of the MHE scheme. Using our method, the SWHE scheme only needs to be capable of evaluating the MHE scheme's decryption function, not its own decryption function. We thereby avoid the circularity that necessitated squashing in the original blueprint.","Polynomials,
Encryption,
Public key,
Vectors,
Logic gates"
A Novel Approach for Failure Localization in All-Optical Mesh Networks,"Achieving fast and precise failure localization has long been a highly desired feature in all-optical mesh networks. Monitoring trail (m-trail) has been proposed as the most general monitoring structure for achieving unambiguous failure localization (UFL) of any single link failure while effectively reducing the amount of alarm signals flooding the networks. However, it is critical to come up with a fast and intelligent m-trail design approach for minimizing the number of m-trails and the total bandwidth consumed, which ubiquitously determines the length of the alarm code and bandwidth overhead for the m-trail deployment, respectively. In this paper, the m-trail design problem is investigated. To gain a deeper understanding of the problem, we first conduct a bound analysis on the minimum length of alarm code of each link required for UFL on the most sparse (i.e., ring) and dense (i.e., fully meshed) topologies. Then, a novel algorithm based on random code assignment (RCA) and random code swapping (RCS) is developed for solving the m-trail design problem. The algorithm is verified by comparison to an integer linear program (ILP) approach, and the results demonstrate its superiority in minimizing the fault management cost and bandwidth consumption while achieving significant reduction in computation time. To investigate the impact of topology diversity, extensive simulation is conducted on thousands of random network topologies with systematically increased network density.","Monitoring,
Network topology,
Topology,
Bandwidth,
Probes,
Optical fiber networks"
Cloud testing tools,"Cloud platform provides an infrastructure for resource sharing, software hosting and service delivering in a pay-per-use approach. To test the cloud-based software systems, techniques and tools are necessary to address unique quality concerns of the cloud infrastructure such as massive scalability and dynamic configuration. The tools can also be built on the cloud platform to benefit from virtualized platform and services, massive resources, and parallelized execution. The paper makes a survey of representative approaches and typical tools for cloud testing. It identifies the needs for cloud testing tools including multi-layer testing, SLA-based testing, large scale simulation, and on-demand test environment. To address the needs, it investigates the new architecture and techniques for designing testing tools for the cloud and in the cloud. Tool implementations are surveyed considering different approaches including migrated conventional tools, research tools, commercial tools and facilities like benchmark and testbed. Based on the analysis of state-of-the-art practices, the paper further investigates future trend of testing tool research and development from both capability and usability perspectives.","Testing,
Resource management,
Scalability,
Computer architecture,
Cloud computing,
Collaboration"
BiCoS: A Bi-level co-segmentation method for image classification,"The objective of this paper is the unsupervised segmentation of image training sets into foreground and background in order to improve image classification performance. To this end we introduce a new scalable, alternation-based algorithm for co-segmentation, BiCoS, which is simpler than many of its predecessors, and yet has superior performance on standard benchmark image datasets.",
A low-cost compliant 7-DOF robotic manipulator,"We present the design of a new low-cost series elastic robotic arm. The arm is unique in that it achieves reasonable performance for the envisioned tasks (backlash-free, sub-3mm repeatability, moves at 1.5m/s, 2kg payload) but with a significantly lower parts cost than comparable manipulators. The paper explores the design decisions and tradeoffs made in achieving this combination of price and performance. A new, human-safe design is also described: the arm uses stepper motors with a series-elastic transmission for the proximal four degrees of freedom (DOF), and non-series-elastic robotics servos for the distal three DOF. Tradeoffs of the design are discussed, especially in the areas of human safety and control bandwidth. The arm is used to demonstrate pancake cooking (pouring batter, flipping pancakes), using the intrinsic compliance of the arm to aid in interaction with objects.",
Finite Approximations of Switched Homogeneous Systems for Controller Synthesis,"In this note, we demonstrate the use of a control oriented notion of finite state input/output approximation to synthesize correct-by-design controllers for hybrid plants under sensor limitations. Specifically, we consider the problem of designing stabilizing switching controllers for a pair of unstable homogeneous second order systems with binary output feedback. In addition to yielding a deterministic finite state approximate model of the hybrid plant, our approach allows one to efficiently establish a useable upper bound on the quality of approximation, and leads to a discrete optimization problem whose solution immediately provides a certified finite state controller for the plant. The resulting controller consists of a deterministic finite state observer and a corresponding full state feedback control law.","Switches,
State feedback,
Approximation error,
Closed loop systems,
Convergence"
Degree-of-Freedom Gain From Using Polarimetric Antenna Elements,"Polarization could be the last resource to be exploited for space-limited devices. Over the past years, theoretical studies and experimental work present different conclusions on the potential increase in the number of degrees of freedom from polarization. This paper attempts to unify the different conclusions and provide a mathematical framework that can be applied to any array geometry and channel scattering condition. It shows that the degree-of-freedom gain from using polarimetric antenna elements ranges from 2 to 6 and the gain depends on the array geometry and the channel scattering condition. Sampling techniques and vector multipole decomposition are applied to derive the results.","Arrays,
Antenna arrays,
Geometry,
Scattering,
Antenna radiation patterns,
Signal resolution"
Local vs. global models for effort estimation and defect prediction,"Data miners can infer rules showing how to improve either (a) the effort estimates of a project or (b) the defect predictions of a software module. Such studies often exhibit conclusion instability regarding what is the most effective action for different projects or modules. This instability can be explained by data heterogeneity. We show that effort and defect data contain many local regions with markedly different properties to the global space. In other words, what appears to be useful in a global context is often irrelevant for particular local contexts. This result raises questions about the generality of conclusions from empirical SE. At the very least, SE researchers should test if their supposedly general conclusions are valid within subsets of their data. At the very most, empirical SE should become a search for local regions with similar properties (and conclusions should be constrained to just those regions).","Estimation,
Software,
Context,
Couplings,
Principal component analysis,
Runtime,
USA Councils"
Energy Reduction in Consolidated Servers through Memory-Aware Virtual Machine Scheduling,"Increasing energy consumption in server consolidation environments leads to high maintenance costs for data centers. Main memory, no less than processor, is a major energy consumer in this environment. This paper proposes a technique for reducing memory energy consumption using virtual machine scheduling in multicore systems. We devise several heuristic scheduling algorithms by using a memory power simulator, which we designed and implemented. We also implement the biggest cover set first (BCSF) scheduling algorithm in the working server system. Through extensive simulation and implementation experiments, we observe the effectiveness of the memory-aware virtual machine scheduling in saving memory energy. In addition, we find out that power-aware memory management is essential to reduce the memory energy consumption.",
New Constructions for Optimal Sets of Frequency-Hopping Sequences,"In this paper, two generic constructions of optimal frequency-hopping sequence (FHS) sets employing d-form functions with difference-balanced property are presented. They generalize the previous constructions of optimal FHS sets using m-sequences and produce new optimal FHS sets that cannot be produced by the earlier constructions. By choosing appropriate d-form functions with difference-balanced property, both constructions lead to FHSs with large linear complexity. In addition, one of the proposed constructions gives new optimal parameters of FHS sets.","Complexity theory,
Equations,
Mathematical model,
Correlation,
Educational institutions,
Finite element methods,
Spread spectrum communication"
Algorithm of Adaptive Fourier Decomposition,"The present paper is a continuing work on the recently established adaptive Fourier decomposition (AFD) mainly stressing on the algorithm aspect, including algorithm analysis and numerical examples. AFD is a variation and realization of greedy algorithm (matching pursuit) suitable for the Hardy H2 and the L2 spaces. Applying AFD to a given signal, one obtains a series expansion in the basic signals, called mono-components, that possess non-negative analytic phase derivatives (functions), or, equivalently, meaningful analytic instantaneous frequencies. AFD is shown to be robust with computational complexity comparable with DFT. Consistent to the greedy algorithm principle experiments show that AFD produces (pre-) mono-component series with efficient energy decay that also leads to efficient pointwise convergence, both in terms of computer running time.","Matching pursuit algorithms,
Greedy algorithms,
Algorithm design and analysis"
Energy-Efficient Multiobjective Thermal Control for Liquid-Cooled 3-D Stacked Architectures,"3-D stacked systems reduce communication delay in multiprocessor system-on-chips (MPSoCs) and enable heterogeneous integration of cores, memories, sensors, and RF devices. However, vertical integration of layers exacerbates temperature-induced problems such as reliability degradation. Liquid cooling is a highly efficient solution to overcome the accelerated thermal problems in 3-D architectures; however, it brings new challenges in modeling and run-time management for such 3-D MPSoCs with multitier liquid cooling. This paper proposes a novel design-time/run-time thermal management strategy. The design-time phase involves a rigorous thermal impact analysis of various thermal control variables. We then utilize this analysis to design a run-time fuzzy controller for improving energy efficiency in 3-D MPSoCs through liquid cooling management and dynamic voltage and frequency scaling (DVFS). The fuzzy controller adjusts the liquid flow rate dynamically to match the cooling demand of the chip for preventing overcooling and for maintaining a stable thermal profile. The DVFS decisions increase chip-level energy savings and help balance the temperature across the system. Our controller is used in conjunction with temperature-aware load balancing and dynamic power management strategies. Experimental results on 2-tier and 4-tier 3-D MPSoCs show that our strategy prevents the system from exceeding the given threshold temperature. At the same time, we reduce cooling energy by up to 63% and system-level energy by up to 21% in comparison to statically setting a flow rate setting to handle worst-case temperatures.",
Estimation and Analysis of Some Generalized Multiple Change-Point Software Reliability Models,"Software typically undergoes debugging during both a testing phase before product release, and an operational phase after product release. But it is noted that the fault detection and removal processes during software development and operation are different. For example, the fault removal during operation occurs generally at a slower pace than development. In this paper, we derive a powerful, easily deployable technique for software reliability prediction and assessment in the testing and operational phases. We first review how several existing software reliability growth models (SRGM) based on non- homogeneous Poisson processes (NHPP) can be readily derived from a unified theory. With the unified theory, we further incorporate the concept of multiple change-points, i.e. points in time when the software environment changes, into software reliability modeling. Several models are proposed and discussed under both ideal and imperfect debugging conditions. We estimate the parameters of the proposed models by employing real software failure data, and give a fair comparison with some existing SRGM. Numerical results show that the proposed models can provide good software reliability prediction in the various stages of software development and operation. Our approach is flexible; we can model various environments ranging from exponential-type to S-shaped NHPP models.",
Q Control of an Atomic Force Microscope Microcantilever: A Sensorless Approach,The scan rate and image resolution of the atomic force microscope (AFM) operating in tapping-mode may be im proved by modifying the quality (Q) factor of the AFM micro cantilever according to the sample type and imaging environment. Piezoelectric shunt control is a new method of controlling the Q factor of a piezoelectric self-actuating AFM microcantilever. The mechanical damping of the microcantilever is controlled by an electrical impedance placed in series with the tip oscillation circuit. A synthetic impedance was designed to allow easy modification of the control parameters which may vary with environmental conditions. The proposed techniques are experimentally demonstrated to reduce the Q factor of an AFM microcantilever from 297.6 to 35.5. AFM images obtained using this method show significant improvement in both scan rate and image quality.,
A Low-Complexity SLM Scheme Using Additive Mapping Sequences for PAPR Reduction of OFDM Signals,"The selected mapping (SLM) scheme is one of the well-known peak-to-average power ratio (PAPR) reduction schemes for orthogonal frequency division multiplexing (OFDM) systems. A number of low-complexity SLM schemes have been proposed but most of them reduce the computational complexity at the cost of bit error rate (BER) or PAPR reduction performance degradation. In this paper, a new low-complexity SLM scheme is proposed, which generates alternative signal sequences by adding mapping signal sequences to an OFDM signal sequence. The proposed scheme considerably reduces the computational complexity without sacrificing BER and PAPR reduction performance only by requiring additional memory to save the additive mapping signal sequences, especially for the OFDM system with quadrature amplitude modulation (QAM). Similarly, a low-complexity SLM scheme is proposed for multi-input multi-output (MIMO) OFDM system with space-frequency block code (SFBC).","Peak to average power ratio,
Computational complexity,
Bit error rate,
OFDM,
Quadrature amplitude modulation"
A First-Order Radiative Transfer Model for Microwave Radiometry of Forest Canopies at L-Band,"In this study, a first-order radiative transfer (RT) model is developed to more accurately account for vegetation canopy scattering by modifying the basic τ-ω model (the zero-order RT solution). In order to optimally utilize microwave radiometric data in soil moisture (SM) retrievals over vegetated landscapes, a quantitative understanding of the relationship between scattering mechanisms within vegetation canopies and the microwave brightness temperature is desirable. The first-order RT model is used to investigate this relationship and to perform a physical analysis of the scattered and emitted radiation from vegetated terrain. This model is based on an iterative solution (successive orders of scattering) of the RT equations up to the first order. This formulation adds a new scattering term to the τ-ω model. The additional term represents emission by particles (vegetation components) in the vegetation layer and emission by the ground that is scattered once by particles in the layer. The model is tested against 1.4-GHz brightness temperature measurements acquired over deciduous trees by a truck-mounted microwave instrument system called ComRAD in 2007. The model predictions are in good agreement with the data, and they give quantitative understanding for the influence of first-order scattering within the canopy on the brightness temperature. The model results show that the scattering term is significant for trees and modifications are necessary to the τ-ω model when applied to dense vegetation. Numerical simulations also indicate that the scattering term has a negligible dependence on SM and is mainly a function of the incidence angle and polarization of the microwave observation.","Scattering,
Mathematical model,
Equations,
Vegetation mapping,
Vegetation,
Microwave radiometry,
Microwave theory and techniques"
A Corpus-Based Approach to Speech Enhancement From Nonstationary Noise,"Temporal dynamics and speaker characteristics are two important features of speech that distinguish speech from noise. In this paper, we propose a method to maximally extract these two features of speech for speech enhancement. We demonstrate that this can reduce the requirement for prior information about the noise, which can be difficult to estimate for fast-varying noise. Given noisy speech, the new approach estimates clean speech by recognizing long segments of the clean speech as whole units. In the recognition, clean speech sentences, taken from a speech corpus, are used as examples. Matching segments are identified between the noisy sentence and the corpus sentences. The estimate is formed by using the longest matching segments found in the corpus sentences. Longer speech segments as whole units contain more distinct dynamics and richer speaker characteristics, and can be identified more accurately from noise than shorter speech segments. Therefore, estimation based on the longest recognized segments increases the noise immunity and hence the estimation accuracy. The new approach consists of a statistical model to represent up to sentence-long temporal dynamics in the corpus speech, and an algorithm to identify the longest matching segments between the noisy sentence and the corpus sentences. The algorithm is made more robust to noise uncertainty by introducing missing-feature based noise compensation into the corpus sentences. Experiments have been conducted on the TIMIT database for speech enhancement from various types of nonstationary noise including song, music, and crosstalk speech. The new approach has shown improved performance over conventional enhancement algorithms in both objective and subjective evaluations.",
Information capacity of energy harvesting sensor nodes,Sensor nodes with energy harvesting sources are gaining popularity due to their ability to improve the network life time and are becoming a preferred choice supporting `green communication'. We study such a sensor node with an energy harvesting source and compare various architectures by which the harvested energy is used. We find its Shannon capacity when it is transmitting its observations over an AWGN channel and show that the capacity achieving energy management policies are related to the throughput optimal policies. We also obtain the capacity when energy conserving sleep-wake modes are supported and an achievable rate for the system with inefficiencies in energy storage.,"Energy harvesting,
Buffer storage,
AWGN channels,
Batteries,
Channel capacity,
Sensors,
Throughput"
Usage pattern analysis of smartphones,"Recently, mobile traffic has increased tremendously due to the deployment of smart devices such as smartphones and smart tablets. These devices use various types of access networks such as 3G, WiFi, and mobile WiMAX. Network service providers also provide these access networks with various types of plans. There is a growing need to manage these smart devices and mobile networks. However, research on mobile network management has focused on the performance of the network itself. Few research has focused on applying the usage patterns of smartphone users to mobile network management. In this paper, we present an analysis of smartphone usage patterns. We define the five possible states of a smartphone based on such a phone's basic operations. We collected real usage log data from real smartphone users over a two month period. We show that all users have their own usage pattern. We present a case study in order to show how to apply usage pattern information to power management of smartphones. We also discuss how to apply such information to mobile device management and network management.","Smart phones,
IEEE 802.11 Standards,
Batteries,
Mobile communication,
Mobile computing,
Data communication"
Ecological inference in empirical software engineering,"Software systems are decomposed hierarchically, for example, into modules, packages and files. This hierarchical decomposition has a profound influence on evolvability, maintainability and work assignment. Hierarchical decomposition is thus clearly of central concern for empirical software engineering researchers; but it also poses a quandary. At what level do we study phenomena, such as quality, distribution, collaboration and productivity? At the level of files? packages? or modules? How does the level of study affect the truth, meaning, and relevance of the findings? In other fields it has been found that choosing the wrong level might lead to misleading or fallacious results. Choosing a proper level, for study, is thus vitally important for empirical software engineering research; but this issue hasn't thus far been explicitly investigated. We describe the related idea of ecological inference and ecological fallacy from sociology and epidemiology, and explore its relevance to empirical software engineering; we also present some case studies, using defect and process data from 18 open source projects to illustrate the risks of modeling at an aggregation level in the context of defect prediction, as well as in hypothesis testing.","Predictive models,
Biological system modeling,
Software engineering,
Measurement,
Object oriented modeling,
Testing,
Data models"
Evolutionary artificial neural network based on Chemical Reaction Optimization,"Evolutionary algorithms (EAs) are very popular tools to design and evolve artificial neural networks (ANNs), especially to train them. These methods have advantages over the conventional backpropagation (BP) method because of their low computational requirement when searching in a large solution space. In this paper, we employ Chemical Reaction Optimization (CRO), a newly developed global optimization method, to replace BP in training neural networks. CRO is a population-based metaheuristics mimicking the transition of molecules and their interactions in a chemical reaction. Simulation results show that CRO outperforms many EA strategies commonly used to train neural networks.","Artificial neural networks,
Training,
Chemicals,
Optimization,
Neurons,
Algorithm design and analysis,
Testing"
Invertible bloom lookup tables,"We present a version of the Bloom filter data structure that supports not only the insertion, deletion, and lookup of key-value pairs, but also allows a complete listing of the pairs it contains with high probability, as long the number of key-value pairs is below a designed threshold. Our structure allows the number of key-value pairs to greatly exceed this threshold during normal operation. Exceeding the threshold simply temporarily prevents content listing and reduces the probability of a successful lookup. If entries are later deleted to return the structure below the threshold, everything again functions appropriately. We also show that simple variations of our structure are robust to certain standard errors, such as the deletion of a key without a corresponding insertion or the insertion of two distinct values for a key. The properties of our structure make it suitable for several applications, including database and networking applications that we highlight.","Data structures,
Random access memory,
Databases,
Polynomials,
Fault tolerance,
Fault tolerant systems,
Probabilistic logic"
Structural Analysis of Articular Cartilage Using Multiphoton Microscopy: Input for Biomechanical Modeling,"The 3-D morphology of chicken articular cartilage was quantified using multiphoton microscopy (MPM) for use in continuum-mechanical modeling. To motivate this morphological study we propose aspects of a new, 3-D finite strain constitutive model for articular cartilage focusing on the essential load-bearing morphology: an inhomogeneous, poro-(visco)elastic solid matrix reinforced by an anisotropic, (visco)elastic dispersed fiber fabric which is saturated by an incompressible fluid residing in strain-dependent pores. Samples of fresh chicken cartilage were sectioned in three orthogonal planes and imaged using MPM, specifically imaging the collagen fibers using second harmonic generation. Employing image analysis techniques based on Fourier analysis, we derived the principal directionality and dispersion of the collagen fiber fabric in the superficial layer. In the middle layer, objective thresholding techniques were used to extract the volume fraction occupied by extracellular collagen matrix. In conjunction with information available in the literature, or additional experimental testing, we show how this data can be used to derive a 3-D map of the initial solid volume fraction and Darcy permeability.",
On-Chip Slot-Ring and High-Gain Horn Antennas for Millimeter-Wave Wafer-Scale Silicon Systems,"This paper presents on-chip slot-ring and horn antennas for wafer-scale silicon systems. A high efficiency is achieved using a 100-μm quartz superstrate on top of the silicon chip, and a low-loss microstrip transformer using the silicon back-end metallization. A finite ground plane is also used to reduce the power coupled to the TEM mode. The slot-ring and 1-λ02 horn achieve a measured gain of 0-2 and 6-8 dBi at 90-96 GHz, respectively, and a radiation efficiency of ~50%. The horns achieve a high antenna gain without occupying a large area on the silicon wafer, thus resulting in a low-cost system. The designs are compatible with either single- or two-antenna transceivers, or with wafer-scale imaging systems and power-combining arrays.",
"A Novel Magnetic-Levitation System: Design, Implementation, and Nonlinear Control","This paper concerns the design, implementation, and nonlinear velocity-tracking control of a novel magnetic-levitation (maglev) system for magnetically levitated trains. The proposed system uses only one tubular linear induction motor to produce three forces required in a maglev system: propulsion, levitation, and guidance. Classical maglev systems, on the other hand, contain a separate force-generating system to build each of these three forces. Another benefit that the proposed system offers is that there is no need to control the guidance, and particularly, the levitation forces, one of the most challenging tasks in maglev systems. The system always centers the moving part during operation and eliminates the necessity for control of the levitation and guidance forces. However, the propulsion force strongly requires some control efforts because a linear induction motor has nonlinear system dynamics. This paper gives a condensed design guideline based on the mature theory of electromagnetic launchers, particularly the linear induction launcher type. It explains the implementation process, shows experimental test results, and finally, presents a nonlinear partial state-feedback controller for the proposed system.",
Parameterization-Invariant Shape Comparisons of Anatomical Surfaces,"We consider 3-D brain structures as continuous parameterized surfaces and present a metric for their comparisons that is invariant to the way they are parameterized. Past comparisons of such surfaces involve either volume deformations or non-rigid matching under fixed parameterizations of surfaces. We propose a new mathematical representation of surfaces, called q-maps, such that L2 distances between such maps are invariant to re-parameterizations. This property allows for removing the parameterization variability by optimizing over the re-parameterization group, resulting in a proper parameterization-invariant distance between shapes of surfaces. We demonstrate this method in shape analysis of multiple brain structures, for 34 subjects in the Detroit Fetal Alcohol and Drug Exposure Cohort study, which results in a 91% classification rate for attention deficit hyperactivity disorder cases and controls. This method outperforms some existing techniques such as spherical harmonic point distribution model (SPHARM-PDM) or iterative closest point (ICP).",
Segmentation of Plaques in Sequences of Ultrasonic B-Mode Images of Carotid Arteries Based on Motion Estimation and a Bayesian Model,"The goal of this paper is to perform a segmentation of atherosclerotic plaques in view of evaluating their burden and to provide boundaries for computing properties such as the plaque deformation and elasticity distribution (elastogram and modulogram). The echogenicity of a region of interest comprising the plaque, the vessel lumen, and the adventitia of the artery wall in an ultrasonic B-mode image was modeled by mixtures of three Nakagami distributions, which yielded the likelihood of a Bayesian segmentation model. The main contribution of this paper is the estimation of the motion field and its integration into the prior of the Bayesian model that included a local geometrical smoothness constraint, as well as an original spatiotemporal cohesion constraint. The Maximum A Posteriori of the proposed model was computed with a variant of the exploration/selection algorithm. The starting point is a manual segmentation of the first frame. The proposed method was quantitatively compared with manual segmentations of all frames by an expert technician. Various measures were used for this evaluation, including the mean point-to-point distance and the Hausdorff distance. Results were evaluated on 94 sequences of 33 patients (for a total of 8988 images). We report a mean point-to-point distance of 0.24 ± 0.08 mm and a Hausdorff distance of 1.24 ± 0.40 mm. Our tests showed that the algorithm was not sensitive to the degree of stenosis or calcification.","Image segmentation,
Pixel,
Motion segmentation,
Carotid arteries,
Bayesian methods,
Video sequences,
Computational modeling"
A fully automated greedy square jigsaw puzzle solver,"In the square jigsaw puzzle problem one is required to reconstruct the complete image from a set of non-overlapping, unordered, square puzzle parts. Here we propose a fully automatic solver for this problem, where unlike some previous work, it assumes no clues regarding parts' location and requires no prior knowledge about the original image or its simplified (e.g., lower resolution) versions. To do so, we introduce a greedy solver which combines both informed piece placement and rearrangement of puzzle segments to find the final solution. Among our other contributions are new compatibility metrics which better predict the chances of two given parts to be neighbors, and a novel estimation measure which evaluates the quality of puzzle solutions without the need for ground-truth information. Incorporating these contributions, our approach facilitates solutions that surpass state-of-the-art solvers on puzzles of size larger than ever attempted before.","Accuracy,
Estimation,
Image segmentation,
Image reconstruction,
Particle measurements,
Atmospheric measurements"
Performance of Multihop Relay Systems with Co-Channel Interference in Rayleigh Fading Channels,"In this letter we investigate the effect of co-channel interference on the performance of multihop transmission systems that employ amplify-and-forward relays and operate in a Rayleigh fading environment. We assume that an arbitrary number of interferers with arbitrary powers are present at each relay node and derive useful bounds for important performance measures, such as the outage probability and the average symbol error probability of various digital modulation schemes.","Signal to noise ratio,
Relays,
Fading,
Interchannel interference,
Error probability,
Analytical models"
Random N-Finder (N-FINDR) Endmember Extraction Algorithms for Hyperspectral Imagery,"N-finder algorithm (N-FINDR) has been widely used in endmember extraction. When it comes to implementation several issues need to be addressed. One is determination of endmembers, p required for N-FINDR to generate. Another is its computational complexity resulting from an exhaustive search. A third one is its requirement of dimensionality reduction. A fourth and probably the most critical issue is its use of random initial endmembers which results in inconsistent final endmember selection and results are not reproducible. This paper re-invents the wheel by re-designing the N-FINDR in such a way that all the above-mentioned issues can be resolved while making the last issue an advantage. The idea is to implement the N-FINDR as a random algorithm, called random N-FINDR (RN-FINDR) so that a single run using one set of random initial endmembers is considered as one realization. If there is an endmember present in the data, it should appear in any realization regardless of what random set of initial endmembers is used. In this case, the N-FINDR is terminated when the intersection of all realizations produced by two consecutive runs of RN-FINDR remains the same in which case the p is then automatically determined by the intersection set without appealing for any criterion. In order to substantiate the proposed RN-FINDR custom-designed synthetic image experiments with complete knowledge are conducted for validation and real image experiments are also performed to demonstrate its utility in applications.","Hyperspectral imaging,
Computational complexity,
Spatial resolution,
Pixel,
Algorithm design and analysis"
Random N-Finder (N-FINDR) Endmember Extraction Algorithms for Hyperspectral Imagery,,
Downlink Subchannel and Power Allocation in Multi-Cell OFDMA Cognitive Radio Networks,"We propose a novel subchannel and transmission power allocation scheme for multi-cell orthogonal frequency-division multiple access (OFDMA) networks with cognitive radio (CR) functionality. The multi-cell CR-OFDMA network not only has to control the interference to the primary users (PUs) but also has to coordinate inter-cell interference in itself. The proposed scheme allocates the subchannels to the cells in a way to maximize the system capacity, while at the same time limiting the transmission power on the subchannels on which the PUs are active. We formulate this joint subchannel and transmission power allocation problem as an optimization problem. To efficiently solve the problem, we divide it into multiple subproblems by using the dual decomposition method, and present the algorithms to solve these subproblems. The resulting scheme efficiently allocates the subchannels and the transmission power in a distributed way. The simulation results show that the proposed scheme provides significant improvement over the traditional fixed subchannel allocation scheme in terms of system throughput.",
Real time simulation of a power system with VSG hardware in the loop,"The method to investigate the interaction between a Virtual Synchronous Generator (VSG) and a power system is presented here. A VSG is a power-electronics based device that emulates the rotational inertia of synchronous generators. The development of such a device started in a pure simulation environment and extends to the practical realization of a VSG. Investigating the interaction between a VSG and a power system is a problem, as a power system cannot be manipulated without disturbing customers. By replacing the power system with a real time simulated one, this problem can be solved. The VSG then interacts with the simulated power system through a power interface. The advantages of such a laboratory test-setup are numerous and should prove beneficial to the further development of the VSG concept.",
A Portable Wireless Online Closed-Loop Seizure Controller in Freely Moving Rats,"A considerable portion of epilepsy cannot be well treated by available therapies nowadays. Brain stimulation with closed-loop seizure control has recently been proposed as an innovative and effective alternative. A portable wireless online closed-loop seizure controller in freely moving rats was developed and shown with several aspects of advantages, including the following: 1) high accuracy of real-time seizure detection (92-99% during wake-sleep states); 2) low cost; and 3) low power consumption. The seizure detection latency was not greater than 0.6 s after seizure onset. A wireless communication feature also provided flexibility for subjects freeing from the hassle of wires. The observation showed that the stimulation elicited no abnormal behavior and had no sleep interruption to the subjects. The experiment data supported the functional possibility of a real-time closed-loop seizure controller.",
"Notice of Violation of IEEE Publication Principles
Bag-of-Features Based Medical Image Retrieval via Multiple Assignment and Visual Words Weighting","Notice of Violation of IEEE Publication Principles

""Bag-of-Features Based Medical Image Retrieval via Multiple Assignment and Visual Words Weighting""
by Jingyan Wang, Yongping Li, Ying Zhang, Chao Wang, Honglan Xie, Guoling Chen, and Xin Gao
in the IEEE Transactions on Medical Imaging, Vol. 30, No. 11, November 2011, pp. 1996-2011

After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.

This paper contains substantial duplication of original text from the paper cited below. The original text was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission.

Due to the nature of this violation, reasonable effort should be made to remove all past references to this paper, and future references should be made to the following article:

""Histopathy Image Classification Using Bag of Features and Kernel Functions""
by Juan C. Caicedo, Angel Cruz, and Fabio Gonzalez
in Lecture Notes in Computer Science. Artificial Intelligence in Medicine, AIME-09, July 2009.Volume 5651/2009, pp 126-135

Bag-of-features based approaches have become prominent for image retrieval and image classification tasks in the past decade. Such methods represent an image as a collection of local features, such as image patches and key points with scale invariant feature transform (SIFT) descriptors. To improve the bag-of-features methods, we first model the assignments of local descriptors as contribution functions, and then propose a novel multiple assignment strategy. Assuming the local features can be reconstructed by their neighboring visual words in a vocabulary, reconstruction weights can be solved by quadratic programming. The weights are then used to build contribution functions, resulting in a novel assignment method, called quadratic programming (QP) assignment. We further propose a novel visual word weighting method. The discriminative power of each visual word is analyzed by the sub-similarity function in the bin that corresponds to the visual word. Each sub-similarity function is then treated as a weak classifier. A strong classifier is learned by boosting methods that combine those weak classifiers. The weighting factors of the visual words are learned accordingly. We evaluate the proposed methods on medical image retrieval tasks. The methods are tested on three well-known data sets, i.e., the ImageCLEFmed data set, the 304 CT Set, and the basal-cell carcinoma image set. Experimental results demonstrate that the proposed QP assignment outperforms the traditional nearest neighbor assignment, the multiple assignment, and the soft assignment, whereas the proposed boosting based weighting strategy outperforms the state-of-the-art weighting methods, such as the term frequency weights and the term frequency-inverse document frequency weights.","Visualization,
Image retrieval,
Biomedical imaging,
Image reconstruction,
Histograms"
P-Sense: A participatory sensing system for air pollution monitoring and control,"This paper presents P-Sense (Pollution-Sense), a PS system for air pollution monitoring and control. The ultimate goal of this system is to allow government officials, international organizations, communities, and individuals access to the pollution data to address their particular problems and needs. P-Sense should provide large amounts of pollution data in time and space with different granularities. Government officials will have data to monitor and control the Air Quality Index (AQI) [1] of a city, state, or country; doctors will be able to correlate respiratory problems of their patients to the AQI they are exposed to during their daily activities, in the places they work and live; county officials, community developers, and realtors will have data to determine the best place where to build a new school or community and advertise properties according to the AQI where they are located.","Sensors,
Data visualization,
Servers,
Computer architecture,
Monitoring,
Mobile communication,
Pollution measurement"
Bounds for the BER of Codes With Fixed Cross Correlation in SAC-OCDMA Systems,"In this paper, two lower and upper bounds for the bit error rate of codes with fixed cross-correlation in spectral-amplitude-coding optical code-division multiple access systems are offered. In this study, we consider only the phase-induced intensity noise and neglect other noises such as shot and thermal noises, in the performance analysis. Also, it is assumed that users are synchronous. This bound is obtained using combinatorics approach and utilizing simple inequalities. In numerical results, the comparison between the upper bound, lower bound, and simulation results for MQC, MFH, BIBD, and Hadamard codes is presented, and the tightness of the bounds is evaluated.","Upper bound,
Bit error rate,
Optical receivers,
Noise,
Equations,
Optical polarization"
Feature context for image classification and object detection,"In this paper, we presents a new method to encode the spatial information of local image features, which is a natural extension of Shape Context (SC), so we call it Feature Context (FC). Given a position in a image, SC computes histogram of other points belonging to the target binary shape based on their distances and angles to the position. The value of each histogram bin of SC is the number of the shape points in the region assigned to the bin. Thus, SC requires knowing the location of the points of the target shape. In other words, an image point can have only two labels, it belongs to the shape or not. In contrast, FC can be applied to the whole image without knowing the location of the target shape in the image. Each image point can have multiple labels depending on its local features. The value of each histogram bin of FC is a histogram of various features assigned to points in the bin region. We also introduce an efficient coding method to encode the local image features, call Radial Basis Coding (RBC). Combining RBC and FC together, and using a linear SVM classifier, our method is suitable for both image classification and object detection.","Encoding,
Shape,
Training,
Image coding,
Context,
Feature extraction,
Support vector machines"
Improving Cooperative Positioning for Vehicular Networks,"Cooperative positioning (CP) can potentially improve the accuracy of vehicle location information, which is vital for several road safety applications. Although concepts of CP have been introduced, the efficiency of CP under real-world vehicular communication constraints is largely unknown. Our simulations reveal that the frequent exchange of large amounts of range information required by existing CP schemes not only increases the packet collision rate of the vehicular network but reduces the effectiveness of the CP as well. To address this issue, we propose simple easily deployable protocol improvements in terms of utilizing as much range information as possible, reducing range broadcasts by piggybacking, compressing the range information, tuning the broadcast frequency, and combining multiple packets using network coding. Our results demonstrate that, even under dense traffic conditions, these protocol improvements achieve a twofold reduction in packet loss rates and increase the positioning accuracy of CP by 40%.","Vehicles,
Global Positioning System,
Accuracy,
Distance measurement,
Kinematics,
Ad hoc networks,
Safety"
Considering binocular spatial sensitivity in stereoscopic image quality assessment,"Developing reliable and generic perceptual quality metrics is an challenging issue in three-dimensional (3D) visual signals processing, although many two dimensional (2D) image quality metrics have been proposed and work well on 2D images. In this paper, the binocular spatial sensitivity influenced by the binocular fusion and rivalry properties is considered in the quality measurement. Firstly, the binocular spatial sensitivity map is modeled to reflect the properties. Then, a framework of integration of binocular spatial sensitivity map into quality assessment is presented. Experimental results show that the proposed metric correlate well with human perception of quality on a dataset of 3D images and human subjective scores.","Stereo image processing,
Image quality,
Image coding,
Sensitivity,
Three dimensional displays,
Visualization"
A Novel Uplink Multiple Access Scheme Based on TDS-FDMA,"This contribution proposes a novel time-domain synchronous frequency division multiple access (TDS-FDMA) scheme to support multi-user uplink application. A unified frame structure for both single-carrier and multi-carrier transmissions and the corresponding low-complexity receiver design are derived. Compared with standard cyclic prefix based orthogonal frequency division multiple access systems, the proposed TDS-FDMA scheme improves the spectral efficiency by about 5% to 10% as well as imposes a similarly low computational complexity, while obtaining a slightly better bit error rate performance over Rayleigh fading channels.","Digital video broadcasting,
Wireless communication,
Channel estimation,
Bit error rate,
Signal to noise ratio,
Doppler effect,
OFDM"
A Linear Doubly Salient Permanent-Magnet Motor With Modular and Complementary Structure,"A linear doubly salient permanent magnet (LDSPM) motor is particularly suitable for long stator applications due to its simple and low cost stator, which consists of only iron. This paper proposes a new LDSPM motor design with complementary and modular structure. The key of this structure is that the primary mover is composed of two modules whose positions are mutually four and one half of the stator pole pitch apart and there is a flux barrier between them. Hence, the back electromotive force (EMF) waveform and cogging force of the two modules have 180 electrical degree differences. This design results in the total cogging force being significantly reduced and the back-EMF of each phase becoming symmetrical because the even harmonics are canceled. For fair comparison, an existing linear LDSPM motor is designed based on the same electromagnetic parameters and compared by the means of finite element analysis (FEA). The results reveal that the proposed LDSPM motor can offer symmetrical back-EMF waveforms, smaller cogging force, lower force ripple, and higher magnet utilization factor than the existing one.","Finite element methods,
Permanent magnet motors,
Coils,
Stator windings,
Magnetic flux"
A New Approach to Dynamic Eye-in-Hand Visual Tracking Using Nonlinear Observers,"This paper presents a new controller for locking a moving object in 3-D space at a particular position (for example, the center) on the image plane of a camera mounted on a robot by actively moving the camera. The controller is designed to cope with both the highly nonlinear robot dynamics and unknown motion of the object. Based on the fact that the unknown position of the moving object appears linearly in the closed-loop dynamics of the system if the depth-independent image Jacobian is used, we developed a nonlinear observer to estimate the 3-D motion of the object online. With a full consideration of dynamic responses of the robot manipulator, we employ the Lyapunov method to prove asymptotic convergence of the image errors. Experimental results are used to demonstrate the performance of the proposed approach.","Nonlinear dynamical systems,
Robot vision systems,
Cameras,
Orbital robotics,
Manipulator dynamics,
Motion control,
Jacobian matrices,
Motion estimation,
Lyapunov method,
Convergence"
An analytical formulation of global occlusion reasoning for multi-target tracking,"We present a principled model for occlusion reasoning in complex scenarios with frequent inter-object occlusions, and its application to multi-target tracking. To compute the putative overlap between pairs of targets, we represent each target with a Gaussian. Conveniently, this leads to an analytical form for the relative overlap - another Gaussian - which is combined with a sigmoidal term for modeling depth relations. Our global occlusion model bears several advantages: Global target visibility can be computed efficiently in closed-form, and varying degrees of partial occlusion can be naturally accounted for. Moreover, the dependence of the occlusion on the target locations - i.e. the gradient of the overlap - can also be computed in closed-form, which makes it possible to efficiently include the proposed occlusion model in a continuous energy minimization framework. Experimental results on seven datasets confirm that the proposed formulation consistently reduces missed targets and lost trajectories, especially in challenging scenarios with crowds and severe inter-object occlusions.",
Design and Analysis of a Stage-Scaled Distributed Power Amplifier,"This paper presents the design, analysis, and measurement of a pseudodifferential distributed power amplifier in a 0.13-μm SiGe BiCMOS process. To mitigate the large loaded transmission line loss due to bipolar base resistance, emitter degeneration is used and an optimal small-signal design point is selected for maximum gain-bandwidth product. To enhance the efficiency of distributed amplifiers (DAs), a stage-scaling technique is proposed to utilize more voltage swing while reducing the total current consumption. The output power and efficiency of the amplifier are evaluated as a function of two scaling coefficients. The fabricated distributed power amplifier achieves a small-signal gain of 10 dB and a 3-dB bandwidth of 110 GHz. The measured midband saturated output power is 17.5 dBm with a peak power-added efficiency (PAE) of 13.2% and the 3-dB output power bandwidth is greater than 77 GHz. The amplifier consumes 119 mA from a 3-V supply and occupies an area of 2.08 mm × 1.05 mm. Compared to a uniform nonscaled DA fabricated in the same process, the stage-scaled amplifier achieves the same output power with higher collector efficiency and PAE over the entire measured frequency range.","Bandwidth,
Impedance,
Capacitance,
Transistors,
Power generation,
Resistors,
Transmission line measurements"
Controllability of diffusively-coupled multi-agent systems with general and distance regular coupling topologies,"This paper studies the controllability of linearly diffusively coupled multi-agent systems when some agents, called leaders, are under the influence of external control inputs. We bound the system's controllable subspace using combinatorial characteristics of some partitions of the graph describing the neighbor relationships between the agents. In particular, when such graphs are distance regular, we provide a full characterization of the controllable subspace for single leader cases while for multi-leader cases, a necessary condition and a sufficient condition for controllability are given respectively. In the end, we discuss how to choose leaders among the agents to guarantee controllability when the graphs are cycles or complete graphs, which are special subclasses of distance regular graphs.","Controllability,
Lead,
Multiagent systems,
Upper bound,
Vectors,
Couplings"
Impact of Alpha Particles on the Electrical Characteristics of TiO_{2} Memristors,"Titanium-oxide (TiO2 ) memristors exposed to 1-MeV alpha particles exhibit only minor changes in the electrical response for ion fluencies up to 1014 cm - 2. At higher fluence levels, virgin and off-state devices exhibit measurable increases in current conduction between the two platinum (Pt) electrodes. Analysis, supported by radiation transport and numerical device simulations, suggests that radiation-induced displacement damage in the TiO2 film increases the density of oxygen vacancies, thereby altering both resistivity in the bulk of the transition-metal oxide and the junction characteristics of Pt-TiO2 interface. Nevertheless, the experimental results indicate continued switching functionality of the memristors even after exposure to 1015 cm- 2 alpha particles. The high intrinsic vacancy density in the devices prior to radiation exposure is identified as the primary feature contributing to apparent radiation hardness.","Memristors,
Alpha particles,
Semiconductor process modeling,
Radiation effects,
Titanium compounds"
Unsupervised learning of a scene-specific coarse gaze estimator,"We present a method to estimate the coarse gaze directions of people from surveillance data. Unlike previous work we aim to do this without recourse to a large hand-labelled corpus of training data. In contrast we propose a method for learning a classifier without any hand labelled data using only the output from an automatic tracking system. A Conditional Random Field is used to model the interactions between the head motion, walking direction, and appearance to recover the gaze directions and simultaneously train randomised decision tree classifiers. Experiments demonstrate performance exceeding that of conventionally trained classifiers on two large surveillance datasets.","Angular velocity,
Head,
Vegetation,
Legged locomotion,
Data models,
Image color analysis,
Optimization"
Visual and semantic similarity in ImageNet,"Many computer vision approaches take for granted positive answers to questions such as “Are semantic categories visually separable?” and “Is visual similarity correlated to semantic similarity?”. In this paper, we study experimentally whether these assumptions hold and show parallels to questions investigated in cognitive science about the human visual system. The insights gained from our analysis enable building a novel distance function between images assessing whether they are from the same basic-level category. This function goes beyond direct visual distance as it also exploits semantic similarity measured through ImageNet. We demonstrate experimentally that it outperforms purely visual distances.","Visualization,
Semantics,
Prototypes,
Humans,
Animals,
Computer vision,
Histograms"
Coded Free-Space Optical Links over Strong Turbulence and Misalignment Fading Channels,"The performance of optical wireless systems deteriorates to a large extent from the presence of turbulence and pointing error effects. To meet the typical bit error rate (BER) targets for reliable communications within the practical ranges of signal-to-noise ratio, error control coding schemes are often proposed. This paper investigates the error performance for convolutional coded on-off keying free-space optical systems through symbol by symbol interleaved channels characterized by strong turbulence and/or pointing error effects. We consider several channel types and derive exact analytical expressions for the pairwise error probability. These expressions are applied to obtain upper bounds on the BER performance using the transfer function technique.","Fading,
Bit error rate,
Receivers,
Optical transmitters,
Upper bound,
Signal to noise ratio,
Encoding"
Optimal scheduling in cooperate-to-join Cognitive Radio Networks,"Optimal transmission scheduling in wireless cognitive networks is considered under the spectrum leasing model. We propose a cooperative scheme in which secondary nodes share the time slot with primary nodes in return for cooperation. Cooperation is feasible only if the system's performance is improved over the non-cooperative case. First, we investigate a scenario where secondary users are interested in immediate rewards. Then, we formulate another problem where the secondary users are guaranteed a portion of the primary utility, on a long term basis, in return for cooperation. In both scenarios, our proposed schemes are shown to outperform non-cooperative scheduling schemes, in terms of both individual and total expected utility, for a given set of feasible constraints. Based on Lyapunov Optimization techniques, we show that our schemes are arbitrarily close to the optimal performance at the price of reduced convergence rate.",
Remote-Sensing Image Compression Using Two-Dimensional Oriented Wavelet Transform,"In this paper, a 2-D oriented wavelet transform (OWT) is introduced for efficient remote-sensing image compression. The proposed 2-D OWT can perform integrative oriented transform in arbitrary direction and achieve a significant transform coding gain. To maximize the transform coding gain, two separable 1-D transforms are implemented in the same direction for local areas with direction consistency. Subpixel interpolation rules are designed for rectangular subbands generation. In addition, semidirection displacement is adjusted to handle direction mismatch after the first 1-D transform. Experimental results demonstrate that the proposed 2-D OWT compression scheme outperforms JPEG2000 for remote-sensing images with high resolution, up to 0.43 dB in peak signal-to-noise ratio (PSNR), 0.0261 in the measure of structural similarity, 0.44% in Kappa coefficients, respectively, and significant subjective improvement. Meanwhile, it outperforms JPEG2000, previous adaptive directional lifting and weighted adaptive lifting methods, up to 1.98, 0.36, and 0.19 dB in PSNR for natural images. Furthermore, it is suitable for real-time remote-sensing processing for its low computational cost.",
A 0.7-to-3.5 GHz 0.6-to-2.8 mW Highly Digital Phase-Locked Loop With Bandwidth Tracking,"A digital phase-locked loop (DPLL) employs a linear proportional path, a double integral path, bandwidth and tuning range tracking; and a novel delta-sigma digital to analog converter to achieve low jitter, wide operating range and low power. The proposed proportional path decouples the detector quantization error and oscillator noise bandwidth tradeoff and helps maximize bandwidth to suppress digitally controlled oscillator (DCO) phase noise in a power efficient manner. A double integral path alleviates the tradeoff between DCO tuning range and its frequency quantization error. The high resolution of the DCO was maintained over a wide range of sampling clock frequencies by using a delta-sigma digital to analog converter and a continuously tunable switched-RC filter. Bandwidth and tuning range tracking are employed to achieve low jitter over the entire operating range. The prototype DPLL, fabricated in a 90 nm CMOS process, operates from 0.7 GHz to 3.5 GHz. At 2.5 GHz, the proposed DPLL consumes only 1.6 mW power from a 1 V supply and achieves 1.6 ps and 11.6 ps of long-term r.m.s and peak jitter, respectively.","Bandwidth,
Jitter,
Tuning,
Quantization,
Phase locked loops,
Oscillators,
Phase frequency detector"
A Study on Universal Background Model Training in Speaker Verification,"State-of-the-art Gaussian mixture model (GMM)-based speaker recognition/verification systems utilize a universal background model (UBM), which typically requires extensive resources, especially if multiple channel and microphone categories are considered. In this study, a systematic analysis of speaker verification system performance is considered for which the UBM data is selected and purposefully altered in different ways, including variation in the amount of data, sub-sampling structure of the feature frames, and variation in the number of speakers. An objective measure is formulated from the UBM covariance matrix which is found to be highly correlated with system performance when the data amount was varied while keeping the UBM data set constant, and increasing the number of UBM speakers while keeping the data amount constant. The advantages of feature sub-sampling for improving UBM training speed is also discussed, and a novel and effective phonetic distance-based frame selection method is developed. The sub-sampling methods presented are shown to retain baseline equal error rate (EER) system performance using only 1% of the original UBM data, resulting in a drastic reduction in UBM training computation time. This, in theory, dispels the myth of “There's no data like more data” for the purpose of UBM construction. With respect to the UBM speakers, the effect of systematically controlling the number of training (UBM) speakers versus overall system performance is analyzed. It is shown experimentally that increasing the inter-speaker variability in the UBM data while maintaining the overall total data size constant gradually improves system performance. Finally, two alternative speaker selection methods based on different speaker diversity measures are presented. Using the proposed schemes, it is shown that by selecting a diverse set of UBM speakers, the baseline system performance can be retained using less than 30% of the original UBM speakers.","Training,
System performance,
Microphones,
NIST,
Probability density function,
Speech,
Time frequency analysis"
Modelling Prostate Motion for Data Fusion During Image-Guided Interventions,"There is growing clinical demand for image registration techniques that allow multimodal data fusion for accurate targeting of needle biopsy and ablative prostate cancer treatments. However, during procedures where transrectal ultrasound (TRUS) guidance is used, substantial gland deformation can occur due to TRUS probe pressure. In this paper, the ability of a statistical shape/motion model, trained using finite element simulations, to predict and compensate for this source of motion is investigated. Three-dimensional ultrasound images acquired on five patient prostates, before and after TRUS-probe-induced deformation, were registered using a nonrigid, surface-based method, and the accuracy of different deformation models compared. Registration using a statistical motion model was found to outperform alternative elastic deformation methods in terms of accuracy and robustness, and required substantially fewer target surface points to achieve a successful registration. The mean final target registration error (based on anatomical landmarks) using this method was 1.8 mm. We conclude that a statistical model of prostate deformation provides an accurate, rapid and robust means of predicting prostate deformation from sparse surface data, and is therefore well-suited to a number of interventional applications where there is a need for deformation compensation.","Glands,
Biological system modeling,
Image segmentation,
Material properties,
Biopsy,
Finite element methods"
Distributed Passive Intermodulation Distortion on Transmission Lines,"A theoretical treatment of distributed electro-thermally induced intermodulation distortion is developed for microstrip transmission lines. The growth of passive intermodulation distortion (PIM) along the length of a line is derived accounting for both loss and electrical dispersion. PIM dependencies on width, length, thickness, and substrate parameters are analyzed leading to design guidelines for low distortion lines. Single metal silver transmission lines are fabricated on sapphire and fused-quartz substrates to isolate the electro-thermal effect and validate the model. Electro-thermal PIM is measured in a two-tone test with tone separation ranging from 4 Hz to 10 kHz.","Strips,
Resistance heating,
Substrates,
Power transmission lines,
Heat transfer"
Normal Factor Graphs and Holographic Transformations,"This paper stands at the intersection of two distinct lines of research. One line is “holographic algorithms,” a powerful approach introduced by Valiant for solving various counting problems in computer science; the other is “normal factor graphs,” an elegant framework proposed by Forney for representing codes defined on graphs. We introduce the notion of holographic transformations for normal factor graphs, and establish a very general theorem, called the generalized Holant theorem, which relates a normal factor graph to its holographic transformation. We show that the generalized Holant theorem on the one hand underlies the principle of holographic algorithms, and on the other hand reduces to a general duality theorem for normal factor graphs, a special case of which was first proved by Forney. In the course of our development, we formalize a new semantics for normal factor graphs, which highlights various linear algebraic properties that potentially enable the use of normal factor graphs as a linear algebraic tool.","Semantics,
Vectors,
Tensile stress,
Information theory,
Joining processes,
Special issues and sections"
A Multifaceted Approach to Modeling Agent Trust for Effective Communication in the Application of Mobile Ad Hoc Vehicular Networks,"An increasingly large number of cars are being equipped with global positioning system and Wi-Fi devices, enabling vehicle-to-vehicle (V2V) communication with the goal of providing increased passenger and road safety. This technology actuates the need for agents that assist users by intelligently processing the received information. Some of these agents might become self-interested and try to maximize car owners' utility by sending out false information. Given the dire consequences of acting on false information in this context, there is a serious need to establish trust among agents. The main goal of this paper is then to develop a framework that models the trustworthiness of the agents of other vehicles, in order to receive the most effective information. We develop a multifaceted trust modeling approach that incorporates role-, experience-, priority-, and majority-based trust and this is able to restrict the number of reports that are received. We include an algorithm that proposes how to integrate these various dimensions of trust, along with experimentation to validate the benefit of our approach, emphasizing the importance of each of the different facets that are included. The result is an important methodology to enable effective V2V communication via intelligent agents.","Vehicles,
Roads,
Measurement,
Security,
Context,
Social network services,
Computational modeling"
Algorithms for leader selection in large dynamical networks: Noise-corrupted leaders,"We examine the leader selection problem in multi-agent dynamical networks where leaders, in addition to relative information from their neighbors, also have access to their own states. We are interested in selecting an a priori specified number of agents as leaders in order to minimize the total variance of the stochastically forced network. Combinatorial nature of this optimal control problem makes computation of the global minimum difficult. We propose a convex relaxation to obtain a lower bound on the global optimal value, and use simple but efficient greedy algorithms to obtain an upper bound. Furthermore, we employ the alternating direction method of multipliers to search for a local minimum. Two examples are provided to illustrate the effectiveness of the developed methods.",
Rate Control Optimization for Temporal-Layer Scalable Video Coding,"A novel frame-level rate control (RC) algorithm is presented in this paper for temporal scalability of scalable video coding. First, by introducing a linear quality dependency model, the quality dependency between a coding frame and its references is investigated for the hierarchical B-picture prediction structure. Second, linear rate-quantization (R-Q) and distortion-quantization (D-Q) models are introduced based on different characteristics of temporal layers. Third, according to the proposed quality dependency model and R-Q and D-Q models for each temporal layer, adaptive weighting factors are derived to allocate bits efficiently among temporal layers. Experimental results on not only traditional quarter common intermediate format/common intermediate format but also standard definition and high definition sequences demonstrate that the proposed algorithm achieves excellent coding efficiency as compared to other benchmark RC schemes.","Bit rate,
Static VAr compensators,
Scalability,
Encoding,
Video coding,
Automatic voltage control,
Prediction algorithms"
Automated 2-D Nanoparticle Manipulation Using Atomic Force Microscopy,"An automated manipulation procedure for spherical nanoparticles with an atomic force microscope (AFM) in 2-D is demonstrated. Robust particle-center and contact-loss detection algorithms are developed using force feedback to improve speed and reliability issues of AFM-based nanomanipulation. Unlike blind manipulation techniques, contact-loss detection enables better control over the success of manipulation. For pattern formation and assembly operations, a fully automated multiple-particle-manipulation method is developed, based on a commanding task planner. The task planner minimizes the obstacles to manipulation trajectories for better efficiency. Forces during AFM tip-particle-substrate contact are analyzed theoretically to determine the mode of manipulation as well as the effect of cantilever normal stiffness. The developed system is used to form patterns and assemblies of 100-nm-diameter gold nanoparticles on a flat substrate.",
Optical Single-Sideband Modulation With Tunable Optical Carrier to Sideband Ratio in Radio Over Fiber Systems,"We show that an optical modulator that consists of an integrated dual parallel Mach-Zehnder modulator (dMZM) can be used for obtaining not only optical single-side band modulation but also tunability of optical carrier to sideband ratio (OCSR) simultaneously. Such a modulator will be vital for optimizing the performance of radio over fiber links by improving modulation efficiency and receiver sensitivity and by removing fiber chromatic dispersion induced RF power fading. It is shown that a wide range of OCSR tunability can be obtained by altering bias voltage of dMZM, and optimum OCSR, to maximize the output RF power, depends on RF modulation index and extinction ratio of the integrated dMZM. Good agreement between theory, simulation, and experiment is obtained. For typical extinction ratio and low modulation index, it is found that an OCSR of 0 dB is optimum to maximize RF carrier power. However, for multiband orthogonal frequency-division multiplexing (MB-OFDM) ultra-wideband (UWB) radio, the best error vector magnitude (EVM) of -21.8 dB is obtained experimentally at an OCSR of ~5.4 dB due to avoidance of clipping induced nonlinear distortion.","Radio frequency,
Amplitude modulation,
Optical modulation,
Optical fibers,
Optical distortion"
HDP code: A Horizontal-Diagonal Parity Code to Optimize I/O load balancing in RAID-6,"With higher reliability requirements in clusters and data centers, RAID-6 has gained popularity due to its capability to tolerate concurrent failures of any two disks, which has been shown to be of increasing importance in large scale storage systems. Among various implementations of erasure codes in RAID-6, a typical set of codes known as Maximum Distance Separable (MDS) codes aim to offer data protection against disk failures with optimal storage efficiency. However, because of the limitation of horizontal parity or diagonal/anti-diagonal parities used in MDS codes, storage systems based on RAID-6 suffers from unbalanced I/O and thus low performance and reliability. To address this issue, in this paper, we propose a new parity called Horizontal-Diagonal Parity (HDP), which takes advantages of both horizontal and diagonal/anti-diagonal parities. The corresponding MDS code, called HDP code, distributes parity elements uniformly in each disk to balance the I/O workloads. HDP also achieves high reliability via speeding up the recovery under single or double disk failure. Our analysis shows that HDP provides better balanced I/O and higher reliability compared to other popular MDS codes.","Reliability,
Load management,
Layout,
Encoding,
Mathematical model,
Equations,
Arrays"
Combinatorial Algorithm for Reliability Analysis of Multistate Systems With Propagated Failures and Failure Isolation Effect,"This paper considers the reliability analysis of multistate systems (MSSs) subject to propagated failure with global effect (PFGE) and failure isolation effect. The PFGE can be caused by an imperfect fault coverage despite the presence of fault-tolerant mechanism or by a destructive effect of failures that originate from some system components on other components. The failure isolation effect is caused by functional dependence among system components, where the failure of some component can prevent the propagation of failures that originate from other components within the same system. Existing approaches for simultaneously addressing PFGE and failure isolation are limited to binary-state systems in which the system and its components exhibit two and only two states: operation or failure. In practice, however, many systems are MSS in which the system and/or its components may exhibit multiple performance levels corresponding to different states ranging from perfect operation to complete failure. In this paper, a separable and combinatorial methodology is proposed for evaluating the reliability of MSS subject to both PFGE and the failure isolation effect. The proposed method has no limitation on the type of time-to-failure distributions for the system components and is applicable to MSS with any arbitrary system structure. Application and advantages of the proposed method are illustrated through a detailed analysis of an example of a multistate memory system.",
A Hierarchy of Near-Optimal Policies for Multistage Adaptive Optimization,"In this paper, we propose a new tractable framework for dealing with linear dynamical systems affected by uncertainty, applicable to multistage robust optimization and stochastic programming. We introduce a hierarchy of near-optimal polynomial disturbance-feedback control policies, and show how these can be computed by solving a single semidefinite programming problem. The approach yields a hierarchy parameterized by a single variable (the degree of the polynomial policies), which controls the trade-off between the optimality gap and the computational requirements. We evaluate our framework in the context of three classical applications-two in inventory management, and one in robust regulation of an active suspension system-in which very strong numerical performance is exhibited, at relatively modest computational expense.","Polynomials,
Robustness,
Uncertain systems,
Optimization,
Adaptive control,
Approximation methods"
General Approach to First-Order Error Prediction in Rigid Point Registration,"A general approach to the first-order analysis of error in rigid point registration is presented that accommodates fiducial localization error (FLE) that may be inhomogeneous (varying from point to point) and anisotropic (varying with direction) and also accommodates arbitrary weighting that may also be inhomogeneous and anisotropic. Covariances are derived for target registration error (TRE) and for weighted fiducial registration error (FRE) in terms of covariances of FLE, culminating in a simple implementation that encompasses all combinations of weightings and anisotropy. Furthermore, it is shown that for ideal weighting, in which the weighting matrix for each fiducial equals the inverse of the square root of the cross covariance of its two-space FLE, fluctuations of FRE and TRE are mutually independent. These results are validated by comparison with previously published expressions and by simulation. Furthermore, simulations for randomly generated fiducial positions and FLEs are presented that show that correlation is negligible in the exact case for both ideal and uniform weighting (i.e., no weighting), the latter of which is employed in commercial surgical guidance systems. From these results we conclude that for these weighting schemes, while valid expressions exist relating the covariance of FRE to the covariance of TRE, there are no measures of the goodness of fit of the fiducials for a given registration that give to first order any information about the fluctuation of TRE from its expected value and none that give useful information in the exact case. Therefore, as estimators of registration accuracy, such measures should be approached with extreme caution both by the purveyors of guidance systems and by the practitioners who use them.",
Statistical Approach for Optoacoustic Image Reconstruction in the Presence of Strong Acoustic Heterogeneities,"A method is presented to reduce artefacts produced in optoacoustic tomography images due to internal reflection or scattering of the acoustic waves. It is based on weighting the tomographic contribution of each detector with the probability that a signal affected by acoustic mismatches is measured at that position. The correction method does not require a priori knowledge of the acoustic or optical properties of the imaged sample. Performance tests were made with agar phantoms that included air gaps for mimicking strong acoustic reflections as well as with an acoustically heterogeneous adult Zebrafish. The results obtained with the method proposed show a clear reduction of the artefacts with respect to the original images reconstructed with filtered back-projection algorithm. This performance is directly related to in vivo small animal imaging applications involving imaging in the presence of bones, lungs, and other highly mismatched organs.","Acoustics,
Image reconstruction,
Transducers,
Optical imaging,
Optical scattering,
Absorption,
Phantoms"
An Adaptive Method of Speckle Reduction and Feature Enhancement for SAR Images Based on Curvelet Transform and Particle Swarm Optimization,"This paper proposes an adaptive method based on the mirror-extended curvelet transform and the improved particle swarm optimization (PSO) algorithm, which reduce speckle noise and enhance edge features and contrast of synthetic aperture radar (SAR) images. First, an improved gain function, which integrates the speckle reduction with the feature enhancement, is introduced to nonlinearly shrink and stretch the curvelet coefficients. Then, a novel objective criterion for the quality of the despeckled and enhanced images is proposed in order to adaptively obtain the optimal parameters in the gain function. Finally, the PSO algorithm is employed as a global search strategy for the best despeckled and enhanced image. In order to increase the convergence speed and avoid the premature convergence, two further improvements for the classic PSO algorithm are presented. That is, a new learning scheme and a mutation operator are introduced. Experimental results demonstrate that the proposed method can efficiently reduce the speckle and enhance the edge features and the contrast of SAR images and outperforms the wavelet- and curvelet-based nonadaptive despeckling and enhancement methods.","Noise,
Image edge detection,
Wavelet transforms,
Speckle,
Pixel,
Convergence"
Moving-Horizon State Estimation for Nonlinear Systems Using Neural Networks,"Moving-horizon (MH) state estimation is addressed for nonlinear discrete-time systems affected by bounded noises acting on system and measurement equations by minimizing a sliding-window least-squares cost function. Such a problem is solved by searching for suboptimal solutions for which a certain error is allowed in the minimization of the cost function. Nonlinear parameterized approximating functions such as feedforward neural networks are employed for the purpose of design. Thanks to the offline optimization of the parameters, the resulting MH estimation scheme requires a reduced online computational effort. Simulation results are presented to show the effectiveness of the proposed approach in comparison with other estimation techniques.","Artificial neural networks,
Approximation methods,
Minimization,
State estimation,
Cost function,
Estimation error"
Optimal sizing of energy storage for efficient integration of renewable energy,"In this paper, we study the optimal storage investment problem faced by an owner of renewable generator the purpose of which is to support a portion of a local demand. The goal is to minimize the long-term average cost of electric bills in the presence of dynamic pricing as well as investment in storage, if any. Examples of this setting include homeowners, industries, hospitals or utilities that own wind turbines or solar panels and have their own demand that they prefer to support with renewable generation. We formulate the optimal storage investment problem and propose a simple balancing control for operating storage. We show that this policy is optimal for constant prices and some special cases of price structures that restrict to at most two levels. Under this policy, we provide structural results that help in evaluating the optimal storage investment uniquely and efficiently. We then characterize how the cost and efficiency of storage, dynamic pricing and parameters that characterize the uncertainty in generation and demand impact the size of optimal storage and its gain. One surprising result we prove is that for storage to be profitable under the balancing policy the ratio amortized cost of storage to the peak price of energy should be less than 1 over 4","Investments,
Pricing,
Uncertainty,
Renewable energy resources,
Energy storage,
Electricity,
Generators"
Inpainting Strategies for Reconstruction of Missing Data in VHR Images,"Missing data in very high spatial resolution (VHR) optical imagery take origin mainly from the acquisition conditions. Their accurate reconstruction represents a great methodological challenge because of the complexity and the ill-posed nature of the problem. In this letter, we present three different solutions, with all based on the inpainting approach, which consists in reconstructing the missing regions in a given image by propagating the spectrogeometrical information retrieved from the remaining parts of the image. They rely on the idea to enrich the patch search process by including local image properties or by isometric transformations or to reformulate it under a multiresolution processing scheme, respectively. Thorough experiments conducted on two different VHR images are reported and discussed.","Image reconstruction,
Pixel,
Remote sensing,
Magnetic resonance imaging,
Clouds,
Spatial resolution"
Optimization Models and Algorithms for Joint Uplink/Downlink UMTS Radio Network Planning With SIR-Based Power Control,"Universal mobile telecommunication system (UMTS) networks should be deployed according to cost-effective strategies that optimize a cost objective and satisfy target quality-of-service (QoS) requirements. In this paper, we propose novel algorithms for joint uplink/downlink UMTS radio planning with the objective of minimizing total power consumption in the network. Specifically, we define two components of the radio planning problem: 1) continuous-based site placement and 2) integer-based site selection. In the site-placement problem, our goal is to find the optimal locations of UMTS base stations (BSs) in a certain geographic area with a given user distribution to minimize the total power expenditure such that a satisfactory level of downlink and uplink signal-to-interference ratio (SIR) is maintained with bounded outage constraints. We model the problem as a constrained optimization problem with SIR-based uplink and downlink power control scheme. An algorithm is proposed and implemented using pattern search techniques for derivative-free optimization with augmented Lagrange multiplier estimates to support general constraints. In the site-selection problem, we aim to select the minimum set of BSs from a fixed set of candidate sites that satisfies quality and outage constraints. We develop an efficient elimination algorithm by proposing a method for classifying BSs that are critical for network coverage and QoS. Finally, the problem is reformulated to take care of location constraints whereby the placement of BSs in a subset of the deployment area is not permitted due to, e.g., private property limitations or electromagnetic radiation constraints. Experimental results and optimal tradeoff curves are presented and analyzed for various scenarios.","Downlink,
Optimization,
Planning,
Quality of service,
Interference,
Base stations,
Radio network"
Analytic Study of Performance of Error Estimators for Linear Discriminant Analysis,"We derive double asymptotic analytical expressions for the first moments, second moments, and cross-moments with the actual error for the resubstitution and leave-one-out error estimators in the case of linear discriminant analysis in the multivariate Gaussian model under the assumption of a common known covariance matrix and a fixed Mahalanobis distance as dimensionality approaches infinity. Sample sizes for the two classes need not be the same; they are only assumed to reach a fixed, but arbitrary, asymptotic ratio with the dimensionality. From the asymptotic moment representations, we directly obtain double asymptotic expressions for the bias, variance, and RMS of the error estimators. The asymptotic expressions presented here generally provide good small sample approximations, as demonstrated via numerical experiments. The applicability of the theoretical results is illustrated by finding the minimum sample size to bound the RMS in gene-expression classification.",
Optimal channel assignment and power allocation for dual-hop multi-channel multi-user relaying,"We consider the problem of jointly optimizing channel pairing, channel-user assignment, and power allocation in a single-relay multiple-access system. The optimization objective is to maximize the weighted sum-rate under total and individual power constraints on the transmitters. By observing the special structure of a three-dimensional assignment problem derived from the original problem, we propose a polynomial-time algorithm based on continuity relaxation and dual minimization. The proposed method is shown to be optimal for all relaying strategies that give a concave rate function in terms of power constraints.","Resource management,
Relays,
OFDM,
Optimization,
Joints,
Complexity theory,
Signal to noise ratio"
Sparsity penalties in dynamical system estimation,"In this work we address the problem of state estimation in dynamical systems using recent developments in compressive sensing and sparse approximation. We formulate the traditional Kalman filter as a one-step update optimization procedure which leads us to a more unified framework, useful for incorporating sparsity constraints. We introduce three combinations of two sparsity conditions (sparsity in the state and sparsity in the innovations) and write recursive optimization programs to estimate the state for each model. This paper is meant as an overview of different methods for incorporating sparsity into the dynamic model, a presentation of algorithms that unify the support and coefficient estimation, and a demonstration that these suboptimal schemes can actually show some performance improvements (either in estimation error or convergence time) over standard optimal methods that use an impoverished model.","Kalman filters,
Technological innovation,
Optimization,
Estimation,
Steady-state,
Noise,
Noise measurement"
Novel Exponential Stability Criteria of High-Order Neural Networks With Time-Varying Delays,"The global exponential stability is analyzed for a class of high-order Hopfield-type neural networks with time-varying delays. Based on the Lyapunov stability theory, together with the linear matrix inequality approach and free-weighting matrix method, some less conservative delay-independent and delay-dependent sufficient conditions are presented for the global exponential stability of the equilibrium point of the considered neural networks. Two numerical examples are provided to demonstrate the effectiveness of the proposed stability criteria.","Stability criteria,
Neural networks,
Hopfield neural networks,
Asymptotic stability,
Delay effects,
Linear matrix inequalities,
Educational institutions,
Stability analysis,
Robust stability,
Lyapunov method"
"Improved human-robot team performance using Chaski, A human-inspired plan execution system","We describe the design and evaluation of Chaski, a robot plan execution system that uses insights from human-human teaming to make human-robot teaming more natural and fluid. Chaski is a task-level executive that enables a robot to collaboratively execute a shared plan with a person. The system chooses and schedules the robot's actions, adapts to the human partner, and acts to minimize the human's idle time. We evaluate Chaski in human subject experiments in which a person works with a mobile and dexterous robot to collaboratively assemble structures using building blocks. We measure team performance outcomes for robots controlled by Chaski compared to robots that are verbally commanded, step-by-step by the human teammate. We show that Chaski reduces the human's idle time by 85%, a statistically significant difference. This result supports the hypothesis that human-robot team performance is improved when a robot emulates the effective coordination behaviors observed in human teams.","Humans,
Robot kinematics,
Teamwork,
Schedules,
Dynamic scheduling,
Decision making"
An Adaptive Reliability Analysis Using Path Testing for Complex Component-Based Software Systems,"With the growing size and complexity of software applications, traditional software reliability methods are insufficient to analyze inter-component interactions of modular software systems. The number of test cases may be extremely large for this application; therefore, it is hard for us to extensively test each software component given resource limitations. In this paper, we propose an adaptive framework of incorporating path testing into reliability estimation for modular software systems. Three estimated methods based on common program structures, namely, sequence, branch, and loop structures, are proposed to calculate the path reliability. Consequently, the derived path reliabilities can be applied to the estimates of software reliability. Some experiments are performed based on two real systems. In addition, the accuracy and correlation with respect to the experiments are investigated by simulation and sensitivity analysis. Experimental results show that the path reliability has a high correlation to the actual software reliability. For software with loop structures, a smaller loop number can be assigned to derive an acceptable estimation of path reliability. Further, the sensitivity analysis can be used to identify critical modules and paths for resource allocation. It can be concluded that the proposed methods are useful and helpful for estimating software reliability and can be adaptively used in the early stages of software development.","Software reliability,
Testing,
Software systems,
Object oriented modeling,
Adaptation model"
Concentration of Measure for Block Diagonal Matrices With Applications to Compressive Signal Processing,"Theoretical analysis of randomized, compressive operators often depends on a concentration of measure inequality for the operator in question. Typically, such inequalities quantify the likelihood that a random matrix will preserve the norm of a signal after multiplication. Concentration of measure results are well established for unstructured compressive matrices, populated with independent and identically distributed (i.i.d.) random entries. Many real-world acquisition systems, however, are subject to architectural constraints that make such matrices impractical. In this paper we derive concentration of measure bounds for two types of block diagonal compressive matrices, one in which the blocks along the main diagonal are random and independent, and one in which the blocks are random but equal. For both types of matrices, we show that the likelihood of norm preservation depends on certain properties of the signal being measured, but that for the best case signals, both types of block diagonal matrices can offer concentration performance on par with their unstructured, i.i.d. counterparts. We support our theoretical results with illustrative simulations as well as analytical and empirical investigations of several signal classes that are highly amenable to measurement using block diagonal matrices. We also discuss applications of these results in ensuring stable embeddings for various signal families and in establishing performance guarantees for solving various signal processing tasks (such as detection and classification) directly in the compressed domain.","Random variables,
Linear matrix inequalities,
Analytical models,
Sparse matrices,
Compressed sensing"
State Estimation Based on the Concept of Continuous Symmetry and Observability Analysis: The Case of Calibration,"This paper considers the problem of state estimation in autonomous navigation from a theoretical perspective. In particular, the investigation concerns problems where the information provided by the sensor data is not sufficient to carry out the state estimation (i.e., the state is not observable). For these systems, the concept of continuous symmetry is introduced. Detection of the continuous symmetries of a given system has a very practical importance. It allows the detection of an observable state whose components are nonlinear functions of the original nonobservable state. So far, this theoretical and very general concept has been applied to deal with two distinct fundamental estimation problems in the framework of mobile robotics. The former is in the framework of self-calibration, and the latter is in the framework of the fusion of the data provided by inertial sensors and vision sensors. For reasons of length, only the former is discussed. In particular, the theoretical machinery is used to address a specific calibration problem. The solution constrains the robot to move along specific trajectories in order to be able to apply the calibration algorithm. This paper provides two distinct contributions. The first is the introduction of this concept of continuous symmetry. The second is the introduction of a simple and efficient strategy to extrinsically calibrate a bearing sensor (e.g., a vision sensor) mounted on a vehicle and, simultaneously, estimate the parameters describing the systematic error of its odometry system. Many accurate simulations and real experiments show the robustness, the efficiency, and the accuracy of the proposed strategy.","Observability,
Calibration,
Estimation,
Robot kinematics,
Robot vision systems"
Three-Dimensional Reconstruction of the Digestive Wall in Capsule Endoscopy Videos Using Elastic Video Interpolation,"Wireless capsule endoscopy is a revolutionary technology that allows physicians to examine the digestive tract of a human body in the minimum invasive way. Physicians can detect diseases such as blood-based abnormalities, polyps, ulcers, and Crohn's disease. Although this technology is really a marvel of our modern times, currently it suffers from two serious drawbacks: 1) frame rate is low (3 frames/s) and 2) no 3-D representation of the objects is captured from the camera of the capsule. In this paper we offer solutions (methodologies) that deal with each of the above issues improving the current technology without forcing hardware upgrades. These methodologies work synergistically to create smooth and visually friendly interpolated images from consecutive frames, while preserving the structure of the observed objects. They also extract and represent the texture of the surface of the digestive tract in 3-D. Thus the purpose of our methodology is not to reduce the time that the gastroenterologists need to spend to examine the video. On the contrary, the purpose is to enhance the video and therefore improve the viewing of the digestive tract leading to a more qualitative and efficient examination. The proposed work introduces 3-D capsule endoscopy textured results that have been welcomed by Digestive Specialists, Inc., Dayton, OH. Finally, illustrative results are given at the end of the paper.",
SOS: The MOS is not enough!,"When it comes to analysis and interpretation of the results of subjective QoE studies, one often witnesses a lack of attention to the diversity in subjective user ratings. In extreme cases, solely Mean Opinion Scores (MOS) are reported, causing the loss of important information on the user rating diversity. In this paper, we emphasize the importance of considering the Standard deviation of Opinion Scores (SOS) and analyze important characteristics of this measure. As a result, we formulate the SOS hypothesis which postulates a square relationship between the MOS and the SOS. We demonstrate the validity and applicability of the SOS hypothesis for a wide range of studies. The main benefit of the SOS hypothesis is that it allows for a compact, yet still comprehensive statistical summary of subjective user tests. Furthermore, it supports checking the reliability of test result data sets as well as their comparability across different QoE studies.","Streaming media,
Motion pictures,
Web pages,
Context,
Reliability,
Image quality,
Databases"
Crosstalk Evaluation in Stereoscopic Displays,"Substantial progress in liquid-crystal display and polarization film technology has enabled several types of stereoscopic displays. Despite all progress, some image distortions still exist in these 3-D displays, of which interocular crosstalk-light leakage of the image for one eye to the other eye-is probably the most annoying. The aim of the current research is to investigate how the two most important physical quantities, contrast and binocular disparity, influence crosstalk perception. Images consisting of a single character and varying in contrast and disparity were computer-generated to measure crosstalk visibility and acceptability thresholds for two stereoscopic displays; one display was based on active shutter glasses, and the other on passive glasses. Results show that, under the same experimental condition, there is no significant difference in crosstalk perception between both 3-D display technologies. Crosstalk annoyance increases with increasing contrast and disparity, i.e., less crosstalk is allowed for higher levels of contrast and disparity. Based on the experimental results, an analytical formula for predicting crosstalk perception is proposed.","Crosstalk,
Glass,
Three dimensional displays,
Pixel,
Multiplexing,
Rendering (computer graphics),
Training"
Determination of Stripe Edge Blurring for Depth Sensing,"Estimation of the blurring effect is very important for many imaging systems. This letter reports an idea to efficiently and robustly compute the blurring parameter on certain stripe edges. Two formulas are found to determine the degree of imaging blur only by calculating the area sizes under the corresponding profile curves, without the need for deconvolution or transformation over the image. The method can be applied to many applications such as vision sensing of scene depth. A 3-D vision system is taken as an implementation instance.","Sensors,
Image edge detection,
Three dimensional displays,
Image restoration,
Machine vision,
Image sensors"
Fuzzy Random Impulse Noise Removal From Color Image Sequences,"In this paper, a new fuzzy filter for the removal of random impulse noise in color video is presented. By working with different successive filtering steps, a very good tradeoff between detail preservation and noise removal is obtained. One strong filtering step that should remove all noise at once would inevitably also remove a considerable amount of detail. Therefore, the noise is filtered step by step. In each step, noisy pixels are detected by the help of fuzzy rules, which are very useful for the processing of human knowledge where linguistic variables are used. Pixels that are detected as noisy are filtered, the others remain unchanged. Filtering of detected pixels is done by blockmatching based on a noise adaptive mean absolute difference. The experiments show that the proposed method outperforms other state-of-the-art filters both visually and in terms of objective quality measures such as the mean absolute error (MAE), the peak-signal-to-noise ratio (PSNR) and the normalized color difference (NCD).","Pixel,
Image color analysis,
Noise measurement,
Colored noise,
Color,
Correlation"
Radiation-Induced Defect Evolution and Electrical Degradation of AlGaN/GaN High-Electron-Mobility Transistors,"Threshold-voltage shifts and increases in 1/f noise are observed in proton-irradiated AlGaN/GaN high-electron-mobility transistors, indicating defect-mediated device degradation. Quantum mechanical calculations demonstrate that low-energy recoils caused by particle interactions with defect complexes are more likely to occur than atomic displacements in a defect-free region of the crystal. We identify the responsible defects and their precursors in the defect-mediated displacement mechanism. The electronic properties of these defects are consistent with the increases in threshold voltage and 1/f noise in proton irradiation experiments.","Protons,
Density functional theory,
HEMTs,
1f noise,
Aluminum gallium nitride,
Radiation effects,
Gallium nitride"
Separating Overlapped Fingerprints,"Fingerprint images generally contain either a single fingerprint (e.g., rolled images) or a set of nonoverlapped fingerprints (e.g., slap fingerprints). However, there are situations where several fingerprints overlap on top of each other. Such situations are frequently encountered when latent (partial) fingerprints are lifted from crime scenes or residue fingerprints are left on fingerprint sensors. Overlapped fingerprints constitute a serious challenge to existing fingerprint recognition algorithms, since these algorithms are designed under the assumption that fingerprints have been properly segmented. In this paper, a novel algorithm is proposed to separate overlapped fingerprints into component or individual fingerprints. The basic idea is to first estimate the orientation field of the given image with overlapped fingerprints and then separate it into component orientation fields using a relaxation labeling technique. We also propose an algorithm to utilize fingerprint singularity information to further improve the separation performance. Experimental results indicate that the algorithm leads to good separation of overlapped fingerprints that leads to a significant improvement in the matching accuracy.",
The 2010 Mario AI Championship: Level Generation Track,"The Level Generation Competition, part of the IEEE Computational Intelligence Society (CIS)-sponsored 2010 Mario AI Championship, was to our knowledge the world's first procedural content generation competition. Competitors participated by submitting level generators - software that generates new levels for a version of Super Mario Bros tailored to individual players' playing style. This paper presents the rules of the competition, the software used, the scoring procedure, the submitted level generators, and the results of the competition. We also discuss what can be learned from this competition, both about organizing procedural content generation competitions and about automatically generating levels for platform games. The paper is coauthored by the organizers of the competition (the first three authors) and the competitors.",
Behavior of EMO algorithms on many-objective optimization problems with correlated objectives,"Recently it has been pointed out in many studies that evolutionary multi-objective optimization (EMO) algorithms with Pareto dominance-based fitness evaluation do not work well on many-objective problems with four or more objectives. In this paper, we examine the behavior of well-known and frequently used EMO algorithms such as NSGA-II, SPEA2 and MOEA/D on many-objective problems with correlated or dependent objectives. First we show that good results on many-objective 0/1 knapsack problems with randomly generated objectives are not obtained by Pareto dominance-based EMO algorithms (i.e., NSGA-II and SPEA2). Next we show that the search ability of NSGA-II and SPEA2 is not degraded by the increase in the number of objectives when they are highly correlated or dependent. In this case, the performance of MOEA/D is deteriorated. As a result, NSGA-II and SPEA2 outperform MOEA/D with respect to the convergence of solutions toward the Pareto front for some many objective problems. Finally we show that the addition of highly correlated or dependent objectives can improve the performance of EMO algorithms on two-objective problems in some cases.",
Fiber Continuity: An Anisotropic Prior for ODF Estimation,"The accurate and reliable estimation of fiber orientation distributions, based on diffusion-sensitized magnetic resonance images is a major prerequisite for tractography algorithms or any other derived statistical analysis. In this work, we formulate the principle of fiber continuity (FC), which is based on the simple observation that the imaging of fibrous tissue implies certain expectations for the measured images. From this principle we derive a prior for the estimation of fiber orientation distributions based on high angular resolution diffusion imaging (HARDI). We demonstrate on simulated, phantom, and in vivo data the superiority of the proposed approach. Further, we propose another application of the FC principle, named FC flow, a method to resolve complex crossing regions solely based on diffusion tensor imaging (DTI). The idea is to infer directional information in crossing regions from adjacent anisotropic areas.",
Teaching Agile Software Development: A Case Study,"This paper describes the authors' experience of teaching agile software development to students of computer science, software engineering, and other related disciplines, and comments on the implications of this and the lessons learned. It is based on the authors' eight years of experience in teaching agile software methodologies to various groups of students at different universities, in different cultural settings, and in a number of courses and seminars. It specifically discusses three different courses on agile software development, given in different teaching settings and at different levels, and briefly surveys variations to these courses given elsewhere. Based on the experience acquired, analyses and evaluations conducted, and current pedagogical trends at relevant university departments, the authors provide recommendations on how to overcome potential problems in teaching agile software development and make their adoption more effective.",
Fast MR Image Reconstruction for Partially Parallel Imaging With Arbitrary k -Space Trajectories,"Both acquisition and reconstruction speed are crucial for magnetic resonance (MR) imaging in clinical applications. In this paper, we present a fast reconstruction algorithm for SENSE in partially parallel MR imaging with arbitrary k-space trajectories. The proposed method is a combination of variable splitting, the classical penalty technique and the optimal gradient method. Variable splitting and the penalty technique reformulate the SENSE model with sparsity regularization as an unconstrained minimization problem, which can be solved by alternating two simple minimizations: One is the total variation and wavelet based denoising that can be quickly solved by several recent numerical methods, whereas the other one involves a linear inversion which is solved by the optimal first order gradient method in our algorithm to significantly improve the performance. Comparisons with several recent parallel imaging algorithms indicate that the proposed method significantly improves the computation efficiency and achieves state-of-the-art reconstruction quality.","Image reconstruction,
TV,
Sensitivity,
Imaging,
Hyperspectral imaging,
Convergence,
Indexes"
Combined Invariants to Similarity Transformation and to Blur Using Orthogonal Zernike Moments,"The derivation of moment invariants has been extensively investigated in the past decades. In this paper, we construct a set of invariants derived from Zernike moments which is simultaneously invariant to similarity transformation and to convolution with circularly symmetric point spread function (PSF). Two main contributions are provided: the theoretical framework for deriving the Zernike moments of a blurred image and the way to construct the combined geometric-blur invariants. The performance of the proposed descriptors is evaluated with various PSFs and similarity transformations. The comparison of the proposed method with the existing ones is also provided in terms of pattern recognition accuracy, template matching and robustness to noise. Experimental results show that the proposed descriptors perform on the overall better.",
Prediction Based Collaborative Trackers (PCT): A Robust and Accurate Approach Toward 3D Medical Object Tracking,"Robust and fast 3D tracking of deformable objects, such as heart, is a challenging task because of the relatively low image contrast and speed requirement. Many existing 2D algorithms might not be directly applied on the 3D tracking problem. The 3D tracking performance is limited due to dramatically increased data size, landmarks ambiguity, signal drop-out or complex nonrigid deformation. In this paper, we present a robust, fast, and accurate 3D tracking algorithm: prediction based collaborative trackers (PCT). A novel one-step forward prediction is introduced to generate the motion prior using motion manifold learning. Collaborative trackers are introduced to achieve both temporal consistency and failure recovery. Compared with tracking by detection and 3D optical flow, PCT provides the best results. The new tracking algorithm is completely automatic and computationally efficient. It requires less than 1.5 s to process a 3D volume which contains millions of voxels. In order to demonstrate the generality of PCT, the tracker is fully tested on three large clinical datasets for three 3D heart tracking problems with two different imaging modalities: endocardium tracking of the left ventricle (67 sequences, 1134 3D volumetric echocardiography data), dense tracking in the myocardial regions between the epicardium and endocardium of the left ventricle (503 sequences, roughly 9000 3D volumetric echocardiography data), and whole heart four chambers tracking (20 sequences, 200 cardiac 3D volumetric CT data). Our datasets are much larger than most studies reported in the literature and we achieve very accurate tracking results compared with human experts' annotations and recent literature.","Cardiology,
Three dimensional displays,
Computed tomography,
Motion learning,
Heart,
Ultrasonic imaging,
Tracking"
Semiautonomous Multivehicle Safety,"In this article, we have illustrated the application of a formal hybrid control approach to design semiautonomous multivehicle systems that are guaranteed to be safe. Our experimental results illustrate that, in a structured task, such as driving, simple human-decision models can be effectively learned and employed in a feedback control system that enforces a safety specification. They also highlight how the incorporation of these models in a safety control system makes the control actions required for safety less conservative. In fact, by virtue of the mode estimate, the current (mode-dependent) capture set to avoid guaranteeing safety is considerably smaller than the capture set to be avoided when the mode estimate is not available. This is essential for the practical applicability of cooperative active safety systems. In our data set, the flow entered the capture set only 3% times. These failures are mainly due to communication delays between the vehicles and the workstation. These delays, when significant, cause the calculated capture set to be different from the actual one and hence may cause to enforce control too late. These delays, in future work, should be formally accounted for in the models and in the safety control algorithm. More complex models of human decisions in the proximity of an intersection and the incorporation of additional details, such as weather conditions and road geometry, offer the potential for reducing the conservatism of safe control actions even further. Future work will also consider the extension to the case in which vehicles are not known to evolve on a fixed route. This case will be handled by keeping track of routes that are compatible with the position and speed of the vehicle and by progressively eliminating those that become incompatible. The models considered here are deterministic because most of the tools currently available to perform safety control have assumed deterministic models, wherein uncertainty is bounded. However, human decision models are more naturally captured by stochastic frameworks, in which uncertainty due to variability in both subjects and realizations of the same decision is probabilistic. As results in stochastic safety verification and design become available, it will be important to extend the proposed techniques of this article to safety control of stochastic hybrid automata in which the mode estimate is constructed probabilistically.","Intelligent transportation systems,
Safety,
Collision avoidance,
Government policies,
US Department of Transportation"
Hybrid ADS-Based Techniques for Radio Astronomy Array Design,"A set of techniques are presented that are based on the exploitation of low correlation sequences called Almost Difference Sets (ADSs) to design correlator arrays for radio astronomy applications. Three approaches are discussed with different objectives and performances. ADS-based analytical designs, GA -optimized arrangements, and PSO optimized arrays are presented and applied to the synthesis of open-ended ""Y"" and ""Cross"" array configurations to maximize the u - v coverage or to minimize the peak sidelobe level (PSL). Representative numerical results are illustrated to point out the features and performances of the proposed approaches, and to assess their effectiveness in comparison with state-of-the-art design methodologies, as well. The presented analysis indicates that the proposed approaches overcome existing PSO-based correlator arrays in terms of PSL control (e.g., >; 1.0 dB reduction) and tracking u - v coverage (e.g., up to 2% enhancement), also improving the speed of convergence of the synthesis process.","Arrays,
Correlators,
Convergence,
Layout,
Cost function,
Lattices"
A comparative study of moodle with other e-learning systems,"E-learning provides the opportunity for student to interact electronically with each other as well as with their teachers. This interaction can be via e-mail or on discussion board or in chat rooms. Though recognizing that the world at large will persist to use language and terminology in different ways, so the term of virtual learning environments (VLE) is used to refer the on-line interactions for a variety of kinds that take place between students and teachers. There are many software systems available that provide VLE systems. This software is in both forms, commercial and open source software (OSS). Moodle is one of the systems that have been increasingly gaining worldwide popularity in e-learning system. This paper is focused on the Moodle Architecture and comparative study of Moodle, thus we discusses comparisons between different virtual learning management systems and presents some authentication plug-in that Moodle supports. The open source learning management, LMS Moodle has been adopted by many people and organizations around the world because it offers a tightly integrated set of tools said to be designed from a social constructive perspective. Moodle has been developed under the general public license and many of its components were developed without a specific design documentation including its security services.","Servers,
Authentication,
Electronic mail,
Electronic learning,
Internet,
Least squares approximation,
Protocols"
On Data Collection Using Mobile Robot in Wireless Sensor Networks,"A novel data-collecting algorithm using a mobile robot to acquire sensed data from a wireless sensor network (WSN) that possesses partitioned/islanded WSNs is proposed in this paper. This algorithm permits the improvement of data-collecting performance by the base station by identifying the locations of partitioned/islanded WSNs and navigating a mobile robot to the desired location. To identify the locations of the partitioned/islanded WSNs, two control approaches, a global- and local-based approach, are proposed. Accordingly, the navigation strategy of the robot can be scheduled based on time and location using three scheduling strategies: time based, location based, and dynamic moving based. With these strategies, the mobile robot can collect the sensed data from the partitioned/islanded WSNs. Therefore, the efficiency of sensed data collected by the base station in partitioned/islanded WSNs is improved. Through simulation under the environment of an ns-2 simulator, the results, from various aspects, show that the collecting strategies proposed can dramatically improve sensed data-collecting performance in partitioned or islanded WSNs.","Wireless sensor networks,
Mobile robots,
Mobile computing,
Algorithm design and analysis"
MARSS: A full system simulator for multicore x86 CPUs,"We present MARSS, an open source, fast, full system simulation tool built on QEMU to support cycle-accurate simulation of superscalar homogeneous and heterogeneous multicore x86 processors. MARSS includes detailed models of coherent caches, interconnections, chipsets, memory and IO devices. MARSS simulates the execution of all software components in the system, including unmodified binaries of applications, OS and libraries.","Multicore processing,
Emulation,
Random access memory,
Benchmark testing,
Kernel,
Context modeling,
Switches"
"Dynamic Hybrid Fault Modeling and Extended Evolutionary Game Theory for Reliability, Survivability and Fault Tolerance Analyses","We introduce a new layered modeling architecture consisting of dynamic hybrid fault modeling and extended evolutionary game theory for reliability, survivability, and fault tolerance analyses. The architecture extends traditional hybrid fault models and their relevant constraints in the Agreement algorithms with survival analysis, and evolutionary game theory. The dynamic hybrid fault modeling (i) transforms hybrid fault models into time- and covariate-dependent models; (ii) makes real-time prediction of reliability more realistic, and allows for real-time prediction of fault-tolerance; (iii) sets the foundation for integrating hybrid fault models with reliability and survivability analyses by integrating them with evolutionary game modeling; and (iv) extends evolutionary game theory by stochastically modeling the survival (or fitness) and behavior of `game players.' To analyse survivability, we extend dynamic hybrid fault modeling with a third-layer, operational level modeling, to develop the three-layer survivability analysis approach (dynamic hybrid fault modeling constitutes the tactical and strategic levels). From the perspective of evolutionary game modeling, the two mathematical fields, i.e., survival analysis and agreement algorithms, which we applied for developing dynamic hybrid fault modeling, can also be utilized to extend the power of evolutionary game theory in modeling complex engineering, biological (ecological), and social systems. Indeed, a common property of the areas where our extensions to evolutionary game theory can be advantageous is that the risk analysis and management are a core issue. Survival analysis (including competing risks analysis, and multivariate survival analysis) offers powerful modeling tools to analyse time-, space-, and/or covariate-dependent uncertainty, vulnerability, and/or frailty which `game players' may experience. The agreement algorithms, which are not limited to the agreement algorithms from distributed computing, when applied to extend evolutionary game modeling, can be any problem (game system) specific rules (algorithms or models) that can be utilized to dynamically check the consensus among game players. We expect that the modeling architecture and approaches discussed in the study should be implemented as a software environment to deal with the necessary sophistication. Evolutionary computing should be particularly convenient to serve as the core optimization engine, and should simplify the implementation. Accordingly, a brief discussion on the software architecture is presented.",
Integration of a Monolithic Buck Converter Power IC and Bondwire Inductors With Ferrite Epoxy Glob Cores,"In this letter, we report a concept of integrating a monolithic buck converter power IC with in-package bondwire inductors. The power IC containing all switching devices, driver circuitry, and control logic was designed and fabricated with a standard 0.5-μm CMOS process. Mutliturn bondwires with and without ferrite epoxy glob cores are used as the filter inductor in the buck converter. A prototype system-in-package converter with an output voltage and current of 2.5 V and 120 mA was built to operate at frequencies up to 5 MHz. The power level of the prototype buck converter is scalable by increasing the size of the active power switches.","Inductors,
Ferrites,
Integrated circuits,
Converters,
Magnetic cores,
Inductance"
Haptic Device Using a Newly Developed Redundant Parallel Mechanism,"A number of haptic devices have recently become available on the commercial market, and these devices are becoming common not only in research but in consumer use as well. In this paper, a new parallel mechanism, referred to herein as DELTA-R (meaning DELTA-Redundant, formerly referred to as DELTA-4) is proposed for a new haptic device having high-quality force display capability and operability. DELTA-R allows three-degree-of-freedom (DOF) translational motions. The key features of DELTA-R, as compared with conventional parallel mechanisms, are redundant actuation, a smaller footprint, a larger working area, and improved access to the end effector. The prototype is equipped with a 3-DOF rotation mechanism, the center of motion of which is located on the wrist position of the operator. An evaluation test of the force display was conducted using a prototype of the proposed mechanism. This paper describes the kinematic design, kinematic modeling, kinematic analysis, prototype implementation, and evaluations.",
EduCloud: PaaS versus IaaS Cloud Usage for an Advanced Computer Science Course,"The cloud has become a widely used term in academia and the industry. Education has not remained unaware of this trend, and several educational solutions based on cloud technologies are already in place, especially for software as a service cloud. However, an evaluation of the educational potential of infrastructure and platform clouds has not been explored yet. An evaluation of which type of cloud would be the most beneficial for students to learn, depending on the technical knowledge required for its usage, is missing. Here, the first systematic evaluation of different types of cloud technologies in an advanced course on network overlays with 84 students and four professors is presented. This evaluation tries to answer the question whether cloud technologies (and which specific type of cloud) can be useful in educational scenarios for computer science students by focusing students in the actual tasks at hand. This study demonstrates that platform clouds are valued by both students and professors to achieve the course objectives and that clouds offer a significant improvement over the previous situation in labs where much effort was devoted to setting up the software necessary for course activities. These results most strongly apply to courses in which students interact with resources that are non-self-contained (e.g., network nodes, databases, mechanical equipment, or the cloud itself), but could also apply to other science disciplines that involve programming or performing virtual experiments.","Education,
Software,
Hardware,
Peer to peer computing,
Algorithm design and analysis,
Programming"
Rate-equivocation optimal spatially coupled LDPC codes for the BEC wiretap channel,"We consider transmission over a wiretap channel where both the main channel and the wiretapper's channel are Binary Erasure Channels (BEC). We use regular convolutional LDPC ensembles, introduced by Felström and Zigangirov, together with Wyner's coset encoding scheme. We show that such a construction achieves the whole rate-equivocation region of the BEC wiretap channel. This result is based on the recent observation by Kudekar, Richardson, and Urbanke who proved that convolutional LDPC ensembles exhibit a “threshold saturation” phenomenon which converts the MAP threshold into the BP threshold for transmission over the BEC. Although our present result is less general (since we only consider the BEC) than the elegant code constructions based on polar codes which were recently introduced by several research groups, we see two potential advantages which we believe makes our construction worth considering. First, the proposed codes have a significantly better performance already for moderate lengths. Second, and perhaps more importantly, the proposed construction has the potential of being universal. More precisely, the phenomenon of spatial coupling has been observed empirically to hold for general binary memoryless symmetric channels as well. Hence, we conjecture that our construction is a universal rate-equivocation achieving construction when the main channel and wiretapper's channel are binary memoryless symmetric channels, and the wiretapper's channel is degraded with respect to the main channel.","Parity check codes,
Convolutional codes,
Encoding,
Couplings,
Constellation diagram,
Reliability,
Error probability"
Sufficient Statistics as a Generalization of Binning in Spectral X-ray Imaging,"It is well known that the energy dependence of X-ray attenuation can be used to characterize materials. Yet, even with energy discriminating photon counting X-ray detectors, it is still unclear how to best form energy dependent measurements for spectral imaging. Common ideas include binning photon counts based on their energies and detectors with both photon counting and energy integrating electronics. These approaches can be generalized to energy weighted measurements, which we prove can form a sufficient statistic for spectral X-ray imaging if the weights used, which we term μ-weights, are basis attenuation functions that can also be used for material decomposition. To study the performance of these different methods, we evaluate the Cramér-Rao lower bound (CRLB) of material estimates in the presence of quantum noise. We found that the choice of binning and weighting schemes can greatly affect the performance of material decomposition. Even with optimized thresholds, binning condenses information but incurs penalties to decomposition precision and is not robust to changes in the source spectrum or object size, although this can be mitigated by adding more bins or removing photons of certain energies from the spectrum. On the other hand, because μ -weighted measurements form a sufficient statistic for spectral imaging, the CRLB of the material decomposition estimates is identical to the quantum noise limited performance of a system with complete energy information of all photons. Finally, we show that μ -weights lead to increased conspicuity over other methods in a simulated calcium contrast experiment.",
An Indoor Localization Framework for Four-Rotor Flying Robots Using Low-Power Sensor Nodes,"We study the relevance of highly precise indoor localization techniques for quadrocopters and present an ultrasonic sensor system that achieves excellent localization performance, although the system has to rely on the limited computation resources of sensor nodes used for time-of-flight-based localization. Quadrocopters, i.e., flying four-rotor robots, are on-board sensor controlled systems. In comparison to classical monorotor objects (helicopters), the quadrocopters can be piloted with much lower effort. However, lateral drifts cannot be compensated for only referring to the built-in sensors. Nonetheless, the detection of such drifts is strongly necessary for indoor operation-without any corrections, the quadrocopter would quickly cause a collision. To compensate for the dislocation, we developed an indoor-localization framework for time-of-flight-based localization using ultrasonic sensors. It is optimized for use in sensor nodes with low computational power and limited memory. The system is designed for high scalability and to provide high accuracy, even in the case of erroneous measurements. The developed hardware platform is very lightweight to be carried by mobile robots and flying quadrocopters. Based on our real-time localization system, position controller and navigation functionality can be implemented.","Robot sensing systems,
Ultrasonic imaging,
Ultrasonic variables measurement,
Accuracy,
Estimation,
Equations"
Rapid Color Grading for Fruit Quality Evaluation Using Direct Color Mapping,"Color grading is a crucial step in the processing of fruits and vegetables that directly affects profitability, because the quality of agricultural products is often associated with their color. Most existing automatic color grading systems determine color quality either by directly comparing product color against a predefined and fixed set of reference colors or by using a set of color separating parameters, often in three-dimensional color spaces. Using these methods, it is not convenient for the user to adjust color preferences or grading parameters. In this paper, we present an effective and user-friendly color mapping concept for automated color grading that is well suited for commercial production. User friendliness is often viewed by the industry as a very important factor to the acceptance and success of automation equipment. This color mapping method uses preselected colors of interest specific to a given application to calculate a unique set of coefficients for color space conversion. The three-dimensional RGB color space is converted into a small set of color indices unique to the application. In contrast with more complex color grading techniques, the proposed method makes it easy for a human operator to specify and adjust color-preference settings Tomato and date maturity evaluation and date surface defect detection are used to demonstrate the performance of this novel color mapping concept.","Image color analysis,
Color,
Indexes,
Machine vision,
Gray-scale,
Automation,
Calibration"
Cooperative Spectrum Sensing Under a Random Geometric Primary User Network Model,"We propose a novel cooperative spectrum sensing algorithm for a cognitive radio (CR) network to detect a primary user (PU) network that exhibits some degree of randomness in topology (e.g., due to mobility). We model the PU network as a random geometric network that can better describe small-scale mobile PUs. Based on this model, we formulate the random PU network detection problem in which the CR network detects the presence of a PU receiver within a given detection area. To address this problem, we propose a location-aware cooperative sensing algorithm that linearly combines multiple sensing results from secondary users (SUs) according to their geographical locations. In particular, we invoke the Fisher linear discriminant analysis to determine the linear coefficients for combining the sensing results. The simulation results show that the proposed sensing algorithm yields comparable performance to the optimal maximum likelihood (ML) detector and outperforms the existing ones, such as equal coefficient combining, OR-rule-based and AND-rule-based cooperative sensing algorithms, by a very wide margin.","Detectors,
Fading,
Algorithm design and analysis,
Vectors,
Linear discriminant analysis,
Network topology"
Enabling improved power management in multicore processors through clustered DVFS,"In recent years, chip multiprocessors (CMP) have emerged as a solution for high-speed computing demands. However, power dissipation in CMPs can be high if numerous cores are simultaneously active. Dynamic voltage and frequency scaling (DVFS) is widely used to reduce the active power, but its effectiveness and cost depends on the granularity at which it is applied. Per-core DVFS allows the greatest flexibility in controlling power, but incurs the expense of an unrealistically large number of on-chip voltage regulators. Per-chip DVFS, where all cores are controlled by a single regulator overcomes this problem at the expense of greatly reduced flexibility. This work considers the problem of building an intermediate solution, clustering the cores of a multicore processor into DVFS domains and implementing DVFS on a per-cluster basis. Based on a typical workload, we propose a scheme to find similarity among the cores and cluster them based on this similarity. We also provide an algorithm to implement DVFS for the clusters, and evaluate the effectiveness of per-cluster DVFS in power reduction.",
Performance modeling for systematic performance tuning,"The performance of parallel scientific applications depends on many factors which are determined by the execution environment and the parallel application. Especially on large parallel systems, it is too expensive to explore the solution space with series of experiments. Deriving analytical models for applications and platforms allow estimating and extrapolating their execution performance, bottlenecks, and the potential impact of optimization options. We propose to use such ""performance modeling"" techniques beginning from the application design process throughout the whole software development cycle and also during the lifetime of supercomputer systems. Such models help to guide supercomputer system design and re-engineering efforts to adopt applications to changing platforms and allow users to estimate costs to solve a particular problem. Models can often be built with the help of well-known performance profiling tools. We discuss how we successfully used modeling throughout the proposal, initial testing, and beginning deployment phase of the Blue Waters supercomputer system.","Analytical models,
Computational modeling,
Optimization,
Runtime,
Predictive models,
Bandwidth,
Computer architecture"
Effect of Oxygen Partial Pressure on Silver Migration of Low-Temperature Sintered Nanosilver Die-Attach Material,"The low-temperature joining technique of silver sintering is being actively pursued in the power electronics industry as a lead-free die-attach solution for packaging power devices and modules. However, one of the concerns of this technique is the migration of silver at a high temperature. Recently, we have reported our findings of the migration of a low-temperature sintered nanosilver in dry air at a temperature over 250°1C. In this paper, we report our results of the effect of oxygen partial pressure on the migration kinetics of the sintered nanosilver at 400°C under an electrical field strength of 50 V/mm. The range of the oxygen partial pressure tested was between <; 0.01 and 0.40 atm. The silver migration kinetics were monitored by measuring the leakage current across a metal-finger pattern, which allowed the determination of the ""lifetime,"" or the onset time for significant leakage current developed across the two electrodes. With decreasing oxygen partial pressure, the lifetime increases exponentially. Our results suggest that the concern for silver migration in a high-temperature application of sintered silver die attach can be effectively remedied through packaging to keep oxygen away from the silver joints.","Silver,
Nanostructured materials,
Temperature,
Kinetic theory,
Leakage current,
Power electronics,
Electronics industry,
Environmentally friendly manufacturing techniques,
Electronics packaging,
Testing"
GPU Acceleration of Predictive Partitioned Vector Quantization for Ultraspectral Sounder Data Compression,"For the large-volume ultraspectral sounder data, compression is desirable to save storage space and transmission time. To retrieve the geophysical paramters without losing precision the ultraspectral sounder data compression has to be lossless. Recently there is a boom on the use of graphic processor units (GPU) for speedup of scientific computations. By identifying the time dominant portions of the code that can be executed in parallel, significant speedup can be achieved by using GPU. Predictive partitioned vector quantization (PPVQ) has been proven to be an effective lossless compression scheme for ultraspectral sounder data. It consists of linear prediction, bit depth partitioning, vector quantization, and entropy coding. Two most time consuming stages of linear prediction and vector quantization are chosen for GPU-based implementation. By exploiting the data parallel characteristics of these two stages, a spatial division design shows a speedup of 72x in our four-GPU-based implementation of the PPVQ compression scheme.",
DFT-based Estimation of Damped Oscillation Parameters in Low-Frequency Mechanical Spectroscopy,"In this paper, we analyze and compare the properties of different well-known and also new nonparametric discrete Fourier transform (DFT)-based methods for resonant frequency and logarithmic decrement estimation in application to mechanical spectroscopy. We derive a new DFT interpolation algorithm for a signal analyzed with Rife-Vincent class-I windows and also propose new formulas that extend Bertocco and Yoshida methods. We study errors of the resonant frequency and logarithmic decrement estimation in realistic conditions that include measurement noise and a zero-point drift. We also investigate the systematic errors of the estimation methods of interest. A nonlinear least squares time-domain parametric signal fitting is used to determine the boundaries of statistical efficiency in all tests.",
Generalized Halanay Inequalities and Their Applications to Neural Networks With Unbounded Time-Varying Delays,"In this brief, we discuss some variants of generalized Halanay inequalities that are useful in the discussion of dissipativity and stability of delayed neural networks, integro-differential systems, and Volterra functional differential equations. We provide some generalizations of the Halanay inequality, which is more accurate than the existing results. As applications, we discuss invariant set, dissipative synchronization, and global asymptotic stability for the Hopfield neural networks with infinite delays. We also prove that the dynamical systems with unbounded time-varying delays are globally asymptotically stable.","Delay,
Artificial neural networks,
Asymptotic stability,
Stability criteria,
Synchronization,
Indexes,
Differential equations"
Robust Camera Calibration and Player Tracking in Broadcast Basketball Video,"With the growth of fandom population, a considerable amount of broadcast sports videos have been recorded, and a lot of research has focused on automatically detecting semantic events in the recorded video to develop an efficient video browsing tool for a general viewer. However, a professional sportsman or coach wonders about high level semantics in a different perspective, such as the offensive or defensive strategy performed by the players. Analyzing tactics is much more challenging in a broadcast basketball video than in other kinds of sports videos due to its complicated scenes and varied camera movements. In this paper, by developing a quadrangle candidate generation algorithm and refining the model fitting score, we ameliorate the court-based camera calibration technique to be applicable to broadcast basketball videos. Player trajectories are extracted from the video by a CamShift-based tracking method and mapped to the real-world court coordinates according to the calibrated results. The player position/trajectory information in the court coordinates can be further analyzed for professional-oriented applications such as detecting wide open event, retrieving target video clips based on trajectories, and inferring implicit/explicit tactics. Experimental results show the robustness of the proposed calibration and tracking algorithms, and three practicable applications are introduced to address the applicability of our system.",
The non-Bayesian restless multi-armed bandit: A case of near-logarithmic regret,"In the classic Bayesian restless multi-armed bandit (RMAB) problem, there are N arms, with rewards on all arms evolving at each time as Markov chains with known parameters. A player seeks to activate K ≥ 1 arms at each time in order to maximize the expected total reward obtained over multiple plays. RMAB is a challenging problem that is known to be PSPACE-hard in general. We consider in this work the even harder non-Bayesian RMAB, in which the parameters of the Markov chain are assumed to be unknown a priori. We develop an original approach to this problem that is applicable when the corresponding Bayesian problem has the structure that, de pending on the known parameter values, the optimal solution is one of a prescribed finite set of policies. In such settings, we propose to learn the optimal policy for the non-Bayesian RMAB by employing a suitable meta-policy which treats each policy from this finite set as an arm in a different non-Bayesian multi-armed bandit problem for which a single-arm selection policy is optimal. We demonstrate this approach by developing a novel sensing policy for opportunistic spectrum access over unknown dynamic channels. We prove that our policy achieves near-logarithmic regret (the difference in expected reward compared to a model-aware genie), which leads to the same average reward that can be achieved by the optimal policy under a known model. This is the first such result in the literature for a non Bayesian RMAB.","Markov processes,
Bayesian methods,
Heuristic algorithms,
Sensors,
Indexes,
Switches,
Algorithm design and analysis"
Dynamic and hierarchical multi-structure geometric model fitting,"The ability to generate good model hypotheses is instrumental to accurate and robust geometric model fitting. We present a novel dynamic hypothesis generation algorithm for robust fitting of multiple structures. Underpinning our method is a fast guided sampling scheme enabled by analysing correlation of preferences induced by data and hypothesis residuals. Our method progressively accumulates evidence in the search space, and uses the information to dynamically (1) identify outliers, (2) filter unpromising hypotheses, and (3) bias the sampling for active discovery of multiple structures in the data-All achieved without sacrificing the speed associated with sampling-based methods. Our algorithm yields a disproportionately higher number of good hypotheses among the sampling outcomes, i.e., most hypotheses correspond to the genuine structures in the data. This directly supports a novel hierarchical model fitting algorithm that elicits the underlying stratified manner in which the structures are organized, allowing more meaningful results than traditional “flat” multi-structure fitting.","Heuristic algorithms,
Data models,
Computational modeling,
Algorithm design and analysis,
Sampling methods,
Filtering,
Image color analysis"
Low-Complexity Iterative Frequency Domain Decision Feedback Equalization,"Single-carrier transmission with frequency-domain equalization (SC-FDE) offers a viable design alternative to the classic orthogonal frequency-division multiplexing (OFDM) technique. However, SC-FDE using a linear equalizer may suffer from serious performance deterioration for transmission over severely frequency-selective fading channels. An effective method of solving this problem is to introduce nonlinear decision feedback equalization (DFE) to SC-FDE. In this paper, a low-complexity iterative DFE operating in the frequency domain of single-carrier systems is proposed. Based on the minimum-mean-square-error (MMSE) criterion, a simplified parameter estimation method is introduced to calculate the coefficients of the feedforward and feedback filters, which significantly reduces the implementation complexity of the equalizer. Simulation results show that the performance of the proposed simplified design is similar to the traditional iterative block DFE under various multipath fading channels, but it imposes a much lower complexity than the latter.",
Developing a Wireless Implantable Body Sensor Network in MICS Band,"Through an integration of wireless communication and sensing technologies, the concept of a body sensor network (BSN) was initially proposed in the early decade with the aim to provide an essential technology for wearable, ambulatory, and pervasive health monitoring for elderly people and chronic patients. It has become a hot research area due to big opportunities as well as great challenges it presents. Though the idea of an implantable BSN was proposed in parallel with the on-body sensor network, the development in this area is relatively slow due to the complexity of human body, safety concerns, and some technological bottlenecks such as the design of ultralow-power implantable RF transceiver. This paper describes a new wireless implantable BSN that operates in medical implant communication service (MICS) frequency band. This system innovatively incorporates both sensing and actuation nodes to form a closed-control loop for physiological monitoring and drug delivery for critically ill patients. The sensing node, which is designed using system-on-chip technologies, takes advantage of the newly available ultralow-power Zarlink MICS transceiver for wireless data transmission. Finally, the specific absorption rate distribution of the proposed system was simulated to determine the in vivo electromagnetic field absorption and the power safety limits.",
Recovery of corrupted low-rank matrices via half-quadratic based nonconvex minimization,"Recovering arbitrarily corrupted low-rank matrices arises in computer vision applications, including bioinformatic data analysis and visual tracking. The methods used involve minimizing a combination of nuclear norm and l1 norm. We show that by replacing the l1 norm on error items with nonconvex M-estimators, exact recovery of densely corrupted low-rank matrices is possible. The robustness of the proposed method is guaranteed by the M-estimator theory. The multiplicative form of half-quadratic optimization is used to simplify the nonconvex optimization problem so that it can be efficiently solved by iterative regularization scheme. Simulation results corroborate our claims and demonstrate the efficiency of our proposed method under tough conditions.",
A Fast Compressed Sensing Approach to 3D MR Image Reconstruction,"The problem of high-resolution image volume reconstruction from reduced frequency acquisition sequences has drawn significant attention from the scientific community because of its practical importance in medical diagnosis. To address this issue, several reconstruction strategies have been recently proposed, which aim to recover the missing information either by exploiting the spatio-temporal correlations of the image series, or by imposing suitable constraints on the reconstructed image volume. The main contribution of this paper is to combine both these strategies in a compressed sensing framework by exploiting the gradient sparsity of the image volume. The resulting constrained 3D minimization problem is then solved using a penalized forward-backward splitting approach that leads to a convergent iterative two-step procedure. In the first step, the updating rule accords with the sequential nature of the data acquisitions, in the second step a truly 3D filtering strategy exploits the spatio-temporal correlations of the image sequences. The resulting NFCS-3D algorithm is very general and suitable for several kinds of medical image reconstruction problems. Moreover, it is fast, stable and yields very good reconstructions, even in the case of highly undersampled image sequences. The results of several numerical experiments highlight the optimal performance of the proposed algorithm and confirm that it is competitive with state of the art algorithms.",
Noninvasive Computational Imaging of Cardiac Electrophysiology for 3-D Infarct,"Myocardial infarction (MI) creates electrophysiologically altered substrates that are responsible for ventricular ar rhythmias, such as tachycardia and fibrillation. The presence, size, location, and composition of infarct scar bear significant prognostic and therapeutic implications for individual subjects. We have developed a statistical physiological model-constrained framework that uses noninvasive body-surface-potential data and tomographic images to estimate subject-specific transmembrane potential (TMP) dynamics inside the 3-D myocardium. In this paper, we adapt this framework for the purpose of noninvasive imaging, detection, and quantification of 3-D scar mass for postMI patients: the framework requires no prior knowledge of MI and converges to final subject-specific TMP estimates after several passes of estimation with intermediate feedback; based on the primary features of the estimated spatiotemporal TMP dynamics, we provide 3-D imaging of scar tissue and quantitative evaluation of scar location and extent. Phantom experiments were performed on a computational model of realistic heart-torso geometry, considering 87 transmural infarct scars of different sizes and locations inside the myocardium, and 12 compact infarct scars (extent between 10% and 30%) at different transmural depths. Real data experiments were carried out on BSP and magnetic resonance imaging (MRI) data from four postMI patients, validated by gold standards and existing results. This framework shows unique advantage of noninvasive, quantitative, computational imaging of subject-specific TMP dynamics and infarct mass of the 3-D myocardium, with the potential to reflect details in the spatial structure and tissue composition/heterogeneity of 3-D infarct scar.",
An energy-efficient adaptive hybrid cache,"By reconfiguring part of the cache as software-managed scratchpad memory (SPM), hybrid caches manage to handle both unknown and predictable memory access patterns. However, existing hybrid caches provide a flexible partitioning of cache and SPM without considering adaptation to the run-time cache behavior. Previous cache set balancing techniques are either energy-inefficient or require serial tag and data array access. In this paper an adaptive hybrid cache is proposed to dynamically remap SPM blocks from high-demand cache sets to low-demand cache sets. This achieves 19%, 25%, 18% and 18% energy-runtime-production reductions over four previous representative techniques on a wide range of benchmarks.","Arrays,
Radiation detectors,
Software,
Benchmark testing,
Indexes,
Decoding"
Expression recognition from 3D dynamic faces using robust spatio-temporal shape features,"This paper proposes a new method for comparing 3D facial shapes using facial level curves. The pair- and segment-wise distances between the level curves comprise the spatio-temporal features for expression recognition from 3D dynamic faces. The paper further introduces universal background modeling and maximum a posteriori adaptation for hidden Markov models, leading to a decision boundary focus classification algorithm. Both techniques, when combined, yield a high overall recognition accuracy of 92.22% on the BU-4DFE database in our preliminary experiments. Noticeably, our feature extraction method is very efficient, requiring simple preprocessing, and robust to variations of the input data quality.",
Extraction and Adaptation of Fuzzy Rules for Friction Modeling and Control Compensation,"Modeling of friction forces has been a challenging task in mechanical engineering. Parameterized approaches for modeling friction find it difficult to achieve satisfactory performance due to the presence of nonlinearity and uncertainties in dynamical systems. This paper aims to develop adaptive fuzzy friction models by the use of data-mining techniques and system theory. Our main technical contributions are twofold: extraction of fuzzy rules and formulation of a static fuzzy friction model and adaptation of the fuzzy friction model by the use of the Lyapunov stability theory, which is associated with a control compensation of a typical motion dynamics. The proposed framework in this paper shows a successful application of adaptive data-mining techniques in engineering. A single-degree-of-freedom mechanical system is employed as an experimental model in simulation studies. Results demonstrate that our proposed fuzzy friction model has promise in the design of uncertain mechanical control systems.",
Locality-constrained group sparse representation for robust face recognition,"This paper presents a novel sparse representation for robust face recognition. We advance both group sparsity and data locality and formulate a unified optimization framework, which produces a locality and group sensitive sparse representation (LGSR) for improved recognition. Empirical results confirm that our LGSR not only outperforms state-of-the-art sparse coding based image classification methods, our approach is robust to variations such as lighting, pose, and facial details (glasses or not), which are typically seen in real-world face recognition problems.",
Small Universal Spiking Neural P Systems Working in Exhaustive Mode,"Spiking neural P systems are a class of distributed parallel computing devices inspired from the way neurons communicate by means of spikes. In this paper, the problem of looking for small universal computing devices is investigated in the framework of spiking neural P systems. A new approach is introduced to simulate register machines by spiking neural P systems, where only one neuron is used for all instructions of the simulated register machine; in this way, less neurons are used to construct universal spiking neural P systems working in exhaustive mode. Specifically, a universal spiking neural P system with 36 neurons is constructed, which works in exhaustive mode. This significantly improves the already known result, where 125 neurons are used.",
Coherent Detection of Multiband Terahertz Radiation Using a Surface Plasmon-Polariton Based Photoconductive Antenna,"We characterize a dipole antenna structure that allows for coherent detection of narrowband terahertz radiation with enhanced sensitivity at the resonant frequency. The antenna incorporates a corrugated metal structure that surrounds the dipole. Each periodically spaced groove in the corrugation couples an approximate replica of the incident THz pulse to a surface plasmon-polariton pulse, which then propagates towards and is detected by the dipole. We use numerical simulations to validate the experimental data. Based on these results, we describe a multiband dipole antenna detector that allows for enhanced sensitivity at multiple frequencies. This device can also be used as an emitter.",
Practical performance prediction under Dynamic Voltage Frequency Scaling,"Predicting performance under Dynamic Voltage Frequency Scaling (DVFS) remains an open problem. Current best practice explores available performance counters to serve as input to linear regression models that predict performance. However, the inaccuracies of these models require that large-scale DVFS runtime algorithms predict performance conservatively in order to avoid significant consequences of mispredictions. Recent theoretical work based on interval analysis advocates a more accurate and reliable solution based on a single new performance counter, Leading Loads. In this paper, we evaluate a processor-independent analytic framework for existing performance counters based on this interval analysis model. We begin with an analysis of the counters used in many published models. We then briefly describe the Leading Loads architectural model and describe how we can use Leading Loads Cycles to predict performance under DVFS. We validate this approach for the NAS Parallel Benchmarks and SPEC CPU 2006 benchmarks, demonstrating an order of magnitude improvement in both error and standard deviation compared to the best existing approaches.","Time frequency analysis,
Benchmark testing,
Clocks,
Load modeling,
Predictive models,
Computational modeling,
Radiation detectors"
High-efficiency high-power dc-dc converter for energy and space saving of power-supply system in a data center,"This paper presents the power density developments of high-power isolated dc-dc converter to be utilized in a higher voltage direct-current (HVDC) power-supply system of a data center. This technique results in a prototype of dc-dc converter unit which is smaller by factor of ten when compared with the conventional one, and the area of power-supply system becomes much smaller than before. Consequently, the cooling power for this power-supply system is saved and both the energy and the space saving are available. In order to realize a prototype of the high-power isolated dc-dc converter, the switching power devices composed of a hybrid pair of Si-CoolMOS and SiC-SBD are utilized and operated in a driving pattern of hard switching with a frequency of 200kHz. As a result, an isolated dc-dc converter with the input/output voltage of 400V/400V, a rating power of 5kW, and a high power density of 10W/cm3 has been fabricated. The experimental confirmation was reported and the surge problems due to diode recovery difficulties mentioned before was solved.","Converters,
Rectifiers,
Surges,
Schottky diodes,
Inverters,
HVDC transmission,
Inductance"
A hidden Markov model based procedure for identifying household electric loads,"In automated energy management systems, to make instantaneous decisions based on the appliance status information, continuous data access is a key requirement. With the advances in sensor and communication technologies, it is now possible to remotely monitor the power consumption data. However, before an appliance is actively monitored, it must be identified using the obtained power consumption data. Appropriate methods are required to analyse power consumption patterns for proper appliance recognition. The focus of this work is to provide the model structure for storing and distinguishing the recurring footprints of the household appliances. Hidden Markov model based method is proposed to recognize the individual appliances from combined load. It is found that the proposed method can efficiently differentiate the power consumption patterns of appliances from their combined profiles.",
Reliability Options for Data Communications in the Future Deep-Space Missions,"Availability of higher capacity for both uplinks and downlinks is expected in the future deep-space missions on Mars, thus enabling a large range of services that could eventually support human remote operations. The provisioning for deep-space links offering data rate up to several megabits per second will be a crucial element to allow new services for the space domain along with the common telecommand and telemetry services with enhanced communication capabilities. On the other hand, also the geometry proper of this scenario with orbiting and landed elements sharing only partial visibility among them and towards Earth provides another challenge. This paper surveys the reliability options that are available in the Consultative Committee for Space Data Systems (CCSDS) Protocol Stack for application in the deep-space missions. In particular, the solutions implemented from the physical up to the application layer are illustrated in terms of channel coding and Automatic Retransmission reQuest (ARQ) schemes. Finally, advanced reliability strategies possibly applicable in next-generation deep-space missions are explored as well.","Protocols,
Space missions,
Fault tolerance,
Channel coding,
Space vehicles,
Synchronization,
Space missions,
Mars"
Topological Spines: A Structure-preserving Visual Representation of Scalar Fields,"We present topological spines-a new visual representation that preserves the topological and geometric structure of a scalar field. This representation encodes the spatial relationships of the extrema of a scalar field together with the local volume and nesting structure of the surrounding contours. Unlike other topological representations, such as contour trees, our approach preserves the local geometric structure of the scalar field, including structural cycles that are useful for exposing symmetries in the data. To obtain this representation, we describe a novel mechanism based on the extraction of extremum graphs-sparse subsets of the Morse-Smale complex that retain the important structural information without the clutter and occlusion problems that arise from visualizing the entire complex directly. Extremum graphs form a natural multiresolution structure that allows the user to suppress noise and enhance topological features via the specification of a persistence range. Applications of our approach include the visualization of 3D scalar fields without occlusion artifacts, and the exploratory analysis of high-dimensional functions.","Topology,
Data visualization,
Approximation methods,
Manifolds"
Simultaneous Optimization of Sensor Placements and Balanced Schedules,"We consider the problem of monitoring spatial phenomena, such as road speeds on a highway, using wireless sensors with limited battery life. A central question is to decide where to locate these sensors to best predict the phenomenon at the unsensed locations. However, given the power constraints, we also need to determine when to activate these sensors in order to maximize the performance while satisfying lifetime requirements. Traditionally, these two problems of sensor placement and scheduling have been considered separately; one first decides where to place the sensors, and then when to activate them.",
Generating natural language summaries for crosscutting source code concerns,"When performing a software change task, programmers expend substantial effort investigating a system's code base to find and understand just the code that is pertinent to a task-at-hand. A particularly difficult kind of code to handle during these tasks is crosscutting concern code. To help programmers handle such code, we introduce an automated approach that produces a natural language summary that describes both what the concern is and how the concern is implemented. We describe our approach and present the results of an experiment in which programmers were able to perform change tasks more efficiently and more easily with generated concern summaries than without.",
Efficient Volume Exploration Using the Gaussian Mixture Model,"The multidimensional transfer function is a flexible and effective tool for exploring volume data. However, designing an appropriate transfer function is a trial-and-error process and remains a challenge. In this paper, we propose a novel volume exploration scheme that explores volumetric structures in the feature space by modeling the space using the Gaussian mixture model (GMM). Our new approach has three distinctive advantages. First, an initial feature separation can be automatically achieved through GMM estimation. Second, the calculated Gaussians can be directly mapped to a set of elliptical transfer functions (ETFs), facilitating a fast pre-integrated volume rendering process. Third, an inexperienced user can flexibly manipulate the ETFs with the assistance of a suite of simple widgets, and discover potential features with several interactions. We further extend the GMM-based exploration scheme to time-varying data sets using an incremental GMM estimation algorithm. The algorithm estimates the GMM for one time step by using itself and the GMM generated from its previous steps. Sequentially applying the incremental algorithm to all time steps in a selected time interval yields a preliminary classification for each time step. In addition, the computed ETFs can be freely adjusted. The adjustments are then automatically propagated to other time steps. In this way, coherent user-guided exploration of a given time interval is achieved. Our GPU implementation demonstrates interactive performance and good scalability. The effectiveness of our approach is verified on several data sets.",
Social-Based Cooperative Caching in DTNs: A Contact Duration Aware Approach,"Data access is an important issue in Delay Tolerant Networks (DTNs), and a common technique to improve the performance of data access is cooperative caching. However, due to the unpredictable node mobility in DTNs, traditional caching schemes cannot be directly applied. In this paper, we propose DAC, a novel caching protocol adaptive to the challenging environment of DTNs. Specifically, we exploit the social community structure to combat the unstable network topology in DTNs. We propose a new centrality metric to evaluate the caching capability of each node within a community, and solutions based on this metric are proposed to determine where to cache. More importantly, we consider the impact of the contact duration limitation on cooperative caching, which has been ignored by the existing works. We prove that the marginal caching benefit that a node can provide diminishes when more data is cached. We derive an adaptive caching bound for each mobile node according to its specific contact patterns with others, to limit the amount of data it caches. In this way, both the storage space and the contact opportunities are better utilized. To mitigate the coupon collector's problem, network coding techniques are used to further improve the caching efficiency. Extensive trace-driven simulations show that our cooperative caching protocol can significantly improve the performance of data access in DTNs.","Communities,
Cooperative caching,
Measurement,
Protocols,
Mobile communication,
Time factors,
Random variables"
Localization of Mobile Nodes in Wireless Networks with Correlated in Time Measurement Noise,"Wireless sensor networks are an inherent part of decision making, object tracking, and location awareness systems. This work is focused on simultaneous localization of mobile nodes based on received signal strength indicators (RSSIs) with correlated in time measurement noises. Two approaches to deal with the correlated measurement noises are proposed in the framework of auxiliary particle filtering: with a noise augmented state vector and the second approach implements noise decorrelation. The performance of the two proposed multimodel auxiliary particle filters (MM AUX-PFs) is validated over simulated and real RSSIs and high localization accuracy is demonstrated.",
Assessing Reactive Power Reserves With Respect to Operating Constraints and Voltage Stability,"This paper proposes a two-step approach to evaluate reactive power reserves with respect to operating constraints and voltage stability for a set of postulated operating scenarios. The first step determines the minimum overall needed reactive power reserves of generators such that the system withstands, from a static viewpoint, any postulated scenario. This problem is formulated as a security constrained optimal power flow (SCOPF) which includes operating constraints relative to all postulated scenarios. Particular attention is paid to the techniques aimed to reduce the large size of the SCOPF problem. The second step determines additional reserves to ensure voltage stability of scenarios for which, when modeling dynamic system behavior, the reserves obtained by SCOPF are insufficient. These reserves are computed using a heuristic technique which relies on dynamic simulation. Numerical results on four test systems of 60, 118, 618, and 1203 buses support the interest of the approach.",
MIMO Closed Loop Identification of an Industrial Robot,"This paper proposes a practical multi-input multi-output (MIMO) closed loop parameters identification procedure for robot manipulators. It is based on the weighted least squares (WLS) method, coupled with particular solutions to facilitate the estimation, reducing the noise effect. More precisely, a two steps procedure to reduce the condition number of the input data matrix with optimal trajectory planning, and a method to estimate the variances matrix to be used as a weight matrix for the WLS method are illustrated. Moreover, the identification problem is solved with reference to an MIMO coupled system. A closed loop identification is needed because the system is open loop unstable, and because the robot has to track an optimal reference input so as to correctly execute the identification procedure. Some solutions are also presented to overtake common identification problems, such as the bias of the estimated parameters, the presence of outliers, the necessity of balancing the kinematics of the third link, and the reduction of the sensitivity to noise of the estimate. The presented procedure has been successfully experimentally tested on a COMAU SMART3-S2 industrial manipulator used in a planar configuration.","MIMO,
Least squares methods,
System identification,
Manipulators,
Robots"
"Adaptive Sampling Algorithm for Macromodeling of Parameterized
S
-Parameter Responses","This paper presents a new adaptive sampling strategy for the parametric macromodeling of -parameter-based frequency responses. It can be linked directly with the simulator to determine up front a sparse set of data samples that characterize the design space. This approach limits the overall simulation and macromodeling time. The resulting sample distribution can be fed into any kind of macromodeling technique, provided that it can deal with scattered data. The effectiveness of the approach is illustrated by a parameterized H-shaped microwave example.","Data models,
Adaptation model,
Algorithm design and analysis,
Measurement,
Frequency response,
Computational modeling,
Linear approximation"
Path Following for Unicycle Robots With an Arbitrary Path Curvature,"A new feedback control model is provided that allows a wheeled vehicle to follow a prescribed path. Differently from all other methods in the literature, the method that is proposed neither requires the computation of a projection of the robot position on the path, nor does it need to consider a moving virtual target to be tracked. Nevertheless, it guarantees asymptotic convergence to a generic 2-D curve which can be represented through its implicit equation in the form f(x,y)=0, and it puts no bounds on the initial position of the vehicle, provided that ∇f ≠ 0 .","Vehicles,
Convergence,
Equations,
Trajectory,
Mobile robots,
Asymptotic stability"
Can one hear the shape of a room: The 2-D polygonal case,"We consider the problem of estimating room geometry from the acoustic room impulse response (RIR). Existing approaches addressing this problem exploit the knowledge of multiple RIRs. In contrast, we are interested in reconstructing the room geometry from a single RIR - a 1-D function of time. We discuss the uniqueness of the mapping between the geometry of a planar polygonal room and a single RIR. In addition to this theoretical analysis, we also propose an algorithm that performs the ""blindfolded"" room estimation. Furthermore, the derived results are used to construct an algorithm for localization in a known room using only a single RIR. Verification of the theoretical developments with numerical simulations is given before concluding the paper.","Geometry,
Delay,
Shape,
Acoustics,
Signal to noise ratio,
Estimation,
Image reconstruction"
Quantum Broadcast Channels,"We consider quantum channels with one sender and two receivers, used in several different ways for the simultaneous transmission of independent messages. We begin by extending the technique of superposition coding to quantum channels with a classical input to give a general achievable region. We also give outer bounds to the capacity regions for various special cases from the classical literature and prove that superposition coding is optimal for a class of channels. We then consider extensions of superposition coding for channels with a quantum input, where some of the messages transmitted are quantum instead of classical, in the sense that the parties establish bipartite or tripartite GHZ entanglement. We conclude by using state merging to give achievable rates for establishing bipartite entanglement between different pair of parties with the assistance of free classical communication.","Quantum mechanics,
Entropy,
Channel coding,
Merging,
Markov processes,
Mutual information"
Control Over Noisy Forward and Reverse Channels,"We consider the problem of remotely controlling a continuous-time linear time-invariant system driven by Brownian motion process, when communication takes place over noisy memoryless discrete- or continuous-alphabet channels. What makes this class of remote control problems different from most of the previously studied models is the presence of noise in both the forward channel (connecting sensors to the controller) and the reverse channel (connecting the controller to the plant). For stability of the closed-loop system, we look for the existence of an invariant distribution for the state, for which we show that it is necessary that the entire control space and the state space be encoded, and that the reverse channel be at least as reliable as the forward channel. We obtain necessary conditions and sufficient conditions on the channels and the controllers for stabilizability. Using properties of the underlying sampled Markov chain, we show that under variable-length coding and some realistic channel conditions, stability can be achieved over discrete-alphabet channels even if the entire state and control spaces are to be encoded and the number of bits that can be transmitted per unit time is strictly bounded. For control over continuous-alphabet channels, however, a variable rate scheme is not necessary. We also show that memoryless policies are rate-efficient for Gaussian channels.","Markov processes,
Noise measurement,
Encoding,
Noise,
Aerospace electronics,
Decoding,
Sensors"
Novel Capacitorless 1T-DRAM Cell for 22-nm Node Compatible With Bulk and SOI Substrates,"A new concept of multibody single-transistor dynamic-random-access-memory cell fully compatible with both standard bulk and silicon-on-insulator substrates is presented. Its novelty comes from the juxtaposition of two silicon films with opposed doping polarities (i.e., a p-n junction), which define a body partitioning for hole storage and current sense. The charge accumulated in the top body controls the current flowing through the bottom body. The scalability is ensured due to the suppression of the supercoupling effect, thus allowing the coexistence of electrons and holes in very thin transistors. Numerical simulations of electrostatics and dynamic operation show how the transient response of this device can be used for dynamic-memory applications, achieving attractive performance in terms of state discrimination and retention time in very scaled devices.",
Continuous Stochastic Feature Mapping Based on Trajectory HMMs,"This paper proposes a technique of continuous stochastic feature mapping based on trajectory hidden Markov models (HMMs), which have been derived from HMMs by imposing explicit relationships between static and dynamic features. Although Gaussian mixture model (GMM)- or HMM-based feature-mapping techniques work effectively, their accuracy occasionally degrades due to inappropriate dynamic characteristics caused by frame-by-frame mapping. While the use of dynamic-feature constraints at the mapping stage can alleviate this problem, it also introduces inconsistencies between training and mapping. The technique we propose can eliminate these inconsistencies while retaining the benefits of using dynamic-feature constraints, and it offers entire sequence-level transformation rather than frame-by-frame mapping. The results obtained from speaker-conversion, acoustic-to-articulatory inversion-mapping, and noise-compensation experiments demonstrated that our new approach outperformed the conventional one.","Stochastic processes,
Trajectory,
Hidden Markov models,
Speech enhancement,
Degradation,
Computer science,
Training data,
Speech recognition,
Stochastic resonance,
Loudspeakers"
Musical Instrument Classification Using Individual Partials,"In a musical signals, the spectral and temporal contents of instruments often overlap. If the number of channels is at least the same as the number of instruments, it is possible to apply statistical tools to highlight the characteristics of each instrument, making their identification possible. However, in the underdetermined case, in which there are fewer channels than sources, the task becomes challenging. One possible way to solve this problem is to seek for regions in the time and/or frequency domains in which the content of a given instrument appears isolated. The strategy presented in this paper explores the spectral disjointness among instruments by identifying isolated partials, from which a number of features are extracted. The information contained in those features, in turn, is used to infer which instrument is more likely to have generated that partial. Hence, the only condition for the method to work is that at least one isolated partial exists for each instrument somewhere in the signal. If several isolated partials are available, the results are summarized into a single, more accurate classification. Experimental results using 25 instruments demonstrate the good discrimination capabilities of the method.",
Motion planning for concentric tube robots using mechanics-based models,"Concentric tube robots have the potential to enable new minimally invasive surgical procedures by curving around anatomical obstacles to reach difficult-to-reach sites in body cavities. Planning motions for these devices is challenging in part due to their complex kinematics; concentric tube robots are composed of thin, pre-curved, telescoping tubes that can achieve a variety of shapes via extension and rotation of each of their constituent tubes. We introduce a new motion planner to maneuver these devices to clinical targets while minimizing the probability of colliding with anatomical obstacles. Unlike prior planners for these devices, we more accurately model device shape using mechanics-based models that consider torsional interaction between the tubes. We also account for the effects of uncertainty in actuation and predicted device shape. We integrate these models with a sampling-based approach based on the Rapidly-Exploring Roadmap to guarantee finding optimal plans as computation time is allowed to increase. We demonstrate our motion planner in simulation using a variety of evaluation scenarios including an anatomy-based neurosurgery case that requires maneuvering to a di#cult-to-reach brain tumor at the skull base.",
Performance guidelines for WDM interconnects based on silicon microring resonators,"We derive fundamental performance tradeoffs that determine bandwidth and optical power budget in large-scale WDM links or networks utilizing silicon microresonators. Bandwidth per waveguide scales to >;1THz, but nonlinearities limit optical power to milliwatt levels.","Optical resonators,
Optical filters,
Optical crosstalk,
Crosstalk,
Nonlinear optics,
Silicon,
Wavelength division multiplexing"
Wireless Sensor Networks for Monitoring Physiological Signals of Multiple Patients,"This paper presents the design of a novel wireless sensor network structure to monitor patients with chronic diseases in their own homes through a remote monitoring system of physiological signals. Currently, most of the monitoring systems send patients' data to a hospital with the aid of personal computers (PC) located in the patients' home. Here, we present a new design which eliminates the need for a PC. The proposed remote monitoring system is a wireless sensor network with the nodes of the network installed in the patients' homes. These nodes are then connected to a central node located at a hospital through an Internet connection. The nodes of the proposed wireless sensor network are created by using a combination of ECG sensors, MSP430 microcontrollers, a CC2500 low-power wireless radio, and a network protocol called the SimpliciTI protocol. ECG signals are first sampled by a small portable device which each patient carries. The captured signals are then wirelessly transmitted to an access point located within the patients' home. This connectivity is based on wireless data transmission at 2.4-GHz frequency. The access point is also a small box attached to the Internet through a home asynchronous digital subscriber line router. Afterwards, the data are sent to the hospital via the Internet in real time for analysis and/or storage. The benefits of this remote monitoring are wide ranging: the patients can continue their normal lives, they do not need a PC all of the time, their risk of infection is reduced, costs significantly decrease for the hospital, and clinicians can check data in a short time.","Electrocardiography,
Wireless communication,
Hospitals,
Wireless sensor networks,
Radio frequency,
Protocols,
Monitoring"
Graceful Network State Migrations,"A significant fraction of network events (such as topology or route changes) and the resulting performance degradation stem from premeditated network management and operational tasks. This paper introduces a general class of Graceful Network State Migration (GNSM) problems, where the goal is to discover the optimal sequence of operations that progressively transition the network from its initial to a desired final state while minimizing the overall performance disruption. We investigate two specific GNSM problems: 1) Link Weight Reassignment Scheduling (LWRS) studies the optimal ordering of link weight updates to migrate from an existing to a new link weight assignment; and 2) Link Maintenance Scheduling (LMS) looks at how to schedule link deactivations and subsequent reactivations for maintenance purposes. LWRS and LMS are both combinatorial optimization problems. We use dynamic programming to find the optimal solutions when the problem size is small, and leverage ant colony optimization to get near-optimal solutions for large problem sizes. Our simulation study reveals that judiciously ordering network operations can achieve significant performance gains. Our GNSM solution framework is generic and applies to similar problems with different operational contexts, underlying network protocols or mechanisms, and performance metrics.","Least squares approximation,
Schedules,
Maintenance engineering,
Transient analysis,
Routing protocols,
Routing,
Optimal scheduling"
"A Little More, a Lot Better: Improving Path Quality by a Path-Merging Algorithm","Sampling-based motion planners are an effective means to generate collision-free motion paths. However, the quality of these motion paths (with respect to quality measures, such as path length, clearance, smoothness, or energy) is often notoriously low, especially in high-dimensional configuration spaces. We introduce a simple algorithm to merge an arbitrary number of input motion paths into a hybrid output path of superior quality, for a broad and general formulation of path quality. Our approach is based on the observation that the quality of certain subpaths within each solution may be higher than the quality of the entire path. A dynamic-programming algorithm, which we recently developed to compare and cluster multiple motion paths, reduces the running time of the merging algorithm significantly. We tested our algorithm in motion-planning problems with up to 12 degrees of freedom (DOFs), where our method is shown to be particularly effective. We show that our algorithm is able to merge a handful of input paths produced by several different motion planners to produce output paths of much higher quality.",
Optimal Anycast Technique for Delay-Sensitive Energy-Constrained Asynchronous Sensor Networks,"In wireless sensor networks (WSNs), asynchronous sleep-wake scheduling protocols can be used to significantly reduce energy consumption without incurring the communication overhead for clock synchronization needed for synchronous sleep-wake scheduling protocols. However, these savings could come at a significant cost in delay performance. Recently, researchers have attempted to exploit the inherent broadcast nature of the wireless medium to reduce this delay with virtually no additional energy cost. These schemes are called “anycasting,” where each sensor node forwards the packet to the first node that wakes up among a set of candidate next-hop nodes. In this paper, we develop a delay-optimal anycasting scheme under periodic sleep-wake patterns. Our solution is computationally simple and fully distributed. Furthermore, we show that periodic sleep-wake patterns result in the smallest delay among all wake-up patterns under given energy constraints. Simulation results illustrate the benefit of our proposed schemes over the state of the art.",
Decentralized Fair Scheduling in Two-Hop Relay-Assisted Cognitive OFDMA Systems,"In this paper, we consider a two-hop relay-assisted cognitive downlink Orthogonal frequency-division multiple access (OFDMA) system (named as secondary system) dynamically accessing a spectrum licensed to a primary network, thereby improving the efficiency of spectrum usage. A cluster-based relay-assisted architecture is proposed for the secondary system, where relay stations are employed for minimizing the interference to the users in the primary network and achieving fairness for cell-edge users in the secondary system. Based on this architecture, an asymptotically optimal solution is derived for jointly controlling data rates, transmission power, and subchannel allocation to optimize the average weighted sum goodput where the proportional fair scheduling (PFS) is included as a special case. This solution supports decentralized implementation, requires small communication overhead, and is robust against imperfect channel state information at the transmitter (CSIT) and imperfect sensing measurement. The proposed solution achieves significant throughput gain and better user-fairness compared with the existing designs. Finally, we derive a simple and asymptotically optimal scheduling solution as well as the associated closed-form performance under the proportional fair scheduling for a large number of users. The system throughput is shown to be O(N(1-qp)(1-qpN)lnlnKc), where Kc is the number of users in one cluster, N is the number of subchannels, and qp is the active probability of primary users.",
Interactive visualization of multivariate trajectory data with density maps,"We present a method to interactively explore multiple attributes in trajectory data using density maps, i.e., images that show an aggregate overview of massive amounts of data. So far, density maps have mainly been used to visualize single attributes. Density maps are created in a two-way procedure; first smoothed trajectories are aggregated in a density field, and then the density field is visualized. In our approach, the user can explore attributes along trajectories by calculating a density field for multiple subsets of the data. These density fields are then either combined into a new density field or first visualized and then combined. Using a widget, called a distribution map, the user can interactively define subsets in an effective and intuitive way, and, supported by high-end graphics hardware the user gets fast feedback for these computationally expensive density field calculations. We show the versatility of our method with use cases in the maritime domain: to distinguish between periods in the temporal aggregation, to find anomalously behaving vessels, to solve ambiguities in density maps via drill down in the data, and for risk assessments. Given the generic framework and the lack of domain-specific assumptions, we expect our concept to be applicable for trajectories in other domains as well.",
Community detection using a neighborhood strength driven Label Propagation Algorithm,"Studies of community structure and evolution in large social networks require a fast and accurate algorithm for community detection. As the size of analyzed communities grows, complexity of the community detection algorithm needs to be kept close to linear. The Label Propagation Algorithm (LPA) has the benefits of nearly-linear running time and easy implementation, thus it forms a good basis for efficient community detection methods. In this paper, we propose new update rule and label propagation criterion in LPA to improve both its computational efficiency and the quality of communities that it detects. The speed is optimized by avoiding unnecessary updates performed by the original algorithm. This change reduces significantly (by order of magnitude for large networks) the number of iterations that the algorithm executes. We also evaluate our generalization of the LPA update rule that takes into account, with varying strength, connections to the neighborhood of a node considering a new label. Experiments on computer generated networks and a wide range of social networks show that our new rule improves the quality of the detected communities compared to those found by the original LPA. The benefit of considering positive neighborhood strength is pronounced especially on real-world networks containing sufficiently large fraction of nodes with high clustering coefficient.",
Controlled Coalitional Games for Cooperative Mobile Social Networks,"Mobile social networks have been introduced as a new efficient (i.e., minimizing bandwidth usage) and effective (i.e., minimizing the delay or maximizing the number of target recipients) way of disseminating content and information to a particular group of mobile users who share similar interests. In this paper, we investigate how the content providers and the network operator can interact to distribute content in a mobile social network. The objective of each content provider is to minimize the cost that pertains to the time used to distribute the content to the subscribed mobile users and the cost due to the price paid to the network operator for transferring the content over a wireless connection through a base station. Although the content providers can cooperate by forming coalitions for sharing a wireless connection, the network operator can control the amount of bandwidth provided over the wireless connection. We introduce a novel coalitional game model, which is referred to as the controlled coalitional game, to investigate the decision-making process of the content providers and the network operator. Numerical studies show that, given the allocated bandwidth from the network operator, the content providers can self organize into coalitions while minimizing their individual cost. In addition, the results demonstrate that the revenue of the network operator can be maximized when the bandwidth allocation is performed while considering the coalitional structure of the content providers.",
Beyond Simon's Slice: Five Fundamental Trade-Offs that Bound the Performance of Macrocognitive Work Systems,"Articulating the laws of cognitive work has been a continuing theme in this department. A number of the articles represent an effort to move toward a unified theory of ""macrocognitive work systems."" These are complex adaptive systems designed to support near-continuous interdependencies among humans and intelligent machines to carry out functions such as sensemaking, replanning, mental projection to the future, and coordination. The effort to identify empirical generalizations and use them to construct a formal theory has led us to the identification of a number of fundamental trade-offs that place boundary conditions on all macrocognitive work systems. This article presents five trade-offs identified to date that define these boundary conditions. It also illustrates how the known empirical generalizations about the performance of human work systems can be systematically organized by the trade-offs.","Man machine systems,
Systems engineering and theory,
Adaptive systems"
Benefits and limitations of tapping into stored energy for datacenters,"Datacenter power consumption has a significant impact on both its recurring electricity bill (Op-ex) and one-time construction costs (Cap-ex). Existing work optimizing these costs has relied primarily on throttling devices or workload shaping, both with performance degrading implications. In this paper, we present a novel knob of energy buffer (eBuff) available in the form of UPS batteries in datacenters for this cost optimization. Intuitively, eBuff stores energy in UPS batteries during “valleys” - periods of lower demand, which can be drained during “peaks” - periods of higher demand. UPS batteries are normally used as a fail-over mechanism to transition to captive power sources upon utility failure. Furthermore, frequent discharges can cause UPS batteries to fail prematurely. We conduct detailed analysis of battery operation to figure out feasible operating regions given such battery lifetime and datacenter availability concerns. Using insights learned from this analysis, we develop peak reduction algorithms that combine the UPS battery knob with existing throttling based techniques for minimizing datacenter power costs. Using an experimental platform, we offer insights about Op-ex savings offered by eBuff for a wide range of workload peaks/valleys, UPS provisioning, and application SLA constraints. We find that eBuff can be used to realize 15-45% peak power reduction, corresponding to 6-18% savings in Op-ex across this spectrum. eBuff can also play a role in reducing Cap-ex costs by allowing tighter overbooking of power infrastructure components and we quantify the extent of such Cap-ex savings. To our knowledge, this is the first paper to exploit stored energy - typically lying untapped in the datacenter - to address the peak power draw problem.","Uninterruptible power systems,
Batteries,
Discharges (electric),
Availability,
Runtime,
US Department of Defense"
Architecture on demand for transparent optical networks,"We present the Architecture on Demand (AoD) concept whereby transparent optical cross-connects (OXC) do not have an associated static architecture but can adapt their architecture to suit to the switching and processing requirements of input traffic. The proposed AoD-OXC is implemented with a 96 × 96 3D-MEMS optical switch functioning as an optical backplane that interconnects architecture-building modules that provide the required services such as arbitrary spectrum switching, time-domain sub-wavelength switching and optical multicasting. This approach will enable unprecedented levels of flexibility and modularity for the introduction of new services and applications in transparent optical networks.","Optical switches,
Integrated optics,
Computer architecture,
High speed optical techniques,
Optical fiber networks,
Optical interconnections"
Distributed computer vision algorithms through distributed averaging,"Traditional computer vision and machine learning algorithms have been largely studied in a centralized setting, where all the processing is performed at a single central location. However, a distributed approach might be more appropriate when a network with a large number of cameras is used to analyze a scene. In this paper we show how centralized algorithms based on linear algebraic operations can be made distributed by using simple distributed averages. We cover algorithms such as SVD, least squares, PCA, GPCA, 3-D point triangulation, pose estimation and affine SfM.","Cameras,
Principal component analysis,
Distributed databases,
Estimation,
Least squares approximation,
Polynomials,
Computer vision"
"Enhanced MIMO LMMSE Turbo Equalization: Algorithm, Simulations, and Undersea Experimental Results","In this paper, an enhanced linear minimum mean square error (LMMSE) turbo equalization scheme is proposed for multiple-input multiple-output (MIMO) communication systems with bit-interleaved coded modulation (BICM) in the time domain and multiplexing in the space domain. The proposed turbo equalization scheme outperforms the conventional LMMSE turbo equalization by adopting two new signal processing techniques. First, it performs hybrid soft interference cancellation (HSOIC) by subtracting the soft decisions of the interfering symbols, and the soft decisions are calculated by using a hybrid of the a priori information at the equalizer input and the a posteriori information at the equalizer output. Second, it employs a novel block-wise reliability-based ordering scheme such that more “reliable” symbols are detected before the less “reliable” ones to reduce error propagation in HSOIC. The symbol reliability information is based on the symbol a priori probability, as a unique byproduct of turbo detection, thus can be obtained with very small overhead. A low-complexity approximation of the enhanced MIMO LMMSE turbo equalization is also proposed to balance the tradeoff between complexity and performance. The performance of the enhanced MIMO LMMSE turbo equalization has been verified through both numerical simulations and the undersea experimental data collected in the SPACE08 experiment launched near Martha's Vineyard, Edgartown, MA, in 2008.",
Simultaneous Capacitive and Electrothermal Position Sensing in a Micromachined Nanopositioner,"This letter reports a micromachined nanopositioner with capacitive actuation together with capacitive and electrothermal sensing on a single chip. With the actuation voltage of 60 V, the electrostatic actuator can achieve a maximum displacement of 2.32 μm. The displacement can be simultaneously measured using capacitive and electrothermal sensors. Both sensors are calibrated to operate at a sensitivity of 0.0137 V/V. The electrothermal sensor is found to display 1/f noise, which affects the low-frequency measurements obtained from this device. However, at higher frequencies, it displays a lower noise power spectral density when compared with the capacitive sensor. The comparisons of frequency responses, power consumptions, and noise performances are presented in this letter.",
Stability and Fairness of AP Selection Games in IEEE 802.11 Access Networks,"Wireless stations (WSs) in an IEEE 802.11 access network compete with each other for collective bandwidth offered by access points (APs). The competition involves selecting an AP with the consideration of potential link rate and workload status. From the perspective of system, a good AP selection policy should be stable, increase overall system throughput, and maintain bandwidth fairness among WSs. This paper models AP selections under the framework of game theory, where each WS's sole goal is to maximize its achievable throughput. The achievable throughput depends on not only the number of WSs that associate with the same AP but the set of link rates these WSs use as well. It is not a monotonically decreasing function of WS population when considering the effect of performance anomaly. We have proven the stability of this game (Nash equilibrium) and shown that selfish behavior of individual WSs in fact improves overall bandwidth fairness among WSs. Thorough simulations were conducted to demonstrate the validity of the analytical results and compare the performance of the proposed game with that of counterparts.",
Liszt: A domain specific language for building portable mesh-based PDE solvers,"Heterogeneous computers with processors and accelerators are becoming widespread in scientific computing. However, it is difficult to program hybrid architectures and there is no commonly accepted programming model. Ideally, applications should be written in a way that is portable to many platforms, but providing this portability for general programs is a hard problem. By restricting the class of programs considered, we can make this portability feasible. We present Liszt, a domain- specific language for constructing mesh-based PDE solvers. We introduce language statements for interacting with an unstructured mesh, and storing data at its elements. Pro- gram analysis of these statements enables our compiler to expose the parallelism, locality, and synchronization of Liszt programs. Using this analysis, we generate applications for multiple platforms: a cluster, an SMP, and a GPU. This approach allows Liszt applications to perform within 12% of hand-written C++, scale to large clusters, and experience order-of-magnitude speedups on GPUs.","Jacobian matrices,
Face,
Hardware,
Computer architecture,
Synchronization,
Graphics processing unit,
Heating"
Obstacles in Using Frameworks and APIs: An Exploratory Study of Programmers' Newsgroup Discussions,"Large software frameworks and APIs can be hard to learn and use, impeding software productivity. But what are the specific challenges that programmers actually face when using frameworks and APIs in practice? What makes APIs hard to use, and what can be done to alleviate the problems associated with API usability and learnability? To explore these questions, we conducted an exploratory study in which we manually analyzed a set of newsgroup discussions about specific challenges that programmers had about a software framework. Based on this set of data, we identified several categories of obstacles in using APIs. We discussed what could be done to help overcome these obstacles.","Documentation,
Usability,
Tutorials,
Buildings,
Manuals,
Electric breakdown"
Real-Time and Accurate Stereo: A Scalable Approach With Bitwise Fast Voting on CUDA,"This paper proposes a real-time design for accurate stereo matching on compute unified device architecture (CUDA). We present a leading local algorithm and then accelerate it by parallel computing. High matching accuracy is achieved by cost aggregation over shape-adaptive support regions and disparity refinement using reliable initial estimates. A novel sample-and-restore scheme is proposed to make the algorithm scalable, capable of attaining several times speedup at the expense of minor accuracy degradation. The refinement and the restoration are jointly realized by a local voting method. To accelerate the voting on CUDA, a graphics processing unit (GPU)-oriented bitwise fast voting method is proposed, faster than the traditional histogram-based approach with two orders of magnitude. The whole algorithm is parallelized on CUDA at a fine granularity, efficiently exploiting the computing resources of GPUs. Our design is among the fastest stereo matching methods on GPUs. Evaluated in the Middlebury stereo benchmark, the proposed design produces the most accurate results among the real-time methods. The advantages of speed, accuracy, and desirable scalability advocate our design for practical applications such as robotics systems and multiview teleconferencing.",
Photoplethysmography detection by smartphone's videocamera,Smartphone's video cameras become more and more powerful while the devices itself become used by many people. That allows utilizing them for many every-day tasks. One of such suitable application of the widely used smartphones is monitoring the state of the health. In this paper we propose an approach to detect the photoplethysmograph signal from the fingertip using a smartphone's camera and built-in LED. The proposed solution allows detecting the proper heart rate and is robust to different situations of wrong-usage of the system.,"Smart phones,
Cameras,
Monitoring,
Fingers,
Biomedical monitoring,
Blood pressure,
Color"
Robust Automatic Rodent Brain Extraction Using 3-D Pulse-Coupled Neural Networks (PCNN),"Brain extraction is an important preprocessing step for further processing (e.g., registration and morphometric analysis) of brain MRI data. Due to the operator-dependent and time-consuming nature of manual extraction, automated or semi-automated methods are essential for large-scale studies. Automatic methods are widely available for human brain imaging, but they are not optimized for rodent brains and hence may not perform well. To date, little work has been done on rodent brain extraction. We present an extended pulse-coupled neural network algorithm that operates in 3-D on the entire image volume. We evaluated its performance under varying SNR and resolution and tested this method against the brain-surface extractor (BSE) and a level-set algorithm proposed for mouse brain. The results show that this method outperforms existing methods and is robust under low SNR and with partial volume effects at lower resolutions. Together with the advantage of minimal user intervention, this method will facilitate automatic processing of large-scale rodent brain studies.","Three dimensional displays,
Signal to noise ratio,
Indexes,
Rodents,
Solid modeling,
Brain models"
Low-Energy X-ray and Ozone-Exposure Induced Defect Formation in Graphene Materials and Devices,"We have evaluated the responses of graphene materials and devices to 10-keV X-ray irradiation and ozone exposure. Large positive shifts are observed in the current-voltage characteristics of graphene-on- SiO2 transistors irradiated under negative gate bias. Moreover, significant radiation-induced increases are found in the resistance of suspended graphene layers; the charge neutral point (CNP) of the graphene layer also shifts positively with increasing total dose. Raman spectroscopy shows that similar defects are generated in graphene-on-SiO2 sheets by 10-keV X-ray irradiation and ozone exposure. First principles calculations of the relevant binding energies, and reaction and diffusion barriers for oxygen on graphene, strongly suggest that oxygen adsorption and reactions, along with the resulting p -type doping, can lead to the observed degradation of irradiated or ozone-exposed graphene materials and devices.","Radiation effects,
Transistors,
Raman scattering,
Annealing,
Logic gates,
Ionizing radiation,
Doping"
Contour Code: Robust and efficient multispectral palmprint encoding for human recognition,"We propose `Contour Code', a novel representation and binary hash table encoding for multispectral palmprint recognition. We first present a reliable technique for the extraction of a region of interest (ROI) from palm images acquired with non-contact sensors. The Contour Code representation is then derived from the Nonsubsampled Contourlet Transform. A uniscale pyramidal filter is convolved with the ROI followed by the application of a directional filter bank. The dominant directional subband establishes the orientation at each pixel and the index corresponding to this subband is encoded in the Contour Code representation. Unlike existing representations which extract orientation features directly from the palm images, the Contour Code uses a two stage filtering to extract robust orientation features. The Contour Code is binarized into an efficient hash table structure that only requires indexing and summation operations for simultaneous one-to-many matching with an embedded score level fusion of multiple bands. We quantitatively evaluate the accuracy of the ROI extraction by comparison with a manually produced ground truth. Multispectral palmprint verification results on the PolyU and CASIA databases show that the Contour Code achieves an EER reduction upto 50%, compared to state-of-the-art methods.","Feature extraction,
Databases,
Veins,
Robustness,
Encoding,
Vectors,
Image recognition"
Learning discriminative local binary patterns for face recognition,"Histograms of Local Binary Patterns (LBPs) and variations thereof are a popular local visual descriptor for face recognition. So far, most variations of LBP are designed by hand or are learned with non-supervised methods. In this work we propose a simple method to learn discriminative LBPs in a supervised manner. The method represents an LBP-like descriptor as a set of pixel comparisons within a neighborhood and heuristically seeks for a set of pixel comparisons so as to maximize a Fisher separability criterion for the resulting histograms. Tests on standard face recognition datasets show that this method can create compact yet discriminative descriptors.",
Stacked Spirals for Biosensor Telemetry,"This paper presents an inductive power transmission coil for biosensor-based telemetric implants. Using stacked spirals reduces the consumed space and the self-resonant frequency (SRF) of the spiral and the required power transmission frequency for the implanted device. A four-layer 15 mm × 15 mm spiral coil of seven turns is simulated in CST Microwave Studio (TM), constructed and tested in hardware with comparable results. Measurements also include the receipt of power inductively from an energized array of spirals powered by a Class-E transmitter at 27 MHz, and rectified to 1 V for biosensor applications.",
Causality Analysis of Neural Connectivity: Critical Examination of Existing Methods and Advances of New Methods,"Granger causality (GC) is one of the most popular measures to reveal causality influence of time series and has been widely applied in economics and neuroscience. Especially, its counterpart in frequency domain, spectral GC, as well as other Granger-like causality measures have recently been applied to study causal interactions between brain areas in different frequency ranges during cognitive and perceptual tasks. In this paper, we show that: 1) GC in time domain cannot correctly determine how strongly one time series influences the other when there is directional causality between two time series, and 2) spectral GC and other Granger-like causality measures have inherent shortcomings and/or limitations because of the use of the transfer function (or its inverse matrix) and partial information of the linear regression model. On the other hand, we propose two novel causality measures (in time and frequency domains) for the linear regression model, called new causality and new spectral causality, respectively, which are more reasonable and understandable than GC or Granger-like measures. Especially, from one simple example, we point out that, in time domain, both new causality and GC adopt the concept of proportion, but they are defined on two different equations where one equation (for GC) is only part of the other (for new causality), thus the new causality is a natural extension of GC and has a sound conceptual/theoretical basis, and GC is not the desired causal influence at all. By several examples, we confirm that new causality measures have distinct advantages over GC or Granger-like measures. Finally, we conduct event-related potential causality analysis for a subject with intracranial depth electrodes undergoing evaluation for epilepsy surgery, and show that, in the frequency domain, all measures reveal significant directional event-related causality, but the result from new spectral causality is consistent with event-related time-frequency power spectrum activity. The spectral GC as well as other Granger-like measures are shown to generate misleading results. The proposed new causality measures may have wide potential applications in economics and neuroscience.",
The Tofu Interconnect,"The Tofu interconnect was developed by Fujitsu as a national project of MEXT. The goal of the project is to develop one of the world's most powerful general purpose supercomputer systems and grand challenge applications, and to build a core research hub for computational science. The Tofu interconnect provides the scalability to implement the 10 petaFLOPS 'K computer' system which has more than 80,000 nodes. The network topology is a 6D mesh/torus. Quad network interfaces provide high throughput. The barrier interface is dedicated to offloading collective communications. This paper describes the Tofu interconnect architecture, the Tofu network router, the Tofu network interface, and the Tofu barrier interface, and also presents preliminary evaluation results.","Throughput,
Registers,
Benchmark testing,
Routing,
Aerospace electronics,
Network topology,
Three dimensional displays"
DRESS codes for the storage cloud: Simple randomized constructions,"We introduce an efficient family of exact regenerating codes for data storage in large-scale distributed systems. We refer to these new codes as Distributed Replication-based Exact Simple Storage (DRESS) codes. A key property of DRESS codes is their very efficient distributed and uncoded repair and growth processes that have minimum bandwidth, reads and computational overheads. This property is essential for large-scale systems with high reliability and availability requirements. DRESS codes will first encode the file using a Maximum Distance Separable (MDS) code, then place multiple replicas of the coded packets on different nodes in the system. We propose a simple and flexible randomized scheme for placing those replicas based on the balls-and-bins model. Our construction showcases the power of the probabilistic approach in constructing regenerating codes that can be efficiently repaired and grown.","Maintenance engineering,
Silicon,
Color,
Bandwidth,
Decision support systems,
Peer to peer computing,
Availability"
Analysis of TSV-to-TSV coupling with high-impedance termination in 3D ICs,"It is widely-known that coupling exists between adjacent through-silicon vias (TSVs) in 3D ICs. Since this TSV-to-TSV coupling is not negligible, it is highly likely that TSV-to-TSV coupling affects crosstalk significantly. Although a few works have already analyzed coupling in 3D ICs, they used S-parameter-based methods under the assumption that all ports in their simulation structures are under 50-Ω termination condition. However, this 50-Ω termination condition does not occur at ports (pins) of gates inside a 3D IC. In this paper, therefore, we analyze TSV-to-TSV coupling in 3D ICs based on a lumped circuit model with a realistic high-impedance termination condition. We also analyze how channel affect TSV-to-TSV coupling differently in different frequency ranges. Based on our results, we propose a technique to reduce TSV-to-TSV coupling in 3D ICs.","Couplings,
Impedance,
Through-silicon vias,
Three dimensional displays,
Capacitance,
Integrated circuit modeling,
Crosstalk"
Approximate Nearest Subspace Search,"Subspaces offer convenient means of representing information in many pattern recognition, machine vision, and statistical learning applications. Contrary to the growing popularity of subspace representations, the problem of efficiently searching through large subspace databases has received little attention in the past. In this paper, we present a general solution to the problem of Approximate Nearest Subspace search. Our solution uniformly handles cases where the queries are points or subspaces, where query and database elements differ in dimensionality, and where the database contains subspaces of different dimensions. To this end, we present a simple mapping from subspaces to points, thus reducing the problem to the well-studied Approximate Nearest Neighbor problem on points. We provide theoretical proofs of correctness and error bounds of our construction and demonstrate its capabilities on synthetic and real data. Our experiments indicate that an approximate nearest subspace can be located significantly faster than the nearest subspace, with little loss of accuracy.",
An Optimal Transportation Approach for Nuclear Structure-Based Pathology,"Nuclear morphology and structure as visualized from histopathology microscopy images can yield important diagnostic clues in some benign and malignant tissue lesions. Precise quantitative information about nuclear structure and morphology, however, is currently not available for many diagnostic challenges. This is due, in part, to the lack of methods to quantify these differences from image data. We describe a method to characterize and contrast the distribution of nuclear structure in different tissue classes (normal, benign, cancer, etc.). The approach is based on quantifying chromatin morphology in different groups of cells using the optimal transportation (Kantorovich-Wasserstein) metric in combination with the Fisher discriminant analysis and multidimensional scaling techniques. We show that the optimal transportation metric is able to measure relevant biological information as it enables automatic determination of the class (e.g., normal versus cancer) of a set of nuclei. We show that the classification accuracies obtained using this metric are, on average, as good or better than those obtained utilizing a set of previously described numerical features. We apply our methods to two diagnostic challenges for surgical pathology: one in the liver and one in the thyroid. Results automatically computed using this technique show potentially biologically relevant differences in nuclear structure in liver and thyroid cancers.","Cancer,
Image segmentation,
Liver,
Measurement,
Transportation,
Pixel,
Lesions"
GaN Single-Polarity Power Supply Bootstrapped Comparator for High-Temperature Electronics,"A high-performance bootstrapped comparator operating with a single-polarity power supply is demonstrated for GaN high-temperature electronics applications. The comparator features monolithically integrated enhancement-mode (E-mode) and depletion-mode (D-mode) AlGaN/GaN HEMTs. The tail current source uses an E-mode HEMT, enabling single-polarity power supply. The E-mode input stage could cover a wide voltage comparison range (from 1 to 6 V) while the bootstrapped loads are implemented with D-mode HEMTs. At room temperature, the comparator delivers a voltage gain as high as 79 V/V and a unity-gain bandwidth of 206 MHz. At 250 , a maximum voltage gain of 40 V/V and a unity-gain bandwidth of 84 MHz are obtained.","Gallium nitride,
MODFETs,
HEMTs,
Aluminum gallium nitride,
Temperature measurement,
Gain,
Bandwidth"
An Extended Grammar System for Learning and Recognizing Complex Visual Events,"For a grammar-based approach to the recognition of visual events, there are two major limitations that prevent it from real application. One is that the event rules are predefined by domain experts, which means huge manual cost. The other is that the commonly used grammar can only handle sequential relations between subevents, which is inadequate to recognize more complex events involving parallel subevents. To solve these problems, we propose an extended grammar approach to modeling and recognizing complex visual events. First, motion trajectories as original features are transformed into a set of basic motion patterns of a single moving object, namely, primitives (terminals) in the grammar system. Then, a Minimum Description Length (MDL) based rule induction algorithm is performed to discover the hidden temporal structures in primitive stream, where Stochastic Context-Free Grammar (SCFG) is extended by Allen's temporal logic to model the complex temporal relations between subevents. Finally, a Multithread Parsing (MTP) algorithm is adopted to recognize interesting complex events in a given primitive stream, where a Viterbi-like error recovery strategy is also proposed to handle large-scale errors, e.g., insertion and deletion errors. Extensive experiments, including gymnastic exercises, traffic light events, and multi-agent interactions, have been executed to validate the effectiveness of the proposed approach.","Stochastic processes,
Pattern recognition,
Costs,
Computer errors,
Vehicles,
Automation,
Logic,
Context modeling,
Large-scale systems,
Traffic control"
A discriminative key pose sequence model for recognizing human interactions,"In this paper we develop a model for recognizing human interactions - activity recognition with multiple actors. An activity is modeled with a sequence of key poses, important atomic-level actions performed by the actors. Spatial arrangements between the actors are included in the model, as is a strict temporal ordering of the key poses. An exemplar representation is used to model the variability in the instantiation of key poses. Quantitative results that form a new state-of-the-art on the benchmark UT-Interaction dataset are presented, along with results on a subset of the TRECVID dataset.","Trajectory,
Hidden Markov models,
Humans,
Computational modeling,
Training,
Video sequences,
Probabilistic logic"
Phase Synchronization Motion and Neural Coding in Dynamic Transmission of Neural Information,"In order to explore the dynamic characteristics of neural coding in the transmission of neural information in the brain, a model of neural network consisting of three neuronal populations is proposed in this paper using the theory of stochastic phase dynamics. Based on the model established, the neural phase synchronization motion and neural coding under spontaneous activity and stimulation are examined, for the case of varying network structure. Our analysis shows that, under the condition of spontaneous activity, the characteristics of phase neural coding are unrelated to the number of neurons participated in neural firing within the neuronal populations. The result of numerical simulation supports the existence of sparse coding within the brain, and verifies the crucial importance of the magnitudes of the coupling coefficients in neural information processing as well as the completely different information processing capability of neural information transmission in both serial and parallel couplings. The result also testifies that under external stimulation, the bigger the number of neurons in a neuronal population, the more the stimulation influences the phase synchronization motion and neural coding evolution in other neuronal populations. We verify numerically the experimental result in neurobiology that the reduction of the coupling coefficient between neuronal populations implies the enhancement of lateral inhibition function in neural networks, with the enhancement equivalent to depressing neuronal excitability threshold. Thus, the neuronal populations tend to have a stronger reaction under the same stimulation, and more neurons get excited, leading to more neurons participating in neural coding and phase synchronization motion.","Couplings,
Encoding,
Oscillators,
Neurons,
Synchronization,
Artificial neural networks,
Biological neural networks"
Energy-Efficient and Bandwidth-Reconfigurable Photonic Networks for High-Performance Computing (HPC) Systems,"Optical interconnects are becoming ubiquitous for short-range communication within boards and racks due to higher communication bandwidth at lower power dissipation when compared to metallic interconnects. Efficient multiplexing techniques (wavelengths, time, and space) allow bandwidths to scale; static or predetermined resource allocation of wavelengths can be detrimental to network performance for nonuniform (adversial) workloads. Dynamic bandwidth reallocation (DBR) based on actual traffic pattern can lead to improved network performance by utilizing idle resources. While DBR techniques can alleviate interconnection bottlenecks, power consumption also increases considerably with increase in bit rate and channels. In this paper, we propose to improve the performance of optical interconnects using DBR techniques and simultaneously optimize the power consumption using dynamic power management (DPM) techniques. DBR reallocates idle channels to busy channels (wavelengths) for improving throughput, and DPM regulates the bit rates and supply voltages for the individual channels. A reconfigurable optoelectronic architecture and a performance adaptive algorithm for implementing DBR and DPM are proposed in this paper. Our proposed reconfiguration algorithm achieves a significant reduction in power consumption and considerable improvement in throughput, with a marginal increase in latency for synthetic and real (Splash-2) traffic traces.",
Identifying Image Composites Through Shadow Matte Consistency,"In this paper, we propose a framework for detecting tampered digital images based on photometric consistency of illumination in shadows. In particular, we formulate color characteristics of shadows measured by the shadow matte value. The shadow boundaries and the penumbra shadow region in an image are first extracted. Then a simple and efficient method is used to estimate shadow matte values of shadows. Our approach efficiently extracts these constraints from a single view of a target scene and makes use of them for the digital forgery detection. Experimental results on both simulated photos and visually plausible real images demonstrate the effectiveness of the proposed method.","Pixel,
Lighting,
Surface reconstruction,
Light sources,
Forgery,
Casting,
Image color analysis"
ODVBA: Optimally-Discriminative Voxel-Based Analysis,"Gaussian smoothing of images prior to applying voxel-based statistics is an important step in voxel-based analysis and statistical parametric mapping (VBA-SPM) and is used to account for registration errors, to Gaussianize the data and to integrate imaging signals from a region around each voxel. However, it has also become a limitation of VBA-SPM based methods, since it is often chosen empirically and lacks spatial adaptivity to the shape and spatial extent of the region of interest, such as a region of atrophy or functional activity. In this paper, we propose a new framework, named optimally-discriminative voxel-based analysis (ODVBA), for determining the optimal spatially adaptive smoothing of images, followed by applying voxel-based group analysis. In ODVBA, nonnegative discriminative projection is applied regionally to get the direction that best discriminates between two groups, e.g., patients and controls; this direction is equivalent to local filtering by an optimal kernel whose coefficients define the optimally discriminative direction. By considering all the neighborhoods that contain a given voxel, we then compose this information to produce the statistic for each voxel. Finally, permutation tests are used to obtain a statistical parametric map of group differences. ODVBA has been evaluated using simulated data in which the ground truth is known and with data from an Alzheimer's disease (AD) study. The experimental results have shown that the proposed ODVBA can precisely describe the shape and location of structural abnormality.","Smoothing methods,
Kernel,
Shape,
Government,
Alzheimer's disease,
Accuracy,
Imaging"
An Effective 16-bit Random Number Aided Query Tree Algorithm for RFID Tag Anti-Collision,"A tag-collision problem (or missed reads) in RFID system is the event that a reader cannot identify the tag if many tags respond to a reader at the same time. Recently, Choi et al. proposed a 16-bit random number query tree algorithm (RN16QTA) for RFID tag anti-collision by using a RN16 as the tags temporary ID. RN16QTA successfully reduce the time consumption for tag identification than the present identification implemented in EPC Class 1 Gen. 2. However, simulation results and the theoretical estimation imply that the length of RN16 is actually not enough in real environments to successfully identify tags. In this letter, we propose an effective RN16QTA (ERN16QTA) to really solve the tag collision in tags identification. Moreover, our new algorithm saves the responded bits.",
A QoE-Oriented Strategy for OFDMA Radio Resource Allocation Based on Min-MOS Maximization,"A balanced strategy for OFDMA radio resource allocation based on game theory concepts is presented. Its main novelty with respect to state-of-the-art methods is that resource allocation is based on application-oriented Mean Opinion Score (MOS), rather than the aggregate system data rate. Thus, users' data flows cooperate in a proactive way in order to jointly maximize the Quality of Experience (QoE). Experimental results show that the MOS achievable by the proposed resource allocation strategy is higher than the one provided by uncoordinated strategies based on water-filling and cooperative strategies based on pure data rate maximization.","Resource management,
Signal to noise ratio,
Games,
OFDM,
Quality of service,
Indexes,
Delay"
Avoiding hot-spots on two-level direct networks,"A low-diameter, fast interconnection network is going to be a prerequisite for building exascale machines. A two-level direct network has been proposed by several groups as a scalable design for future machines. IBM's PERCS topology and the dragonfly net-work discussed in the DARPA exascale hardware study are examples of this design. The presence of multiple levels in this design leads to hot-spots on a few links when processes are grouped together at the lowest level to minimize total communication volume. This is especially true for communication graphs with a small number of neighbors per task. Routing and mapping choices can impact the communication performance of parallel applications running on a machine with a two-level direct topology. This paper explores intelligent topology aware mappings of different communication patterns to the physical topology to identify cases that minimize link utilization. We also analyze the trade-offs between using direct and indirect routing with different mappings. We use simulations to study communication and overall performance of applications since there are no installations of two-level direct networks yet. This study raises interesting issues regarding the choice of job scheduling, routing and mapping for future machines.","Topology,
Routing,
Network topology,
Bandwidth,
Computational modeling,
Predictive models,
Arrays"
HWRFx: Improving Hurricane Forecasts with High-Resolution Modeling,"Using the hurricane weather research and forecasting experimental modeling system (HWRFx), researchers examined the impact of increased model resolution on system performance in forecasting a select sample of tropical cyclones from the 2005 and 2007 hurricane seasons.","Atmospheric modeling,
Hurricanes,
Predictive models,
Computational modeling,
Weather forecasting"
Accelerating Regular LDPC Code Decoders on GPUs,"Modern active and passive satellite and airborne sensors with higher temporal, spectral and spatial resolutions for Earth remote sensing result in a significant increase in data volume. This poses a challenge for data transmission over error-prone wireless links to a ground receiving station. Low-density parity-check (LDPC) codes have been adopted in modern communication systems for robust error correction. Demands for LDPC decoders at a ground receiving station for efficient and flexible data communication links have inspired the usage of a cost-effective high-performance computing device. In this paper we propose a graphic-processing-unit (GPU)-based regular LDPC decoders with the log sum-product iterative decoding algorithm (log-SPA). The GPU code was written to run NVIDIA GPUs using the compute unified device architecture (CUDA) language with a novel implementation of asynchronous data transfer for LDPC decoding. Experimental results showed that the proposed GPU-based high-throughput regular LDPC decoder achieved a significant 271x speedup compared to its CPU-based single-threaded counterpart written in the C language.",
Artificial Societies and GPU-Based Cloud Computing for Intelligent Transportation Management,"The article focuses on the C part of the ACP approach. The ACP approach comprises of artificial societies, computational experiments, and parallel execution of real and artificial systems. It explains the advantages of cloud computing and GPUs and presents the architectures of GPU-based cloud computing for transportation systems.","Graphics processing unit,
Cloud computing,
Instruction sets,
Computational modeling,
Mathematical model,
Land transportation,
Intelligent transportation systems"
Massively parallelizing the RRT and the RRT,"In recent years, the growth of the computational power available in the Central Processing Units (CPUs) of consumer computers has tapered significantly. At the same time, growth in the computational power available in the Graphics Processing Units (GPUs) has remained strong. Algorithms that can be implemented on GPUs today are not only limited to graphics processing, but include scientific computation and beyond. This paper is concerned with massively parallel implementations of incremental sampling-based robot motion planning algorithms, namely the widely-used Rapidly-exploring Random Tree (RRT) algorithm and its asymptotically-optimal counterpart called RRT*. We demonstrate an example implementation of RRT and RRT* motion-planning algorithm for a high-dimensional robotic manipulator that takes advantage of an NVidia CUDA-enabled GPU. We focus on parallelizing the collision-checking procedure, which is generally recognized as the computationally expensive component of sampling-based motion planning algorithms. Our experimental results indicate significant speedup when compared to CPU implementations, leading to practical algorithms for optimal motion planning in high-dimensional configuration spaces.","Manipulators,
Kernel,
Planning,
Graphics processing unit,
Instruction sets,
Trajectory"
Learning occlusion with likelihoods for visual tracking,"We propose a novel algorithm to detect occlusion for visual tracking through learning with observation likelihoods. In our technique, target is divided into regular grid cells and the state of occlusion is determined for each cell using a classifier. Each cell in the target is associated with many small patches, and the patch likelihoods observed during tracking construct a feature vector, which is used for classification. Since the occlusion is learned with patch likelihoods instead of patches themselves, the classifier is universally applicable to any videos or objects for occlusion reasoning. Our occlusion detection algorithm has decent performance in accuracy, which is sufficient to improve tracking performance significantly. The proposed algorithm can be combined with many generic tracking methods, and we adopt L1 minimization tracker to test the performance of our framework. The advantage of our algorithm is supported by quantitative and qualitative evaluation, and successful tracking and occlusion reasoning results are illustrated in many challenging video sequences.","Target tracking,
Cognition,
Vectors,
Training,
Minimization,
Videos"
A Reservation-based Smart Parking System,"Finding a parking space in most metropolitan areas, especially during the rush hours, is difficult for drivers. The difficulty arises from not knowing where the available spaces may be at that time; even if known, many vehicles may pursue very limited parking spaces to cause serious traffic congestion. In this paper, we design and implement a prototype of Reservation-based Smart Parking System (RSPS) that allows drivers to effectively find and reserve the vacant parking spaces. By periodically learning the parking status from the sensor networks deployed in parking lots, the reservation service is affected by the change of physical parking status. The drivers are allowed to access this cyber-physical system with their personal communication devices. Furthermore, we study state-of-the-art parking policies in smart parking systems and compare their performance. The experiment results show that the proposed reservation-based parking policy has the potential to simplify the operations of parking systems, as well as alleviate traffic congestion caused by parking searching.","Driver circuits,
Databases,
IEEE 802.11 Standards,
Availability,
Sensors,
Monitoring,
Synchronization"
A Dynamic Social Feedback System to Support Learning and Social Interaction in Higher Education,"In this research, we examine the design, construction, and implementation of a dynamic, easy to use, feedback mechanism for social software. The tool was integrated into an existing university's online learning community (OLC). In line with constructivist learning models and practical information systems (IS) design, the feedback system provides members of the OLC with the capability to rate blog posts and provide instant feedback on the content of their peers. The software was implemented at a US university in an introductory course on IS with the goal of fostering higher levels of learning and social interaction. A content analysis showed higher levels of system usage corresponded with higher course grades. A survey analysis supported these results showing statistical significance between levels of system use and perceived levels of learning.","Software design,
Blogs,
Feedback,
Social network services,
Internet,
Education,
Learning systems"
Analysis on the Collaboration Between Global Search and Local Search in Memetic Computation,"The synergy between exploration and exploitation has been a prominent issue in optimization. The rise of memetic algorithms, a category of optimization techniques which feature the explicit exploration-exploitation coordination, much accentuates this issue. While memetic algorithms have achieved remarkable success in a wide range of real-world applications, the key to successful exploration-exploitation synergies still remains obscure as conclusions drawn from empirical results or theoretical derivations are usually quite algorithm specific and/or problem dependent. This paper aims to provide a theoretical model that can depict the collaboration between global search and local search in memetic computation on a broad class of objective functions. In the proposed model, the interaction between global search and local search creates a set of local search zones, in which the global optimal points reside, within the search space. Based on such a concept, the quasi-basin class (QBC) which categorizes problems according to the distribution of their local search zones is adopted. The subthreshold seeker, taken as a representative archetype of memetic algorithms, is analyzed on various QBCs to develop a general model for memetic algorithms. As the proposed model not only well describes the expected time for a simple memetic algorithm to find the optimal point on different QBCs but also consists with the observations made in previous studies in the literature, the proposed model may reveal important insights to the design of memetic algorithms in general.",
Two-Stage Monte Carlo Tree Search for Connect6,"Recently, Monte Carlo tree search (MCTS) has become a well-known game search method, and has been successfully applied to many games. This method performs well in solving search trees with numerous branches, such as Go, Havannah, etc. Connect6 is a game involving a search tree with numerous branches, and it is also one of the sudden-death games. This paper thus proposes a new MCTS variant related to Connect6, called two-stage MCTS. The first stage focuses on threat space search (TSS), which is designed to solve the sudden-death problem. For the double-threat TSS in Connect6, this study proposes an algorithm called iterative threat space search (ITSS) which combines normal TSS with conservative threat space search (CTSS). The second stage uses MCTS to estimate the game-theoretic value of the initial position. This stage aims at finding the most promising move. The experimental result shows that two-stage MCTS is considerably more efficient than traditional MCTS on those positions with TSS solution in Connect6. Furthermore, according to Connect6 heuristic knowledge, this paper uses relevance-zone search to accelerate identifying winning and losing moves.","Games,
Vegetation,
Search methods,
Law,
Monte Carlo methods,
Iterative algorithm"
Design of Observer-Based H_{\infty} Robust Repetitive-Control System,"This technical note deals with the problem of designing a robust observer-based repetitive-control system that provides a given H∞ disturbance attenuation performance for a class of plants with time-varying structured uncertainties. A continuous-discrete two-dimensional model is built that accurately describes the features of repetitive control, thereby enabling the control and learning actions to be preferentially adjusted. A sufficient condition for the repetitive-control system to have a disturbance-attenuation bound in the H∞ setting is given in terms of a linear matrix inequality (LMI). It yields the parameters of the repetitive controller and the state observer. Finally, a numerical example demonstrates the effectiveness of the method, whose main advantage is the easy, preferential adjustment of control and learning through the tuning of two parameters in the LMI-based condition.","Attenuation,
Robustness,
Observers,
Iron,
Uncertainty,
Tuning,
Symmetric matrices"
Randomized Sensor Selection in Sequential Hypothesis Testing,"We consider the problem of sensor selection for time-optimal detection of a hypothesis. We consider a group of sensors transmitting their observations to a fusion center. The fusion center considers the output of only one randomly chosen sensor at the time, and performs a sequential hypothesis test. We study a sequential multiple hypothesis test with randomized sensor selection strategy. We incorporate the random processing times of the sensors to determine the asymptotic performance characteristics of this test. For three distinct performance metrics, we show that, for a generic set of sensors and binary hypothesis, the time-optimal policy requires the fusion center to consider at most two sensors. We also show that for the case of multiple hypothesis, the time-optimal policy needs at most as many sensors to be observed as the number of underlying hypotheses.","Testing,
Decision making,
Minimization,
Sonar,
Accuracy,
Materials,
Programming"
An Autonomous Framework to Produce and Distribute Personalized Team-Sport Video Summaries: A Basketball Case Study,"Democratic and personalized production of multimedia content is a challenge that content providers will have to face in the near future. In this paper, we address this challenge by building on computer vision tools to automate the collection and distribution of audiovisual content. Especially, we proposed a complete production process of personalized video summaries in a typical application scenario, where the sensor network for media acquisition is composed of multiple cameras, which, for example, cover a basketball field. Distributed analysis and interpretation of the scene are exploited to decide what to show or not to show about the event, so as to produce a video composed of a valuable subset of the streams provided by each individual camera. Interestingly, the selection of the streams subsets to forward to each user depends on his/her individual preferences, making the process adaptive and personalized. The process involves numerous integrated technologies and methodologies, including but not limited to automatic scene analysis, camera viewpoint selection, adaptive streaming, and generation of summaries through automatic organization of stories. The proposed technology provides practical solutions to a wide range of applications, such as personalized access to local sport events through a web portal, cost-effective and fully automated production of content dedicated to small-audience, or even automatic log in of annotations.",
Equalizer Design and Performance Trade-Offs in ADC-Based Serial Links,"This paper investigates the performance benefit of using nonuniformly quantized ADCs for implementing high-speed serial receivers with decision-feedback equalization (DFE). A way of determining an optimal set of ADC thresholds to achieve the minimum bit-error rate (BER) is described, which can yield a very different set from the one that minimizes signal quantization errors. By recognizing that both the loop-unrolling DFE receiver and ADC-based DFE receiver decide each received bit based upon the result of a single slicer, an efficient architecture named reduced-slicer partial-response DFE (RS-PRDFE) receiver is proposed. The RS-PRDFE receiver eliminates redundant or unused slicers from the previous DFE receiver implementations. Both the simulation and measurement results from a 10 Gb/s ADC-based receiver fabricated in 65 nm CMOS technology and multiple backplane channels demonstrate that the RS-PRDFE can achieve the BER of a 3-4-bit uniform ADC only with 4 data slicers. Also, the combined use of linear equalizers (LEs) can further reduce the required slicer count in RS-PRDFE receivers, but only when the LEs are realized in analog domain.",
Statistical Modeling of MIMO Mobile-to-Mobile Underwater Channels,"This paper proposes a geometry-based statistical model for wideband multiple-input-multiple-output (MIMO) mobile-to-mobile (M-to-M) shallow-water acoustic (SWA) multipath fading channels. Based on the reference model, the corresponding MIMO time-frequency correlation function, Doppler power spectral density, and delay cross-power spectral density are derived. These statistics are important tools for the design and performance analysis of MIMO M-to-M SWA communication and sonar systems. Finally, the derived statistics are compared with the experimentally obtained channel statistics, and close agreement is observed.","MIMO,
Transducers,
Correlation,
Sea surface,
Wideband,
Acoustics,
Time frequency analysis"
On-body device localization for health and medical monitoring applications,"We present a technique to discover the position of sensors on the human body. Automatic on-body device localization ensures correctness and accuracy of measurements in health and medical monitoring systems. In addition, it provides opportunities to improve the performance and usability of ubiquitous devices. Our technique uses accelerometers to capture motion data to estimate the location of the device on the user's body, using mixed supervised and unsupervised time series analysis methods. We have evaluated our technique with extensive experiments on 25 subjects. On average, our technique achieves 89% accuracy in estimating the location of devices on the body.",
Multi-label learning with incomplete class assignments,"We consider a special type of multi-label learning where class assignments of training examples are incomplete. As an example, an instance whose true class assignment is (c1, c2, c3) is only assigned to class c1 when it is used as a training sample. We refer to this problem as multi-label learning with incomplete class assignment. Incompletely labeled data is frequently encountered when the number of classes is very large (hundreds as in MIR Flickr dataset) or when there is a large ambiguity between classes (e.g., jet vs plane). In both cases, it is difficult for users to provide complete class assignments for objects. We propose a ranking based multi-label learning framework that explicitly addresses the challenge of learning from incompletely labeled data by exploiting the group lasso technique to combine the ranking errors. We present a learning algorithm that is empirically shown to be efficient for solving the related optimization problem. Our empirical study shows that the proposed framework is more effective than the state-of-the-art algorithms for multi-label learning in dealing with incompletely labeled data.",
Design of a one million neuron single FPGA neuromorphic system for real-time multimodal scene analysis,"In this paper, we present an architecture and corresponding analysis for large-scale neuromorphic systems using a digital approach where neurons are abstracted as arithmetic logic units and communication processors. After presenting the architecture, we establish a few basic architectural principles, particularly the scaling of the system to large arrays. We demonstrate the reality of a single chip million neuron system built from these principles in commercial off the shelf FPGA.",
Mapping Multi-Domain Applications Onto Coarse-Grained Reconfigurable Architectures,"Coarse-grained reconfigurable architectures (CGRAs) have drawn increasing attention due to their performance and flexibility. However, their applications have been restricted to domains based on integer arithmetic since typical CGRAs support only integer arithmetic or logical operations. This paper introduces approaches to mapping applications onto CGRAs supporting both integer and floating-point arithmetic. After presenting an optimal formulation using integer linear programming, we present a fast heuristic mapping algorithm. Our experiments on randomly generated examples generate optimal mapping results using our heuristic algorithm for 97% of the examples within a few seconds. We observe similar results for practical examples from multimedia and 3-D graphics benchmarks. The applications mapped on a CGRA show up to 120 times performance improvement compared to software implementations, demonstrating the potential for application acceleration on CGRAs supporting floating-point operations.",
Fuzzy keyword search on encrypted cloud storage data with small index,"To ensure that the data can be stored in the cloud securely, people encrypt their data before outsourcing to the cloud, which makes searching on a large amount of encrypted data become a demanding task. Traditional searchable encryption schemes provide a range of approaches to search on encrypted data, but they only support exact keyword search. Exact keyword search is not suitable for cloud storage systems, because it doesn't allow users making any spelling errors or format inconsistencies, which greatly reduce the system usability. To the best of our knowledge, the relatively most feasible scheme published so far which supports fuzzy keyword search is the “Wildcard-based Fuzzy Set Construction” (INFOCOM 2010), in which each keyword is corresponding with O(ld) fuzzy keywords when the keyword length is l and the edit distance is d. In this paper we present the “Dictionary-based Fuzzy Set Construction”, in which each keyword is corresponding with much less fuzzy keywords. This improvement greatly reduces the index size, thereby reducing the storage and communication overheads. The experiment results show that when the number of keywords is 104, the index size ratio between ours and theirs is 1:3.4(d = 1) and 1: 20.4(d = 2).",
EMI Analysis and Evaluation of an Improved ZCT Flyback Converter,"Switching power supplies are sources of noise for sensitive circuits. Converters should comply with electromagnetic compatibility (EMC) rules so that the electromagnetic interference (EMI) caused by switching cannot interfere with the normal operation of adjacent circuits and also the converter itself. The produced interference can be in the form of conduction or radiation. In this paper, some techniques are used in switching converters to suppress EMI with emphasis on the conduction form. EMI analysis and evaluation of a conventional flyback converter and a proposed zero-current transition (ZCT) flyback converter is achieved by simulation and experimental results. In addition to evaluating some EMI suppression techniques, the main objective of this paper is to improve EMI in the topology design stage. The operating modes of the improved ZCT flyback are discussed. In addition to the efficiency improvement, the amount of EMI reduction of this ZCT flyback and the effectiveness of some EMI reduction techniques are shown by practical implementation.","Electromagnetic interference,
Converters,
Switches,
Electromagnetic compatibility,
Topology,
Inductance,
Switching circuits"
Robust Linear Transceiver Design in MIMO Ad Hoc Cognitive Radio Networks with Imperfect Channel State Information,"The joint linear transceiver design for Multiple-Input Multiple-Output (MIMO) \adhoc cognitive radio networks when the channel state information (CSI) is uncertain is discussed in this paper. The uncertainty in CSI is modeled using Stochastic Error (SE) and Norm Bounded Error (NBE) models. The Sum-Mean Square Error (SMSE) performance is used to formulate the design problem. To optimize the network, the transmit power budget for secondary user transmitters and the maximum allowed interference at primary user receivers are constrained. In the design methodology, the network parameters are optimized to best serve the users when the worst possible channel realizations occur. It is shown that for the SE model of uncertainty, this problem can be cast as a Second Order Cone Problem (SOCP), while for the NBE model, the problem becomes a Semi-Definite Program (SDP). These two problems are solved efficiently using the numerical solver packages YALMIP and SDPT3. Finally simulation results are presented to evaluate the performance of the proposed methods.",
Ferrite LTCC-Based Antennas for Tunable SoP Applications,"For the first time, ferrite low temperature co-fired ceramic (LTCC) tunable antennas are presented. These antennas are frequency tuned by a variable magnetostatic field produced in a winding that is completely embedded inside the ferrite LTCC substrate. Embedded windings have reduced the typically required magnetic bias field for antenna tuning by over 95%. The fact that large electromagnets are not required for tuning makes ferrite LTCC with embedded bias windings an ideal platform for advanced tunable system-on-package applications. Measurements of rectangular microstrip patch antennas on a ferrite LTCC substrate display a maximum tuning range of 610 MHz near 12 GHz. Two different bias windings and their effect on the antenna performance are discussed, as is the effect of antenna orientation with respect to the bias winding. The antenna radiation patterns are measured under biased and unbiased conditions, showing a stable co-polarized linear gain.",
TCP-FIT: An improved TCP congestion control algorithm and its performance,"The Transport Control Protocol (TCP) has been widely used by wired and wireless Internet applications such as FTP, email and HTTP. Numerous congestion algorithms have been proposed to improve the performance of TCP in various scenarios, especially for high bandwidth-delay product (BDP) and wireless networks. Although different algorithms may achieve different performance improvements under different network conditions, designing a congestion algorithm that performs well across a wide spectrum of network conditions remains a great challenge. In this paper, we propose a novel congestion control algorithm, named TCP-FIT, which could perform gracefully in both wireless and high BDP networks. The algorithm was inspired by parallel TCP, but with the important distinctions that only one TCP connection with one congestion window is established for each TCP session, and that no modifications to other layers (e.g. the application layer) of the end-to-end system need to be made. Extensive experimental results obtained using both network simulators as well as over “live” wired line, WiFi and 3G networks at different geographical locations and at different times of the day are presented. The performance of the algorithm shown in the experiment results is significantly improved as compared to other state-of-the-art algorithms, while maintaining good fairness.",
Algebraic Algorithms for Vector Network Coding,"We develop new algebraic algorithms for scalar and vector network coding. In vector network coding, the source multicasts information by transmitting vectors of length L, while intermediate nodes process and combine their incoming packets by multiplying them with L × L coding matrices that play a similar role as coding coefficients in scalar coding. We start our work by extending the algebraic framework developed for multicasting over graphs by Koetter and Medard to include operations over matrices; we build on this generalized framework, to provide a new approach for both scalar and vector code design which attempts to minimize the employed field size and employed vector length, while selecting the coding operations. Our algorithms also lead as a special case to network code designs that employ structured matrices.","Encoding,
Polynomials,
Network coding,
Receivers,
Algorithm design and analysis,
Vectors"
Error-correcting schemes with dynamic thresholds in nonvolatile memories,"Predetermined fixed thresholds are commonly used in nonvolatile memories for reading binary sequences, but they usually result in significant asymmetric errors after a long duration, due to voltage or resistance drift. This motivates us to construct error-correcting schemes with dynamic reading thresholds, so that the asymmetric component of errors are minimized. In this paper, we discuss how to select dynamic reading thresholds without knowing cell level distributions, and present several error-correcting schemes. Analysis based on Gaussian noise models reveals that bit error probabilities can be significantly reduced by using dynamic thresholds instead of fixed thresholds, hence leading to a higher information rate.","Nonvolatile memory,
Decoding,
Bit error rate,
Error correction codes,
Reliability,
Ash,
Threshold voltage"
Fuzzy classification by evolutionary algorithms,Fuzzy sets and fuzzy logic can be used for efficient data classification by fuzzy rules and fuzzy classifiers. This paper presents an application of genetic programming to the evolution of fuzzy classifiers based on extended Boolean queries. Extended Boolean queries are well known concept in the area of fuzzy information retrieval. An extended Boolean query represents a complex soft search expression that defines a fuzzy set on the collection of searched documents. We interpret the data mining task as a fuzzy information retrieval problem and we apply a proven method for query induction from data to find useful fuzzy classifiers. The ability of the genetic programming to evolve useful fuzzy classifiers is demonstrated on two use cases in which we detect faulty products in a product processing plant and discover intrusions in a computer network.,"Genetic programming,
Biological cells,
Intrusion detection,
Information retrieval,
Training,
Data mining"
"Tracking Web Video Topics: Discovery, Visualization, and Monitoring","Despite the massive growth of web-shared videos in Internet, efficient organization and monitoring of videos remains a practical challenge. While nowadays broadcasting channels are keen to monitor online events, identifying topics of interest from huge volume of user uploaded videos and giving recommendation to emerging topics are by no means easy. Specifically, such process involves discovering of new topic, visualization of the topic content, and incremental monitoring of topic evolution. This paper studies the problem from three aspects. First, given a large set of videos collected over months, an efficient algorithm based on salient trajectory extraction on a topic evolution link graph is proposed for topic discovery. Second, topic trajectory is visualized as a temporal graph in 2-D space, with one dimension as time and another as degree of hotness, for depicting the birth, growth, and decay of a topic. Finally, giving the previously discovered topics, an incremental monitoring algorithm is proposed to track newly uploaded videos, while discovering new topics and giving recommendation to potentially hot topics. We demonstrate the application on three months' videos crawled from YouTube during December 2008 to February 2009. Both objective and user studies are conducted to verify the performance.","Trajectory,
Visualization,
Monitoring,
Recommender systems,
Algorithm design and analysis"
DODT: Increasing requirements formalism using domain ontologies for improved embedded systems development,"In times of ever-growing system complexity and thus increasing possibilities for errors, high-quality requirements are crucial to prevent design errors in later project phases and to facilitate design verification and validation. To ensure and improve the consistency, completeness and correctness of requirements, formal languages have been introduced as an alternative to using natural language (NL) requirement descriptions. However, in many cases existing NL requirements must be taken into account. The formalization of those requirements by now is a primarily manual task, which therefore is both cumbersome and error-prone. We introduce the tool DODT that semi-automatically transforms NL requirements into semi-formal boilerplate requirements. The transformation builds upon a domain ontology (DO) containing knowledge of the problem domain and upon natural language processing techniques. The tool strongly reduced the required manual effort for the transformation. In addition the quality of the requirements was improved.","Manuals,
Ontologies,
Natural language processing,
Syntactics,
Logic gates,
Transforms,
Embedded systems"
Robust Shape Regression for Supervised Vessel Segmentation and its Application to Coronary Segmentation in CTA,"This paper presents a vessel segmentation method which learns the geometry and appearance of vessels in medical images from annotated data and uses this knowledge to segment vessels in unseen images. Vessels are segmented in a coarse-to-fine fashion. First, the vessel boundaries are estimated with multivariate linear regression using image intensities sampled in a region of interest around an initialization curve. Subsequently, the position of the vessel boundary is refined with a robust nonlinear regression technique using intensity profiles sampled across the boundary of the rough segmentation and using information about plausible cross-sectional vessel shapes. The method was evaluated by quantitatively comparing segmentation results to manual annotations of 229 coronary arteries. On average the difference between the automatically obtained segmentations and manual contours was smaller than the inter-observer variability, which is an indicator that the method outperforms manual annotation. The method was also evaluated by using it for centerline refinement on 24 publicly available datasets of the Rotterdam Coronary Artery Evaluation Framework. Centerlines are extracted with an existing method and refined with the proposed method. This combination is currently ranked second out of 10 evaluated interactive centerline extraction methods. An additional qualitative expert evaluation in which 250 automatic segmentations were compared to manual segmentations showed that the automatically obtained contours were rated on average better than manual contours.","Computed tomography,
Image segmentation,
Arteries,
Data models,
Biomedical imaging,
Blood vessels,
Cardiology,
Coronary arteries"
Position Modulation Code for Rewriting Write-Once Memories,"A write-once memory (wom) is a storage medium formed by a number of “write-once” bit positions (wits), where each wit initially is in a “0” state and can be changed to a “1” state irreversibly. Examples of write-once memories include SLC flash memories and optical disks. This paper presents a low complexity coding scheme for rewriting such write-once memories, which is applicable to general problem configurations. The proposed scheme is called the position modulation code, as it uses the positions of the zero symbols to encode some information. The proposed technique can achieve code rates higher than state-of-the-art practical solutions for some configurations. For instance, there is a position modulation code that can write 56 bits 10 times on 278 wits, achieving rate 2.01. In addition, the position modulation code is shown to achieve a rate at least half of the optimal rate.","Modulation,
Encoding,
Complexity theory,
Indexes,
Ash,
Polynomials,
Decoding"
MR-Guided Thermotherapy of Abdominal Organs Using a Robust PCA-Based Motion Descriptor,"Thermotherapies can now be guided in real-time using magnetic resonance imaging (MRI). This technique is rapidly gaining importance in interventional therapies for abdominal organs such as liver and kidney. An accurate online estimation and characterization of organ displacement is mandatory to prevent misregistration and correct for motion related thermometry artifacts. In addition, when the ablation is performed with an extracorporal heating device such as high intensity focused ultrasound (HIFU), the continuous estimation of the organ displacement is the basis for the dynamic adjustment of the focal point position to track the targeted pathological tissue. In this paper, we describe the use of an optimized principal component analysis (PCA)-based motion descriptor to characterize in real-time the complex organ deformation during the therapy. The PCA was used to detect, in a preparative learning step, spatio-temporal coherences in the motion of the targeted organ. During hyperthermia, incoherent motion patterns could be discarded, which enabled improvements in motion estimation robustness, the compensation of motion related errors in thermal maps, and the adjustment of the beam position. The suggested method was evaluated for a moving phantom, and tested in vivo in the kidney and the liver of 12 healthy volunteers under free breathing conditions. The ability to perform a MR-guided thermotherapy in vivo during HIFU intervention was finally demonstrated on a porcine kidney.",
Decision Making of Networked Multiagent Systems for Interaction Structures,"Networked multiagent systems are very popular in large-scale application environments. In networked multiagent systems, the interaction structures can be shaped into the form of networks where each agent occupies a position that is determined by such agent's relations with others. To avoid collisions between agents, the decision of each agent's strategies should match its own interaction position, so that the strategies available to all agents are in line with their interaction structures. Therefore, this paper presents a novel decision-making model for networked multiagent strategies based on their interaction structures, where the set of strategies for an agent is conditionally decided by other agents within its dependence interaction substructure. With the presented model, the resulting strategies available to all agents can minimize the collisions of multiagents regarding their interaction structures, and the model can produce the same resulting strategies for the isomorphic interaction structures. Furthermore, this paper uses a multiagent citation network as a case study to demonstrate the effectiveness of the presented decision-making model.","Decision making,
Multiagent systems,
Social network services,
Distributed decision making,
Interactive systems"
"Efficient learning of sparse, distributed, convolutional feature representations for object recognition","Informative image representations are important in achieving state-of-the-art performance in object recognition tasks. Among feature learning algorithms that are used to develop image representations, restricted Boltzmann machines (RBMs) have good expressive power and build effective representations. However, the difficulty of training RBMs has been a barrier to their wide use. To address this difficulty, we show the connections between mixture models and RBMs and present an efficient training method for RBMs that utilize these connections. To the best of our knowledge, this is the first work showing that RBMs can be trained with almost no hyperparameter tuning to provide classification performance similar to or significantly better than mixture models (e.g., Gaussian mixture models). Along with this efficient training, we evaluate the importance of convolutional training that can capture a larger spatial context with less redundancy, as compared to non-convolutional training. Overall, our method achieves state-of-the-art performance on both Caltech 101 / 256 datasets using a single type of feature.","Training,
Convolutional codes,
Feature extraction,
Encoding,
Clustering algorithms,
Context,
Object recognition"
Latent structured models for human pose estimation,"We present an approach for automatic 3D human pose reconstruction from monocular images, based on a discriminative formulation with latent segmentation inputs. We advanced the field of structured prediction and human pose reconstruction on several fronts. First, by working with a pool of figure-ground segment hypotheses, the prediction problem is formulated in terms of combined learning and inference over segment hypotheses and 3D human articular configurations. Beside constructing tractable formulations for the combined segment selection and pose estimation problem, we propose new augmented kernels that can better encode complex dependencies between output variables. Furthermore, we provide primal linear re-formulations based on Fourier kernel approximations, in order to scale-up the non-linear latent structured prediction methodology. The proposed models are shown to be competitive in the HumanEva benchmark and are also illustrated in a clip collected from a Hollywood movie, where the model can infer human poses from monocular images captured in complex environments.",
Capacity of dual-radio multi-channel wireless sensor networks for continuous data collection,"Data collection is an important operation of wireless sensor networks (WSNs). The performance of data collection can be measured by its achievable network capacity. Most existing works focus on the capacity of unicast, multicast or snapshot data collection in single-radio single-channel wireless networks, and no dedicated works consider the continuous data collection capacity for WSNs in detail under the protocol interference model. In this paper, we first propose a multi-path scheduling algorithm for the snapshot data collection in single-radio multi-channel WSNs and prove that its achievable network capacity is at least W/[(3.63/H)ρ2+o(ρ)], which is a tighter lower bound compared with the previously best result in which is W/(8ρ2), where W is the bandwidth over a channel, H is the number of the available orthogonal channels, ρ is the ratio of the interference radius over the transmission radius of a sensor and o(ρ) is a linear equation of ρ. For the continuous data collection problem, although the authors in claim that data collection can be pipelined with existing works, we find that such an idea cannot actually improve network capacity. We explain the reason for this and propose a novel continuous data collection method for dual-radio multi-channel WSNs. This method significantly speeds up the data collection process, and achieves a capacity of nW/[12M((3.63/H)ρ2+o(ρ))] when Δe ≤ 12, or nW/[MΔc((3.63/H)ρ2+o(ρ))] when Δe >; 12, where n is the number of sensors, M is a constant value and usually M<;<; n, and Δe is the maximum number of leaf nodes having a same parent node in the routing tree (i.e. data collection tree). The simulation results also indicate that the proposed algorithms significantly improve network capacity compared with the existing works.","Wireless communication,
Wireless sensor networks"
Mean-Square Deviation Analysis of Affine Projection Algorithm,"This paper presents an improved mean-square deviation (MSD) analysis of the standard affine projection algorithm (APA) based on two distinctive features. First, the propagation model of the error covariance includes the cross-correlation between the current weight error vector and the prior measurement noises associated with the reused inputs; such a cross-correlation has merely been considered previously. Second, the analysis based on n most recent accumulated iterations, rather than a typical analysis based on a current single iteration, is suggested to reveal a previously unseen phenomenon, where n denotes the tap-length of the filter. Simulation results are in better agreement with the proposed theoretical results, than the previous theoretical ones, over a wide range of parameters such as tap-length, projection order, and step-size.",
Flight of the FINCH Through the Java Wilderness,"We describe Fertile Darwinian Bytecode Harvester (FINCH), a methodology for evolving Java bytecode, enabling the evolution of extant, unrestricted Java programs, or programs in other languages that compile to Java bytecode. Our approach is based upon the notion of compatible crossover, which produces correct programs by performing operand stack-based, local variables-based, and control flow-based compatibility checks on source and destination bytecode sections. This is in contrast to existing work that uses restricted subsets of the Java bytecode instruction set as a representation language for individuals in genetic programming. We demonstrate FINCH's unqualified success at solving a host of problems, including simple and complex regression, trail navigation, image classification, array sum, and tic-tac-toe. FINCH exploits the richness of the Java virtual machine architecture and type system, ultimately evolving human-readable solutions in the form of Java programs. The ability to evolve Java programs will hopefully lead to a valuable new tool in the software engineer's toolkit.",
Mapping and Pursuit-Evasion Strategies For a Simple Wall-Following Robot,"This paper defines and analyzes a simple robot with local sensors that moves in an unknown polygonal environment. The robot can execute wall-following motions and can traverse the interior of the environment only when following parallel to an edge. The robot has no global sensors that would allow precise mapping or localization. Special information spaces are introduced for this particular model. Using these, strategies are presented to solve several tasks: 1) counting vertices, 2) computing the path winding number, 3) learning a combinatorial map, which is called the cut ordering, that encodes partial geometric information, and 4) solving pursuit-evasion problems.","Windings,
Clocks,
Mobile robots,
Tactile sensors"
Robust High-Accuracy Ultrasonic Range Measurement System,This paper presents a novel method for ultrasonic range estimation. The method uses a wideband frequency-hop spread spectrum ultrasonic signal to increase robustness to noise and reverberation. The method applies cross-correlation with earliest peak search and a novel minimum variance search technique to correct the error in the cross-correlation time-of-flight estimate to within one wavelength of the carrier before applying a phase-shift technique for subwavelength range refinement. The method can be implemented digitally in software and only requires low-cost hardware for signal transmission and acquisition. Experimental results show an accuracy of better than 0.5 mm in a typical office environment.,"Acoustics,
Receivers,
Noise,
Accuracy,
Estimation,
Transmitters,
Ultrasonic variables measurement"
User-guided discovery of declarative process models,"Process mining techniques can be used to effectively discover process models from logs with example behaviour. Cross-correlating a discovered model with information in the log can be used to improve the underlying process. However, existing process discovery techniques have two important drawbacks. The produced models tend to be large and complex, especially in flexible environments where process executions involve multiple alternatives. This “overload” of information is caused by the fact that traditional discovery techniques construct procedural models explicitly showing all possible behaviours. Moreover, existing techniques offer limited possibilities to guide the mining process towards specific properties of interest. These problems can be solved by discovering declarative models. Using a declarative model, the discovered process behaviour is described as a (compact) set of rules. Moreover, the discovery of such models can easily be guided in terms of rule templates. This paper uses DECLARE, a declarative language that provides more flexibility than conventional procedural notations such as BPMN, Petri nets, UML ADs, EPCs and BPEL. We present an approach to automatically discover DECLARE models. This has been implemented in the process mining tool ProM. Our approach and toolset have been applied to a case study provided by the company Thales in the domain of maritime safety and security.",
Annotator rationales for visual recognition,"Traditional supervised visual learning simply asks annotators “what” label an image should have. We propose an approach for image classification problems requiring subjective judgment that also asks “why”, and uses that information to enrich the learned model. We develop two forms of visual annotator rationales: in the first, the annotator highlights the spatial region of interest he found most influential to the label selected, and in the second, he comments on the visual attributes that were most important. For either case, we show how to map the response to synthetic contrast examples, and then exploit an existing large-margin learning technique to refine the decision boundary accordingly. Results on multiple scene categorization and human attractiveness tasks show the promise of our approach, which can more accurately learn complex categories with the explanations behind the label choices.",
Modeling of the Output and Transfer Characteristics of Graphene Field-Effect Transistors,"We obtain the output and transfer characteristics of graphene field-effect transistors by using the charge-control model for the current, based on the solution of the Boltzmann equation in the field-dependent relaxation time approximation. Closed expressions for the conductance, transconductance, and saturation voltage are derived. We found good agreement with the experimental data of Meric et al. [Nat. Nanotechnol. vol. 3, p. 684, 2008] without assuming carrier density-dependent velocity saturation.","Logic gates,
Resistance,
Threshold voltage,
Mathematical model,
Scattering,
Transistors,
Materials"
Fast Intersection-Free Offset Surface Generation From Freeform Models With Triangular Meshes,"A fast offset surface generation approach is presented in this paper to construct intersection-free offset surfaces, which preserve sharp features, from freeform triangular mesh surfaces. The basic spirit of our algorithm is to sample a narrowband signed distance-field from the input model on a uniform grid and then employ a contouring algorithm to build the resultant offset mesh surface from the signed distance-field. Four filters are conducted to generate the narrowband signed distance-field around the offset surface in a very efficient way by alleviating computation redundancies in the regions far from the offset surfaces. The resultant mesh surfaces are generated by a modified dual contouring algorithm which relies on accurate intersections between the grid edges and the isosurfaces. A hybrid method is developed to prevent the expensive bisection search in the configurations that the analytical solutions exist. Our modified intersection-free dual contouring algorithm is based on convex-concave analysis, which is more robust and efficient. The quality and performance of our approach are demonstrated with a number of experimental tests on various examples.","Surface reconstruction,
Solid modeling,
Computational modeling,
Narrowband,
Solids,
Three dimensional displays,
Mathematical model"
Evolutionary Computation on Programmable Robust IIR Filter Pole-Placement Design,"This paper explores the pole-placement design problem of a robust stable infinite-impulse-response (IIR) filter to attenuate or eliminate the undesired measurement noise and proposes a strategy based on an adaptive differential evolution (ADE) algorithm to design a filter. The results are compared to the results of other popular evolutionary algorithms, e.g., particle swarm optimization (PSO), genetic algorithm (GA), and improved genetic algorithm (IGA). The stability robustness for an IIR filter will be achieved by placing all poles inside a disk D(α, r) contained in the unit disk, in which α is the center, and r is the radius of the disk. This investigation first uses a robust stability criterion, called the D(α, r)-stability criterion, to ensure that digital filter poles lie inside a disk D(α, r). The proposed strategy checks the criterion during differential evolution (DE) and adaptively adjusts the DE parameters, depending on the current DE performance. This paper also introduces two design examples of a bandpass IIR filter and a low-pass IIR filter for the measurement of a speech signal. These examples show that the proposed strategy performance based on the proposed ADE is better than designs based on PSO, GA, and IGA. Finally, this paper implements an IIR filter on the field-programmable gate array (FPGA) chip to verify the designed filter performance in practical electronic devices and uses speech signals as an input signal to the FPGA chip to verify that the measurement noise of the speech signal is attenuated by the designed IIR filter.",
"A New Method for Volume Segmentation of PET Images, Based on Possibility Theory","18F-fluorodeoxyglucose positron emission tomography (18FDG PET) has become an essential technique in oncology. Accurate segmentation and uptake quantification are crucial in order to enable objective follow-up, the optimization of radiotherapy planning, and therapeutic evaluation. We have designed and evaluated a new, nearly automatic and operator-independent segmentation approach. This incorporated possibility theory, in order to take into account the uncertainty and inaccuracy inherent in the image. The approach remained independent of PET facilities since it did not require any preliminary calibration. Good results were obtained from phantom images [percent error =18.38% (mean) ±9.72% (standard deviation)]. Results on simulated and anatomopathological data sets were quantified using different similarity measures and showed the method was efficient (simulated images: Dice index =82.18% ±13.53% for SUV =2.5 ). The approach could, therefore, be an efficient and robust tool for uptake volume segmentation, and lead to new indicators for measuring volume of interest activity.",
Biometric and mobile gait analysis for early diagnosis and therapy monitoring in Parkinson's disease,"Parkinson's disease (PD) is the most frequent neurodegenerative movement disorder. Early diagnosis and effective therapy monitoring is an important prerequisite to treat patients and reduce health care costs. Objective and non-invasive assessment strategies are an urgent need in order to achieve this goal. In this study we apply a mobile, lightweight and easy applicable sensor based gait analysis system to measure gait patterns in PD and to distinguish mild and severe impairment of gait. Examinations of 16 healthy controls, 14 PD patients in an early stage, and 13 PD patients in an intermediate stage were included. Subjects performed standardized gait tests while wearing sport shoes equipped with inertial sensors (gyroscopes and accelerometers). Signals were recorded wirelessly, features were extracted, and distinct subpopulations classified using different classification algorithms. The presented system is able to classify patients and controls (for early diagnosis) with a sensitivity of 88% and a specificity of 86%. In addition it is possible to distinguish mild from severe gait impairment (for therapy monitoring) with 100% sensitivity and 100% specificity. This system may be able to objectively classify PD gait patterns providing important and complementary information for patients, caregivers and therapists.","Feature extraction,
Monitoring,
Frequency measurement,
Accelerometers,
Parkinson's disease,
Frequency control"
Ultra-Low-Power and Robust Digital-Signal-Processing Hardware for Implantable Neural Interface Microsystems,"Implantable microsystems for monitoring or manipulating brain activity typically require on-chip real-time processing of multichannel neural data using ultra low-power, miniaturized electronics. In this paper, we propose an integrated-circuit/architecture-level hardware design framework for neural signal processing that exploits the nature of the signal-processing algorithm. First, we consider different power reduction techniques and compare the energy efficiency between the ultra-low frequency subthreshold and conventional superthreshold design. We show that the superthreshold design operating at a much higher frequency can achieve comparable energy dissipation by taking advantage of extensive power gating. It also provides significantly higher robustness of operation and yield under large process variations. Next, we propose an architecture level preferential design approach for further energy reduction by isolating the critical computation blocks (with respect to the quality of the output signal) and assigning them higher delay margins compared to the noncritical ones. Possible delay failures under parameter variations are confined to the noncritical components, allowing graceful degradation in quality under voltage scaling. Simulation results using prerecorded neural data from the sea-slug (Aplysia californica) show that the application of the proposed design approach can lead to significant improvement in total energy, without compromising the output signal quality under process variations, compared to conventional design approaches.","Delay,
Hardware,
Algorithm design and analysis,
Clocks,
Signal processing algorithms,
Logic gates,
Latches"
Smooth object retrieval using a bag of boundaries,"We describe a scalable approach to 3D smooth object retrieval which searches for and localizes all the occurrences of a user outlined object in a dataset of images in real time. The approach is illustrated on sculptures. A smooth object is represented by its material appearance (sufficient for foreground/background segmentation) and imaged shape (using a set of semi-local boundary descriptors). The descriptors are tolerant to scale changes, segmentation failures, and limited viewpoint changes. Furthermore, we show that the descriptors may be vector quantized (into a bag-of-boundaries) giving a representation that is suited to the standard visual word architectures for immediate retrieval of specific objects. We introduce a new dataset of 6K images containing sculptures by Moore and Rodin, and annotated with ground truth for the occurrence of twenty 3D sculptures. It is demonstrated that recognition can proceed successfully de- spite changes in viewpoint, illumination and partial occlusion, and also that instances of the same shape can be retrieved even though they may be made of different materials.",
"Improved Subthreshold Swing and Gate-Bias Stressing Stability of p-Type
Cu
2
O
Thin-Film Transistors Using a
HfO
2
High-
k
Gate Dielectric Grown on a
SiO
2
/Si
Substrate by Pulsed Laser Ablation","p-Type Cu2O thin films and HfO2 high-k gate dielectrics are deposited by pulsed laser ablation. p-Type Cu2O metal-oxide-semiconductor capacitors and thin-film transistors (TFTs) are then fabricated and investigated. Experimental results show that a HfO2/SiO2-stacked gate dielectric can effectively improve interface properties and decrease gate-leakage current when compared with a SiO2 gate dielectric. Thus, increased mobility, a decreased subthreshold swing, and enhanced gate-bias-voltage stressing stability have been achieved for the relevant Cu2O TFTs. Bottom-gate and top-source/drain-contact p-channel Cu2O TFTs (W/L= 500/20 μm) with the HfO2/SiO2-stacked gate dielectric exhibit superior performance with a saturation-carrier-mobility value of 2.7 cm2/V·s, an on-off current ratio of 1.5×106, a subthreshold swing of 137 mV/dec, and a threshold-voltage shift of 1.4 V after gate-bias stress at 10 V for 3600 s.","Logic gates,
Thin film transistors,
Dielectrics,
MOS capacitors,
Temperature measurement,
Current measurement"
Sparse spectral factorization: Unicity and reconstruction algorithms,"Spectral factorization is a classical tool in signal processing and communications. It also plays a critical role in X-ray crystallography, in the context of phase retrieval. In this work, we study the problem of sparse spectral factorization, aiming to recover a one-dimensional sparse signal from its autocorrelation. We present a sufficient condition for the recovery to be unique, and propose an iterative algorithm that can obtain the original signal (up to a sign change, time-shift and time-reversal). Numerical simulations verify the effectiveness of the proposed algorithm.","Correlation,
Frequency modulation,
Discrete Fourier transforms,
Reconstruction algorithms,
Signal processing algorithms,
Concrete,
Image reconstruction"
"Analysis of Transconductance
(
g
m
)
in Schottky-Barrier MOSFETs","This paper experimentally investigates the unique behavior of transconductance (gm) in the Schottky-barrier metal-oxide-semiconductor field-effect transistors (SB-MOSFETs) with various silicide materials. When the Schottky-barrier height (SBH) or a scaling parameter is not properly optimized, a peculiar shape of gm is observed. Thus, gm can be used as a novel metric that exhibits the transition of the carrier injection mechanisms from a thermionic emission (TE) to thermally assisted tunneling (TU) in the SB-MOSFETs. When the local maximum point of gm is observed, it can be expected that an incomplete transition occurs between TE and TU in SB-MOSFETs. When a dopant-segregation (DS) technique is implemented in the SB-MOSFETs, however, the carrier injection efficiency from the source to the channel is significantly improved, although the SBH is not minimized. As a consequence, the peculiar shape of the gm disappears, i.e., a complete transition from TE to TU can be enabled by the DS technique.","MOSFETs,
Silicides,
Logic gates,
Transconductance,
Silicon"
The NEEShub Cyberinfrastructure for Earthquake Engineering,"The US Network for Earthquake Engineering Simulation (NEES) operates a shared network of civil engineering experimental facilities aimed at facilitating research on mitigating earthquake damage and loss of life. The NEEShub gateway was created in response to the NEES community's needs, combining data, simulation, and analysis functionality with collaboration tools.","Earthquakes,
Structural engineeirng,
Collaboration,
Research and development"
Employing zSlices based general type-2 fuzzy sets to model multi level agreement,"In this paper, we introduce the concept of Multi Level Agreement (MLA) based on (zSlices based) general type-2 fuzzy sets. We define the notion of MLA and describe how it can be computed based on a series of interval type-2 fuzzy sets. We provide examples, visualizing the nature of MLA sets and discuss their properties and interpretation. Moreover, we specifically address the reason for introducing MLA in order to allow the modeling of agreement in real world applications using fuzzy sets while still maintaining an uncertainty model and show that the use of general type-2 fuzzy sets is essential for MLA as classical sets, type-1 and interval type-2 fuzzy sets do not provide a degree of freedom which could be employed to model agreement.","Fuzzy sets,
Computational modeling,
Uncertainty,
Fuzzy logic,
Sensor phenomena and characterization,
Complexity theory"
An Adaptive Slope Compensation for the Single-Stage Inverter With Peak Current-Mode Control,"This letter develops a mathematical model of the slope compensation for a single-stage inverter with peak current-mode control. The model proves that the single-stage inverter with peak current-mode control will be unconditionally stable only if a slope compensation equal or greater than half the slope rate of the inductor current downslope is applied. Thus, the slope compensation requirements for a conventional dc-dc converter and a single-stage inverter with peak current-mode control are the same. A simulation model has been developed to prove this mathematical model is valid. A frequency-domain analysis of the single-stage inverter shows that the unified slope compensation will degrade the loop gain at lower input voltages. An adaptive slope compensation is proposed to keep the loop gain of the single-stage inverter nearly constant at all the duty cycles. A practical design is also proposed.","Programmable control,
Adaptive control,
Inverters,
DC-DC power converters,
Voltage,
Mathematical model,
Power electronics,
Inductors,
Photovoltaic systems,
Galvanizing"
Intraoperative Brain Shift Compensation: Accounting for Dural Septa,"Biomechanical models that describe soft tissue deformation provide a relatively inexpensive way to correct registration errors in image-guided neurosurgical systems caused by nonrigid brain shift. Quantifying the factors that cause this deformation to sufficient precision is a challenging task. To circumvent this difficulty, atlas-based methods have been developed recently that allow for uncertainty, yet still capture the first-order effects associated with deformation. The inverse solution is driven by sparse intraoperative surface measurements, which could bias the reconstruction and affect the subsurface accuracy of the model prediction. Studies using intraoperative MR have shown that the deformation in the midline, tentorium, and contralateral hemisphere is relatively small. The dural septa act as rigid membranes supporting the brain parenchyma and compartmentalizing the brain. Accounting for these structures in models may be an important key to improving subsurface shift accuracy. A novel method to segment the tentorium cerebelli will be described, along with the procedure for modeling the dural septa. Results in seven clinical cases show a qualitative improvement in subsurface shift accuracy making the predicted deformation more congruous with previous observations in the literature. The results also suggest a considerably more important role for hyperosmotic drug modeling for the intraoperative shift correction environment.","Brain models,
Surgery,
Computational modeling,
Boundary conditions,
Tumors,
Head"
Numerical simulation of Stochastic Differential Algebraic Equations for power system transient stability with random loads,This paper summarizes numerical methods for Stochastic Differential Algebraic Equations (SDAEs) with which power system are modeled. The loads are modeled as random variables which appear in algebraic equations. The properties of numerical methods for Differential Algebraic Equations (DAE) and Stochastic Differential Equations (SDE) are reviewed and the first-order backward euler method is proposed for SDAE in power system transient stability simulation. Illustration examples are given on a single-machine-infinite-bus (SMIB) system.,
Learning to predict how rigid objects behave under simple manipulation,"An important problem in robotic manipulation is the ability to predict how objects behave under manipulative actions. This ability is necessary to allow planning of object manipulations. Physics simulators can be used to do this, but they model many kinds of object interaction poorly. An alternative is to learn a motion model for objects by interacting with them. In this paper we address the problem of learning to predict the interactions of rigid bodies in a probabilistic framework, and demonstrate the results in the domain of robotic push manipulation. A robot arm applies random pushes to various objects and observes the resulting motion with a vision system. The relationship between push actions and object motions is learned, and enables the robot to predict the motions that will result from new pushes. The learning does not make explicit use of physics knowledge, or any pre-coded physical constraints, nor is it even restricted to domains which obey any particular rules of physics. We use regression to learn efficiently how to predict the gross motion of a particular object. We further show how different density functions can encode different kinds of information about the behaviour of interacting objects. By combining these as a product of densities, we show how learned predictors can cope with a degree of generalisation to previously unencountered object shapes, subjected to previously unencountered push directions. Performance is evaluated through a combination of virtual experiments in a physics simulator, and real experiments with a 5-axis arm equipped with a simple, rigid finger.",
"Simultaneous Handling of Symmetry, Common Centroid, and General Placement Constraints","In today's system-on-chip designs, both digital and analog parts of a circuit will be implemented on the same chip. Parasitic mismatch induced by layout will affect circuit performance significantly for analog designs. Consideration of symmetry and common centroid constraints during placement can help to reduce these errors. Besides these two specific types of placement constraints, other constraints, such as alignment, abutment, preplace, and maximum separation, are also essential in circuit placement. In this paper, we will present a placement methodology that can handle all these constraints at the same time. To the best of our knowledge, this is the first piece of work that can handle symmetry constraint, common centroid constraint, and other general placement constraints, simultaneously. Experimental results do confirm the effectiveness and scalability of our approach in solving this mixed constraint-driven placement problem.","Layout,
Annealing,
Upper bound,
Simulated annealing,
Shape,
Engines,
Cost function"
Who Blocks Who: Simultaneous clothing segmentation for grouping images,"Clothing is one of the most informative cues of human appearance. In this paper, we propose a novel multi-person clothing segmentation algorithm for highly occluded images. The key idea is combining blocking models to address the person-wise occlusions. In contrary to the traditional layered model that tries to solve the full layer ranking problem, the proposed blocking model partitions the problem into a series of pair-wise ones and then determines the local blocking relationship based on individual and contextual information. Thus, it is capable of dealing with cases with a large number of people. Additionally, we propose a layout model formulated as Markov Network which incorporates the blocking relationship to pursue an approximately optimal clothing layout for group people. Experiments demonstrated on a group images dataset show the effectiveness of our algorithm.","Clothing,
Shape,
Layout,
Face,
Image segmentation,
Decision trees,
Humans"
Cross-Layer Design of Rateless Random Network Codes for Delay Optimization,"We study joint network and channel code design to optimize delay performance. Here the delay is the transmission time of information packets from a source to sinks without considering queuing effects. In our systems, network codes (network layer) are on top of channel codes (physical layer) which are disturbed by noise. Network codes run in a rateless random method, and thus have erasure-correction capability. For the constraint of finite transmission time, transmission errors are inevitable in the physical layer. A detection error in the physical layer means an erasure of network codewords. For the analysis, we model the delay of each information generation in the network layer as independent, identically distributed random variables. The calculation approaches for delay measures are investigated for coded erasure networks. We show how to evaluate the rate and erasure probability of a set of channels belonging to one cut. We also show that the min-cut determines the decoding error probability in the sinks if the number of information packets is large. We observe that for a given amount of source information, larger packet length leads to fewer packets to be transmitted but higher physical-layer detection error probabilities. Further, longer transmission time (delay) in the physical-layer causes smaller detection error probability at the physical layer. Thus, both parameters have opposite impacts on the physical and network layer, considering delay. We should find the optimal values of them in a cross-layer approach. We then formulate the problems of optimizing delay performance, and discuss solutions for them.","Delay,
Network coding,
Physical layer,
Encoding,
Decoding,
Error probability,
Network topology,
Optimization"
A Passive-Blind Forgery Detection Scheme Based on Content-Adaptive Quantization Table Estimation,"In this paper, we propose a passive-blind scheme for detecting forged images. The scheme leverages quantization table estimation to measure the inconsistency among images. To improve the accuracy of the estimation process, each AC DCT coefficient is first classified into a specific type; then the corresponding quantization step size is measured adaptively from its energy density spectrum (EDS) and the EDS's Fourier transform. The proposed content-adaptive quantization table estimation scheme is comprised of three phases: pre-screening, candidate region selection, and tampered region identification. In the pre-screening phase, we determine whether an input image has been JPEG compressed, and count the number of quantization steps whose size is equal to one. To select candidate regions for estimating the quantization table, we devise a candidate region selection algorithm based on seed region generation and region growing. First, the seed region generation operation finds a suitable region by removing suspect regions, after which the selected seed region is merged with other suitable regions to form a candidate region. To avoid merging suspect regions, a candidate region refinement operation is performed in the region growing step. After estimating the quantization table from the candidate region, an maximum-likelihood-ratio classifier exploits the inconsistency of the quantization table to identify tampered regions block by block. To evaluate the scheme's performance in terms of tampering detection, three common forgery techniques, copy-paste tampering, inpainting, and composite tampering, are used. Experiment results demonstrate that the proposed scheme can estimate quantization tables and identify tampered regions effectively.",
Using Social Networking Technology to Enhance Learning in Higher Education: A Case Study Using Facebook,"In this paper we explore the possibility of using Web 2.0 technology, specifically social networking technology, to support a community of practice in a graduate-level classroom setting in order to enhance learning. For our experiment, we utilized Facebook as a learning resource for an MIS course for learners to share prior knowledge and experience. We present the results of our five-month study, and found that Facebook provides an easy-to-use and familiar technology for learners to leverage social networking to share and generate tacit knowledge amongst each other within the small group environment.",
Nonidentical Linear Pulse-Coupled Oscillators Model With Application to Time Synchronization in Wireless Sensor Networks,"Similar to other cyber infrastructure systems, as wireless sensor networks become larger and more complex, many classic algorithms may no longer work efficiently. This paper presents a wireless sensor network time synchronization model that was initially inspired by synchronous flashing of fireflies. Synchronous flashing of fireflies is an interesting phenomenon that has been studied for decades. A variety of models have been proposed to explain this phenomenon, among which is the pulse-coupled oscillators model that models fireflies as oscillators. The oscillators in such a model interact only through discrete pulses, similar to the flashing of fireflies. In this paper, we propose a new nonidentical linear pulse-coupled oscillators model and use the model to analyze synchronization of pulse-coupled oscillators with different frequencies. The conditions to achieve and maintain synchronization are derived, and then, the results are used to prove that the oscillators in the model can achieve synchronization eventually, except for a set of frequencies with zero Lebesgue measure. Furthermore, through simulations and implementation on a wireless sensor network testbed, we demonstrate that the proposed nonidentical linear pulse-coupled oscillators model can be used in designing lightweight scalable time synchronization protocols for distributed systems.",
An Automatic Recommendation Scheme of TV Program Contents for (IP)TV Personalization,"Due to the rapid increase of contents available under the convergence of broadcasting and Internet, efficient access to personally preferred contents has become an important issue. In this paper, an automatic recommendation scheme based on collaborative filtering is presented for intelligent personalization of (IP)TV services. The proposed scheme does not require TV viewers (users) to make explicit ratings on their watched TV program contents. Instead, it implicitly infers the users' interests on the watched TV program contents. For the recommendation of user preferred TV program contents, our proposed recommendation scheme first clusters TV users into similar groups based on their preferences on the content genres from the user's watching history of TV program contents. For the personalized recommendation of TV program contents to an active user, a candidate set of preferred TV program contents is obtained via collaborative filtering for the group to which the active user belongs. The candidate TV programs for recommendation are then ranked by a proposed novel ranking model. Finally, a set of top- N ranked TV program contents is recommended to the active user. The experimental results show that the proposed TV program recommendation scheme yields about 77% of average precision accuracy and 0.135 value of ANMRR (Average Normalized Modified Retrieval Rank) with top five recommendations for 1,509 people.",
Global Disturbance Rejection of Lower Triangular Systems With an Unknown Linear Exosystem,"In this technical note, we study the global disturbance rejection problem of nonlinear systems in lower triangular form with unknown exosystem via state feedback control. The problem is dealt with in two steps. In the first step, an augmented system composed of the given plant and an internal model is constructed. Owing to the presence of the unknown parameter in the exosystem, the augmented system contains both nonlinearly and linearly parameterized uncertainties. In the second step, the stabilization of the augmented system is solved by an approach integrating both robust and adaptive techniques. The solution of the stabilization problem of the augmented system in turn leads to the solution of the global disturbance rejection problem of the original system. Further, the convergence issue of an estimated unknown parameter vector is also discussed.","Trajectory,
Nonlinear systems,
Mathematical model,
Equations,
Lyapunov methods,
Uncertainty,
Adaptive control"
Knowledge Based Cluster Ensemble for Cancer Discovery From Biomolecular Data,"The adoption of microarray techniques in biological and medical research provides a new way for cancer diagnosis and treatment. In order to perform successful diagnosis and treatment of cancer, discovering and classifying cancer types correctly is essential. Class discovery is one of the most important tasks in cancer classification using biomolecular data. Most of the existing works adopt single clustering algorithms to perform class discovery from biomolecular data. However, single clustering algorithms have limitations, which include a lack of robustness, stability, and accuracy. In this paper, we propose a new cluster ensemble approach called knowledge based cluster ensemble (KCE) which incorporates the prior knowledge of the data sets into the cluster ensemble framework. Specifically, KCE represents the prior knowledge of a data set in the form of pairwise constraints. Then, the spectral clustering algorithm (SC) is adopted to generate a set of clustering solutions. Next, KCE transforms pairwise constraints into confidence factors for these clustering solutions. After that, a consensus matrix is constructed by considering all the clustering solutions and their corresponding confidence factors. The final clustering result is obtained by partitioning the consensus matrix. Comparison with single clustering algorithms and conventional cluster ensemble approaches, knowledge based cluster ensemble approaches are more robust, stable and accurate. The experiments on cancer data sets show that: 1) KCE works well on these data sets; 2) KCE not only outperforms most of the state-of-the-art single clustering algorithms, but also outperforms most of the state-of-the-art cluster ensemble approaches.","Clustering algorithms,
Cancer,
Accuracy,
Knowledge based systems,
Partitioning algorithms,
Lungs,
Tumors"
High-Quality Visualization for Geographically Distributed 3-D Teleimmersive Applications,"The growing popularity of 3-D movies has led to the rapid development of numerous affordable consumer 3-D displays. In contrast, the development of technology to generate 3-D content has lagged behind considerably. In spite of significant improvements to the quality of imaging devices, the accuracy of the algorithms that generate 3-D data, and the hardware available to render such data, the algorithms available to calibrate, reconstruct, and then visualize such data remain difficult to use, extremely noise sensitive, and unreasonably slow. In this paper, we present a multi-camera system that creates a highly accurate (on the order of a centimeter), 3-D reconstruction of an environment in real-time (under 30 ms) that allows for remote interaction between users. This paper focuses on addressing the aforementioned deficiencies by describing algorithms to calibrate, reconstruct, and render objects in the system. We demonstrate the accuracy and speed of our results on a variety of benchmarks and data collected from our own system.","Cameras,
Three dimensional displays,
Calibration,
Image reconstruction,
Pixel,
Real time systems,
Matrix decomposition"
A Scalable Parallel Wideband MLFMA for Efficient Electromagnetic Simulations on Large Scale Clusters,"The development of the multilevel fast multipole algorithm (MLFMA) and its multiscale variants have enabled the use of integral equation (IE) based solvers to compute scattering from complicated structures. Development of scalable parallel algorithms, to extend the reach of these solvers, has been a topic of intense research for about a decade. In this paper, we present a new algorithm for parallel implementation of IE solver that is augmented with a wideband MLFMA and scalable on large number of processors. The wideband MLFMA employed here, to handle multiscale problems, is a hybrid combination of the accelerated Cartesian expansion (ACE) and the classical MLFMA. The salient feature of the presented parallel algorithm is that it is implicitly load balanced and exhibits higher performance. This is achieved by developing a strategy to partition the MLFMA tree, and hence the associated computations, in a self-similar fashion among the parallel processors. As detailed in the paper, the algorithm employs both spatial and direction partitioning approaches in a flexible manner to ensure scalable performance. Plethora of results are presented here to exhibit the scalability of this algorithm on 512 and more processors.","Program processors,
Vegetation,
Partitioning algorithms,
Wideband,
Parallel algorithms,
Electromagnetic scattering,
MLFMA"
An approach for cloud resource scheduling based on Parallel Genetic Algorithm,"Resource scheduling is a key process for clouds such as Infrastructure as a Service cloud. To make the most efficient use of the resources, we propose an optimized scheduling algorithm to achieve the optimization or sub-optimization for cloud scheduling problems. We investigate the possibility to place the Virtual Machines in a flexible way to improve the speed of finding the best allocation on the premise of permitting the maximum utilization of resources. Mathematically, we consider the scheduling problem come down to an Unbalance Assignment Problem. Our scheduling policy achieved by Parallel Genetic Algorithm which is much faster than traditional Genetic Algorithm. The experiments show that our method improved both the speed of resources allocation and the utilization of system resource.","Electronics packaging,
Genetic algorithms,
Processor scheduling,
Resource management,
Gallium,
Scheduling,
Cloud computing"
Window-Level Rate Control for Smooth Picture Quality and Smooth Buffer Occupancy,"In rate control, smooth picture quality and smooth buffer occupancy are both important but contrary to each other at a given bit rate. How to get a good tradeoff between them was not devoted much attention previously. To deal with this problem, a theoretical window model is proposed in this paper, in which several adjacent frames grouped as a window are considered together. The smoothness of both picture quality and buffer occupancy can be gracefully achieved by regulating the size of the window. To illustrate the usage of window model, a window-level rate control algorithm cooperated with the traditional ρ-domain rate-distortion model is further introduced. In experiments, we first show how the proposed window model achieves the tradeoff between picture quality smoothness and buffer smoothness, and then demonstrate the significant PSNR improvement, accuracy of bit control and consistency of visual quality of the proposed window-level rate control algorithm.","Bit rate,
Buffer storage,
Video coding,
Computer science,
Permission,
Rate-distortion,
Internet,
Communication standards,
Streaming media,
Communication system control"
How the Ocean Personality Model Affects the Perception of Crowds,"This approach extends the HiDAC (High-Density Autonomous Crowds) system by providing each agent with a personality model based on the Ocean (openness, conscientiousness, extroversion, agreeableness, and neuroticism) personality model. Each personality trait has an associated nominal behavior. Specifying an agent's personality leads to an automation of low-level parameter tuning.","Computational modeling,
Animation,
Psychology,
Computer simulation,
Autonomous agents,
Human factors,
Information science,
Automation"
Double Closed-Loop Control Method for Injection-Type Hybrid Active Power Filter,"Injection-type hybrid active power filter (IHAPF) shows great promise in reducing harmonics and improving power factor with a relatively low capacity active power filter (APF), but suffers from fundamental current circulation that inadvertently impacts the compensation performance and stability of the IHAPF. In this paper, the control model of IHAPF is established first, and then the origin and harm of fundamental current circulation are analyzed. To solve this problem, a double closed-loop control method is proposed. In the double closed-loop control scheme, the outer control loop based on injection harmonic current detection is used to eliminate load harmonic current, while the inner control loop based on APF output current detection is used to ensure the secure operation of IHAPF. The new control method is compared to other IHAPF control methods. It is implemented in a 100-kVA IHAPF in the laboratory. Both simulation and experimental results show that the new double closed-loop control method is not only easy to implement, but also very effective in reducing harmonics. The fundamental current circulation issue was also resolved with the new design.","RLC circuits,
Harmonic analysis,
Power harmonic filters,
Active filters,
Inverters,
Inductors"
Anonymous Publication of Sensitive Transactional Data,"Existing research on privacy-preserving data publishing focuses on relational data: in this context, the objective is to enforce privacy-preserving paradigms, such as k-anonymity and ℓ-diversity, while minimizing the information loss incurred in the anonymizing process (i.e., maximize data utility). Existing techniques work well for fixed-schema data, with low dimensionality. Nevertheless, certain applications require privacy-preserving publishing of transactional data (or basket data), which involve hundreds or even thousands of dimensions, rendering existing methods unusable. We propose two categories of novel anonymization methods for sparse high-dimensional data. The first category is based on approximate nearest-neighbor (NN) search in high-dimensional spaces, which is efficiently performed through locality-sensitive hashing (LSH). In the second category, we propose two data transformations that capture the correlation in the underlying data: 1) reduction to a band matrix and 2) Gray encoding-based sorting. These representations facilitate the formation of anonymized groups with low information loss, through an efficient linear-time heuristic. We show experimentally, using real-life data sets, that all our methods clearly outperform existing state of the art. Among the proposed techniques, NN-search yields superior data utility compared to the band matrix transformation, but incurs higher computational overhead. The data transformation based on Gray code sorting performs best in terms of both data utility and execution time.",
Wireless AMI application and security for controlled home area networks,"Compared to the conventional grid, the smart grid requires active participation of consumers to improve the quality and reliability of power delivery. Advanced metering infrastructure (AMI), commonly known as the smart meter, which has the capability of supporting various functions beyond that of recording energy usage, will facilitate this expected increase in consumer participation. Another primary benefit of AMI is load and cost management for the utility. AMI requires a reliable communication system between the smart meter and consumer equipment. This paper identifies wireless networking solutions such as ZigBee as the best mode for such communication. Due to the shared nature of the wireless medium, however, these deployments face security challenges and interference issues. These must be addressed, taking into account the interests of both the utility and the consumer. This paper takes a comprehensive look at wireless security in the AMI based home-area network by identifying a wide range of possible vulnerabilities. Countermeasures that can be used by both the utility company as well as the customer are developed.",
Soft robot actuators using energy-efficient valves controlled by electropermanent magnets,"This paper presents the design, fabrication, and evaluation of a novel type of valve that uses an electropermanent magnet [1]. This valve is then used to build actuators for a soft robot. The developed EPM valves require only a brief (5 ms) pulse of current to turn flow on or off for an indefinite period of time. EPMvalves are characterized and demonstrated to be well suited for the control of elastomer fluidic actuators. The valves drive the pressurization and depressurization of fluidic channels within soft actuators. Furthermore, the forward locomotion of a soft, multi-actuator rolling robot is driven by EPM valves. The small size and energy-efficiency of EPM valves may make them valuable in soft mobile robot applications.","Valves,
Actuators,
Robots,
Magnetic cores,
Geometry,
Pneumatic systems,
Magnetic flux"
A Differential Geometric Approach to Automated Segmentation of Human Airway Tree,"Airway diseases are frequently associated with morphological changes that may affect the physiology of the lungs. Accurate characterization of airways may be useful for quantitatively assessing prognosis and for monitoring therapeutic efficacy. The information gained may also provide insight into the underlying mechanisms of various lung diseases. We developed a computerized scheme to automatically segment the 3-D human airway tree depicted on computed tomography (CT) images. The method takes advantage of both principal curvatures and principal directions in differentiating airways from other tissues in geometric space. A “puzzle game” procedure is used to identify false negative regions and reduce false positive regions that do not meet the shape analysis criteria. The negative impact of partial volume effects on small airway detection is partially alleviated by repeating the developed differential geometric analysis on lung anatomical structures modeled at multiple iso-values (thresholds). In addition to having advantages, such as full automation, easy implementation and relative insensitivity to image noise and/or artifacts, this scheme has virtually no leakage issues and can be easily extended to the extraction or the segmentation of other tubular type structures (e.g., vascular tree). The performance of this scheme was assessed quantitatively using 75 chest CT examinations acquired on 45 subjects with different slice thicknesses and using 20 publicly available test cases that were originally designed for evaluating the performance of different airway tree segmentation algorithms.",
A non-convex relaxation approach to sparse dictionary learning,"Dictionary learning is a challenging theme in computer vision. The basic goal is to learn a sparse representation from an overcomplete basis set. Most existing approaches employ a convex relaxation scheme to tackle this challenge due to the strong ability of convexity in computation and theoretical analysis. In this paper we propose a non-convex online approach for dictionary learning. To achieve the sparseness, our approach treats a so-called minimax concave (MC) penalty as a nonconvex relaxation of the ℓ0 penalty. This treatment expects to obtain a more robust and sparse representation than existing convex approaches. In addition, we employ an online algorithm to adaptively learn the dictionary, which makes the non-convex formulation computationally feasible. Experimental results on the sparseness comparison and the applications in image denoising and image inpainting demonstrate that our approach is more effective and flexible.","Dictionaries,
Encoding,
Convergence,
Learning systems,
Image reconstruction,
Optimization,
Computer vision"
Facet-Based Investigation on EM Scattering From Electrically Large Sea Surface With Two-Scale Profiles: Theoretical Model,"This paper is aimed at developing an applicable and feasible facet model, which formulation should be tractable and time saving for personal computers to take charge of the efficient evaluation on the complex reflective function of large-scope 2-D oceans, either in the monostatic or bistatic case. The sea surface is envisaged as a two-scale profile on which the long waves are locally approximated by planar facets. The microscopic profile within a facet is assumed to be represented by a set of sinusoidal ripple patches. The complex reflective function of each modified facet is evaluated by a modified formula of the original Bass and Fuks' two-scale model, in which the phase factor of each facet is with the capillary wave modification. Several examples with application to the frozen or time-evolving case are given to prove the implementation.","Sea surface,
Scattering,
Surface waves,
Computational modeling,
Decorrelation,
Backscatter"
Parallel Deblocking Filtering in MPEG-4 AVC/H.264 on Massively Parallel Architectures,"The deblocking filter in the MPEG-4 AVC/H.264 standard is computationally complex because of its high content adaptivity, resulting in a significant number of data dependencies. These data dependencies interfere with parallel filtering of multiple macroblocks (MBs) on massively parallel architectures. In this letter, we introduce a novel MB partitioning scheme for concurrent deblocking in the MPEG-4 AVC/H.264 standard, based on our idea of deblocking filter independency, a corrected version of the limited error propagation effect proposed in the letter. Our proposed scheme enables concurrent MB deblocking of luma samples with limited synchronization effort, independently of slice configuration, and is compliant with the MPEG-4 H.264/AVC standard. We implemented the method on the massively parallel architecture of the graphics processing unit (GPU). Experimental results show that our GPU implementation achieves faster-than real-time deblocking at 1309 frames per second for 1080p video pictures. Both software-based deblocking filters and state-of-the-art GPU-enabled algorithms are outperformed in terms of speed by factors up to 10.2 and 19.5, respectively, for 1080p video pictures.",
Optimization-Based Feedback Control for Pedestrian Evacuation From an Exit Corridor,"The evacuation of pedestrians is the most important task when a building is subjected to a significant level of threat that compromises occupant safety. However, very few studies have dealt with the problem of controlling pedestrian evacuation in real time. Due to modern developments in sensor technology and computational facilities, it now seems possible to attempt a real-time controlled evacuation by instructing pedestrians to adjust their velocities according to an algorithm to effect an efficient evacuation. This paper deals with the development of such a control algorithm for an exit corridor where high congestion can be expected during evacuation. To accommodate the possible variation in the pedestrian density along the length, the corridor is divided into several sections. Using the conservation of pedestrian mass, ordinary differential equations that define the pedestrian flow in all sections are developed. For the system of state-space equations that define the flow in all the sections of the corridor, an optimization-based feedback control scheme is developed, which ensures the maximum input discharge subject to tracking the critical state and boundedness of the control variables. Simulation results are obtained, which indicate the superior performance of the controlled flow over the uncontrolled flow. The proposed flow control is also applicable to the regulation of vehicular traffic on a long section of a freeway in urban areas that receives input at several ramps along its length.",
Shear Wave Velocity Imaging Using Transient Electrode Perturbation: Phantom and ex vivo Validation,"This paper presents a new shear wave velocity imaging technique to monitor radio-frequency and microwave ablation procedures, coined electrode vibration elastography. A piezoelectric actuator attached to an ablation needle is transiently vibrated to generate shear waves that are tracked at high frame rates. The time-to-peak algorithm is used to reconstruct the shear wave velocity and thereby the shear modulus variations. The feasibility of electrode vibration elastography is demonstrated using finite element models and ultrasound simulations, tissue-mimicking phantoms simulating fully (phantom 1) and partially ablated (phantom 2) regions, and an ex vivo bovine liver ablation experiment. In phantom experiments, good boundary delineation was observed. Shear wave velocity estimates were within 7% of mechanical measurements in phantom 1 and within 17% in phantom 2. Good boundary delineation was also demonstrated in the ex vivo experiment. The shear wave velocity estimates inside the ablated region were higher than mechanical testing estimates, but estimates in the untreated tissue were within 20% of mechanical measurements. A comparison of electrode vibration elastography and electrode displacement elastography showed the complementary information that they can provide. Electrode vibration elastography shows promise as an imaging modality that provides ablation boundary delineation and quantitative information during ablation procedures.","Phantoms,
Electrodes,
Materials,
Radio frequency,
Vibrations,
Ultrasonic imaging,
Ellipsoids"
Multi-robot path-planning using artificial bee colony optimization algorithm,"Path-planning is an interesting problem in mobile robotics. This paper proposes an alternative approach to path-planning of mobile robots using the artificial bee colony (ABC) optimization algorithm. The problem undertaken here attempts to determine the trajectory of motion of the robots from predefined starting positions to fixed goal positions in the world map with an ultimate objective to minimize the path length of all the robots. A local trajectory planning scheme has been developed with ABC optimization algorithm to optimally obtain the next positions of all the robots in the world map from their current positions, so that the paths to be developed locally for n-robots are sufficiently small with minimum spacing with the obstacles, if any, in the world map. Experiments reveal that the proposed optimization scheme outperforms two well-known algorithms with respect to standard metrics, called average total path deviation and average uncovered target distance.",
Single-Event Tolerant Flip-Flop Design in 40-nm Bulk CMOS Technology,"In this paper, the radiation response of a single-event tolerant flip-flop design named the Quatro flip-flop is presented. Circuit level simulations on the flip-flop design show 1) the critical charge of the sensitive nodes to be greater than that of DICE flip-flop, 2) the number of sensitive nodes and the sensitive area to be fewer than that of DICE flip-flop. A test-chip designed and fabricated at the 40-nm bulk CMOS technology node consisting of Quatro, DICE, and standard D- flip-flops was used for heavy-ions, neutrons, and alpha particles exposures. The experimental results demonstrate superior performance of the Quatro flip-flop design over conventional DICE and D-flip-flop designs.","Latches,
Neutrons,
Alpha particles,
CMOS integrated circuits,
Flip-flops,
Single event upset,
CMOS technology"
OS diversity for intrusion tolerance: Myth or reality?,"One of the key benefits of using intrusion-tolerant systems is the possibility of ensuring correct behavior in the presence of attacks and intrusions. These security gains are directly dependent on the components exhibiting failure diversity. To what extent failure diversity is observed in practical deployment depends on how diverse are the components that constitute the system. In this paper we present a study with operating systems (OS) vulnerability data from the NIST National Vulnerability Database. We have analyzed the vulnerabilities of 11 different OSes over a period of roughly 15 years, to check how many of these vulnerabilities occur in more than one OS. We found this number to be low for several combinations of OSes. Hence, our analysis provides a strong indication that building a system with diverse OSes may be a useful technique to improve its intrusion tolerance capabilities.","Security,
Databases,
Linux,
Driver circuits,
Kernel"
RECON: Scale-adaptive robust estimation via Residual Consensus,"In this paper, we present a novel, threshold-free robust estimation framework capable of efficiently fitting models to contaminated data. While RANSAC and its many variants have emerged as popular tools for robust estimation, their performance is largely dependent on the availability of a reasonable prior estimate of the inlier threshold. In this work, we aim to remove this threshold dependency. We build on the observation that models generated from uncontaminated minimal subsets are “consistent” in terms of the behavior of their residuals, while contaminated models exhibit uncorrelated behavior. By leveraging this observation, we then develop a very simple, yet effective algorithm that does not require apriori knowledge of either the scale of the noise, or the fraction of uncontaminated points. The resulting estimator, RECON (REsidual CONsensus), is capable of elegantly adapting to the contamination level of the data, and shows excellent performance even at low inlier ratios and high noise levels. We demonstrate the efficiency of our framework on a variety of challenging estimation problems.","Computational modeling,
Data models,
Estimation,
Robustness,
Silicon,
Noise,
Pollution measurement"
Multilevel polarization of polar codes over arbitrary discrete memoryless channels,"It is shown that the original construction of polar codes suffices to achieve the symmetric capacity of discrete memoryless channels with arbitrary input alphabet sizes. It is shown that in general, channel polarization happens in several, rather than only two, levels so that the synthesized channels are either useless, perfect or ""partially perfect"". Given a coset decomposition of the input alphabet, there exists a corresponding partially perfect channel whose outputs uniquely determine the coset where the channel input symbol belongs to. By a slight modification of the encoding and decoding rules, it is shown that perfect transmission of certain information letters over partially perfect channels is possible. It is also shown through an example that polar codes do not achieve the capacity of coset codes over arbitrary channels.","Decoding,
Channel capacity,
Encoding,
Bismuth,
Generators,
Vectors,
Random variables"
Design of Sequential Elements for Low Power Clocking System,"Power consumption is a major bottleneck of system performance and is listed as one of the top three challenges in International Technology Roadmap for Semiconductor 2008. In practice, a large portion of the on chip power is consumed by the clock system which is made of the clock distribution network and flop-flops. In this paper, various design techniques for a low power clocking system are surveyed. Among them is an effective way to reduce capacity of the clock load by minimizing number of clocked transistors. To approach this, we propose a novel clocked pair shared flip-flop which reduces the number of local clocked transistors by approximately 40%. A 24% reduction of clock driving power is achieved. In addition, low swing and double edge clocking, can be easily incorporated into the new flip-flop to build clocking systems.","Clocks,
Flip-flops,
Pulse amplifiers,
Master-slave,
System-on-a-chip,
Energy consumption,
System performance,
Network-on-a-chip,
Packaging"
Architecting on-chip interconnects for stacked 3D STT-RAM caches in CMPs,"Emerging memory technologies such as STT-RAM, PCRAM, and resistive RAM are being explored as potential replacements to existing on-chip caches or main memories for future multi-core architectures. This is due to the many attractive features these memory technologies posses: high density, low leakage, and non-volatility. However, the latency and energy overhead associated with the write operations of these emerging memories has become a major obstacle in their adoption. Previous works have proposed various circuit and architectural level solutions to mitigate the write overhead. In this paper, we study the integration of STT-RAM in a 3D multi-core environment and propose solutions at the on-chip network level to circumvent the write overhead problem in the cache architecture with STT-RAM technology. Our scheme is based on the observation that instead of staggering requests to a write-busy STT-RAM bank, the network should schedule requests to other idle cache banks for effectively hiding the latency. Thus, we prioritize cache accesses to the idle banks by delaying accesses to the STTRAM cache banks that are currently serving long latency write requests. Through a detailed characterization of the cache access patterns of 42 applications, we propose an efficient mechanism to facilitate such delayed writes to cache banks by (a) accurately estimating the busy time of each cache bank through logical partitioning of the cache layer and (b) prioritizing packets in a router requesting accesses to idle banks. Evaluations on a 3D architecture, consisting of 64 cores and 64 STT-RAM cache banks, show that our proposed approach provides 14% average IPC improvement for multi-threaded benchmarks, 19% instruction throughput benefits for multi-programmed workloads, and 6% latency reduction compared to a recently proposed write buffering mechanism.","Magnetic tunneling,
System-on-a-chip,
Computer architecture,
Phase change random access memory,
Resistance,
MOS devices"
Fast Approximate Max-n Monte Carlo Tree Search for Ms Pac-Man,"We present an application of Monte Carlo tree search (MCTS) for the game of Ms Pac-Man. Contrary to most applications of MCTS to date, Ms Pac-Man requires almost real-time decision making and does not have a natural end state. We approached the problem by performing Monte Carlo tree searches on a five player maxn tree representation of the game with limited tree search depth. We performed a number of experiments using both the MCTS game agents (for pacman and ghosts) and agents used in previous work (for ghosts). Performance-wise, our approach gets excellent scores, outperforming previous non-MCTS opponent approaches to the game by up to two orders of magnitude.",
Spike Latency Coding in Biologically Inspired Microelectronic Nose,"Recent theoretical and experimental findings suggest that biological olfactory systems utilize relative latencies or time-to-first spikes for fast odor recognition. These time-domain encoding methods exhibit reduced computational requirements and improved classification robustness. In this paper, we introduce a microcontroller-based electronic nose system using time-domain encoding schemes to achieve a power-efficient, compact, and robust gas identification system. A compact (4.5 cm × 5 cm × 2.2 cm) electronic nose, which is integrated with a tin-oxide gas-sensor array and capable of wireless communication with computers or mobile phones through Bluetooth, was implemented and characterized by using three different gases (ethanol, carbon monoxide, and hydrogen). During operation, the readout circuit digitizes the gas-sensor resistances into a concentration-independent spike timing pattern, which is unique for each individual gas. Both sensing and recognition operations have been successfully demonstrated in hardware. Two classification algorithms (rank order and spike distance) have been implemented. Both algorithms do not require any explicit knowledge of the gas concentration to achieve simplified training procedures, and exhibit comparable performances with conventional pattern-recognition algorithms while enabling hardware-friendly implementation.","Arrays,
Encoding,
Timing,
Gases,
Sensors,
Capacitors,
Sensitivity"
Color Extended Visual Cryptography Using Error Diffusion,"Color visual cryptography (VC) encrypts a color secret message into color halftone image shares. Previous methods in the literature show good results for black and white or gray scale VC schemes, however, they are not sufficient to be applied directly to color shares due to different color structures. Some methods for color visual cryptography are not satisfactory in terms of producing either meaningless shares or meaningful shares with low visual quality, leading to suspicion of encryption. This paper introduces the concept of visual information pixel (VIP) synchronization and error diffusion to attain a color visual cryptography encryption method that produces meaningful color shares with high visual quality. VIP synchronization retains the positions of pixels carrying visual information of original images throughout the color channels and error diffusion generates shares pleasant to human eyes. Comparisons with previous approaches show the superior performance of the new method.",
Regression from local features for viewpoint and pose estimation,"In this paper we propose a framework for learning a regression function form a set of local features in an image. The regression is learned from an embedded representation that reflects the local features and their spatial arrangement as well as enforces supervised manifold constraints on the data. We applied the approach for viewpoint estimation on a Multiview car dataset, a head pose dataset and arm posture dataset. The experimental results show that this approach has superior results (up to 67% improvement) to the state-of-the-art approaches in very challenging datasets.","Manifolds,
Kernel,
Training,
Estimation,
Accuracy,
Feature extraction,
Head"
Total variation regularization of local-global optical flow,"More data fidelity terms in variational optical flow methods improve the estimation's robustness. A robust and anisotropic smoother enhances the specific fill-in process. This work presents a combined local-global (CLG) approach with total variation regularization. The combination of bilateral filtering and anisotropic (image driven) regularization is used to control the propagation phenomena. The resulted method, CLG-TV, is able to compute larger displacements in a reasonable time. The numerical scheme is highly parallelizable and runs in real-time on current generation graphic processing units.",
Ripple: An effective routability-driven placer by iterative cell movement,"In this paper, we describe a routability-driven placer called Ripple. Two major techniques called cell inflation and net-based movement are used in global placement followed by a rough legalization step to reduce congestion. Cell inflation is performed in the horizontal and the vertical directions alternatively. We propose a new method called net-based movement, in which a target position is calculated for each cell by considering the movement of a net as a whole instead of working on each cell individually. In detailed placement, we use a combination of two kinds of strategy: the traditional HPWL-driven approach and our new congestion-driven approach. Experimental results show that Ripple is very effective in improving routability. Comparing with our pervious placer, which is the winner in the ISPD 2011 Contest, Ripple can further improve the overflow by 38% while reduce the runtime is reduced by 54%.","Routing,
Tiles,
Estimation,
Runtime,
Benchmark testing,
Equations,
Mathematical model"
Characterization and Design of Logic Circuits in the Presence of Carbon Nanotube Density Variations,"Variations in the spatial density of carbon nanotubes (CNTs), resulting from the lack of precise control over CNT positioning during chemical synthesis, is a major hurdle to the scalability of carbon nanotube field effect transistor (CNFET) circuits. Such CNT density variations can lead to non-functional CNFET circuits. This paper presents a probabilistic framework for modeling the CNT count distribution contained in a CNFET of given width, and establishes the accuracy of the model using experimental data obtained from CNT growth. Using this model, we estimate the impact of CNT density variations on the yield of CNFET very large-scale integrated circuits. Our estimation results demonstrate that CNT density variations can significantly degrade the yield of CNFETs, and can be a major concern for scaled CNFET circuits. Finally, we analyze the impact of CNT correlation (i.e., correlation of CNT count between CNFETs) that exists in CNT growth, and demonstrate how the yield of a CNFET storage circuit (primarily limited by its noise immunity) can be significantly improved by taking advantage of such correlation.","CNTFETs,
Integrated circuit modeling,
Correlation,
Dispersion,
Random variables,
Indexes,
Carbon nanotubes"
Review of pricing models for grid & cloud computing,"Distributed system resources have become prevalent in ICT departments to lessen the burden of huge expenses incurred by very expensive storage computer systems. Add to this the continuous introduction and ever-growing evolution of simple to complex applications, the demand to access huge quantities of data, intensive computations, powerful simulations, maintaining and offering system resources and middleware infrastructure services the need to do all of this at an affordable and reasonable price is crucial. Distributed grid and cloud computing resources are currently considered to be one of the best technology options to provide this. They have many similar features and functions, and both of them are classed as distributed systems. They are capable of offering unaffordable resources and services at a reasonable price in a mass marketplace. The big question is: what is a reasonable price? How is pricing modeled and on what kind of economic principles is it based? Much of the issues surrounding these questions are very complex in themselves. This paper provides a comparative review of grid and cloud computing economic and pricing models from which appropriate tariffs and charging models can be chosen to meet particular business objectives. The actual choice depends on many other factors like enterprise regulations, tax laws, service level agreements and return on investments, are very important but outside the scope of this paper. In this paper we give the basic core principles and a comparative review of the latest and most appropriate economic and pricing models applicable to grid and cloud computing in order to propose better models for the future.","Biological system modeling,
Pricing,
Computational modeling,
Cloud computing,
Grid computing,
Economics,
Software"
On the design and implementation of a home energy management system,"To reduce energy consumption and wastage, effective energy management at home is key and an integral part of the future Smart Grid. In this paper, we present the design and implementation of Green Home Service (GHS) for home energy management. Our approach addresses the key issues of home energy management in Smart Grid: a holistic management solution, improved device manageability, and an enabler of Demand-Response. We also present the scheduling algorithms in GHS for smart energy management and show the results in simulation studies.","Energy management,
Home appliances,
Monitoring,
Protocols,
Delay,
Servers,
Smart grids"
A Detailed Analytical Model of a Salient-Pole Synchronous Generator Under Dynamic Eccentricity Fault,"In this paper, a new detailed analytical model of a salient-pole synchronous generator (SPSG) under dynamic eccentricity (DE) is presented which is capable of accounting for the effects of magnetic saturation, rotor pole shoe saliency, and space distribution of stator phases and rotor winding. A real form of rotor pole shoes is taken into account in the proposed SPSG air-gap function distribution. Saturation effects incorporate into the air-gap function of SPSG as a simple proposed analytic equation that varies by the generator load and operating condition. Furthermore, variation of the resulted air-gap distribution of SPSG in the presence of DE fault is then computed precisely and the inverse air-gap function calculated using Fourier series in order to compute time varying self- and mutual-inductances of stator phases and rotor winding via the modified winding function approach (MWFA). The computed inductances are used for simulation of SPSG and studying the frequency spectrum of stator line current in the presence of DE fault. It is shown that the results of proposed model are closer to the finite-element (FE) computation results compared to the available analytic models.","Rotors,
Stator windings,
Atmospheric modeling,
Windings,
Analytical models,
Circuit faults"
Link prediction by de-anonymization: How We Won the Kaggle Social Network Challenge,"This paper describes the winning entry to the IJCNN 2011 Social Network Challenge run by Kaggle.com. The goal of the contest was to promote research on real-world link prediction, and the dataset was a graph obtained by crawling the popular Flickr social photo sharing website, with user identities scrubbed. By de-anonymizing much of the competition test set using our own Flickr crawl, we were able to effectively game the competition. Our attack represents a new application of de-anonymization to gaming machine learning contests, suggesting changes in how future competitions should be run. We introduce a new simulated annealing-based weighted graph matching algorithm for the seeding step of de-anonymization. We also show how to combine de-anonymization with link prediction-the latter is required to achieve good performance on the portion of the test set not de-anonymized-for example by training the predictor on the de-anonymized portion of the test set, and combining probabilistic predictions from de-anonymization and link prediction.",
A Modified Binary Particle Swarm Optimization for Selecting the Small Subset of Informative Genes From Gene Expression Data,"Gene expression data are expected to be of significant help in the development of efficient cancer diagnoses and classification platforms. In order to select a small subset of informative genes from the data for cancer classification, recently, many researchers are analyzing gene expression data using various computational intelligence methods. However, due to the small number of samples compared to the huge number of genes (high dimension), irrelevant genes, and noisy genes, many of the computational methods face difficulties to select the small subset. Thus, we propose an improved (modified) binary particle swarm optimization to select the small subset of informative genes that is relevant for the cancer classification. In this proposed method, we introduce particles' speed for giving the rate at which a particle changes its position, and we propose a rule for updating particle's positions. By performing experiments on ten different gene expression datasets, we have found that the performance of the proposed method is superior to other previous related works, including the conventional version of binary particle swarm optimization (BPSO) in terms of classification accuracy and the number of selected genes. The proposed method also produces lower running times compared to BPSO.","Gene expression,
Cancer,
Mathematical model,
Particle swarm optimization,
Noise measurement"
Linear Precoding for MIMO Multiple Access Channels with Finite Discrete Inputs,"In this paper, we study linear precoding for multiple-input multiple-output (MIMO) multiple access channels (MAC) with finite discrete inputs. We derive the constellation-constrained capacity region for the MIMO MAC with an arbitrary number of users and find that the boundary can be achieved by solving the problem of weighted sum rate maximization with constellation and individual power constraints. Due to the non-concavity of the objective function, we obtain a set of necessary conditions for the optimization problem through Karush-Kuhn-Tucker analysis. To find the optimal precoding matrices for all users, we propose an iterative algorithm utilizing alternating optimization strategy. In particular, each iteration of the algorithm involves the gradient descent update with backtracking line search. Numerical results show that when inputs are digital modulated signals and the signal-to-noise ratio is in the medium range, our proposed algorithm offers considerably higher sum rate than non-precoding and the traditional method which maximizes Gaussian-input sum capacity. Furthermore, a low-density parity-check coded system with iterative detection and decoding for MAC is presented to evaluate the bit error rate (BER) performance of precoders. BER results also indicate that the system with the proposed linear precoder achieves significant gains over the non-precoding system and the precoder designed for Gaussian inputs.",
Unified Development of Multiplicative Algorithms for Linear and Quadratic Nonnegative Matrix Factorization,"Multiplicative updates have been widely used in approximative nonnegative matrix factorization (NMF) optimization because they are convenient to deploy. Their convergence proof is usually based on the minimization of an auxiliary upper-bounding function, the construction of which however remains specific and only available for limited types of dissimilarity measures. Here we make significant progress in developing convergent multiplicative algorithms for NMF. First, we propose a general approach to derive the auxiliary function for a wide variety of NMF problems, as long as the approximation objective can be expressed as a finite sum of monomials with real exponents. Multiplicative algorithms with theoretical guarantee of monotonically decreasing objective function sequence can thus be obtained. The solutions of NMF based on most commonly used dissimilarity measures such as α - and β-divergence as well as many other more comprehensive divergences can be derived by the new unified principle. Second, our method is extended to a nonseparable case that includes e.g., γ-divergence and Rényi divergence. Third, we develop multiplicative algorithms for NMF using second-order approximative factorizations, in which each factorizing matrix may appear twice. Preliminary numerical experiments demonstrate that the multiplicative algorithms developed using the proposed procedure can achieve satisfactory Karush-Kuhn-Tucker optimality. We also demonstrate NMF problems where algorithms by the conventional method fail to guarantee descent at each iteration but those by our principle are immune to such violation.",
A Multi-Agent Memetic System for Human-Based Knowledge Selection,"In these last decades, both industrial and academic organizations have used extensively different learning methods to improve humans' capabilities and, as consequence, their overall performance and competitiveness in the new economy context. However, the rapid change in modern knowledge due to exponential growth of information sources is complicating learners' activity. At the same time, new technologies offer, if used in a right way, a range of possibilities for the efficient design of learning scenarios. For that reason, novel approaches are necessary to obtain suitable learning solutions which are able to generate efficient, personalized, and flexible learning experiences. From this point of view, computational intelligence methodologies can be exploited to provide efficient and intelligent tools to be able to analyze learner's needs and preferences and, consequently, personalize its knowledge acquirement. This paper reports an attempt to achieve these results by exploiting an ontological representation of learning environment and an adaptive memetic approach, integrated into a cooperative multi-agent framework. In particular, a collection of agents analyzes learner preferences and generate high-quality learning presentations by executing, in a parallel way, different cooperating optimization strategies. This cooperation is performed by jointly exploiting data mining via fuzzy decision trees, together with a decision-making framework exploiting fuzzy methodologies.","Electronic learning,
Memetics,
Optimization,
Ontologies,
Vocabulary,
Internet"
Discriminative figure-centric models for joint action localization and recognition,"In this paper we develop an algorithm for action recognition and localization in videos. The algorithm uses a figure-centric visual word representation. Different from previous approaches it does not require reliable human detection and tracking as input. Instead, the person location is treated as a latent variable that is inferred simultaneously with action recognition. A spatial model for an action is learned in a discriminative fashion under a figure-centric representation. Temporal smoothness over video sequences is also enforced. We present results on the UCF-Sports dataset, verifying the effectiveness of our model in situations where detection and tracking of individuals is challenging.","Videos,
Loss measurement,
Humans,
Detectors,
Vectors,
Shape,
Training"
High-Temperature SiC Power Module Electrical Evaluation Procedure,"To take full advantage of silicon carbide semiconductor devices, high-temperature device packaging needs to be developed. This paper describes potential defects from design and fabrication procedures, and presents a systematic electrical evaluation process to detect such defects. This systematic testing procedure can rapidly detect many defects and reduce the risk in high-temperature packaging testing. A multichip module development procedure that uses this testing procedure is also presented and demonstrated with an example.","Multichip modules,
Silicon carbide,
Heating,
Soldering,
Layout"
A Stratified Approach for Camera Calibration Using Spheres,"This paper proposes a stratified approach for camera calibration using spheres. Previous works have exploited epipolar tangents to locate frontier points on spheres for estimating the epipolar geometry. It is shown in this paper that other than the frontier points, two additional point features can be obtained by considering the bitangent envelopes of a pair of spheres. A simple method for locating the images of such point features and the sphere centers is presented. An algorithm for recovering the fundamental matrix in a plane plus parallax representation using these recovered image points and the epipolar tangents from three spheres is developed. A new formulation of the absolute dual quadric as a cone tangent to a dual sphere with the plane at infinity being its vertex is derived. This allows the recovery of the absolute dual quadric, which is used to upgrade the weak calibration to a full calibration. Experimental results on both synthetic and real data are presented, which demonstrate the feasibility and the high precision achieved by our proposed algorithm.",
On the Frequent Acquisition of Small Data Through RACH in UMTS for ITS Applications,"Wireless communications are currently considered the most promising solutions to provide real-time traffic information, suggest alternative routes, and help to reduce congestion. These new services are all based on the real-time acquisition of traffic information directly from vehicles, which act as sensors that travel on the roads. With the idea of having new widespread and real-time infomobility services in the short-medium term, neither installations onboard nor new roadside infrastructures that have been set up can be taken into account. Hence, in this paper, we aim at verifying the feasibility of the real-time acquisition of traffic information from vehicles in dense areas through the universal mobile telecommunication system (UMTS). In particular, we first analytically evaluate the capacity and the coverage of a UMTS cell when multiple users frequently transmit their traffic measurements to a remote control center through a shared (common) channel. Then, we extend our results to a realistic urban scenario by investigating, through simulations, the feasibility of the service and its impact on the quality of service (QoS) perceived by other users (e.g., voice).","Vehicles,
3G mobile communication,
Real time systems,
Analytical models,
Interference,
Quality of service,
Pollution measurement"
Causal Inference on Discrete Data Using Additive Noise Models,"Inferring the causal structure of a set of random variables from a finite sample of the joint distribution is an important problem in science. The case of two random variables is particularly challenging since no (conditional) independences can be exploited. Recent methods that are based on additive noise models suggest the following principle: Whenever the joint distribution P(X,Y) admits such a model in one direction, e.g., Y = f(X)+N, N ⊥X, but does not admit the reversed model X=g(Y)+Ñ, Ñ ⊥ Y, one infers the former direction to be causal (i.e., X → Y). Up to now, these approaches only dealt with continuous variables. In many situations, however, the variables of interest are discrete or even have only finitely many states. In this work, we extend the notion of additive noise models to these cases. We prove that it almost never occurs that additive noise models can be fit in both directions. We further propose an efficient algorithm that is able to perform this way of causal inference on finite samples of discrete variables. We show that the algorithm works on both synthetic and real data sets.","Regression analysis,
Additive noise,
Random variables,
Mathematical model,
Markov processes,
Inference algorithms"
Atomic norm denoising with applications to line spectral estimation,"The sub-Nyquist estimation of line spectra is a classical problem in signal processing, but currently popular subspace-based techniques have few guarantees in the presence of noise and rely on a priori knowledge about system model order. Motivated by recent work on atomic norms in inverse problems, we propose a new approach to line spectrum estimation that provides theoretical guarantees for the mean-square-error performance in the presence of noise and without advance knowledge of the model order. We propose an abstract theory of denoising with atomic norms which is specialized to provide a convex optimization problem for estimating the frequencies and phases of a mixture of complex exponentials with guaranteed bounds on the mean-squared-error. In general, our proposed optimization problem has no known polynomial time solution, but we provide an efficient algorithm, called DAST, based on the Fast Fourier Transform that achieves nearly the same error rate. We compare DAST with Cadzow's canonical alternating projection algorithm, which performs marginally better under high signal-to-noise ratios when the model order is known exactly, and demonstrate experimentally that DAST outperforms other denoising techniques, including Cadzow's, over a wide range of signal-to-noise ratios.","Noise reduction,
Estimation,
Optimization,
Polynomials,
Atomic clocks,
Signal to noise ratio"
Improving Performance of Hybrid Active Noise Control Systems for Uncorrelated Narrowband Disturbances,"In filtered-x LMS (FxLMS) single-channel feedforward active noise control (ANC) systems, a reference signal is available that is correlated with the primary disturbance at the error microphone. In some practical situations, there may also be a disturbance uncorrelated with the primary disturbance at the error microphone, for which a correlated reference signal is not available. This disturbance, being uncorrelated with the primary noise, cannot be controlled by the standard FxLMS algorithm, and increases the residual noise. In this paper we propose an improved hybrid ANC system that can simultaneously control both the correlated and uncorrelated noise signals. The proposed method comprises three adaptive filters: 1) the FxLMS-based ANC filter to cancel the primary noise; 2) a separate FxLMS-based ANC filter to cancel the uncorrelated disturbance; and 3) an LMS-based supporting adaptive filter to generate appropriate signals for the two ANC filters. Computer simulations demonstrate that the proposed method can effectively mitigate the correlated and uncorrelated primary disturbances. This improved performance is achieved at only a small increase in computational complexity.",
"A convex, smooth and invertible contact model for trajectory optimization","Trajectory optimization is done most efficiently when an inverse dynamics model is available. Here we develop the first model of contact dynamics defined in both the forward and inverse directions. The contact impulse is the solution to a convex optimization problem: minimize kinetic energy in contact space subject to non-penetration and friction-cone constraints. We use a custom interior-point method to make the optimization problem unconstrained; this is key to defining the forward and inverse dynamics in a consistent way. The resulting model has a parameter which sets the amount of contact smoothing, facilitating continuation methods for optimization. We implemented the proposed contact solver in our new physics engine (MuJoCo). A full Newton step of trajectory optimization for a 3D walking gait takes only 160 msec, on a 12-core PC.",
Biometric-based two-level secure access control for Implantable Medical Devices during emergencies,"Implantable Medical Devices (IMDs) are widely used to treat chronic diseases. Nowadays, many IMDs can wirelessly communicate with an outside programmer (reader). However, the wireless access also introduces security concerns. An attacker may get an IMD reader and gain access to a patient's IMD. IMD security is an important issue since attacks on IMDs may directly harm the patient. A number of research groups have studied IMD security issues when the patient is in nonemergency situations. However, these security schemes usually require the patient's participation, and they may not work during emergencies (e.g., when the patient is in comma) for various reasons. In this paper, we propose a light-weight secure access control scheme for IMDs during emergencies. Our scheme utilizes patient's biometric information to prevent unauthorized access to IMDs. The scheme consists of two levels: level 1 employs some basic biometric information of the patient and it is lightweight; level 2 utilizes patients' iris data for authentication and it is very effective. In this research, we also make contributions in human iris verification: we discover that it is possible to perform iris verification by comparing partial iris data rather than the entire iris data. This significantly reduces the overhead of iris verification, which is critical for resource-limited IMDs. We evaluate the performance of our schemes by using real iris data sets. Our experimental results show that the secure access control scheme is very effective and has small overhead (hence feasible for IMDs). Specifically, the false acceptance rate (FAR) and false rejection rate (FRR) of our secure access control scheme are close to 0.000% with suitable threshold, and the memory and computation overheads are acceptable. Our analysis shows that the secure access control scheme reduces computation overhead by an average of 58%.",
Throughput Optimization in Cooperative Communications Based on Incremental Relaying,"In wireless networks, designing transmission schemes that can adapt to time-varying channel conditions is key to improving spectral efficiency. However, the realization of such schemes for multihop wireless networks is challenging, owing to the requirement of coordination among nodes. As coordination through the use of feedback between nodes incurs significant bandwidth penalty, spectral efficiency can be improved by minimizing traffic in the feedback channel. This paper proposes an adaptive rate transmission scheme using incremental-redundancy-based cooperative coding that minimizes the required feedback. By exploiting the inherent implicit feedback channel during relaying, the spectral efficiency of multihop wireless networks can be improved considerably. Rather than allocating dedicated channels to feedback the quality of information at the relay, the implicit feedback channel measures such information and determines the transmitter for the additional coded (redundancy) bits. This optimizes the throughput. The proposed scheme is thoroughly analyzed under different deployment environments. Theoretical bounds for the proposed scheme are presented and supported with results from extensive simulation studies.","Relays,
Tin,
Decoding,
Signal to noise ratio,
Redundancy,
Bit error rate"
Understanding the performance of thin-client gaming,"The thin-client model is considered a good fit for online gaming. As modern games normally require tremendous computing and rendering power at the game client, deploying games with such models can transfer the burden of hardware upgrades from players to game operators. As a result, there are a variety of solutions proposed for thin-client gaming today. However, little is known about the performance of such thin-client systems in different scenarios, and there is no systematic means yet to conduct such analysis. In this paper, we propose a methodology for quantifying the performance of thin-clients on gaming, even for thin-clients which are close-sourced. Taking a classic game, Ms. Pac-Man, and three popular thin-clients, LogMeIn, TeamViewer, and UltraVNC, as examples, we perform a demonstration study and determine that 1) display frame rate and frame distortion are both critical to gaming; and 2) different thin-client implementations may have very different levels of robustness against network impairments. Generally, LogMeIn performs best when network conditions are reasonably good, while TeamViewer and UltraVNC are the better choices under certain network conditions.","Games,
Predictive models,
Delay,
Servers,
Bandwidth,
Computational modeling"
LEGION-Based Automatic Road Extraction From Satellite Imagery,"An automatic method for road extraction from satellite imagery is presented. The core of the proposed method is locally excitatory globally inhibitory oscillator networks (LEGION). The road extraction task is decomposed into three stages. The first stage is image segmentation by LEGION. In the second stage, the medial axis of each segment is computed, and the medial axis points corresponding to narrow regions are selected. The third is the road grouping stage. Alignment-dependent connections between selected points are established, and LEGION is utilized to group well-aligned points, which represent the extracted roads. Due to the selective gating mechanism of LEGION, different roads in an image are grouped separately. Road extraction results on synthetic and real images are presented. A comparison with other methods shows that the proposed method produces very competitive extraction results.",
Flight control for target seeking by 13 gram ornithopter,"Recent advances in small-scale flapping-wing micro aerial vehicles have extended the capabilities of flight control for a number of applications, such as intelligence, surveillance, and reconnaissance activities. In this work, we demonstrate autonomous flight control of a 13 gram ornithopter capable of flying toward a target without remote assistance. For autonomous flight control, we developed 1.0 gram control electronics integrated with a microcontroller, inertial and visual sensors, communication electronics, and motor drivers. We also developed a simplified aerodynamic model of ornithopter flight to reduce the order of the control system. With the aerodynamic model and the orientation estimation from on-board inertial sensors, we present flight control of an ornithopter capable of flying toward a target using onboard sensing and computation only. To this end, we developed a dead-reckoning algorithm to recover from the temporary loss of the target which can occur with a visual sensor with a narrow field of view. As a result, the 28 cm wing-span ornithopter flying toward a target landed within a radius of 0.5 m from the target with more than 85% success (N = 20).","Cameras,
Sensors,
Propellers,
Aerodynamics,
Force,
Vehicles,
Dead reckoning"
Integrated Photonics for Low-Power Packet Networking,"Communications interconnects and networks will continue to play a large role in contributing to the global carbon footprint, especially in data center and cloud-computing applications exponential growth in capacity. Key to maximizing the benefits of photonics technology is highly functional, lower power, and large-scale photonics integration. In this paper, we report on the latest advances in the photonic integration technologies used for asynchronous optical packet switching using an example photonic integrated switched optical router, the label switched optical router architecture. We report measurements of the power consumed by the photonic circuits in performing their intended function, the electronics required to bias the photonics, processing electronics, and required cooling technology. Data is presented to show that there is room (potentially greater than 10 ×) for improvement in the router packet-forwarding plane. The purpose of this exercise is not to provide a comparison of all-optical versus electronic routers, rather to present a data point on actual measurements of the power contributions for various photonic integration technologies of an all-optical packet router that has been demonstrated and conclude, where the technology can move to reduce power consumption for high-capacity packet routing systems.","Photonics,
Optical switches,
Optical packet switching,
Integrated optics,
Optical buffering,
Optical device fabrication,
Bit rate"
Determining the minimal number of lines for large reversible circuits,"Synthesis of reversible circuits is an active research area motivated by its applications e.g. in quantum computation or low-power design. The number of used circuit lines is thereby a crucial criterion. In this paper, we introduce several methods (including a theoretical upper bound) for the efficient computation or at least approximation of the minimal number of lines needed to realize a given function in reversible logic. While the proposed exact approach requires a significant amount of run-time (exponential in the worst case), the heuristic methods lead to very precise approximations in very short run-time. Using this, it can be shown that current synthesis approaches for large functions are still far away from producing optimal circuits with respect to the number of lines.",
Characterization of a high temperature multichip SiC JFET-based module,"This paper presents a SiC JFET-based, 200°C, 50 kW three-phase inverter module and evaluates its electrical performance. With 1200 V, 100 A rating of the module, each switching element is composed of four paralleled SiC JFETs with two anti-parallel SiC Shottky Barrier Diodes (SBDs). The substrate layout inside the module is designed to reduce package parasitics. Then, experimental static characteristics of the module are obtained over a wide range of temperature, and low on-state resistance is shown up to 200°C. The dynamic performance of this module is evaluated by double pulse test up to 150°C, under 650 V dc bus voltage and 60 A drain current, with different turn-on and turn-off gate resistances. The current unbalance phenomenon and phase-leg shoot-through problem are analyzed too. The results by simulation and experiments show that the causes of shoot-through are JFET inside parameters, package parasitics, and high temperature. The switching losses of this module at different temperatures are shown at the end.","JFETs,
Silicon carbide,
Logic gates,
Switches,
Temperature,
Transient analysis,
Resistance"
Adaptive Object Tracking by Learning Hybrid Template Online,"This paper presents an adaptive tracking algorithm by learning hybrid object templates online in video. The templates consist of multiple types of features, each of which describes one specific appearance structure, such as flatness, texture, or edge/corner. Our proposed solution consists of three aspects. First, in order to make the features of different types comparable with each other, a unified statistical measure is defined to select the most informative features to construct the hybrid template. Second, we propose a simple yet powerful generative model for representing objects. This model is characterized by its simplicity since it could be efficiently learnt from the currently observed frames. Last, we present an iterative procedure to learn the object template from the currently observed frames, and to locate every feature of the object template within the observed frames. The former step is referred to as feature pursuit, and the latter step is referred to as feature alignment, both of which are performed over a batch of observations. We fuse the results of feature alignment to locate objects within frames. The proposed solution to object tracking is in essence robust against various challenges, including background clutters, low-resolution, scale changes, and severe occlusions. Extensive experiments are conducted over several publicly available databases and the results with comparisons show that our tracking algorithm clearly outperforms the state-of-the-art methods.","Bismuth,
Matching pursuit algorithms,
Target tracking,
Feature extraction,
Visualization,
Image color analysis"
Study of Conducted EMI Reduction for Three-Phase Active Front-End Rectifier,"The problem of electromagnetic interference (EMI) plays an important role in the design of power electronic converters, especially for airplane electrical systems. This paper explores techniques to reduce EMI noise in three-phase active front-end rectifier. The Vienna-type rectifier is used as the object. The design approach introduced in this paper is using a high-density EMI filter to satisfy the EMI standard. Design methodology is introduced in the paper by a three-stage LC- LC-L filter structure. In particular, the cause of high noise at high frequencies is studied in experiments, and the coupling effect of the final-stage capacitor and inductors is investigated. In order to reduce the EMI noise in the mid-frequency range, the application of random pulsewidth modulation (PWM) is also presented. The performance of random PWM in a Vienna-type rectifier is verified by theoretical analysis and experimental results. The approaches discussed in this paper significantly reduce the EMI noise in the Vienna-type rectifier, and therefore, the filter size can also be reduced.",
Adaptive Multiwavelet-Based Watermarking Through JPW Masking,"In this paper, a multibit, multiplicative, spread spectrum watermarking using the discrete multiwavelet (including unbalanced and balanced multiwavelet) transform is presented. Performance improvement with respect to existing algorithm is obtained by means of a new just perceptual weighting (JPW) model. The new model incorporates various masking effects of human visual perception by taking into account the eye's sensitivity to noise changes depending on spatial frequency, luminance and texture of all the image subbands. In contrast to conventional JND threshold model, JPW describing minimum perceptual sensitivity weighting to noise changes, is fitter for nonadditive watermarking. Specifically, watermarking strength is adaptively adjusted to obtain minimum perceptual distortion by employing the JPW model. Correspondingly, an adaptive optimum decoding is derived using a statistic model based on generalized-Gaussian distribution (GGD) for multiwavelet coefficients of the cover-image. Furthermore, the impact of multiwavelet characteristics on proposed watermarking scheme is also analyzed. Finally, the experimental results show that proposed JPW model can improve the quality of the watermarked image and give more robustness of the watermark as compared with a variety of state-of-the-art algorithms.","Watermarking,
Noise,
Robustness,
Wavelet transforms,
Adaptation model,
Sensitivity"
Extracting foreground masks towards object recognition,"Effective segmentation prior to recognition has been shown to improve recognition performance. However, most segmentation algorithms adopt methods which are not explicitly linked to the goal of object recognition. Here we solve a related but slightly different problem in order to assist object recognition more directly - the extraction of a foreground mask, which identifies the locations of objects in the image. We propose a novel foreground/background segmentation algorithm that attempts to segment the interesting objects from the rest of the image, while maximizing an objective function which is tightly related to object recognition. We do this in a manner which requires no class-specific knowledge of object categories, using a probabilistic formulation which is derived from manually segmented images. The model includes a geometric prior and an appearance prior, whose parameters are learnt on the fly from images that are similar to the query image. We use graph-cut based energy minimization to enforce spatial coherence on the model's output. The method is tested on the challenging VOC09 and VOC10 segmentation datasets, achieving excellent results in providing a foreground mask. We also provide comparisons to the recent segmentation method of [7].","Image segmentation,
Training,
Visualization,
Object recognition,
Approximation methods,
Kernel,
Layout"
Image segmentation by figure-ground composition into maximal cliques,"We propose a mid-level statistical model for image segmentation that composes multiple figure-ground hypotheses (FG) obtained by applying constraints at different locations and scales, into larger interpretations (tilings) of the entire image. Inference is cast as optimization over sets of maximal cliques sampled from a graph connecting all non-overlapping figure-ground segment hypotheses. Potential functions over cliques combine unary, Gestalt-based figure qualities, and pairwise compatibilities among spatially neighboring segments, constrained by T-junctions and the boundary interface statistics of real scenes. Learning the model parameters is based on maximum likelihood, alternating between sampling image tilings and optimizing their potential function parameters. State of the art results are reported on the Berkeley and Stanford segmentation datasets, as well as VOC2009, where a 28% improvement was achieved.","Image segmentation,
Computational modeling,
Junctions,
Image edge detection,
Optimization,
Approximation methods,
Complexity theory"
Active Volume Models for Medical Image Segmentation,"In this paper, we propose a novel predictive model, active volume model (AVM), for object boundary extraction. It is a dynamic “object” model whose manifestation includes a deformable curve or surface representing a shape, a volumetric interior carrying appearance statistics, and an embedded classifier that separates object from background based on current feature information. The model focuses on an accurate representation of the foreground object's attributes, and does not explicitly represent the background. As we will show, however, the model is capable of reasoning about the background statistics thus can detect when is change sufficient to invoke a boundary decision. When applied to object segmentation, the model alternates between two basic operations: 1) deforming according to current region of interest (ROI), which is a binary mask representing the object region predicted by the current model, and 2) predicting ROI according to current appearance statistics of the model. To further improve robustness and accuracy when segmenting multiple objects or an object with multiple parts, we also propose multiple-surface active volume model (MSAVM), which consists of several single-surface AVM models subject to high-level geometric spatial constraints. An AVM's deformation is derived from a linear system based on finite element method (FEM). To keep the model's surface triangulation optimized, surface remeshing is derived from another linear system based on Laplacian mesh optimization (LMO) , . Thus efficient optimization and fast convergence of the model are achieved by solving two linear systems. Segmentation, validation and comparison results are presented from experiments on a variety of 2-D and 3-D medical images.",
Wavelet-Based Reactive Power and Energy Measurement in the Presence of Power Quality Disturbances,"This paper investigates the performance of electronic reactive power/energy meters by evaluating differences that arise as a result of (1) the distinct operating principles of the meter and (2) the presence of stationary and nonstationary power quality disturbances. The paper also includes a comparative study to determine the effectiveness of using orthogonal, bi-orthogonal, or reverse bi-orthogonal wavelets for such application. Moreover, the paper identifies the reactive power quantities required for accurate assessment and monitoring of reactive energy in the presence of power quality disturbances. Finally, the paper provides recommendations on reactive power and energy measurement for future generations of smart meters.","Reactive power,
Wavelet transforms,
Energy measurement,
Wavelet analysis,
Power measurement,
Power quality"
TOFU: Semi-Truthful Online Frequency Allocation Mechanism for Wireless Networks,"In wireless networks, we need to allocate spectrum efficiently. One challenge is that the spectrum usage requests often come in an online fashion. The second challenge is that the secondary users in a cognitive radio network are often selfish and prefer to maximize their own benefits. In this paper, we address these two challenges by proposing TOFU, a semi-truthful online frequency allocation method for wireless networks when primary users can sublease the spectrums to secondary users. In our protocol, secondary users are required to submit the spectrum bid α time slots before its usage. Upon receiving an online spectrum request, our protocol will decide whether to grant its exclusive usage or not, within at least γ time slots of requests' arrival. We assume that existing spectrum usage can be preempted with some compensation. For various possible known information, we analytically prove that the competitive ratios of our methods are within small constant factors of the optimum online method. Furthermore, in our mechanisms, no selfish users will gain benefits by bidding lower than their willing payment. Our extensive simulation results show that they perform almost optimum: Our methods get a total profit that is more than 95% of the offline optimum when γ is about the duration of spectrum usage Δ.","Resource management,
Upper bound,
Wireless networks,
Delay,
Protocols,
Algorithm design and analysis,
Radio spectrum management"
A Multiple-Input Boost Converter for Low-Power Energy Harvesting,"In this paper, a component efficient multiple-input boost converter is proposed to extract power from multiple low-power energy harvesting sources. The time-multiplexed operation of the proposed converter enables sharing of the power stage between different input sources, leading to a reduced component count. Combined with a novel digital control method and a universal tracking algorithm, maximum power is automatically extracted for all the input sources. A dual-input prototype built with off-the-shelf components validates the overall strategy with commercially available energy transducers. A tracking efficiency of more than 97.5% is demonstrated.",
Joint Sensing-Channel Selection and Power Control for Cognitive Radios,"We consider joint optimization for sensing-channel selection and ensuing power control problem with cognitive radios over time-varying fading channels. It is shown that this joint design can be judiciously formulated as a convex optimization problem. Optimal joint sensing-channel selection and power control scheme is then derived in closed-form under the constraints of average power budget and maximum allowable probability of collisions with the primary communications. In addition, we develop a stochastic optimization algorithm that can operate without a-priori knowledge of the fading channel statistics. It is rigourously established that the proposed stochastic scheme is capable of dynamically learning the intended wireless channels on-the-fly to approach the optimal strategy almost surely. Numerous results are also provided to evaluate the proposed schemes for cognitive transmissions over block fading channels.","Sensors,
Fading,
Joints,
Power control,
Cognitive radio,
Optimization,
Wireless sensor networks"
On the Temporal Granularity in Fuzzy Cognitive Maps,"The theory of fuzzy cognitive maps (FCMs) is a powerful approach to modeling human knowledge that is based on causal reasoning. Taking advantage of fuzzy logic and cognitive map theories, FCMs enable system designers to model complex frameworks by defining degrees of causality between causal objects. They can be used to model and represent the behavior of simple and complex systems by capturing and emulating the human being to describe and present systems in terms of tolerance, imprecision, and granulation of information. However, FCMs lack the temporal concept that is crucial in many real-world applications, and they do not offer formal mechanisms to verify the behavior of systems being represented, which limit conventional FCMs in knowledge representation. In this paper, we present an extension to FCMs by exploiting a theory from formal languages, namely, the timed automata, which bridges the aforementioned inadequacies. Indeed, the theory of timed automata enables FCMs to effectively deal with a double-layered temporal granularity, extending the standard idea of B-time that characterizes the iterative nature of a cognitive inference engine and offering model checking techniques to test the cognitive and dynamic comportment of the framework being designed.",
Design and Implementation of Fully Integrated Digitally Controlled Current-Mode Buck Converter,"Digital current-mode control is a dual-loop control which potentially results in a better transient response and thus is more favorable than voltage-mode control. There are only a few publications on how to design and implement a fully integrated digital controller as the on-chip implementation is very challenging, especially for current-mode control. This paper addresses those design challenges and considerations. One of the main challenges is to efficiently sample and quantize both the output voltage and inductor current of the buck converter for control purposes. A time-multiplex scheme is used for the control-loop which enables the converter to work with a single ADC. A modified delay-lock-loop DPWM has been developed for minimizing the mismatch of the delay-cells. This enhances the accuracy at high frequency to prevent limit-cycle. A new algorithm has also been proposed for implementing look-up-table digital compensators with 20% less chip area. A converter with the fully integrated digitally controlled loop, including the single ADC, digital compensators and DPWM, has been fabricated in a CMOS 0.35 μ m process with a chip area of 1049 μm × 1533 μm. Measurement results show that the buck converter has a load transient response of 20 μs, which is one of the fastest compared to other state-of-the-art digitally controlled buck converter.","Clocks,
Quantization,
Inductors,
Converters,
Synchronization,
Integrated circuits,
Voltage control"
Impact of Process Variations on SRAM Single Event Upsets,Process variations affect the single event (SE) hardness of SRAM cells. Monte-Carlo simulations show this effect and can be used to quantify the significance of process parameter shifts on SRAM SE upset probabilities.,
The misuse of the NASA metrics data program data sets for automated software defect prediction,"Background: The NASA Metrics Data Program data sets have been heavily used in software defect prediction experiments. Aim: To demonstrate and explain why these data sets require significant pre-processing in order to be suitable for defect prediction. Method: A meticulously documented data cleansing process involving all 13 of the original NASA data sets. Results: Post our novel data cleansing process; each of the data sets had between 6 to 90 percent less of their original number of recorded values. Conclusions: One: Researchers need to analyse the data that forms the basis of their findings in the context of how it will be used. Two: Defect prediction data sets could benefit from lower level code metrics in addition to those more commonly used, as these will help to distinguish modules, reducing the likelihood of repeated data points. Three: The bulk of defect prediction experiments based on the NASA Metrics Data Program data sets may have led to erroneous findings. This is mainly due to repeated data points potentially causing substantial amounts of training and testing data to be identical.","data mining,
fault tolerant computing"
Spectral Estimation of Nonstationary EEG Using Particle Filtering With Application to Event-Related Desynchronization (ERD),"This paper proposes non-Gaussian models for parametric spectral estimation with application to event-related desynchronization (ERD) estimation of nonstationary EEG. Existing approaches for time-varying spectral estimation use time-varying autoregressive (TVAR) state-space models with Gaussian state noise. The parameter estimation is solved by a conventional Kalman filtering. This study uses non-Gaussian state noise to model autoregressive (AR) parameter variation with estimation by a Monte Carlo particle filter (PF). Use of non-Gaussian noise such as heavy-tailed distribution is motivated by its ability to track abrupt and smooth AR parameter changes, which are inadequately modeled by Gaussian models. Thus, more accurate spectral estimates and better ERD tracking can be obtained. This study further proposes a non-Gaussian state space formulation of time-varying autoregressive moving average (TVARMA) models to improve the spectral estimation. Simulation on TVAR process with abrupt parameter variation shows superior tracking performance of non-Gaussian models. Evaluation on motor-imagery EEG data shows that the non-Gaussian models provide more accurate detection of abrupt changes in alpha rhythm ERD. Among the proposed non-Gaussian models, TVARMA shows better spectral representations while maintaining reasonable good ERD tracking performance.",
Guiding feature subset selection with an interactive visualization,"We propose a method for the semi-automated refinement of the results of feature subset selection algorithms. Feature subset selection is a preliminary step in data analysis which identifies the most useful subset of features (columns) in a data table. So-called filter techniques use statistical ranking measures for the correlation of features. Usually a measure is applied to all entities (rows) of a data table. However, the differing contributions of subsets of data entities are masked by statistical aggregation. Feature and entity subset selection are, thus, highly interdependent. Due to the difficulty in visualizing a high-dimensional data table, most feature subset selection algorithms are applied as a black box at the outset of an analysis. Our visualization technique, SmartStripes, allows users to step into the feature subset selection process. It enables the investigation of dependencies and interdependencies between different feature and entity subsets. A user may even choose to control the iterations manually, taking into account the ranking measures, the contributions of different entity subsets, as well as the semantics of the features.",
Cloud model for service selection,"Cloud computing is Internet-based computing where computing resources are offered over the Internet as scalable, on-demand services. Web services are widely employed for building distributed cloud applications. Performance of web services may fluctuate due to the dynamic Internet environment, which makes the Quality-of-Service (QoS) inherently uncertain. With the increase of Web services in the Internet, selecting the optimal service from a set of functionally equivalent candidates becomes an important research problem. In this paper, we propose an efficient and effective QoS-aware service selection approach. Our approach first employs cloud model to compute the QoS uncertainty for pruning redundant services while extracting reliable services. Then, mixed integer programming is used to select optimal services. The experimental results show that our approach can provide reliable and efficient optimal service selection for users.","Quality of service,
Web services,
Uncertainty,
Computational modeling,
Numerical models,
Helium"
The Use of Partial Discharges as an Online Monitoring System for Underground Cable Joints,"With their vast amount of joints, underground cable systems are expensive to maintain; therefore, measurement equipment must be cost-effective. This study proposes the long-term placement of partial-discharge (PD) monitoring units at cable joints. The unit consists of a peak detect circuit and a digital signal processor for acquiring and converting the sensors' PD signals into discharge sequence data, whose data are then provided to a remote computer for analysis and display of the condition of the cable joint. Finally, a cable joint with artificial defects was tested by accelerated aging tests to verify the performance of the equipment. Two characteristics, namely, the average discharge quantity (Qave) and the discharge phase region, are proposed and plotted against each other to render an evolution locus, which reveals a shape of an upside-down letter N. The locus allows a judgment to be made on the state of the insulation in the cable joint. These results further justify work to further develop the method as an online cable monitoring system.","Partial discharges,
Joints,
Cable insulation,
Monitoring,
Discharges,
Power cables"
A threat taxonomy for mHealth privacy,"Networked mobile devices have great potential to enable individuals (and their physicians) to better monitor their health and to manage medical conditions. In this paper, we examine the privacy-related threats to these so-called mHealth technologies. We develop a taxonomy of the privacy-related threats, and discuss some of the technologies that could support privacy-sensitive mHealth systems. We conclude with a brief summary of research challenges.",
Face Image Modeling by Multilinear Subspace Analysis With Missing Values,"Multilinear subspace analysis (MSA) is a promising methodology for pattern-recognition problems due to its ability in decomposing the data formed from the interaction of multiple factors. The MSA requires a large training set, which is well organized in a single tensor, which consists of data samples with all possible combinations of the contributory factors. However, such a “complete” training set is difficult (or impossible) to obtain in many real applications. The missing-value problem is therefore crucial to the practicality of the MSA but has been hardly investigated up to present. To solve the problem, this paper proposes an algorithm named M2SA, which is advantageous in real applications due to the following: 1) it inherits the ability of the MSA to decompose the interlaced semantic factors; 2) it does not depend on any assumptions on the data distribution; and 3) it can deal with a high percentage of missing values. M2SA is evaluated by face image modeling on two typical multifactorial applications, i.e., face recognition and facial age estimation. Experimental results show the effectiveness of M2 SA even when the majority of the values in the training tensor are missing.","Tensile stress,
Training,
Face,
Approximation algorithms,
Principal component analysis,
Face recognition,
Approximation methods"
An Interactive Simulation Tool for Complex Multilayer Dielectric Devices,"Novel devices incorporating multiple layers of new materials increase the complexity of device structures, particularly in field-effect transistors, capacitors, and nonvolatile memory (NVM). The mounting complexity of these devices increases the difficulty of generating energy band diagrams and performing device parameter calculations whether these calculations are done by hand, using spreadsheets, or via mathematical programs. Although finite-element Poisson-Schrodinger equation solvers are available to perform the calculations, the cost and time spent learning them can be a hindrance. A straightforward GUI interactive simulation tool is presented that quickly calculates and displays energy bands, electric fields, potentials, and charge distributions for 1-D metal-multilayered-dielectrics-semiconductor stacks. Fixed charge can be inserted into dielectric layers. The freeware program calculates device parameters, (e.g., effective oxide thickness, flat-band voltage (VFB), threshold voltage (Vt), stack capacitance) and layer parameters (e.g., capacitance, potential, electric field, tunneling distance). Calculated data can be exported. Using the simulation tool, trap-based flash NVM is examined. Device performance characteristics such as the Vt and VFB shifts of three different stacks are examined. Comparisons between the program and a finite-element Poisson-Schrodinger equation solver are performed to validate the program's accuracy.","Dielectrics,
Electric fields,
Electric potential,
Tunneling,
Mathematical model,
Metals,
Materials"
Modeling Nonsaturated IEEE 802.11 DCF Networks Utilizing an Arbitrary Buffer Size,"We propose an approximate model for a nonsaturated IEEE 802.11 DCF network. This model captures the significant influence of an arbitrary node transmit buffer size on the network performance. We find that increasing the buffer size can improve the throughput slightly but can lead to a dramatic increase in the packet delay without necessarily a corresponding reduction in the packet loss rate. This result suggests that there may be little benefit in provisioning very large buffers, even for loss-sensitive applications. Our model outperforms prior models in terms of simplicity, computation speed, and accuracy. The simplicity stems from using a renewal theory approach for the collision probability instead of the usual multidimensional Markov chain, and it makes our model easier to understand, manipulate and extend; for instance, we are able to use our model to investigate the important problem of convergence of the collision probability calculation. The remarkable improvement in the computation speed is due to the use of an efficient numerical transform inversion algorithm to invert generating functions of key parameters of the model. The accuracy is due to a carefully constructed model for the service time distribution. We verify our model using ns-2 simulation and show that our analytical results based on an M/G/1/K queuing model are able to accurately predict a wide range of performance metrics, including the packet loss rate and the waiting time distribution. In contradiction to claims by other authors, we show that 1) a nonsaturated DCF model like ours that makes use of decoupling assumptions for the collision probability and queuing dynamics can produce accurate predictions of metrics other than just the throughput, and 2) the actual service time and waiting time distributions for DCF networks have truncated heavy-tailed shapes (i.e., appear initially straight on a log-log plot) rather than exponential shapes. Our work will help developers select appropriate buffer sizes for 802.11 devices, and will help system administrators predict the performance of applications.","Computational modeling,
Mathematical model,
Numerical models,
Markov processes,
Delay,
Equations,
IEEE 802.11 Standards"
Supervised Gaussian Process Latent Variable Model for Dimensionality Reduction,"The Gaussian process latent variable model (GP-LVM) has been identified to be an effective probabilistic approach for dimensionality reduction because it can obtain a low-dimensional manifold of a data set in an unsupervised fashion. Consequently, the GP-LVM is insufficient for supervised learning tasks (e.g., classification and regression) because it ignores the class label information for dimensionality reduction. In this paper, a supervised GP-LVM is developed for supervised learning tasks, and the maximum a posteriori algorithm is introduced to estimate positions of all samples in the latent variable space. We present experimental evidences suggesting that the supervised GP-LVM is able to use the class label information effectively, and thus, it outperforms the GP-LVM and the discriminative extension of the GP-LVM consistently. The comparison with some supervised classification methods, such as Gaussian process classification and support vector machines, is also given to illustrate the advantage of the proposed method.","Gaussian processes,
Principal component analysis,
Kernel,
Supervised learning,
Nonlinear optics,
Laboratories,
Support vector machines,
Support vector machine classification,
Manifolds"
Continuous Neighbor Discovery in Asynchronous Sensor Networks,"In most sensor networks, the nodes are static. Nevertheless, node connectivity is subject to changes because of disruptions in wireless communication, transmission power changes, or loss of synchronization between neighboring nodes. Hence, even after a sensor is aware of its immediate neighbors, it must continuously maintain its view, a process we call continuous neighbor discovery. In this work, we distinguish between neighbor discovery during sensor network initialization and continuous neighbor discovery. We focus on the latter and view it as a joint task of all the nodes in every connected segment. Each sensor employs a simple protocol in a coordinate effort to reduce power consumption without increasing the time required to detect hidden sensors.","Wireless communication,
Propagation losses,
Protocols,
Energy consumption,
Telecommunication traffic,
Hardware,
Wireless sensor networks,
Traffic control,
Terrorism,
Computer science"
Hibernets: Energy-Efficient Sensor Networks Using Analog Signal Processing,"Preprocessing of data before transmission is recommended for many sensor network applications to reduce communication and improve energy efficiency. However, constraints on memory, speed, and energy currently limit the processing capabilities within a sensor network. In this paper, we describe how ultra-low-power analog circuitry can be integrated with sensor nodes to create energy-efficient sensor networks. To demonstrate this concept, we present a custom analog front-end which performs spectral analysis at a fraction of the power used by a digital counterpart. Furthermore, we show that the front-end can be combined with existing sensor nodes to 1) selectively wake up the mote based upon spectral content of the signal, thus increasing battery life without missing interesting events, and to 2) achieve low-power signal analysis using an analog spectral decomposition block, freeing up digital computation resources for higher-level analysis. Experiments in the context of vehicle classification show improved performance for our ASP-interfaced mote over an all-digital implementation.","Event detection,
Power demand,
Detectors,
Digital systems,
Spectral analysis"
Model Selection for Sinusoids in Noise: Statistical Analysis and a New Penalty Term,"Detection of the number of sinusoids embedded in noise is a fundamental problem in statistical signal processing. Most parametric methods minimize the sum of a data fit (likelihood) term and a complexity penalty term. The latter is often derived via information theoretic criteria, such as minimum description length (MDL), or via Bayesian approaches including Bayesian information criterion (BIC) or maximum a posteriori (MAP). While the resulting estimators are asymptotically consistent, empirically their finite sample performance is strongly dependent on the specific penalty term chosen. In this paper we elucidate the source of this behavior, by relating the detection performance to the extreme value distribution of the maximum of the periodogram and of related random fields. Based on this relation, we propose a combined detection-estimation algorithm with a new penalty term. Our proposed penalty term is sharp in the sense that the resulting estimator achieves a nearly constant false alarm rate. A series of simulations support our theoretical analysis and show the superior detection performance of the suggested estimator.","Analytical models,
Maximum likelihood estimation,
White noise,
Bayesian methods,
Time series analysis"
How Blended Learning Reduces Underachievement in Higher Education: An Experience in Teaching Computer Sciences,"This paper presents a blended learning approach and a study evaluating instruction in a software engineering-related course unit as part of an undergraduate engineering degree program in computing. In the past, the course unit had a lecture-based format. In view of student underachievement and the high course unit dropout rate, a distance-learning system was deployed, where students were allowed to choose between a distance-learning approach driven by a moderate constructivist instructional model or a blended-learning approach. The results of this experience are presented, with the aim of showing the effectiveness of the teaching/learning system deployed compared to the lecture-based system previously in place. The grades earned by students under the new system, following the distance-learning and blended-learning courses, are compared statistically to the grades attained in earlier years in the traditional face-to-face classroom (lecture-based) learning.","Electronic learning,
Roads,
Analysis of variance,
Computer aided instruction,
Computational modeling,
Object oriented modeling"
"Group Testing With Probabilistic Tests: Theory, Design and Application","Identification of defective members of large populations has been widely studied in the statistics community under the name of group testing. It involves grouping subsets of items into different pools and detecting defective members based on the set of test results obtained for each pool. In a classical noiseless group testing setup, it is assumed that the sampling procedure is fully known to the reconstruction algorithm, in the sense that the existence of a defective member in a pool results in the test outcome of that pool to be positive. However, this may not be always a valid assumption in some cases of interest. In particular, we consider the case where the defective items in a pool can become independently inactive with a certain probability. Hence, one may obtain a negative test result in a pool despite containing some defective items. As a result, any sampling and reconstruction method should be able to cope with two different types of uncertainty, i.e., the unknown set of defective items and the partially unknown, probabilistic testing procedure. In this work, motivated by the application of detecting infected people in viral epidemics, we design nonadaptive sampling procedures that allow successful identification of the defective items through a set of probabilistic tests. Our design requires only a small number of tests to single out the defective items. In particular, for a population of size N and at most K defective items with activation probability p, our results show that M = O(K2 log (N/K)/p3) tests is sufficient if the sampling procedure should work for all possible sets of defective items, while M = O(K log (N)/p3) tests is enough to be successful for any single set of defective items. Moreover, we show that the defective members can be recovered using a simple reconstruction algorithm with complexity of O(MN).","Testing,
Sparse matrices,
Decoding,
Probabilistic logic,
Reconstruction algorithms,
Compressed sensing,
Uncertainty"
Scalable Modulation for Video Transmission in Wireless Networks,"In conventional wireless systems with layered architectures, the physical (PHY) layer equally treats all data streams from the upper layers and applies the same modulation and coding schemes to them. Newer systems such as Digital Video Broadcast start to introduce hierarchical modulation schemes with SuperPosition Coding (SPC) and support data streams of different priorities. However, SPC requires specialized hardware and has high complexity, which is not desirable for handheld devices. In this paper, we propose scalable modulation (s-mod) by reusing the current mainstream modulation schemes with software-based bit remapping. The performance evaluation has shown that s-mod can achieve the same and, in some cases, even better performance than SPC with much lower complexity. We further propose how to optimize the configuration of the PHY-layer s-mod and coding schemes to maximize the utility of video streaming with scalable video coding (SVC). Simulation results demonstrate substantial performance gains using s-mod and cross-layer optimization, indicating that s-mod and SVC are a good combination for video transmission in wireless networks.","Encoding,
Streaming media,
Wireless communication,
Demodulation,
Bit error rate,
Static VAr compensators"
Semisupervised Generalized Discriminant Analysis,"Generalized discriminant analysis (GDA) is a commonly used method for dimensionality reduction. In its general form, it seeks a nonlinear projection that simultaneously maximizes the between-class dissimilarity and minimizes the within-class dissimilarity to increase class separability. In real-world applications where labeled data are scarce, GDA may not work very well. However, unlabeled data are often available in large quantities at very low cost. In this paper, we propose a novel GDA algorithm which is abbreviated as semisupervised generalized discriminant analysis (SSGDA). We utilize unlabeled data to maximize an optimality criterion of GDA and formulate the problem as an optimization problem that is solved using the constrained concave-convex procedure. The optimization procedure leads to estimation of the class labels for the unlabeled data. We propose a novel confidence measure and a method for selecting those unlabeled data points whose labels are estimated with high confidence. The selected unlabeled data can then be used to augment the original labeled dataset for performing GDA. We also propose a variant of SSGDA, called M-SSGDA, which adopts the manifold assumption to utilize the unlabeled data. Extensive experiments on many benchmark datasets demonstrate the effectiveness of our proposed methods.",
Cloud computing for education and learning: Education and learning as a service (ELaaS),"Cloud computing, despite its hype, is being widely deployed, with its dynamic scalability and usage of virtualized resources, in many organizations for several applications. It is envisioned that, in the near future, cloud computing will have a significant impact on the educational and learning environment, enabling their own users (i.e., learners, instructors, and administrators) to perform their tasks effectively with less cost by utilizing the available cloud-based applications offered by the cloud service providers. This paper discusses the use of cloud computing in the educational and learning arena, to be called “Education and Learning as a Service” (ELaaS), emphasizing its possible benefits and offerings. It is essential for an educational and learning organization, with its budget restrictions and sustainability challenges, to use the cloud formation best suited for a particular IT activity. The Jericho Forum proposes a cloud computing formation model, called the Cloud Cube Model (CCM), which is based on 4 criteria. To preserve the symmetry of the cube, a new cloud computing formation model, called the Complete Cloud Computing Formations (C3F), is proposed. The IT activities in the educational and learning organizations are then classified with respect to the two criteria: mission criticality and sensitivity. Each class is then mapped into the appropriate position in the C3F, creating ELaaS Quadrant. This essentially establishes a general conceptual framework for ELaaS.","Cloud computing,
Organizations,
Computational modeling,
Conferences,
Educational institutions"
FACES: Friend-Based Ad Hoc Routing Using Challenges to Establish Security in MANETs Systems,"Friend based Ad hoc routing using Challenges to Establish Security (FACES) is an algorithm to provide secure routing in ad hoc mobile networks. We propose this scheme that has been drawn from a network of friends in real life scenarios. The algorithm works by sending challenges and sharing friend Lists to provide a list of trusted nodes to the source node through which data transmission finally takes place. The nodes in the friend list are rated on the basis of the amount of data transmission they accomplish and their friendship with other nodes in the network. The account of friendship of a node with other nodes in the network is obtained through the Share Your Friends process which is a periodic event in the network. As a result of this scheme of operation, the network is able to effectively isolate the malicious nodes which are left with no role to play in the ad hoc network. One major benefit of this scheme is that the nodes do not need to promiscuously listen to the traffic passing through their neighbors. The information about the malicious nodes is gathered effectively by using Challenges. This reduces the overhead on the network significantly. Through extensive simulation analysis it was inferred that this scheme provides an efficient approach towards security and easier detection of malicious nodes in the mobile ad hoc network.","Ad hoc networks,
Routing,
Peer to peer computing,
Protocols,
Cryptography,
Mobile computing"
Single-phase cascaded H-bridge multilevel inverter with nonactive power compensation for grid-connected photovoltaic generators,"This paper presents a single-phase cascaded H-bridge multilevel inverter for a grid-connected photovoltaic (PV) system with nonactive power compensation. A generalized nonactive power theory is applied to generate the nonactive current reference. Within the inverter's capability, nonactive power required by the local load is provided to improve the grid power quality. To minimize harmonics and achieve zero error tracking, a hybrid controller composed of a proportional controller and a repetitive controller is applied to current control. A single-phase 11-level cascaded multilevel inverter is considered in both simulation and experimental tests. Each H-bridge is connected to a 195 W solar panel. Simulation and experimental results are presented to validate the proposed ideas.","Inverters,
Power harmonic filters,
Photovoltaic systems,
Voltage control,
Harmonic analysis,
Control systems"
Relay Selection for Decode-and-Forward Cooperative Network with Multiple Antennas,"In this paper, a new relay selection scheme for decode-and-forward (DF) relay cooperative network with multiple antennas is proposed based on both channel state information (CSI) and transmission scheme by deriving the upper bound on the pairwise error probability (PEP) of the near-maximum-likelihood (near-ML) decoder. It is also proved that the proposed relay selection which selects m (1≤ m≤ N) relays from N relays achieves full diversity MS MD+N MR min[MS, MD] regardless of the value of m in the DF relay network consisting of one source, one destination, and N relays with MS, MD, and MR antennas, respectively. Through Monte Carlo simulation, the error correction performance of the proposed relay selection for various m is shown for the uncoded single-antenna, Alamouti coded, and multiple-input multiple-output (MIMO) DF relay networks.","Relays,
Decoding,
Upper bound,
Cooperative systems,
Pairwise error probability,
Maximum likelihood decoding,
MIMO"
MIMO Transceiver Designs for Spatial Sensing in Cognitive Radio Networks,"We propose transceiver algorithms in cognitive radio networks where the cognitive users are equipped with multiple antennas. Prior work has focused on the design of precoding matrices to suppress interference to the primary receivers. This work considers designs of precoding and decoding matrices for spatial sensing to achieve two objectives: (i) to prevent interference to the primary receivers and (ii) to remove the interference, due to primary transmissions, at the secondary receiver. With single antenna primary terminals and two antenna cognitive terminals, a linear transceiver design has been introduced under a global channel state information (CSI) assumption . In this letter, multiple antenna primary and cognitive terminals and three different CSI scenarios depending upon the amount of CSI are studied: (i) local CSI, (ii) global CSI, and (iii) local CSI with side information. When local CSI is available, we leverage prior work and employ the projected-channel singular value decomposition (P-SVD). In the global CSI scenario, we propose a joint transmitter-receiver design under the assumption of full CSI of all the users at the secondary transceiver. To reduce the feedback overhead, we also propose a new iterative algorithm that exploits only local CSI with side information. In this algorithm, the secondary transmitter and receiver iteratively update precoding and decoding matrices based on the local CSI and side information (precoding/decoding matrices at the previous iteration step) to maximize the rate of the secondary link while maintaining the zero-interference constraint. Convergence is established in the special case of single stream beamforming. Numerical results confirm that the proposed joint design and the iterative algorithm show better achievable rate performance than the P-SVD technique at the expense, respectively, of CSI knowledge and side information.","Receivers,
Transceivers,
Radio transmitters,
Interference,
Iterative methods,
Iterative decoding"
Single-phase inverter design for V2G reactive power compensation,Vehicle to grid (V2G) power transfer has been under research for more than a decade because of the large energy reserve of an electric vehicle battery and the potential of thousands of these connected to the grid. In this study a complete analysis of the front end inverter of a non-isolated bidirectional EV/PHEV charger capable of V2G reactive power compensation is presented.,"Inverters,
Integrated circuits,
Capacitors,
Batteries,
Inductance,
Reactive power,
Switches"
Sampling and reconstructing diffusion fields with localized sources,"We study the spatiotemporal sampling of a diffusion field generated by K point sources, aiming to fully reconstruct the unknown initial field distribution from the sample measurements. The sampling operator in our problem can be described by a matrix derived from the diffusion model. We analyze the important properties of the sampling matrices, leading to precise bounds on the spatial and temporal sampling densities under which perfect field reconstruction is feasible. Moreover, our analysis indicates that it is possible to compensate linearly for insufficient spatial sampling densities by oversampling in time. Numerical simulations on initial field reconstruction under different spatiotemporal sampling densities confirm our theoretical results.","Spatiotemporal phenomena,
Mathematical model,
Equations,
Heating,
Estimation,
Sparse matrices,
Approximation methods"
Online environment mapping,"The paper proposes a vision based online mapping of large-scale environments. Our novel approach uses a hybrid representation of a fully metric Euclidean environment map and a topological map. This novel hybrid representation facilitates our scalable online hierarchical bundle adjustment approach. The proposed method achieves scalability by solving the local registration through embedding neighboring keyframes and landmarks into a Euclidean space. The global adjustment is performed on a segmentation of the keyframes and posed as the iterative optimization of the arrangement of keyframes in each segment and the arrangement of rigidly moving segments. The iterative global adjustment is performed concurrently with the local registration of the keyframes in a local map. Thus the map is always locally metric around the current location, and likely to be globally consistent. Loop closures are handled very efficiently benefiting from the topological nature of the map and overcoming the loss of the metric map properties as previous approaches. The effectiveness of the proposed method is demonstrated in real-time on various challenging video sequences.",
"The RWTH 2010 Quaero ASR evaluation system for English, French, and German","Recognizing Broadcast Conversational (BC) speech data is a difficult task, which can be regarded as one of the major challenges beyond the recognition of Broadcast News (BN). This paper presents the automatic speech recognition systems developed by RWTH for the English, French, and German language which attained the best word error rates for English and German, and competitive results for the French task in the 2010 Quaero evaluation for BC and BN data. At the same time, the RWTH German system used the least amount of training data among all participants. Large reductions in word error rate were obtained by the incorporation of the new Bottleneck Multilayer Perception (MLP) features for all three languages. Additional improvements were obtained for the German system by applying a new language modeling technique, decomposing words into sublexical components.","Training,
Speech recognition,
Mel frequency cepstral coefficient,
Speech,
Training data,
Hidden Markov models"
Torus-Bifurcation Mechanisms in a DC/DC Converter With Pulsewidth-Modulated Control,"Pulse-modulated converter systems play an important role in modern power electronics. However, by virtue of the complex interplay between ordinary (smooth) and so-called border-collision bifurcations generated by the switching dynamics, the changes in behavior that can occur in multilevel converter systems under varying operational conditions still remain to be explored in full. Considering the dynamics of a three-level dc/dc-converter, we demonstrate a number of new scenarios for the birth or destruction of resonant and ergodic tori. One scenario involves the formation of a doubled-layered torus structure around a stable focus point through three subsequent border-collision fold bifurcations. Another scenario replaces one of the fold bifurcations by a global bifurcation. In both of these scenarios, the basic mode of the converter remains stable while other modes grow up and bifurcate around it. We also illustrate the subcritical birth of both an ergodic and a resonance torus from the basic operational mode.","Bifurcation,
Switches,
DC-DC power converters,
Feedback control,
Erbium"
Enrichment of Peer Assessment with Agent Negotiation,"This study presents a conceptual framework for providing intelligent supports through agent negotiation and fuzzy constraints to enhance the effectiveness of peer assessment. By using fuzzy constraints, it not only provides a flexible marking scheme to deal with the imprecision and uncertainty for the representation of assessment but also provides a computational framework to incorporate student's personal characteristics into the process for the reduction of assessment bias. Additionally, a fuzzy constraint-based negotiation mechanism is employed to coordinate the cognitive differences between students. Through iterative agent negotiation, students can reconcile the differences and reach an agreement on the assessment results. Thus, the proposed framework allows students to provide more detailed, informed, and less biased assessments for their peers' work. To demonstrate the usefulness and effectiveness of the proposed approach, a negotiation-based peer assessment system, NePAS, has been built and used in classroom. Experimental results suggested that students were more willing to accept the assessment results and able to acquire more useful information to reflect upon and revise their work. Instructors can also observe students' participation and performance to appropriately adjust instructional strategies.","Materials,
Book reviews,
Cognition,
Uncertainty,
Proposals,
Computational modeling,
Reflection"
Minimum Expected Length of Fixed-to-Variable Lossless Compression Without Prefix Constraints,"The minimum expected length for fixed-to-variable length encoding of an n-block memoryless source with entropy H grows as nH + O(1), where the term O(1) lies between 0 and 1. However, this well-known performance is obtained under the implicit constraint that the code assigned to the whole n-block is a prefix code. Dropping the prefix constraint, which is rarely necessary at the block level, we show that the minimum expected length for a finite-alphabet memoryless source with known distribution grows as nH-1/2 log n + O(1) unless the source is equiprobable. We also refine this result up to o(1) for those memoryless sources whose log probabilities do not reside on a lattice.",
Variable-Conversion-Ratio Switched-Capacitor-Voltage-Multiplier/Divider DC-DC Converter,"An interleaved scheme of variable-conversion-ratio (VCR) multistage switched-capacitor-voltage-multiplier/divider (SCVM/SCVD) converter is proposed by combining a VCR-based phase generator and pulse-width-modulation (PWM) controller to integrate step-up and down modes in one structure for high-efficiency conversion. The power part consists of two mc-stage SC cells (front) and two nc-stage SC cells (rear) in series for step-up/down gain of mc × nc or 1/(mc × nc) at most. Here, VCR-based phase generator is suggested with changing the running stage number m, n and topological path to obtain a suitable gain of m × n or 1/(m × n) (m = 1, 2,..., mc, n = 1,2,..., nc) for improving efficiency, especially for the lower desired output. Besides, PWM is adopted to enhance output regulation as well as robustness to source/loading variation. Further, some theoretical analysis and design include: formulation, steady-state analysis, conversion ratio, efficiency, output ripple, stability, capacitance selection, and control design. Finally, the closed-loop SCVM/SCVD is simulated, and the hardware is implemented and tested. All results are illustrated to show the efficacy of this scheme.",
Tag Tagging: Towards More Descriptive Keywords of Image Content,"Tags have been demonstrated to be effective and efficient for organizing and searching social image content. However, these human-provided keywords are far from a comprehensive description of the image content, which limits their effectiveness in tag-based image search. In this paper, we propose an automatic scheme called tag tagging to supplement semantic image descriptions by associating a group of property tags with each existing tag. For example, an initial tag “tiger” may be further tagged with “white”, “stripes”, and “bottom-right” along three tag properties: color, texture, and location, respectively. In this way, the descriptive ability of the existing tags can be greatly enhanced. In the proposed scheme, a lazy learning approach is first applied to estimate the corresponding image regions of each initial tag, and then a set of property tags that correspond to six properties, including location, color, texture, size, shape, and dominance, are derived for each initial tag. These tag properties enable much more precise image search especially when certain tag properties are included in the query. The results of the empirical evaluation show that tag properties remarkably boost the performance of social image retrieval.",
Maintaining Temporal Coherence in Video Retargeting Using Mosaic-Guided Scaling,"Video retargeting from a full-resolution video to a lower resolution display will inevitably cause information loss. Content-aware video retargeting techniques have been studied to avoid critical visual information loss while resizing a video. Maintaining the spatio-temporal coherence of a retargeted video is very critical on visual quality. Camera motions and object motions, however, usually make it difficult to maintain temporal coherence using existing schemes. In this paper, we propose the use of a panoramic mosaic to guide the scaling of corresponding regions of video frames in a video shot to ensure good temporal coherence. In the proposed method, after aligning video frames in a shot to a panoramic mosaic constructed for the shot, a global scaling map for these frames is derived from the panoramic mosaic. Subsequently, the local scaling maps of individual frames are derived from the global map and is further refined according to spatial coherence constraints. Our experimental results show that the proposed method can effectively maintain temporal coherence so as to achieve good visual quality even a video contains camera motions and object motions.","Pixel,
Visualization,
Coherence,
Cameras,
Optimization,
Streaming media,
Spatial coherence"
Rumor Riding: Anonymizing Unstructured Peer-to-Peer Systems,"Although anonymizing Peer-to-Peer (P2P) systems often incurs extra traffic costs, many systems try to mask the identities of their users for privacy considerations. Existing anonymity approaches are mainly path-based: peers have to pre-construct an anonymous path before transmission. The overhead of maintaining and updating such paths is significantly high. We propose Rumor Riding (RR), a lightweight and non-path-based mutual anonymity protocol for decentralized P2P systems. Employing a random walk mechanism, RR takes advantage of lower overhead by mainly using the symmetric cryptographic algorithm. We conduct comprehensive trace-driven simulations to evaluate the effectiveness and efficiency of this design, and compare it with previous approaches. We also introduce some early experiences on RR implementations.","Peer to peer computing,
Privacy,
Costs,
Cryptographic protocols,
Public key cryptography,
Random media,
IP networks,
Protection,
Data structures,
Public key"
A Low-Overhead Asynchronous Interconnection Network for GALS Chip Multiprocessors,"A new asynchronous interconnection network is introduced for globally-asynchronous locally-synchronous (GALS) chip multiprocessors. The network eliminates the need for global clock distribution, and can interface multiple synchronous timing domains operating at unrelated clock rates. In particular, two new highly-concurrent asynchronous components are introduced which provide simple routing and arbitration/merge functions. Post-layout simulations in identical commercial 90 nm technology indicate that comparable recent synchronous router nodes have 5.6-10.7 more energy per packet and 2.8-6.4 greater area than the new asynchronous nodes. Under random traffic, the network provides significantly lower latency and identical throughput over the entire operating range of the 800 MHz network and through mid-range traffic rates for the 1.36 GHz network, but with degradation at higher traffic rates. Preliminary evaluations are also presented for a mixed-timing (GALS) network in a shared-memory parallel architecture, running both random traffic and parallel benchmark kernels, as well as directions for further improvement.","Routing,
Latches,
Registers,
Pipelines,
Throughput,
Multiprocessor interconnection"
Stochastic Resonance Can Enhance Information Transmission in Neural Networks,"Stochastic resonance (SR) is a noise-induced phenomenon whereby signal detection can be improved by the addition of background noise in nonlinear systems. SR can also improve the transmission of information within single neurons. Since information processing in the brain is carried out by neural networks and noise is present throughout the brain, the hypothesis that noise and coupling play an important role in the control of information processing within a population of neurons to control was tested. Using computer simulations, we investigate the effect of noise on the transmission of information in an array of neurons, known as array-enhanced SR (AESR) in an interconnected population of hippocampal neurons. A subthreshold synaptic current (signal) modeled by a filtered homogeneous Poisson process was applied to a distal position in each of the apical dendrites, while background synaptic signals (uncorrelated noise) were presented to the midpoint in the basal dendrite. The transmembrane potentials were recorded in each cell of an array of CA1 neuron models, in order to determine spike firing times and to estimate the total and noise entropies from the spike firing times. The results show that the mutual information is maximized for a specific amplitude of uncorrelated noise, implying the presence of AESR. The results also show that the maximum mutual information increases with increased numbers of neurons and the strength of connections. Moreover, the relative levels of excitation and inhibition modulate the mutual information transfer. It is concluded that uncorrelated noise can enhance information transmission of subthreshold synaptic input currents in a population of hippocampal CA1 neuron models. Therefore, endogenous neural noise could play an important role in neural tissue by modulating the transfer of information across the network.",
"Cyclotron Production of Radioactive {\hbox{CeO}} _{2}
Nanoparticles and Their Application for In Vitro Uptake Studies","Nowadays, a wide variety of nanoparticles (NPs) are applied in different fields such as medical science and industry. Due to their large commercial volume, the OECD Working Party on Manufactured Nanomaterials (NMs) has proposed to study a set of 14 nanomaterials, one of which being cerium oxide (CeO2). In particular, CeO2 based NPs are widely used in automotive industry, healthcare, and cosmetics. In this paper, we propose a method for the production of radioactive CeO2 NPs. We demonstrate that they maintain the same physicochemical characteristics as the “cold” ones in terms of size distribution and Zeta potential; we develop a new protocol to assess their cellular interaction in immortalized mouse fibroblast cell line Balb/3T3, a model for the study of basal cytotoxicity and carcinogenic potential induced by chemicals and in the present case by NPs. Experimental result of this work, which shows a quasi-linear concentration-uptake response of cells, can be useful as a reference dose-uptake curve for explaining effects following biological uptake after exposure to CeO2 NPs.","Nanomaterials,
Radiation effects,
Nanoparticles,
Radioactive materials,
Production,
Cyclotrons"
Semiunitary Precoding for Spatially Correlated MIMO Channels,"The focus of this paper is on spatial precoding in correlated multiantenna channels where the number of data-streams is adapted independent of the number of transmit antennas. Towards the goal of a low-complexity implementation, a statistical semiunitary precoder is studied where the precoder matrix evolves fairly slowly with respect to the channel evolution. While prior work on statistical precoding has focussed on information-theoretic limits, most of these computations result in complicated functional dependencies of the mutual information with the channel statistics that do not explicitly reveal the impact of statistics on performance. In contrast, estimates that are directly in terms of the channel statistics are obtained here for the relative mutual information loss of a semiunitary precoder with respect to a perfect channel information benchmark. Based on these estimates, matching metrics are developed that capture the degree of matching of a channel to the precoder structure continuously and allow ordering two matrix channels in terms of their mutual information performance. While these metrics are based on bounds, numerical studies are used to show that the proposed metrics capture the performance tradeoffs accurately. The main conclusion of this work is a simple-to-state fundamental principle in the context of signaling design for single-user MIMO systems: the best channel for the statistical precoder is the channel that is matched to it.",
Fuzzy Diagnosis Method for Rotating Machinery in Variable Rotating Speed,"In order to effectively diagnose faults for rotating machinery in the variable rotating speed, a novel diagnosis method is proposed based on time-frequency analysis techniques, the automatic feature extraction method, and fuzzy inference. The diagnosis sensitivities of three time-frequency analysis methods, namely, the short-time Fourier transform (STFT), wavelet analysis (WA), and the pseudo-Wigner-Ville distribution (PWVD), are investigated for condition diagnosis of rotating machinery. In the case of the bearing diagnosis, the diagnosis sensitivity of the PWVD was found to be highest. An extraction method for instantaneous feature spectrum is proposed using the relative crossing information (RCI), by which the feature spectrum from time-frequency distribution can be automatically extracted by a computer in order to identify among the conditions of a machine. The symptom parameters are also defined in the frequency domain using the feature spectrum extracted by the RCI. The synthetic symptom parameters can be obtained by the least squares mapping (LSM) technique to increase the diagnosis sensitivity of the symptom parameters. Based on the above studies, a fuzzy diagnosis method using sequential inference and possibility theory was also proposed, by which the conditions of machinery can be well identified sequentially. Practical examples of diagnosis for a roller bearing are given in order to verify the effectiveness of the approaches proposed in this paper.","Machinery,
Time frequency analysis,
Data mining,
Feature extraction,
Fault diagnosis,
Fourier transforms,
Wavelet analysis,
Distributed computing,
Frequency domain analysis,
Least squares methods"
Tumor Classification Based on Non-Negative Matrix Factorization Using Gene Expression Data,"This paper presents a new method for tumor classification using gene expression data. In the proposed method, we first select genes using nonnegative matrix factorization (NMF) or sparse NMF (SNMF), and then we extract features from the selected genes by virtue of NMF or SNMF. At last, we apply support vector machines (SVM) to classify the tumor samples using the extracted features. In order for a better classification, a modified SNMF algorithm is also proposed. The experimental results on benchmark three microarray data sets validate that the proposed method is efficient. Moreover, the biological meaning of the selected genes are also analyzed.",
Time Reversal Based Active Array Source Localization,"Source localization especially direction-of-arrival (DOA) estimation using sensor arrays is of considerable interest in both classical array signal processing and radar applications. Most radar systems are designed under the line-of-sight (LOS) assumption with multipath echos treated as undesired clutter noise. Strong multipath, therefore, has a negative impact on the resolution of the radar systems and their ability in accurately localizing the target. Rather than treating multipath as a detrimental effect, the paper introduces time reversal (TR) to exploit spatial/multipath diversity in improving the capability of the existing localization algorithms. In particular, we design TR based range and DOA estimators that adaptively adjust the probing radar waveforms to the multipath characteristics of the environment. The benefits of the spatial/multipath diversity in the proposed DOA and range estimators are quantified by deriving the respective Cramér-Rao bounds (CRB) and comparing them with the analytical expressions for their conventional counterparts. Numerical simulations also confirm the benefit of applying TR to source localization algorithms especially at low signal-to-noise ratios below -5 dB.",
A Miniaturized System for Spike-Triggered Intracortical Microstimulation in an Ambulatory Rat,"This paper reports on a miniaturized system for spike-triggered intracortical microstimulation (ICMS) in an ambulatory rat. The head-mounted microdevice comprises a previously developed application-specific integrated circuit fabricated in 0.35-μm two-poly four-metal complementary metal-oxide-semiconductor technology, which is assembled and packaged on a miniature rigid-flex substrate together with a few external components for programming, supply regulation, and wireless operation. The microdevice operates autonomously from a single 1.55-V battery, measures 3.6 cm × 1.3 cm × 0.6 cm, weighs 1.7 g (including the battery), and is capable of stimulating as well as recording the neural response to ICMS in biological experiments with anesthetized laboratory rats. Moreover, it has been interfaced with silicon microelectrodes chronically implanted in the cerebral cortex of an ambulatory rat and successfully delivers electrical stimuli to the second somatosensory area when triggered by neural activity from the rostral forelimb area with a user-adjustable spike-stimulus time delay. The spike-triggered ICMS is further shown to modulate the neuronal firing rate, indicating that it is physiologically effective.","Application specific integrated circuits,
Microelectrodes,
Batteries,
Receivers,
Programming,
Microcontrollers,
Rats"
Robotic Surgery,"In this article, we discuss formal methods for the verification of properties of control systems designed for autonomous robotic systems. In the last few decades, robotics played a relevant role in the progress of surgery. The use of robots in the operating rooms has given rise to new terminologies: robot-assisted surgery, medical robotics, rehabilitation robotics, telesurgery, robotic assistive systems, and so on. Since robotic surgery is a relatively new field of investigation, there are no established methods for bringing new concepts and operational procedures to the surgical practice, in spite of the interest and pressing requests of the medical community.","Surgery,
Robot control,
Medical services,
Telerobotics,
Mobile robots,
Medical treatment"
Collocated interaction with flying robots,"We introduce a socially motivated interaction technique with collocated flying robots (a quadrotor in our current prototype). Instead of the traditional remote interaction controllers often used when interacting with flying robots and UAVs, we explore the collocated interaction space and suggest a direct interaction technique motivated by social human-robot interaction themes. Our approach is inspired by the types of interaction humans have with birds, specifically falconeering, and is facilitated by gestures-based interaction, while the user is within the field of view of the flying robot. This paper outlines our research goals, task examples, and our overall design approach. The paper also discusses our current prototyping efforts, as well as a preliminary evaluation of our approach, performed through two design critiques, studying our collocated interaction technique concept, and its potential, drawbacks and benefits for users.",
Estimating Soil Moisture With the Support Vector Regression Technique,"This letter presents an experimental analysis of the application of the ε-insensitive support vector regression (SVR) technique to soil moisture content estimation from remotely sensed data at field/basin scale. SVR has attractive properties, such as ease of use, good intrinsic generalization capability, and robustness to noise in the training data, which make it a valid candidate as an alternative to more traditional neural-network-based techniques usually adopted in soil moisture content estimation. Its effectiveness in this application is assessed by using field measurements and considering various combinations of the input features (i.e., different active and/or passive microwave measurements acquired using various sensor frequencies, polarizations, and acquisition geometries). The performance of the SVR method (in terms of estimation accuracy, generalization capability, computational complexity, and ease of use) is compared with that achieved using a multilayer perceptron neural network, which is considered as a benchmark in the addressed application. This analysis provides useful indications for building soil moisture estimation processors for upcoming satellites or near-real-time applications.","Estimation,
Soil moisture,
Remote sensing,
Microwave theory and techniques,
Accuracy,
Training"
Discriminative affine sparse codes for image classification,"Images in general are captured under a diverse set of conditions. An image of the same object can be captured with varied poses, illuminations, scales, backgrounds and probably different camera parameters. The task of image classification then lies in forming features of the input images in a representational space where classifiers can be better supported in spite of the above variations. Existing methods have mostly focused on obtaining features which are invariant to scale and translation, and thus they generally suffer from performance degradation on datasets which consist of images with varied poses or camera orientations. In this paper we present a new framework for image classification, which is built upon a novel way of feature extraction that generates largely affine-invariant features called affine sparse codes. This is achieved through learning a compact dictionary of features from affine-transformed input images. Analysis and experiments indicate that this novel feature is highly discriminative in addition to being largely affine-invariant. A classifier using AdaBoost is then designed using the affine sparse codes as the input. Extensive experiments with standard databases demonstrate that the proposed approach can obtain the state-of-the-art results, outperforming existing leading approaches in the literature.","Dictionaries,
Accuracy,
Feature extraction,
Encoding,
Cameras,
Training,
Transforms"
A secured cost-effective multi-cloud storage in cloud computing,"The end of this decade is marked by a paradigm shift of the industrial information technology towards a pay-per-use service business model known as cloud computing. Cloud data storage redefines the security issues targeted on customer's outsourced data (data that is not stored/retrieved from the costumers own servers). In this work we observed that, from a customer's point of view, relying upon a solo SP for his outsourced data is not very promising. In addition, providing better privacy as well as ensuring data availability, can be achieved by dividing the user's data block into data pieces and distributing them among the available SPs in such a way that no less than a threshold number of SPs can take part in successful retrieval of the whole data block. In this paper, we propose a secured cost-effective multi-cloud storage (SCMCS) model in cloud computing which holds an economical distribution of data among the available SPs in the market, to provide customers with data availability as well as secure storage. Our results show that, our proposed model provides a better decision for customers according to their available budgets.","Cloud computing,
Quality of service,
Data models,
Servers,
Memory,
Security,
Availability"
"Engineering Design of Fluid-Filled Soft Covers for Robotic Contact Interfaces: Guidelines, Nonlinear Modeling, and Experimental Validation","Viscoelastic contact interfaces can be found in various robotic components that are covered with a compliant surface (pad) such as anthropomorphic hands, biomimetic haptic/tactile sensors, prostheses, and orthoses. In all these cases, it is desirable to obtain thin and resistant pads with predetermined compliance and damping properties (e.g., mimicking the human skin and pulpy tissues). In order to overcome the limits of homogeneous layers of a soft viscoelastic material, which is commonly used in the aforementioned devices, this paper suggests the adoption of soft pads that are composed of a continuous external layer (skin) coupled with an internal layer having fluid-filled voids. The process to design the pad starts with the selection of a hyperelastic medium with proper tribological features, whose constitutive parameters are determined by numerically fitting nonlinear stress-strain curves under pure homogenous deformations. The optimization of the internal layer morphology is then achieved through nonlinear finite element analysis (FEA) that provides an estimate of hardness and friction influence on the pad static compliance. Finally, the pad is filled with a viscous fluid that is chosen to modify time-dependent phenomena and to increase damping effects. The effectiveness of the procedure is proven by designing and modeling better-behaved artificial pads that mimic human-finger dynamic properties.","Materials,
Humans,
Skin,
Geometry,
Robot sensing systems,
Rubber"
Fast and compact per-flow traffic measurement through randomized counter sharing,"Traffic measurement provides critical real-world data for service providers and network administrators to perform capacity planning, accounting and billing, anomaly detection, and service provision. One of the greatest challenges in designing an online measurement module is to minimize the per-packet processing time in order to keep up with the line speed of the modern routers. To meet this challenge, we should minimize the number of memory accesses per packet and implement the measurement module in the on-die SRAM. The small size of SRAM requires extremely compact data structures to be designed for storing per-flow information. The best existing work, called counter braids, requires more than 4 bits per flow and performs 6 or more memory accesses per packet. In this paper, we design a fast and compact measurement function that estimates the sizes of all flows. It achieves the optimal processing speed: 2 memory accesses per packet. In addition, it provides reasonable measurement accuracy in a tight space where the counter braids no longer work. Our design is based on a new data encoding/decoding scheme, called randomized counter sharing. This scheme allows us to mix per-flow information together in storage for compactness and, at the decoding time, separate the information of each flow through statistical removal of the error introduced during information mixing from other flows. The effectiveness of our online per-flow measurement approach is analyzed and confirmed through extensive experiments based on real network traffic traces.","Radiation detectors,
Random access memory,
Estimation,
Size measurement,
Accuracy,
Noise,
Memory management"
Network Coding: A Historical Perspective,"Ten years ago, Ahlswede, Cai, Li, and Yeung refuted the folklore that information can be regarded as a commodity in network communication by means of an example now known as the butterfly network. The concept of network coding was formulated, and the fundamental max-flow-min-cut theorem for information flow was established. Since then, the work has generated much interest among many different research communities in engineering, mathematics, and natural science. This paper gives a historical account of the developments that led to this seminal work in network coding.","Network coding,
History,
Satellite broadcasting,
Channel coding,
Decoding,
Entropy,
Telecommunication network topology"
Reliability-oriented broadcast electrode-addressing for pin-constrained digital microfluidic biochips,"Designs for pin-constrained digital microfluidic biochips (PDMFBs) are receiving much attention because they simplify chip fabrication and packaging, and reduce product cost. To reduce the pin count, broadcast addressing, by minimally grouping electrode sets with non-conflict signal merging, has emerged as a promising solution. Nevertheless, naive signal merging has the potential to cause excessive electrode actuations, which has been reported to have direct and adverse effect on chip reliability. According to recent studies, reliability is an important attribute for PDMFBs particularly developed for medical applications as it directly affects the final medical decision making. However, no research findings have been reported on the reliability problem in pin-constrained designs. To make PDMFBs more feasible for practical applications, we propose in this paper the first matching-based reliability-oriented broadcast-addressing algorithm for PDMFBs. We identify the factors that affect reliability and incorporate into the design-technique attributes that enhance reliability. Experimental results demonstrate the effectiveness of the proposed algorithm.","Electrodes,
Pins,
Reliability engineering,
Algorithm design and analysis,
Grounding,
Force"
Location Estimation of a Random Signal Source Based on Correlated Sensor Observations,"The problem of location estimation of a source of random signals using a network of sensors is considered. A novel maximum-likelihood estimation (MLE) based approach using copula functions is proposed. The measurements received at the sensors are often spatially correlated and characterized by a multivariate distribution. Using the theory of copulas, the joint parametric density of sensor observations (joint likelihood) is approximated assuming only the knowledge of the marginal likelihood functions of the sensor observations. The problem of selecting the best copula function to model the joint likelihood is approached as one of model selection and a model fusion strategy is used to reduce the effect of selection bias. An example involving source localization of a Poisson source is presented to illustrate the proposed approach and demonstrate its performance.","Joints,
Maximum likelihood estimation,
Data models,
Mathematical model,
Distribution functions,
Position measurement"
A multi-modal approach for hand motion classification using surface EMG and accelerometers,"For decades, electromyography (EMG) has been used for diagnostics, upper-limb prosthesis control, and recently even for more general human-machine interfaces. Current commercial upper limb prostheses usually have only two electrode sites due to cost and space limitations, while researchers often experiment with multiple sites. Micro-machined inertial sensors are gaining popularity in many commercial and research applications where knowledge of the postures and movements of the body is desired. In the present study, we have investigated whether accelerometers, which are relatively cheap, small, robust to noise, and easily integrated in a prosthetic socket; can reduce the need for adding more electrode sites to the prosthesis control system. This was done by adding accelerometers to a multifunction system and also to a simplified system more similar to current commercially available prosthesis controllers, and assessing the resulting changes in classification accuracy. The accelerometer does not provide information on muscle force like EMG electrodes, but the results show that it provides useful supplementary information. Specifically, if one wants to improve a two-site EMG system, one should add an accelerometer affixed to the forearm rather than a third electrode.",
Intelligent Highway Traffic Surveillance With Self-Diagnosis Abilities,"In this paper, we propose a self-diagnosing intelligent highway surveillance system and design effective solutions for both daytime and nighttime traffic surveillance. For daytime surveillance, vehicles are detected via background modeling. For nighttime videos, headlights of vehicles need to be located and paired for vehicle detection. An algorithm based on likelihood computation is developed to pair the headlights of vehicles at night. Moreover, to balance between the robustness and abundance of acquired information, the proposed system adapts different strategies under different traffic conditions. Performing tracking would be preferred when traffic is smooth. However, under congestion conditions, it is better to obtain traffic parameters by estimation. We utilize a time-varying adaptive system state transition matrix in Kalman filter for better prediction in a traffic surveillance scene when performing tracking. We also propose a mechanism for estimating the traffic flow parameter via regression analysis. The experimental results have shown that the self-diagnosis ability and the modules designed for the system make the proposed system robust and reliable.","Regression analysis,
Surveillance,
Tracking,
Histograms,
Road transportation"
Secure Communications Over Wireless Broadcast Networks: Stability and Utility Maximization,"A wireless broadcast network model with secrecy constraints is investigated, in which a source node broadcasts K confidential message flows to K user nodes, with each message intended to be decoded accurately by one user and to be kept secret from all other users (who are thus considered to be eavesdroppers with regard to all other messages but their own). The source maintains a queue for each message flow if it is not served immediately. The channel from the source to the K users is modeled as a fading broadcast channel, and the channel state information is assumed to be known to the source and the corresponding receivers. Two eavesdropping models are considered. For a collaborative eavesdropping model, in which the eavesdroppers exchange their outputs, the secrecy capacity region is obtained, within which each rate vector is achieved by using a time-division scheme and a source power control policy over channel states. A throughput optimal queue-length-based rate scheduling algorithm is further derived that stabilizes all arrival rate vectors contained in the secrecy capacity region. Moreover, the network utility function is maximized via joint design of rate control, rate scheduling, power control, and secure coding. More precisely, a source controls the message arrival rate according to its message queue, the rate scheduling selects a transmission rate based the queue length vector, and the rate vector is achieved by power control and secure coding. These components work jointly to solve the network utility maximization problem. For a noncollaborative eavesdropping model, in which eavesdroppers do not exchange their outputs, an achievable secrecy rate region is derived based on a time-division scheme, and the queue-length-based rate scheduling algorithm and the corresponding power control policy are obtained that stabilize all arrival rate vectors in this region. The network utility maximizing rate control vector is also obtained.","Security,
Power control,
Stability analysis,
Physical layer,
Encoding,
Communication system security"
GPU-Assisted Computation of Centroidal Voronoi Tessellation,"Centroidal Voronoi tessellations (CVT) are widely used in computational science and engineering. The most commonly used method is Lloyd's method, and recently the L-BFGS method is shown to be faster than Lloyd's method for computing the CVT. However, these methods run on the CPU and are still too slow for many practical applications. We present techniques to implement these methods on the GPU for computing the CVT on 2D planes and on surfaces, and demonstrate significant speedup of these GPU-based methods over their CPU counterparts. For CVT computation on a surface, we use a geometry image stored in the GPU to represent the surface for computing the Voronoi diagram on it. In our implementation a new technique is proposed for parallel regional reduction on the GPU for evaluating integrals over Voronoi cells.","Computer science,
Computational geometry,
Computer graphics,
Visualization,
Hardware,
Application software,
Pattern recognition,
Art,
Computational modeling,
Mesh generation"
Using Bayesian Filtering to Localize Flexible Materials During Manipulation,"Localization and manipulation of features such as buttons, snaps, or grommets embedded in fabrics and other flexible materials is a difficult robotics problem. Approaches that rely too much on sensing and localization that occurs before touching the material are likely to fail because the flexible material can move when the robot actually makes contact. This paper experimentally explores the possibility to use proprioceptive and load-based tactile information to localize features embedded in flexible materials during robot manipulation. In our experiments, Robonaut 2, a robot with human-like hands and arms, uses particle filtering to localize features based on proprioceptive and tactile measurements. Our main contribution is to propose a method to interact with flexible materials that reduces the state space of the interaction by forcing the material to comply in repeatable ways. Measurements are matched to a “haptic map,” which is created during a training phase, that describes expected measurements as a low-dimensional function of state. We evaluate localization performance when using proprioceptive information alone and when tactile data are also available. The two types of measurements are shown to contain complementary information. We find that the tactile measurement model is critical to localization performance and propose a series of models that offer increasingly better accuracy. Finally, this paper explores the localization approach in the context of two flexible material insertion tasks that are relevant to manufacturing applications.","Materials,
Training,
Robots,
Sensors,
Joints,
Thumb,
Bayesian methods"
On Dynamic Server Provisioning in Multichannel P2P Live Streaming,"To guarantee the streaming quality in live peer-to-peer (P2P) streaming channels, it is preferable to provision adequate levels of upload capacities at dedicated streaming servers, compensating for peer instability and time-varying peer upload bandwidth availability. Most commercial P2P streaming systems have resorted to the practice of overprovisioning a fixed amount of upload capacity on streaming servers. In this paper, we have performed a detailed analysis on 10 months of run-time traces from UUSee, a commercial P2P streaming system, and observed that available server capacities are not able to keep up with the increasing demand by hundreds of channels. We propose a novel online server capacity provisioning algorithm that proactively adjusts server capacities available to each of the concurrent channels, such that the supply of server bandwidth in each channel dynamically adapts to the forecasted demand, taking into account the number of peers, the streaming quality, and the channel priority. The algorithm is able to learn over time, has full Internet service provider (ISP) awareness to maximally constrain P2P traffic within ISP boundaries, and can provide differentiated streaming qualities to different channels by manipulating their priorities. To evaluate its effectiveness, our experiments are based on an implementation of the algorithm, which replays real-world traces.","Servers,
Bandwidth,
Peer to peer computing,
Correlation,
Time series analysis,
Protocols,
Ash"
Towards Situational Awareness of Large-Scale Botnet Probing Events,"Botnets dominate today's attack landscape. In this work, we investigate ways to analyze collections of malicious probing traffic in order to understand the significance of large-scale “botnet probes.” In such events, an entire collection of remote hosts together probes the address space monitored by a sensor in some sort of coordinated fashion. Our goal is to develop methodologies by which sites receiving such probes can infer-using purely local observation-information about the probing activity: What scanning strategies does the probing employ? Is this an attack that specifically targets the site, or is the site only incidentally probed as part of a larger, indiscriminant attack? Our analysis draws upon extensive honeynet data to explore the prevalence of different types of scanning, including properties, such as trend, uniformity, coordination, and darknet avoidance. In addition, we design schemes to extrapolate the global properties of scanning events (e.g., total population and target scope) as inferred from the limited local view of a honeynet. Cross-validating with data from DShield shows that our inferences exhibit promising accuracy.","Grippers,
Protocols,
Probes,
Security,
IP networks,
Redundancy,
Testing"
An Infinite Sequence of Additive Channels: The Classical Capacity of Cloning Channels,"We introduce an infinite sequence of quantum channels for which the Holevo capacity is additive. The channel series is closely related to the quantum channels arising from universal quantum cloning machines. The additivity proof is motivated by a special property the studied channels enjoy: the property of conjugate degradability. As a consequence of the announced proof, we also provide an easy way of proving the additivity of the Holevo capacity for the original Unruh channel for which the quantum capacity is already known. Consequently, we present not only an infinite series of finite-dimensional channels but also a nontrivial example of an infinite-dimensional channel for which the classical and quantum channel capacities are easily calculable.","Cloning,
Additives,
Observers,
Hilbert space,
Channel capacity,
Photonics,
Acceleration"
Decentralized support detection of multiple measurement vectors with joint sparsity,"This paper considers the problem of finding sparse solutions from multiple measurement vectors (MMVs) with joint sparsity. The solutions share the same sparsity structure, and the locations of the common nonzero support contain important information of signal features. When the measurement vectors are collected from spatially distributed users, the issue of decentralized support detection arises. This paper develops a decentralized row-based Lasso (DR-Lasso) algorithm for the distributed MMV problem. A penalty term on row-based total energy is introduced to enforce joint sparsity for the MMVs, and consensus constraints are formulated such that users can consent on the total energy, and hence the common nonzero support, in a decentralized manner. As an illustrative example, the problem of cooperative spectrum occupancy detection is solved in the context of wideband cognitive radio networks.",
Comparison of Texture Analysis Schemes Under Nonideal Conditions,"Several recent advancements in the field of texture analysis prompt some fundamental questions. For instance, what is the true impact of these novel advancements under real-world environments? When do these novel advancements fail to perform? Which methods perform better and under what conditions? In this work, we investigate these and other issues under nonideal image acquisition environments, specifically, environments with changing conditions due to illumination variations and those caused by both affine and nonaffine transformations. We study the performance of nine popular texture analysis algorithms using three different datasets, with varying levels of difficulty. Experiments are performed on nonideal texture datasets under five different setups. We find that most state-of-the-art techniques do not perform well under these conditions. To a large extent, their performance under nonideal conditions depends critically on the nature of the textural surface. Moreover, most techniques fail to perform reliably when the number of classes in the dataset is increased significantly, over the regular-size datasets used in previous work. Multiscale features performed reasonably well against variations caused by illumination and rotation but are prone to fail under changes in scale. Surprisingly, the performance for most of the algorithms is generally stable on structured or periodic textures, even with variations in illumination or affine transformations.","Algorithm design and analysis,
Lighting,
Surface texture,
Three dimensional displays,
Light sources,
Training,
Image color analysis"
Complementary hashing for approximate nearest neighbor search,"Recently, hashing based Approximate Nearest Neighbor (ANN) techniques have been attracting lots of attention in computer vision. The data-dependent hashing methods, e.g., Spectral Hashing, expects better performance than the data-blind counterparts, e.g., Locality Sensitive Hashing (LSH). However, most data-dependent hashing methods only employ a single hash table. When higher recall is desired, they have to retrieve exponentially growing number of hash buckets around the bucket containing the query, which may drag down the precision rapidly. In this paper, we propose a so-called complementary hashing approach, which is able to balance the precision and recall in a more effective way. The key idea is to employ multiple complementary hash tables, which are learned sequentially in a boosting manner, so that, given a query, its true nearest neighbors missed from the active bucket of one hash table are more likely to be found in the active bucket of the next hash table. Compared with LSH that also can exploit multiple hash tables, our approach is more effective to find true NNs, thanks to the complementarity property of the hash tables from our approach. Experimental results on large scale ANN search show that the proposed method significantly improves the performance and outperforms the state-of-the-art.",
Integration of Self-Assembled Redox Molecules in Flash Memory Devices,"Self-assembled monolayers (SAMs) of either ferrocenecarboxylic acid or 5-(4-Carboxyphenyl)-10,15,20-triphenyl-porphyrin-Co(II) (CoP) with a high- dielectric were integrated into the Flash memory gate stack. The molecular reduction-oxidation (redox) states are used as charge storage nodes to reduce charging energy and memory window variations. Through the program/erase operations over tunneling barriers, the device structure also provides a unique capability to measure the redox energy without strong orbital hybridization of metal electrodes in direct contact. Asymmetric charge injection behavior was observed, which can be attributed to the Fermi-level pinning between the molecules and the high- dielectric. With increasing redox molecule density in the SAM, the memory window exhibits a saturation trend. Three programmable molecular orbital states, i.e., CoP0, CoP1-, and CoP2-, can be experimentally observed through a charge-based nonvolatile memory structure at room temperature. The electrostatics is determined by the alignment between the highest occupied or the lowest unoccupied molecular orbital (HOMO or LUMO, respectively) energy levels and the charge neutrality level of the surrounding dielectric. Engineering the HOMO-LUMO gap with different redox molecules can potentially realize a multibit memory cell with less variation.",
Energy-Efficient Channel-Dependent Cooperative Relaying for the Multiuser SC-FDMA Uplink,"In this paper, we exploit the benefits of combining the diversity gains that arise from cooperation, multiple propagation paths, and opportunistic relaying (OR) of multiple users. Our goal is to improve the energy efficiency of the amplify-and forward (AF) single-relay-assisted single-carrier frequency-division multiple-access (SC-FDMA) uplink, where the single relay considered may support a single user or may be shared by multiple users who communicate over dispersive channels subject to large-scale fading. Based on the proposed amalgam of single-tap frequency-domain equalization (FDE) and a diversity-combining-aided receiver that relies on the minimum mean-square error (MMSE) criterion, three different relay selection schemes designed for either single-user or multiuser relaying scenarios are investigated, when combined with source/relay power sharing, which employ imperfect power control. Our results demonstrate that, at a bit error ratio (BER) of 10-4, the proposed receiver can save 2 dB power by achieving a higher cooperative diversity gain than the conventional receiver. Moreover, a beneficial energy efficiency improvement may be achieved when the cooperative regime operates at Eb/N0<; 0. Most importantly, when the shadowing variance is increased from 4 dB to 8 dB, the energy consumption gain gleaned from our multiuser and multiaccess relay selection schemes may increase to 4~9, compared with the direct transmission in the absence of shadowing at Eb|N0 = -10 dB.",
Cloud Computing Interoperability: The State of Play,"Cloud computing is a promising IT paradigm which enables the Internet's evolution into a global market of collaborating services. Cloud computing semantic interoperability plays a key role in making this a reality. Towards this direction, a comprehensive and systematic survey of Cloud computing interoperability efforts by standardization groups, industry and research community is carried out. The main objective of this survey is to derive an initial set of semantic interoperability requirements to be supported by existing as well as next generation Cloud systems. Ôhe survey motivates and encourages the Cloud community to adopt a common Cloud computing interoperability framework with core dimensions the creation of a common data model and a standardized Cloud interface (API), which will constitute the base for the development of a semantically interoperable Cloud environment.","Cloud computing,
Semantics,
Computational modeling,
Data models,
Standards,
Computer architecture"
Hearing is believing: Detecting mobile primary user emulation attack in white space,"In cognitive radio networks, an adversary transmits signals whose characteristics emulate those of primary users, in order to prevent secondary users from transmitting. Such an attack is called primary user emulation (PUE) attack. There are two main types of primary users in white space: TV towers and wireless microphones. Existing work on PUE attack detection focused on the first category. However, for the latter category, primary users are mobile and their transmission power is low. These unique properties of wireless microphones introduce great challenges and existing methods are not applicable. In this paper, we propose a novel method to detect the PUE attack of mobile primary users. We exploit the correlations between RF signals and acoustic information to verify the existence of wireless microphones. The effectiveness of our approach is validated through extensive real-world experiments. It shows that our method achieves both false positive rate and false negative rate lower than 0.1.","Microphones,
Variable speed drives,
Transmitters,
Microwave integrated circuits"
Fiber Endoscopes Utilizing Liquid Tunable-Focus Microlenses Actuated Through Infrared Light,"We report on prototype fiber endoscopes with tunable-focus liquid microlenses integrated at their distal ends and actuated through infrared (IR) light. Tunable-focus microlenses allow minimal back-and-forth movements of the scopes themselves and different depths of focus (DOFs), thus having spatial depth perception in the obtained images. The liquid microlens was formed by a water-oil meniscus pinned at a hydrophobic-hydrophilic boundary at an aperture. IR light-responsive hydrogel microstructures were formed by photopatterning thermo-responsive N-isopropylacrylamide hydrogel with entrapped IR light absorbing gold nanoparticles. The volumetric change in the hydrogel microstructures regulated the pressure difference across the water-oil interface and thus varied its focal length. The operations of the microlenses were realized through light transmitted via optical fibers. The images obtained from the microlenses were transferred via image fiber bundles. For two alignments between the hydrogel structures and the fibers, the response times of the microlenses are 65 and 20 s, respectively. Images of the simulated polyps in simulated colons were obtained. The range of focal length of a typical microlens was from 52 to 8 mm. The angle of view of an endoscope was from 77° to 128°. A microlens array could potentially be utilized to simultaneously obtain different DOFs and to increase the field of view.","Lenses,
Microoptics,
Endoscopes,
Optical imaging,
Nanoparticles,
Gold,
Microstructure"
Evaluation of image features using a photorealistic virtual world,"Image features are widely used in computer vision applications. They need to be robust to scene changes and image transformations. Designing and comparing feature descriptors requires the ability to evaluate their performance with respect to those transformations. We want to know how robust the descriptors are to changes in the lighting, scene, or viewing conditions. For this, we need ground truth data of different scenes viewed under different camera or lighting conditions in a controlled way. Such data is very difficult to gather in a real-world setting. We propose using a photorealistic virtual world to gain complete and repeatable control of the environment in order to evaluate image features. We calibrate our virtual world evaluations by comparing against feature rankings made from photographic data of the same subject matter (the Statue of Liberty). We find very similar feature rankings between the two datasets. We then use our virtual world to study the effects on descriptor performance of controlled changes in viewpoint and illumination. We also study the effect of augmenting the descriptors with depth information to improve performance.","Vectors,
Robustness"
On-chip biochemical sample preparation using digital microfluidics,"Sample preparation plays a pivotal role in bioassay operations on digital microfluidic biochips (DMFBs). This paper proposes a dilution/mixing method with high utilization of intermediate droplets for preparing biochemical samples of multiple target concentrations on DMFBs. It provides the first solution to the problem of generating samples of multiple target concentrations. Unlike prior work in which the preparation of droplets of multiple target concentrations has to be carried out sequentially, this proposed approach takes a global view and all the target concentrations are processed concurrently. In addition, this is also the first approach that minimizes the number of waste droplets by utilizing intermediate droplets. Finally, the number of mixing steps can be reduced, leading to reduced completion time for sample preparation. The number of waste droplets is minimized by reducing the number of intermediate concentrations produced during sample preparation. Usable intermediate droplets are subsequently utilized to further reduce wastage. Simulation results show that the proposed method can achieve up to 71% reduction in the number of waste droplets and up to 50% reduction in sample preparation time.",
Self-Reconfigurable Wireless Mesh Networks,"During their lifetime, multihop wireless mesh networks (WMNs) experience frequent link failures caused by channel interference, dynamic obstacles, and/or applications' bandwidth demands. These failures cause severe performance degradation in WMNs or require expensive manual network management for their real-time recovery. This paper presents an autonomous network reconfiguration system (ARS) that enables a multiradio WMN to autonomously recover from local link failures to preserve network performance. By using channel and radio diversities in WMNs, ARS generates necessary changes in local radio and channel assignments in order to recover from failures. Next, based on the thus-generated configuration changes, the system cooperatively reconfigures network settings among local mesh routers. ARS has been implemented and evaluated extensively on our IEEE 802.11-based WMN test-bed as well as through ns2-based simulation. Our evaluation results show that ARS outperforms existing failure-recovery schemes in improving channel-efficiency by more than 90% and in the ability of meeting the applications' bandwidth demands by an average of 200%.","Quality of service,
Planning,
Bandwidth,
Wireless communication,
Monitoring,
Logic gates,
Routing protocols"
A Distributed Algorithm for Web Service Composition Based on Service Agent Model,"Agent-based service composition has provided a promising computing paradigm for the automatic web service composition. In this paper, a formal service agent model is proposed, which integrates the web service and software agent technologies into one cohesive entity. Based on the service agent model, a distributed planning algorithm for web service composition called DPAWSC is presented. DPAWSC formalizes web service composition into a graph search problem according to the dependence relations among service agents. The key to DPAWSC is that the alternative solution with smaller length has higher priority to be searched than one with larger length. DPAWSC is based on the distributed decision making of the autonomous service agents and addresses the distributed nature of web service composition. We evaluate the algorithm by simulation experiments and the results demonstrate that DPAWSC is effective for its ability to produce the high quality solution at a low cost of communications.",
Decentralized Optimal Control of a Class of Interconnected Nonlinear Discrete-Time Systems by Using Online Hamilton-Jacobi-Bellman Formulation,"In this paper, the direct neural dynamic programming technique is utilized to solve the Hamilton-Jacobi-Bellman equation forward-in-time for the decentralized near optimal regulation of a class of nonlinear interconnected discrete-time systems with unknown internal subsystem and interconnection dynamics, while the input gain matrix is considered known. Even though the unknown interconnection terms are considered weak and functions of the entire state vector, the decentralized control is attempted under the assumption that only the local state vector is measurable. The decentralized nearly optimal controller design for each subsystem consists of two neural networks (NNs), an action NN that is aimed to provide a nearly optimal control signal, and a critic NN which evaluates the performance of the overall system. All NN parameters are tuned online for both the NNs. By using Lyapunov techniques it is shown that all subsystems signals are uniformly ultimately bounded and that the synthesized subsystems inputs approach their corresponding nearly optimal control inputs with bounded error. Simulation results are included to show the effectiveness of the approach.","Cost function,
Optimal control,
Artificial neural networks,
Approximation methods,
Equations,
Nonlinear systems,
Interconnected systems"
Plastic-Based Supershaped Dielectric Resonator Antennas for Wide-Band Applications,"Novel cylindrical dielectric resonator antennas (DRAs) having supershaped base contour and adopting plastic materials for the resonator are studied. The specialization of the supershaped DRAs to the generation of linearly and circularly polarized waves is discussed, analyzed and experimentally verified. The resulting antennas exhibit wide-band (WB) performance in terms of input impedance matching, radiation patterns, realized gain and polarization properties. The proposed class of antennas shows broadside radiation with broad and smooth patterns stable over frequency, efficient and stable radiation and wide matching bandwidths. These antennas can potentially find application as access points for indoor multimedia radio systems.","Antenna measurements,
Antenna radiation patterns,
Probes,
Bandwidth,
Feeds,
Frequency measurement,
Materials"
Microwave Bessel Beams Generation Using Guided Modes,"A novel method is devised for Bessel beams generation in the microwave regime. The beam is decomposed in terms of a number of guided transverse electric modes of a metallic waveguide. Modal expansion coefficients are computed from the modal power orthogonality relation. Excitation is achieved by means of a number of inserted coaxial loop antennas, whose currents are calculated from the excitation coefficients of the guided modes. The efficiency of the method is evaluated and its feasibility is discussed. Obtained results can be utilized to practically realize microwave Bessel beam launchers.",
Latent fingerprint enhancement via robust orientation field estimation,"Latent fingerprints, or simply latents, have been considered as cardinal evidence for identifying and convicting criminals. The amount of information available for identification from latents is often limited due to their poor quality, unclear ridge structure and occlusion with complex back ground or even other latent prints. We propose a latent fingerprint enhancement algorithm, which expects manually marked region of interest (ROI) and singular points. The core of the proposed algorithm is a robust orientation field estimation algorithm for latents. Short-time Fourier transform is used to obtain multiple orientation elements in each image block. This is followed by a hypothesize-and test paradigm based on randomized RANSAC, which generates a set of hypothesized orientation fields. Experimental results on NIST SD27 latent fingerprint database show that the matching performance of a commercial matcher is significantly improved by utilizing the enhanced latent finger prints produced by the proposed algorithm.",
Learning Sparse Representations of Depth,"This paper introduces a new method for learning and inferring sparse representations of depth (disparity) maps. The proposed algorithm relaxes the usual assumption of the stationary noise model in sparse coding. This enables learning from data corrupted with spatially varying noise or uncertainty, such as that obtained by laser range scanners or structured light depth cameras. Sparse representations are learned from the Middlebury database disparity maps and then exploited in a two-layer graphical model for inferring depth from stereo, by including a sparsity prior on the learned features. Since they capture higher order dependencies in the depth structure, these priors can complement smoothness priors commonly used in depth inference based on Markov random field (MRF) models. Inference on the proposed graph is achieved using an alternating iterative optimization technique, where the first layer is solved using an existing MRF-based stereo matching algorithm, then held fixed as the second layer is solved using the proposed nonstationary sparse coding algorithm. This leads to a general method for improving solutions of state-of-the-art MRF-based depth estimation algorithms. Our experimental results first show that depth inference using learned representations leads to state-of-the-art denoising of depth maps obtained from laser range scanners and a time of flight camera. Furthermore, we show that adding sparse priors improves the results of depth estimation methods based on graph cut optimization of MRFs with first and second order priors.",
Use case analysis of real-time low voltage network management,"Real-time low voltage network management is becoming possible thanks to massive smart meter rollouts, integration of them to distribution network management systems and utilization of distributed energy resources in distribution network management. Nowadays low voltage network management is emerging by integrating automatic meter infrastructure to centralized systems like SCADA/DMS. European project INTEGRIS is proposing a distributed approach based on hybrid and meshed communication. The paper is focused on low voltage network management use cases developed within the context of INTEGRIS and their ICT requirements to test the level of performance provided by the ICT architecture developed in the mentioned project.",
Performance analysis of left/right hand movement classification from EEG signal by intelligent algorithms,"Brain Computer interfaces (BCI) has immense potentials to improve human lifestyle including that of the disabled. BCI has possible applications in the next generation human-computer, human-robot and prosthetic/assistive devices for rehabilitation. The dataset used for this study has been obtained from the BCI competition-II 2003 databank provided by the University of Technology, Graz. After pre-processing of the signals from their electrodes (C3 & C4), the wavelet coefficients, Power Spectral Density of the alpha and the central beta band and the average power of the respective bands have been employed as features for classification. This paper presents a comparative study of different classification methods including linear discriminant analysis (LDA), Quadratic discriminant analysis (QDA), k-nearest neighbor (KNN) algorithm, linear support vector machine (SVM), radial basis function (RBF) SVM and naive Bayesian classifiers algorithms in differentiating the raw EEG data obtained, into their associative left/right hand movements. Performance of left/right hand classification is studied using both original features and reduced features. The feature reduction here has been performed using Principal component Analysis (PCA). It is as observed that RBF kernelised SVM classifier indicates the highest performance accuracy of 82.14% with both original and reduced feature set. However, experimental results further envisage that all the other classification techniques provide better classification accuracy for reduced data set in comparison to the original data. It is also noted that the KNN classifier improves the classification accuracy by 5% when reduced features are used instead of the original.","Electroencephalography,
Electrodes,
Feature extraction,
Algorithm design and analysis,
Support vector machine classification,
Principal component analysis"
Simultaneous Support Recovery in High Dimensions: Benefits and Perils of Block \ell _{1}/\ell _{\infty} -Regularization,"Given a collection of r ≥ 2 linear regression problems in p dimensions, suppose that the regression coefficients share partially common supports of size at most s. This set-up suggests the use of ℓ1/ℓ∞-regularized regression for joint estimation of the p×r matrix of regression coefficients. We analyze the high-dimensional scaling of ℓ1/ℓ∞-regularized quadratic programming, considering both consistency rates in ℓ∞-norm, and how the minimal sample size n required for consistent variable selection scales with model dimension, sparsity, and overlap between the supports. We first establish bounds on the ℓ∞-error as well sufficient conditions for exact variable selection for fixed design matrices, as well as for designs drawn randomly from general Gaussian distributions. Specializing to the case r = 2 linear regression problems with standard Gaussian designs whose supports overlap in a fraction α ∈ [0,1] of their entries, we prove that ℓ1/ℓ∞-regularized method undergoes a phase transition characterized by the rescaled sample size θ1,∞(n, p, s, α) = n/{(4 - 3 α) s log(p-(2- α) s)}. An implication is that the use of ℓ1/ℓ∞-regularization yields improved statistical efficiency if the overlap parameter is large enough ( α >; 2/3), but has worse statistical efficiency than a naive Lasso-based approach for moderate to small overlap (α <; 2/3 ). Empirical simulations illustrate the close agreement between theory and actual behavior in practice. These results show that caution must be exercised in applying ℓ1/ℓ∞ block regularization: if the data does not match its structure very closely, it can impair statistical performance relative to computationally less expensive schemes.","Input variables,
Estimation,
Symmetric matrices,
Multivariate regression,
Joints,
Noise,
Linear regression"
On the Relationship Between Double Bounce and the Orientation of Buildings in VHR SAR Images,"In this letter, we study empirically the relation between the double-bounce effect of buildings in very high resolution (VHR) synthetic aperture radar (SAR) and the orientation angle for two different ground materials (i.e., asphalt and grass) by analyzing two different TerraSAR-X VHR spaceborne SAR images. Furthermore, we compare our empirical results with the simulations obtained using theoretical electromagnetic models. In order to deal with slightly rough surfaces, we also present a novel model for double-bounce scattering based on the small-perturbation method. We show that the double-bounce effect results in different power signatures, depending on the type of the building and the surrounding ground properties. Finally, we discuss the reliability of theoretical models for predicting the double-bounce power for the analyzed data sets. The models can predict the general behavior of the double bounce but lack in calculating the accurate double-bounce radar cross section reliably.",
Comparing Stochastic Approaches to Spoken Language Understanding in Multiple Languages,"One of the first steps in building a spoken language understanding (SLU) module for dialogue systems is the extraction of flat concepts out of a given word sequence, usually provided by an automatic speech recognition (ASR) system. In this paper, six different modeling approaches are investigated to tackle the task of concept tagging. These methods include classical, well-known generative and discriminative methods like Finite State Transducers (FSTs), Statistical Machine Translation (SMT), Maximum Entropy Markov Models (MEMMs), or Support Vector Machines (SVMs) as well as techniques recently applied to natural language processing such as Conditional Random Fields (CRFs) or Dynamic Bayesian Networks (DBNs). Following a detailed description of the models, experimental and comparative results are presented on three corpora in different languages and with different complexity. The French MEDIA corpus has already been exploited during an evaluation campaign and so a direct comparison with existing benchmarks is possible. Recently collected Italian and Polish corpora are used to test the robustness and portability of the modeling approaches. For all tasks, manual transcriptions as well as ASR inputs are considered. Additionally to single systems, methods for system combination are investigated. The best performing model on all tasks is based on conditional random fields. On the MEDIA evaluation corpus, a concept error rate of 12.6% could be achieved. Here, additionally to attribute names, attribute values have been extracted using a combination of a rule-based and a statistical approach. Applying system combination using weighted ROVER with all six systems, the concept error rate (CER) drops to 12.0%.",
A Three-Dimensional 64-Site Folded Electrode Array Using Planar Fabrication,"Neuroscience and neuroprosthetic devices are increasingly in need of more compact less invasive 3-D electrode arrays for interfacing with neural tissue. To meet these needs, a folding 64-site 3-D array architecture has been developed. The microstructure, in which four probes and two platforms are fabricated as a single planar unit, results in a low-profile (<; 350-μm) narrow-platform (0.604-mm2 silicon footprint) implant for cortical use. Signals are routed from 177-μm2 iridium sites through polysilicon lines to the probe back end and then across 4-μm-thick parylene-encased electroplated-gold folding lead transfers to the associated platform. Three levels of interconnect with a 10-μm minimum pitch are utilized for the 32 leads that traverse the platforms. After rapid microassembly, micromachined latches are used to fasten the folded device. Two flexible parylene cables with gold leads at a 20- μm pitch are monolithically integrated with the probes to minimize tethering and avoid any need for lead bonding within the array, and these cables carry the neural signals to a remote circuit module or percutaneous connector. With thin (~15-μm) boron-doped shanks at a ~ 200-μm pitch, the array displaces only 1.7% of the 0.64-mm2 instrumented tissue area, assuming a 100-μm recording range. Neural signals were recorded in vivo from the guinea pig auditory cortex.","Probes,
Arrays,
Assembly,
Lead,
Gold,
Electrodes,
Latches"
Multivariate Compressive Sensing for Image Reconstruction in the Wavelet Domain: Using Scale Mixture Models,"Most wavelet-based reconstruction methods of compressive sensing (CS) are developed under the independence assumption of the wavelet coefficients. However, the wavelet coefficients of images have significant statistical dependencies. Lots of multivariate prior models for the wavelet coefficients of images have been proposed and successfully applied to the image estimation problems. In this paper, the statistical structures of the wavelet coefficients are considered for CS reconstruction of images that are sparse or compressive in wavelet domain. A multivariate pursuit algorithm (MPA) based on the multivariate models is developed. Several multivariate scale mixture models are used as the prior distributions of MPA. Our method reconstructs the images by means of modeling the statistical dependencies of the wavelet coefficients in a neighborhood. The proposed algorithm based on these scale mixture models provides superior performance compared with many state-of-the-art compressive sensing reconstruction algorithms.",
Learning universal multi-view age estimator using video context,"Many existing techniques for analyzing face images assume that the faces are at nearly frontal. Generalizing to non-frontal faces is often difficult, due to a dearth of ground truth for non-frontal faces and also to the inherent challenges in handling pose variations. In this work, we investigate how to learn a universal multi-view age estimator by harnessing 1) unlabeled web videos, 2) a publicly available labeled frontal face corpus, and 3) zero or more non-frontal faces with age labels. First, a large diverse human-involved video corpus is collected from online video sharing website. Then, multi-view face detection and tracking are performed to build a large set of frontal-vs-profile face bundles, each of which is from the same tracking sequence, and thus exhibiting the same age. These unlabeled face bundles constitute the so-called video context, and the parametric multi-view age estimator is trained by 1) enforcing the face-to-age relation for the partially labeled faces, 2) imposing the consistency of the predicted ages for the non-frontal and frontal faces within each face bundle, and 3) mutually constraining the multi-view age models with the spatial correspondence priors derived from the face bundles. Our multi-view age estimator performs well on a realistic evaluation dataset that contains faces under varying poses, and whose ground truth age was manually annotated.",
System-Oriented Harmonic-Balance Algorithms for Circuit-Level Simulation,"This paper discusses a self-consistent set of modern computational concepts providing an effective approach to the circuit-level harmonic-balance (HB) simulation of nonlinear microwave systems of complex topology. The system is automatically split into the interconnection of a near-optimal number of nonlinear blocks at run time. The resulting structure is then exploited by the domain-partitioning concept. A block-wise constant spectrum is used rather than a common spectrum by considering for each block only the set of spectral lines that are relevant to its electrical function, which leads to a very significant reduction in the number of problem unknowns. System simulation under digitally modulated RF drive is reduced to a sequence of modified multitone HB analyses that are backward coupled through the envelope dynamics. Besides providing high numerical efficiency, this set of techniques opens the way to an effective co-simulation of RF and baseband transceiver sections.","Jacobian matrices,
Equations,
Integrated circuit modeling,
Harmonic analysis,
Integrated circuit interconnections,
Mathematical model,
DH-HEMTs"
Continuous emotion detection in response to music videos,"Viewers' preference for multimedia selection depends highly on their emotional experience. In this paper, we present an emotion detection method for music videos using central and peripheral nervous system physiological signals as well as multimedia content analysis. A set of 40 music clips eliciting a broad range of emotions were first selected. After extracting the one minute long emotional highlight of each video, they were shown to 32 participants while their physiological responses were recorded. Participants self-reported their felt emotions after watching each clip by means of arousal, valence, dominance, and liking ratings. The physiological signals included electroencephalogram, galvanic skin response, respiration pattern, skin temperature, electromyograms and blood volume pulse using plethysmograph. Emotional features were extracted from the signals and the multimedia content. The emotional features were used to train a linear ridge regressor to detect emotions for each participant using a leave-one-out cross-validation strategy. The performance of the personalized emotion detection is shown to be significantly superior to a random regressor.",
"Design, characterization and management of a wireless sensor network for smart gas monitoring","Air quality monitoring in indoor environments is of great significance for comfort and health, especially nowadays that people spend more than 80% of the day indoor. We propose a flexible wireless system able to detect polluted air and dangerous situations in a complex and large environment. It is important for ambient intelligent systems to be unobtrusive and to optimize the power consumption of the platforms in order to be able to live on batteries for several years. We present a system with aggressive energy management that involves three levels: sensor level, node level and network level. The sensor board we designed is a wireless sensor network (WSN) node, with very low sleep current consumption (only 8 μA). It contains two modalities - a gas sensor and a Pyroelectric InfraRed (PIR) sensor. The network is multimodal: it uses information from the PIR sensor and neighbor nodes to detect the presence of people and to modulate the duty cycle of the node and the Metal Oxide Semiconductor (MOX) gas sensor. In this way we reduce the nodes' activity and energy requirements, providing a reliable service at the same time. We simulate the benefits of the context-aware adaptive duty-cycling of the gas sensor activity and we demonstrate a significant lifetime extension compared to the continuously driven gas sensor (several years vs. several days).","Gas detectors,
Power demand,
Monitoring,
Wireless sensor networks,
Temperature sensors,
Energy consumption,
Transceivers"
A Connotative Space for Supporting Movie Affective Recommendation,"The problem of relating media content to users' affective responses is here addressed. Previous work suggests that a direct mapping of audio-visual properties into emotion categories elicited by films is rather difficult, due to the high variability of individual reactions. To reduce the gap between the objective level of video features and the subjective sphere of emotions, we propose to shift the representation towards the connotative properties of movies, in a space inter-subjectively shared among users. Consequently, the connotative space allows to define, relate, and compare affective descriptions of film videos on equal footing. An extensive test involving a significant number of users watching famous movie scenes suggests that the connotative space can be related to affective categories of a single user. We apply this finding to reach high performance in meeting user's emotional preferences.","Motion pictures,
Semantics,
Recommender systems,
Physiology,
Human factors"
HomeWeb: An application framework for Web-based smart homes,"Household appliances are being equipped with embedded micro-controllers and wireless transceivers, offering smart behavior. These augmented appliances form wireless networks and transform residential areas into smart homes. Advancements such as the effective penetration of the Internet in embedded computing and the promising practice of the Web of Things, allow the realization of Web-oriented smart homes. In a previous work, we developed a Web-based application framework for smart homes, supporting concurrent interaction from multiple family members. In this paper, we improve the functionality of our system by including a 6LoWPAN-based wireless sensor network inside the home environment, addressing issues such as device discovery and service description. Web techniques such as HTTP caching and push messaging, facilitate the efficient operation of a fully Web-based smart home. Through a technical evaluation, we show the benefits of directly Web-enabling embedded sensors in terms of performance and energy conservation. The development of a Web-based graphical application abstracts home automation procedure for typical residents.","Smart homes,
Wireless sensor networks,
Home appliances,
Mashups,
Protocols"
A Theoretical Development and Analysis of Jumping Gene Genetic Algorithm,"Recently, gene transpositions have gained their power and attentions in computational evolutionary algorithm designs. In 2004, the Jumping Gene Genetic Algorithm (JGGA) was first proposed and two new gene transposition operations, namely, cut-and-paste and copy-and-paste, were introduced. Although the outperformance of JGGA has been demonstrated by some detailed statistical analyses based on numerical simulations, more rigorous theoretical justification is still in vain. In this paper, a mathematical model based on schema is derived. It then provides theoretical justifications on why JGGA is superiority in searching, particularly when it is applied to solve multiobjective optimization problems. The studies are also further verified by solving some optimization problems and comparisons are made between different optimization algorithms.","Mathematical model,
Biological cells,
Genetic algorithms,
Optimization,
Computational modeling"
Face recognition across time lapse: On learning feature subspaces,"There is a growing interest in understanding the impact of aging on face recognition performance, as well as de- signing recognition algorithms that are mostly invariant to temporal changes. While some success has been made on this front, a fundamental questions has yet to be answered: do face recognition systems that compensate for the effects of aging compromise recognition performance for faces that have not undergone any aging? The studies in this paper help confirm that age invariant systems do seem to decrease performance in non-aging scenarios. This is demonstrated by performing training experiments on the largest face aging dataset studied in the literature to date (over 200,000 images from roughly 64,000 subjects). Further experiments conducted in this research help demonstrate the impact of aging on two leading commercial face recognition systems. We also determine the regions of the face that remain the most stable over time.","learning (artificial intelligence),
age issues,
face recognition,
feature extraction"
S-AKA: A Provable and Secure Authentication Key Agreement Protocol for UMTS Networks,"The authentication and key agreement (AKA) protocol of Universal Mobile Telecommunication System (UMTS), which is proposed to solve the vulnerabilities found in Global System for Mobile Communications (GSM) systems, is still vulnerable to redirection and man-in-the-middle attacks. An adversary can mount these attacks to eavesdrop or mischarge the subscribers in the system. In this paper, we propose a secure AKA (S-AKA) protocol to cope with these problems. The S-AKA protocol can reduce bandwidth consumption and the number of messages required in authenticating mobile subscribers. We also give the formal proof of the S-AKA protocol to guarantee its robustness.","Authentication,
3G mobile communication,
Bandwidth,
GSM,
Protocols"
Unified Bit-Based Probabilistic Data Association Aided MIMO Detection for High-Order QAM Constellations,"A unified bit-based probabilistic data association (B-PDA) detection approach is proposed for multiple-input-multiple-output (MIMO) systems employing high-order rectangular quadrature amplitude modulation (QAM). The new approach transforms the symbol detection process of QAM to a bit-based process by introducing a unified matrix representation (UMR) of QAM. Both linear natural and nonlinear binary reflected Gray bit-to-symbol mappings are considered. With the aid of simulation results, we demonstrate that the linear-natural-mapping-based B-PDA approach typically attained an improved detection performance [measured in terms of both bit error ratio (BER) and symbol error ratio (SER)] in comparison with the conventional symbol-based probabilistic data association (PDA)-aided MIMO detector, despite its dramatically reduced computational complexity. The only exception is that, at low SNRs, the linear-natural-mapping-based B-PDA is slightly inferior in terms of its BER to the conventional symbol-based PDA using binary reflected Gray mapping. Furthermore, the simulation results show that the linear-natural-mapping-based B-PDA MIMO detector may approach the best-case performance provided by the nonlinear binary reflected Gray-mapping-based B-PDA MIMO detector under ideal conditions. Additionally, the implementation of the B-PDA MIMO detector is shown to be much simpler in the case of the linear natural mapping. Based on these two points, we conclude that, in the context of the uncoded B-PDA MIMO detector, it is preferable to use the linear natural bit-to-symbol mapping, rather than the nonlinear Gray mapping.","Quadrature amplitude modulation,
MIMO,
Detectors,
Personal digital assistants,
Complexity theory,
Multiaccess communication"
DAQ Architecture Design of Daya Bay Reactor Neutrino Experiment,"The Daya Bay Reactor Neutrino Experiment consists of seventeen detectors distributed in three underground experimental halls. Each detector has a separate VME readout crate that contains the trigger and electronics modules. The data acquisition (DAQ) system reads data fragments from electronics and trigger modules and concatenates them into an event in each crate. The DAQ monitors the data quality, merges the event streams from each hall, and records these data to disk. The DAQ architecture is designed as a multi-level system based on the BESIII DAQ and ATLAS TDAQ systems using embedded Linux, VME bus system, advanced commercial computers and distributed network technologies. This paper presents the main DAQ design requirements, and the hardware and software architectures.","Data acquisition,
Detectors,
Software,
Servers,
Computer architecture,
Throughput,
Monitoring"
Testing the scalability of SaaS applications,"Cloud computing and SaaS (Software-as-a-Service) received significant attention recently. Testing SaaS applications is important because many mission-critical applications will be deployed on the cloud. However, to the best of our knowledge, testing framework designed specifically for SaaS applications is not developed. The issue of testing the scalability of SaaS applications remains untouched. This paper discusses the unique features and challenges in testing SaaS applications, and proposes scalability metrics that can be used to test the scalability of SaaS applications.","Scalability,
Testing,
Measurement,
Cloud computing,
Program processors,
Sun"
"Secure Stochastic ECG Signals Based on Gaussian Mixture Model for
e
-Healthcare Systems","The blood circulation system in a human body provides a unique and natural trust zone for secure data communications in wireless healthcare systems such as body area networks. Unfortunately, biometric signal authentication using physiological attributes in wireless healthcare has not been extensively studied. In this paper, we propose a data authentication approach utilizing electrocardiography (ECG) signal patterns for reducing key exchange overhead. The major contribution of this research is to apply stochastic pattern recognition techniques in wireless healthcare. In the proposed approach, the inter-pulse interval (IPI) signal pattern at transmitter side is summarized as a biometric authentication key using Gaussian mixture model (GMM). At the receiver side, a light-weight signature verification scheme is adopted that uses IPI signals gathered locally at the receiver. The proposed authentication scheme has the advantage of high sample misalignment tolerance. In our earlier work, we had demonstrated the concept of stochastic authentication for ECG signal, but the signature verification process and GMM authentication performance under time synchronization and various sample points were not discussed. Here, we present a new set of analytical and experimental results to demonstrate that the proposed stochastic authentication approach achieves a low half total error rate in ECG signals verification.","Electrocardiography,
Authentication,
Stochastic processes,
Body area networks,
Biometrics,
Pattern recognition"
A Local-Concentration-Based Feature Extraction Approach for Spam Filtering,"Inspired from the biological immune system, we propose a local concentration (LC)-based feature extraction approach for anti-spam. The LC approach is considered to be able to effectively extract position-correlated information from messages by transforming each area of a message to a corresponding LC feature. Two implementation strategies of the LC approach are designed using a fixed-length sliding window and a variable-length sliding window. To incorporate the LC approach into the whole process of spam filtering, a generic LC model is designed. In the LC model, two types of detector sets are at first generated by using term selection methods and a well-defined tendency threshold. Then a sliding window is adopted to divide the message into individual areas. After segmentation of the message, the concentration of detectors is calculated and taken as the feature for each local area. Finally, all the features of local areas are combined as a feature vector of the message. To evaluate the proposed LC model, several experiments are conducted on five benchmark corpora using the cross-validation method. It is shown that the LC approach cooperates well with three term selection methods, which endows it with flexible applicability in the real world. Compared to the global-concentration-based approach and the prevalent bag-of-words approach, the LC approach has better performance in terms of both accuracy and F1 measure. It is also demonstrated that the LC approach is robust against messages with variable message length.","Feature extraction,
Electronic mail,
Training,
Immune system,
Productivity,
Accuracy,
Artificial neural networks"
Matched public PUF: Ultra low energy security platform,"Hardware-based physically unclonable functions (PUFs) leverage intrinsic process variation of modern integrated circuits to provide interesting security solutions but either induce high storage requirements or require significant resources of at least one involved party. We use device aging to realize two identical unclonable modules that cannot be matched with any third such module. Each device enables rapid, low-energy computation of ultra-complex functions that are too complex for simulation in any reasonable time. The approach induces negligible area and energy costs and enables a majority of security protocols to be completed in a single or a few clock cycles.","Logic gates,
Aging,
Delay,
Public key,
Mathematical model,
Protocols"
Depth map coding using graph based transform and transform domain sparsification,"Depth map compression is important for compact “texture-plus-depth” representation of a 3D scene, where texture and depth maps captured from multiple camera viewpoints are coded into the same format. Having received such format, the decoder can synthesize any novel intermediate view using texture and depth maps of two neighboring captured views via depth-image-based rendering (DIBR). In this paper, we combine two previously proposed depth map compression techniques that promote sparsity in the transform domain for coding gain-graph-based transform (GBT) and transform domain sparsification (TDS) - together under one unified optimization framework. The key to combining GBT and TDS is to adaptively select the simplest transform per block that leads to a sparse representation. For blocks without detected prominent edges, the synthesized view's distortion sensitivity to depth map errors is low, and TDS can effectively identify a sparse depth signal in fixed DCT domain within a large search space of good signals with small synthesized view distortion. For blocks with detected prominent edges, the synthesized view's distortion sensitivity to depth map errors is high, and the search space of good depth signals for TDS to find sparse representations in DCT domain is small. In this case, GBT is first performed on a graph defining all detected edges, so that filtering across edges is avoided, resulting in a sparsity count ρ in GBT. We then incrementally add the most important edge to an initial no-edge graph, each time performing TDS in the resulting GBT domain, until the same sparsity count ρ is achieved. Experimentation on two sets of multiview images showed gain of up to 0.7dB in PSNR in synthesized view quality compared to previous techniques that employ either GBT or TDS alone.","Image edge detection,
Discrete cosine transforms,
Encoding,
Distortion,
Sensitivity,
Cameras"
Multi-Touch Table System for Medical Visualization: Application to Orthopedic Surgery Planning,"Medical imaging plays a central role in a vast range of healthcare practices. The usefulness of 3D visualizations has been demonstrated for many types of treatment planning. Nevertheless, full access to 3D renderings outside of the radiology department is still scarce even for many image-centric specialties. Our work stems from the hypothesis that this under-utilization is partly due to existing visualization systems not taking the prerequisites of this application domain fully into account. We have developed a medical visualization table intended to better fit the clinical reality. The overall design goals were two-fold: similarity to a real physical situation and a very low learning threshold. This paper describes the development of the visualization table with focus on key design decisions. The developed features include two novel interaction components for touch tables. A user study including five orthopedic surgeons demonstrates that the system is appropriate and useful for this application domain.","Three dimensional displays,
Surgery,
Biomedical image processing,
Orthopedic surgery"
An Indium-Free Transparent Resistive Switching Random Access Memory,We report an indium-free transparent resistive switching random access memory device based on GZO-Ga2O3-ZnO-Ga2O3 -GZO structure by metal-organic chemical vapor deposition. The memory device shows good transmittance in the visible region and bipolar resistive switching behavior with good cycling characteristics and retention time under room temperature. The conduction and resistive switching mechanism was discussed based on filament theory.,"Switches,
Zinc oxide,
Random access memory,
Ions,
Electrodes,
Sun"
Topology-Based Kernels With Application to Inference Problems in Alzheimer's Disease,"Alzheimer's disease (AD) research has recently witnessed a great deal of activity focused on developing new statistical learning tools for automated inference using imaging data. The workhorse for many of these techniques is the support vector machine (SVM) framework (or more generally kernel-based methods). Most of these require, as a first step, specification of a kernel matrix K between input examples (i.e., images). The inner product between images Ii and Ij in a feature space can generally be written in closed form and so it is convenient to treat K as “given.” However, in certain neuroimaging applications such an assumption becomes problematic. As an example, it is rather challenging to provide a scalar measure of similarity between two instances of highly attributed data such as cortical thickness measures on cortical surfaces. Note that cortical thickness is known to be discriminative for neurological disorders, so leveraging such information in an inference framework, especially within a multi-modal method, is potentially advantageous. But despite being clinically meaningful, relatively few works have successfully exploited this measure for classification or regression. Motivated by these applications, our paper presents novel techniques to compute similarity matrices for such topologically-based attributed data. Our ideas leverage recent developments to characterize signals (e.g., cortical thickness) motivated by the persistence of their topological features, leading to a scheme for simple constructions of kernel matrices. As a proof of principle, on a dataset of 356 subjects from the Alzheimer's Disease Neuroimaging Initiative study, we report good performance on several statistical inference tasks without any feature selection, dimensionality reduction, or parameter tuning.","Kernel,
Thickness measurement,
Topology,
Alzheimer's disease,
Neuroimaging,
Accuracy,
Surface treatment"
Automated Assessment in a Programming Tools Course,Automated assessment systems can be useful for both students and instructors. Ranking and immediate feedback can have a strongly positive effect on student learning. This paper presents an experience using automatic assessment in a programming tools course. The proposal aims at extending the traditional use of an online judging system with a series of assignments related to programming tools. Some empirical results on how students use an automated assessment system in a CS2 course are presented. Research suggested that automated assessment systems promoted the students' interest and produced statistically significant differences in the scores between experimental and control groups.,"Programming profession,
Testing,
Debugging,
Electronic learning,
Software,
Runtime"
Robust Network Codes for Unicast Connections: A Case Study,"We consider the problem of establishing reliable unicast connections across a communication network with nonuniform edge capacities. Our goal is to provide instantaneous recovery from single edge failures. With instantaneous recovery, the destination node can decode the packets sent by the source node even if one of the network edges fails, without the need of retransmission or rerouting. It has been recognized that the network coding technique offers significant advantages for this problem over standard solutions such as disjoint path routing and diversity coding. We focus on two cases of practical interest: 1) backup protection of a single flow that can be split into two subflows; and 2) shared backup protection of two unicast flows. We present an efficient network coding algorithm that operates over a small finite field (GF(2)). The small size of the underlying field results in a significant reduction in the computational and communication overhead associated with the practical implementation of the network coding technique. Our algorithm exploits the unique structure of minimum coding networks, i.e., networks that do not contain redundant edges. We also consider the related capacity reservation problem and present an approximation algorithm that finds a solution whose cost is at most two times more than the optimum.",
A Reciprocal and Extensible Architecture for Multiple-Target Tracking in a Smart Home,"Every home has its own unique considerations for location-aware applications. This makes a flexible architecture very crucial for efficiently integrating various tracking devices/models for adapting to real human needs. Here, we propose a reciprocal and extensible architecture to flexibly add/remove tracking sensors/models for tracking multiple targets in a smart home. Regarding tracking devices, we employ sensors from two different categories, those with seamless sensors and those with seamful ones. This allows us to take human-centric needs into consideration and to facilitate reciprocal and cooperative interaction among sensors from the two categories. Such reciprocal cooperation aims to increase the accuracy of location estimates and to compensate for the limitations of each sensor or a tracking algorithm, which allows us to track multiple targets simultaneously in a more reliable way. Moreover, the approach demonstrated in this paper can serve as a guideline to help users customize sensor arrangements to fulfill their requirements. Our experimental results, which comprise three tracking scenarios using a load sensory floor as the seamless sensor and RF identifications (RFIDs) as seamful sensors, demonstrate the effectiveness of the proposed architecture.","Smart homes,
Target tracking,
Intelligent sensors,
Humans,
Radiofrequency identification,
Home appliances,
Space technology,
Computer science,
Wearable sensors,
Chaos"
Capacity scaling of multihop cellular networks,"Wireless cellular networks are large-scale networks in which asymptotic capacity investigation is no longer a cliché. A substantial body of work has been carried out to improve the capacity of cellular networks by introducing ad hoc communications, resulting in the so-called multihop cellular networks. Most of the previous research allows ad hoc transmissions between certain source and destination pairs to alleviate base stations' relay burden. However, since reports show that Internet data traffic is becoming more and more dominant in cellular networks, we explore in this paper the capacity of multihop cellular networks with all traffic going through base stations and ad hoc transmissions only acting as relay. We first investigate the capacity of regular multihop cellular networks where both nodes and base stations are regularly placed. By fully exploiting the link rate variability, we find that multihop cellular networks can have higher per-node throughput than traditional cellular networks by a scaling factor of log2n. Then, for the first time we extend our study to the capacity of heterogeneous multihop cellular networks where nodes are distributed according to a general Inhomogeneous Poisson Process and base stations are randomly placed. We show that under certain conditions multihop cellular networks can also outperform traditional cellular networks by a scaling factor of log2n. Moreover, both throughput-fairness and bandwidth-fairness are considered as fairness constraints for both kinds of networks.",
Failure Localization for Shared Risk Link Groups in All-Optical Mesh Networks Using Monitoring Trails,"This paper considers the problem of out-of-band failure localization in all-optical mesh networks using bidirectional monitoring trails (bm-trails), where every possible link set with up to d arbitrary links is considered as a shared risk link group (SRLG). With the SRLG scenario, the bm-trail allocation problem is firstly formulated, which includes the phases of code assignment and bm-trail formation. In the first phase, each SRLG is uniquely coded by assigning each link with a nonadaptive d̅-separable combinatorial group testing code. Then, the second phase manipulates a sophisticated yet efficient bm-trail formation process through a novel greedy code-swapping mechanism, such that any SRLG failure can be unambiguously localized by collecting the alarms of the interrupted bm-trails. The algorithm prototype can be found in . Extensive simulation is conducted on hundreds of randomly generated planar topologies to verify the proposed approach in terms of the number of required bm-trails and the computational efficiency. Our approach is compared with previously reported counterparts, by which its merits are further demonstrated.","Monitoring,
Resource management,
Topology,
Complexity theory,
Network topology,
Testing,
Receivers"
Effect of time resolution of meteorological inputs on dynamic thermal rating calculations,"Dynamic thermal rating (DTR) of power transmission lines can provide a significant increase in transmission capacity compared to the more traditional static rating. This gained capacity can be used to increase the normal and emergency operational flexibility of power transmission systems. Ampacity values can be determined either directly or indirectly from sag or ambient weather conditions. The most important inputs to weather-based DTR systems are meteorological data. The data can be obtained in the form of instantaneous or averaged values, and with various sampling/update intervals. This study examines the effect of the character of the meteorological inputs on the performance of DTR calculations. The analysis is based on real high-resolution wind and temperature measurements. Owing to the random character of the updates with instantaneous weather data, the averaged inputs provide more accurate estimates of ampacity and temperature. Update intervals of 10 minutes are sufficient, while longer intervals cause significant calculation errors. This could lead to a substantial risk of conductor thermal overload. The presented results can be used for effective data management in DTR systems. They can help to avoid substantial errors in ampacity calculations, thus minimising the risk of transmission system outages and premature ageing of transmission conductors.","power transmission lines,
conductors (electric),
meteorology"
FOARS: FLUTE Based Obstacle-Avoiding Rectilinear Steiner Tree Construction,"In this paper, we present an algorithm called FOARS for obstacle-avoiding rectilinear Steiner minimal tree (OARSMT) construction. FOARS applies a top-down approach which first partitions the set of pins into several subsets uncluttered by obstacles. Then an obstacle-avoiding Steiner tree is generated for each subset by an obstacle aware version of the rectilinear Steiner minimal tree algorithm FLUTE. Finally, the trees are merged and refined to form the OARSMT. To guide the partitioning of pins, we propose a novel algorithm to construct a linear-sized obstacle-avoiding spanning graph which guarantees to contain a rectilinear minimum spanning tree if there is no obstacle. Experimental results show that FOARS is among the best algorithms in terms of both wirelength and runtime for testcases both with and without obstacles.","Algorithm design and analysis,
Partitioning algorithms,
Pins,
Steiner trees,
Routing,
Runtime,
Nearest neighbor searches"
Space-Time-Frequency Shift Keying for Dispersive Channels,"Inspired by the concept of the Space-Time Shift Keying (STSK) modulation, in this paper we proposed the Space-Frequency Shift Keying (SFSK) modulation as well as the Space-Time-Frequency Shift Keying (STFSK) concept which spreads the transmit signal not only across the space and time domains, but also the frequency domain. The performance of STSK modulation is degraded by about 2 dB, when the channel changes from uncorrelated frequency-flat fading to the frequency-selective environment of the 6-tap COST207 model. By contrast, as a benefit of Frequency Shift keying, the SFSK and STFSK schemes are capable of maintaining their performance also in frequency-selective fading environments. Finally, we demonstrate that the STSK and SFSK schemes constitute special cases of the STFSK modulation.","Frequency shift keying,
Fading,
Throughput,
Dispersion,
Channel models"
Video processing techniques for traffic flow monitoring: A survey,"Video-based traffic flow monitoring is a fast emerging field based on the continuous development of computer vision. A survey of the state-of-the-art video processing techniques in traffic flow monitoring is presented in this paper. Firstly, vehicle detection is the first step of video processing and detection methods are classified into background modeling based methods and non-background modeling based methods. In particular, nighttime detection is more challenging due to bad illumination and sensitivity to light. Then tracking techniques, including 3D model-based, region-based, active contour-based and feature-based tracking, are presented. A variety of algorithms including MeanShift algorithm, Kalman Filter and Particle Filter are applied in tracking process. In addition, shadow detection and vehicles occlusion bring much trouble into vehicle detection, tracking and so on. Based on the aforementioned video processing techniques, discussion on behavior understanding including traffic incident detection is carried out. Finally, key challenges in traffic flow monitoring are discussed.","Vehicles,
Monitoring,
Tracking,
Vehicle detection,
Image edge detection,
Trajectory,
Computational modeling"
Efficient and Explicit Coding for Interactive Communication,"We revisit the problem of reliable interactive communication over a noisy channel, and obtain the first fully explicit (randomized) efficient constant-rate emulation procedure for reliable interactive communication. Our protocol works for any discrete memory less noisy channel with constant capacity, and fails with exponentially small probability in the total length of the protocol. Following a work by Schulman [Schulman 1993] our simulation uses a tree-code, yet as opposed to the non-constructive absolute tree-code used by Schulman, we introduce a relaxation in the notion of goodness for a tree code and define a potent tree code. This relaxation allows us to construct an explicit emulation procedure for any two-party protocol. Our results also extend to the case of interactive multiparty communication. We show that a randomly generated tree code (with suitable constant alphabet size) is an efficiently decodable potent tree code with overwhelming probability. Furthermore we are able to partially derandomize this result by means of epsilon-biased distributions using only O(N) random bits, where N is the depth of the tree.",
A study on the efficiency of transparent patch antennas designed from conductive oxide films,"A study on the efficiency of transparent patch antennas designed from indium tin oxide (ITO) films is presented to provide design guidelines for patch type transparent antennas. The trade-offs between optical transparency and antenna efficiency is analyzed by considering typical material properties of ITO films. It is shown that the efficiency of a patch antenna designed from ITO films is determined by the electron mobility of ITO films, operational frequency, and the substrate material. The study shows that with today's material processing methods, it is feasible to achieve at least 30% efficiency of an ITO antenna with 90% optical transparency for operational frequency higher than 5 GHz. While progress in material science may improve the antenna performance, the highly transparent patch antenna with 30% efficiency may be employed in array design for practical implementations.","Indium tin oxide,
Patch antennas,
Substrates,
Electron mobility,
Optical films"
Analysis of facial features in identical twins,"A study of the distinctiveness of different facial features (MLBP, SIFT, and facial marks) with respect to distinguishing identical twins is presented. The accuracy of distinguishing between identical twin pairs is measured using the entire face, as well as each facial component (eyes, eye brows, nose, and mouth). The impact of discriminant learning methods on twin face recognition is investigated. Experimental results indicate that features that perform well in distinguishing identical twins are not always consistent with the features that best distinguish two non-twin faces.","Face,
Facial features,
Mouth,
Shape,
Eyebrows"
Reconstructing hand kinematics during reach to grasp movements from electroencephalographic signals,"With continued research on brain machine interfaces (BMIs), it is now possible to control prosthetic arm position in space to a high degree of accuracy. However, a reliable decoder to infer the dexterous movements of fingers from brain activity during a natural grasping motion is still to be demonstrated. Here, we present a methodology to accurately predict and reconstruct natural hand kinematics from non-invasively recorded scalp electroencephalographic (EEG) signals during object grasping movements. The high performance of our decoder is attributed to a combination of the correct input space (time-domain amplitude modulation of delta-band smoothed EEG signals) and an optimal subset of EEG electrodes selected using a genetic algorithm. Trajectories of the joint angles were reconstructed for metacarpo-phalangeal (MCP) joints of the fingers as well as the carpo-metacarpal (CMC) and MCP joints of the thumb. High decoding accuracy (Pearson's correlation coefficient, r) between the predicted and observed trajectories (r = 0.76+0.01; averaged across joints) indicate that this technique may be suitable for use with a closed-loop real-time BMI to control grasping motion in prosthetics with high degrees of freedom. This demonstrates the first successful decoding of hand pre-shaping kinematics from noninvasive neural signals.",
Optimal Subcarrier-Chunk Scheduling for Wireless OFDMA Systems,"In practical orthogonal frequency division multiple-access (OFDMA) systems, subcarriers are grouped into chunks and a chunk of subcarriers is regarded as the minimum unit for subcarrier allocation. Given that the number of chunks and the number of subcarriers in each chunk are predefined, we consider the optimal chunk allocation that maximizes a utility function of average user rates for a wireless OFDMA system under different power control policies. The relevant optimization problems are formulated as non-convex mixed-integer programs; yet it is shown that the optimal schemes can be obtained through Lagrange dual-based gradient iterations with fast convergence and low computational complexity under conditions. Furthermore, novel low-complexity algorithms are developed to approach the optimal strategies without a-priori knowledge of statistics of the intended wireless channels. Numerical results are provided to gauge the performance of the proposed schemes.","Resource management,
Wireless communication,
Power control,
Fading,
Optimization,
Convergence,
Lagrangian functions"
Crash graphs: An aggregated view of multiple crashes to improve crash triage,"Crash reporting systems play an important role in the overall reliability and dependability of the system helping in identifying and debugging crashes in software systems deployed in the field. In Microsoft for example, the Windows Error Reporting (WER) system receives crash data from users, classifies them, and presents crash information for developers to fix crashes. However, most crash reporting systems deal with crashes individually; they compare crashes individually to classify them, which may cause misclassification. Developers need to download multiple crash data files for debugging, which requires non-trivial effort. In this paper, we propose an approach based on crash graphs, which are an aggregated view of multiple crashes. Our experience with crash graphs indicates that it reduces misclassification and helps identify fixable crashes in advance.","Computer bugs,
Debugging,
Servers,
Algorithm design and analysis,
Feature extraction,
Complexity theory"
Travelling Wave Expansion: A Model Fitting Approach to the Inverse Problem of Elasticity Reconstruction,"In this paper, a novel approach to the problem of elasticity reconstruction is introduced. In this approach, the solution of the wave equation is expanded as a sum of waves travelling in different directions sharing a common wave number. In particular, the solutions for the scalar and vector potentials which are related to the dilatational and shear components of the displacement respectively are expanded as sums of travelling waves. This solution is then used as a model and fitted to the measured displacements. The value of the shear wave number which yields the best fit is then used to find the elasticity at each spatial point. The main advantage of this method over direct inversion methods is that, instead of taking the derivatives of noisy measurement data, the derivatives are taken on the analytical model. This improves the results of the inversion. The dilatational and shear components of the displacement can also be computed as a byproduct of the method, without taking any derivatives. Experimental results show the effectiveness of this technique in magnetic resonance elastography. Comparisons are made with other state-of-the-art techniques.","Mathematical model,
Elasticity,
Data models,
Propagation,
Phantoms,
Optimization,
Finite element methods"
A New Solution for Characterizing Electromagnetic Scattering by a Gyroelectric Sphere,"A new solution to electromagnetic scattering by a gyroelectric sphere is obtained. Gyroelectric characteristics are considered, where both internal transmitted fields and external scattered fields are derived theoretically. The derived solutions are capable of dealing with incident electromagnetic waves at an arbitrary incident angle and arbitrary polarization. After the theoretical formulas are obtained, numerical validations are made by comparing our present results with those obtained using the Fourier transform method. Good agreements are observed between the present results obtained in this paper and those obtained using the other method. Some new numerical results are presented to investigate effects of electric anisotropy ratio and gyroelectric ratio on the radar cross section for a gyroelectric sphere and a left-handed metamaterial gyroelectric sphere. The new formulation of the problem is expected to have wide practical applications. In addition, some critical mistakes in literature were corrected.","Manganese,
Electromagnetic scattering,
Fourier transforms,
Radar cross section,
Eigenvalues and eigenfunctions,
Metamaterials"
Adaptive-gain complementary filter of inertial and magnetic data for orientation estimation,"Accurate estimation of orientation based on data from small low-cost strapdown inertial and magnetic sensors is often inaccurate during highly dynamic motion or when trying to track movements that include two or more periods characterized by significantly different frequencies. This paper presents a complementary filtering algorithm for estimating orientation based on inertial/magnetic sensor measurements. The algorithm takes advantage of the complementary nature of the information offered by high-frequency angular rate sensor data and low frequency accelerometers and magnetometers. The filtering algorithm utilizes a single gain that can be adaptively adjusted to achieve satisfactory performance while tracking two or more different types of motion. An additional feature of our approach involves the simple estimation of the gyro bias during periods exhibiting low dynamics and its subsequent use to correct the instantaneous gyro measurements. Simulation and experimental results are presented that demonstrate the performance of the algorithm during slow or nearly static movements, as well as, those which are highly dynamic. Experimental results indicate that the algorithm is able to track pitch and roll during dynamic motion with an RMS error of less than two degrees. This is believed to be superior to current proprietary commercial algorithms.","Magnetic separation,
Quaternions,
Low pass filters,
Filtering algorithms,
Accelerometers,
Magnetometers,
Optical filters"
Anti-Forensics with Steganographic Data Embedding in Digital Images,"E-forensics investigates and extracts confidential information from electronic products; in other words, the anti-forensics indicates that evidences in those products are imperceptible and undetected. This work presents an anti-forensic steganography method that can embed and extract messages from images. Highlight of exploiting modification direction (HoEMD) and adaptive EMD (AdEMD) methods use the module operation and take into account of the sensitive nature of a human visual system. The HoEMD approach exploits the pixel directions. A pixel with a larger change implies more pixel directions and, ultimately, a larger embedding capacity. The pixel differencing in the proposed AdEMD method is used to evaluate whether the pixel located in the edge area can tolerate a larger change than that of the pixel location in a smooth area. To successfully extract a message, the differencing value is maintained on the same level before and after data is concealed; a delicate adjusting phase is used as well. In contrast with the PVD and LSB replacement method of Wu et al., LSB substitution method, and Lee and Chen's data hiding scheme based on modulus function, the proposed steganography system has a larger embedding capacity and a higher image quality. Effectiveness of the proposed steganography schemes over that of a previous blind steganalyzer is demonstrated using the statistical attack of Chi-square analysis.","Pixel,
Image quality,
Data mining,
Erbium,
Security,
Sun,
Humans"
Comparative Study of Derivative Free Optimization Algorithms,"Derivative free optimization algorithms are often used when it is difficult to find function derivatives, or if finding such derivatives are time consuming. The Nelder Mead's simplex method is one of the most popular derivative free optimization algorithms in the fields of engineering, statistics, and sciences. This algorithm is favored and widely used because of its fast convergence and simplicity. The simplex method converges really well with small scale problems of some variables. However, it does not have much success with large-scale problems of multiple variables. This factor has reduced its popularity in optimization sciences significantly. Two solutions of quasi-gradients are introduced to improve it in terms of the convergence rate and the convergence speed. The improved algorithm with higher success rate and faster convergence which still maintains the simplicity is the key feature of this paper. This algorithm will be compared on several benchmark functions with other popular optimization algorithms such as the genetic algorithm, the differential evolution algorithm, the particle swarm algorithm, and the original simplex method. Then, the comparing results will be reported and discussed.","Convergence,
Genetic algorithms,
Algorithm design and analysis,
Gradient methods,
Particle swarm optimization"
A Dictionary-Driven P300 Speller With a Modified Interface,"P300 spellers are mainly composed of an interface, by which alphanumerical characters are presented to users, and a classification system, which identifies the target character by using acquired EEG data. In this study, we proposed modifications both to the interface and to the classification system, in order to reduce the number of required stimulus repetitions and consequently boost the information transfer rate. We initially incorporated a custom-built dictionary into the classification system, and conducted a study on 14 healthy subjects who copy-spelled 15 four letter words. Incorporating the dictionary, the mean accuracy at five trials increased from 72.86% to 95.71%. To further increase the system performance, we first validated the hypothesis that for a conventional P300 system, most target-error pairs lie on the same row or column. Then based on the validated hypothesis, we adjusted letter positions on the well-known from A to Z interface. The same subjects spelled the same 15 words using the modified interface as well, and the mean information transfer rate at two trials reached 55.32 bits/min.","Electroencephalography,
Dictionaries,
Support vector machines,
Support vector machine classification,
Linear discriminant analysis,
Computational intelligence,
Materials science and technology,
Permission,
System performance,
Genetic algorithms"
Moving bits from 3G to metro-scale WiFi for vehicular network access: An integrated transport layer solution,"We investigate a transport layer protocol design that integrates 3G and WiFi networks, specifically targeting vehicular mobility. The goal is to move load from the expensive 3G network to the less expensive WiFi network without hurting the user experience. As the test platform we choose a nationwide 3G network and a commercially operated metro-scale WiFi network. We exploit the often complementary characteristics of these networks for a hybrid design at the transport layer. To this end, we modify the stock Linux SCTP implementation to support `striping' across multiple interfaces and the ability to handle frequent path failures and recovery in a seamless fashion. Instead of simply striping data over two network connections, we develop a utility and cost-based formulation that decides the right amount of load that can be put on the 3G network to maximize the user's benefit. We develop and experiment with a transport level scheduler to do this. We call the new SCTP design as oSCTP, meaning `SCTP to be used for offloading.' We demonstrate the effectiveness of oSCTP and show that it is able to deliver superior network throughput and user experience, while significantly reducing the load on the 3G network.","IEEE 802.11 Standards,
Throughput,
Delay,
Bandwidth,
Emulation,
Mobile communication,
Protocols"
Engineering Design of Strategies for Winning Iterated Prisoner's Dilemma Competitions,"In this paper, we investigate winning strategies for round-robin iterated Prisoner's Dilemma (IPD) competitions and evolutionary IPD competitions. Since the outcome of a single competition depends on the composition of the population of participants, we propose a statistical evaluation methodology that takes into account outcomes across varying compositions. We run several series of competitions in which the strategies of the participants are randomly chosen from a set of representative strategies. Statistics are gathered to evaluate the performance of each strategy. With this approach, the conditions for some well-known strategies to win a round-robin IPD competition are analyzed. We show that a strategy that uses simple rule-based identification mechanisms to explore and exploit the opponent outperforms well-known strategies such as tit-for-tat (TFT) in most round-robin competitions. Group strategies have an advantage over nongroup strategies in evolutionary IPD competitions. Group strategies adopt different strategies in interacting with kin members and nonkin members. A simple group strategy, Clique, which cooperates only with kin members, performs well in competing against well-known IPD strategies. We introduce several group strategies developed by combining Clique with winning strategies from round-robin competitions and evaluate their performance by adapting three parameters: sole survivor rate, extinction rate, and survival time. Simulation results show that these group strategies outperform well-known IPD strategies in evolutionary IPD competitions.","Thin film transistors,
Games,
Noise,
Nash equilibrium,
Statistical analysis,
System recovery"
Solid-Projectile Helical Electromagnetic Launcher With Variable Gradient Stator and Magnetically Levitated Armature,The design and operation of 40- and 70-mm-bore solid-projectile helical electromagnetic launchers is presented and discussed. The 70-mm launcher demonstrates the first reported magnetically levitated zero hoop-stress armature and is tested in both constant- and variable-gradient stators. The theory of variable-gradient launcher operation is presented and shows that a properly designed variable-gradient launcher has efficiency independent of velocity but dependent on a new parameter called the launcher impedance constant. The variable-gradient launcher can also behave as an ideal launcher operating at 100% of its maximum theoretical efficiency independent of velocity if the ratio of the system resistance and impedance constant meets other conditions. This investigation also introduces the concept of launcher impedance and shows that variable-gradient launchers with high impedance are desirable in terms of efficiency.,"Coilguns,
Electromagnetic launching,
Railguns,
Armature"
LLS: Cooperative integration of wear-leveling and salvaging for PCM main memory,"Phase change memory (PCM) has emerged as a promising technology for main memory due to many advantages, such as better scalability, non-volatility and fast read access. However, PCM's limited write endurance restricts its immediate use as a replacement for DRAM. Recent studies have revealed that a PCM chip which integrates millions to billions of bit cells has non-negligible variations in write endurance. Wear leveling techniques have been proposed to balance write operations to different PCM regions. To further prolong the lifetime of a PCM device after the failure of weak cell, techniques have been proposed to remap failed lines to spares and to salvage a PCM device that has a large number of failed lines or pages with graceful degradation. However, current wear-leveling and salvaging schemes have not been designed and integrated to work cooperatively to achieve the best PCM device lifetime. In particular, a non-contiguous PCM space generated from salvaging complicates wear leveling and incurs large overhead. In this paper, we propose LLS, a Line-Level mapping and Salvaging design. By allocating a dynamic portion of total space in a PCM device as backup space, and mapping failed lines to backup PCM, LLS constructs a contiguous PCM space and masks lower-level failures from the OS and applications. LLS seamlessly integrates wear leveling and salvaging and copes well with modern OSs, including ones that support multiple page sizes. Our experimental results show that LLS achieves 24% longer lifetime than a state-of-the-art technique. It has negligible hardware cost and performance overhead.","Phase change materials,
Performance evaluation"
Segmentation fusion for connectomics,"We address the problem of automatic 3D segmentation of a stack of electron microscopy sections of brain tissue. Unlike previous efforts, where the reconstruction is usually done on a section-to-section basis, or by the agglomerative clustering of 2D segments, we leverage information from the entire volume to obtain a globally optimal 3D segmentation. To do this, we formulate the segmentation as the solution to a fusion problem. We first enumerate multiple possible 2D segmentations for each section in the stack, and a set of 3D links that may connect segments across consecutive sections. We then identify the fusion of segments and links that provide the most globally consistent segmentation of the stack. We show that this two-step approach of pre-enumeration and posterior fusion yields significant advantages and provides state-of-the-art reconstruction results. Finally, as part of this method, we also introduce a robust rotationally-invariant set of features that we use to learn and enumerate the above 2D segmentations. Our features outperform previous connectomic-specific descriptors without relying on a large set of heuristics or manually designed filter banks.","Three dimensional displays,
Neurons,
Image segmentation,
Brain,
Labeling,
Joining processes,
Educational institutions"
Location-based image retrieval for urban environments,"Image based localization is an important problem with many applications. The basic idea is to match a user generated query image against a database of geo-tagged images with known 6 degrees of freedom poses. Once this retrieval problem is solved, it is possible to recover the pose of the query image. A challenging problem in image retrieval is performance degradation as the size of the image database grows. In this paper we describe an approach to large scale image retrieval for user localization in urban environment by taking advantage of coarse position estimates available, e.g. via cell tower triangulation, on many mobile devices today. The basic idea is to partition the large image database for a large region into a number of overlapping cells each with its own prebuilt search and retrieval structure. We demonstrate retrieval results over a ~12,000 image database covering a 1 km2 area of downtown Berkeley.","Image retrieval,
Global Positioning System,
FCC,
Urban areas,
Mobile handsets"
Peripheral Neural Activity Recording and Stimulation System,"This paper presents a portable, embedded, microcontroller-based system for bidirectional communication (recording and stimulation) between an electrode, implanted in the peripheral nervous system, and a host computer. The device is able to record and digitize spontaneous and/or evoked neural activities and store them in data files on a PC. In addition, the system has the capability of providing electrical stimulation of peripheral nerves, injecting biphasic current pulses with programmable duration, intensity, and frequency. The recording system provides a highly selective band-pass filter from 800 Hz to 3 kHz, with a gain of 56 dB. The amplification range can be further extended to 96 dB with a variable gain amplifier. The proposed acquisition/stimulation circuitry has been successfully tested through in vivo measurements, implanting a tf-LIFE electrode in the sciatic nerve of a rat. Once implanted, the device showed an input referred noise of 0.83 μVrms, was capable of recording signals below 10 μ V, and generated muscle responses to injected stimuli. The results demonstrate the capability of processing and transmitting neural signals with very low distortion and with a power consumption lower than 1 W. A graphic, user-friendly interface has been developed to facilitate the configuration of the entire system, providing the possibility to activate stimulation and monitor recordings in real time.","Electrodes,
Gain,
In vivo,
Animals,
Bandwidth,
Switches"
Energy-Adaptive Dual-Field Processor for High-Performance Elliptic Curve Cryptographic Applications,"We present an elliptic curve cryptographic (ECC) processor, capable of parallel and serial operation modes, with the unified architecture for both prime field and binary field cryptosystems, featuring comprehensive cryptographic functions to fulfill realistic security applications. An advanced field inversion method and the scheduler-controlled datapath are integrated into the processor to provide high-throughput and energy-adaptive security computing with power-performance trade off. Using 130-nm CMOS technology, the fabricated chip measures 4.97 mm2 with the core area of 1.35 mm2. A 160-bit point scalar multiplication with coordinate conversion can be done in 385 μ s at 141 MHz with core power of 80.4 mW over GF(p) and in 272 μs at 158 MHz with 79.6 mW over GF(2m). The comparison of throughput, area, power, and energy consumption among different ECC designs justifies that our high-throughput processor chip provides power- and energy-efficient implementation with the flexibility of dual-field ECC.","Elliptic curve cryptography,
Data security,
CMOS technology,
Computer architecture,
Processor scheduling,
Area measurement,
Semiconductor device measurement,
Throughput,
Energy consumption,
Energy efficiency"
Blind grasping: Stable robotic grasping using tactile feedback and hand kinematics,"We propose a machine learning approach to the perception of a stable robotic grasp based on tactile feedback and hand kinematic data, which we call blind grasping. We first discuss a method for simulating tactile feedback using a soft finger contact model in Grasplt!, which is a robotic grasping simulator [10]. Using this simulation technique, we compute tactile contacts of thousands of grasps with a robotic hand using the Columbia Grasp Database [6]. The tactile contacts along with the hand kinematic data are then input to a Support Vector Machine (SVM) which is trained to estimate the stability of a given grasp based on this tactile feedback and also the robotic hand kinematics. Experimental results indicate that the tactile feedback along with the hand kinematic data carry meaningful information for the prediction of the stability of a blind robotic grasp.","Tactile sensors,
Grasping,
Kinematics,
Computational modeling,
Planning"
A FACS valid 3D dynamic action unit database with applications to 3D dynamic morphable facial modeling,"This paper presents the first dynamic 3D FACS data set for facial expression research, containing 10 subjects performing between 19 and 97 different AUs both individually and in combination. In total the corpus contains 519 AU sequences. The peak expression frame of each sequence has been manually FACS coded by certified FACS experts. This provides a ground truth for 3D FACS based AU recognition systems. In order to use this data, we describe the first framework for building dynamic 3D morphable models. This includes a novel Active Appearance Model (AAM) based 3D facial registration and mesh correspondence scheme. The approach overcomes limitations in existing methods that require facial markers or are prone to optical flow drift. We provide the first quantitative assessment of such 3D facial mesh registration techniques and show how our proposed method provides more reliable correspondence.","Three dimensional displays,
Solid modeling,
Gold,
Optical imaging,
Data models,
Adaptive optics,
Cameras"
"On adaptive-width channel allocation in non-cooperative, multi-radio wireless networks","Due to the limitation of radio spectrum resource and fast growing of wireless applications, careful channel allocation is highly needed to mitigate the performance degradation of wireless networks because of interference among different users. While most of the existing works consider allocating fixed-width channels, combining contiguous channels may provide an alternative way to better utilize the available channels. In this paper, we study the problem of adaptive-width channel allocation from a game-theoretic point of view, in which the nodes are rational and always pursue their own objectives. We first model the problem as a strategic game, and show the existence of Nash equilibrium (NE), when there is no exogenous factor to influence players' behavior. We further propose a charging scheme to influence the players' behavior, by which the system is guaranteed to converge to a Dominant Strategy Equilibrium (DSE), a solution concept that gives participants much stronger incentives. We show that, when the system converges to a DSE, it also achieves global optimality, in terms of system-wide throughput without starvation. Numerical results verify that with our charging scheme, the system-wide throughput obtained is higher as compared to the throughput obtained when system is in NE.",Throughput
Lightweight Detection of Additive Watermarking in the DWT-Domain,"This article aims at lightweight, blind detection of additive spread-spectrum watermarks in the DWT domain. We focus on two host signal noise models and two types of hypothesis tests for watermark detection. As a crucial point of our work we take a closer look at the computational requirements of watermark detectors. This involves the computation of the detection response, parameter estimation and threshold selection. We show that by switching to approximate host signal parameter estimates or even fixed parameter settings we achieve a remarkable improvement in runtime performance without sacrificing detection performance. Our experimental results on a large number of images confirm the assumption that there is not necessarily a tradeoff between computation time and detection performance.","Watermarking,
Discrete wavelet transforms,
Detectors,
Discrete cosine transforms,
Parameter estimation,
Runtime,
Testing,
Signal detection,
Additives,
Gaussian noise"
Combining search-based and constraint-based testing,"Many modern automated test generators are based on either meta-heuristic search techniques or use constraint solvers. Both approaches have their advantages, but they also have specific drawbacks: Search-based methods get stuck in local optima and degrade when the search landscape offers no guidance; constraint-based approaches, on the other hand, can only handle certain domains efficiently. In this paper we describe a method that integrates both techniques and delivers the best of both worlds. On a high-level view, our method uses a genetic algorithm to generate tests, but the twist is that during evolution a constraint solver is used to ensure that mutated offspring efficiently explores different control flow. Experiments on 20 case study examples show that on average the combination improves branch coverage by 28% over search-based techniques and by 13% over constraint-based techniques.","Search problems,
Genetic algorithms,
USA Councils,
IEEE Computer Society,
Software testing,
Java"
Convex Optimization of Coincidence Time Resolution for a High-Resolution PET System,"We are developing a dual panel breast-dedicated positron emission tomography (PET) system using LSO scintillators coupled to position sensitive avalanche photodiodes (PSAPD). The charge output is amplified and read using NOVA RENA-3 ASICs. This paper shows that the coincidence timing resolution of the RENA-3 ASIC can be improved using certain list-mode calibrations. We treat the calibration problem as a convex optimization problem and use the RENA-3's analog-based timing system to correct the measured data for time dispersion effects from correlated noise, PSAPD signal delays and varying signal amplitudes. The direct solution to the optimization problem involves a matrix inversion that grows order (n3) with the number of parameters. An iterative method using single-coordinate descent to approximate the inversion grows order (n). The inversion does not need to run to convergence, since any gains at high iteration number will be low compared to noise amplification. The system calibration method is demonstrated with measured pulser data as well as with two LSO-PSAPD detectors in electronic coincidence. After applying the algorithm, the 511 keV photopeak paired coincidence time resolution from the LSO-PSAPD detectors under study improved by 57%, from the raw value of 16.3 ± 0.07 ns full-width at half-maximum (FWHM) to 6.92 ±0.02 ns FWHM (11.52 ±0.05 ns to 4.89 ± 0.02 ns for unpaired photons).","Calibration,
Crystals,
Delay,
Photonics,
Noise,
Shape"
Network Intrusion Detection System Embedded on a Smart Sensor,"This paper proposes a Network Intrusion Detection System (NIDS) embedded in a smart-sensor-inspired device under a service-oriented architecture (SOA) approach which is able to operate independently as an anomaly-based NIDS, or integrated transparently in a Distributed Intrusion Detection System (DIDS). The proposal is innovative because it combines the advantages of the smart sensor approach and the subsequent offering of the NIDS functionality as a service with the SOA use to achieve their integration with other DIDS components. The main goal of this paper is to reduce the huge volume of management tasks inherent to this type of network services, as well as facilitating the design of DIDS whose managing complexity could be restricted within well-defined margins. This paper also addresses the construction of a physical sensor prototype. This prototype was used to carry out the tests that has demonstrated the proposal's validity, providing detection and performance ratios similar to those of existing intrusion detection systems (IDS), but with the advantage of a zero-maintenance approach.",
Detecting social network profile cloning,"Social networking is one of the most popular Internet activities, with millions of users from around the world. The time spent on sites like Facebook or LinkedIn is constantly increasing at an impressive rate. At the same time, users populate their online profile with a plethora of information that aims at providing a complete and accurate representation of themselves. Attackers may duplicate a user's online presence in the same or across different social networks and, therefore, fool other users into forming trusting social relations with the fake profile. By abusing that implicit trust transferred from the concept of relations in the physical world, they can launch phishing attacks, harvest sensitive user information, or cause unfavorable repercussions to the legitimate profile's owner. In this paper we propose a methodology for detecting social network profile cloning. We present the architectural design and implementation details of a prototype system that can be employed by users to investigate whether they have fallen victims to such an attack. Our experimental results from the use of this prototype system prove its efficiency and also demonstrate its simplicity in terms of deployment by everyday users. Finally, we present the findings from a short study in terms of profile information exposed by social network users.","LinkedIn,
Cloning,
Companies,
Educational institutions,
Prototypes"
Efficient Decentralized Approximation via Selective Gossip,"Recently, gossip algorithms have received much attention from the wireless sensor network community due to their simplicity, scalability and robustness. Motivated by applications such as compression and distributed transform coding, we propose a new gossip algorithm called Selective Gossip. Unlike traditional randomized gossip which computes the average of scalar values, we run gossip algorithms in parallel on the elements of a vector. The goal is to compute only the entries which are above a defined threshold in magnitude, i.e., significant entries. Nodes adaptively approximate the significant entries while abstaining from calculating the insignificant ones. Consequently, network lifetime and bandwidth are preserved. We show that with the proposed algorithm nodes reach consensus on the values of the significant entries and on the indices of insignificant ones. We illustrate the performance of our algorithm with a field estimation application. For regular topologies, selective gossip computes an approximation of the field using the wavelet transform. For irregular network topologies, we construct an orthonormal transform basis using eigenvectors of the graph Laplacian. Using two real sensor network datasets we show substantial communication savings over randomized gossip. We also propose a decentralized adaptive threshold mechanism such that nodes estimate the threshold while approximating the entries of the vector for computing the best m -term approximation of the data.","Approximation methods,
Transforms,
Approximation algorithms,
Signal processing algorithms,
Convergence,
Topology,
Estimation"
Simulating and optimising design decisions in quantitative goal models,Making decisions among a set of alternative system designs is an essential activity of requirements engineering. It involves evaluating how well each alternative satisfies the stakeholders' goals and selecting one alternative that achieves some optimal tradeoffs between possibly conflicting goals. Quantitative goal models support such activities by describing how alternative system designs - expressed as alternative goal refinements and responsibility assignments - impact on the levels of goal satisfaction specified in terms of measurable objective functions. Analyzing large numbers of alternative designs in such models is an expensive activity for which no dedicated tool support is currently available. This paper takes a first step towards providing such support by presenting automated techniques for (i) simulating quantitative goal models so as to estimate the levels of goal satisfaction contributed by alternative system designs and (ii) optimising the system design by applying a multi-objective optimisation algorithm to search through the design space. These techniques are presented and validated using a quantitative goal model for a well-known ambulance service system.,"Mathematical model,
Computational modeling,
Equations,
System analysis and design,
Probability distribution,
Numerical models,
Optimization"
Efficient grasping from RGBD images: Learning using a new rectangle representation,"Given an image and an aligned depth map of an object, our goal is to estimate the full 7-dimensional gripper configuration-its 3D location, 3D orientation and the gripper opening width. Recently, learning algorithms have been successfully applied to grasp novel objects-ones not seen by the robot before. While these approaches use low-dimensional representations such as a `grasping point' or a `pair of points' that are perhaps easier to learn, they only partly represent the gripper configuration and hence are sub-optimal. We propose to learn a new `grasping rectangle' representation: an oriented rectangle in the image plane. It takes into account the location, the orientation as well as the gripper opening width. However, inference with such a representation is computationally expensive. In this work, we present a two step process in which the first step prunes the search space efficiently using certain features that are fast to compute. For the remaining few cases, the second step uses advanced features to accurately select a good grasp. In our extensive experiments, we show that our robot successfully uses our algorithm to pick up a variety of novel objects.","Grasping,
Grippers,
Histograms,
Three dimensional displays,
Robots,
Complexity theory,
Image edge detection"
A Variational Stereo Method for the Three-Dimensional Reconstruction of Ocean Waves,"We develop a novel remote sensing technique for the observation of waves on the ocean surface. Our method infers the 3-D waveform and radiance of oceanic sea states via a variational stereo imagery formulation. In this setting, the shape and radiance of the wave surface are given by minimizers of a composite energy functional that combines a photometric matching term along with regularization terms involving the smoothness of the unknowns. The desired ocean surface shape and radiance are the solution of a system of coupled partial differential equations derived from the optimality conditions of the energy functional. The proposed method is naturally extended to study the spatiotemporal dynamics of ocean waves and applied to three sets of stereo video data. Statistical and spectral analysis are carried out. Our results provide evidence that the observed omnidirectional wavenumber spectrum S(k) decays as k-2.5 is in agreement with Zakharov's theory (1999). Furthermore, the 3-D spectrum of the reconstructed wave surface is exploited to estimate wave dispersion and currents.","Sea surface,
Surface reconstruction,
Image reconstruction,
Cameras,
Surface waves,
Mathematical model,
Surface treatment"
Textureless Macula Swelling Detection With Multiple Retinal Fundus Images,"Retinal fundus images acquired with nonmydriatic digital fundus cameras are versatile tools for the diagnosis of various retinal diseases. Because of the ease of use of newer camera models and their relatively low cost, these cameras can be employed by operators with limited training for telemedicine or point-of-care (PoC) applications. We propose a novel technique that uses uncalibrated multiple-view fundus images to analyze the swelling of the macula. This innovation enables the detection and quantitative measurement of swollen areas by remote ophthalmologists. This capability is not available with a single image and prone to error with stereo fundus cameras. We also present automatic algorithms to measure features from the reconstructed image, which are useful in PoC automated diagnosis of early macular edema, e.g., before the appearance of exudation. The technique presented is divided into three parts: first, a preprocessing technique simultaneously enhances the dark microstructures of the macula and equalizes the image; second, all available views are registered using nonmorphological sparse features; finally, a dense pyramidal optical flow is calculated for all the images and statistically combined to build a naive height map of the macula. Results are presented on three sets of synthetic images and two sets of real-world images. These preliminary tests show the ability to infer a minimum swelling of 300 and to correlate the reconstruction with the swollen location.","Cameras,
Retina,
Image reconstruction,
Three dimensional displays,
Optical imaging,
Algorithm design and analysis,
Diabetes"
"Object mapping, recognition, and localization from tactile geometry","We present a method for performing object recognition using multiple images acquired from a tactile sensor. The method relies on using the tactile sensor as an imaging device, and builds an object representation based on mosaics of tactile measurements. We then describe an algorithm that is able to recognize an object using a small number of tactile sensor readings. Our approach makes extensive use of sequential state estimation techniques from the mobile robotics literature, whereby we view the object recognition problem as one of estimating a consistent location within a set of object maps. We examine and test approaches based on both traditional particle filtering and histogram filtering. We demonstrate both the mapping and recognition / localization techniques on a set of raised letter shapes using real tactile sensor data.","Histograms,
Robot sensing systems,
Atmospheric measurements,
Particle measurements,
Robot kinematics"
Full polarimetric beam-forming algorithm for through-the-wall radar imaging,"Development of an imaging algorithm that accurately models the wave propagation physical process has become an important topic in through-the-wall radar imaging (TWRI). In this paper, a full polarimetric beam-forming algorithm for through-the-wall radar imaging for a general multilayer wall case is presented and applied to various 2D and 3D simulated and measured scenarios. Polarimetric TWRI not only enhances the target characterization but also mitigates the wall ringing effect in cross polarizations. The far field layered medium Green's function is incorporated in the proposed TWRI algorithm for the quad-polarization of the target returns, namely, VV, HV, VH and HH. Due to the incorporation of the layered medium Green's function, the imaging algorithm not only takes into account the wall reflection, bending, and delay effects but also accounts for the complex scattering mechanism due to the presence of the wall. Numerical and experimental results show that the proposed full polarimetric beam former can provide high quality focused images in various wall-target scenarios, in particular, when the technique is combined with a wall parameter estimation technique.","Imaging,
Radar imaging,
Green's function methods,
Receivers,
Reflection,
Scattering"
Wind energy aggregation: A coalitional game approach,"In this paper we explore the extent to which a group of N wind power producers can exploit the statistical benefits of aggregation and quantity risk sharing by forming a willing coalition to pool their variable power to jointly offer their aggregate power output as single entity into a forward energy market. We prove that wind power generators will always improve their expected profit when they aggregate their generated power and use tools from coalitional game theory to design fair sharing mechanisms to allocate the payoff among the coalition participants. We show that the corresponding coalitional game is super-additive and has a nonempty core. Hence, there always exists a mechanism for profit-sharing that makes the coalition stable. However, the game is not convex and the celebrated Shapley value may not belong to the core of the game. An allocation mechanism that minimizes the worst-case dissatisfaction is proposed.","Games,
Wind power generation,
Resource management,
Contracts,
Aggregates,
Game theory,
Wind"
A systematic review of goal-oriented requirements management frameworks for business process compliance,"Legal compliance has been an active topic in Software Engineering and Information Systems for many years. However, business analysts and others recently started exploiting Requirements Engineering techniques, and in particular goal-oriented approaches, to model and reason about legal documents in system design and business process management. Many contributions involve extracting legal requirements, providing law-compliant business processes, as well as managing and maintaining compliance. In this paper, we report on a systematic literature review focusing on goal-oriented legal compliance of business processes. 88 papers were selected out of nearly 800 unique papers extracted from five search engines, with manual additions from the Requirements Engineering Journal and four relevant conferences. We grouped these papers in eight categories based on a set of criteria and then highlight their main contributions. We found that the main areas for contributions have been in extracting legal requirements, modeling them with goal modeling languages, and integrating them with business processes. We identify gaps and opportunities for future work in areas related to prioritization to improve compliance, templates for generating law-compliant processes, general links between legal requirements, goal models, and business processes, and semi-automation of legal compliance and analysis.","Law,
Unified modeling language,
Organizations,
Analytical models,
Databases"
REDMAPS: Reduced-Dimensionality Matching for Prostate Brachytherapy Seed Reconstruction,"The success of prostate brachytherapy critically depends on delivering adequate dose to the prostate gland. Intraoperative localization of the implanted seeds provides potential for dose evaluation and optimization during therapy. A reduced-dimensionality matching algorithm for prostate brachytherapy seed reconstruction (REDMAPS) that uses multiple X-ray fluoroscopy images obtained from different poses is proposed. The seed reconstruction problem is formulated as a combinatorial optimization problem, and REDMAPS finds a solution in a clinically acceptable amount of time using dimensionality reduction to create a smaller space of possible solutions. Dimensionality reduction is possible since the optimal solution has approximately zero cost when the poses of the acquired images are known to be within a small error. REDMAPS is also formulated to address the “hidden seed problem” in which seeds overlap on one or more observed images. REDMAPS uses a pruning algorithm to avoid unnecessary computation of cost metrics and the reduced problem is solved using linear programming. REDMAPS was first evaluated and its parameters tuned using simulations. It was then validated using five phantom and 21 patient datasets. REDMAPS was successful in reconstructing the seeds with an overall seed matching rate above 99% and a reconstruction error below 1 mm in less than 5 s.","Brachytherapy,
Image reconstruction,
Glands,
Medical treatment,
X-ray imaging,
Cost function,
Computational efficiency,
Linear programming,
Computational modeling,
Imaging phantoms"
Fast-join: An efficient method for fuzzy token matching based string similarity join,"String similarity join that finds similar string pairs between two string sets is an essential operation in many applications, and has attracted significant attention recently in the database community. A significant challenge in similarity join is to implement an effective fuzzy match operation to find all similar string pairs which may not match exactly. In this paper, we propose a new similarity metrics, called “fuzzy token matching based similarity”, which extends token-based similarity functions (e.g., Jaccard similarity and Cosine similarity) by allowing fuzzy match between two tokens. We study the problem of similarity join using this new similarity metrics and present a signature-based method to address this problem. We propose new signature schemes and develop effective pruning techniques to improve the performance. Experimental results show that our approach achieves high efficiency and result quality, and significantly outperforms state-of-the-art methods.",
A new approach for LSB based image steganography using secret key,"This paper introduces a best approach for Least Significant Bit (LSB) based on image steganography that enhances the existing LSB substitution techniques to improve the security level of hidden information. It is a new approach to substitute LSB of RGB true color image. The new security conception hides secret information within the LSB of image where a secret key encrypts the hidden information to protect it from unauthorized users. In general, in LSB methods, hidden information is stored into a specific position of LSB of image. For this reason, knowing the retrieval methods, anyone can extract the hidden information. In our paper, hidden information is stored into different position of LSB of image depending on the secret key. As a result, it is difficult to extract the hidden information knowing the retrieval methods. We have used the Peak Signal-to-Noise Ratio (PSNR) to measure the quality of the stego images. The value of PSNR gives better result because our proposed method changes very small number of bits of the image. The obtained results show that the proposed method results in LSB based image steganography using secret key which provides good security issue and PSNR value than general LSB based image steganography methods.","steganography,
cryptography,
image colour analysis"
"Closed-loop belief space planning for linear, Gaussian systems","This paper considers the problem of motion planning for linear, Gaussian systems, and extends existing chance constrained optimal control solutions [1], [2] by incorporating the closed-loop uncertainty of the system and by reducing the conservativeness in the constraints. Due to the imperfect knowledge of the system state caused by motion uncertainty and sensor noise, the constraints cannot be guaranteed to be satisfied and consequently must be considered probabilistically. In this work, they are formulated as convex constraints on a univariate Gaussian random variable, with the violation probability of all the constraints guaranteed to be below a threshold. This threshold is a tuning parameter which trades off the performance of the system and the conservativeness of the solution. In contrast to similar methods, the proposed work considers the specific estimator and controller used in the closed-loop system in order to directly characterize the a priori distribution of the closed-loop system state. Using this distribution, a convex optimization program is formulated to solve for the optimal solution for the closed-loop system. The performance of the algorithm is demonstrated through several examples.","Uncertainty,
Noise,
Trajectory,
Planning,
Optimization,
Resource management,
Kalman filters"
Dual-Polarized Coupled Sectorial Loop Antennas for UWB Applications,"In this letter, we present two compact dual-polarized UWB antennas based on the coupled sectorial loops antenna (CSLA) concept. The first antenna is a directional dual-polarized cavity-backed asymmetric CSLA for radar and communications applications. The antenna has the added ad vantage of easily controllable gain compared to conventional dual-polarized antennas. The second antenna design is a planar CSLA in a crossed dipole configuration that offers both polarization and pattern diversities. Its dimensions are 0.44λm × 0.44λm, where λm is the wavelength at the lowest operating frequency. These dimensions are about 20% higher than those of the original CSLA, but with the advantage of providing an extra polarization. This antenna is fabricated with an integrated balun feed and measured. The measurements and the simulations agree well and show good matching over more than two octaves of bandwidth and isolation better than 25 dB between the two polarization ports.","Antenna measurements,
Cavity resonators,
Ultra wideband antennas,
Impedance matching,
Directive antennas,
Feeds"
Manipulating the electricity power market via jamming the price signaling in smart grid,"While enhancing the efficiency and agility to the power system, the communication infrastructure in smart grid also incurs vulnerabilities to the reliability of the power market and power grid. A novel attacking scheme is proposed, in which an attacker jams the signaling of power price and then ceases jamming when the power price has been significantly changed. The power users jammed by the attacker will make a rapid response to the changed power price, whose change direction can be predicted by the attacker. Then, the attacker can manipulate the price in the power market and thus makes profit. The abrupt change of power consumption will also cause a significant impact on the power grid stability. The effect of such an attack will be discussed both analytically and numerically. A countermeasure for this attack is also proposed.","Jamming,
Power demand,
Power markets,
Smart grids,
Power generation,
Power system stability"
Multiple task scheduling for low-duty-cycled wireless sensor networks,"For energy conservation, a wireless sensor network is usually designed to work in a low-duty-cycle mode, in which a sensor node keeps active for a small percentage of time during its working period. In applications where there are multiple data delivery tasks with high data rates and time constraints, low-duty-cycle working mode may cause severe transmission congestion and data loss. In order to alleviate congestion and reduce data loss, the tasks need to be carefully scheduled to balance the workloads among the sensor nodes in both spatial and temporal dimensions. This paper studies the load balancing problem, and proves it is NP-Complete in general network graphs. Two efficient scheduling algorithms to achieve load balance are proposed and analyzed. Furthermore, a task scheduling protocol is designed relying on the proposed algorithms. To the best of our knowledge, this paper is the first one to tackle multiple task scheduling for low-duty-cycled sensor networks. The simulation results show that the proposed algorithms greatly improve the network performance in most scenarios.",
A Tutorial for Emerging Wireless Medical Video Transmission Systems [Wireless Corner],"The wireless transmission of medical video is expected to see significant growth in the coming years. This is primarily due to the expected availability of significant bandwidth in the next-generation of wireless communications networks, and the emergence of effective wireless video-compression standards. The design of wireless medical video transmission systems presents unique requirements for error-resilience and clinical validation. We present a tutorial introduction to the most important components of a wireless medical video transmission system. We focus on video-encoding requirements for error resilience, quality-of-service transmission, and diagnostic validation. Whenever possible, we give references to open-source software and provide references to the literature. We demonstrate the basic principles through the use of simple examples of stroke ultrasound videos.","Tutorials,
Wireless communication,
Medical services,
Medical information processing,
Distance learning"
Key Predistribution Schemes for Establishing Pairwise Keys with a Mobile Sink in Sensor Networks,"Security services such as authentication and pairwise key establishment are critical to sensor networks. They enable sensor nodes to communicate securely with each other using cryptographic techniques. In this paper, we propose two key predistribution schemes that enable a mobile sink to establish a secure data-communication link, on the fly, with any sensor nodes. The proposed schemes are based on the polynomial pool-based key predistribution scheme, the probabilistic generation key predistribution scheme, and the Q-composite scheme. The security analysis in this paper indicates that these two proposed predistribution schemes assure, with high probability and low communication overhead, that any sensor node can establish a pairwise key with the mobile sink. Comparing the two proposed key predistribution schemes with the Q-composite scheme, the probabilistic key predistribution scheme, and the polynomial pool-based scheme, our analytical results clearly show that our schemes perform better in terms of network resilience to node capture than existing schemes if used in wireless sensor networks with mobile sinks.","Wireless sensor networks,
Data security,
Cryptography,
Polynomials,
Mobile communication,
Communication system control,
Sensor systems,
Monitoring,
Computer networks,
Computer science"
Optimal Pilot Sequence Design for Multi-Cell MIMO-OFDM Systems,"In this paper, optimal pilot sequence designs for MIMO-OFDM systems in multi-cell environments are provided. The proposed multi-cell optimality criterion is to minimize the worst-case MSE of an LS-based channel estimator. To satisfy the multi-cell optimality, it is found that the pilot sequence set, having the perfect auto-correlation property, should meet the Welch bound and the maximum magnitude of the cross-correlation function should be further minimized. Multi-cell optimal pilot sequence designs for various pilot types and their DFT representations are proposed by adopting Chu sequences and a tight upper-bound on the maximum size of the pilot sequence set is derived for a given pilot sequence length and the maximum allowed cross-correlation value. Simulation results show that the proposed pilot sequences can improve both the MSE performance and the system performance in multi-cell environments.","Partial transmit sequences,
Channel estimation,
Correlation,
Frequency division multiplexing"
Exploitation of OpenFlow in wireless sensor networks,"A novel idea presented in this paper is to exploit the OpenFlow technology to address reliability, which is one of the most important factors in sensor networks. The proposed approach unified with flow-sensor and communication with controller. Hardware to programmable hardware, operating system to network operating system, vendor to owner specific, previous hardware defined networking (device monitoring, traffic controlling, and topology definition) turns to be software defined and where everything leads to a programmable and customized networking system. OpenFlow bears the characteristics to control the flow-sensor and monitor sensor traffic flow that also addresses another two important problems robust routing and load balancing. Flow-sensor displayed much better performances in comparison to typical sensors through generating less number of packets with lower simulation time in ideal scenario and even better results are possible for larger networks.","Buffer storage,
IP networks,
Switches,
Reliability"
A semi-preemptive garbage collector for solid state drives,"NAND flash memory is a preferred storage media for various platforms ranging from embedded systems to enterprise-scale systems. Flash devices do not have any mechanical moving parts and provide low-latency access. They also require less power compared to rotating media. Unlike hard disks, flash devices use out-of-update operations and they require a garbage collection (GC) process to reclaim invalid pages to create free blocks. This GC process is a major cause of performance degradation when running concurrently with other I/O operations as internal bandwidth is consumed to reclaim these invalid pages. The invocation of the GC process is generally governed by a low watermark on free blocks and other internal device metrics that different workloads meet at different intervals. This results in I/O performance that is highly dependent on workload characteristics. In this paper, we examine the GC process and propose a semi-preemptive GC scheme that can preempt on-going GC processing and service pending I/O requests in the queue. Moreover, we further enhance flash performance by pipelining internal GC operations and merge them with pending I/O requests whenever possible. Our experimental evaluation of this semi-preemptive GC sheme with realistic workloads demonstrate both improved performance and reduced performance variability. Write-dominant workloads show up to a 66.56% improvement in average response time with a 83.30% reduced variance in response time compared to the non-preemptive GC scheme.",
Contourlet appearance model for facial age estimation,"In this paper we propose a novel Contourlet Appearance Model (CAM) that is more accurate and faster at localizing facial landmarks than Active Appearance Models (AAMs). Our CAM also has the ability to not only extract holistic texture information, as AAMs do, but can also extract local texture information using the Nonsubsampled Contourlet Transform (NSCT). We demonstrate the efficiency of our method by applying it to the problem of facial age estimation. Compared to previously published age estimation techniques, our approach yields more accurate results when tested on various face aging databases.",
Local Interference Can Accelerate Gossip Algorithms,"In this paper, we show how interference can be exploited to perform gossip computations for average-based consensus over a larger local neighborhood, rather than only pairs of nodes. We use a new channel coding technique called computation coding to compute sums reliably over the wireless medium. Since many nodes can simultaneously average in a single round, our neighborhood gossip algorithm converges faster than the standard nearest neighbor gossip algorithm. For a network with n nodes and size m neighborhoods, neighborhood gossip requires O(n2/m2) rounds while standard gossip requires Θ(n2) rounds. Furthermore, we show that if the power path loss coefficient is less than 4, the total transmit energy employed by neighborhood gossip is polynomially smaller than that employed by standard gossip.","Signal processing algorithms,
Convergence,
Sensors,
Markov processes,
Wireless sensor networks,
Signal processing,
Algorithm design and analysis"
High-Performance Scalable Flash File System Using Virtual Metadata Storage with Phase-Change RAM,"Several flash file systems have been developed based on the physical characteristics of NAND flash memory. However, previous flash file systems have performance overhead and scalability problems caused by metadata management in NAND flash memory. In this paper, we present a flash file system called PFFS2. PFFS2 stores all metadata into virtual metadata storage, which employs Phase-change RAM (PRAM). PRAM is a next-generation nonvolatile memory and will be good for dealing with word-level read/write of small-size data. Based on the virtual metadata storage, PFFS2 can manage metadata in a virtually fixed location and through byte-level in-place updates. Therefore, the performance of PFFS2 is 38 percent better than YAFFS2 for small file read/write while matching YAFFS2 performance for large file. Virtual metadata storage is particularly effective in decreasing the burden of computational and I/O overhead of garbage collection. In addition, PFFS2 maintains a 0.18 second mounting time and 284 KB memory usage in spite of increases in NAND flash memory size. We also propose a wear-leveling solution for PRAM in virtual metadata storage and greatly reduce the total write count of NAND flash memory. In addition, the life span of PFFS2 is longer than other flash file systems.","Ash,
Phase change random access memory,
Nonvolatile memory,
Memory management,
Flash memory,
Ferroelectric films"
Year,,
Cognitive Radio Through Primary Control Feedback,"A fundamental problem in dynamic frequency reuse is that the cognitive radio is ignorant of the amount of interference it inflicts on the primary license holder. Policies that attempt to limit interference without the active participation of the primary are thus difficult to implement. However, many wireless systems use flow control feedback such as ARQs. By listening to these control signals, a cognitive radio can obtain indirect information about the interference it generates and thus behave in an acceptable manner. This paper introduces an information-theoretic model of this basic observation and develops and analyzes algorithms that can exploit it. In particular, a simple generic strategy is proposed where the cognitive radio monitors the primary's effective packet rate and only transmits when that rate is above a threshold. The strategy is shown to have important universality properties with respect to unknown time-varying interference characteristics as well as favorable delay properties.",
Implementation and Evaluation of Raptor Codes on Embedded Systems,"Raptor codes have been proven very suitable for mobile broadcast and multicast multimedia content delivery, and yet their computational complexity has not been investigated in the context of embedded systems. At the heart of Raptor codes are the matrix inversion and vector decoder operations. This paper analyzes the performance, energy profile, and resource implication of two matrix inversion and decoding algorithms; Gaussian elimination (GE) and third Generation Partnership Group (3GPP) standard (SA), for the Raptor decoder on a system on a chip (SoC) platform with a soft-core embedded processor. We investigate the effect of the cache size, memory type, and mapping on the performance of the two algorithms under consideration. We show that with an appropriate data to memory mapping, a speedup factor of 5.77 can be obtained for GE with respect to SA. This paper also proposes a dedicated peripheral hardware block that achieves 5.90 times better performance compared with the software, requiring an energy consumption that is lower by a factor of 5.5, when the symbol size and the data path word length are small (32 bits). We show that with parallel processing in hardware, using the wider word lengths, and employing bigger symbol sizes T, we can improve the performance, while reducing the energy consumption. Extending the hardware word length and symbol size T to 128 bits will result in a performance improvement factor of 6.73 in favor of the hardware; while energy consumption reduces by a factor of 3.8.","Decoding,
Sparse matrices,
Memory management,
Embedded systems,
Encoding"
Asymmetric Versus Symmetric Pulses for Cortical Microstimulation,"Intracortical microstimulation (ICMS), which has shown promise in the visual, auditory and somatosensory systems as a platform for sensory prostheses, typically relies on charged balanced, symmetric, biphasic stimulation. However, neural stimulation models as well as experiments conducted in cochlear implant users have suggested that charge balanced asymmetric pulses could generate lower detection thresholds for stimulation in terms of charge per phase. For this study, rats were chronically implanted with microelectrode arrays unilaterally in their right auditory cortex and then trained to detect ICMS delivered through a single electrode site in order to determine their behavioral threshold. This model was used in two experiments. The first experiment addressed the effect of lead phase direction, asymmetry, and phase duration on detection threshold. The second experiment fixed the cathode phase duration at 123 μs and varied only the phase asymmetry and lead phase direction. Taken together, the results of these experiments suggest that, for ICMS, the primary determinant of threshold level is cathode phase duration, and that asymmetry provides no significant advantage when compared to symmetric, cathode leading pulses. However, symmetric anode leading pulses of less than or equal to 205 μs per phase consistently showed higher thresholds when compared to all other pulses of equal cathode phase duration.",
Learning to interpret pointing gestures with a time-of-flight camera,"Pointing gestures are a common and intuitive way to draw somebody's attention to a certain object. While humans can easily interpret robot gestures, the perception of human behavior using robot sensors is more difficult. In this work, we propose a method for perceiving pointing gestures using a Time-of-Flight (ToF) camera. To determine the intended pointing target, frequently the line between a person's eyes and hand is assumed to be the pointing direction. However, since people tend to keep the line-of-sight free while they are pointing, this simple approximation is inadequate. Moreover, depending on the distance and angle to the pointing target, the line between shoulder and hand or elbow and hand may yield better interpretations of the pointing direction. In order to achieve a better estimate, we extract a set of body features from depth and amplitude images of a ToF camera and train a model of pointing directions using Gaussian Process Regression. We evaluate the accuracy of the estimated pointing direction in a quantitative study. The results show that our learned model achieves far better accuracy than simple criteria like head-hand, shoulder-hand, or elbow-hand line.","Cameras,
Head,
Humans,
Robot vision systems,
Elbow"
"A continuous, wearable, and wireless heart monitor using head ballistocardiogram (BCG) and head electrocardiogram (ECG)","Continuous and wearable heart monitoring is essential for early detection and diagnosis of cardiovascular diseases. We demonstrate a continuous, wearable, and wireless heart monitor that is worn at the ear. The device has the form factor of a hearing aid and is wirelessly connected to a PC for data recording and analysis. With the ear as an anchoring point, the heart monitor measures the ballistocardiographic (BCG) motion of the head using a MEMS tri-axial accelerometer, which is an electrode-less method to measure heart rate. Additionally, electrocardiogram (ECG) is measured locally near the ear using a single-lead configuration. The peak timing delay between the head ECG and the head BCG, or RJ interval, can be extracted in the presence of noise using cross-correlation. The RJ interval is shown to correlate to the heart's pre-ejection period during both Valsalva and whole-body tilt maneuvers.","Electrocardiography,
Biomedical monitoring,
Heart,
Monitoring,
Ear,
Magnetic heads,
Noise"
The Land Mobile Earth-Space Channel,"Research on mobile satellite and high-altitude platform (HAP) systems (MSHSs) has recently proliferated because of the allocation of additional spectrum, the intense standardization efforts from different international institutes, the detailed studies pursued by the European [European Space Agency (ESA)], French (CNES), and Japanese (JAXA) space agencies, and the commercial impact of some of the corresponding system implementations. A survey of mobile satellite systems is provided. Enhanced land mobile Earth-space (LMES) channels encompassing a variety of geometries, frequency bands, and propagation environments are critical for developing and assessing the performance of these new MSHS paradigms. In this article, we provide a survey of the state-of-the-art measurement campaigns, modeling approaches, and generative methods concerning the LMES channel and pinpoint future research directions. We refer to LMES since, due to the close similarities they exhibit, we present channels from both geostationary (GEO) satellites and quasi-stationary HAPs. Most of the cited models apply in both cases. General emphasis is on statistical/physical narrow-band models, which is the norm in LMES channels.","Satellites,
Markov processes,
Shadow mapping,
Doppler effect,
Channel models,
Land mobile radio cellular systems,
Integrated circuit modeling"
Fast List-Mode Reconstruction for Time-of-Flight PET Using Graphics Hardware,"Positron emission tomography (PET) measurements with time-of-flight (TOF) information are often very sparse. As a result, direct reconstruction from raw list-mode data is an attractive strategy for dealing with the large dimension spanned by the measurements. However, even though sparse datasets are more efficiently processed in list mode than as sinograms, list-mode reconstruction remains computationally demanding and computer clusters are typically required for reconstructing clinical PET scans with TOF information. In this work, we demonstrate that off-the-shelf graphics processing units can be used as an alternative approach to accelerate line projections with TOF kernels.",
Hybrid CMOS/nanodevice circuits for high throughput pattern matching applications,"We propose a class of novel hybrid CMOS/nanodevice circuits for pattern matching applications (e.g. real-time network intrusion detection, network packet routing, DNA sequencing), with the potential for dramatic improvements in throughput, density, and power performance relative to state-of-the-art designs. The performance advantage of our novel circuits is mainly due to three factors: the implementation of a ternary content addressable memory cell with stackable ultra-dense resistive switching (“memristive” or RRAM) devices; three dimensional hybrid CMOS/nanodevice circuitry with an area-distributed interface enabling high communication bandwidth between the memory and CMOS subsystems; and use of a modified CMOL FPGA fabric with low reconfiguration overhead.",
SNR Dependence of Optimal Parameters for Apparent Diffusion Coefficient Measurements,"Optimizing the diffusion-weighted imaging (DWI) parameters (i.e., the b-value and the number of image averages) to the tissue of interest is essential for producing high-quality apparent diffusion coefficient (ADC) maps. Previous investigation of this optimization was performed assuming Gaussian noise statistics for the ADC map, which is only valid for high signal-to-noise ratio (SNR) imaging. In this work, the true statistics of the noise in ADC maps are derived, followed by an optimization of the DWI parameters as a function of the imaging SNR. Specifically, it is demonstrated that the optimum b-value is a monotonically increasing function of the imaging SNR, which converges to the optimum b-value from previously proposed approaches for high-SNR cases, while exhibiting a significant deviation from this asymptote for low-SNR situations. Incorporating the effects of T2 weighting further increases the SNR dependence of the optimal parameters. The proposed optimization scheme is particularly important for high-resolution DWI, which intrinsically suffers from low SNR and therefore cannot afford the use of the conventional high b-values. Comparison scans were performed for high-resolution DWI of the spinal cord, demonstrating the improvements in the resulting images and the ADC maps achieved by this method.","Signal to noise ratio,
Estimation,
Optimization,
Biomedical imaging,
Noise measurement"
Assuring application-level correctness against soft errors,"Traditionally, research in fault tolerance has required architectural state to be numerically perfect for program execution to be correct. However, in many programs, even if execution is not 100% numerically correct, the program can still appear to execute correctly from the user's perspective. To quantify user satisfaction, application-level fidelity metrics (such as PSNR) can be used. The output for such applications is defined to be correct if the fidelity metrics satisfy a certain threshold. However, such applications still contain instructions whose outputs are critical - i.e. their correctness decides if the overall quality of the program output is acceptable. In this paper, we present an analysis technique for identifying such critical program segments. More importantly, our technique is capable of guaranteeing application-level correctness through a combination of static analysis and runtime monitoring. Our static analysis consists of data flow analysis followed by control flow analysis to find static critical instructions which affect several instructions. Critical instructions are further refined into likely non-critical and likely critical sets in a profiling phase. At runtime, we use a monitoring scheme to monitor likely non-critical instructions and take remedial actions if some likely non-critical instructions become critical. Based on this analysis, we minimize the number of instructions that are duplicated and checked at runtime using a software-based fault detection and recovery technique [20]. Put together, our approach can lead to 22% average energy savings for multimedia applications while guaranteeing application-level correctness, when compared to a recent work [9], which cannot guarantee application-level correctness. Comparing to the approach proposed in [20] which guarantees both application-level and numerical correctness, our method achieves 79% energy reduction.","Runtime,
Monitoring,
Arrays,
Measurement,
Indexes,
Handheld computers,
Vectors"
A Network-Flow Based Pin-Count Aware Routing Algorithm for Broadcast-Addressing EWOD Chips,"Electrowetting-on-dielectric (EWOD) chips have emerged as the most widely used actuators for digital microfluidic (DMF) systems. These devices enable the electrical manipulation of microfluidics with various advantages, such as low power consumption, flexibility, accuracy, and efficiency. In addressing the need for low-cost and practical fabrication, pin-count reduction has become a key problem to the large-scale integration of EWOD-chip designs. One of the major approaches, broadcast addressing, reduces the pin count by assigning a single control pin to multiple electrodes with mutually compatible control signals. Most previous studies utilize this addressing scheme by scheduling fluidic-level synthesis on pin-constrained chip arrays. However, the associated interconnect routing problem is still not provided in currently available DMF automations, and thus the broadcast-addressing scheme cannot be actually realized. In this paper, we present the first network-flow based pin-count aware routing algorithm for EWOD-chip designs with a broadcast electrode-addressing scheme. Our algorithm simultaneously takes pin-count reduction and wirelength minimization into consideration for higher integration and better design performance. Experimental results show the effectiveness and scalability of our algorithm on a set of real-life chip applications.","Algorithm design and analysis,
Microfluidics,
Electrodes,
Actuators,
Power demand,
Printed circuits,
Broadcast technology"
NUcache: An efficient multicore cache organization based on Next-Use distance,"The effectiveness of the last-level shared cache is crucial to the performance of a multi-core system. In this paper, we observe and make use of the DelinquentPC - Next-Use characteristic to improve shared cache performance. We propose a new PC-centric cache organization, NUcache, for the shared last level cache of multi-cores. NUcache logically partitions the associative ways of a cache set into MainWays and DeliWays. While all lines have access to the MainWays, only lines brought in by a subset of delinquent PCs, selected by a PC selection mechanism, are allowed to enter the DeliWays. The PC selection mechanism is an intelligent cost-benefit analysis based algorithm that utilizes Next-Use information to select the set of PCs that can maximize the hits experienced in DeliWays. Performance evaluation reveals that NUcache improves the performance over a baseline design by 9.6%, 30% and 33% respectively for dual, quad and eight core workloads comprised of SPEC benchmarks. We also show that NUcache is more effective than other well-known cache-partitioning algorithms.","Organizations,
Histograms,
Multicore processing,
Algorithm design and analysis,
Measurement,
Correlation,
Benchmark testing"
"Congestion aware, fault tolerant, and thermally efficient inter-layer communication scheme for hybrid NoC-bus 3D architectures","Three-dimensional IC technology offers greater device integration and shorter interlayer interconnects. In order to take advantage of these attributes, 3D stacked mesh architecture was proposed which is a hybrid between packet-switched network and a bus. Stacked mesh is a feasible architecture which provides both performance and area benefits, while suffering from inefficient intermediate buffers. In this paper, an efficient architecture to optimize system performance, power consumption, and reliability of stacked mesh 3D NoC is proposed. The mechanism benefits from a congestion-aware and bus failure tolerant routing algorithm called AdaptiveZ for vertical communication. In addition, we hybridize the proposed adaptive routing with available algorithms to mitigate the thermal issues by herding most of the switching activities closer to the heat sink. Our extensive simulations with synthetic and real benchmarks, including the one with an integrated video-conference application, demonstrate significant power, performance, and peak temperature improvements compared to a typical stacked mesh 3D NoC.","Three dimensional displays,
Routing,
Thermal resistance,
Silicon,
Heat sinks"
Multi-Task Rank Learning for Visual Saliency Estimation,"Visual saliency plays an important role in various video applications such as video retargeting and intelligent video advertising. However, existing visual saliency estimation approaches often construct a unified model for all scenes, thus leading to poor performance for the scenes with diversified contents. To solve this problem, we propose a multi-task rank learning approach which can be used to infer multiple saliency models that apply to different scene clusters. In our approach, the problem of visual saliency estimation is formulated in a pair-wise rank learning framework, in which the visual features can be effectively integrated to distinguish salient targets from distractors. A multi-task learning algorithm is then presented to infer multiple visual saliency models simultaneously. By an appropriate sharing of information across models, the generalization ability of each model can be greatly improved. Extensive experiments on a public eye-fixation dataset show that our multi-task rank learning approach outperforms 12 state-of-the-art methods remarkably in visual saliency estimation.",
Low-Complexity Parallel Chien Search Structure Using Two-Dimensional Optimization,"To achieve a high-throughput decoder, massive-parallel computations are normally applied to the Chien search, but the parallel realization increases the hardware complexity significantly. To reduce the hardware complexity of the parallel Chien search, this brief proposes a 2-D optimization method. In contrast to the previous 1-D optimizations, the proposed method maximizes the sharing of common subexpressions in both the row and column directions. All the partial products needed in the parallel structure are represented in a single matrix, and the finite-field adders are completely eliminated in effect. Simulation results show that the proposed 2-D optimization leads to a significant reduction of the hardware complexity. For the (8191, 7684, 39) BCH code, the count of xor gates in the parallel Chien search is reduced by 92% and 22%, compared to the straightforward and strength-reduced structures, respectively.","Complexity theory,
Computer architecture,
Optimization,
Hardware,
Logic gates,
Decoding,
Adders"
Limit of the Accuracy of Parameter Estimation for Moving Single Molecules Imaged by Fluorescence Microscopy,"In this paper, we consider the problem of the accuracy of estimating the location and other attributes of a moving single molecule whose trajectory is imaged by fluorescence microscopy. As accuracy in parameter estimation is closely related to the Fisher information matrix, we first give a general expression of the Fisher information matrix for the estimated parameters for a single object moving in three-dimensional (3D) space. Explicit Cramér-Rao lower bound (CRLB) expressions are then obtained from the Fisher information matrix for a single object moving in the two-dimensional (2D) focus plane with the object trajectory being either linear or circular. We also investigate how extraneous noise sources, pixelation, parameters of the detection system and parameters of the trajectory affect the limit of the accuracy. The results obtained in this paper provide insights that enable the experimentalists to optimize their experimental setups for tracking single molecules in order to achieve the best possible accuracy. They are also applicable to the general problem of tracking an object using quantum limited detectors.","Accuracy,
Detectors,
Trajectory,
Microscopy,
Photonics,
Pixel,
Optical microscopy"
An intelligent system for detecting faults in photovoltaic fields,"In this work, an intelligent system for automatic detection of fault in PV fields is proposed. This system is based on a Takagi-Sugeno-Kahn Fuzzy Rule-Based System (TSK-FRBS), which provides an estimation of the instant power production of the PV field in normal functioning, i.e, when no faults occur. Then, the estimated power is compared with the real power and an alarm signal is generated if the difference between powers overcomes a threshold. The TSK-FRBS has been trained using data collected from a PV plant simulator, during normal functioning. Preliminary tests were carried out in a simulated framework, by reproducing both normal and fault conditions. Results show that the system can recognize more than 90% of fault conditions, even when noisy data are introduced.","Arrays,
Circuit faults,
Training,
Intelligent systems,
Inverters,
Noise measurement,
Monitoring"
MDP optimal control under temporal logic constraints,"In this paper, we develop a method to automatically generate a control policy for a dynamical system modeled as a Markov Decision Process (MDP). The control specification is given as a Linear Temporal Logic (LTL) formula over a set of propositions defined on the states of the MDP. We synthesize a control policy such that the MDP satisfies the given specification almost surely, if such a policy exists. In addition, we designate an “optimizing proposition” to be repeatedly satisfied, and we formulate a novel optimization criterion in terms of minimizing the expected cost in between satisfactions of this proposition. We propose a sufficient condition for a policy to be optimal, and develop a dynamic programming algorithm that synthesizes a policy that is optimal under some conditions, and sub-optimal otherwise. This problem is motivated by robotic applications requiring persistent tasks, such as environmental monitoring or data gathering, to be performed.","Markov processes,
Equations,
Vectors,
Dynamic programming,
Probabilistic logic,
Strontium,
Transient analysis"
Learning Similarity With Multikernel Method,"In the field of machine learning, it is a key issue to learn and represent similarity. This paper focuses on the problem of learning similarity with a multikernel method. Motivated by geometric intuition and computability, similarity between patterns is proposed to be measured by their included angle in a kernel-induced Hilbert space. Having noticed that the cosine of such an included angle can be represented by a normalized kernel, it can be said that the task of learning similarity is equivalent to learning an appropriate normalized kernel. In addition, an error bound is also established for learning similarity with the multikernel method. Based on this bound, a boosting-style algorithm is developed. The preliminary experiments validate the effectiveness of the algorithm for learning similarity.","Kernel,
Extraterrestrial measurements,
Laboratories,
Mathematics,
Machine learning,
Hilbert space,
Clustering algorithms,
Particle measurements,
Semisupervised learning,
Matrix decomposition"
Direct geometrico-static problem of under-constrained cable-driven parallel robots with three cables,"This paper studies under-constrained cable-driven parallel robots with three cables. A major challenge in the study of these manipulators is the intrinsic coupling between kinematics and statics, which must be tackled simultaneously. In this contribution, a general elimination procedure is provided that solves the direct geometrico-static problem, which consists in determining the platform posture and the cable tensions when the cable lengths are assigned. The problem is proven to have up to 156 complex solutions.","Polynomials,
Manipulators,
Bismuth,
Robot kinematics,
Generators"
Automatic alignment of a camera with a line scan LIDAR system,"We propose a new method for extrinsic calibration of a line-scan LIDAR with a perspective projection camera. Our method is a closed-form, minimal solution to the problem. The solution is a symbolic template found via variable elimination and the multi-polynomial Macaulay resultant. It does not require initialization, and can be used in an automatic calibration setting when paired with RANSAC and least-squares refinement. We show the efficacy of our approach through a set of simulations and a real calibration.","Calibration,
Laser radar,
Cameras,
Three dimensional displays,
Polynomials,
Image edge detection"
Computational Perceptual Features for Texture Representation and Retrieval,"A perception-based approach to content-based image representation and retrieval is proposed in this paper. We consider textured images and propose to model their textural content by a set of features having a perceptual meaning and their application to content-based image retrieval. We present a new method to estimate a set of perceptual textural features, namely coarseness, directionality, contrast, and busyness. The proposed computational measures can be based upon two representations: the original images representation and the autocorrelation function (associated with original images) representation. The set of computational measures proposed is applied to content-based image retrieval on a large image data set, the well-known Brodatz database. Experimental results and benchmarking show interesting performance of our approach. First, the correspondence of the proposed computational measures to human judgments is shown using a psychometric method based upon the Spearman rank-correlation coefficient. Second, the application of the proposed computational measures in texture retrieval shows interesting results, especially when using results fusion returned by each of the two representations. Comparison is also given with related works and show excellent performance of our approach compared to related approaches on both sides: correspondence of the proposed computational measures with human judgments as well as the retrieval effectiveness.","Image retrieval,
Content based retrieval,
Humans,
Anthropometry,
Psychology,
Image texture analysis,
Statistical analysis,
Permission,
Computational efficiency,
Image representation"
BCN: Expansible network structures for data centers using hierarchical compound graphs,"A fundamental challenge in data centers is how to design networking structures for efficiently interconnecting a large number of servers. Several server-centric structures have been proposed, but are not truly expansible and suffer low degree of regularity and symmetry. To address this issue, we propose two novel structures called HCN and BCN, which utilize hierarchical compound graphs to interconnect large population of servers each with two ports only. They own two topological advantages, i.e., the expansibility and equal degree. In addition, HCN offers high degree of regularity, scalability and symmetry, which well conform to the modular design of data centers. Moreover, a BCN of level one in each dimension involves more servers than FiConn with server degree 2 and diameter 7, and is large enough for a single data center. Mathematical analysis and comprehensive simulations show that BCN possesses excellent topology properties and is a viable network structure for data centers.",
Target shift awareness in balanced ensemble learning,"In the balanced ensemble learning for a two-class classification problem, the target values are shifted between [1 : 0.5) or (0.5 : 0] instead of 1 and 0 in the learned error function. Such shifted error function could let the ensemble avoid from unnecessary further learning on the well-learned data points. Therefore, the learning direction could be shifted away from the well-learned data points, and turned to the other not-yet-learned data points. By shifting away from well-learned data and focusing on not-yet-learned data, a good balanced learning could be achieved in the ensemble. Through examining both individual learners and the combined ensembles, this paper is to explore how the target shift awareness could help to decide a decision boundary that is neither too close nor too further to all training samples.","pattern classification,
learning (artificial intelligence)"
Resource Sharing in GPU-Accelerated Windowing Systems,"Recent windowing systems allow graphics applications to directly access the graphics processing unit (GPU) for fast rendering. However, application tasks that render frames on the GPU contend heavily with the windowing server that also accesses the GPU to blit the rendered frames to the screen. This resource-sharing nature of direct rendering introduces core challenges of priority inversion and temporal isolation in multi-tasking environments. In this paper, we identify and address resource-sharing problems raised in GPU-accelerated windowing systems. Specifically, we propose two protocols that enable application tasks to efficiently share the GPU resource in the X Window System. The Priority Inheritance with X server (PIX) protocol eliminates priority inversion caused in accessing the GPU, and the Reserve Inheritance with X server (RIX) protocol addresses the same problem for resource-reservation systems. Our design and implementation of these protocols highlight the fact that neither the X server nor user applications need modifications to use our solutions. Our evaluation demonstrates that multiple GPU-accelerated graphics applications running concurrently in the X Window System can be correctly prioritized and isolated by the PIX and the RIX protocols.",
Modeling of Complex-Valued Wiener Systems Using B-Spline Neural Network,"In this brief, a new complex-valued B-spline neural network is introduced in order to model the complex-valued Wiener system using observational input/output data. The complex-valued nonlinear static function in the Wiener system is represented using the tensor product from two univariate B-spline neural networks, using the real and imaginary parts of the system input. Following the use of a simple least squares parameter initialization scheme, the Gauss-Newton algorithm is applied for the parameter estimation, which incorporates the De Boor algorithm, including both the B-spline curve and the first-order derivatives recursion. Numerical examples, including a nonlinear high-power amplifier model in communication systems, are used to demonstrate the efficacy of the proposed approaches.","Spline,
Artificial neural networks,
Numerical models,
Biological system modeling,
Polynomials,
Signal processing algorithms"
Index coding with outerplanar side information,"We study the Index Coding problem with side information graphs which are outerplanar. For general side information graphs, linearly solving the Index Coding problem implies a linear solution to the general (non-multicast) Network Coding problem - a central open problem in the field of network communication. For outerplanar side information graphs, we show that the Index Coding problem can be solved efficiently, and characterize its solution in terms of the clique cover size of the information graph at hand.","Indexes,
Network coding,
Complexity theory,
Computer science,
Channel coding,
Face"
Hybrid networks: lessons learned and future challenges based on ESnet4 experience,"ESnet, the Energy Sciences Network, has the mission of providing the network infrastructure to the U.S. Department of Energy's Office of Science programs and facilities, which depend on large collaborations and large-scale data sharing, enabling them to accomplish their science. ESnet4 - a hybrid IP and dynamic circuit network designed in 2006 and completed in 2008 - has managed to effectively satisfy the networking needs of the science community, easily handling dramatic growth in traffic requirements: around 80 percent growth year over year and 300 percent growth with the Large Hadron Collider (LHC) coming online. In this article, we examine the benefits and limitations of the current hybrid architecture based on actual production experience; discuss open research problems; and predict factors that will drive the evolution of hybrid networks, including advances in network technology, new computer architectures, and the onset of large-scale distributed computing.","Bandwidth,
IP networks,
Large Hadron Collider,
Optical switches,
US Departent of Energy,
Optical network units,
Hybrid integrated circuits,
Telecommunication network topology"
Enhanced Functional Brain Imaging by Using Adaptive Filtering and a Depth Compensation Algorithm in Diffuse Optical Tomography,"Reflectance diffuse optical tomography (rDOT) of brain function is limited by its high sensitivity to the superficial tissues (i.e., the scalp and skull) and by its severe decrease in measurement sensitivity with increased depth. Significant interference in rDOT results from spontaneous fluctuations that are embedded in both the superficial tissues and brain, such as arterial pulsation and vasomotion. In this study, first we investigate coherence and phase shift of the spontaneous fluctuations in the resting state, within the superficial tissues and at various depths of the brain, respectively. We demonstrate that the spontaneous fluctuations originating from arterial pulsations (~ 1 Hz) are spatially global and temporally coherent, while the fluctuations originating from vasomotion (~ 0.1 Hz) tend to have less coherence with increased depth. Second, adaptive cancellation of spontaneous fluctuations with a frequency-specific strategy is utilized and validated in both resting and activation (evoked by a finger-tapping task) states. Third, improved depth localization of motor activation in reconstructed rDOT images is achieved by combining adaptive cancellation with a depth compensation algorithm that we recently reported.","Fluctuations,
Coherence,
Adaptive filters,
Protocols,
Sensitivity,
Detectors,
Band pass filters"
Reachability-based synthesis of feedback policies for motion planning under bounded disturbances,"The task of planning and controlling robot motion in practical applications is often complicated by the effects of model uncertainties and environment disturbances. We present in this paper a systematic approach for generating robust motion control strategies to satisfy high level specifications of safety, target attainability, and invariance, under unknown but bounded, continuous disturbances. The motion planning task is decomposed into the two sub-problems of finite horizon reach with avoid and infinite horizon invariance. The set of states for which each of the sub-problems is robustly feasible is computed via iterative reachability calculations under a differential game framework. We discuss how the results of this computation can be used to inform selections of control inputs based upon state measurements at run-time and provide an algorithm for implementing the corresponding feedback control policies. Finally, we demonstrate an experimental application of this method to the control of an autonomous helicopter in tracking a moving ground vehicle.",
"The ""S"" in Social Network Games: Initiating, Maintaining, and Enhancing Relationships","Social network games embedded within social network sites (SNSs) such as Facebook facilitate play with ""Friends"" within the SNS. In this study, we look at different dimensions of how game play contributes to relationship initiation and development using qualitative data collected from adult Facebook users (N=18). Our data suggest that interpersonal motivations are a primary driver of initial game play and that while game play doesn't facilitate direct social interaction, participants perceived indirect interaction and sharing game-based content was useful in maintaining and even enhancing relationships.","Games,
Facebook,
Interviews,
Publishing,
Computers,
Feeds"
A cooperative social and vehicular network and its dynamic bandwidth allocation algorithms,"This paper investigates into a special type of network that encourages cooperation between its upper layer social network and lower layer wireless communication network with particular focus on commuters on the road. Regarded as a branch of mobile social networks, the so-called vehicular social network (VSNs) proposed in this paper needs to consider both social aspects (such as social ties through common interests) and physical network operational mechanisms to design a system that is effective to its users and efficient to network resources. This calls for in-depth investigations into the correlation between social behaviours and network algorithms. This paper aims to making some preliminary exploration into this exciting field by investigating into how social centrality, an important concept in social network analysis, makes impact on dynamic bandwidth allocation (DBA) in a specific scenario of vehicular social networks. In particular the paper introduces centrality into the utility function's formula, based on which DBA is carried out in IEEE 802.16j-enable vehicular networks.",
Human Motion Tracking by Temporal-Spatial Local Gaussian Process Experts,"Human pose estimation via motion tracking systems can be considered as a regression problem within a discriminative framework. It is always a challenging task to model the mapping from observation space to state space because of the high-dimensional characteristic in the multimodal conditional distribution. In order to build the mapping, existing techniques usually involve a large set of training samples in the learning process which are limited in their capability to deal with multimodality. We propose, in this work, a novel online sparse Gaussian Process (GP) regression model to recover 3-D human motion in monocular videos. Particularly, we investigate the fact that for a given test input, its output is mainly determined by the training samples potentially residing in its local neighborhood and defined in the unified input-output space. This leads to a local mixture GP experts system composed of different local GP experts, each of which dominates a mapping behavior with the specific covariance function adapting to a local region. To handle the multimodality, we combine both temporal and spatial information therefore to obtain two categories of local experts. The temporal and spatial experts are integrated into a seamless hybrid system, which is automatically self-initialized and robust for visual tracking of nonlinear human motion. Learning and inference are extremely efficient as all the local experts are defined online within very small neighborhoods. Extensive experiments on two real-world databases, HumanEva and PEAR, demonstrate the effectiveness of our proposed model, which significantly improve the performance of existing models.","Humans,
Gaussian processes,
Computational modeling,
Training,
Databases,
Estimation,
Tracking"
"Crafting a usable microkernel, processor, and I/O system with strict and provable information flow security","High assurance systems used in avionics, medical implants, and cryptographic devices often rely on a small trusted base of hardware and software to manage the rest of the system. Crafting the core of such a system in a way that achieves flexibility, security, and performance requires a careful balancing act. Simple static primitives with hard partitions of space and time are easier to analyze formally, but strict approaches to the problem at the hardware level have been extremely restrictive, failing to allow even the simplest of dynamic behaviors to be expressed. Our approach to this problem is to construct a minimal but configurable architectural skeleton. This skeleton couples a critical slice of the low level hardware implementation with a microkernel in a way that allows information flow properties of the entire construction to be statically verified all the way down to its gate-level implementation. This strict structure is then made usable by a runtime system that delivers more traditional services (e.g. communication interfaces and long-living contexts) in a way that is decoupled from the information flow properties of the skeleton. To test the viability of this approach we design, test, and statically verify the information-flow security of a hardware/software system complete with support for unbounded operation, inter-process communication, pipelined operation, and I/O with traditional devices. The resulting system is provably sound even when adversaries are allowed to execute arbitrary code on the machine, yet is flexible enough to allow caching, pipelining, and other common case optimizations.","Security,
Kernel,
Logic gates,
Hardware,
Skeleton,
Registers"
Low-Complexity Nonlinear Adaptive Filter Based on a Pipelined Bilinear Recurrent Neural Network,"To reduce the computational complexity of the bilinear recurrent neural network (BLRNN), a novel low-complexity nonlinear adaptive filter with a pipelined bilinear recurrent neural network (PBLRNN) is presented in this paper. The PBLRNN, inheriting the modular architectures of the pipelined RNN proposed by Haykin and Li, comprises a number of BLRNN modules that are cascaded in a chained form. Each module is implemented by a small-scale BLRNN with internal dynamics. Since those modules of the PBLRNN can be performed simultaneously in a pipelined parallelism fashion, it would result in a significant improvement of computational efficiency. Moreover, due to nesting module, the performance of the PBLRNN can be further improved. To suit for the modular architectures, a modified adaptive amplitude real-time recurrent learning algorithm is derived on the gradient descent approach. Extensive simulations are carried out to evaluate the performance of the PBLRNN on nonlinear system identification, nonlinear channel equalization, and chaotic time series prediction. Experimental results show that the PBLRNN provides considerably better performance compared to the single BLRNN and RNN models.","Recurrent neural networks,
Neurons,
Artificial neural networks,
Convergence,
Computational modeling,
Computer architecture,
Pipeline processing"
Fabrication of Highly Ordered Silicon Nanowire Arrays With Controllable Sidewall Profiles for Achieving Low-Surface Reflection,"A novel and simple approach is demonstrated for fabricating silicon nanowire arrays (SNWAs) with controllable sidewall profiles. A single-step deep-reactive-ion etching (SDRIE) is used to transfer the holography patterned photoresist template to silicon or silicon-on-insulator substrates. With the SDRIE etching process, scalloping of the sidewalls can be avoided while reserving the high-mask selectivity over resist and high-etching rate. The sidewall angle of resultant patterns can be adjusted by tuning the composition of the gas mixture of the process. A modified-SDRIE process with a linearly changed gas flow is further developed to extend its capability. A post-high-energy argon plasma treatment is used to create sharp tips on the top of SNWAs and to increase the filling factor. Broadband antireflective (AR) window with a low reflectivity can be realized from tall SNWAs with high-filling factor. Depositing silicon dioxide over SNWAs can further enhance the AR performance. The position and bandwidth of the AR window can be controlled by tuning the SNWA parameters.",
Continuous-Time Linear Parameter-Varying Identification of a Cross Flow Heat Exchanger: A Local Approach,"In this paper, the problem of deriving a dynamical model of a cross flow heat exchanger is considered. In order to take into account the dependency of the system's dynamics on the hot and the cold mass flow rates in an explicit way, an input-output linear parameter-varying (LPV) model is used. A local approach composed of three steps is carried out to identify this LPV model. A parameter estimation scheme is introduced in which cost functions are minimized by using specific nonlinear programming methods. In this study, a finite volume physical model simulator is exploited to simulate and to generate the data. Simulations are performed to demonstrate the benefits of the suggested approach.","Heating,
Numerical models,
Heat transfer,
Transfer functions,
Data models,
Atmospheric modeling,
Mathematical model"
Performance Bounds for Expander-Based Compressed Sensing in Poisson Noise,"This paper provides performance bounds for compressed sensing in the presence of Poisson noise using expander graphs. The Poisson noise model is appropriate for a variety of applications, including low-light imaging and digital streaming, where the signal-independent and/or bounded noise models used in the compressed sensing literature are no longer applicable. In this paper, we develop a novel sensing paradigm based on expander graphs and propose a maximum a posteriori (MAP) algorithm for recovering sparse or compressible signals from Poisson observations. The geometry of the expander graphs and the positivity of the corresponding sensing matrices play a crucial role in establishing the bounds on the signal reconstruction error of the proposed algorithm. We support our results with experimental demonstrations of reconstructing average packet arrival rates and instantaneous packet counts at a router in a communication network, where the arrivals of packets in each flow follow a Poisson process.",
Noncoherent Capacity of Secret-Key Agreement With Public Discussion,"We study the noncoherent capacity of secret-key agreement with public discussion over independent identically distributed (i.i.d.) Rayleigh fading wireless channels, where neither the sender nor the receivers have access to instantaneous channel state information (CSI). We present two results. At high signal-to-noise ratio (SNR), the secret-key capacity is bounded in SNR, regardless of the number of antennas at each terminal. Second, for a system with a single antenna at both the legitimate and the eavesdropper terminals and an arbitrary number of transmit antennas, the secret-key capacity-achieving input distribution is discrete, with a finite number of mass points. Numerically we observe that at low SNR, the capacity achieving distribution has two mass points with one of them at the origin.",
On a game theoretic approach to capacity maximization in wireless networks,"We consider the capacity problem (or, the single slot scheduling problem) in wireless networks. Our goal is to maximize the number of successful connections in arbitrary wirelessnetworks where a transmission is successful only if the signal-to-interference-plus-noise ratio at the receiver is greater than some threshold. We study a game theoretic approach towards capacity maximization introduced by Andrews and Dinitz (INFOCOM 2009) and Dinitz (INFOCOM 2010). We prove vastly improved bounds for the game theoretic algorithm. In doing so, we achieve the first distributed constant factor approximation algorithm for capacity maximization for the uniform power assignment. When compared to the optimum where links may use an arbitrary power assignment, we prove a O(log Δ) approximation, where Δ is the ratio between the largest and the smallest link in the network. This is an exponential improvement of the approximation factor compared to existing results for distributed algorithms. All our results work for links located in any metric space. In addition, we provide simulation studies clarifying the picture on distributed algorithms for capacity maximization.","Approximation algorithms,
Approximation methods,
Measurement,
Optimized production technology,
Games,
Interference,
Wireless networks"
"Comments on ""Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering","In order to resolve the problem that the denoising performance has a sharp drop when noise standard deviation reaches 40, proposed to replace the wavelet transform by the DCT. In this comment, we argue that this replacement is unnecessary, and that the problem can be solved by adjusting some numerical parameters. We also present this parameter modification approach here. Experimental results demonstrate that the proposed modification achieves better results in terms of both peak signal-to-noise ratio and subjective visual quality than the original method for strong noise.","Image denoising,
Collaboration,
Noise reduction,
Filtering,
Noise level,
PSNR,
Permission,
Wavelet transforms,
Discrete cosine transforms,
Standards development"
Friend recommendations in social networks using genetic algorithms and network topology,"Social networking sites employ recommendation systems in contribution to providing better user experiences. The complexity in developing recommendation systems is largely due to the heterogeneous nature of social networks. This paper presents an approach to friend recommendation systems by using complex network theory, cognitive theory and a Pareto-optimal genetic algorithm in a two-step approach to provide quality, friend recommendations while simultaneously determining an individual's perception of friendship. Our research emphasizes that by combining network topology and genetic algorithms, better recommendations can be achieved compared to each individual counterpart. We test our approach on 1,200 Facebook users in which we observe the combined method to outper form purely social or purely network-based approaches. Our preliminary results represent strong potential for developing link recommendation systems using this combined approach of personal interests and the underlying network.","Bioinformatics,
Genomics,
Genetic algorithms,
Facebook,
Cost accounting,
Humans"
Advanced control strategies for wind energy systems: An overview,"Wind energy systems have been emerging as a highly significant solution to the problem of limited traditional energy sources. In this paper, control methodologies adapted to wind energy systems are topically reviewed. oHard computing or control techniques such as proportional-integral-derivative (PID), optimal, nonlinear, adaptive and robust and soft computing or control techniques such as neural networks, fuzzy logic, genetic algorithms and on the fusion or hybrid of hard and soft control techniques are primarily focused. This overview concludes with some possible future directions are also suggested. This overview is not intended to be an exhaustive survey on this topic and any omissions of other works is purely unintentional.",
Localized Field Enhancements in Guided and Defect Modes of a Periodic Slot Waveguide,"We present a periodic slot waveguide for achieving enhanced light-matter interaction that provides significant localized field and power density enhancements over traditional slot waveguides. The basic structure is based on a slot waveguide with 1-D periodic holes. The slot effect provides strong field enhancement and subwavelength confinement, and the periodicity of the structure is exploited to locally magnify or “pinch” the electric field distribution, resulting in additional enhancements. Characteristics of the modes presented by this structure are examined by finite-difference time-domain (FDTD) modeling. Distinct optical gradients and localized enhancements, which are up to 4-5 times greater than comparable slot waveguides, can be achieved. Potential application of the periodic slot waveguide structure to fields, including optical manipulation, sensing, and nonlinear or active material integration, is discussed.","Optical waveguides,
Dielectrics,
Electric fields,
Photonic crystals,
Optical resonators"
Shape Measurement of Steel Strips Using a Laser-Based Three-Dimensional Reconstruction Technique,"Quality control is of utmost importance in the metal industry. It requires online measurement and inspection systems which provide precise feedback to closed-loop controllers in industrial facilities. In rolled products, shape is one of the main quality criteria. In this paper, a low-cost real-time 3-D shape measurement system for long flat (FL)-rolled products based on laser triangulation is proposed. The system provides online measurements of two geometrical features of the shape of rolled products: flatness and width. The proposed system is based on 3-D surface reconstruction of rolled products with which flatness can be measured accurately and continuously across the whole width of the strip. Three-dimensional surface reconstruction provides highly accurate width measurements not only of FL products, as do most other systems, but also of non-FL products. The accuracy of the laser extraction method used to reconstruct the surface of the rolled products is evaluated, as well as the online performance of the system.","Strips,
Surface emitting lasers,
Three dimensional displays,
Measurement by laser beam,
Shape,
Shape measurement,
Accuracy"
Deploying Cryptography in Internet-Scale Systems: A Case Study on DNSSEC,"The DNS Security Extensions (DNSSEC) are among the first attempts to deploy cryptographic protections in an Internet-scale operational system. DNSSEC applies well-established public key cryptography to ensure data integrity and origin authenticity in the DNS system. While the cryptographic design of DNSSEC is sound and seemingly simple, its development has taken the IETF over a decade and several protocol revisions, and even today its deployment is still in the early stage of rolling out. In this paper, we provide the first systematic examination of the design, deployment, and operational challenges encountered by DNSSEC over the years. Our study reveals a fundamental gap between cryptographic designs and operational Internet systems. To be deployed in the global Internet, a cryptographic protocol must possess several critical properties including scalability, flexibility, incremental deployability, and ability to function in face of imperfect operations. We believe that the insights gained from this study can offer valuable inputs to future cryptographic designs for other Internet-scale systems.","Internet,
Public key cryptography,
Computer science,
Data security,
Protection,
Cryptographic protocols,
Computer security,
Scalability,
Web server,
Public key"
Using deceptive packets to increase base-station anonymity in wireless sensor network,"In wireless sensor networks, nodes probe ambient conditions in their surrounding and report back to the base-station via multi-hop routing. In a hostile environment the network may be subject to adversary attacks. Given the role that the base-station plays, it can be targeted in order to inflict the most damage to the network. Although stealth design and other physical precautionary measures may be pursued to hide the base-station, the fact that the base-station acts as a sink of all data transmission enables an adversary to employ traffic analysis techniques and identify the location of the base-station. This paper presents a novel approach for countering such traffic analysis and boosting the anonymity of the base-station. Sensors in low activity areas will send out deceptive packets among each other in order to distract the attention of the adversary and make the traffic analysis inconclusive. Simulation results show the effectiveness of the approach.","Sensors,
Routing,
Wireless sensor networks,
Topology,
Switches,
Traffic control,
Data communication"
Secure cloud storage for convenient data archive of smart phones,"The importance of the data stored in the smart phones is increased as more applications are deployed and executed. Once the smart phone is damaged or lost, the valuable information treasured in the device is lost altogether. If cloud storage can be integrated with cloud services for periodical data backup of a mobile client, the risk of data lost can be minimized. However, the important data might be uncovered by a malicious third party during retrieval or transmission of information using wireless cloud storage without proper authentication and protection. Therefore, in this paper, we design an archive mechanism that integrates cloud storage, hybrid cryptography, and digital signatures to provide security requirements for data storage of mobile phones. Our mechanism not only can avoid malicious attackers from illegal access but also can share desired information with targeted friends by distinct access rights.","Mobile communication,
Coplanar waveguides,
Cloud computing,
Authentication,
Mobile handsets"
Teaching teamwork in engineering and computer science,"Teamwork is recognized as an important skill for engineering and computer science professionals. Both potential employers and accrediting agencies, such as ABET, expect students to gain proficiency in teamwork skills through experiential learning. Teamwork based projects challenge the student to apply the technical knowledge they gain in school to solve meaningful and complex problems. However, to be truly proficient in teamwork, a student must also learn and practice a large number of peripheral skills. These include planning, estimating, tracking progress, taking corrective actions, managing change, controlling and managing risks, maintaining ethical and professional conduct, communicating complex ideas clearly and concisely, using design automation tools, leveraging web-based tools for team collaboration, and most importantly participating effectively as team members. It is essential that students should be taught these important skills. It is unlikely that without adequate faculty guidance students can pick up these skills through ad-hoc project experience. Yet, many engineering and computer science programs expect the students to do just that. We feel strongly that we need to employ a more pragmatic approach in teaching students the skills necessary to function as effective and productive team members. Additionally, we need to develop criteria for assessing the effectiveness of teaching teamwork and the tools to measure learning outcomes. Among the problems contributing to this situation are the following: engineering and computer science instructors themselves often have had little or no experience operating in teams; training or guidance in effective ways to teach teamwork is seldom provided; and tools and effective approaches to assist in the teaching and assessment of teamwork are lacking. Another problem is that, it takes a great deal of faculty time, effort and energy to guide groups of students in doing effective teamwork. We will describe an approach that we have used to teach team collaboration skills using free and freely available web-based tools. Students learn to use tools for design automation, metrics collection, project management, and web-based collaboration. Our approach encourages students to learn teamwork skills and improves levels of collaboration among team members while reducing demands on faculty time and effort. Use of web-based collaboration tools allows students to participate without the need for frequent face-to-face meetings; this our students love. In an effort to maximize the use of techniques like the ones described in this paper, we hold regular informal sessions of interested faculty to share ideas on improving teaching teamwork and to develop methods and tools for assessment. The paper and the conference presentation will describe both our approach and the results we have obtained.","Teamwork,
Educational institutions,
Computer science,
Google,
Conferences"
Magnetic Hand Tracking for Human-Computer Interface,"Hand motion tracking is useful in human-computer interface and many other applications requiring human-machine interactions. In this work, permanent magnets and contactless magnetic sensors are used to track finger motion. A magnet patch is affixed to each fingernail to mark the location and orientation of the fingertip. When fingers move, the combined magnetic fields produced by the magnets at fingertips are recorded by a set of magnetic sensors around a wristband. The recorded data from the sensors are utilized to calculate the magnets' locations and orientations, which can provide estimate of the hand posture based on a geometric hand model.","Tracking,
Keyboards,
Indexes,
Magnetic sensors,
Magnetic resonance imaging,
Computational modeling"
Behavioral Modeling of MIMO Nonlinear Systems With Multivariable Polynomials,"This paper proposes a novel behavioral model for multiple-input single-output (MISO) and multiple-input multiple-output (MIMO) nonlinear transmitters based on multivariable polynomials (MVPs). The main source of nonlinearity in these transmitters is the RF power amplifier, which is commonly modeled using polynomial models. The proposed MVP model is capable of handling the nonlinear effects of the RF transmitters, as well as the linear and nonlinear crosstalk between the input signals. At the same time, the developed model was optimized for computing efficiency without compromising its accuracy. The model was tested for MISO and MIMO wireless transmitters. The simulations and measurement results revealed that the proposed model gives excellent accuracy when modeling MIMO transmitters with different branch coupling factors.",
Wideband Beam-Steerable Flat Reflectors via Transformation Optics,"A conventional parabolic reflector is converted into a flat one based on the discrete coordinate transformation. Instead of general beam-steering techniques, such as off-axis feeding, tilting the feed/reflector, or utilizing phase shift, we show an alternative way to manipulate the reflected emission through tuning transformed dielectrics. The proposed design, only including the conventional dielectric components, has a merit of keeping the flat profile of a compact reflector system while possessing the ability to steer the radiation beams in a wide frequency band.","Permittivity,
Feeds,
Apertures,
Dielectrics,
Optics,
Materials,
Educational institutions"
Wideband energy harvesting for piezoelectric devices with linear resonant behavior,"In this paper, an active energy harvesting technique for a spring-mass-damper mechanical resonator with piezoelectric electromechanical coupling is investigated. This technique applies a square-wave voltage to the terminals of the device at the same frequency as the mechanical excitation. By controlling the magnitude and phase angle of this voltage, an effective impedance matching can be achieved which maximizes the amount of power extracted from the device. Theoretically, the harvested power can be the maximum possible value, even at off-resonance frequencies. However, in actual implementation, the efficiency of the power electronic circuit limits the amount of power harvested. A power electronic full-bridge converter is built to implement the technique. Experimental results show that the active technique can increase the effective bandwidth by a factor of more than 2, and harvests significantly higher power than rectifier-based circuits at off-resonance frequencies.",
Synthesis and Beyond,"This article outlined several optimization techniques applied in different steps of the synthesis of filters and multiplexers. The importance of the subject has been appreciated by more and more researchers and engineers in this community. As it is impossible to cover all technologies available, the objective here is to provoke a broader thinking beyond basic filter synthesis. Established computer-aided design methodology is a true blend of both synthesis and optimization. In most cases, to meet a set of well thought-out specifications, the science of filter synthesis and trade-off applies. In other cases, the optimization of design is an art which creates opportunities and new possibilities.","Resonator filters,
Optimization,
Predistortion,
Multiplexing,
Base stations,
Insertion loss"
Deep belief nets for natural language call-routing,"This paper considers application of Deep Belief Nets (DBNs) to natural language call routing. DBNs have been successfully applied to a number of tasks, including image, audio and speech classification, thanks to the recent discovery of an efficient learning technique. DBNs learn a multi-layer generative model from unlabeled data and the features discovered by this model are then used to initialize a feed-forward neural network which is fine-tuned with backpropagation. We compare a DBN-initialized neural network to three widely used text classification algorithms; Support Vector machines (SVM), Boosting and Maximum Entropy (MaxEnt). The DBN-based model gives a call-routing classification accuracy that is equal to the best of the other models even though it currently uses an impoverished representation of the input.","Training,
Boosting,
Artificial neural networks,
Training data,
Data models,
Support vector machines,
Accuracy"
A Hyperelastic Finite-Element Model of Human Skin for Interactive Real-Time Surgical Simulation,"A finite-element (FE) model of human skin is proposed for future use in an interactive real-time surgical simulation to teach surgeons procedures, such as facial reconstruction using skin-flap repair. For this procedure, skin is cut into flaps that are stretched to cover openings in the face. Thus, the model must recreate the visual, haptic, and force feedback expected by the surgeon. To develop the FE model, a series of in vitro experiments were conducted on samples of human skin, subjected to uniaxial and planar tensile straining. Reduced polynomial hyperelastic (HE) materials were found to fit many of the samples' stress-strain data well. Finally, an explicit dynamic FE mesh was developed based on the fitted HE material models. A total Lagrangian formulation with the half-step central difference method was employed to integrate the dynamic equation of motion of the mesh. The mesh was integrated into two versions of a real-time skin simulator: a single-threaded version running on a computer's main central processing unit and a multithreaded version running on the computer's graphics card. The latter was achieved by exploiting recent advances in programmable graphics technology.","Finite element methods,
Humans,
Skin,
Surgery,
Conducting materials,
Computer graphics,
Haptic interfaces,
Force feedback,
In vitro,
Polynomials"
Adaptive Learning for Target Tracking and True Linking Discovering Across Multiple Non-Overlapping Cameras,"To track targets across networked cameras with disjoint views, one of the major problems is to learn the spatio-temporal relationship and the appearance relationship, where the appearance relationship is usually modeled as a brightness transfer function. Traditional methods learning the relationships by using either hand-labeled correspondence or batch-learning procedure are applicable when the environment remains unchanged. However, in many situations such as lighting changes, the environment varies seriously and hence traditional methods fail to work. In this paper, we propose an unsupervised method which learns adaptively and can be applied to long-term monitoring. Furthermore, we propose a method that can avoid weak links and discover the true valid links among the entry/exit zones of cameras from the correspondence. Experimental results demonstrate that our method outperforms existing methods in learning both the spatio-temporal and the appearance relationship, and can achieve high tracking accuracy in both indoor and outdoor environment.","Cameras,
Target tracking,
Topology,
Brightness,
Lighting,
Transfer functions,
Monitoring"
Predict and spread: An efficient routing algorithm for opportunistic networking,"With their proliferation and increasing capabilities, mobile devices with local wireless interfaces can be organized into opportunistic networks that exploit communication opportunities arising out of the movement of their users. Because the nodes are carried by people, these opportunistic networks can also be viewed as social networks. Unfortunately, existing routing algorithms for opportunistic networks rely on relatively simple mobility models that rarely consider these social network characteristics. In this paper, we propose PreS (Predict and Spread), an efficient routing algorithm for opportunistic networking that employs an adapted Markov chain to model a node's mobility pattern, and capture its social characteristics. A comparison with state-of-the-art algorithms suggests that PreS can yield better performance in terms of delivery ratio and delivery latency, and approaches the performance of the Epidemic algorithm with lower resource consumption.",
Bayesian Visual Reranking,"Visual reranking has been proven effective to refine text-based video and image search results. It utilizes visual information to recover “true” ranking list from the noisy one generated by text-based search, by incorporating both textual and visual information. In this paper, we model the textual and visual information from the probabilistic perspective and formulate visual reranking as an optimization problem in the Bayesian framework, termed Bayesian visual reranking. In this method, the textual information is modeled as a likelihood, to reflect the disagreement between reranked results and text-based search results which is called ranking distance. The visual information is modeled as a conditional prior, to indicate the ranking score consistency among visually similar samples which is called visual consistency. Bayesian visual reranking derives the best reranking results by maximizing visual consistency while minimizing ranking distance. To model the ranking distance more precisely, we propose a novel pair-wise method which measure the ranking distance based on the disagreement in terms of pair-wise orders. For visual consistency, we study three different regularizers to mine the best way for its modeling. We conduct extensive experiments on both video and image search datasets. Experimental results demonstrate the effectiveness of our proposed Bayesian visual reranking.","Visualization,
Bayesian methods,
Laplace equations,
Kernel,
Predictive models,
Probabilistic logic,
Face detection"
Shape-based pedestrian parsing,"We describe a simple model for parsing pedestrians based on shape. Our model assembles candidate parts from an oversegmentation of the image and matches them to a library of exemplars. Our matching uses a hierarchical decomposition into a variable number of parts and computes scores on partial matchings in order to prune the search space of candidate segment. Simple constraints enforce consistent layout of parts. Because our model is shape-based, it generalizes well. We use exemplars from a controlled dataset of poses but achieve good test performance on unconstrained images of pedestrians in street scenes. We demonstrate results of parsing detections returned from a standard scanning-window pedestrian detector and use the resulting parse to perform viewpoint prediction and detection re-scoring.","Shape,
Image segmentation,
Accuracy,
Legged locomotion,
Assembly,
Face"
A 3-D 160-Site Microelectrode Array for Cochlear Nucleus Mapping,"A 3-D application-specific microelectrode array has been developed for physiological studies in guinea pig cochlear nucleus (CN). The batch-fabricated silicon probes contain integrated parylene cables and use a boron etch-stop to define 15μm-thick shanks and limit tissue displacement. Targeting the ventral (three probes) and dorsal (two probes) subnuclei, the custom four-shank 32-site probes are combined in a slotted block platform having a 1.18-mm2 footprint. The device has permitted, for the first time, high-density 3-D in vivo studies of ventral CN to dorsal CN connections, stimulating with 1000 μm2 sites in one subnucleus while recording with 177 μm 2 sites in the other. Through these experiments, it has demonstrated the efficacy of bimodal silicon arrays to better understand the central nervous system at the circuit level. The 160 electrode sites also provide a high-density neural interface, which is an essential aspect of auditory prosthesis prototypes.","Probes,
Arrays,
Surgery,
Prosthetics,
Silicon,
Microelectrodes"
Multidimensional Shrinkage-Thresholding Operator and Group LASSO Penalties,"The scalar shrinkage-thresholding operator is a key ingredient in variable selection algorithms arising in wavelet denoising, JPEG2000 image compression and predictive analysis of gene microarray data. In these applications, the decision to select a scalar variable is given as the solution to a scalar sparsity penalized quadratic optimization. In some other applications, one seeks to select multidimensional variables. In this work, we present a natural multidimensional extension of the scalar shrinkage thresholding operator. Similarly to the scalar case, the threshold is determined by the minimization of a convex quadratic form plus an Euclidean norm penalty, however, here the optimization is performed over a domain of dimension N ≥ 1. The solution to this convex optimization problem is called the multidimensional shrinkage threshold operator (MSTO). The MSTO reduces to the scalar case in the special case of N=1. In the general case of N >; 1 the optimal MSTO shrinkage can be found through a simple convex line search. We give an efficient algorithm for solving this line search and show that our method to evaluate the MSTO outperforms other state-of-the art optimization approaches. We present several illustrative applications of the MSTO in the context of Group LASSO penalized estimation.",
Socioscope: Human Relationship and Behavior Analysis in Social Networks,"In this paper, we propose a socioscope model for social-network and human-behavior analysis based on mobile-phone call-detail records. Because of the diversity and complexity of human social behavior, no one technique will detect every attribute that arises when humans engage in social behaviors. We use multiple probability and statistical methods for quantifying social groups, relationships, and communication patterns and for detecting human-behavior changes. We propose a new index to measure the level of reciprocity between users and their communication partners. This reciprocity index has application in homeland security, detection of unwanted calls (e.g., spam), telecommunication presence, and product marketing. For the validation of our results, we used real-life call logs of 81 users which contain approximately 500 000 h of data on users' location, communication, and device-usage behavior collected over eight months at the Massachusetts Institute of Technology (MIT) by the Reality Mining Project group. Also, call logs of 20 users collected over six months by the University of North Texas (UNT) Network Security team are used. The MIT and UNT data sets contain approximately 5000 callers. The experimental results show that our model is effective.","Social network services,
Humans,
Data models,
Statistical analysis,
Mobile handsets,
Social factors"
High performance computing for electric power systems: Applications and trends,"The last significant works that made an effort to review and summarize the relationship between High Performance Computing (HPC) and Power Systems Analysis were published in the mid 1990's. Since that time significant changes have occurred in both fields. HPC has seen the maturation of cluster computing, the advent of multicore, the creation of Grid Computing, the rise of the GPU for general purpose computing and the gradual ending of Moore's law. Power systems have also changed and matured at a rapid pace through deregulation, the integration of renewable energy, the integration of distributed energy production and storage, concerns regarding climate change, and recent discussions concerning the smart grid. Considering the vast amount of change that has occurred in both industries, this work reviews ways in which HPC has been used in the field of power systems over the last 15 years while also identifying some emerging trends and suggesting possible future applications.","Program processors,
Power system reliability,
Reliability,
Computational modeling,
Grid computing,
Algorithm design and analysis"
Microwave-Plasma-Coupled Re-Ignition of Methane-and-Oxygen Mixture Under Auto-Ignition Temperature,"The re-ignition phenomenon is observed when fuel/oxidizer is re-introduced into an atmospheric-pressure plasma discharge generated by cutting off the gas flow in a re-entrant microwave-plasma applicator system used for plasma-assisted ignition and combustion research works. Results indicate that, for re-ignition to occur, the electric field must be strong enough to fully establish a weakly ionized and self-sustained plasma discharge, and with elevated radical concentrations. The re-ignition was possible at gas flow speeds higher than typical flame propagation rates, and temperature measurements (thermocouple and N2 emission) reveal that re-ignition occurs under auto-ignition temperatures. The high-speed imaging of the flame propagation shows that it is a two step process of initiating a fast pyrolysis flame, which, in turn, stabilizes and starts the direct coupling process of the plasma energy into the flame for full re-ignition to occur.","Fluorescence,
Temperature measurement,
Discharges,
Plasma temperature,
Combustion,
Ignition"
A Two-Stage Integer Linear Programming-Based Droplet Routing Algorithm for Pin-Constrained Digital Microfluidic Biochips,"With the increasing design complexities, the design of pin-constrained digital microfluidic biochips (PDMFBs) is of practical importance for the emerging marketplace. However, solutions of current pin-count reduction are inevitably limited by simply adopting it after the droplet routing stage. In this paper, we propose the first droplet routing algorithm for PDMFBs that can integrate pin-count reduction with droplet routing stage. Furthermore, our algorithm is capable of minimizing the number of control pins, the number of used cells, and the droplet routing time. We first present a basic integer linear programming (ILP) formulation to optimally solve the droplet routing problem for PDMFBs with simultaneous multiobjective optimization. Due to the complexity of this ILP formulation, we also propose a two-stage technique of global routing followed by incremental ILP-based routing to reduce the solution space. To further reduce the runtime, we present a deterministic ILP formulation that casts the original routing optimization problem into a decision problem, and solve it by a binary solution search method that searches in logarithmic time. Extensive experiments demonstrate that in terms of the number of the control pins, the number of the used cells, and the routing time, we obtain much better achievement than all the state-of-the-art algorithms in any aspect.","Routing,
Electrodes,
Pins,
Complexity theory,
Algorithm design and analysis,
Arrays,
Timing"
Improvement of the Off-State Breakdown Voltage With Fluorine Ion Implantation in AlGaN/GaN HEMTs,"Improvement of the AlGaN/GaN high-electron mobility transistor's (HEMT's) off -state breakdown voltage is achieved by implanting 19F+ ions at an energy of 50 keV and dose of 1 × 1012 cm-2 under the gate region using BF3 as the source. The charge state of the implanted fluorine ions changes from positive to negative in the AlGaN/GaN structure because of fluorine's strong electronegativity. The negative-charged fluorine ions at the back side of the two-dimensional electron gas can raise the energy barrier of the GaN buffer layer under the channel, effectively blocking the current injected from the source to the high-field region of the GaN channel when the HEMT is biased at off-state. The source-injected electrons, if not blocked, could flow to the high-field region and initiate a premature three-terminal off-state breakdown in a conventional AlGaN/GaN HEMT. A 38% improvement of the three-terminal off-state breakdown voltage and 40% improvement of the power figure-of-merit VBD-off2/Ron are achieved in the enhanced back barrier HEMT.","Gallium nitride,
HEMTs,
MODFETs,
Aluminum gallium nitride,
Electric breakdown,
Logic gates,
Ion implantation"
Impact of HfTaO Buffer Layer on Data Retention Characteristics of Ferroelectric-Gate FET for Nonvolatile Memory Applications,"A p-channel metal-ferroelectric-insulator-silicon field-effect transistor (FET) with a 300-nm-thick SrBi2Ta2O9 (SBT) ferroelectric film and a 10-nm-thick HfTaO layer on silicon substrate was fabricated and characterized. The device shows a nearly unchanged memory window of about 0.9 V after a 2 × 1011-cycles fatigue test, an on/off current ratio of more than 107, and a field-effect mobility of approximately 42 cm2/V · s. Moreover, a drain-current on/off ratio as high as 105 was obtained with a fixed gate voltage of 2.5 V after over a 105 -s elapsed time without any obvious degradation. These results may suggest that the Pt/SBT/HfTaO/Si FET is suitable for high-performance ferroelectric memory.","Logic gates,
FETs,
Silicon,
Buffer layers,
Substrates,
Fabrication"
Linearized Downconverting Microwave Photonic Link Using Dual-Wavelength Phase Modulation and Optical Filtering,"We describe a technique transmitting K-band microwave signals over an optical channel using electrooptic phase modulation at the transmitter followed by series phase modulation and bandpass filtering in the receiver to downconvert the transmitted signal to an intermediate frequency (IF). Unlike other downconversion methods, the method does not require a microwave mixer, high-speed optical photoreceivers, optically stabilized local oscillator, or active bias control at either phase modulator. We further show that the link can be linearized by using two wavelengths launched along orthogonal axes of a single lithium niobate phase modulator at the transmitter. We successfully demonstrate linearized downconversion of a 20-GHz microwave signal to a 250-MHz IF. The linearization method results in a 14-dB improvement in the spurious-free dynamic range compared with the nonlinearized case.","Optical transmitters,
Optical modulation,
Phase modulation,
Optical receivers,
Optical mixing,
Microwave photonics"
Efficient AUV navigation fusing acoustic ranging and side-scan sonar,"This paper presents an on-line nonlinear least squares algorithm for multi-sensor autonomous underwater vehicle (AUV) navigation. The approach integrates the global constraints of range to and GPS position of a surface vehicle or buoy communicated via acoustic modems and relative pose constraints arising from targets detected in side-scan sonar images. The approach utilizes an efficient optimization algorithm, iSAM, which allows for consistent on-line estimation of the entire set of trajectory constraints. The optimized trajectory can then be used to more accurately navigate the AUV, to extend mission duration, and to avoid GPS surfacing. As iSAM provides efficient access to the marginal covariances of previously observed features, automatic data association is greatly simplified - particularly in sparse marine environments. A key feature of our approach is its intended scalability to single surface sensor (a vehicle or buoy) broadcasting its GPS position and simultaneous one-way travel time range (OWTT) to multiple AUVs. We discuss why our approach is scalable as well as robust to modem transmission failure. Results are provided for an ocean experiment using a Hydroid REMUS 100 AUV co-operating with one of two craft: an autonomous surface vehicle (ASV) and a manned support vessel. During these experiments the ranging portion of the algorithm ran online on-board the AUV. Extension of the paradigm to multiple missions via the optimization of successive survey missions (and the resultant sonar mosaics) is also demonstrated.","Vehicles,
Sonar,
Sonar navigation,
Acoustics,
Distance measurement,
Sea measurements,
Position measurement"
Conversation Scene Analysis [Social Sciences],"This paper discusses about conservation scene analysis. It has the potential to revitalize human-human communications. Conversation scene analysis aims to provide the automatic description of conversation scenes from the multimodal nonverbal behaviors of participants, which are captured with cameras and microphones.","Mobile communication,
Visualization,
Markov processes,
Image analysis,
Probabilistic logic,
Face recognition"
A low-power 64-point pipeline FFT/IFFT processor for OFDM applications,"4G and other wireless systems are currently hot topics of research and development in the communication field. Broadband wireless systems based on orthogonal frequency division multiplexing (OFDM) often require an inverse fast Fourier transform (IFFT) to produce multiple subcarriers. In this paper, we present the efficient implementation of a pipeline FFT/IFFT processor for OFDM applications. Our design adopts a single-path delay feedback style as the proposed hardware architecture. To eliminate the read-only memories (ROM's) used to store the twiddle factors, the proposed architecture applies a reconfigurable complex multiplier and bit-parallel multipliers to achieve a ROM-less FFT/IFFT processor, thus consuming lower power than the existing works. The design spends about 33.6K gates, and its power consumption is about 9.8mW at 20MHz.","Hardware,
Pipelines,
Computer architecture,
OFDM,
Read only memory,
Discrete Fourier transforms,
Power demand"
Evaluation of Mechanisms in TID Degradation and SEE Susceptibility of Single- and Multi-Level High Density NAND Flash Memories,"Heavy ion single-event measurements and total ionizing dose (TID) response for 8 Gb commercial NAND flash memories are reported. Radiation results of multi-level flash technology are compared with results from single-level flash technology. The single-level devices are less sensitive to single event upsets (SEUs) than multi-level devices. In general, these commercial high density memories exhibit less TID degradation compared to older generations of flash memories.","Ash,
Radiation effects,
Computer architecture,
Microprocessors,
Silicon,
Threshold voltage,
Logic gates"
Efficient complex operators for irregular codes,"Complex “fat operators” are important contributors to the efficiency of specialized hardware. This paper introduces two new techniques for constructing efficient fat operators featuring up to dozens of operations with arbitrary and irregular data and memory dependencies. These techniques focus on minimizing critical path length and load-use delay, which are key concerns for irregular computations. Selective Depipelining(SDP) is a pipelining technique that allows fat operators containing several, possibly dependent, memory operations. SDP allows memory requests to operate at a faster clock rate than the datapath, saving power in the datapath and improving memory performance. Cachelets are small, customized, distributed L0 caches embedded in the datapath to reduce load-use latency. We apply these techniques to Conservation Cores(c-cores) to produce coprocessors that accelerate irregular code regions while still providing superior energy efficiency. On average, these enhanced c-cores reduce EDP by 2× and area by 35% relative to c-cores. They are up to 2.5× faster than a general-purpose processor and reduce energy consumption by up to 8× for a variety of irregular applications including several SPECINT benchmarks.","Clocks,
Registers,
Hardware,
Pipeline processing,
Silicon,
Memory management"
A Low-Power FPGA Based on Autonomous Fine-Grain Power Gating,"This paper presents a field-programmable gate array (FPGA) based on lookup table level fine-grain power gating with small overheads. The power gating technique implemented in the proposed architecture can directly detect the activity of each look-up-table easily by exploiting features of asynchronous architectures. Moreover, detecting the data arrival in advance prevents the delay increase for waking-up and the power consumption of unnecessary power switching. Since the power gating technique has small overheads, the granularity size of a power-gated domain is as fine as a single two-input and one-output lookup table. The proposed FPGA is fabricated using the ASPLA 90-nm CMOS process with dual threshold voltages. We use an image processing application called “template matching” for evaluation. Since the proposed FPGA is suitable for processing where the workload changes dynamically, an adaptive algorithm where a small computational kernel is employed. Compared to a synchronous FPGA and an asynchronous FPGA without power gating, the power consumption is reduced respectively by 38% and 15% at 85°C.","Field programmable gate arrays,
Clocks,
Energy consumption,
Table lookup,
Very large scale integration,
Threshold voltage,
Computer architecture,
Costs,
Delay estimation,
CMOS process"
Mobile Phones and Outdoor Advertising: Measurable Advertising,A system for measuring audiences of outdoor advertising in specific areas is based on the combination of mobile phone location estimations with Internet listings of social events.,"Mobile handsets,
Advertising,
Marketing and sales,
Internet,
Mobile communication"
Efficient Hybrid-Game Strategies Coupled to Evolutionary Algorithms for Robust Multidisciplinary Design Optimization in Aerospace Engineering,"A number of game strategies have been developed in past decades and used in the fields of economics, engineering, computer science, and biology due to their efficiency in solving design optimization problems. In addition, research in multiobjective and multidisciplinary design optimization has focused on developing a robust and efficient optimization method so it can produce a set of high quality solutions with less computational time. In this paper, two optimization techniques are considered; the first optimization method uses multifidelity hierarchical Pareto-optimality. The second optimization method uses the combination of game strategies Nash-equilibrium and Pareto-optimality. This paper shows how game strategies can be coupled to multiobjective evolutionary algorithms and robust design techniques to produce a set of high quality solutions. Numerical results obtained from both optimization methods are compared in terms of computational expense and model quality. The benefits of using Hybrid and non-Hybrid-Game strategies are demonstrated.","Robustness,
Games,
Uncertainty,
Evolutionary computation,
Topology,
Optimization methods"
Advance reservation frameworks in hybrid IP-WDM networks,"New e-Science and grid applications require the coordination of geographically distributed scientific instruments along with data and computing resources. Due to the quality of service requirements of these applications, these distributed resources can be connected by a wavelength-routed optical network, allowing each application to get dedicated bandwidth. These networks are referred to as LambdaGrids. One important service provided in these networks is advance reservation. Applications need to coordinate the use of both grid resources and the network. Advance reservation allows these applications to reserve bandwidth in advance to guarantee availability. In this article, we discuss different networks and frameworks that support advance reservation of bandwidth. We discuss the general architecture of each network and the type of advance reservation services supported.","Optical fiber networks,
Resource management,
Computer architecture,
Network topology,
Network toplogy,
IP networks,
Wavelength division multiplexing"
Privacy in the Age of Google and Facebook,"Google and Facebook look to be at best naive, and at worst inept, when it comes to managing data privacy.Privacy is a key protection for intellectual, polit ical, and religious freedom, as well as the dignity of the individual. We cannot underestimate the power of the online revolution unleashed by Google and Facebook, but we can not ignore the inherent vulnerabili ties their size brings to digital social databases.","Facebook,
Google,
Privacy,
Legal aspects,
Electronic mail,
IEEE 802.11 Standards"
Analysis of Coordinated Denial-of-Service Attacks in IEEE 802.22 Networks,"The cognitive radio enabled IEEE 802.22 wireless regional area network (WRAN) is designed to opportunistically utilize the unused or under-utilized TV bands. However, due to the open nature of cognitive radio networks and lack of proactive security protocols, the IEEE 802.22 networks are vulnerable to various denial-of-service (DoS) threats. In this paper, we study coordinated DoS attacks on IEEE 802.22 networks from the malicious users' perspective. We consider both one-stage and a multi-stage cases of the problem. In the one-stage scenario, we formulate a cooperative game among the malicious nodes and derive the optimal decision strategy for the them. In the multi-stage case, we propose a discrete-time Markov chain model for the dynamic behavior of both malicious nodes and the 802.22 secondary networks. Simulation and numerical results demonstrate that in the one-stage case, the coordinated attack achieves 10-15% improvement compared to the non-cooperative attack from the perspective of malicious nodes, and, in the multi-stage case, there exists an optimal number of malicious nodes that maximize the net payoff under the steady state.","Switches,
Games,
Computer crime,
Markov processes,
Jamming,
Sensors"
Automatic Enrichment of Semantic Relation Network and Its Application to Word Sense Disambiguation,"The most fundamental step in semantic information processing (SIP) is to construct knowledge base (KB) at the human level; that is to the general understanding and conception of human knowledge. WordNet has been built to be the most systematic and as close to the human level and is being applied actively in various works. In one of our previous research, we found that a semantic gap exists between concept pairs of WordNet and those of real world. This paper contains a study on the enrichment method to build a KB. We describe the methods and the results for the automatic enrichment of the semantic relation network. A rule based method using WordNet's glossaries and an inference method using axioms for WordNet relations are applied for the enrichment and an enriched WordNet (E-WordNet) is built as the result. Our experimental results substantiate the usefulness of E-WordNet. An evaluation by comparison with the human level is attempted. Moreover, WSD-SemNet, a new word sense disambiguation (WSD) method in which E-WordNet is applied, is proposed and evaluated by comparing it with the state-of-the-art algorithm.","Semantics,
Artificial neural networks,
Terminology,
Surgery,
Grasping,
Humans,
Diseases"
A 10-MHz Green-Mode Automatic Reconfigurable Switching Converter for DVS-Enabled VLSI Systems,"A power-efficient, high-frequency, automatic reconfigurable switching converter is presented in this paper for DVS-enabled VLSI systems. Tailored to the system-level power management, the proposed cross-layered green-mode (GM) operation scheme adaptively configures the converter into three operation structures to achieve a seamless step-up/down voltage conversion with minimized power loss. In addition, an adaptive power transistor sizing (APTS) scheme is incorporated to further improve efficiency on the transistor level. To enable high-frequency operation in all power regulation conditions, an i L-assisted single-bound hysteresis controller (SBHC) is also proposed in this work. Meanwhile, in order to suppress output spectrum variations induced by the hysteresis controller, an adaptive frequency compensator (AFC) is employed. The proposed converter was fabricated with IBM 130-nm CMOS process, with a total chip area of 1 mm2. Its output voltage can be seamlessly regulated from 0.9 to 2.2 V, with a maximum load power of 400 mW. The input voltage is designed at 1.5 V, but is variable at any level between 0.9 and 1.8 V. The switching frequency of the converter is regulated at 10 MHz in all three operation modes, with ±3% deviation. Experimental results show a 26.7- μs/V down-tracking and 93.3-μs/V up-tracking speed for dynamic voltage scaling (DVS) reference tracking. Line regulation is maintained below 0.8% throughout the full input voltage range, with a lowest value of 0.17%. The power efficiency stays above 80% over the entire 400-mW power range, with a peak value of 92.1% at 1.2-V output and 250-mW load power.","Voltage control,
Hysteresis,
Delay,
Switches,
Power transistors,
Switching converters,
Switching frequency"
Development of a controllable and continuous jumping robot,"A miniature robot with continuous jumping ability is presented in this paper. The robot has a dimension about 6cm×8cm×2cm and weighs 20 grams. To achieve continuous jumping, various mechanisms are needed including the jumping mechanism, energy store and release mechanism, self-righting mechanism, and jumping direction changing mechanism. The design and analysis for those mechanisms are elaborated in this paper. Moreover, implementation and experimental results are also presented. It is shown that the robot can jump higher than 55cm with a 75° takeoff angle. The robot can be used as mobile sensors and deployed in the areas of rugged terrain and natural obstacles which are not suitable for sensors with wheels.",
Achieving Memetic Adaptability by Means of Agent-Based Machine Learning,"Over recent years, there has been increasing interest of the research community towards evolutionary algorithms, i.e., algorithms that exploit computational models of natural processes to solve complex optimization problems. In spite of their ability to explore promising regions of the search space, they present two major drawbacks: 1) they can take a relatively long time to locate the exact optimum and 2) may sometimes not find the optimum with sufficient precision. Memetic Algorithms are evolutionary algorithms inspired by both Darwinian principles and Dawkins' notion of a meme, able not only to converge to high-quality solutions, but also search more efficiently than their conventional evolutionary counterparts. However, memetic approaches are affected by several design issues related to the different choices that can be made to implement them. This paper introduces a multiagent-based memetic algorithm which executes in a parallel way different cooperating optimization strategies in order to solve a given problem's instance in an efficient way. The algorithm adaptation is performed by jointly exploiting a knowledge extraction process together with a decision making framework based on fuzzy methodologies. The effectiveness of our approach is tested in several experiments in which our results are compared with those obtained by nonadaptive memetic algorithms. The superiority of the proposed strategy is manifest in the majority of cases.","Algorithm design and analysis,
Multiagent systems,
Memetics,
Machine learning,
Data mining"
Opportunistic Access of TV Spectrum Using Cognitive-Radio-Enabled Cellular Networks,"Motivated by the Federal Communications Commission's recent approval of commercial unlicensed operations of some television (TV) spectrum, we propose to integrate cognitive radios (CRs) that operate on unoccupied TV bands with an existing cellular network to increase bandwidth for mobile users. The existing cellular infrastructure is used to enable the operation of such CRs. Because base stations (BSs) can sense spectrum and exchange the sensed information for the reliable detection of primary users (PUs) and white spaces, we propose a collaborative sensing mechanism based on cell topology, where the BS declares its cell to be PU-free when neither the BS nor its neighboring BSs detect any PU. This way, in a PU-free cell, the following two types of channels are available: 1) channels that are originally licensed for the cellular system and 2) CR channels that are discovered through spectrum sensing. Because the CR channels that operate on TV bands usually suffer less path loss than the cellular channels, we derive two important results. First, each user gains more capacity when accessing a cellular channel than an empty TV channel, as long as intercell interferences are caused by the same sources. Second, assigning TV bands to cell-edge users is better in maximizing cell capacity. These two effects and the performance of the proposed sensing mechanism are verified through numerical evaluation.","Sensors,
TV,
Collaboration,
Bandwidth,
Topology,
Interference,
Land mobile radio cellular systems"
A highly-underactuated robotic hand with force and joint angle sensors,"This paper describes a novel underactuated robotic hand design. The hand is highly underactuated as it contains three fingers with three joints each controlled by a single motor. One of the fingers (“thumb”) can also be rotated about the base of the hand, yielding a total of two controllable degrees-of-freedom. A key component of the design is the addition of position and tactile sensors which provide precise angle feedback and binary force feedback. Our mechanical design can be analyzed theoretically to predict contact forces as well as hand position given a particular object shape","Thumb,
Force,
Joints,
Tendons,
Sensors,
Actuators"
Constant approximation for virtual backbone construction with Guaranteed Routing Cost in wireless sensor networks,"In wireless sensor networks, virtual backbone construction based on connected dominating set is a competitive issue for routing efficiency and topology control. Assume that a sensor networks is defined as a connected unit disk graph (UDG). The problem is to find a minimum connected dominating set of given UDG with minimum routing cost for each node pair. We present a constant approximation scheme which produces a connected dominating set D, whose size |D| is within a factor α from that of the minimum connected dominating set and each node pair exists a routing path with all intermediate nodes in D and with length at most 5 · d(u,v), where d(u,v) is the length of shortest path of this node pair. A distributed algorithm is also provided with analogical performance. Extensive simulation shows that our distributed algorithm achieves significantly than the latest solution in research direction.",
An optimization-based approach for connecting partitioned mobile sensor/Actuator Networks,"Wireless Sensor and Actuator Networks (WSANs) employ mobile nodes in addition to stationary tiny sensors. Similarly, mobile sensors make it possible to have the flexibility of mobility in mobile sensor network (MSN) applications. Mobility can be exploited to connect partitioned WSANs and MSNs due to large scale damages or deployment problems. However, since mobility consume significant energy and it can be limited due to terrain constraints, the travel distance for the mobile nodes should be minimized in such a recovery effort. In this paper, we present a mathematical model which minimizes the total travel distance for connecting a given number of partitions. The idea is based on network flows and the problem is modeled as a mixed integer nonlinear program. The nonlinear terms in the model are linearized using a polygon approximation for computational efficiency. We evaluated the performance of the proposed approach in terms of total distance as well as the time to reconnect the partitions. The results show that our approach outperforms the heuristic approach in terms of total distance and delay and reveals various trade-offs involved in connecting multiple partitions.","Actuators,
Delay,
Robot sensing systems,
Mobile communication,
Wireless sensor networks,
Mobile computing,
Approximation methods"
Advances in High-Voltage Modulators for Applications in Pulsed Power and Plasma-Based Ion Implantation,"Modern pulsed power technology has its roots in the late 1950s and early 1960s, and it was driven overwhelmingly by applications in national defense carried out by several countries, especially the U.S., U.K., Russia, and China. The following decades, particularly the early 1990s, witnessed an increased interest in compact systems with pulse repetition rate that could be used in nondefense applications such as treatment of material surfaces by plasma and beam interactions, treatment of pollutants, food sterilization, medical applications, etc. This spawned a new generation of pulsed power components (solid-state switches) that led to completely solid-state modulators. This paper describes how the pulsed power technology used originally in beam sources and cathodic arcs has converged to produce power sources for plasma-based ion implantation (PBII) and related technologies. The present state of the art is reviewed, and prospects for future advances are described, especially for PBII.",
Computing the Effects of Operator Attention Allocation in Human Control of Multiple Robots,"In time-critical systems in which a human operator supervises multiple semiautomated tasks, failure of the operator to focus attention on high-priority tasks in a timely manner can lower the effectiveness of the system and potentially result in catastrophic consequences. These systems must integrate computer-based technologies that help the human operator place attention on the right tasks at the right times to be successful. One way to assist the operator in this process is to compute where the operator's attention should be focused and then use this computation to influence the operator's behavior. In this paper, we analyze the ability of a particular modeling method to make such computations for effective attention allocation in human-multiple-robot systems. Our results demonstrate that it is not sufficient to simply compute and dictate how operators should allocate their attention. Rather, in stochastic domains, where small changes in either the endogenous or exogenous environment can dramatically affect model fidelity, model predictions should guide rather than dictate operator attentional resources so that operators can effectively exercise their judgment and experience.","Computational modeling,
Resource management,
Buildings,
Humans,
Visualization,
Robot sensing systems"
Transition-Code Based Linearity Test Method for Pipelined ADCs With Digital Error Correction,"A transition-code based method is proposed to reduce the linearity testing time of pipelined analog-to-digital converters (ADCs). By employing specific architecture-dependent rules, only a few specific transition codes need to be measured to accomplish the accurate linearity test of a pipelined ADC. In addition, a simple digital Design-for-Test (DfT) circuit is proposed to help correctly detect transition codes corresponding to each pipelined stage. With the help of the DfT circuit, the proposed method can be applied for pipelined ADCs with digital error correction (DEC). Experimental results of a practical chip show that the proposed method can achieve high test accuracy for a 12-bit 1.5-bit/stage pipelined ADC with different nonlinearities by measuring only 9.3% of the total measured samples of the conventional histogram based method.",
A Hybrid Multiagent Framework With Q-Learning for Power Grid Systems Restoration,"This paper presents a hybrid multiagent framework with a Q-learning algorithm to support rapid restoration of power grid systems following catastrophic disturbances involving loss of generators. This framework integrates the advantages of both centralized and decentralized architectures to achieve accurate decision making and quick responses when potential cascading failures are detected in power systems. By using this hybrid framework, which does not rely on a centralized controller, the single point of failure in power grid systems can be avoided. Further, the use of the Q-learning algorithm developed in conjunction with the restorative framework can help the agents to make accurate decisions to protect against cascading failures in a timely manner without requiring a global reward signal. Simulation results demonstrate the effectiveness of the proposed approach in comparison with the typical centralized and decentralized approaches based on several evaluation attributes.",
Prostate Segmentation in HIFU Therapy,"Prostate segmentation in 3-D transrectal ultrasound images is an important step in the definition of the intra-operative planning of high intensity focused ultrasound (HIFU) therapy. This paper presents two main approaches for the semi-automatic methods based on discrete dynamic contour and optimal surface detection. They operate in 3-D and require a minimal user interaction. They are considered both alone or sequentially combined, with and without postregularization, and applied on anisotropic and isotropic volumes. Their performance, using different metrics, has been evaluated on a set of 28 3-D images by comparison with two expert delineations. For the most efficient algorithm, the symmetric average surface distance was found to be 0.77 mm.","Ultrasonic imaging,
Three dimensional displays,
Image segmentation,
Probes,
Shape,
Image edge detection,
Cost function"
A Low Complexity Sign Detection and Text Localization Method for Mobile Applications,"We propose a low complexity method for sign detection and text localization in natural images. This method is designed for mobile applications (e.g., unmanned or handheld devices) in which computational and energy resources are limited. No prior assumption is made regarding the text size, font, language, or character set. However, the text is assumed to be located on a homogeneous background using a contrasting color. We have deployed our method on a Nokia N800 cellular phone as part of a system for automatic detection and translation of outdoor signs. This handheld device is equipped with a 0.3-megapixel camera capable of acquiring images of outdoor signs that typically contain enough details for the sign to be readable by a human viewer. Our experiments show that the text of these images can be accurately localized within the device in a fraction of a second.","Videos,
Feature extraction,
Image segmentation,
Image color analysis,
Image edge detection,
Complexity theory,
Optical character recognition software"
Loading Balance of Distribution Feeders With Loop Power Controllers Considering Photovoltaic Generation,"For the operation of distribution systems, loading balance of distribution feeders is important for reducing power loss and mitigating power flow overloading. In this paper, a loop power controller (LPC) is applied for the control of real power and reactive power flows by adjusting voltage ratio and phase shift so that the loading balance of distribution feeders can be obtained. To incorporate photovoltaic (PV) power generation in feeder loading balance, a Taipower distribution feeder with large PV installation is selected for computer simulation. Daily loading unbalance is determined by analyzing PV power generation recorded by the SCADA system and by constructing daily power load profiles based on distribution automation system (DAS) data. The load transfer required to achieve loading balance and the line impedance of distribution feeders are used to derive the voltage ratio and phase shift of the LPC. Computer simulations indicated that loading balance can be achieved in distribution feeders with large PV system installation by using loop power controllers according to the variation of solar energy and power loading of study feeders. The system power loss reduction resulting from feeder loading balance by LPC is also investigated in this paper.","Loading,
Reactive power,
Power generation,
Load modeling,
Integrated circuit modeling,
Voltage control,
Circuit faults"
High-Performance Voltage Regulation of Current Source Inverters,"Current source inverters (CSI) offer advantages of voltage boost, short-circuit protection, reduced electromagnetic interference, and direct regeneration. While CSI control strategies are less developed than for voltage source inverters (VSI), the topologies are functional duals and have much in common in a control sense. In particular, since CSI voltage regulation is the dual of VSI current regulation, current regulation control strategies for a VSI can be readily implemented as equivalent voltage control strategies for a CSI. This paper shows how a high-performance proportional-integral stationary frame and P+Resonant CSI voltage regulator can be analytically designed and optimized, while in particular taking into account the second-order response of a CSI filter/load combination.","Voltage control,
Delay,
Phase modulation,
Resonant frequency,
Gain,
Switches"
A unified model for data and constraint repair,"Integrity constraints play an important role in data design. However, in an operational database, they may not be enforced for many reasons. Hence, over time, data may become inconsistent with respect to the constraints. To manage this, several approaches have proposed techniques to repair the data, by finding minimal or lowest cost changes to the data that make it consistent with the constraints. Such techniques are appropriate for the old world where data changes, but schemas and their constraints remain fixed. In many modern applications however, constraints may evolve over time as application or business rules change, as data is integrated with new data sources, or as the underlying semantics of the data evolves. In such settings, when an inconsistency occurs, it is no longer clear if there is an error in the data (and the data should be repaired), or if the constraints have evolved (and the constraints should be repaired). In this work, we present a novel unified cost model that allows data and constraint repairs to be compared on an equal footing. We consider repairs over a database that is inconsistent with respect to a set of rules, modeled as functional dependencies (FDs). FDs are the most common type of constraint, and are known to play an important role in maintaining data quality. We evaluate the quality and scalability of our repair algorithms over synthetic data and present a qualitative case study using a well-known real dataset. The results show that our repair algorithms not only scale well for large datasets, but are able to accurately capture and correct inconsistencies, and accurately decide when a data repair versus a constraint repair is best.",
Bayesian deblurring with integrated noise estimation,"Conventional non-blind image deblurring algorithms involve natural image priors and maximum a-posteriori (MAP) estimation. As a consequence of MAP estimation, separate pre-processing steps such as noise estimation and training of the regularization parameter are necessary to avoid user interaction. Moreover, MAP estimates involving standard natural image priors have been found lacking in terms of restoration performance. To address these issues we introduce an integrated Bayesian framework that unifies non-blind deblurring and noise estimation, thus freeing the user of tediously pre-determining a noise level. A sampling-based technique allows to integrate out the unknown noise level and to perform deblurring using the Bayesian minimum mean squared error estimate (MMSE), which requires no regularization parameter and yields higher performance than MAP estimates when combined with a learned high-order image prior. A quantitative evaluation demonstrates state-of-the-art results for both non-blind deblurring and noise estimation.","Noise,
Estimation,
Noise level,
Image restoration,
Kernel,
Bayesian methods,
Noise reduction"
Assessing network vulnerability under probabilistic region failure model,"The mission critical network infrastructures are facing potential large region threats, both intentional (like EMP attack, bomb explosion) and natural (like earthquake, flooding). The available research on region failure related vulnerability studies generally adopt a kind of simple “deterministic” region failure models, which can not capture some important features of real region failure scenarios, where a network component in the region only fails with certain probability, and more importantly, such failure probability tends to vary with both its dimension and its distance to failure center. In this paper, we provide a more general “probabilistic” region failure model to capture the key features of a region failure and apply it for the network vulnerability assessment. To facilitate such assessment, we adopt a grid partition-based scheme to estimate various statistical network metrics under a random region failure. A theoretical framework is also established to determine a suitable grid partition such that a specified estimation error requirement is satisfied. The grid partition technique is also useful for identifying the vulnerable zones of a network, which can guide network designers to initiate proper network protection against such failures. The work in this paper helps us more deeply understand the network vulnerability behavior under region failure and facilitates the design and maintenance of future highly survivable mission critical networks.","Measurement,
Estimation,
Routing,
Probabilistic logic,
Joining processes,
Zinc,
Capacity planning"
Remote labs as learning services in the educational arena,"Technology-enhanced learning is not just interacting with learning objects. Physical labs are another useful resource in education, especially for engineering and science education. They are confined to the physical location they are bound to. It is obviously interesting for any learning process to be able to open up this access from remote locations in the same effective way as learning objects are accessed through a Learning Management System, taking advantage of the provided services, such as authentication, group building, etc.","Least squares approximation,
Computer architecture,
Software,
Instruments,
Service oriented architecture,
Laboratories,
Engineering education"
OpenID authentication as a service in OpenStack,"The evolution of cloud computing is driving the next generation of internet services. OpenStack is one of the largest open-source cloud computing middleware development communities. Currently, OpenStack supports platform specific signatures and tokens for user authentication. In this paper, we aim to introduce a cloud platform independent, flexible, and decentralized authentication mechanism, using OpenID as an open-source authentication mechanism in OpenStack. OpenID allows a decentralized framework for user authentication. It has its own advantages for web services, which include improvements in usability and seamless Single-Sign-On experience for the users. This paper presents the OpenlD-Authentication-as-a-Service APIs in OpenStack for front-end GUI servers, and performs the authentication in the back-end at a single Policy Decision Point (PDP). Our implementation allows users to use their OpenID Identifiers from standard OpenTD providers and log into the Dashboard/Django-Nova graphical interface of OpenStack.","Authentication,
Servers,
Graphical user interfaces,
Cloud computing,
Computer architecture,
Usability"
An energy-efficient routing protocol for UWSNs using physical distance and residual energy,"In Underwater Wireless Sensor Networks (UWSNs), developing an energy efficient routing protocol is a challenge due to the peculiar characteristics of UWSNs. In this paper, we therefore propose an energy-efficient routing protocol, called ERP2R (Energy-efficient Routing Protocol based on Physical distance and Residual energy). ERP2R is based on a novel idea of utilizing the physical distances of the sensor nodes towards the sink node. ERP2R also takes into account the residual energy of the sensor nodes in order to extend the network life-time. Sensor nodes make a local decision of packet forwarding according to their physical distance and the residual energy information. Using the ns-2 simulator, we proved that the ERP2R protocol performs better than a representative protocol (i.e. DBR) in terms of energy efficiency, end-to-end delay and network lifetime.",
Node geometry and broadband jamming in noncooperative relay networks under received power constraint,This paper presents node geometry and broadband jamming in noncooperative wireless relay networks under the received power constraint. Diagonal relay amplifying matrices based on minimum mean square error (MMSE) criteria corresponding to node geometry and broadband jamming in wireless networks under the received power constraint are derived. All relay nodes are assumed not to communicate with their received signals for no cooperation. N relay nodes and one-source-one-destination node pair for amplify-and-forward (AF) strategy are employed. Bit error rate of the wireless relay network using the derived diagonal relay amplifying matrices is presented.,
Software aging issues on the eucalyptus cloud computing infrastructure,Demands on software reliability and availability have increased due to the nature of present day applications. Cloud computing systems fundamentally provide access to large pools of data and computational resources through a variety of interfaces similarly to existing grid and HPC resource management and programming systems. This work investigates the software aging effects on the Eucalyptus cloud computing infrastructure considering workloads composed of provisioning different types of virtual machines.,"Aging,
Cloud computing,
Process control,
Monitoring,
Memory management,
Linux"
Productivity Improvement From Using Machine Buffers in Dual-Gripper Cluster Tools,"Cluster tools (also referred to as robotic cells) are extensively used in semiconductor wafer fabrication. We consider the problem of scheduling operations in an m -machine cluster tool that produces identical parts (wafers). Each machine is equipped with a unit-capacity input buffer and a unit-capacity output buffer. The machines and buffers are served by a dual-gripper robot. Each wafer is processed on each of the m machines, and the objective is to find a cyclic sequence of robot moves that minimizes the long-run average time to produce a part or, equivalently, maximizes the throughput. We first obtain a tight upper bound on the optimal throughput and then use this bound to obtain an asymptotically optimal sequence under conditions that are common in practice. Next, we quantify the improvement in productivity that can be realized from the use of unit-capacity input and output buffers at the machines. Finally, we illustrate our analysis on cluster tools with realistic parameters, based on our work with a Dallas-based semiconductor equipment manufacturer.","Productivity,
Semiconductor device manufacture,
Service robots,
Throughput,
Manufacturing processes,
Manufacturing industries,
Chemical vapor deposition,
Planarization,
Fabrication,
Job shop scheduling"
Video Inpainting on Digitized Vintage Films via Maintaining Spatiotemporal Continuity,"Video inpainting is an important video enhancement technique used to facilitate the repair or editing of digital videos. It has been employed worldwide to transform cultural artifacts such as vintage videos/films into digital formats. However, the quality of such videos is usually very poor and often contain unstable luminance and damaged content. In this paper, we propose a video inpainting algorithm for repairing damaged content in digitized vintage films, focusing on maintaining good spatiotemporal continuity. The proposed algorithm utilizes two key techniques. Motion completion recovers missing motion information in damaged areas to maintain good temporal continuity. Frame completion repairs damaged frames to produce a visually pleasing video with good spatial continuity and stabilized luminance. We demonstrate the efficacy of the algorithm on different types of video clips.","Motion estimation,
Films,
Maintenance engineering,
Video sequences,
Algorithm design and analysis,
Visualization,
Spatiotemporal phenomena"
The Impact of Multiple Protein Sequence Alignment on Phylogenetic Estimation,"Multiple sequence alignment is typically the first step in estimating phylogenetic trees, with the assumption being that as alignments improve, so will phylogenetic reconstructions. Over the last decade or so, new multiple sequence alignment methods have been developed to improve comparative analyses of protein structure, but these new methods have not been typically used in phylogenetic analyses. In this paper, we report on a simulation study that we performed to evaluate the consequences of using these new multiple sequence alignment methods in terms of the resultant phylogenetic reconstruction. We find that while alignment accuracy is positively correlated with phylogenetic accuracy, the amount of improvement in phylogenetic estimation that results from an improved alignment can range from quite small to substantial. We observe that phylogenetic accuracy is most highly correlated with alignment accuracy when sequences are most difficult to align, and that variation in alignment accuracy can have little impact on phylogenetic accuracy when alignment error rates are generally low. We discuss these observations and implications for future work.","Protein sequence,
Phylogeny,
Sequences,
Evolution (biology),
Genetics,
Biology computing,
Muscles,
Protein engineering,
Performance evaluation,
Error analysis"
Experimental evidence of a template aging effect in iris biometrics,"It has been widely accepted that iris biometric systems are not subject to a template aging effect. Baker et al. [1] recently presented the first published evidence of a template aging effect, using images acquired from 2004 through 2008 with an LG 2200 iris imaging system, representing a total of 13 subjects (26 irises). We report on a template aging study involving two different iris recognition algorithms, a larger number of subjects (43), a more modern imaging system (LG 4000), and over a shorter time-lapse (2 years). We also investigate the degree to which the template aging effect may be related to pupil dilation and/or contact lenses. We find evidence of a template aging effect, resulting in an increase in match hamming distance and false reject rate.","Iris recognition,
Aging,
High definition video,
Hamming distance,
Lenses,
Software"
Picbreeder: A Case Study in Collaborative Evolutionary Exploration of Design Space,"For domains in which fitness is subjective or difficult to express formally, interactive evolutionary computation (IEC) is a natural choice. It is possible that a collaborative process combining feedback from multiple users can improve the quality and quantity of generated artifacts. Picbreeder, a large-scale online experiment in collaborative interactive evolution (CIE), explores this potential. Picbreeder is an online community in which users can evolve and share images, and most importantly, continue evolving others' images. Through this process of branching from other images, and through continually increasing image complexity made possible by the underlying neuroevolution of augmenting topologies (NEAT) algorithm, evolved images proliferate unlike in any other current IEC system. This paper discusses not only the strengths of the Picbreeder approach, but its challenges and shortcomings as well, in the hope that lessons learned will inform the design of future CIE systems.",
Towards Systematic Design of Enterprise Networks,"Enterprise networks are important, with size and complexity even surpassing carrier networks. Yet, the design of enterprise networks remains ad hoc and poorly understood. In this paper, we show how a systematic design approach can handle two key areas of enterprise design: virtual local area networks (VLANs) and reachability control. We focus on these tasks given their complexity, prevalence, and time-consuming nature. Our contributions are threefold. First, we show how these design tasks may be formulated in terms of network-wide performance, security, and resilience requirements. Our formulations capture the correctness and feasibility constraints on the design, and they model each task as one of optimizing desired criteria subject to the constraints. The optimization criteria may further be customized to meet operator-preferred design strategies. Second, we develop a set of algorithms to solve the problems that we formulate. Third, we demonstrate the feasibility and value of our systematic design approach through validation on a large-scale campus network with hundreds of routers and VLANs.","Bridges,
Security,
Routing,
Systematics,
Complexity theory,
Topology,
Network topology"
A Physical/Virtual Carrier-Sense-Based Power Control MAC Protocol for Collision Avoidance in Wireless Ad Hoc Networks,"A kind of hidden terminal problem, called the POINT problem, which is caused by the expansion of the interference range of the receiver due to the controlled transmission power of the sender, is deemed a notorious problem in wireless ad hoc networks. This paper utilizes physical and virtual carrier-sensing schemes to avoid the POINT problem. We analyze the relationships among the transmission range, the carrier-sensing range, and the interference range in case power control is adopted, and based on the analyzed results, we propose four mechanisms to prevent the POINT problem from occurring in wireless ad hoc networks. This paper further analyzes the superiority of each mechanism under certain situations and proposes an adaptive range-based power control (ARPC) MAC protocol to make use of the advantages of the four mechanisms to avoid the POINT problem from happening. The proposed protocol cannot only prevent collisions caused by the POINT problem, but it can also reduce the energy consumption of STAs. Simulation results also verify the advantages of the proposed protocol.",
Hard-real-time scheduling of data-dependent tasks in embedded streaming applications,"Most of the hard-real-time scheduling theory for multiprocessor systems assumes independent periodic or sporadic tasks. Such a simple task model is not directly applicable to modern embedded streaming applications. This is because a modern streaming application is typically modeled as a directed graph where nodes represent actors (i.e. tasks) and edges represent data-dependencies. The actors in such graphs have data-dependency constraints and do not necessarily conform to the periodic or sporadic task models. Therefore, in this paper we investigate the applicability of hard-real-time scheduling theory for periodic tasks to streaming applications modeled as acyclic Cyclo-Static Dataflow (CSDF) graphs. In such graphs, the actors are data-dependent, however, we analytically prove that they (i.e. the actors) can be scheduled as implicit-deadline periodic tasks. As a result, a variety of hard-real-time scheduling algorithms for periodic tasks can be applied to schedule such applications with a certain guaranteed throughput. We compare the throughput resulting from such scheduling approach to the maximum achievable throughput of an application for a set of 19 real streaming applications. We find that in more than 80% of the cases, the throughput resulting from our approach is equal to the maximum achievable throughput.","Schedules,
Program processors,
Processor scheduling,
Scheduling,
Vectors,
Equations,
Silicon"
An automatic framework for extracting and classifying near-miss clone genealogies,"Extracting code clone genealogies across multiple versions of a program and classifying them according to their change patterns underlies the study of code clone evolution. While there are a few studies in the area, the approaches do not handle near-miss clones well and the associated tools are often computationally expensive. To address these limitations, we present a framework for automatically extracting both exact and near-miss clone genealogies across multiple versions of a program and for identifying their change patterns using a few key similarity factors. We have developed a prototype clone genealogy extractor, applied it to three open source projects including the Linux Kernel, and evaluated its accuracy in terms of precision and recall. Our experience shows that the prototype is scalable, adaptable to different clone detection tools, and can automatically identify evolution patterns of both exact and near-miss clones by constructing their genealogies.","Cloning,
Software systems,
Prototypes,
Accuracy,
Complexity theory,
Measurement,
History"
User Customizable Logic Paper (UCLP) With Sea-Of Transmission-Gates (SOTG) of 2-V Organic CMOS and Ink-Jet Printed Interconnects,"In this paper we present User Customizable Logic Paper (UCLP) with a Sea-of Transmission-Gates (SOTG) of 2-V organic CMOS transistors. This can enable users to fabricate custom integrated circuits, by printing 200 wide interconnects with at-home ink-jet printers for the prototyping of large-area electronics and educational purposes. The SOTG reduces the area of the circuits in UCLP by between 11% and 85% compared with a conventional gate array architecture.","Computer architecture,
Microprocessors,
Integrated circuit interconnections,
Transistors,
Ink jet printing,
Logic gates,
Resistance"
Low-Complexity Soft-Decision Feedback Turbo Equalization for MIMO Systems With Multilevel Modulations,"Many communication systems today encounter the problem of data transmission over a channel with intersymbol interference (ISI). The purpose of this paper is to develop a low-complexity iterative soft-decision feedback equalization (SDFE) receiver for severe frequency-selective ISI channels in multiple-input-multiple-output (MIMO) communication systems. The proposed SDFE algorithm offers a novel approach to combat error propagation. In addition, its computational complexity only linearly grows with the number of equalizer coefficients, compared with the quadratic complexity of minimum mean square error (MMSE)-based linear turbo equalizer with time-varying coefficients. The performance of the proposed detection scheme is verified through simulations using different signal constellations. In addition, convergence properties of the proposed SDFE algorithm are also analyzed using an extrinsic information transfer (EXIT) chart and verified by simulations in a severe ISI channel. Simulation results show that our proposed algorithm has significant improvement over the Approximate MMSE linear turbo equalizer proposed by Tüchler et al. Moreover, we show that the performance of the proposed equalization scheme significantly improves when higher order constellations are used for digital modulation.","Equalizers,
MIMO,
Receivers,
Equations,
Mathematical model,
Modulation,
Decoding"
Component-Based Localization in Sparse Wireless Networks,"Localization is crucial for wireless ad hoc and sensor networks. As the distance-measurement ranges are often less than the communication ranges for many ranging systems, most communication-dense wireless networks are localization-sparse. Consequently, existing algorithms fail to provide accurate localization supports. In order to address this issue, by introducing the concept of component, we group nodes into components so that nodes are able to better share ranging and anchor knowledge. Operating on the granularity of components, our design, CALL, relaxes two essential restrictions in localization: the node ordering and the anchor distribution. Compared to previous designs, CALL is proven to be able to locate the same number of nodes using the least information. We evaluate the effectiveness of CALL through extensive simulations. The results show that CALL locates 90% nodes in a network with average degree 7.5 and 5% anchors, which outperforms the state-of-the-art design Sweeps by about 40%.","Distance measurement,
Algorithm design and analysis,
Joining processes,
Merging,
Estimation,
Wireless networks,
Ad hoc networks"
Product Constructions for Perfect Lee Codes,"A well-known conjecture of Golomb and Welch is that the only nontrivial perfect codes in the Lee and Manhattan metrics have length two or minimum distance three. This problem and related topics were subject for extensive research in the last 40 years. In this paper, two product constructions for perfect Lee codes and diameter perfect Lee codes are presented. These constructions yield a large number of nonlinear perfect codes and nonlinear diameter perfect codes in the Lee and Manhattan metrics. A short survey and other related problems on perfect codes in the Lee and Manhattan metrics are also discussed.","Lattices,
Linear code,
Hamming distance"
A new reversible design of BCD adder,"Reversible logic is one of the emerging technologies having promising applications in quantum computing. In this work, we present new design of the reversible BCD adder that has been primarily optimized for the number of ancilla input bits and the number of garbage outputs. The number of ancilla input bits and the garbage outputs is primarily considered as an optimization criteria as it is extremely difficult to realize a quantum computer with many qubits. As the optimization of ancilla input bits and the garbage outputs may degrade the design in terms of the quantum cost and the delay, thus the quantum cost and the delay parameters are also considered for optimization with primary focus towards the optimization of the number of ancilla input bits and the garbage outputs. Firstly, we propose a new design of the reversible ripple carry adder having the input carry Co and is designed with no ancilla input bits. The proposed reversible ripple carry adder design with no ancilla input bits has less quantum cost and the logic depth (delay) compared to its existing counterparts. The existing reversible Peres gate and a new reversible gate called the TR gate is efficiently utilized to improve the quantum cost and the delay of the reversible ripple carry adder. The improved quantum design of the TR gate is also illustrated. Finally, the reversible design of the BCD adder is presented which is based on a 4 bit reversible binary adder to add the BCD number, and finally the conversion of the binary result to the BCD format using a reversible binary to BCD converter.","Logic gates,
Adders,
Delay,
Quantum computing,
Bismuth,
Optimization,
Converters"
Efficient Multi-Reference Frame Selection Algorithm for Hierarchical B Pictures in Multiview Video Coding,"Multiple reference frame prediction technology is adopted in Multiview Video Coding (MVC) to explore temporal and inter-view redundancies of multiview videos, resulting in extremely high encoding complexity by searching the best reference frame indices and the best reference directions for each macroblock (MB). In order to reduce MVC coding computations while keeping the coding efficiency and thus to advance MVC in real-time multimedia broadcasting applications, we propose a Fast Multi-reference Frame Selection Algorithm (FMFSA) for hierarchical B picture prediction structure in this paper. Due to high spatial correlations within a MB, there is a high probability for smaller MB partition modes selecting the same reference frame and direction as B16 16 does. Therefore, the reference information of latter checked MB partition modes can be directly set according to the reference information of previous examined mode. Experimental results on MVC show that the proposed FMFSA can achieve 68.34%~79.01% total encoding time reduction while the average bit rate increase and peak signal-to-noise ratio degradation are within 0.54% and 0.04 dB, respectively for test multiview sequences with various motion properties and camera arrangements.","Encoding,
Complexity theory,
Probability,
Video coding,
Video sequences,
Correlation,
Statistical analysis"
Multi-Relay Selection Design and Analysis for Multi-Stream Cooperative Communications,"In this paper, we consider the problem of multi-relay selection for multi-stream cooperative MIMO systems with M relay nodes. Traditionally, relay selection approaches are primarily focused on selecting one relay node to improve the transmission reliability given a single-antenna destination node. As such, in the cooperative phase whereby both the source and the selected relay nodes transmit to the destination node, it is only feasible to exploit cooperative spatial diversity (for example by means of distributed space time coding). For wireless systems with a multi-antenna destination node, in the cooperative phase it is possible to opportunistically transmit multiple data streams to the destination node by utilizing multiple relay nodes. Therefore, we propose a low overhead multi-relay selection protocol to support multi-stream cooperative communications. In addition, we derive the asymptotic performance results at high SNR for the proposed scheme and discuss the diversity-multiplexing tradeoff as well as the throughput-reliability tradeoff. From these results, we show that the proposed multi-stream cooperative communication scheme achieves lower outage probability compared to existing baseline schemes.","Relays,
Protocols,
Fading,
Maximum likelihood decoding,
Cooperative systems,
Encoding"
A Coordinate Transformation-Based Broadband Flat Lens via Microstrip Array,"A conventional convex lens is compressed into a flat one based on a so-called discrete coordinate transformation technique. While maintaining a good performance of the original lens, such a transformed flat lens only requires a few blocks of isotropic dielectrics. Physical realization via multiple transmission lines is then demonstrated, and it shows an alternative approach to achieve the desired spatially varying dielectric constant across the lens aperture. The full-wave simulation shows that the proposed microstrip array mimics the original convex lens nicely and can function well over a broad frequency band while possessing the merits of a flat profile and small volume.","Lenses,
Microstrip,
Arrays,
Microstrip antenna arrays,
Permittivity,
Electromagnetics,
Broadband antennas"
Multi-level inference by relaxed dual decomposition for human pose segmentation,"Combining information from the higher level and the lower level has long been recognized as an essential component in holistic image understanding. However, an efficient inference method for multi-level models remains an open problem. Moreover, modeling the complex relations within real world images often gives rise to energy terms that couple many variables in arbitrary ways. They make the inference problem even harder. In this paper, we construct an energy function over the pose of the human body and pixel-wise foreground / background segmentation. The energy function incorporates terms both on the higher level, which models the human poses, and the lower level, which models the pixels. It also contains an intractable term that couples all body parts. We show how to optimize this energy in a principled way by relaxed dual decomposition, which proceeds by maximizing a concave lower bound on the energy function. Empirically, we show that our approach improves the state-of-the-art performance of human pose estimation on the Ramanan benchmark dataset.","Joints,
Image segmentation,
Computational modeling,
Estimation,
Humans,
Minimization,
Torso"
Ranges of human mobility in Los Angeles and New York,"The advent of ubiquitous, mobile, personal devices creates an unprecedented opportunity to improve our understanding of human movement. In this work, we study human mobility in Los Angeles and New York by analyzing anonymous records of approximate locations of cell phones belonging to residents of those cities. We examine two data sets gathered six months apart, each representing hundreds of thousands of people, containing hundreds of millions of location events, and spanning two months of activity. We present, compare, and validate the daily range of travel for people in these populations. Our findings include that human mobility changes with the seasons: both Angelenos and New Yorkers travel less in the winter, with New Yorkers showing a greater decrease in mobility during the cold months. We also show that text messaging activity does not by itself accurately characterize daily range, whereas voice calling alone suffices. Finally, we show that our methodology is accurate by comparing our results to ground truth obtained from volunteers.","Cities and towns,
Springs,
Humans,
Cellular phones,
Poles and towers,
Business,
Aggregates"
The Power of Linear Estimators,"For a broad class of practically relevant distribution properties, which includes entropy and support size, nearly all of the proposed estimators have an especially simple form. Given a set of independent samples from a discrete distribution, these estimators tally the vector of summary statistics -- the number of domain elements seen once, twice, etc. in the sample -- and output the dot product between these summary statistics, and a fixed vector of coefficients. We term such estimators linear. This historical proclivity towards linear estimators is slightly perplexing, since, despite many efforts over nearly 60 years, all proposed such estimators have significantly sub optimal convergence, compared to the bounds shown in [26], [27]. Our main result, in some sense vindicating this insistence on linear estimators, is that for any property in this broad class, there exists a near-optimal linear estimator. Additionally, we give a practical and polynomial-time algorithm for constructing such estimators for any given parameters. While this result does not yield explicit bounds on the sample complexities of these estimation tasks, we leverage the insights provided by this result to give explicit constructions of near-optimal linear estimators for three properties: entropy, L1 distance to uniformity, and for pairs of distributions, L1 distance. Our entropy estimator, when given O(n/∈log n) independent samples from a distribution of support at most n, will estimate the entropy of the distribution to within additive accuracy ∈, with probability of failure o(1/poly(n)). From the recent lower bounds given in [26], [27], this estimator is optimal, to constant factor, both in its dependence on n, and its dependence on ∈. In particular, the inverse-linear convergence rate of this estimator resolves the main open question of [26], [28], which left open the possibility that the error decreased only with the square root of the number of samples. Our distance to uniformity estimator, when given O(m/∈2 log m) independent samples from any distribution, returns an ∈-accurate estimate of the L1 distance to the uniform distribution of support m. This is constant-factor optimal, for constant ∈. Finally, our framework extends naturally to properties of pairs of distributions, including estimating the L1 distance and KL-divergence between pairs of distributions. We give an explicit linear estimator for estimating L1 distance to additive accuracy ∈ using O(n/∈2 log n) samples from each distribution, which is constant-factor optimal, for constant ∈. This is the first sub linear-sample estimator for this fundamental property.","Entropy,
Histograms,
Estimation,
Approximation methods,
Vectors,
Additives,
Accuracy"
A Boosted Co-Training Algorithm for Human Action Recognition,"This paper proposes a boosted co-training algorithm for human action recognition. To address the view-sufficiency and view-dependency issues in co-training, two new confidence measures, namely, inter-view confidence and intra-view confidence, are proposed. They are dynamically fused into a semi-supervised learning process. Mutual information is employed to quantify the inter-view uncertainty and measure the independence among respective views. Intra-view confidence is estimated from boosted hypotheses to measure the total data inconsistency of labeled data and unlabeled data. Given a small set of labeled videos and a large set of unlabeled videos, the proposed semi-supervised learning algorithm trains a classifier by maximizing the inter-view confidence and intra-view confidence, and dynamically incorporating unlabeled data into the labeled data set. To evaluate the proposed boosted co-training algorithm, eigen-action and information saliency feature vectors are employed as two input views. The KTH and Weizmann human action databases are used for experiments, average recognition accuracy of 93.2% and 99.6% are obtained, respectively.","Humans,
Videos,
Classification algorithms,
Training,
Feature extraction,
Mutual information,
Shape"
Joint Channel Estimation and Multiuser Detection for SDMA/OFDM Based on Dual Repeated Weighted Boosting Search,"A joint channel estimation and multiuser detection (JCEMUD) scheme is proposed for multiuser multiple-input-multiple-output (MIMO) space-division multiple-access/orthogonal frequency-division-multiplexing (SDMA/OFDM) systems. We design a dual repeated weighted boosting search (DRWBS) scheme for JCEMUD, which is capable of providing “soft” outputs, which are directly fed to the forward error correction (FEC) decoder. The proposed DRWBS-JCEMUD scheme iteratively estimates the channel impulse responses and detects the users' transmitted signals while exploiting the error correction capability of an FEC decoder to iteratively exchange information between the detector and the estimator. Furthermore, the proposed DRWBS-JCEMUD scheme is capable of providing the log-likelihood ratios of the coded bits at low computational complexity (comparable with the single-user scenario), which can directly be fed to the FEC decoder. The simulation results demonstrate that the proposed DRWBS-JCEMUD scheme is capable of attaining a mean square error performance close to that of the ideal scenario of the least-square channel estimator associated with 100% pilot overhead and narrows the discrepancy with respect to the optimal maximum-likelihood (ML) MUD associated with perfect channel knowledge. As an example, at Eb/N0 = 10 dB, a factor-of-0.756 complexity reduction was achieved at the cost of a 1-dB performance penalty, in comparison with the ML-MUD.","Channel estimation,
OFDM,
Multiaccess communication,
Multiuser detection,
Boosting,
Joints,
Forward error correction"
Resource allocation for security services in mobile cloud computing,"Mobile cloud is a machine-to-machine service model, where a mobile device can use the cloud for searching, data mining, and multimedia processing. To protect the processed data, security services, i.e., encryption, decryption, authentications, etc., are performed in the cloud. In general, we can classify cloud security services in two categories: Critical Security (CS) service and Normal Security (NS) service. CS service provides strong security protection such as using longer key size, strict security access policies, isolations for protecting data, and so on. The CS service usually occupies more cloud computing resources, however it generates more rewards to the cloud provider since the CS service users need to pay more for using the CS service. With the increase of the number of CS and NS service users, it is important to allocate the cloud resource to maximize the system rewards with the considerations of the cloud resource consumption and incomes generated from cloud users. To address this issue, we propose a Security Service Admission Model (SSAM) based on Semi-Markov Decision Process to model the system reward for the cloud provider. We, first, define system states by a tuple represented by the numbers of cloud users and their associated security service categories, and current event type (i.e., arrival or departure).We then derive the system steady-state probability and service request blocking probability by using the proposed SSAM. Numerical results show that the obtained theoretic probabilities are consistent with our simulation results.","Mobile communication,
Computational modeling,
Cloud computing,
Resource management,
Mobile handsets,
Authentication"
SOI-based integrated circuits for high-temperature power electronics applications,"The growing demand for hybrid electric vehicles (HEVs) has increased the need for high-temperature electronics that can operate at the extreme temperatures that exist under the hood. This paper presents a high-voltage, high-temperature SOI-based gate driver for SiC FET switches. The gate driver is designed and implemented on a 0.8-micron BCD on SOI process. This gate driver chip is intended to drive SiC power FETs for DC-DC converters and traction drives in HEVs. To this end, the gate driver IC has been successfully tested up to 200°C. Successful operation of the circuit at this temperature with minimal or no heat sink, and without liquid cooling, will help to achieve higher power-to-volume as well as power-to-weight ratios for the power electronics modules in HEVs.","Logic gates,
Driver circuits,
Regulators,
Voltage control,
Circuit faults,
Switches,
Capacitors"
Mosaic Decomposition: An Electronic Cleansing Method for Inhomogeneously Tagged Regions in Noncathartic CT Colonography,"Electronic cleansing (EC) is a method that segments fecal material tagged by an X-ray-opaque oral contrast agent in computed tomographic colonography (CTC) images, and effectively removes the material for digitally cleansing the colon. In this study, we developed a novel EC method, called mosaic decomposition (MD), for reduction of the artifacts due to incomplete cleansing of inhomogeneously tagged fecal material in CTC images, especially in noncathartic CTC images. In our approach, the entire colonic region, including the residual fecal regions, was first decomposed into a set of local homogeneous regions, called tiles, after application of a 3-D watershed transform to the CTC images. Each tile was then subjected to a single-class support vector machine (SVM) classifier for soft-tissue discrimination. The feature set of the soft-tissue SVM classifier was selected by a genetic algorithm (GA). A scalar index, called a soft-tissue likelihood, is formulated for differentiation of the soft-tissue tiles from those of other materials. Then, EC based on MD, called MD-cleansing, is performed by first initializing of the level-set front with the classified tagged regions; the front is then evolved by use of a speed function that was designed, based on the soft-tissue index, to reserve the submerged soft-tissue structures while suppressing the residual fecal regions. The performance of the MD-cleansing method was evaluated by use of a phantom and of clinical cases. In the phantom evaluation, our MD-cleansing was trained with the supine (prone) scan and tested on the prone (supine) scan, respectively. In both cases, the sensitivity and specificity of classification were 100%. The average cleansing ratio was 90.6%, and the soft-tissue preservation ratio was 97.6%. In the clinical evaluation, 10 noncathartic CTC cases (20 scans) were collected, and the ground truth of a total of 2095 tiles was established by manual assignment of a material class to each tile. Five cases were randomly selected for training GA/SVM, and the remaining five cases were used for testing. The overall sensitivity and specificity of the proposed classification scheme were 97.1% and 85.3%, respectively, and the accuracy was 94.6%. The area under the ROC curve (Az) was 0.96. Our results indicated that the use of MD-cleansing substantially improved the effectiveness of our EC method in the reduction of incomplete cleansing artifacts.","Tiles,
Fluids,
Nonhomogeneous media,
Computed tomography,
Colon,
Eigenvalues and eigenfunctions"
PFlow: Reconstructing People Flow Recycling Large-Scale Social Survey Data,Understanding people flow on a macroscopic scale requires reconstructing it from various forms of existing fragmentary spatiotemporal data. This article illustrates a process for reconstructing such data using existing person-trip survey data.,"Traffic control,
Spatiotemporal phenomena,
Intelligent transportation systems,
Behavioral science,
Urban areas,
Mobile radio mobility management"
Churn-Resilient Protocol for Massive Data Dissemination in P2P Networks,"Massive data dissemination is often disrupted by frequent join and departure or failure of client nodes in a peer-to-peer (P2P) network. We propose a new churn-resilient protocol (CRP) to assure alternating path and data proximity to accelerate the data dissemination process under network churn. The CRP enables the construction of proximity-aware P2P content delivery systems. We present new data dissemination algorithms using this proximity-aware overlay design. We simulated P2P networks up to 20,000 nodes to validate the claimed advantages. Specifically, we make four technical contributions: 1). The CRP scheme promotes proximity awareness, dynamic load balancing, and resilience to node failures and network anomalies. 2). The proximity-aware overlay network has a 28-50 percent speed gain in massive data dissemination, compared with the use of scope-flooding or epidemic tree schemes in unstructured P2P networks. 3). The CRP-enabled network requires only 1/3 of the control messages used in a large CAM-Chord network. 4) Even with 40 percent of node failures, the CRP network guarantees atomic broadcast of all data items. These results clearly demonstrate the scalability and robustness of CRP networks under churn conditions. The scheme appeals especially to web-scale applications in digital content delivery, network worm containment, and consumer relationship management over hundreds of datacenters in cloud computing services.","Peer to peer computing,
Protocols,
Delay,
Distributed databases,
Resilience,
IP networks,
Clocks"
Gradient-Based Threshold Adaptation for Energy Detector in Cognitive Radio Systems,"Cognitive Radio (CR) systems have been proposed to enable flexible use of the frequency spectrum in future generations of wireless networks. These are expected to detect spectrum bands that are not actively used by licensed (primary) users and provide unlicensed (secondary) users access to these bands. In this context it is important for the CR systems to promptly react to changes in the operating environment and to adapt to the changing patterns of spectrum use. This motivates the work presented in this paper, which studies adaptation of the detection threshold for energy-based spectrum sensing in dynamic scenarios under constraints imposed on the probabilities of missed detection and false alarm.","Sensors,
Heuristic algorithms,
Noise measurement,
Signal to noise ratio,
Numerical models,
Mathematical model"
Modeling and performance evaluation of an OpenFlow architecture,"The OpenFlow concept of flow-based forwarding and separation of the control plane from the data plane provides a new flexibility in network innovation. While initially used solely in the research domain, OpenFlow is now finding its way into commercial applications. However, this creates new challenges, as questions of OpenFlow scalability and performance have not yet been answered. This paper is a first step towards that goal. Based on measurements of switching times of current OpenFlow hardware, we derive a basic model for the forwarding speed and blocking probability of an OpenFlow switch combined with an OpenFlow controller and validate it using a simulation. This model can be used to estimate the packet sojourn time and the probability of lost packets in such a system and can give hints to developers and researchers on questions how an OpenFlow architecture will perform given certain parameters.","Switches,
Analytical models,
Load modeling,
Hardware,
Process control,
Delay"
A hierarchical security architecture for cyber-physical systems,"Security of control systems is becoming a pivotal concern in critical national infrastructures such as the power grid and nuclear plants. In this paper, we adopt a hierarchical viewpoint to these security issues, addressing security concerns at each level and emphasizing a holistic cross-layer philosophy for developing security solutions. We propose a bottom-up framework that establishes a model from the physical and control levels to the supervisory level, incorporating concerns from network and communication levels. We show that the game-theoretical approach can yield cross-layer security strategy solutions to the cyber-physical systems.","Security,
Control systems,
Physical layer,
Sensors,
Monitoring,
Computer architecture,
Maintenance engineering"
MAC scheduling for high throughput underwater acoustic networks,"Underwater acoustic networks (UWANs) have emerged as the primary tool to monitor and act upon the well-being of marine environment. However, the significantly slower propagation speed of acoustic signals, in contrast to RF signals, introduces the spatio-temporal uncertainty, which makes existing medium access control (MAC) solutions for terrestrial RF wireless networks unsuitable for UWANs. In this paper, we investigate transmission scheduling for time-based MAC protocols and design scheduling algorithms that take advantage of the long propagation delay of acoustic signals to facilitate concurrent transmissions and receptions of acoustic communications. Specifically, we specify the constraints that MAC protocols need to satisfy to avoid conflicts and model these constrains into a Mixed Integer Linear Programming model. We also design heuristics that compute conflict-free transmission schedules, and demonstrate via simulation that the heuristics significantly improve network throughput.","Schedules,
Propagation delay,
Throughput,
Acoustics,
Interference,
Receivers,
Media Access Protocol"
Who knows who - Inverting the Social Force Model for finding groups,Social groups based on friendship or family relations are very common phenomena in human crowds and a valuable cue for a crowd activity recognition system. In this paper we present an algorithm for automatic on-line inference of social groups from observed trajectories of individual people. The method is based on the Social Force Model (SFM) - widely used in crowd simulation applications - which specifies several attractive and repulsive forces influencing each individual relative to the other pedestrians and their environment. The main contribution of the paper is an algorithm for inference of the social groups (parameters of the SFM) based on analysis of the observed trajectories through attractive or repulsive forces which could lead to such behaviour. The proposed SFM-based method shows its clear advantage especially in more crowded scenarios where other state-of-the-art methods fail. The applicability of the algorithm is illustrated on an abandoned bag scenario.,"Force,
Trajectory,
Clustering algorithms,
Mathematical model,
Computational modeling,
Prediction algorithms,
Inference algorithms"
Improving source code search with natural language phrasal representations of method signatures,"As software continues to grow, locating code for maintenance tasks becomes increasingly difficult. Software search tools help developers find source code relevant to their maintenance tasks. One major challenge to successful search tools is locating relevant code when the user's query contains words with multiple meanings or words that occur frequently throughout the program. Traditional search techniques, which treat each word individually, are unable to distinguish relevant and irrelevant methods under these conditions. In this paper, we present a novel search technique that uses information such as the position of the query word and its semantic role to calculate relevance. Our evaluation shows that this approach is more consistently effective than three other state of the art search techniques.","Semantics,
Software,
Mathematical model,
Equations,
Information retrieval,
Head,
Natural languages"
Kernel selection in linear system identification part II: A classical perspective,"In this companion paper, the choice of kernels for estimating the impulse response of linear stable systems is considered from a classical, “frequentist”, point of view. The kernel determines the regularization matrix in a regularized least squares estimate of an FIR model. The quality is assessed from a mean square error (MSE) perspective, and measures and algorithms for optimizing the MSE are discussed. The ideas are tested on the same data bank as used in Part I of the companion papers. The resulting findings and conclusions in the two papers are very similar despite the different perspectives.","Finite impulse response filter,
Kernel,
Linear matrix inequalities,
Computational modeling,
Mean square error methods,
Noise,
Least squares approximation"
Noncooperative distributed MMSE relay schemes under jamming environment and node geometry in wireless relay networks,"The main contribution of this paper is the derivation of optimum relay amplifying matrices for noncooperative distributed wireless amplifying-and-forward relay networks. Channels connecting any two nodes are under fading, and either partial-band noise jamming or non-symmetrical node geometry. The minimum mean squared error criterion is used for the optimality. With the derived optimum relay amplifying matrices, the bit error rate is compared through simulation for various situations.","Relays,
Jamming,
Geometry,
Bit error rate,
Wireless communication,
Wireless sensor networks,
Broadband communication"
Effective Scheduling in Infrastructure-Based Cognitive Radio Networks,"In this paper, we investigate a joint scheduling and power control for an infrastructure-based cognitive radio network (CRN) in coexistence with a cellular primary radio network (PRN). The PRN uses a set of licensed nonoverlapping orthogonal frequency channels for transmission. This set of channels is also accessed in an opportunistic manner by a set of cognitive radio base stations (CR-BSs) to support secondary users (SUs). The problem is formulated to maximize the spectrum utilization of SUs without causing excessive interference to active primary users (PUs) of the PRN. In addition, all the serviced SUs must meet a certain Quality of Service (QoS), such as satisfying a predefined signal to interference noise ratio (SINR). A centralized solution for joint scheduling and power control is derived to make the global accessing decision for all unserved SUs. With the assumption that the knowledge of all subscribers is available, a coordinator of the CRN can use the joint scheduling and power control algorithm to maximize the spectrum utilization of serviced SUs by solving a mixed-integer linear programming (MILP) with an NP-hard complexity. To avoid the NP-hard complexity, we propose a suboptimal heuristic greedy algorithm that can be obtained at a much lower complexity based on the coloring interference graph among unserved SUs effected by serviced SUs and active PUs. Its superior performance over the existing algorithms is demonstrated through simulations.","Interference,
Power control,
Quality of service,
Cognitive radio,
Joints,
Scheduling,
Processor scheduling"
System-level application-aware dynamic power management in adaptive pipelined MPSoCs for multimedia,"System-level dynamic power management (DPM) schemes in Multiprocessor System on Chips (MPSoCs) exploit the idleness of processors to reduce the energy consumption by putting idle processors to low-power states. In the presence of multiple low-power states, the challenge is to predict the duration of the idle period with high accuracy so that the most beneficial power state can be selected for the idle processor. In this work, we propose a novel dynamic power management scheme for adaptive pipelined MPSoCs, suitable for multimedia applications. We leverage application knowledge in the form of future workload prediction to forecast the duration of idle periods. The predicted duration is then used to select an appropriate power state for the idle processor. We proposed five heuristics as part of the DPM and compared their effectiveness using an MPSoC implementation of the H.264 video encoder supporting HD720p at 30 fps. The results show that one of the application prediction based heuristic (MAMAPBH) predicted the most beneficial power states for idle processors with less than 3% error when compared to an optimal solution. In terms of energy savings, MAMAPBH was always within 1% of the energy savings of the optimal solution. When compared with a naive approach (where only one of the possible power states is used for all the idle processors), MAMAPBH achieved up to 40% more energy savings with only 0.5% degradation in throughput. These results signify the importance of leveraging application knowledge at system-level for dynamic power management schemes.","Multimedia communication,
History,
Prediction algorithms,
Energy consumption,
Motion estimation,
Streaming media,
Clocks"
A Low-Cost Electrochemical Biosensor for Rapid Bacterial Detection,"A three-electrode electrochemical biosensor has been developed using printed circuit boards for detecting bacterial contamination. This low-cost, small-size device consists of thin-film gold electrodes and is fabricated using photo-lithography paired with electro-deposition. Pathogen presence is deduced by detection of change in electrical impedance caused by binding of the pathogen to bio-receptors coated on the sensor surface. The biosensor has a total area of 3.2 cm and requires only 100 L of test sample for detection. The sensor geometry has been optimized using techniques from Design of Experiments, and the device can be operated using a small ac excitation potential of magnitude 5 mV. The sensor is tested on the common food-borne pathogen Salmonella typhimurium and is able detect bacterial concentrations of the order of 500 CFU/mL within 6 min. In this paper, the design and fabrication of the biosensor is detailed along with the experiments that validate its performance.","Electrodes,
Biosensors,
Pathogens,
Impedance,
Microorganisms,
Surface impedance,
Fabrication"
Comparing multilayer perceptron to Deep Belief Network Tandem features for robust ASR,"In this paper, we extend the work done on integrating multilayer perceptron (MLP) networks with HMM systems via the Tandem approach. In particular, we explore whether the use of Deep Belief Networks (DBN) adds any substantial gain over MLPs on the Aurora2 speech recognition task under mismatched noise conditions. Our findings suggest that DBNs outperform single layer MLPs under the clean condition, but the gains diminish as the noise level is increased. Furthermore, using MFCCs in conjunction with the posteriors from DBNs outperforms merely using single DBNs in low to moderate noise conditions. MFCCs, however, do not help for the high noise settings.","Training,
Mel frequency cepstral coefficient,
Speech recognition,
Noise measurement,
Accuracy,
Signal to noise ratio"
A clustering approach to improving test case prioritization: An industrial case study,"Regression testing is an important activity for controlling the quality of a software product, but it accounts for a large proportion of the costs of software. We believe that an understanding of the underlying relationships in data about software systems, including data correlations and patterns, could provide information that would help improve regression testing techniques. We conjecture that if test cases have common properties, then test cases within the same group may have similar fault detection ability. As an initial approach to investigating the relationships in massive data in software repositories, in this paper, we consider a clustering approach to help improve test case prioritization. We implemented new prioritization techniques that incorporate a clustering approach and utilize code coverage, code complexity, and history data on real faults. To assess our approach, we have designed and conducted empirical studies using an industrial software product, Microsoft Dynamics Ax, which contains real faults. Our results show that test case prioritization that utilizes a clustering approach can improve the effectiveness of test case prioritization techniques.","Testing,
Complexity theory,
History,
Fault detection,
Measurement,
Software systems"
A simple mathematical model for information rate of active transport molecular communication,"In molecular communication, gaps in the underlying theoretical and mathematical framework create numerous challenges. Currently, most researchers rely on simulations to study these systems. However, simulations can be time consuming and impractical. Moreover, due to the complexity and dependencies present in these systems, deriving a mathematical framework that can capture the essence of molecular communication systems is also challenging. In this work, we derive a simple mathematical model, based on some independence assumptions, to estimate the information rate of a molecular communication system employing active transport propagation. We show that the presented model estimates the simulated information rate closely for small communication time intervals. We also use the derived mathematical model to design and verify an optimal loading area that would maximize the information rate.","Mathematical model,
Loading,
Molecular communication,
Load modeling,
Information rates,
Receivers,
Strips"
Balancing Attended and Global Stimuli in Perceived Video Quality Assessment,"The visual attention mechanism plays a key role in the human perception system and it has a significant impact on our assessment of perceived video quality. In spite of receiving less attention from the viewers, unattended stimuli can still contribute to the understanding of the visual content. This paper proposes a quality model based on the late attention selection theory, assuming that the video quality is perceived via two mechanisms: global and local quality assessment. First we model several visual features influencing the visual attention in quality assessment scenarios to derive an attention map using appropriate fusion techniques. The global quality assessment as based on the assumption that viewers allocate their attention equally to the entire visual scene, is modeled by four carefully designed quality features. By employing these same quality features, the local quality model tuned by the attention map considers the degradations on the significantly attended stimuli. To generate the overall video quality score, global and local quality features are combined by a content adaptive linear fusion method and pooled over time, taking the temporal quality variation into consideration. The experimental results have been compared to results from appropriate eye tracking and video quality assessment experiments, demonstrating promising performance.","Visual system,
Quality assessment,
Computational modeling,
Degradation,
Image color analysis,
Human factors"
Exploiting Long-Term Channel Correlation in Limited Feedback SDMA Through Channel Phase Codebook,"Improving channel information quality at the base station (BS) is crucial for the optimization of frequency division duplexed (FDD) multi-antenna multiuser downlink systems with limited feedback. To this end, this paper proposes to estimate a particular representation of channel state information (CSI) at the BS through channel norm feedback and a newly developed channel phase codebook, where the long-term channel correlation is efficiently exploited to improve performance. In particular, the channel representation is decomposed into a gain-related part and a phase-related part, with each of them estimated separately. More specifically, the gain-related part is estimated from the channel norm and channel correlation matrix, while the phase-related part is determined using a channel phase codebook, constructed with the generalized Lloyd algorithm. Using the estimated channel representation, joint optimization of multiuser precoding and opportunistic scheduling is performed to obtain an SDMA transmit scheme. Computer simulation results confirm the advantage of the proposed scheme over state of the art limited feedback SDMA schemes under correlated channel environment.","Channel estimation,
Correlation,
Base stations,
Multiaccess communication,
Array signal processing,
Downlink,
Eigenvalues and eigenfunctions"
Embedded security for Internet of Things,"Internet of Things (IoT) consists of several tiny devices connected together to form a collaborative computing environment. IoT imposes peculiar constraints in terms of connectivity, computational power and energy budget, which make it significantly different from those contemplated by the canonical doctrine of security in distributed systems. In order to circumvent the problem of security in IoT domain, networks and devices need to be secured. In this paper, we consider the embedded device security only, assuming that network security is properly in place. It can be noticed that the existence of tiny computing devices that form ubiquity in IoT domain are very much vulnerable to different security attacks. In this work, we provide the requirements of embedded security, the solutions to resists different attacks and the technology for resisting temper proofing of the embedded devices by the concept of trusted computing. Our paper attempts to address the issue of security for data at rest. Addressing this issue is equivalent to addressing the security issue of the hardware platform. Our work also partially helps in addressing securing data in transit.","Security,
Embedded systems,
Smart phones,
Protocols,
Hardware,
Computer architecture"
On human analyst performance in assisted requirements tracing: Statistical analysis,"Assisted requirements tracing is a process in which a human analyst validates candidate traces produced by an automated requirements tracing method or tool. The assisted requirements tracing process splits the difference between the commonly applied time-consuming, tedious, and error-prone manual tracing and the automated requirements tracing procedures that are a focal point of academic studies. In fact, in software assurance scenarios, assisted requirements tracing is the only way in which tracing can be at least partially automated. In this paper, we present the results of an extensive 12 month study of assisted tracing, conducted using three different tracing processes at two different sites. We describe the information collected about each study participant and their work on the tracing task, and apply statistical analysis to study which factors have the largest effect on the quality of the final trace.","Accuracy,
Humans,
Manuals,
Educational institutions,
Software tools,
Statistical analysis"
A Geometric Method for Optimal Design of Color Filter Arrays,"A color filter array (CFA) used in a digital camera is a mosaic of spectrally selective filters, which allows only one color component to be sensed at each pixel. The missing two components of each pixel have to be estimated by methods known as demosaicking. The demosaicking algorithm and the CFA design are crucial for the quality of the output images. In this paper, we present a CFA design methodology in the frequency domain. The frequency structure, which is shown to be just the symbolic DFT of the CFA pattern (one period of the CFA), is introduced to represent images sampled with any rectangular CFAs in the frequency domain. Based on the frequency structure, the CFA design involves the solution of a constrained optimization problem that aims at minimizing the demosaicking error. To decrease the number of parameters and speed up the parameter searching, the optimization problem is reformulated as the selection of geometric points on the boundary of a convex polygon or the surface of a convex polyhedron. Using our methodology, several new CFA patterns are found, which outperform the currently commercialized and published ones. Experiments demonstrate the effectiveness of our CFA design methodology and the superiority of our new CFA patterns.","Image color analysis,
Frequency domain analysis,
Pixel,
Optimization,
Discrete Fourier transforms,
Design methodology,
Color"
A high-throughput routing metric for reliable multicast in multi-rate wireless mesh networks,"We propose a routing metric for enabling high-throughput reliable multicast in multi-rate wireless mesh networks. This new multicast routing metric, called expected multicast transmission time (EMTT), captures the combined effects of 1) MAC-layer retransmission-based reliability, 2) transmission rate diversity, 3) wireless broadcast advantage, and 4) link quality awareness. The EMTT of one-hop transmission of a multicast packet minimizes the amount of expected transmission time (including that required for retransmissions). This is achieved by allowing the sender to adapt its bit-rate for each ongoing transmission/retransmission, optimized exclusively for its next-hop receivers that have not yet received the multicast packet. We model the rate adaptation process as a Markov decision process (MDP) and derive an efficient procedure for computing EMTT from the theory of MDP. We present receiver-initiated algorithms and describe protocol implementation for the EMTT-based multicast routing problem. Numerical results are presented to demonstrate the accuracy of the proposed algorithms against optimal solutions to the multicast routing problem. Simulation experiments confirm that, in comparison with single-rate multicast, multi-rate multicast using the EMTT metric effectively reduces the overall multicast transmission time while yielding higher packet delivery ratio and lower end-to-end latency.","Routing,
Measurement,
Wireless communication,
Receivers,
Ad hoc networks,
Markov processes,
Computational modeling"
Prioritization of quality requirements: State of practice in eleven companies,"Requirements prioritization is recognized as an important but challenging activity in software product development. For a product to be successful, it is crucial to find the right balance among competing quality requirements. Although literature offers many methods for requirements prioritization, the research on prioritization of quality requirements is limited. This study identifies how quality requirements are prioritized in practice at 11 successful companies developing software intensive systems. We found that ad-hoc prioritization and priority grouping of requirements are the dominant methods for prioritizing quality requirements. The results also show that it is common to use customer input as criteria for prioritization but absence of any criteria was also common. The results suggests that quality requirements by default have a lower priority than functional requirements, and that they only get attention in the prioritizing process if decision-makers are dedicated to invest specific time and resources on QR prioritization. The results of this study may help future research on quality requirements to focus investigations on industry-relevant issues.","Companies,
Interviews,
Industries,
Ad hoc networks,
Instruments,
Planning,
Telecommunications"
Simultaneous self-calibration of a projector and a camera using structured light,"We propose a method for geometric calibration of an active vision system, composed of a projector and a camera, using structured light projection. Unlike existing methods of self-calibration for projector-camera systems, our method estimates the intrinsic parameters of both the projector and the camera as well as extrinsic parameters except a global scale without any calibration apparatus such as a checker-pattern board. Our method is based on the decomposition of a radial fundamental matrix into intrinsic and extrinsic parameters. Dense and accurate correspondences are obtained utilizing structured light patterns consisting of Gray code and phase-shifting sinusoidal code. To alleviate the sensitivity issue in estimating and decomposing the radial fundamental matrix, we propose an optimization approach that guarantees the possible solution using a prior for the principal points. We demonstrate the stability of our method using several examples and evaluate the system quantitatively and qualitatively.",
Online group-structured dictionary learning,"We develop a dictionary learning method which is (i) online, (ii) enables overlapping group structures with (iii) non-convex sparsity-inducing regularization and (iv) handles the partially observable case. Structured sparsity and the related group norms have recently gained widespread attention in group-sparsity regularized problems in the case when the dictionary is assumed to be known and fixed. However, when the dictionary also needs to be learned, the problem is much more difficult. Only a few methods have been proposed to solve this problem, and they can handle two of these four desirable properties at most. To the best of our knowledge, our proposed method is the first one that possesses all of these properties. We investigate several interesting special cases of our framework, such as the online, structured, sparse non-negative matrix factorization, and demonstrate the efficiency of our algorithm with several numerical experiments.","Dictionaries,
Minimization,
Learning systems,
Training,
Cost function,
Estimation"
Functional Analysis of Manufacturing Execution System Distribution,"Manufacturing Execution Systems are essential elements for vertical integration in modern automation systems because they provide the link between the centralized enterprise level and the distributed shop floor. Existing centralized MES implementations can however not properly cope with an unpredictable order flow, changes on the shop floor, or the increasing complexity of both. Distribution of the MES functionalities would allow shifting the decision making process from the enterprise down to the field level, resulting in a more flexible manufacturing system. This paper investigates how and to which extent MES functionalities can actually be distributed in different approaches with varying degree of organization and shows what affects system behavior with respect to flexibility and optimization.","Software agents,
Enterprise resource systems,
Flexible manufacturing systems,
Manufacturing,
Automation"
Iterative Reconstruction in X-ray Fluorescence Tomography Based on Radon Inversion,"We describe a new approach for the inversion of the generalized attenuated radon transform in X-ray fluorescence computed tomography (XFCT). The approach consists of using the radon inverse as an approximation for the actual one, followed by an iterative refinement. Also, we analyze the problem of retrieving the attenuation map directly from the emission data, giving rise to a novel alternating method for the solution. We applied our approach to real and simulated XFCT data and compared its performance to previous inversion algorithms for the problem, showing its main advantages: better images than those obtained by other analytic methods and much faster than iterative methods in the discrete setting.",
On the energy efficiency of proxy-based traffic shaping for mobile audio streaming,"We study how much energy can be saved by reshaping audio streaming traffic before receiving at the mobile devices. The rationale is the following: Mobile network interfaces (WLAN and 3G) are in active mode when they transmit or receive data, otherwise they are in idle/sleep mode. To save energy, minimum possible time should be spent in active mode and maximum in idle/sleep mode. It is well known that by reshaping the usually constant bit rate multimedia traffic into bursts, it is possible to spend more time in idle/sleep mode leading to impressive energy savings. We propose a proxy-based solution that shapes an audio stream into bursts before relaying the traffic to the mobile device. The novelty of our work is an evaluation of the energy savings using such a proxy with different configurations for both WLAN access with standard 802.11 Power Saving Mode and 3G access. We conclude that for WLAN access, proxy causes power savings of 30%-65% depending on the audio stream rate, location of the proxy and amount of cross traffic. In the case of 3G, the effectiveness of our proxy seems to vary depending on the phone model and operator. In some cases, the energy savings are encouraging, while in other cases the proxy turns out to be ineffective due to abnormal delay variation and TCP flow control behavior.","Power demand,
Mobile communication,
Mobile handsets,
Servers,
Wireless LAN,
Streaming media,
Internet"
An Inter-Landmark Approach to 4-D Shape Extraction and Interpretation: Application to Myocardial Motion Assessment in MRI,"This paper presents a novel approach to shape extraction and interpretation in 4-D cardiac magnetic resonance imaging data. Statistical modeling of spatiotemporal interlandmark relationships is performed to enable the decomposition of global shape constraints and subsequently of the image analysis tasks. The introduced descriptors furthermore provide invariance to similarity transformations and thus eliminate pose estimation errors in the presence of image artifacts or geometrical inconsistencies. A set of algorithms are derived to address key technical issues related to constrained boundary tracking, dynamic model relaxation, automatic initialization, and dysfunction localization. The proposed framework is validated with a relatively large dataset of 50 subjects and compared to existing statistical shape modeling methods. The results indicate increased adaptation to spatiotemporal variations and imaging conditions.","Shape,
Myocardium,
Magnetic resonance imaging,
Spatiotemporal phenomena,
Biomedical engineering,
High-resolution imaging,
Biomedical imaging,
Biological materials,
Biomedical materials,
Permission"
Removal of Respiratory Influences From Heart Rate Variability in Stress Monitoring,"This paper addresses a major weakness of traditional heart-rate-variability (HRV) analysis for the purpose of monitoring stress: sensitivity to respiratory influences. To address this issue, a linear system-identification model of the cardiorespiratory system using commercial heart rate monitors and respiratory sensors was constructed. Subtraction of respiratory driven fluctuations in heart rate leads to a residual signal where the effects of mental stress become more salient. We experimentally validated the effectiveness of this method on a binary discrimination problem with two conditions: mental stress of subjects performing cognitive tasks and a relaxation condition. In the process, we also propose a normalization method that can be used to compensate for ventilation differences between paced and spontaneous breathing. Our results suggest that, by separating respiration influences, the residual HRV has more discrimination power than traditional HRV analysis for the purpose of monitoring mental stress/load.","Heart rate variability,
Stress,
Autoregressive processes,
Sensors,
Transfer functions,
Cardiology,
Mathematical model"
"Dynamic model of a hyper-redundant, octopus-like manipulator for underwater applications","The octopus arm is a unique tool that combines strength and flexibility. It can shorten, elongate and bend at any point along its length. To model this behavior, a hyper-redundant manipulator composed of multiple segments is proposed. Each segment is a parallel robotic mechanism with redundant actuation. The kinematics and dynamics of this manipulator are analyzed and simulated utilizing a modular computational modeling method. Simulation results for some primitive movements are presented, and the effect of hydrodynamic forces is included.",
Real time services for future cloud computing enabled vehicle networks,"Cloud computing technique is gaining more and more popularity recently. It can be applied to the vehicle applications to ensure real time performance as well as to improve accuracy and comfort degree for drivers. In this paper, we propose our novel vehicle cloud architecture which includes device level, communication level and service level. Each of these levels is explained in further detail with flow chart and taxonomy definition. Some innovative and real time vehicle cloud services are introduced to show the wide potential applications of vehicles and some discussion about research challenges, context classification is also provided.","Vehicles,
Cloud computing,
Real time systems,
Smart phones,
Monitoring,
Computer architecture,
Roads"
Gait characterization via pulse-Doppler radar,"Falls are a major cause of injury in the elderly with almost 1/3rd of people aged 65 and more falling each year. This work aims to use gait measurements from everyday living environments to estimate risk of falling and enable improved interventions. For this purpose, we consider the use of low-cost pulse-Doppler range control radar. These radars can continuously acquire data during normal activity of a person in night and day conditions and even in the presence of obstructing furniture. A short-time Fourier transform of the radar data reveals unique Doppler signatures from the torso motion and the leg swings. Two algorithms that can extract these features from the radar spectrogram are proposed in this study for estimating gait velocity and stride durations. The performance of the proposed radar system is evaluated with experimental data, which consists of 9 different walk types and a total of 27 separate tests. A high accuracy motion-capture camera system has also been used to acquire data simultaneously with the radar and provides the ground truth reference. Results indicate that the proposed radar system is a viable candidate for gait characterization and can be used to accurately track mean gait velocity, mean stride duration and stride duration variability. The gait velocity variability can also be estimated but with relatively larger error levels.","Doppler radar,
Frequency estimation,
Leg,
Spectrogram,
Cutoff frequency,
Cameras"
A Linear Permanent Magnet Generator for Powering Implanted Electronic Devices,"Permanent magnet (PM) machines provide high efficiency, compact size, robustness, lightweight, and low noise. These features qualify them as the best suitable machine for medical applications. The system presented in this paper is a self-contained, small size, and reliable device that can continuously provide power. The core of the system is a linear generator that consists of two layers of PMs and one layer of coils. It generates power from multidirectional body movements. The movement of the device causes the coil layer to move. The relative movement of the coils versus PMs, on two sides, creates a varying flux in the windings. This change in flux produces voltage in the winding and can be converted into electrical power if a load is connected. The best place to implement this device to produce continuous power is on a muscle inside the body that is linked to the respiratory system. Design, simulation, implementation, and testing of the generator are presented in this paper. The testing results reveal that the generator can produce up to 1 mW of power in the body.",
Optimizing Voting Rule for Cooperative Spectrum Sensing Through Learning Automata,"In cooperative spectrum sensing (CSS), an optimal decision fusion rule can effectively improve the performance of the secondary system. Considering that a priori knowledge about the characteristics of primary users and secondary users (SUs) is usually unknown in practice, we propose a learning automata-based algorithm to derive the optimal voting rule for decision fusion in CSS. The proposed algorithm can work with any detection method used at SUs. Its convergence and robustness are shown here. Its stability is also analyzed by using noncooperative game theory. The condition that the obtained optimal voting rule remains unchanged is derived based on the concept of subgame perfect Nash equilibrium. It is shown that the proposed algorithm generally does not need to run many times and can work at a low cost in practice. Computer simulations validate the effectiveness of the proposed scheme.",
Service modelling for the Internet of Things,"The Internet of Things envisions a multitude of heterogeneous objects and interactions with the physical environment. The functionalities provided by these objects can be termed as `real-world services' as they provide a near real-time state of the physical world. A structured, machine-processible approach to provision such real-world services is needed to make heterogeneous physical objects accessible on a large scale and to integrate them with the digital world. This paper presents a semantic modeling approach for different components in an IoT framework. It is also discussed how the model can be integrated into the IoT framework by using automated association mechanisms with physical entities and how the data can be discovered using semantic search and reasoning mechanisms.","Ontologies,
Internet,
Semantics,
Actuators,
Data models,
Educational institutions,
Grounding"
Analysis of fMRI Data Using an Integrated Principal Component Analysis and Supervised Affinity Propagation Clustering Approach,"Clustering analysis is a promising data-driven method for analyzing functional magnetic resonance imaging (fMRI) time series data. The huge computational load, however, creates practical difficulties for this technique. We present a novel approach, integrating principal component analysis (PCA) and supervised affinity propagation clustering (SAPC). In this method, fMRI data are initially processed by PCA to obtain a preliminary image of brain activation. SAPC is then used to detect different brain functional activation patterns. We used a supervised Silhouette index to optimize clustering quality and automatically search for the optimal parameter p in SAPC, so that the basic affinity propagation clustering is improved by applying SAPC. Four simulation studies and tests with three in vivo fMRI datasets containing data from both block-design and event-related experiments revealed that functional brain activation was effectively detected and different response patterns were distinguished using our integrated method. In addition, the improved SAPC method was superior to the k -centers clustering and hierarchical clustering methods in both block-design and event-related fMRI data, as measured by the average squared error. These results suggest that our proposed novel integrated approach will be useful for detecting brain functional activation in both block-design and event-related experimental fMRI data.","Principal component analysis,
Visualization,
Covariance matrix,
Indexes,
Imaging,
Hemodynamics,
Signal to noise ratio"
Solving Nonstationary Classification Problems With Coupled Support Vector Machines,"Many learning problems may vary slowly over time: in particular, some critical real-world applications. When facing this problem, it is desirable that the learning method could find the correct input-output function and also detect the change in the concept and adapt to it. We introduce the time-adaptive support vector machine (TA-SVM), which is a new method for generating adaptive classifiers, capable of learning concepts that change with time. The basic idea of TA-SVM is to use a sequence of classifiers, each one appropriate for a small time window but, in contrast to other proposals, learning all the hyperplanes in a global way. We show that the addition of a new term in the cost function of the set of SVMs (that penalizes the diversity between consecutive classifiers) produces a coupling of the sequence that allows TA-SVM to learn as a single adaptive classifier. We evaluate different aspects of the method using appropriate drifting problems. In particular, we analyze the regularizing effect of changing the number of classifiers in the sequence or adapting the strength of the coupling. A comparison with other methods in several problems, including the well-known STAGGER dataset and the real-world electricity pricing domain, shows the good performance of TA-SVM in all tested situations.","Support vector machines,
Estimation,
Kernel,
Extrapolation,
Training,
Couplings,
Accuracy"
Byzantine fault tolerance of regenerating codes,"Recent years have witnessed a slew of coding techniques custom designed for networked storage systems. Network coding inspired regenerating codes are the most prolifically studied among these new age storage centric codes. A lot of effort has been invested in understanding the fundamental achievable trade-offs of storage and bandwidth usage to maintain redundancy in presence of different models of failures, showcasing the efficacy of regenerating codes with respect to traditional erasure coding techniques. For practical usability in open and adversarial environments, as is typical in peer-to-peer systems, we need however not only resilience against erasures, but also from (adversarial) errors. In this paper, we study the resilience of generalized regenerating codes (supporting multi-repairs, using collaboration among newcomers) in the presence of two classes of Byzantine nodes, relatively benign selfish (non-cooperating) nodes, as well as under more active, malicious polluting nodes. We give upper bounds on the resilience capacity of regenerating codes, and show that the advantages of collaborative repair can turn to be detrimental in the presence of Byzantine nodes. We further exhibit that system mechanisms can be combined with regenerating codes to mitigate the effect of rogue nodes.","Peer to peer computing,
Collaboration,
Bandwidth,
Redundancy,
Maintenance engineering,
Encoding,
Network coding"
"A Novel Model-Based 3D
+
Time Left Ventricular Segmentation Technique","A common approach to model-based segmentation is to assume a top-down modelling strategy. However, this is not feasible for complex 3D +time structures, such as the cardiac left ventricle, due to increased training requirements, aligning difficulties and local minima in resulting models. As our main contribution, we present an alternate bottom-up modelling approach. By combining the variation captured in multiple dimensionally-targeted models at segmentation-time we create a scalable segmentation framework that does not suffer from the “curse of dimensionality.” Our second contribution involves a flexible contour coupling technique that allows our segmentation method to adapt to unseen contour configurations outside the training set. This is used to identify the endo- and epicardium contours of the left ventricle by coupling them at segmentation-time, instead of at model-time. We apply our approach to 33 3D+time cardiac MRI datasets and perform comprehensive evaluation against several state-of-the-art works. Quantitative evaluation illustrates that our method requires significantly less training than state-of-the-art model-based methods, while maintaining or improving segmentation accuracy.","Shape,
Training,
Image segmentation,
Solid modeling,
Three dimensional displays,
Couplings,
Myocardium"
An EScheduler-Based Data Dependence Analysis and Task Scheduling for Parallel Circuit Simulation,"The sparse matrix solver has become the bottleneck in a Simulation Program with Integrated Circuit Emphasis circuit simulator. It is difficult to parallelize the sparse matrix solver because of the high data dependence during the numerical LU factorization. In this brief, a parallel LU factorization algorithm is developed on shared-memory computers with multicore central processing units, based on KLU algorithms. An Elimination Scheduler (EScheduler) is proposed to represent the data dependence during the LU factorization. Based on the EScheduler, the parallel tasks are scheduled in two modes to achieve a high level of concurrence, i.e., cluster mode and pipeline mode . The experimental results on 26 circuit matrices reveal that the developed algorithm can achieve speedup of 1.18-4.55&times; (on geometric average), as compared with KLU, with 1-8 threads. The result analysis indicates that for different data dependence, different parallel strategies should be dynamically selected to obtain optimal performance.",
E-Assessment as a Service,"Assessment is an essential element in learning processes. It is therefore not unsurprising that almost all learning management systems (LMSs) offer support for assessment, e.g., for the creation, execution, and evaluation of multiple choice tests. We have designed and implemented generic support for assessment that is based on assignments that students submit as electronic documents. In addition to assignments that are graded by teachers, we also support assignments that can be automatically tested and evaluated, e.g., assignments in programming languages, or other formal notations. In this paper, we report about the design and implementation of a service-oriented approach for automatic assessment of programming assignments. The most relevant aspects of our “assessment as a service” solution are that on the one hand the advantages of automatic assessment can be used with a multitude of programming languages, as well as other formal notations (as so-called backends); on the other hand, the features of these types of assessment can be easily interfaced with different existing learning management systems (as so called frontends). We also report about the practical use of the implemented software components at our university and other educational institutions.","Computer languages,
Programming profession,
Least squares approximation,
Education,
Automatic testing"
Multi-field range encoding for packet classification in TCAM,"Packet classification has wide applications such as unauthorized access prevention in firewalls and Quality of Service supported in Internet routers. The classifier containing pre-defined rules is processed by the router for finding the best matching rule for each incoming packet and for taking appropriate actions. Although many software-based solutions had been proposed, high search speed required for Internet backbone routers is not easy to achieve. To accelerate the packet classification, the state-of-the-art ternary content-addressable memory (TCAM) is a promising solution. In this paper, we propose an efficient multi-field range encoding scheme to solve the problem of storing ranges in TCAM and to decrease TCAM usage. Existing range encoding schemes are usually single-field schemes that perform range encoding processes in the range fields independently. Our performance experiments on real-life classifiers show that the proposed multi-field range encoding scheme uses less TCAM memory than the existing single field schemes. Compared with existing notable single-field encoding schemes, the proposed scheme uses 12% ~ 33% of TCAM memory needed in DRIPE or SRGE and 56% ~ 86% of TCAM memory needed in PPC for the classifiers of up to 10k rules.","Erbium,
Random access memory"
Quantitative Analysis of Human Keratinocyte Cell Elasticity Using Atomic Force Microscopy (AFM),"We present the use of atomic force microscopy (AFM) to visualize and quantify the dynamics of epithelial cell junction interactions under physiological and pathophysiological conditions at the nanoscale. Desmosomal junctions are critical cellular adhesion components within epithelial tissues and blistering skin diseases such as Pemphigus are the result in the disruption of these components. However, these structures are complex and mechanically inhomogeneous, making them difficult to study. The mechanisms of autoantibody mediated keratinocyte disassembly remain largely unknown. Here, we have used AFM technology to image and measure the mechanical properties of living skin epithelial cells in culture. We demonstrate that force measurement data can distinguish cells cultured with and without autoantibody treatment. Our demonstration of the use of AFM for in situ imaging and elasticity measurements at the local, or tissue level opens potential new avenues for the investigation of disease mechanisms and monitoring of therapeutic strategies in blistering skin diseases.","Junctions,
Humans,
Microscopy,
Diseases,
Biomedical monitoring,
Adhesives,
Mechanical factors"
Read More with Less: An Adaptive Approach to Energy-Efficient RFID Systems,"Recent years have witnessed the wide adoption of the RFID technology in many important application domains including logistics, inventory, retailing, public transportation, and security. Though RFID tags (transponders) can be passive, the high power consumption of RFID readers (interrogators) has become a critical issue as handheld and mobile readers are increasingly available in pervasive computing environments. Moreover, high transmission power aggravates interference, complicating the deployment and operation of RFID systems. In this paper, we present an energy-efficient RFID inventory algorithm called Automatic Power Stepping (APS). The design of APS is based on extensive empirical study on passive tags, and takes into consideration several important details such as tag response states and variable slot lengths. APS dynamically estimates the number of tags to be read, incrementally adjusts the transmission power level to use sufficient but not excessive power for communication, and consequently reduces both the energy consumption for reading a set of tags and the possibility of collisions. We design APS to be compatible with the current Class-1 Generation-2 RFID standards so that a reader running APS can interact with existing commercial tags without modification. We have implemented APS both on an NI RFID testing platform and in a high-fidelity simulator. The evaluation shows that APS can save more than 60% energy used by RFID readers while maintaining comparable performance on the read rate.",
On decentralized connectivity maintenance for mobile robotic systems,"To accomplish cooperative tasks, robotic systems are often required to communicate with each other. Thus, maintaining connectivity of the interagent communication graph is a fundamental issue in the field of multi-robot systems. In this paper we present a completely decentralized control strategy for global connectivity maintenance of the interagent communication graph. We describe a gradient-based control strategy that exploits decentralized estimation of the algebraic connectivity. The proposed control algorithm guarantees the global connectivity of the communication graph without requiring maintenance of the local connectivity between the robotic systems. The control strategy is validated by means of an analytical proof and simulative results.","Maintenance engineering,
Vectors,
Eigenvalues and eigenfunctions,
Laplace equations,
Robots,
Estimation error"
"Design and Application of Faithfully Rounded and Truncated Multipliers With Combined Deletion, Reduction, Truncation, and Rounding","A faithfully rounded truncated multiplier design is presented where the maximum absolute error is guaranteed to be no more than 1 unit of least position. The proposed method jointly considers the deletion, reduction, truncation, and rounding of partial product bits in order to minimize the number of full adders and half adders during tree reduction. Experimental results demonstrate the efficiency of the proposed faithfully truncated multiplier with area saving rates of more than 30%. In addition, the truncated multiplier design also has smaller delay due to the smaller bit width in the final carry-propagate adder.","Delay,
Adders,
Finite wordlength effects,
Algorithm design and analysis,
Vegetation,
Erbium,
Very large scale integration"
Equivalence of Generative and Log-Linear Models,"Conventional speech recognition systems are based on hidden Markov models (HMMs) with Gaussian mixture models (GHMMs). Discriminative log-linear models are an alternative modeling approach and have been investigated recently in speech recognition. GHMMs are directed models with constraints, e.g., positivity of variances and normalization of conditional probabilities, while log-linear models do not use such constraints. This paper compares the posterior form of typical generative models related to speech recognition with their log-linear model counterparts. The key result will be the derivation of the equivalence of these two different approaches under weak assumptions. In particular, we study Gaussian mixture models, part-of-speech bigram tagging models, and eventually, the GHMMs. This result unifies two important but fundamentally different modeling paradigms in speech recognition on the functional level. Furthermore, this paper will present comparative experimental results for various speech tasks of different complexity, including a digit string and large-vocabulary continuous speech recognition tasks.","Hidden Markov models,
Mathematical model,
Equations,
Covariance matrix,
Training,
Markov processes,
Speech recognition"
Data Management and Layout for Shingled Magnetic Recording,"Ultimately the performance and success of a shingled write disk (SWD) will be determined by more than the physical hardware realized, but will depend on the data layouts employed, the workloads experienced, and the architecture of the overall system, including the level of interfaces provided by the devices to higher levels of system software. While we discuss several alternative layouts for use with SWD, we also discuss the dramatic implications of observed workloads. Example data access traces demonstrate the surprising stability of written device blocks, with a small fraction requiring multiple updates (the problematic operation for a shingled-write device). Specifically, we discuss how general purpose workloads can show that more than 93% of device blocks can remain unchanged over a day, and that for more specialized workloads less than 0.5% of a shingled-write disk's capacity would be needed to hold randomly updated blocks. We further demonstrate how different approaches to data layout can alternatively improve or reduce the performance of a shingled-write device in comparison to the performance of a traditional non-shingled device.",
Hypervolume-based expected improvement: Monotonicity properties and exact computation,"The expected improvement (EI) is a well established criterion in Bayesian global optimization (BGO) and metamodel assisted evolutionary computation, both applied in optimization with costly function evaluations. Recently, it has been adopted in different ways to multiobjective optimization. A promising approach to formulate the expected improvement in this context, is to base it on the hypervolume indicator. Given the Bayesian model of the optimization landscape, the EI in hypervolume computes the expected gain in attained hypervolume for a given input point. Although a formulation of this expected improvement is relatively straightforward, its computation and mathematical properties are still to be investigated. This paper will outline and derive an algorithm for the exact computation of the proposed hypervolume-based EI. Moreover, this paper establishes monotonicity properties of the expected improvement. In particular the effect of the predictive distribution's variance on the hypervolume-based EI and elementary properties of the EI landscape are studied. The monotonicity properties will reveal regions where Pareto front approximations can be improved as well as underexplored regions that are favored by the hypervolume based expected improvement. A first numerical example is included that illustrates the behavior of the hypervolume-based EI in the multiobjective BGO framework.","Optimization,
Approximation methods,
Silicon,
Strips,
Gaussian distribution,
Computational modeling,
Argon"
Analysis of Errors in ToF Range Imaging With Dual-Frequency Modulation,"Range imaging is a technology that utilizes an amplitude-modulated light source and gain-modulated image sensor to simultaneously produce distance and intensity data for all pixels of the sensor. The precision of such a system is, in part, dependent on the modulation frequency. There is typically a tradeoff between precision and maximum unambiguous range. Research has shown that, by taking two measurements at different modulation frequencies, the unambiguous range can be extended without compromising distance precision. In this paper, we present an efficient method for combining two distance measurements obtained using different modulation frequencies. The behavior of the method in the presence of noise has been investigated to determine the expected error rate. In addition, we make use of the signal amplitude to improve the precision of the combined distance measurement. Simulated results compare well to actual data obtained using a system based on the PMD19k range image sensor.","Frequency modulation,
Error analysis,
Phase measurement,
Time frequency analysis,
Noise"
Optimal Control of Sleep Periods for Wireless Terminals,"We consider a mobile connected to a base station, and study how to optimally schedule shutting off its transceiver. First, we study the model from optimal control perspective. We consider off-times (periods of inactivity) of (controlled) duration. We study the question of scheduling ""waking up"" instants in which the mobile communicates with the base station and checks whether the inactivity period is over. There is a cost proportional to the delay from the moment the off-time ends until the mobile discovers it, a (small) running cost while the mobile is sleeping and a cost for waking up. We present conditions for optimal sleep periods to be constant and derive the optimal period. For the case that the conditions do not hold, we obtain suboptimal solutions which perform strictly better than the optimal constant one. We then investigate optimality restricted to classes of policies with specific constraints. We adopt the parametric optimization approach which entails cost minimization for a given parameterized policy and selection of the best policy among a class. We then compare the performance of optimal policies, of the proposed suboptimal policies as well as that of standard policies like IEEE 802.16e.","Mobile communication,
Delay,
IEEE 802.16 Standards,
Probability distribution,
Transceivers,
Base stations"
Image annotation using bi-relational graph of images and semantic labels,"Image annotation is usually formulated as a multi-label semi-supervised learning problem. Traditional graph-based methods only utilize the data (images) graph induced from image similarities, while ignore the label (semantic terms) graph induced from label correlations of a multi-label image data set. In this paper, we propose a novel Bi-relational Graph (BG) model that comprises both the data graph and the label graph as subgraphs, and connect them by an additional bipartite graph induced from label assignments. By considering each class and its labeled images as a semantic group, we perform random walk on the BG to produce group-to-vertex relevance, including class-to-image and class-to-class relevances. The former can be used to predict labels for unannotated images, while the latter are new class relationships, called as Causal Relationships (CR), which are asymmetric. CR is learned from input data and has better semantic meaning to enhance the label prediction for unannotated images. We apply the proposed approaches to automatic image annotation and semantic image retrieval tasks on four benchmark multi-label image data sets. The superior performance of our approaches compared to state-of-the-art multi-label classification methods demonstrate their effectiveness.","Semantics,
Correlation,
Roads,
Symmetric matrices,
Marine vehicles,
Image color analysis,
Benchmark testing"
A countermeasure to black hole attacks in mobile ad hoc networks,"This paper presents a solution to counter black hole attacks in mobile ad hoc networks (MANETs). Black hole attacks are effective DoS (Denial of Service) attacks committed by fabricating routing information, attracting packets routed through them, and then dropping the packets. The ETX (Expected Transmission Count) metric is a common routing metric in MANETs. It measures the delivery ratio of a wireless link to find the high throughput routes. However, the acquisition of a ETX metric value is subject to abuse. This paper describes a solution to counter black hole attacks on the ETX metric acquisition process. The solution is called the Secure ETX (SETX) protocol. The protocol, instead of allowing individual nodes to advertise their respective delivery ratios (as in ETX) at will, allows nodes to measure neighbours' delivery ratios directly. Simulation results have shown that this novel protocol can provide a marked improvement in network performances in the presence of black hole attacks, and it can do so with a negligible level of additional overhead.","Probes,
Measurement,
Routing,
Throughput,
Routing protocols,
Ad hoc networks"
VQ Applications in Steganographic Data Hiding Upon Multimedia Images,"Data hiding is one of the most important techniques to achieve better data and communication protection by hiding information into a media carrier. It provides a secure method to distribute data through a public and open channel. Data hiding for vector quantization (VQ)-based images focuses on the problem of embedding secret data into a cover VQ-based image to achieve secret communication and data protection. This paper provides a state-of-the-art review and comparison of the different existing data-hiding methods for VQ-based images. In this paper, we classify VQ-based data-hiding methods into four nonoverlapping groups according to their reversibility and output formats, introduce the details of the representative methods, summarize the features of the representative methods, and compare the performance of the representative methods using peak signal-to-noise ratio, capacity of secret data, and bit rate. Our paper shows that an irreversible method is very likely a VQ-based data-hiding method that produces a stego-image as its output, and it can embed more secret data than a reversible method. Nonstandard encoding methods (e.g., joint neighboring coding) are becoming popular in reversible data hiding since they can increase the capacity for embedding the secret data. Some methods with high compression rate, such as the search order coding-based methods, may reduce the compression rate in return for the capacity for the secret data.","Image coding,
Vector quantization,
Streaming media,
Image processing,
Steganography"
Auto-scaling to minimize cost and meet application deadlines in cloud workflows,"A goal in cloud computing is to allocate (and thus pay for) only those cloud resources that are truly needed. To date, cloud practitioners have pursued schedule-based (e.g., time-of-day) and rule-based mechanisms to attempt to automate this matching between computing requirements and computing resources. However, most of these ""auto-scaling"" mechanisms only support simple resource utilization indicators and do not specifically consider both user performance requirements and budget concerns. In this paper, we present an approach whereby the basic computing elements are virtual machines (VMs) of various sizes/costs, jobs are specified as workflows, users specify performance requirements by assigning (soft) deadlines to jobs, and the goal is to ensure all jobs are finished within their deadlines at minimum financial cost. We accomplish our goal by dynamically allocating/deallocating VMs and scheduling tasks on the most cost-efficient instances. We evaluate our approach in four representative cloud workload patterns and show cost savings from 9.8% to 40.4% compared to other approaches.","Vectors,
Dynamic scheduling,
Data models,
Servers,
Silicon,
Estimation,
Schedules"
Time synchronization in WSNs: A maximum value based consensus approach,"This paper proposes a novel synchronization algorithm for wireless sensor networks (WSNs), the Maximum Time Synchronization (MTS), which is based on maximum value consensus approach. The main idea is to maximize the local information to achieve a global synchronization. Compared with the existing consensus-based synchronization protocols, the main advantages of our protocol include: i) a faster convergence speed such that the synchronization can be completed in a finite time; ii) simultaneous compensation for both the skew and the offset. We provide a rigorous proof of convergence to global synchronization and also give the upper bound of the convergence time. Moreover, the protocol is completely distributed, asynchronous, and robust against packet losses, nodes failure and the addition of new nodes. Some numerical examples are presented to demonstrate the efficiency of our protocol.","Synchronization,
Clocks,
Wireless sensor networks,
Hardware,
Protocols,
Convergence,
Peer to peer computing"
An effective data locality aware task scheduling method for MapReduce framework in heterogeneous environments,"Data locality has recently been extensively exploited in Cloud computing to improve system performance. However, when schedule Map tasks in Hadoop MapReduce framework working in a heterogeneous environment, existing methods either cannot reduce the occurrence of these Map tasks or injure fairness, thus degrading the system performance. In order to address this problem, this paper proposes a data locality aware scheduling method to improve the Hadoop MapReduce system performance in heterogeneous computing environments. After receiving a request from a requesting node, our method preferentially schedules the task whose input data is stored on the requesting node. If no such tasks exist, our method will select the task whose input data is nearest to the requesting node, and then make a decision on whether to reserve the task for the node storing the input data or schedule the task to the requesting node by transferring the input data to the requesting node on the fly. As a proof of concept, we implement the method in Hadoop-0.20.2. In order to evaluate the performance, we carry out an experimental comparison study on our proposed method against the default scheduling method used in Hadoop-0.20.2. The experiment results show that our proposed method improves the data locality and reduces the normalized execution time as well as the response time of jobs.","Schedules,
System performance,
Time factors,
Data communication,
Distributed databases,
Processor scheduling,
Cloud computing"
Two Birds With One Stone: Wireless Access Point Deployment for Both Coverage and Localization,"Wireless access points (APs) divide a plane into small areas where their coverage ranges overlap. A mobile device can be located within a particular small overlapped area based on the unique set of APs covering the device. We formally define an Optimal Loc-deployment problem for both coverage and area localization. Our objective is to deploy a minimum number of APs that provide full communication coverage while achieving the ability to locate a mobile device within a certain area no larger than a given accuracy parameter. We obtain a formula that precisely determines the optimal solution for more than half of the accuracy values. For the rest of the accuracy values, we propose an algorithm that will return an approximation whose difference to the optimal solution is less than ε for any ε >; 0. Finally, we conduct extensive numerical evaluation and real experiments to validate our proposed solutions.","Accuracy,
Mobile handsets,
Wireless communication,
IEEE 802.11 Standards,
Wireless sensor networks,
Area measurement,
Estimation"
Malicious Circuitry Detection Using Thermal Conditioning,"Gate-level characterization (GLC) is the process of quantifying physical and manifestational properties for each gate of an integrated circuit (IC). It is a key step in many IC applications that target cryptography, security, digital rights management, low power, and yield optimization. However, GLC is a challenging task due to the size and structure of modern circuits and insufficient controllability of a subset of gates in the circuit. We have developed a new approach for GLC that employs thermal conditioning to calculate the scaling factors of all the gates by solving a system of linear equations using linear programming (LP). Therefore, the procedure captures the complete impact of process variation (PV). In order to resolve the correlations in the system of linear equations, we expose different gates to different temperatures and thus change their corresponding linear coefficients in the linear equations. We further improve the accuracy of GLC by applying statistical methods in the LP formulation as well as the post-processing steps. In order to enable non-destructive hardware Trojan horse (HTH) detection, we generalize our generic GLC procedure by manipulating the constraint of each linear equation. Furthermore, we ensure the scalability of the approaches for GLC and HTH detection using iterative IC segmentation. We evaluate our approach on a set of ISCAS and ITC benchmarks.","Logic gates,
Equations,
Mathematical model,
Integrated circuits,
Power measurement,
Delay,
Switches"
Online generation of kinodynamic trajectories for non-circular omnidirectional robots,"This paper presents a novel approach to kino-dynamic trajectory generation for non-circular omnidirectional platforms that can be combined with existing path planners. We use quintic Bézier splines to specify position and orientation of the holonomic robot for every point in time. To fully exploit the capabilities of the holonomic robot we propose a novel path representation. It allows for continuous variation of path shapes in the spectrum between straight-line paths with turns on the spot and smooth paths with independent rotations and translations. Using this representation our method optimizes trajectories according to a user-defined cost function, considering the constraints of the platform. This way, it generates fast and efficient trajectories in an anytime fashion. The experiments carried out on an industrial robot show that our approach generates highly efficient and smooth motion trajectories that can be tracked with high precision and predictability. Furthermore, the system operates in real-world environments containing unmapped obstacles and narrow passages.","Trajectory,
Robots,
Optimization,
Spline,
Planning,
Shape,
Transportation"
CACAO: Distributed Client-Assisted Channel Assignment Optimization for Uncoordinated WLANs,"IEEE 802.11 WLANs are becoming more and more popular in homes and urban areas. As compared to traditional WLAN setups (such as in campuses) where knowledgeable network administrators can make centralized decisions on channel selection, access points (APs) in these networks are often deployed by network nonspecialists in an uncoordinated manner, leading to unplanned topologies, interference, and therefore unsatisfactory throughput performance. We consider in this paper a distributed channel assignment algorithm for uncoordinated WLANs, where APs can self-configure their operating channels to minimize interference with adjacent APs. We first formulate the optimization problem on channel assignment which overcomes some of the weaknesses encountered by uncoordinated WLANs. We show that the problem is NP-hard, and propose an efficient, simple, and distributed algorithm termed CACAO (Client-Assisted Channel Assignment Optimization). In CACAO, the clients feed back traffic information to their APs. This leads to better network condition knowledge and better channel assignment decisions at the APs. We conduct extensive simulation study and comparisons using Network Simulator 2 (NS2). Our results show that CACAO outperforms other traditional and recent schemes in terms of TCP and UDP throughputs with a similar level of fairness. Furthermore, it converges quite fast and reduces cochannel interference significantly.","Interference,
Throughput,
Topology,
Optimization,
Network topology,
Data models,
Distributed algorithms"
Constant-Weight Gray Codes for Local Rank Modulation,"We consider the local rank-modulation (LRM) scheme in which a sliding window going over a sequence of real-valued variables induces a sequence of permutations. LRM is a generalization of the rank-modulation scheme, which has been recently suggested as a way of storing information in flash memory. We study constant-weight Gray codes for the LRM scheme in order to simulate conventional multilevel flash cells while retaining the benefits of rank modulation. We present a practical construction of codes with asymptotically-optimal rate and weight asymptotically half the length, thus having an asymptotically-optimal charge difference between adjacent cells. Next, we turn to examine the existence of optimal codes by specifically studying codes of weight 2 and 3. In the former case, we upper bound the code efficiency, proving that there are no such asymptotically-optimal cyclic codes. In contrast, for the latter case we construct codes which are asymptotically-optimal. We conclude by providing necessary conditions for the existence of cyclic and cyclic optimal Gray codes.","Reflective binary codes,
Flash memory,
Permutations,
Demodulation"
k-NS: A Classifier by the Distance to the Nearest Subspace,"To improve the classification performance of k-NN, this paper presents a classifier, called k -NS, based on the Euclidian distances from a query sample to the nearest subspaces. Each nearest subspace is spanned by k nearest samples of a same class. A simple discriminant is derived to calculate the distances due to the geometric meaning of the Grammian, and the calculation stability of the discriminant is guaranteed by embedding Tikhonov regularization. The proposed classifier, k-NS, categorizes a query sample into the class whose corresponding subspace is proximal. Because the Grammian only involves inner products, the classifier is naturally extended into the high-dimensional feature space induced by kernel functions. The experimental results on 13 publicly available benchmark datasets show that k-NS is quite promising compared to several other classifiers founded on nearest neighbors in terms of training and test accuracy and efficiency.",
Collision avoidance for UAV using visual detection,"Unmanned Arial Vehicles (UAVs) require the development of some on-board safety equipments before inheriting the sky. An on-board collision avoidance system is being built by our team. Due to the strict size, weight, power, and costs constraints, visual intruder airplane detection is the only option. This paper introduces our visual airplane detector algorithm, which is designed to be operational in clear and in cloudy situations under regular daylight visual conditions. To be able to implement the algorithm on-board, we have carefully selected topographic operators, which can be efficiently solved on cellular processor arrays.","Aircraft,
Pixel,
Image processing,
Cameras,
Clouds,
Aerospace control,
Mathematical model"
Optimal roadside units placement along highways,"Roadside units (RSUs) are a critical component of Vehicular ad hoc network (VANET). Ideally, RSUs should be deployed pervasively to provide continuous coverage or connectivity. However, during the initial stages of VANET, it will not be possible to ensure such a pervasive RSU deployment due to the huge cost and/or the lack of market penetration of VANET enabled vehicles. Given a limited number of RSUs, in this paper, we address the issue of optimal placement of these RSUs along highways with the goal of minimizing the average time taken for a vehicle to report an event of interest to a nearby RSU. We present a so-called balloon optimization method - the optimal solution is found by using a dynamic process similar to the natural expansion of multiple balloons in a two-dimensional space where each balloon corresponds to the coverage area of one RSU. Our preliminary evaluation shows that the balloon method performs optimal or near optimal compared with the exhaustive method and it can be used for the optimal placement of RSUs along highways.","Vehicles,
Roads,
Optimization methods,
Logic gates,
Accidents"
A machine model for dataflow actors and its applications,"In application areas that process stream-like data such as multimedia, networking and DSP, the pipelined concurrent processing is frequently represented as a dataflow network of communicating computational kernels connected by FIFO queues. However, while dataflow is a natural medium for conceptualizing and modeling stream-processing systems, its adoption as a programming methodology has been hindered by an unappealing choice between expressiveness and efficient implementability-efficient implementation techniques being primarily limited to restricted subclasses of dataflow programs. The paper presents a simple machine model for a very general class of dataflow programs and shows how it can be used as a foundation for their efficient implementation.","Computational modeling,
Software,
Testing,
Processor scheduling,
Analytical models,
Signal processing,
Buildings"
Electrostatic actuation and control of micro robots using a post-processed high-voltage SOI CMOS chip,In this paper we present an energy efficient control and power conversion circuit in a 1 μm HV SOI CMOS for a sub-millimeter robot known as a catom. The circuit provides power delivery through capacitive coupling and generates an internal high voltage that is then used to charge electrostatic actuation electrodes that move the robot. The architecture is implemented in a low power digital design and a novel high voltage driver that minimizes static power consumption for charging high voltage actuation electrodes. High voltage operation is extended by removing inherent parasitic FET gates through the post-processing removal of the Si backside carrier substrate of the SOI die.,"Electrodes,
Driver circuits,
Robots,
Electron tubes,
Silicon,
Logic gates,
Substrates"
Data aggregation for periodic sensor networks using sets similarity functions,"Energy is a major constraint in wireless sensor networks. Data Aggregation constitutes a fundamental mechanism for energy optimization. The idea is to minimize redundancy from the raw data captured by the sensors, minimizing the number of transmissions to the sink and thus saving energy. Since the data is often captured on a periodic basis, and sensor nodes detect common phenomena, a periodic based protocol that manages collected data sets can help to preserve the scarce energy. This paper proposes a new filtering technique for identifying duplicate sets of periodically captured data. We suggest a data aggregation model based on set joins similarity functions that conserves data integration while eliminating inherited redundancy. We show through the result that our approach offers significant data reduction by eliminating in-network redundancy and sending only necessary information to the sink.","Frequency measurement,
Size measurement,
Phase measurement,
Temperature measurement,
Wireless sensor networks,
Computational modeling,
Aggregates"
"Real-time resource-sharing under clustered scheduling: mutex, reader-writer, and k-exclusion locks","This paper presents the first suspension-based real-time locking protocols for clustered schedulers. Such schedulers pose challenges from a locking perspective because they exhibit aspects of both partitioned and global scheduling, which seem to necessitate fundamentally different means for bounding priority inversions. A new mechanism to bound such inversions, termed priority donation, is presented and used to derive protocols for mutual exclusion, reader-writer exclusion, and k-exclusion. Each protocol has asymptotically optimal blocking bounds under certain analysis assumptions. The latter two protocols are also the first of their kind for the special cases of global and partitioned scheduling.","Protocols,
Processor scheduling,
Boosting,
Scheduling,
Real time systems,
Delay,
Suspensions"
New Bound on Frequency Hopping Sequence Sets and Its Optimal Constructions,"In this paper, we derive a new bound on maximum nontrivial Hamming correlation of frequency hopping (FH) sequences from the Singleton bound in error correcting code literature, and we discuss the relation between the new bound and the known ones on FH sequences. Further, we construct two classes of FH sequences from punctured Reed-Solomon codes and one class of FH sequences from polynomial functions, which meet the new bound.",
Identifying Regional Cardiac Abnormalities From Myocardial Strains Using Nontracking-Based Strain Estimation and Spatio-Temporal Tensor Analysis,"Myocardial strain is a critical indicator of many cardiac diseases and dysfunctions. The goal of this paper is to extract and use the myocardial strain pattern from tagged magnetic resonance imaging (MRI) to identify and localize regional abnormal cardiac function in human subjects. In order to extract the myocardial strains from the tagged images, we developed a novel nontracking-based strain estimation method for tagged MRI. This method is based on the direct extraction of tag deformation, and therefore avoids some limitations of conventional displacement or tracking-based strain estimators. Based on the extracted spatio-temporal strain patterns, we have also developed a novel tensor-based classification framework that better conserves the spatio-temporal structure of the myocardial strain pattern than conventional vector-based classification algorithms. In addition, the tensor-based projection function keeps more of the information of the original feature space, so that abnormal tensors in the subspace can be back-projected to reveal the regional cardiac abnormality in a more physically meaningful way. We have tested our novel methods on 41 human image sequences, and achieved a classification rate of 87.80%. The regional abnormalities recovered from our algorithm agree well with the patient's pathology and clinical image interpretation, and provide a promising avenue for regional cardiac function analysis.","Strain,
Myocardium,
Magnetic resonance imaging,
Cardiac disease,
Image motion analysis,
Deformable models,
Linear discriminant analysis"
Redispatching Active and Reactive Powers Using a Limited Number of Control Actions,"This paper deals with some essential open questions in the field of optimal power flow (OPF) computations, namely: the limitation of the number of controls allowed to move, the trade-off between the objective function and the number of controls allowed to move, the computation of the minimum number of control actions needed to satisfy constraints, and the determination of the sequence of control actions to be taken by the system operator in order to achieve its operation goal. To address these questions, we propose approaches which rely on the computation of sensitivities of the objective function and inequality constraints with respect to control actions. We thus determine a subset of controls allowed to move in the OPF, by solving a sensitivity-based mixed integer linear programming (MILP) problem. We study the performances of these approaches on three test systems (of 60, 118, and 618 buses) and by considering three different OPF problems important for a system operator in emergency and/or in normal states, namely the removal of thermal congestions, the removal of bus voltage limits violation, and the reduction of the active power losses.",
Sensor Placement Algorithms for Fusion-Based Surveillance Networks,"Mission-critical target detection imposes stringent performance requirements for wireless sensor networks, such as high detection probabilities and low false alarm rates. Data fusion has been shown as an effective technique for improving system detection performance by enabling efficient collaboration among sensors with limited sensing capability. Due to the high cost of network deployment, it is desirable to place sensors at optimal locations to achieve maximum detection performance. However, for sensor networks employing data fusion, optimal sensor placement is a nonlinear and nonconvex optimization problem with prohibitively high computational complexity. In this paper, we present fast sensor placement algorithms based on a probabilistic data fusion model. Simulation results show that our algorithms can meet the desired detection performance with a small number of sensors while achieving up to seven-fold speedup over the optimal algorithm.",
A Hybrid Simulated Annealing Algorithm for Nonslicing VLSI Floorplanning,"Floorplanning in very large scale integrated-circuit (VLSI) design is the first phase in the process of designing the physical layout of a chip. This makes the floorplanning problem of paramount importance, since it determines the performance, size, yield, and reliability of VLSI chips . From the computational point of view, the VLSI floorplanning is an NP-hard problem. In this paper, we present a hybrid simulated annealing algorithm (HSA) for nonslicing VLSI floorplanning. The HSA uses a new greedy method to construct an initial B*-tree, a new operation on the B*-tree to explore the search space, and a novel bias search strategy to balance global exploration and local exploitation. Experimental results on Microelectronic Center of North Carolina (MCNC) benchmarks show that the HSA can quickly produce optimal or nearly optimal solutions for all the tested problems.","Simulated annealing,
Search methods,
Space exploration,
Pediatrics,
Heuristic algorithms,
Benchmark testing,
Cost function"
A 4-Port-Inductor-Based VCO Coupling Method for Phase Noise Reduction,"A 4-port-inductor-based voltage-controlled oscillator (VCO) coupling technique is introduced to improve VCO phase noise performance. The analysis of the stability of oscillation modes and the phase noise performance of a coupled oscillator is provided as theoretical fundamental. Four-port inductors are compared with typical two-port inductors, and their superior performance over the latter is demonstrated through analysis and measurements. The design strategies of coupled VCOs using 4-port inductors are discussed. Two coupled VCO topologies, the NMOS-cross-coupled-pair coupled VCO (NCVCO) and the complementary-cross-coupled-pair coupled VCO (CCVCO), are proposed and compared with the conventional NMOS-cross-coupled-pair VCO (NVCO). Prototype designs have been demonstrated to verify the analysis. The 12.8-GHz CCVCO design achieves phase noise of -116 dBc/Hz at 1-MHz offset, a tuning range of 31.4%, and FOM and FOMT of 184 and 194, respectively.","Inductors,
Couplings,
Phase noise,
Impedance,
Voltage-controlled oscillators"
Experimental Investigation of a Cavity-Mode Resonator Using a Micromachined Two-Dimensional Silicon Phononic Crystal in a Square Lattice,"A 2-D silicon phononic crystal (PnC) slab of a square array of cylindrical air holes in a 10-μm-thick freestanding silicon plate with line defects is characterized as a cavity-mode PnC resonator. A piezoelectric aluminum nitride (AlN) film is employed as the interdigital transducers to transmit and detect acoustic waves, thus making the whole microfabrication process CMOS compatible. Both the band structure of the PnC and the transmission spectrum of the proposed PnC resonator are analyzed and optimized using finite-element method. The measured quality factor (Q factor) of the microfabricated PnC resonator is over 1000 at its resonant frequency of 152.46 MHz. The proposed PnC resonator shows promising acoustic resonance characteristics for radio-frequency communications and sensing applications.","Silicon,
Photonic band gap,
Slabs,
Crystals,
Resonant frequency,
Q factor,
Frequency measurement"
Online Video Stream Abstraction and Stylization,"This paper gives an automatic method for online video stream abstraction, producing a temporally coherent output video stream, in a style with large regions of constant color and highlighted bold edges. Our system includes two novel components. Firstly, to provide coherent and simplified output, we segment frames, and use optical flow to propagate segmentation information from frame to frame; an error control strategy is used to help ensure that the propagated information is reliable. Secondly, to achieve coherent and attractive coloring of the output, we use a color scheme replacement algorithm specifically designed for an online video stream. We demonstrate real-time performance for CIF videos, allowing our approach to be used for live communication and other related applications.",
Fast-Write Resistive RAM (RRAM) for Embedded Applications,"Especially for microcontroller and mobile applications, embedded nonvolatile memory is an important technology offering to reduce power and provide local persistent storage. This article describes a new resistive RAM device with fast write operation to improve the speed of embedded nonvolatile memories.","Nonvolatile memory,
Phase change random access memory,
Electrical engineering,
MOS devices,
Resistance,
Electrodes,
Embedded systems"
Kernel Similarity Modeling of Texture Pattern Flow for Motion Detection in Complex Background,"This paper proposes a novel kernel similarity modeling of texture pattern flow (KSM-TPF) for background modeling and motion detection in complex and dynamic environments. The texture pattern flow encodes the binary pattern changes in both spatial and temporal neighborhoods. The integral histogram of texture pattern flow is employed to extract the discriminative features from the input videos. Different from existing uniform threshold based motion detection approaches which are only effective for simple background, the kernel similarity modeling is proposed to produce an adaptive threshold for complex background. The adaptive threshold is computed from the mean and variance of an extended Gaussian mixture model. The proposed KSM-TPF approach incorporates machine learning method with feature extraction method in a homogenous way. Experimental results on the publicly available video sequences demonstrate that the proposed approach provides an effective and efficient way for background modeling and motion detection.",
Hierarchical hybrid MLP/HMM or rather MLP features for a discriminatively trained Gaussian HMM: A comparison for offline handwriting recognition,"We use neural network based features extracted by a hierarchical multilayer-perceptron (MLP) network either in a hybrid MLP/HMM approach or to discriminatively retrain a Gaussian hidden Markov model (GHMM) system in a tandem approach. MLP networks have been successfully used to model long-term and non-linear features dependencies in automatic speech and optical character recognition. In offline hand writing recognition, MLPs have been mostly used for isolated character and word recognition in hybrid approaches. Here we analyze MLPs within an LVCSR framework for continuous handwriting recognition using discriminative MMI/MPE training. Especially hybrid MLP/HMM and discriminatively retrained MLP-GHMM tandem approaches are evaluated. Significant improvements and competitive results are re ported for a closed-vocabulary task on the IfN/ENIT Arabic handwriting database and for a large-vocabulary task using the IAM English handwriting database.","Hidden Markov models,
Handwriting recognition,
Training,
Databases,
Feature extraction,
Text recognition,
Character recognition"
Linear Parameter Varying Identification of Freeway Traffic Models,"This paper deals with linear parameter varying (LPV) modeling and identification of a generic, second-order freeway traffic flow model. A non-conventional technique is proposed to transform the nonlinear freeway traffic flow model into a parameter-dependent form. The resulting exact LPV model is equivalent to the original nonlinear dynamics. Simplification of the nonlinear model gives rise to the introduction of an approximate LPV description. The application of parameter varying identification approaches are made possible by the transformation. Closed-loop predictor-based subspace identification for LPV systems (PBSID LPV) is applied to estimate the affine parameter matrices of the LPV freeway models developed. If the model structure of the original plant is assumed to be known, this paper shows a solution how to estimate LPV model parameters based on the identified model. Parameter-dependent models are identified and validated using real detector measurement data in order to emphasize the applicability of the kernel PBSID LPV methodology. Comparison with traditional nonlinear parametric identification, generally used in traffic identification, is also provided.","Mathematical model,
Traffic control,
Steady-state,
Equations,
Computational modeling,
Vehicles,
Adaptation model"
Sleep Control for Tracking in Sensor Networks,"We study the problem of tracking an object moving through a network of wireless sensors. In order to conserve energy, the sensors may be put into a sleep mode with a timer that determines their sleep duration. It is assumed that an asleep sensor cannot be communicated with or woken up, and hence the sleep duration needs to be determined at the time the sensor goes to sleep based on all the information available to the sensor. Having sleeping sensors in the network could result in degraded tracking performance, therefore, there is a tradeoff between energy usage and tracking performance. We design sleeping policies that attempt to optimize this tradeoff and characterize their performance. As an extension to our previous work in this area, we consider generalized models for object movement, object sensing, and tracking cost. For discrete state spaces and continuous Gaussian observations, we derive a lower bound on the optimal energy-tracking tradeoff. It is shown that in the low tracking error regime, the generated policies approach the derived lower bound.","Tracking,
Equations,
Mathematical model,
Sensors,
Cost function,
Markov processes,
Aerospace electronics"
An automated truck platoon for energy saving,"This paper presents an automated truck platoon that has been developed under a national ITS project named Energy ITS. The project, started in 2008, aims at energy saving and global warming prevention with ITS technologies. A platoon of 3 fully-automated trucks currently drives at 80 km/h with the gap of 10 m on a test truck and along an expressway before public use, under not only steady state driving but also lane changing. The lateral control is based on the lane marker detection by the computer vision, and the longitudinal control is based on the gap measurement by 76 GHz radar and lidar in addition to the inter-vehicle communications of 5.8 GHz DSRC. The radar and lidar also work as the obstacle detection. The feature of the technologies is the high reliability, aiming at the near future introduction. Fuel consumption measurement on a test track and along an expressway shows that the fuel can be saved by about 14 %. The evaluation simulation shows that the effectiveness of the platooning with the gap of 10 m when the 40 % penetration in heavy trucks is 2.1 % reduction of CO2 along an expressway. The introduction scenario is also discussed.","Control systems,
Energy consumption,
Safety,
Sensors,
Automobiles"
Utility optimization for dynamic peer-to-peer networks with tit-for-tat constraints,"We consider a peer-to-peer network where nodes can send and receive files amongst their peers. File requests are generated randomly, and each new file can correspond to a different subset of peers that already have the file and hence can assist in the download. Nodes that help others are rewarded by being able to download more. The goal is to design a control algorithm that allocates requests and schedules transmissions to maximize overall throughput-utility, subject to meeting “tit-for-tat” constraints that incentivize participation. Our algorithm is shown to operate efficiently on networks with arbitrary traffic and channel sample paths, including wireless networks whose capacity can be significantly extended by the peer-to-peer functionality.",
Joint Coding/Routing Optimization for Distributed Video Sources in Wireless Visual Sensor Networks,"This paper studies a joint coding/routing optimization between network lifetime and video distortion by applying information theory to wireless visual sensor networks for correlated sources. Arbitrary coding [distributed video coding and network coding (NC)] from both combinatorial optimization and information theory could make significant progress toward the performance limit and tractable. Also, multipath routing can spread energy utilization across nodes within the entire network to keep a potentially longer lifetime, and solve the wireless contention issues by the splitting traffic. The objective function not only keeps the total energy consumption of encoding power, transmission power, and reception power minimized, but ensures the information received by sink nodes to approximately reconstruct the visual field. Also, a generalized power consumption model for distributed video sources is developed, in which the coding complexity of Key frames and Wyner-Ziv frames is measured by translating specific coding behavior into energy consumption. On the basis of the distributed multiview video coding and NC-based multipath routing, the balance problem between lifetime (costs) and distortion (capacity) is modeled as an optimization formulation with a fully distributed solution. Through a primal decomposition, a two-level optimization is relaxed with Lagrangian dualization and solved by the gradient algorithm. The low-level optimization problem is further decomposed into a secondary master dual problem with four cross-layer subproblems: a rate control problem, a channel contention problem, a distortion control problem, and an energy conservation problem. The implementation of the distributed algorithm is discussed with regard to the communication overhead and dynamic network change. Simulation results validate the convergence and performance of the proposed algorithm.","Encoding,
Wireless sensor networks,
Wireless communication,
Optimization,
Video coding,
Correlation,
Power demand"
Risk-Aware Provisioning for Optical WDM Mesh Networks,"A service-level agreement (SLA) typically specifies, among other metrics, the availability a service provider (SP) promises to a customer. In an optical wavelength division multiplexing (WDM) network, connection-oriented provisioning is commonly based on whether the path's statistical availability complies with the SLA-requested availability. Because of the stochastic nature of network failures, the actually provisioned availability over a specific time period is subject to uncertainty, and hence the SLA is usually at risk. We consider this uncertainty and study provisioning to minimize SLA violations. We show that the SLA Violation Risk is affected by a number of factors (e.g., failure profiles, availability target, and penalty period), and hence cannot simply be characterized by statistical path availability. We formulate the problem of risk-aware provisioning in WDM mesh networks, where path selection is dictated by SLA Violation Risk. In particular, we focus on devising an efficient scheme capable of computing path(s) that are likely to successfully accommodate the SLA-requested availability. A novel technique is applied to convert links with heterogeneous failure profiles to reference links that capture the main risk features in a relative manner. Based on the “reference link” concept, our Risk-Aware Provisioning scheme uses only limited failure information. We also extend our Risk-Aware Provisioning to use shared-path protection (SPP) for connections with strict availability requirements. We evaluate the performance and demonstrate the effectiveness of our schemes in terms of SLA violation ratio compared to the generic availability-aware approaches.",
Millimeter-wave dielectric properties of single-crystal ferroelectric and dielectric materials,"Transmittance measurements on various single crystal ferroelectric and dielectric materials, BaTiO3, SrTiO3, LiNbO3, LiTaO3, (PbMg1/3Nb2/3O3)0.73-(PbTiO3)0.27, LaAlO3, and Bi4Ge3O12,, over a broad millimeter-wave (MMW) frequency range have been performed. Frequency dependence of the complex dielectric permittivity has been measured in the MMW region using high-power sources for the first time, using a free-space, quasi-optical MMW spectrometer equipped with high-power backward wave oscillators (BWOs) as sources of coherent radiation, tunable in the range from 30 to 120 and 180 to 260 GHz. These results are compared with MMW permittivity of these materials obtained by other methods as well as to RF, microwave, and optical frequency permittivities for all the materials tested. The effects of both crystallographic orientation and quality of the surface polishing of the crystals have been examined. Uncertainties and possible sources of instrumentation and measurement errors related to the freespace MMW technique are discussed. This work demonstrates that precise MMW permittivity data can be obtained even on relatively small and thin crystals of different surface conditions and orientations using the high-power BWO-based quasioptical approach.","Crystals,
Dielectrics,
Permittivity,
Optical variables control,
Frequency measurement,
Titanium compounds"
Variation-Aware Task and Communication Mapping for MPSoC Architecture,"As technology scales, the delay uncertainty caused by process variations has become increasingly pronounced in deep submicrometer designs. As a result, a paradigm shift from deterministic to statistical design methodology at all levels of the design hierarchy is inevitable. In this paper, we propose a variation-aware task and communication mapping methodology for multiprocessor system-on-chips that uses network-on-chip communication architecture so that the impact of parameter variations can be mitigated. Our mapping scheme accounts for variability in both the processing cores and the communication links to ensure a complete and accurate model of the entire system. A new design metric, called performance yield and defined as the probability of the assigned schedule meeting the predefined performance constraints, is used to guide both the task scheduling and the routing path allocation procedure. An efficient yield computation method for this mapping complements and significantly improves the effectiveness of the proposed variation-aware mapping algorithm. Experimental results show that our variation-aware mapper achieves significant yield improvements over worst-case and nominal-case deterministic mapper.","Schedules,
Real time systems,
Embedded systems,
Delay,
Computer architecture,
Resource management"
A Novel Hexa-Band Antenna for Mobile Handsets Application,"A novel hexa-band antenna for mobile handsets application is proposed and analyzed in this communication. An asymmetric T-type monopole antenna with a shorted-line is designed to be operated in code-division multiple access (CDMA, 824-894 MHz), global system for mobile communications (GSM, 880-960 MHz), digital communication system (DCS, 1710-1880 MHz), personal communication system (PCS, 1850-1990 MHz), wideband code division multiple access (WCDMA, 1920-2170 MHz) and Bluetooth (2400-2484 MHz) bands. A prototype of the proposed antenna with 50 mm in length, 3 mm in height and 15 mm in width is fabricated and experimentally investigated. The experimental results indicate that the VSWR 2.5:1 bandwidths achieved were 17.8% and 37.1% at 900 MHz and 2100 MHz, respectively. The specific absorption rate (SAR) for an input power of 24 dBm in CDMA, GSM and WCDMA bands, and an input power of 21 dBm in DCS and PCS bands all meet the SAR limit of 1.6 mW/g. Experimental results are shown to verify the validity of theoretical work.",
Storing Secrets on Continually Leaky Devices,"We consider the question of how to store a value secretly on devices that continually leak information about their internal state to an external attacker. If the secret value is stored on a single device from which it is efficiently retrievable, and the attacker can leak even a single predicate of the internal state of that device, then she may learn some information about the secret value itself. Therefore, we consider a setting where the secret value is shared between multiple devices (or multiple components of a single device), each of which continually leaks arbitrary adaptively chosen predicates its individual state. Since leakage is continual, each device must also continually update its state so that an attacker cannot just leak it entirely one bit at a time. In our model, the devices update their state individually and asynchronously, without any communication between them. The update process is necessarily randomized, and its randomness can leak as well. As our main result, we construct a sharing scheme for two devices, where a constant fraction of the internal state of each device can leak in between and during updates. Our scheme has the structure of a public-key encryption, where one share is a secret key and the other is a ciphertext. As a contribution of independent interest, we also get public-key encryption in the continual leakage model, introduced by Brakerski et al. and Dodis et al. (FOCS '10). This scheme tolerates continual leakage on the secret key and the updates, and simplifies the recent construction of Lewko, Lewko and Waters (STOC '11). For our main result, we show how to update the ciphertexts of the encryption scheme so that the message remains hidden even if an attacker interleaves leakage on secret key and ciphertext shares. The security of our scheme is based on the linear assumption in prime-order bilinear groups. We also provide an extension to general access structures realizable by linear secret sharing schemes across many devices. The main advantage of this extension is that the state of some devices can be compromised entirely, while that of the all remaining devices is susceptible to continual leakage. Lastly, we show impossibility of information theoretic sharing schemes in our model, where continually leaky devices update their state individually.",
A side-channel and fault-attack resistant AES circuit working on duplicated complemented values,"Cryptographic circuits can be subjected to several kinds of side-channel and fault attacks in order to extract the secret key. Side-channel attacks can be carried by measuring either the power consumed or the EM waves emitted by the cryptographic module and trying to find a correlation between the given side-channel and the data manipulated. Concerning fault attacks, in the case of differential fault attacks (DFA), a cryptographic calculation is corrupted in such a way as to retrieve information about the secret key. Faults can be induced by different means such as lasers, voltage glitches, electromagnetic perturbations or clock skews. Several counter-measures, like in, have been separately proposed to tackle either kind of attack. In this paper, we describe the implementation of an AES chip where duplicated and complemented data paths provide resistance against both side-channel and fault attacks.","Cryptography,
Circuit faults,
Correlation,
Logic gates,
Semiconductor device measurement,
Computer science,
Analytical models"
Recognition of Traffic Lights in Live Video Streams on Mobile Devices,"A mobile computer vision system is presented that helps visually impaired pedestrians cross roads. The system detects pedestrian lights in the environment and gives feedback about the current phase of the crucial light. For this purpose the live video stream of a mobile phone is analyzed in four steps: localization, classification, video analysis, and time-based verification. In particular, the temporal analysis allows us to alleviate the inherent problems such as occlusions (by vehicles), falsified colors, and others, and to further increase the decision certainty over a period of time. Due to the limited resources of mobile devices very efficient and precise algorithms have to be developed to ensure the reliability and the interactivity of the system. A prototype system was implemented on a Nokia N95 mobile phone and tested in real environment. It was trained to detect German traffic lights. For the prototype training and testing, we generated image and video databases including manually specified ground truth meta-data. These databases described in this paper are publicly available for the research community. Quantitative performance analysis is provided to demonstrate the reliability and interactivity of the prototype system.","Image color analysis,
Mobile handsets,
Streaming media,
Mobile communication,
Prototypes,
Databases,
Cameras"
Incorporating Temperature Variations Into Transmission-Line Models,"This paper discusses a transmission-line modeling approach that incorporates available ambient temperature information. Several proposed line modeling techniques are studied and include distributed and lumped parameter models. In order to capture the nonuniformity of line parameters caused by temperature gradients, a model with multiple nonuniform segments is also proposed. An automated tool has been developed to obtain appropriate line model segmentation and parameter values of each segment, given a set of temperature measurements and their locations along the line.","Temperature measurement,
Distributed parameter circuits,
Power system modeling,
Transmission line measurements,
Temperature dependence,
Power transmission lines"
"A survey on SQL injection: Vulnerabilities, attacks, and prevention techniques","In this paper, we present a detailed review on various types of SQL injection attacks, vulnerabilities, and prevention techniques. Alongside presenting our findings from the survey, we also note down future expectations and possible development of countermeasures against SQL injection attacks.","Databases,
Runtime,
Manuals,
Programming,
Access control,
Authentication"
Randomness and dependencies extraction via polarization,"The basic polarization phenomenon for i.i.d. sources is extended to a framework allowing dependencies within and between multiple sources. In particular, it is shown that taking the polar transform of a random matrix with i.i.d. columns of arbitrary (correlated) distribution allows to extract the randomness and dependencies. This result is the used to develop polar coding schemes (having low complexity) for: (1) distributed data compression, i.e., Slepian-Wolf coding (without decomposing the problem into single-user problems), (2) compression of sources with memory, (3) compression of sources on finite fields, extending the polarization phenomenon for alphabets of prime cardinality to powers of primes.","Entropy,
Channel coding,
Complexity theory,
Decoding,
Error probability,
Computer science"
Digital microfluidic operations on micro-electrode dot array architecture,"As digital microfluidics-based biochips find more applications, their complexity is expected to increase significantly owing to the trend of multiple and concurrent assays on the chip. There is a pressing need to deliver a top-down design methodology that the biochip designer can leverage the same level of computer-aided design support as the semi-conductor industry now does. Moreover, as microelectronics fabrication technology is scaling up and integrated device performance is improving, it is expected that these microfluidic biochips will be integrated with microelectronic components in next-generation system-on-chip designs. This study presents the analysis and experiments of digital microfluidic operations on a novel electrowetting-on-dielectric-based `micro-electrode dot array architecture` that fosters a development path for hierarchical top-down design approach for digital microfluidics. The proposed architecture allows dynamic configurations and activations of identical basic microfluidic unit called `micro-electrode cells` to design microfluidic components, layouts, routing, microfluidic operations and applications of the biochip hierarchically. Fundamental microfluidic operations have been successfully performed by the architecture. In addition, this novel architecture demonstrates a number of advantages and flexibilities over the conventional digital microfluidics in performing advanced microfluidic operations.",
KnitSketch: A Sketch Pad for Conceptual Design of 2D Garment Patterns,"In this paper, we present a new sketch-based system - KnitSketch, to improve the efficiency of process planning for knitting garments at an early design stage. The KnitSketch system utilizes sketching interface with the pen-paper metaphor and users only need to draw outlines of different parts of the garment. Based on sketching understanding, the system automatically makes reasonable geometric inferences about the process-planning data of the garment. The system is designed for nonprofessional users and can design diverse garment styles by freehand drawings. The contributions of this work include contextual extraction of reusable data from sketches, a MDG structure for sketch beautification, and an integrated system with natural expression and effective communication that reduces the cognitive load of human beings. User experience shows that the proposed system helps designers focus on the task instead of the designing tools, and thus improves the efficiency and productivity of human beings.","Conceptual design,
Clothing,
Graphics,
Databases,
Process planning,
Semantics,
Domain knowledge"
A universal-input high-power-factor PFC pre-regulator without electrolytic capacitor for PWM dimming LED lighting application,"High brightness white LED has attracted a lot of attention for its high efficacy, simple to drive, environmentally friendly, long lifespan and small size. The power supply for LED lighting also requires long life while maintaining high efficiency, high power factor and low cost. However, a typical design employs electrolytic capacitor as storage capacitor, which is not only bulky, but also with short lifespan, thus hampering the entire LED lighting system. To prolong the lifespan of power supply, it has to use film capacitor with small capacitance to replace electrolytic capacitor. In this paper, a universal input high efficiency, high power factor LED driver is proposed based on the modified SEPIC converter. Along with a relatively large voltage ripple allowable in a PFC design, the proposal of LED lamp driver is able to eliminate the electrolytic capacitor while maintaining high power factor. To increase the efficiency of LED driver, the presented SEPIC-derived converter is modified further as the twin-bus output stage for matching ultra-high efficiency twin-bus LED current regulator. The operation principle and related analysis is described in detail. A 50-W prototype has been built and tested to verify the proposed LED Driver.","Capacitors,
Light emitting diodes,
Inductors,
Lighting,
Switches,
Reactive power,
Capacitance"
Performance Characteristics of an HTS Linear Synchronous Motor With HTS Bulk Magnet Secondary,"A single-sided high-temperature superconducting (HTS) linear synchronous motor (HTSLSM) with an HTS bulk magnet array as its secondary has been developed, and a split pulse coil magnetization system is used to magnetize the secondary HTS bulks with alternating magnetic poles. The electromagnetic parameters of the HTSLSM have been calculated to verify its performance. The HTSLSM is incorporated with a developed control system based on the voltage space vector pulsewidth modulation strategy implemented by a computer-software-controlled platform. A compositive experimental testing system has also been developed to measure the thrust and normal force of the HTSLSM. The traits of the thrust and normal force have been comprehensively identified experimentally, and the results from the experiments and analysis would benefit the electromagnetic design and the control scheme development for the HTSLSM.","High temperature superconductors,
Magnetic flux,
Superconducting magnets,
Saturation magnetization,
Magnetic circuits,
Magnetic levitation,
Windings"
"Humans and Bots in Internet Chat: Measurement, Analysis, and Automated Classification","The abuse of chat services by automated programs, known as chat bots, poses a serious threat to Internet users. Chat bots target popular chat networks to distribute spam and malware. In this paper, we first conduct a series of measurements on a large commercial chat network. Our measurements capture a total of 16 different types of chat bots ranging from simple to advanced. Moreover, we observe that human behavior is more complex than bot behavior. Based on the measurement study, we propose a classification system to accurately distinguish chat bots from human users. The proposed classification system consists of two components: 1) an entropy-based classifier; and 2) a Bayesian-based classifier. The two classifiers complement each other in chat bot detection. The entropy-based classifier is more accurate to detect unknown chat bots, whereas the Bayesian-based classifier is faster to detect known chat bots. Our experimental evaluation shows that the proposed classification system is highly effective in differentiating bots from humans.",
Interference Suppression in Uniform Linear Arrays Through a Dynamic Thinning Strategy,"Thinned arrays are designed to have low average sidelobe levels. The randomness in selecting the elements that are turned on/off to achieve the low sidelobes implies that there are several arrangements of the thinned aperture that have the same or nearly the same average sidelobe level. If the same number of elements are always turned on, but the elements that are turned off change, then the array directivity does not change, but the nulls and sidelobes do. This paper presents a technique for dynamically altering the thinning configuration of a linear array in order place low sidelobe and nulls in desired directions. A set of representative results is reported and discussed to show the effectiveness of the proposed approach.","Antenna arrays,
Apertures,
Interference suppression,
Linear antenna arrays"
Improved Bounds on the Throughput Efficiency of Greedy Maximal Scheduling in Wireless Networks,"In this paper, we derive new bounds on the throughput efficiency of Greedy Maximal Scheduling (GMS) for wireless networks of arbitrary topology under the general k -hop interference model. These results improve the known bounds for networks with up to 26 nodes under the 2-hop interference model. We also prove that GMS is throughput-optimal in small networks. In particular, we show that GMS achieves 100% throughput in networks with up to eight nodes under the 2-hop interference model. Furthermore, we provide a simple proof to show that GMS can be implemented using only local neighborhood information in networks of any size.",
Ground surface segmentation for navigation with a low resolution visual prosthesis,"We propose the use of ground surface segmentation to enhance the perception of obstacles in low to medium resolution prosthetic visual representations. We apply a recently proposed algorithm for segmenting traversable space in stereo disparity data, and show how such a scheme may be utilised to enhance the distinction between the ground surface and obstructions (in particular, small trip hazards). Qualitative comparisons with intensity and straight depth-based representations highlight advantages for the visualisation of obstacles, offering potential gains for visual navigation with low resolution and low dynamic range visual prostheses.",
Current-Mode Analog Adaptive Mechanism for Ultra-Low-Power Neural Networks,"Neural networks (NNs) implemented at the transistor level are powerful adaptive systems. They can perform hundreds of operations in parallel but at the expense of a large number of building blocks. In the case of analog realization, an extremely low chip area and low power dissipation can be achieved. To accomplish this, the building blocks should be simple. This brief presents a new current-mode low-complexity flexible adaptive mechanism (ADM) with a strongly reduced leakage in analog memory. Input signals ranging from 0.5 to 20 μA are held for 10-50 ms, with the leakage rate from 0.2%/ms to 0.04%/ms, respectively, depending on temperature. A small storage capacitor of 200 fF enables a short write time ( <; 100 ns). A single ADM cell occupies 1400 μm2 when realized in the Taiwan Semiconductor Manufacturing Company Ltd. CMOS 0.18-μm technology. The potential application of this NN is envisioned in a mobile platform based on a wireless sensor network to be used for online analysis of electrocardiography signals.",
Fast Algebraic Attacks and Decomposition of Symmetric Boolean Functions,"In this correspondence, first we give a decomposition of symmetric Boolean functions, then we show that almost all symmetric Boolean functions, including these functions with good algebraic immunity, behave badly against fast algebraic attacks. Besides, we improve the relations between algebraic degree and algebraic immunity of symmetric Boolean functions.",
Optimizing Visual Search Reranking via Pairwise Learning,"Visual search reranking is defined as reordering visual documents (images or video clips) based on the initial search results or some auxiliary knowledge to improve the search precision. Conventional approaches to visual search reranking empirically take the “classification performance” as the optimization objective, in which each visual document is determined relevant or not, followed by a process of increasing the order of relevant documents. In this paper, we first show that the classification performance fails to produce a globally optimal ranked list, and then we formulate reranking as an optimization problem, in which a ranked list is globally optimal only if any arbitrary two documents in the list are correctly ranked in terms of relevance. This is different from existing approaches which simply classify a document as “relevant” or not. To find the optimal ranked list, we convert the individual documents to “document pairs,” each represented as a “ordinal relation.” Then, we find the optimal document pairs which can maximally preserve the initial rank order while simultaneously keeping the consistency with the auxiliary knowledge mined from query examples and web resources as much as possible. We develop two pairwise reranking methods, difference pairwise reranking (DP-reranking) and exclusion pairwise reranking (EP-reranking), to obtain the relevant relation of each document pair. Finally, a round robin criterion is explored to recover the final ranked list. We conducted comprehensive experiments on an automatic video search task over TRECVID 2005-2007 benchmarks, and showed consistent improvements over text search baseline and other reranking approaches.","Visualization,
Web search,
Detectors,
Search engines,
Optimization,
Knowledge engineering,
Accuracy"
A Practical Adaptive Pacing Scheme for TCP in Multihop Wireless Networks,"We introduce and evaluate a feasible end-to-end congestion control algorithm for overcoming the severe deficiencies of TCP in IEEE 802.11 multihop wireless networks. Our approach, which we denote as TCP with Adaptive Pacing (TCP-AP), implements rate-based scheduling of transmissions within the TCP congestion window. The TCP source adaptively sets its transmission rate using an estimate of the current out-of-interference delay and the coefficient of variation of recently measured round-trip times. TCP-AP retains the end-to-end semantics of TCP and neither relies on modifications at the routing or the link layer nor requires cross-layer information from intermediate nodes along the path. As opposed to previous proposals that build on network simulators, we implement and evaluate our approach in a real wireless mesh test-bed comprising 20 nodes. In a comprehensive comparative performance study using our test-bed, we show that, depending on the current network state and traffic patterns, TCP-AP achieves up to 10 times more goodput than TCP NewReno, provides excellent fairness, and is highly responsive to changing network traffic conditions.","Spread spectrum communication,
Wireless networks,
Sensors,
Delay,
IEEE 802.11 Standards,
Wireless sensor networks"
Multi-label visual classification with label exclusive context,"We introduce in this paper a novel approach to multi-label image classification which incorporates a new type of context - label exclusive context - with linear representation and classification. Given a set of exclusive label groups that describe the negative relationship among class labels, our method, namely LELR for Label Exclusive Linear Representation, enforces repulsive assignment of the labels from each group to a query image. The problem can be formulated as an exclusive Lasso (eLasso) model with group overlaps and affine transformation. Since existing eLasso solvers are not directly applicable to solving such an variant of eLasso in our setting, we propose a Nesterov's smoothing approximation algorithm for efficient optimization. Extensive comparing experiments on the challenging real-world visual classification benchmarks demonstrate the effectiveness of incorporating label exclusive context into visual classification.","Vectors,
Context,
Visualization,
Kernel,
Approximation methods,
Training,
Optimization"
Deep Learning Regularized Fisher Mappings,"For classification tasks, it is always desirable to extract features that are most effective for preserving class separability. In this brief, we propose a new feature extraction method called regularized deep Fisher mapping (RDFM), which learns an explicit mapping from the sample space to the feature space using a deep neural network to enhance the separability of features according to the Fisher criterion. Compared to kernel methods, the deep neural network is a deep and nonlocal learning architecture, and therefore exhibits more powerful ability to learn the nature of highly variable datasets from fewer samples. To eliminate the side effects of overfitting brought about by the large capacity of powerful learners, regularizers are applied in the learning procedure of RDFM. RDFM is evaluated in various types of datasets, and the results reveal that it is necessary to apply unsupervised regularization in the fine-tuning phase of deep learning. Thus, for very flexible models, the optimal Fisher feature extractor may be a balance between discriminative ability and descriptive ability.",
RescueMe: Location-Based Secure and Dependable VANETs for Disaster Rescue,"Natural disasters and terrorism threaten our nation's safety and security, rendering post-disaster rescue mission critical. It is of paramount importance to carry out rescue work relying on secure and dependable networking. In this paper, we propose RescueMe, location-based vehicular ad hoc networks (VANETs), to aid in secure and dependable rescue planning for the efficient allocation of rescue resources. RescueMe leverages the location information stored during normal network operations to facilitate post-disaster rescue planning, while guaranteeing that the sensitive user location information is not exploited to trace a user's whereabouts when disasters are absent, even if the most powerful collusion attack is allowed. We provide a novel construction for the location update message, and propose several enhancements, to achieve the functional and security goals of RescueMe.","Privacy,
Planning,
Cryptography,
Servers,
Redundancy,
Sun"
Adaptive transmission policies for energy harvesting wireless nodes in fading channels,"In this paper, we consider a single-user communication system, where an energy harvesting transmitter communicates with a receiver over a fading wireless channel. We design adaptive transmission policies that adapt to the random energy arrivals at the transmitter and random fluctuations in the channel, in order to maximize the average number of bits transmitted by a finite deadline T. We solve for the optimum transmission scheme using stochastic dynamic programming. This optimal solution does not admit a closed form expression and is computationally expensive. We then propose several suboptimal event based adaptive transmission policies that react to the changes in energy arrivals and fading states. We provide extensive simulation results that compare the performances of the optimal and proposed simpler solutions.","Fading,
Batteries,
Transmitters,
Throughput,
Energy harvesting,
Dynamic programming,
Energy states"
Archive management for dynamic multi-objective optimisation problems using vector evaluated particle swarm optimisation,"Many optimisation problems have more than one objective that are in conflict with one another and that change over time, called dynamic multi-objective problems. To solve these problems an algorithm must be able to track the changing Pareto Optimal Front (POF) over time and find a diverse set of solutions. This requires detecting that a change has occurred in the environment and then responding to the change. Responding to the change also requires to update the archive of non-dominated solutions that represents the found POF. This paper discusses various ways to manage the archive solutions when a change occurs in the environment. Furthermore, two new benchmark functions are presented where the POF is discontinuous. The dynamic Vector Evaluation Particle Swarm Optimisation (DVEPSO) algorithm is tested against a variety of benchmark function types and its performance is compared against three state-of-the-art DMOO algorithms.","Heuristic algorithms,
Optical fibers,
Measurement,
Benchmark testing,
Optimization,
Particle swarm optimization,
Algorithm design and analysis"
High temperature packaging of 50 kW three-phase SiC power module,"Research on silicon carbide (SiC) power electronics has shown their advantages in high temperature and high efficiency applications. This paper presents a SiC JFET based, 200°C, 50 kW three-phase inverter module and evaluates its electrical performance. With 1200 V, 100 A rating of the module, each switching element is composed of four paralleled SiC JFETs (1200 V/25 A each) and two anti parallel SiC Shottky Barrier Diodes (SBDs). The substrate layout inside the module is designed to reduce package parasitics. Then, experimental static characteristics of the module are obtained over a wide range of temperature, and low on-state resistance is shown up to 200°C. A gate driver, with different turn-on, turn-off gate resistances and RCD network, is designed to optimize the switching performances. The module is verified to have low power loss, fast switching characteristics at 650 V dc bus voltage, 60 A drain current, in both simulation and experiments. Finally, switching time and losses, obtained from simulation and experiment, are compared.","Silicon carbide,
JFETs,
Logic gates,
Switches,
Temperature,
Multichip modules,
Resistance"
Per panel photovoltaic energy extraction with multilevel output DC-DC switched capacitor converters,"Switched capacitor multilevel output DC-DC converters are evaluated as panel integrated modules in a solar maximum power point tracking system. The recommended system includes a central input current-controlled ripple port inverter. Potential benefits include per panel MPPT without inter-panel communication, electrolytic capacitors or per panel magnetics. Statistical methods are used to predict average tracking and conversion efficiencies. A particular implementation of the switched capacitor module is studied - the Marx converter. Average total efficiencies (tracking × conversion) greater than 93% are predicted for a simulated 510 W, 3 panel, DC-DC system.",
Numerical and Experimental Investigation of Grounding Electrode Impulse-Current Dispersal Regularity Considering the Transient Ionization Phenomenon,"This paper presents a numerical method, combined the finite element method in the spatial domain with the finite difference time domain, to calculate the transient impulse response of grounding systems considering the ionization phenomenon. In this numerical method, space-time variable soil resistivity is used to simulate the soil ionization phenomenon where soil resistivity is controlled according to its relationship with the local instantaneous value of the electric field and no a priori hypothesis on the geometrical shape of the ionized region around the electrodes is necessary. Based on the widely accepted principle of dimensional similarity, this paper makes simulated experimental investigations on the impulse-current dispersal regularity of grounding electrodes with various structures. The proposed numerical scheme is validated by comparing computed results with experimental results and simulation results in literature. Based on the measurement and simulation results, the impulse response regularity of grounding electrodes is discussed and the effect of ionization on human and installations safety is reported.",
The Effect of Eavesdroppers on Network Connectivity: A Secrecy Graph Approach,"This paper investigates the effect of eavesdroppers on network connectivity, using a wiretap model and percolation theory. The wiretap model captures the effect of eavesdroppers on link security. A link exists between two nodes only if the secrecy capacity of that link is positive. Network connectivity is defined in a percolation sense, i.e., connectivity exists if an infinite connected component exists in the corresponding secrecy graph. We consider uncertainty in location of eavesdroppers, which is modeled directly at the network level as correlated failures in the secrecy graph. Our approach attempts to bridge the gap between physical layer security under uncertain channel state information and network level connectivity under secrecy constraints. For square and triangular lattice secrecy graphs, we obtain bounds on the percolation threshold, which is the critical value of the probability of occurrence of an eavesdropper, above which network connectivity does not exist. For Poisson secrecy graphs, degree distribution and mean value of upper and lower bounds on node degree are obtained. Further, inner and outer bounds on the achievable region for network connectivity are obtained. Both analytic and simulation results show that uncertainty in location of eavesdroppers has a dramatic effect on network connectivity in a secrecy graph.","Lattices,
Uncertainty,
Upper bound,
USA Councils,
Electronic mail,
Security"
Web-based real-time remote monitoring for pervasive healthcare,"The goal of the CARA (Context-Aware Real-time Assistant) healthcare architecture is to enable improved healthcare through the intelligent use of wireless remote monitoring of patient vital signs, supplemented by rich contextual information. One of its applications currently being deployed is the remote live monitoring of a patient by a healthcare professional. The vital signs are monitored using a wireless BAN based on sensors that can monitor position in space, ECG, blood pressure, and blood oxygenation. A design goal of ubiquitous access means that all communications are performed using recent web technologies, thereby minimizing issues with firewalls and facilitating remote ease of access. The only tool required for this application is a web browser with the commonly-available Adobe Flash plug-in installed. Thus remote monitoring, independent of geographic location, is possible form any computer or suitable smartphone. Important aspects of this application include: inter-visibility between patient and caregiver; real-time interactive medical consultation; and replay, review and annotation of the remote consultation by the medical professional. The annotation of significant parts of the multi-modal monitored signals by the medical professional provides the basis for the automated intelligent analysis of the CARA system. The paper discusses the application in the context of the overall CARA healthcare architecture, and presents results of some experiments using the application.",
Perceptually Guided Fast Compression of 3-D Motion Capture Data,"A time efficient compression technique, incorporating attention stimulating factors, for motion capture data is proposed. Compression ratios of 25:1 to 30:1 can be achieved with very little noticeable degradation in perceptual quality of animation. Experimental analysis shows that the proposed algorithm is much faster than comparable approaches using wavelets, thereby making our approach feasible for motion capture, transmission, and real-time synthesis on mobile devices, where processing power and memory capacity are limited.",
Toward a wireless charging for battery electric vehicles at traffic intersections,"In near future, Battery Electric Vehicles (BEVs) will become widely accepted and used. One of the main challenges of BEVs is their limited energy capacity. Current battery technologies require BEVs to make frequent trips, in comparison to traditional refuel, to charging stations for recharging. In this paper, we envision a new scheme for charging of BEV based on wireless charging. Our scheme exploits the frequent BEVs stops at traffic intersections to charge their batteries via wireless charging device. We study how to integrate control strategy at traffic intersections for maximizing charging while minimizing waiting delays. Simulation results are provided to show the effectiveness of proposed charging schemes.","Batteries,
Wireless communication,
Delay,
Electric vehicles,
Topology"
A prior-free revenue maximizing auction for secondary spectrum access,"Dynamic spectrum allocation has proven promising for mitigating the spectrum scarcity problem. In this model, primary users lease chunks of under-utilized spectrum to secondary users, on a short-term basis. Primary users may need financial motivations to share spectrum, since they assume costs in obtaining spectrum licenses. Auctions are a natural revenue generating mechanism to apply. Recent design on spectrum auctions make the strong assumption that the primary user knows the probability distribution of user valuations. We study revenue-maximizing spectrum auctions in the more realistic prior-free setting, when information on user valuations is unavailable. A two-phase auction framework is constructed. In phase one, we design a strategyproof mechanism that computes a subset of users with an interference-free spectrum allocation, such that the potential revenue in the second phase is maximized. A tailored payment scheme ensures truthful bidding at this stage. The selected users then participate in phase two, where we design a randomized competitive auction and prove its strategyproofness through the argument of bid independence. Employing probabilistic techniques, we prove that our auction generates a revenue that is at least 1/3 of the optimal revenue, improving the best known ratio of 1/4 proven for similar settings.","Cost accounting,
Resource management,
Interference,
Protocols,
Algorithm design and analysis,
Dynamic scheduling,
Economics"
Non-sequential structure from motion,"Prior work on multi-view structure from motion is dominated by sequential approaches starting from a single two-view reconstruction, then adding new images one by one. In contrast, we propose a non-sequential methodology based on rotational consistency and robust estimation using convex optimization. The resulting system is more robust with respect to (i) unreliable two-view estimations caused by short baselines, (ii) repetitive scenes with locally consistent structures that are not consistent with the global geometry and (iii) loop closing as errors are not propagated in a sequential manner. Both theoretical justifications and experimental comparisons are given to support these claims.","Cameras,
Quaternions,
Geometry,
Estimation,
Image reconstruction,
Three dimensional displays,
Noise"
Analysis of multiple cell upsets due to neutrons in SRAMs for a Deep-N-well process,"This work accounts for the single-bit and multiple-cell upset phenomena due to neutron strikes in highly scaled SRAMs implemented in a Deep-N-well process. 3D TCAD simulations are used to explain test results, upset mechanisms and implications for ECC.",
Categorizing software applications for maintenance,"Software repositories hold applications that are often categorized to improve the effectiveness of various maintenance tasks. Properly categorized applications allow stakeholders to identify requirements related to their applications and predict maintenance problems in software projects. Unfortunately, for different legal and organizational reasons the source code is often not available, thus making it difficult to automatically categorize binary executables of software applications. In this paper, we propose a novel approach in which we use Application Programming Interface (API) calls from third-party libraries as attributes for automatic categorization of software applications that use these API calls. API calls can be extracted from source code and more importantly, from the byte-code of applications, thus making automatic categorization approaches applicable to closed source repositories. We evaluate our approach along with other machine learning algorithms for software categorization on two large Java repositories: an open-source repository containing 3,286 projects and a closed-source one with 745 applications. Our contribution is twofold: not only do we propose a new approach that makes it possible to categorize software projects without any source code using a small number of API calls as attributes, but also we carried out the first comprehensive empirical evaluation of automatic categorization approaches.",
Granular Box Regression,"Granular computing (GrC) has gained increasing attention in the past decade. Although not uniquely defined, its basic idea is to approximate detailed machine-like information by a coarser presentation on a human-like level. Within granular computing, the mapping of continuous variables into intervals plays an important role. These intervals are often prerequisites for the formulation of linguistic variables. In this paper, we suggest a piecewise interval approximation and propose granular box regression. Its objective is to establish relationships between independent and dependent variables by multidimensional boxes. We interpret granular box regression as interval regression and show its potential for the extraction of fuzzy rules from data. In two experiments, we apply granular box regression to an artificial as well as to a real dataset in the field of finance and evaluate its properties.",
A Suitable Initialization Procedure for Speeding a Neural Network Job-Shop Scheduling,"Artificial neural network models have been successfully applied to solve a job-shop scheduling problem (JSSP) known as a Nonpolynomial (NP-complete) constraint satisfaction problem. Our main contribution is an improvement of the algorithm proposed in the literature. It consists in using a procedure optimizing the initial value of the starting time. The aim is to speed a Hopfield Neural Network (HNN) and therefore reduce the number of searching cycles. This new heuristic provides several advantages; mainly to improve the searching speed of an optimal or near optimal solution of a deterministic JSSP using HNN and reduce the makespan. Simulation results of the proposed method have been performed on various benchmarks and compared with current algorithms such as genetic algorithm, constraint satisfaction adaptive neural networks, simulated annealing, threshold accepting, flood method, and priority rules such as shortest processing time (SPT) to mention a few. As the simulation results show, and Brandts algorithm, combined with the proposed heuristic method, is efficient with respect to the resolution speed, quality of the solution, and the reduction of the computation time.",
A new design of the reversible subtractor circuit,"In [1] we have presented the reversible subtractor designs based on a new reversible TR gate (TR refers to Thapliyal Ranganathan). In [1] as the quantum gates implementation of the TR gate was not known, only the upper bound on the quantum cost of the reversible subtractors units were established. In this work, we present a new design of the reversible half subtractor based on the quantum gates implementation of the reversible TR gate. The reversible TR gate is designed from 2×2 quantum gates such as CNOT and Controlled-V and Controlled-V+ gates. The design of the proposed reversible half subtractor is shown to be better than the design presented in [2], [1] in terms of the quantum cost and delay while maintaining the minimum number of garbage outputs. Further, we present a new design of the reversible full subtractor based on the proposed quantum gates implementation of the TR gate. The proposed reversible full subtractor is optimized in terms of quantum cost, delay and garbage outputs by utilizing the identity property of V and V+ reversible gates. The proposed reversible full subtractor is shown to be better than the existing design reported in [3], [1]. The reversible subtractors proposed in this work will be useful in a number of digital signal processing applications.","Logic gates,
Delay,
Quantum computing,
Equations,
Vectors,
Logic circuits,
Upper bound"
Design and Testing of a 10-MJ Electromagnetic Launch Facility,"For basic research on electromagnetic launch technology, the Beijing Institute of Special Electromechanical Technology has initiated a program focusing on the design and testing of a 10-MJ electromagnetic launcher facility with the cooperation of Nanjing University and the Institute of Electrical Engineering, Chinese Academy of Sciences. The facility will consist of a 10-MJ prime energy, a 6-m-long railgun, and a control system. A 3.2-MJ pulse power unit (PPU) with 32 100-kJ modular PFN units has been completed and tested, and its prime energy can be easily extended to 10 MJ. A 6-m-long railgun has been built, which can be easily cut into a 4-m-long railgun by which many firings have been done with the new PPU. Construction and testing of the whole facility are being continued.",
Collaborative Filtering with Personalized Skylines,"Collaborative filtering (CF) systems exploit previous ratings and similarity in user behavior to recommend the top-k objects/records which are potentially most interesting to the user assuming a single score per object. However, in various applications, a record (e.g., hotel) maybe rated on several attributes (value, service, etc.), in which case simply returning the ones with the highest overall scores fails to capture the individual attribute characteristics and to accommodate different selection criteria. In order to enhance the flexibility of CF, we propose Collaborative Filtering Skyline (CFS), a general framework that combines the advantages of CF with those of the skyline operator. CFS generates a personalized skyline for each user based on scores of other users with similar behavior. The personalized skyline includes objects that are good on certain aspects, and eliminates the ones that are not interesting on any attribute combination. Although the integration of skylines and CF has several attractive properties, it also involves rather expensive computations. We face this challenge through a comprehensive set of algorithms and optimizations that reduce the cost of generating personalized skylines. In addition to exact skyline processing, we develop an approximate method that provides error guarantees. Finally, we propose the top-k personalized skyline, where the user specifies the required output cardinality.",
Shape-from-shading under complex natural illumination,"We present a shape-from-shading algorithm for Lambertian surfaces of uniform but unknown albedo, illuminated by unknown, arbitrarily complex environment lighting. Our approach is based on a first order spherical harmonic approximation to the reflectance map. This is estimated from the image using surface normals interpolated from boundary points. The shape-from-shading step minimises local brightness error and an edge sensitive smoothness constraint. This involves the solution of a linear least squares problem with a quadratic equality constraint, the global optimum of which can be found using the method of Lagrange multipliers. We demonstrate the performance of the algorithm on complex objects rendered under realworld illumination.","Lighting,
Shape,
Harmonic analysis,
Image color analysis,
Approximation methods,
Mathematical model,
Equations"
A globally asymptotically stable polynomial vector field with no polynomial Lyapunov function,"We give a simple, explicit example of a two-dimensional polynomial vector field that is globally asymptotically stable but does not admit a polynomial Lyapunov function.",
Micromachining of Optical Fibers Using Selective Etching Based on Phosphorus Pentoxide Doping,"This paper presents a maskless micromachining process that can reform or reshape a section of an optical fiber into a complex 3-D photonic microstructure. This proposed micromachining process is based on the etching rate control achieved by the introduction of phosphorus pentoxide into silica glass through standard fiber manufacturing technology. Regions within a fiber cross section doped with phosphorus pentoxide can etch up to 100 times faster than pure silica when exposed to hydrofluoric acid. Various new photonic devices can be effectively and economically created by design and production of purposely doped fibers that are spliced at the tip or in-between standard lead-in fibers, followed by etching into a final structure.",
Diagonal Stability on Cactus Graphs and Application to Network Stability Analysis,"A square matrix E is said to be diagonally stable if there exists a diagonal matrix D >; 0 satisfying DE+ETD <; 0 . This notion has been instrumental in recent studies on stability of interconnected system models in communication and biological networks, in which the subsystems satisfy passivity properties and the matrix E combines this passivity information with the interconnection structure. This paper presents a necessary and sufficient condition for diagonal stability when the digraph describing the network conforms to a “cactus” structure, which means that a pair of distinct simple circuits in the graph have at most one common vertex. In the special case of a single circuit, this diagonal stability test recovers the “secant criterion” that was recently derived for cyclic networks. The paper then incorporates the new diagonal stability test in network stability analysis where the diagonal entries of the matrix D serve as weights in a Lyapunov function constructed from storage functions that verify passivity properties of the components. Finally, the paper illustrates this stability test on examples motivated by gene networks and population dynamics.",
High-quality image restoration from partial random samples in spatial domain,"In this paper, a novel algorithm for high-quality image restoration is proposed. The contributions of this work are two-fold. First, a new form of minimization function for solving image inverse problems is formulated via combining local total variation model and nonlocal adaptive 3-D sparse representation model as regularizers under the regularization- based framework. Second, a new Split-Bregman based iterative algorithm is developed to solve the above optimization problem efficiently associated with proved theoretical convergence property. Experimental results on image restoration from partial random samples have shown that the proposed algorithm achieves significant performance improvements over the current state-of-the-art schemes and exhibits nice convergence property.","Image restoration,
Convergence,
Adaptation models,
Solid modeling,
Minimization,
Three dimensional displays,
Optimization"
ACP-Based Control and Management of Urban Rail Transportation Systems,"Urban rail transportation (URT) has long become the preferred public transportation choice for major metropolitan areas such as New York, London, Paris, Moscow, Tokyo, and Beijing. The highest daily record for Beijing's URT reached 5.71 million passenger trips in 2010, which makes the network extremely crowded in rush hours. To accommodate the increasing demand for URT, the service frequencies have been increased tremendously. To address these safety, efficiency, and reliability issues, the paper presents a novel parallel system for URT operations that uses the concept of parallel system and computational experiments based on artificial systems (ACP). The parallel URT system can analyze and facilitate passenger-flow management, vehicle scheduling, and other operational issues while considering human-related, environmental, and other social and economical factors.",
Time and space efficient spectral clustering via column sampling,"Spectral clustering is an elegant and powerful approach for clustering. However, the underlying eigen-decomposition takes cubic time and quadratic space w.r.t. the data set size. These can be reduced by the Nyström method which samples only a subset of columns from the matrix. However, the manipulation and storage of these sampled columns can still be expensive when the data set is large. In this paper, we propose a time- and space-efficient spectral clustering algorithm which can scale to very large data sets. A general procedure to orthogonalize the approximated eigenvectors is also proposed. Extensive spectral clustering experiments on a number of data sets, ranging in size from a few thousands to several millions, demonstrate the accuracy and scalability of the proposed approach. We further apply it to the task of image segmentation. For images with more than 10 millions pixels, this algorithm can obtain the eigenvectors in 1 minute on a single machine.",
Noninvasive Biological Sensor System for Detection of Drunk Driving,"Systems capable of monitoring the biological condition of a driver and issuing warnings during instances of drowsiness have recently been studied. Moreover, many researchers have reported that biological signals, such as brain waves, pulsation waves, and heart rate, are different between people who have and have not consumed alcohol. Currently, we are developing a noninvasive system to detect individuals driving under the influence of alcohol by measuring biological signals. We used the frequency time series analysis to attempt to distinguish between normal and intoxicated states of a person as the basis of the sensing system.",
Arrowhead-Shaped Microelectrodes Fabricated on a Flexible Substrate for Enhancing the Spherical Conformity of Retinal Prostheses,"In this paper, a novel microelectrode array (MEA), with varying arrowhead shapes, is fabricated and evaluated for retinal prostheses. The proposed MEA has a total of 199 arrowhead-shaped microelectrodes, with heights ranging from 42 to 123.5 μm. This height variation allows each microelectrode to contact the spherical eyeball conformably and to approach the stimulation target retinal cells very closely. The fabricated MEAs are implanted in rabbit eyes. The physical contact of the MEA is evaluated using optical coherent tomography (OCT) images, which show that the implanted MEA makes an excellent conformal contact with the spherically shaped retinal layers. These OCT images also exhibit good biocompatibility of the implanted MEA. The evaluation results show that the proposed MEA has a high potential for clinical applications. Our ongoing project is aimed at clinical application in three years. [2010-0037].",
Wide-baseline stereo for face recognition with large pose variation,"2-D face recognition in the presence of large pose variations presents a significant challenge. When comparing a frontal image of a face to a near profile image, one must cope with large occlusions, non-linear correspondences, and significant changes in appearance due to viewpoint. Stereo matching has been used to handle these problems, but performance of this approach degrades with large pose changes. We show that some of this difficulty is due to the effect that foreshortening of slanted surfaces has on window-based matching methods, which are needed to provide robustness to lighting change. We address this problem by designing a new, dynamic programming stereo algorithm that accounts for surface slant. We show that on the CMU PIE dataset this method results in significant improvements in recognition performance.","Face recognition,
Face,
Lighting,
Heuristic algorithms,
Dynamic programming,
Cameras,
Solid modeling"
Traffic and Interference Aware Scheduling for Multiradio Multichannel Wireless Mesh Networks,This paper proposes a scheduling scheme for wireless mesh networks that are capable of multiple channel access and equipped with multiple radio interfaces. The proposed scheme is interference and traffic aware in that it increases the overall achievable throughput of the network by eliminating the interference between the wireless mesh routers and maximizes the satisfaction ratios of all active sessions by accounting for the sessions' data rate requirements. Simulation results show that the proposed scheme outperforms the Tabu-based scheduling scheme and yields good tradeoffs between the achievable throughput of the network and the satisfaction ratios of the sessions.,"Throughput,
Interference constraints,
Wireless communication,
Scheduling,
Receivers,
Ad hoc networks"
Towards preserving privacy in participatory sensing,"With the abundance and ubiquity of mobile devices, a new class of applications is emerging, called participatory sensing (PS), where people can contribute data (e.g., images, video) collected by their mobile devices to central data servers. However, privacy concerns are becoming a major impediment in the success of many participatory sensing systems. While several privacy preserving techniques exist in the context of conventional location-based services, they are not directly applicable to the PS systems because of the extra information that the PS systems can collect from their participants. In this paper, we formally define the problem of privacy in PS systems and identify its unique challenges assuming an un-trusted central data server model. We propose PiRi, a privacy-aware framework for PS systems, which enables participation of the users without compromising their privacy.",
Pavement pothole detection and severity measurement using laser imaging,"Over the years, Automated Image Analysis Systems (AIAS) have been developed for pavement surface analysis and management. The cameras used by most of the AIAS are based on Charge-Coupled Device (CCD) image sensors where a visible ray is projected. However, the quality of the images captured by the CCD cameras was limited by the inconsistent illumination and shadows caused by sunlight. To enhance the CCD image quality, a high-power artificial lighting system has been used, which requires a complicated lighting system and a significant power source. In this paper, we will introduce an efficient and more economical approach for pavement distress inspection by using laser imaging. After the pavement images are captured, regions corresponding to potholes are represented by a matrix of square tiles and the estimated shape of the pothole is determined. The vertical, horizontal distress measures, the total number of distress tiles and the depth index information are calculated providing input to a three-layer feed-forward neural network for pothole severity and crack type classification. The proposed analysis algorithm is capable of enhancing the pavement image, extracting the pothole from background and analyzing its severity. To validate the system, actual pavement pictures were taken from pavements both in highway and local roads. The experimental results demonstrated that the proposed model works well for pothole and crack detection.","Tiles,
Lasers,
Pixel,
Laser noise,
Roads,
Indexes"
MHS: A Multimedia System for Improving Medication Adherence in Elderly Care,"Due to its proven capability in customizing information according to the patients' needs, multimedia has been regarded as a promising technology for home healthcare. In this paper, we present our study on improving medication adherence of the elderly with the support of ubiquitous multimedia services. A multimedia healthcare system (MHS) is built based on a comprehensive understanding of the requirements of the elderly care. It provides the continuous medication monitoring, context aware prompting, adaptive multimedia presentation, and flexible medicine management. The experimental results show that the MHS can improve the medication adherence of the elderly effectively.",
Compressive topology identification of interconnected dynamic systems via Clustered Orthogonal Matching Pursuit,"In this paper, we consider topology identification of large-scale interconnected dynamical systems. The system topology under study has the structure of a directed graph. Each edge of the directed network graph represents a Finite Impulse Response (FIR) filter with a possible transport delay. Each node is a summer, whose inputs are the signals from the incoming edges, while the output of the summer is sent to outgoing edges. Edges of the graph can be of different unknown orders and delays. Both the graph topology and the FIR filters and delays that make up the edges are unknown. We aim to do the topology identification from the smallest possible number of node observations when there is limited data available and for this reason, we call this problem Compressive Topology Identification (CTI). Inspired by Compressive Sensing (CS) which is a recent paradigm in signal processing for sparse signal recovery, we show that in cases where network interconnections are suitably sparse (i.e., the network contains sufficiently few links), it is possible to perfectly identify the network topology along with the filter orders and delays from small numbers of node observations, even though this leaves an apparently ill-conditioned identification problem. The main technical novelty of our approach is in casting the identification problem as the recovery of a clustered-sparse signal z ∈ RN from the measurements b = Az ∈ RM with M <; N, where the measurement matrix A is a block-concatenation of Toeplitz matrices. To this end, we introduce a greedy algorithm called Clustered Orthogonal Matching Pursuit (COMP) that tackles the problem of recovering clustered-sparse signals from few measurements. In a clustered-sparse model, in contrast to block-sparse models, there is no prior knowledge of the locations or the sizes of the clusters. We discuss the COMP algorithm and support our discussions with simulations.","Matching pursuit algorithms,
Clustering algorithms,
Topology,
Delay,
Network topology,
Finite impulse response filter,
Algorithm design and analysis"
Wireless LAN with medical-grade QoS for e-healthcare,"In this paper, we study the problem of how to design a medical-grade wireless local area network (WLAN) for healthcare facilities. First, unlike the IEEE 802.11e MAC, which categorizes traffic primarily by their delay constraints, we prioritize medical applications according to their medical urgency. Second, we propose a mechanism that can guarantee absolute priority to each traffic category, which is critical for medical-grade quality of service (QoS), while the conventional 802.11e MAC only provides relative priority to each traffic category. Based on absolute priority, we focus on the performance of real-time patient monitoring applications, and derive the optimal contention window size that can significantly improve the throughput performance. Finally, for proper performance evaluation from a medical viewpoint, we introduce the weighted diagnostic distortion (WDD) as a medical QoS metric to effectively measure the medical diagnosability by extracting the main diagnostic features of medical signal. Our simulation result shows that the proposed mechanism, together with medical categorization using absolute priority, can significantly improve the medical-grade QoS performance over the conventional IEEE 802.11e MAC.","Medical diagnostic imaging,
Medical services,
Quality of service,
Wireless communication,
IEEE 802.11e Standard,
Wireless LAN,
Biomedical equipment"
A Distributed Controller for Managing Speculative Functional Units in High Level Synthesis,"Speculative functional units (SFUs) are arithmetic functional units that operate using a predictor for the carry signal. The carry prediction helps to shorten the critical path of the functional unit. The average case performance of these units is determined by the hit rate of the prediction. In case of mispredictions, the SFUs need to be coordinated by the datapath control mechanism to perform corrections and to maintain the datapath in the correct state. Devising a control mechanism for correcting mispredictions without adversely impacting overall performance is the most important challenge. In this paper, we present techniques for designing a datapath controller for seamless deployment of SFUs in high level synthesis. We have developed two techniques based on two main control paradigms: centralized and distributed control. The centralized approach stops the execution of the entire datapath for each misprediction and resumes execution once the correct value of the carry is known. The distributed approach decouples the functional unit suffering from the misprediction from the rest of the datapath. Hence, it allows the remainder of the functional units to carry on execution and be at different scheduling states at different times. We tested datapaths utilizing both linear structures and logarithmic structures for speculative arithmetic functional units. Our results show that it is possible to reduce execution time by as much as 38% (33% on average) for linear structures and by as much as 37.2% (25% on average) for logarithmic structures.",
Year,,
Exploratory Strategies in Haptic Softness Discrimination Are Tuned to Achieve High Levels of Task Performance,"Haptic perception essentially depends on the executed exploratory movements. It has been speculated that spontaneously executed movements are optimized for the computation of associated haptic properties. We investigated to what extent people strategically execute movements that are tuned for softness discrimination of objects with deformable surfaces. In Experiment 1, we investigated how movement parameters depend on expected stimulus compliance. In a discrimination task, we measured exploratory forces for less compliant (hard) stimuli and for more compliant (soft) stimuli. In Experiment 2, we investigated whether exploratory force also depends on the expected compliance difference between the two stimuli. The results indicate that participants apply higher forces when expecting harder objects as compared to softer objects, and they apply higher forces for smaller compliance differences than for larger ones. Experiment 3 examined how applied force influences differential sensitivity for softness as assessed by just noticeable differences (JNDs). For soft stimuli, JNDs did not depend on force. For hard stimuli, JNDs were “worse” (higher) if participants applied less force than they use naturally. We conclude that applying high force is a robust strategy to obtain high differential sensitivity, and that participants used this strategy if it was required for successful discrimination performance.","Perception,
Force measurement,
Haptic interfaces,
Particle measurements,
Atmospheric measurements,
Behavioral science"
Language and compiler support for auto-tuning variable-accuracy algorithms,"Approximating ideal program outputs is a common technique for solving computationally difficult problems, for adhering to processing or timing constraints, and for performance optimization in situations where perfect precision is not necessary. To this end, programmers often use approximation algorithms, iterative methods, data resampling, and other heuristics. However, programming such variable accuracy algorithms presents difficult challenges since the optimal algorithms and parameters may change with different accuracy requirements and usage environments. This problem is further compounded when multiple variable accuracy algorithms are nested together due to the complex way that accuracy requirements can propagate across algorithms and because of the size of the set of allowable compositions. As a result, programmers often deal with this issue in an ad-hoc manner that can sometimes violate sound programming practices such as maintaining library abstractions. In this paper, we propose language extensions that expose trade-offs between time and accuracy to the compiler. The compiler performs fully automatic compile-time and installtime autotuning and analyses in order to construct optimized algorithms to achieve any given target accuracy. We present novel compiler techniques and a structured genetic tuning algorithm to search the space of candidate algorithms and accuracies in the presence of recursion and sub-calls to other variable accuracy code. These techniques benefit both the library writer, by providing an easy way to describe and search the parameter and algorithmic choice space, and the library user, by allowing high level specification of accuracy requirements which are then met automatically without the need for the user to understand any algorithm-specific parameters. Additionally, we present a new suite of benchmarks, written in our language, to examine the efficacy of our techniques. Our experimental results show that by relaxing accuracy requirements, we can easily obtain performance improvements ranging from 1.1× to orders of magnitude of speedup.","Accuracy,
Transforms,
Libraries,
Signal processing algorithms,
Approximation algorithms,
Algorithm design and analysis,
Runtime"
Spread Spectrum Visual Sensor Network Resource Management Using an End-to-End Cross-Layer Design,"In this paper, we propose an approach to manage network resources for a direct sequence code division multiple access (DS-CDMA) visual sensor network where nodes monitor scenes with varying levels of motion. It uses cross-layer optimization across the physical layer, the link layer, and the application layer. Our technique simultaneously assigns a source coding rate, a channel coding rate, and a power level to all nodes in the network based on one of two criteria that maximize the quality of video of the entire network as a whole, subject to a constraint on the total chip rate. One criterion results in the minimal average end-to-end distortion amongst all nodes, while the other criterion minimizes the maximum distortion of the network. Our experimental results demonstrate the effectiveness of the cross-layer optimization.","Source coding,
Channel coding,
Visualization,
Bit rate,
Multiaccess communication,
Optimization,
PSNR"
Toward Realistic Simulation of Intervehicle Communication,"The quality of intelligent transportation systems strongly depends on the underlying communication protocols and techniques. In this article, we discuss the current state of the art, trends, and open problems in the area of simulation techniques used to study intervehicle communication (IVC). Here, we touch on a broad range of topics but focus on three aspects that have a strong influence on the degree of realism and hence the reliability of simulation results: the need to integrate microscopic mobility models, the used evaluation metrics, and the impact of human driver behavior on a macroscopic scale. We study and discuss the state of the art of simulation-based performance evaluation of IVC protocols and applications. In the scope of this article, we concentrate on the most recent advances and findings by outlining selected models, techniques, and issues that are specifically related to IVC, with a strong focus on aspects beyond network simulation issues. The main objective is to determine the degree to which available simulation techniques produce realistic results.",
Beyond Timbral Statistics: Improving Music Classification Using Percussive Patterns and Bass Lines,"This paper discusses a new approach for clustering sequences of bar-long percussive and bass-line patterns in audio music collections and its application to genre classification. Many musical genres and styles are characterized by two kinds of distinct representative patterns, i.e., percussive patterns and bass-line patterns. So far, in most automatic genre classification systems, rhythmic and bass melody information has not been effectively used. In order to extract bar-long unit rhythmic patterns for a music collection, we propose a clustering method based on one-pass dynamic programming and k-means clustering. For clustering bass-line patterns, a method based on k -means clustering capable of handling pitch-shifting is proposed. After extracting these two fundamental kinds of patterns for each style/genre, feature vectors which are suitable for representing information about the patterns are proposed for supervised learning. Experimental results show that the automatically calculated rhythmic pattern information and bass pattern information can be used to effectively classify musical genre/style and improve upon current approaches based on timbral features.",
Prototyping an automatic notification scheme for traffic accidents in vehicular networks,"The new communication technologies integrated into the automotive sector offer an opportunity for better assistance to people injured in traffic accidents, reducing the response time of emergency services, and increasing the information they have about the incident. Determining more accurately the human and material resources required for each particular accident could significantly reduce the number of victims. The proposed system requires each vehicle to be endowed with an On-Board Unit responsible for detecting and reporting accident situations to an external Control unit that estimates its severity, allocating the necessary resources for its assistance. The development of a prototype based on off-the-shelf devices shows that this system could reduce notably the time needed to deploy the emergency services after an accident takes place.","Accidents,
Vehicles,
Prototypes,
Acceleration,
Sensors,
Copper,
Emergency services"
Improving automated documentation to code traceability by combining retrieval techniques,"Documentation written in natural language and source code are two of the major artifacts of a software system. Tracking a variety of traceability links between software documentation and source code assists software developers in comprehension, efficient development, and effective management of a system. Automated traceability systems to date have been faced with a major open research challenge: how to extract these links with both high precision and high recall. In this paper we introduce an approach that combines three supporting techniques, Regular Expression, Key Phrases, and Clustering, with a Vector Space Model (VSM) to improve the performance of automated traceability between documents and source code. This combination approach takes advantage of strengths of the three techniques to ameliorate limitations of VSM. Four case studies have been used to evaluate our combined technique approach. Experimental results indicate that our approach improves the performance of VSM, increases the precision of retrieved links, and recovers more true links than VSM alone.","Documentation,
Vectors,
Clustering algorithms,
Unified modeling language,
Software systems,
Engines"
Localized Multiple Kernel Learning for Realistic Human Action Recognition in Videos,"Realistic human action recognition in videos has been a useful yet challenging task. Video shots of same actions may present huge intra-class variations in terms of visual appearance, kinetic patterns, video shooting, and editing styles. Heterogeneous feature representations of videos pose another challenge on how to effectively handle the redundancy, complementariness and disagreement in these features. This paper proposes a localized multiple kernel learning (L-MKL) algorithm to tackle the issues above. L-MKL integrates the localized classifier ensemble learning and multiple kernel learning in a unified framework to leverage the strengths of both. The basis of L-MKL is to build multiple kernel classifiers on diverse features at subspace localities of heterogeneous representations. L-MKL integrates the discriminability of complementary features locally and enables localized MKL classifiers to deliver better performance in its own region of expertise. Specifically, L-MKL develops a locality gating model to partition the input space of heterogeneous representations to a set of localities of simpler data structure. Each locality then learns its localized optimal combination of Mercer kernels of heterogeneous features. Finally, the gating model coordinates the localized multiple kernel classifiers globally to perform action recognition. Experiments on two datasets show that the proposed approach delivers promising performance.","Kernel,
Classification algorithms,
Videos,
Humans,
Computational modeling,
Training,
Support vector machines"
"Real-time preprocessing for dense 3-D range imaging on the GPU: Defect interpolation, bilateral temporal averaging and guided filtering","Recent advances in range imaging (RI) have enabled dense 3-D scene acquisition in real-time. However, due to physical limitations and the underlying range sampling principles, range data are subject to noise and may contain invalid measurements. Hence, data preprocessing is a prerequisite for practical applications but poses a challenge with respect to real-time constraints. In this paper, we propose a generic and modality-independent pipeline for efficient RI data preprocessing on the graphics processing unit (GPU). The contributions of this work are efficient GPU implementations of normalized convolution for the restoration of invalid measurements, bilateral temporal averaging for dynamic scenes, and guided filtering for edge-preserving denoising. Furthermore, we show that the transformation from range measurements to 3-D world coordinates can be computed efficiently on the GPU. The pipeline has been evaluated on real data from a Time-of-Flight sensor and Microsoft's Kinect. In a run-time performance study, we show that for VGA-resolution data, our preprocessing pipeline runs at ~100 fps on an off-the-shelf consumer GPU.",
Supporting Scalable and Adaptive Metadata Management in Ultralarge-Scale File Systems,"This paper presents a scalable and adaptive decentralized metadata lookup scheme for ultralarge-scale file systems (more than Petabytes or even Exabytes). Our scheme logically organizes metadata servers (MDSs) into a multilayered query hierarchy and exploits grouped Bloom filters to efficiently route metadata requests to desired MDSs through the hierarchy. This metadata lookup scheme can be executed at the network or memory speed, without being bounded by the performance of slow disks. An effective workload balance method is also developed in this paper for server reconfigurations. This scheme is evaluated through extensive trace-driven simulations and a prototype implementation in Linux. Experimental results show that this scheme can significantly improve metadata management scalability and query efficiency in ultralarge-scale storage systems.","Large-scale systems,
File systems,
Filters,
Network servers,
Scalability,
Throughput,
File servers,
Computer science,
Broadcasting,
Virtual prototyping"
Instabilities in Spin-Polarized Vertical-Cavity Surface-Emitting Lasers,"We report a first comprehensive theoretical analysis of optically pumped spin-polarized vertical-cavity surface-emitting lasers, which combines the spin-flip model with the largest Lyapunov exponent technique to determine regions of stability and instability. The dependence of these regions on a wide range of fundamental device parameters is investigated, and results were presented in a new form of maps of the polarization versus the magnitude of the optical pump. We also reveal the importance of considering both the birefringence rate and the linewidth enhancement factor when engineering a device for high-frequency applications.","Vertical cavity surface emitting lasers,
Mathematical model,
Numerical stability,
Stability analysis,
Oscillators,
Laser stability,
Optical pumping"
Two-dimensional manipulation of micro particles by acoustic radiation pressure in a heptagon cell,"An acoustic particle manipulation system is presented, using a flexible printed circuit board formed into a regular heptagon. It is operated at 4 MHz and has a side dimension of 10 mm. The heptagonal geometry was selected for its asymmetry, which tends to reduce standing wave behavior. This leads to the possibility of having fine control over the acoustic field by varying the output phases of the transducer elements. Configurations with two and three active transducers are demonstrated experimentally. It is shown that with two transducers, the particles align along straight lines, the position of which can be moved by varying the relative excitation phases of the two transducers. With three active transducers, hexagonal-shaped patterns are obtained that can also be moved, again according to the phase of the excitation signals. Huygens' principle-based simulations were used to investigate the resultant pressure distributions. Good agreement was achieved between these simulations and both Schlieren imaging and particle manipulation observations.","Transducers,
Acoustics,
Acoustic beams,
Reflection,
Flexible printed circuits,
Charge carrier processes,
Interference"
Adaptive Imaging for Lesion Detection Using a Zoom-in PET System,"Positron emission tomography (PET) has become a leading modality in molecular imaging. Demands for further improvements in spatial resolution and sensitivity remain high with growing number of applications. In this paper we present a novel PET system design that integrates a high-resolution depth-of-interaction (DOI) detector into an existing PET system to obtain higher-resolution and higher-sensitivity images in a target region around the face of the high-resolution detector. A unique feature of the proposed PET system is that the high-resolution detector can be adaptively positioned based on the detectability or quantitative accuracy of a feature of interest. This paper focuses on the signal-known-exactly, background-known-exactly (SKE-BKE) detection task. We perform theoretical analysis of lesion detectability using computer observers, and then develop methods that can efficiently calculate the optimal position of the high-resolution detector that maximizes the lesion detectability. We simulated incorporation of a high-resolution DOI detector into the microPET II scanner. Quantitative results verified that the new system has better performance than the microPET II scanner in terms of spatial resolution and lesion detectability, and that the optimal position for lesion detection can be reliably predicted by the proposed method.","Lesions,
Positron emission tomography,
Detectors,
Face detection,
Spatial resolution,
High-resolution imaging,
Molecular imaging,
Computer vision,
Signal detection,
Performance analysis"
CLASH: Climbing vertical loose cloth,"CLASH is a 10cm, 15g robot capable of climbing vertical loose-cloth surfaces at 15 cm per second. The robot has a single actuator driving its six legs which are equipped with novel passive foot mechanisms to facilitate smooth engagement and disengagement of spines. These foot mechanisms are designed to be used on penetrable surfaces and offer improved tensile normal force generation during stance and reduced normal pull-off forces during retraction. Descended from the DASH hexapedal robot, CLASH features a redesigned transmission with a lower profile and improved dynamics for climbing. CLASH is the first known robot to climb loose vertical cloth and is able to climb surfaces when surface rigidity is not guaranteed.",
1-D Transforms for the Motion Compensation Residual,"Transforms used in image coding are also commonly used to compress prediction residuals in video coding. Prediction residuals have different spatial characteristics from images, and it is useful to develop transforms that are adapted to prediction residuals. In this paper, we explore the differences between the characteristics of images and motion compensated prediction residuals by analyzing their local anisotropic characteristics and develop transforms adapted to the local anisotropic characteristics of these residuals. The analysis indicates that many regions of motion compensated prediction residuals have 1-D anisotropic characteristics and we propose to use 1-D directional transforms for these regions. We present experimental results with one example set of such transforms within the H.264/AVC codec and the results indicate that the proposed transforms can improve the compression efficiency of motion compensated prediction residuals over conventional transforms.","Mathematical model,
Correlation,
Image edge detection,
Image coding,
Discrete wavelet transforms,
Discrete cosine transforms"
A 1.2-A Buck-Boost LED Driver With On-Chip Error Averaged SenseFET-Based Current Sensing Technique,"This paper presents circuit techniques to improve the efficiency of high-current LED drivers. An error-averaged, senseFET-based current sensing technique is used to regulate the LED current accurately. Because the proposed scheme eliminates the series current-regulation element present in all conventional LED drivers, it greatly improves efficiency and reduces cost. The converter operates in three different operating modes, namely buck, buck-boost, and boost modes, and achieves high efficiency over the entire Li-Ion battery range (3-5.5 V). Fabricated in 0.5-μm CMOS process, the prototype occupies an active area of 5 mm2. At 1.2-A LED current, the driver achieves an efficiency improvement of over 13% compared to current-regulation-element-based LED drivers. Measured LED current accuracy is better than 2.8% over the entire range of the battery and its standard deviation measured across seven devices is less than 1.6%. The peak efficiencies are 90.7% and 86% at 600-and 1200-mA currents, respectively.",
Scale and object aware image retargeting for thumbnail browsing,"Many image retargeting algorithms, despite aesthetically carving images smaller, pay limited attention to image browsing tasks where tiny thumbnails are presented. When applying traditional retargeting methods for generating thumbnails, several important issues frequently arise, including thumbnail scales, object completeness and local structure smoothness. To address these issues, we propose a novel image retargeting algorithm, Scale and Object Aware Retargeting (SOAR), which has four components: (1) a scale dependent saliency map to integrate size information of thumbnails, (2) objectness (Alexe et al. 2010) for preserving object completeness, (3) a cyclic seam carving algorithm to guide continuous retarget warping, and (4) a thin-plate-spline (TPS) retarget warping algorithm that champions local structure smoothness. The effectiveness of the proposed algorithm is evaluated both quantitatively and qualitatively. The quantitative evaluation is conducted through an image browsing user study to measure the effectiveness of different thumbnail generating algorithms, followed by the ANOVA analysis. The qualitative study is performed on the RetargetMe benchmark dataset. In both studies, SOAR generates very promising performance, in comparison with state-of-the-art retargeting algorithms.",
Mobility-aware Ant Colony Optimization routing for vehicular ad hoc networks,"Vehicular Ad hoc Networks (VANETs) are a special type of Mobile Ad hoc Networks (MANETs), made by vehicles communicating among themselves, and by vehicles communicating to devices located in the margins of roads and highways. The main characteristic of a VANET is the high speed of network nodes - that can go up to 200 km/h -, and that impacts directly on the ability the network has to deliver data, given we might have a network formed for just a small amount of time. It has been shown in several works that ant-based routing can be successfully applied to both wired and wireless networks. This work proposes Ant Colony Optimization (ACO) procedures that take advantage of information available in vehicular networks - such as the vehicles' position and speed -, in order to design an ant-based algorithm that performs well in the dynamics of such networks. The authors have also adapted the Dynamic MANET On-demand (DYMO) routing protocol to make use of the ACO procedures proposed in this paper, and the resulting bio-inspired protocol, MAR-DYMO, had its performance evaluated in an urban scenario and compared against a few other routing protocols. The obtained results suggest that making use of environmental information can make ACO algorithms more suitable for routing in vehicular ad hoc networks.","Routing protocols,
Routing,
Vehicles,
Mathematical model,
Ad hoc networks,
Equations"
Feature-Based Statistical Analysis of Combustion Simulation Data,"We present a new framework for feature-based statistical analysis of large-scale scientific data and demonstrate its effectiveness by analyzing features from Direct Numerical Simulations (DNS) of turbulent combustion. Turbulent flows are ubiquitous and account for transport and mixing processes in combustion, astrophysics, fusion, and climate modeling among other disciplines. They are also characterized by coherent structure or organized motion, i.e. nonlocal entities whose geometrical features can directly impact molecular mixing and reactive processes. While traditional multi-point statistics provide correlative information, they lack nonlocal structural information, and hence, fail to provide mechanistic causality information between organized fluid motion and mixing and reactive processes. Hence, it is of great interest to capture and track flow features and their statistics together with their correlation with relevant scalar quantities, e.g. temperature or species concentrations. In our approach we encode the set of all possible flow features by pre-computing merge trees augmented with attributes, such as statistical moments of various scalar fields, e.g. temperature, as well as length-scales computed via spectral analysis. The computation is performed in an efficient streaming manner in a pre-processing step and results in a collection of meta-data that is orders of magnitude smaller than the original simulation data. This meta-data is sufficient to support a fully flexible and interactive analysis of the features, allowing for arbitrary thresholds, providing per-feature statistics, and creating various global diagnostics such as Cumulative Density Functions (CDFs), histograms, or time-series. We combine the analysis with a rendering of the features in a linked-view browser that enables scientists to interactively explore, visualize, and analyze the equivalent of one terabyte of simulation data. We highlight the utility of this new framework for combustion science; however, it is applicable to many other science domains.",
A microgrid energy management system for inducing optimal demand response,"This paper focuses on optimal operation schedule of a Microgrid that is interconnected to the power grid. We develop a mathematical model to compute the optimal operation schedule that embodies demand response. Integer Programming optimization is used to this end. Our model incorporates the electricity load into three types: fixed, transferable, and user-action loads. The transferable load plays a key role in molding demand response. Experimental results show that the proposed model exploits the demand elasticity and significantly reduces the total operation cost. Also observed from the experiments are the impact of the uncertainty in renewable distributed generators on operation schedule and total cost and the role of power storages for enhancing the demand elasticity with respect to user-action loads and for reserving power against high price.",
Sparsity-Driven Reconstruction for FDOT With Anatomical Priors,"In this paper we propose a method based on (2, 1)-mixed-norm penalization for incorporating a structural prior in FDOT image reconstruction. The effect of (2, 1)-mixed-norm penalization is twofold: first, a sparsifying effect which isolates few anatomical regions where the fluorescent probe has accumulated, and second, a regularization effect inside the selected anatomical regions. After formulating the reconstruction in a variational framework, we analyze the resulting optimization problem and derive a practical numerical method tailored to (2, 1)-mixed-norm regularization. The proposed method includes as particular cases other sparsity promoting regularization methods such as ℓ1-norm penalization and total variation penalization. Results on synthetic and experimental data are presented.","Image reconstruction,
Labeling,
Pixel,
Mathematical model,
Imaging,
Image segmentation,
Noise reduction"
Multilayer networks: an architecture framework,"We present an architecture framework for the control and management of multilayer networks and associated advanced network services. This material is identified as an ""architecture framework"" to emphasize its role in providing guidance and structure to our subsequent detailed architecture, design, and implementation activities. Our work is motivated by requirements from the Department of Energy science application community for real-time on-demand science-domain-specific network services and resource provisioning. We also summarize the current state of deployments and use of network services based on this multilayer network architecture framework.",
The Client and the Cloud: Democratizing Research Computing,"Extending the capabilities of PC, Web, and mobile applications through on-demand cloud services will significantly broaden the research community's capabilities, accelerating the pace of engineering and scientific discovery in this age of data-driven research. The net effect will be the democratization of research capabilities that are now available only to the most elite scientists.",
Building mega data center from heterogeneous containers,"Data center containers are regarded as the basic units to build mega data centers. In practice, heterogeneity exists among data center containers, because of technical innovation and vendor diversity. In this paper, we propose uFix, a scalable, flexible and modularized network architecture to interconnect heterogeneous data center containers. The inter-container connection rule in uFix is designed in such a way that it can flexibly scale to a huge number of servers with stable server/switch hardware settings. uFix allows modularized and fault-tolerant routing by completely decoupling inter-container routing from intra-container routing. We implement a software-based uFix stack on the Linux platform. Simulation and experiment results show that uFix enjoys high network capacity, gracefully handles server/switch failures, and brings light-weight CPU overhead onto data center servers.",
Adaptive nulling in time-modulated linear arrays with minimum power losses,"The synthesis of adaptive time-modulated linear arrays is dealt with by means of an innovative strategy, in which a particle swarm optimiser is used to reconfigure the pulse sequence controlling the static element excitations, as well as the least significant bits of digital phase shifters to maximise the signal-to-interference-plus-noise ratio at the receiver. The reduction of the power content of sideband radiation generated by the periodic on-off commutation of switches is addressed by customising to non-isotropic sources a very effective analytic relationship. A set of selected results is reported and discussed to show the advantages and limitations of the proposed approach. Comparisons with previously published results are also presented.","phase shifters,
adaptive antenna arrays,
antenna radiation patterns,
linear antenna arrays,
particle swarm optimisation"
Twitter Mood as a Stock Market Predictor,Behavioral finance researchers can apply computational methods to large-scale social media data to better understand and predict markets.,"Behavioral science,
Consumer behavior,
Psychology,
Twitter,
Financial management,
Prediction methods"
Low-Cost Dual Rotating Infrared Sensor for Mobile Robot Swarm Applications,"This paper presents a novel low-cost position detection prototype from practical design to implementation of its control schemes. This prototype is designed to provide mobile robot swarms with advanced sensing capabilities in an efficient, cost-effective way. From the observation of bats' foraging behaviors, the prototype with a particular emphasis on variable rotation range and speed, as well as 360° observation capability has been developed. The prototype also aims at giving each robot reliable information about identification of neighboring robots from objects and their positions. For this purpose, an observation algorithm-based sensor is proposed. The implementation details are explained, and the effectiveness of the control schemes is verified through extensive experiments. The sensor provides real-time location of stationary targets positioned 100 cm away within an average error of 2.6 cm. Moreover, experimental results show that the prototype observation capability can be quite satisfactory for practical use of mobile robot swarms.","Robot sensing systems,
Robot kinematics,
Mobile robots,
Prototypes,
Arrays"
Satisfiability Modulo Graph Theory for Task Mapping and Scheduling on Multiprocessor Systems,"Task graph scheduling on multiprocessor systems is a representative multiprocessor scheduling problem. A solution to this problem consists of the mapping of tasks to processors and the scheduling of tasks on each processor. Optimal solution can be obtained by exploring the entire design space of all possible mapping and scheduling choices. Since the problem is NP-hard, scalability becomes the main concern in solving the problem optimally. In this paper, a SAT-based optimization framework is proposed to address this problem, in which SAT solver is enhanced by integrating with a scheduling analysis tool in a branch and bound manner to prune the solution space efficiently. Performance evaluation results show that our technique has average performance improvement in more than an order of magnitude compared to state-of-the-art techniques. We further build a cycle-accurate network-on-chip simulator based on SystemC to verify the effectiveness of the proposed technique on realistic multiprocessor systems.",
Rate and Distortion Modeling of CGS Coded Scalable Video Content,"In this paper, we derive single layer and scalable video rate and distortion models for video bitstreams encoded using the coarse grain quality scalability (CGS) feature of the scalable extension of H.264/AVC. In these models, we assume the source is Laplacian distributed and compensate for errors in the distribution assumption by linearly scaling the Laplacian parameter . Moreover, we present simplified approximations of the derived models that allow for a run-time calculation of sequence dependent model constants. Our models use the mean absolute difference (MAD) of the prediction residual signal and the encoder quantization parameter (QP) as input parameters. Consequently, we are able to estimate the residual MAD, bitrate, and distortion of a future video frame at any QP value and for both base-layer and CGS layer packets. We also present simulation results that demonstrate the accuracy of the proposed models.","Quantization,
Rate distortion theory,
Laplace equations,
Rate-distortion,
Discrete cosine transforms,
Automatic voltage control"
HORNS: A homomorphic encryption scheme for Cloud Computing using Residue Number System,"In this paper, we propose a homomorphic encryption scheme using Residue Number System (RNS). In this scheme, a secret is split into multiple shares on which computations can be performed independently. Security is enhanced by not allowing the independent clouds to collude. Efficiency is achieved through the use of smaller shares.",
How Bad is Forming Your Own Opinion?,"A long-standing line of work in economic theory has studied models by which a group of people in a social network, each holding a numerical opinion, can arrive at a shared opinion through repeated averaging with their neighbors in the network. Motivated by the observation that consensus is rarely reached in real opinion dynamics, we study a related sociological model in which individuals' intrinsic beliefs counterbalance the averaging process and yield a diversity of opinions. By interpreting the repeated averaging as best-response dynamics in an underlying game with natural payoffs, and the limit of the process as an equilibrium, we are able to study the cost of disagreement in these models relative to a social optimum. We provide a tight bound on the cost at equilibrium relative to the optimum, our analysis draws a connection between these agreement models and extremal problems for generalized eigenvalues. We also consider a natural network design problem in this setting, where adding links to the underlying network can reduce the cost of disagreement at equilibrium.","Nash equilibrium,
Eigenvalues and eigenfunctions,
Vectors,
Games,
Cost function,
Social network services,
Laplace equations"
Computing Blindfolded: New Developments in Fully Homomorphic Encryption,"A fully homomorphic encryption scheme enables computation of arbitrary functions on encrypted data. Fully homomorphic encryption has long been regarded as cryptography's prized ""holy grail"" - extremely useful yet rather elusive. Starting with the groundbreaking work of Gentry in 2009, the last three years have witnessed numerous constructions of fully homomorphic encryption involving novel mathematical techniques, and a number of exciting applications. We will take the reader through a journey of these developments and provide a glimpse of the exciting research directions that lie ahead.","Encryption,
Polynomials,
Privacy,
Databases,
Public key"
On the accuracy of approximate techniques for the evaluation of lightning electromagnetic fields along a mixed propagation path,"In this paper we review simplified analytical expressions derived by Wait using the concept of attenuation function for the analysis of the propagation of lightning-radiated electromagnetic fields over a mixed propagation path (vertically stratified ground). Two different formulations proposed by Wait that depend on the relative values of ground surface impedances are discussed. It is shown that both formulations give nearly the same results for the time domain electric field. However, depending on the values of the normalized surface impedance for each ground section, the use of one of the two formulations is computationally more efficient. The accuracy of the Wait formulations was examined taking as reference full-wave simulations obtained using the finite difference time domain technique. It is shown that Wait's simplified formulas are able to reproduce the distant field peak and waveshape with a good accuracy.","Electric fields,
Time-domain analysis,
Finite difference methods,
Lightning,
Attenuation,
Surface impedance"
Generalized background subtraction based on hybrid inference by belief propagation and Bayesian filtering,"We propose a novel background subtraction algorithm for the videos captured by a moving camera. In our technique, foreground and background appearance models in each frame are constructed and propagated sequentially by Bayesian filtering. We estimate the posterior of appearance, which is computed by the product of the image likelihood in the current frame and the prior appearance propagated from the previous frame. The motion, which transfers the previous appearance models to the current frame, is estimated by nonparametric belief propagation; the initial motion field is obtained by optical flow and noisy and incomplete motions are corrected effectively through the inference procedure. Our framework is represented by a graphical model, where the sequential inference of motion and appearance is performed by the combination of belief propagation and Bayesian filtering. We compare our algorithm with the existing state-of-the-art technique and evaluate its performance quantitatively and qualitatively in several challenging videos.","Computational modeling,
Estimation,
Predictive models,
Bayesian methods,
Random variables,
Videos,
Motion estimation"
On the empirical performance of self-calibrating WiFi location systems,"The pervasive deployment of 802.11 in modern enterprise buildings has long made it an attractive technology for constructing indoor location services. To this end, a broad range of algorithms have been proposed to accurately estimate location from 802.11 signal strength measurements, some without requiring manual calibration for each physical location. Prior work suggests that many of these protocols can be highly effective- reporting median errors of under 2 meters in some instances. However, there are few studies validating these claims at scale, nor comparing the algorithms in a uniform, realistic environment. Our work provides precisely this kind of empirical evaluation in a realistic office building environment. Surprisingly, we find that median errors in our environment are consistently greater than 5 meters and, counter-intuitively, that simpler algorithms frequently outperform their more sophisticated counterparts. In analyzing our results, we argue that unrealistic assumptions about access point densities and underlying variability in the indoor environment may preclude highly accurate location estimates based on 802.11 signal strength.","Monitoring,
IEEE 802.11 Standards,
Buildings,
Probabilistic logic,
Training,
Databases,
Accuracy"
Adaptive Subcarrier Nulling: Enabling partial spectrum sharing in wireless LANs,"Emerging WLAN standards have been incorporating a variety of channel widths ranging from 5MHz to 160MHz, in order to match the diverse traffic demands on different networks. Unfortunately, the current 802.11 MAC/PHY is not designed for the coexistence of variable-width channels. Overlapping narrowband channels may block an entire wide-band channel, resulting in severe spectrum underutilization and even starvation of WLANs on the wide-band. A similar peril exists when a WLAN partially overlaps its channel with multiple orthogonal WLANs. In this paper, we propose to solve the problem of partial spectrum sharing using Adaptive Subcarrier Nulling (ASN). ASN builds on the 802.11 OFDM PHY, but allows the radios to sense, transmit, detect, and decode packets through spectrum fragments, or subbands. An ASN transmitter can adapt its spectrum usage on a per-packet basis, by nulling the subbands used by neighboring WLANs, and sending packets through the remaining idle subbands. ASN preserves the 802.11 CSMA/CA primitives while allowing users to contend for access to each subband, and can opportunistically exploit the merits of wide-band channels via spectrum aggregation. We have implemented and evaluated ASN on the GNURadio/USRP platform. Our experimental results have shown ASN to achieve detection and decoding performance comparable to the legacy 802.11. Our detailed simulation in ns-2 further shows that ASN substantially improves the efficiency and fairness of spectrum sharing for multi-cell WLANs.","Wireless LAN,
IEEE 802.11g Standard,
Sensors,
OFDM,
Interference,
Throughput"
A Joint Approach to Global Motion Estimation and Motion Segmentation From a Coarsely Sampled Motion Vector Field,"In many content-based video processing systems, the presence of moving objects limits the accuracy of global motion estimation (GME). On the other hand, the inaccuracy of global motion parameter estimates affects the performance of motion segmentation. In this paper, we introduce a procedure for simultaneous object segmentation and GME from a coarsely sampled (i.e., block-based) motion vector (MV) field. The procedure starts with removing MV outliers from the MV field, and then performs GME to obtain an estimate of global motion parameters. Using these estimates, global motion is removed from the MV field, and moving region segmentation is performed on this compensated MV field. MVs in the moving regions are treated as outliers in the context of GME in the next round of processing. Iterating between GME and motion segmentation helps improve both GME and segmentation accuracy. Experimental results demonstrate the advantage of the proposed approach over state-of-the-art methods on both synthetic motion fields and MVs from real video sequences.","Motion segmentation,
Computer vision,
Motion estimation,
Cameras,
Pixel,
Bayesian methods,
Mathematical model"
Cyber security challenges in Smart Grids,"The introduction of telecommunication in the energy grid, leading the way towards Smart Grids, challenges the way safe operations have traditionally been assured in the energy sector. New cyber security challenges emerge, especially related to privacy, connectivity and security management, and these need to be properly addressed. Existing cyber security technology and good practice mainly come from the traditional telecommunication environment where the requirements on safety and availability are less strict. For Smart Grids, lessons can be learned from the oil and gas industry on how they have dealt with security challenges in their implementation of integrated operations. Still, Smart Grids face a slightly different reality, due to their extensive geographical distribution and the enormous number of end-users. The contribution of this paper is a survey of cyber security challenges for Smart Grids, together with a roadmap of how these challenges must be addressed in the near future.","Smart grids,
Computer security,
Safety,
Communications technology,
Process control"
Multihop Virtual MIMO Systems With Channel Reuse in a Poisson Field of Nodes,"This paper investigates the performance of multihop virtual multiple-input-multiple-output systems (V-MIMO), based on the concept of virtual antenna array (VAA), in the presence of random location of nodes. Nodes are supposed to be distributed according to a Poisson point process. Random fluctuations are considered, and the channel model takes both slow and fast fading into account. Performance is evaluated in terms of outage probability, which is defined as the probability that the ergodic capacity between the source and the destination is smaller than a given threshold. We investigate the impact of a random distribution of nodes on the overall performance. The role played by the interference, when some reuse of radio resources is considered for inter-VAA communication, is also investigated.",
An event driven Smart Home Controller enabling cost effective use of electric energy and automated Demand Side Management,"This paper proposes the design of a Smart Home Controller strategy providing efficient management of electric energy in a domestic environment. The problem is formalized as a binary linear programming problem, the output of which specifies the best time to run of Smart Household Appliances, under a Virtual Power Threshold constraint, taking into account the real power threshold and the forecast of consumption from not plannable loads. This problem formulation allows to analyze relevant scenarios from consumer and energy retailer point of view: here optimization of economic saving in case of multi-tariff contract and Demand Side Management have been discussed and simulated. Simulations have been performed on relevant test cases, based on real load profiles provided by the smart appliance manifacturer Electrolux S.p.A. and on energy tariffs suggested by the energy retailer Edison. Results provide a proof of concept about the consumers benefits coming from the use of local energy management systems and the relevance of automated Demand Side Management for the general target of efficient and cost effective operation of electric networks.","Planning,
Home appliances,
Load modeling,
Contracts,
Linear programming,
Power demand,
Control systems"
S-FTL: An efficient address translation for flash memory by exploiting spatial locality,"The solid-state disk (SSD) is becoming increasingly popular, especially among users whose workloads exhibit substantial random access patterns. As SSD competes with the hard disk, whose per-GB cost keeps dramatically falling, the SSD must retain its performance advantages even with low-cost configurations, such as those with a small built-in DRAM cache for mapping table and using MLC NAND. To this end, we need to make the limited cache space efficiently used to support fast logical-to-physical address translation in the flash translation layer (FTL) with minimal access of flash memory and minimal merge operations. Existing schemes usually require a large number of overhead accesses, either for accessing uncached entries of the mapping table or for the merge operation, and achieve suboptimal performance when the cache space is limited. In this paper we take into account spatial locality exhibited in the workloads to obtain a highly efficient FTL even with a relatively small cache, named as S-FTL. Specifically, we identify three access patterns related to spatial locality, including sequential writes, clustered access, and sparse writes. Accordingly we propose designs to take advantage of these patterns to reduce mapping table size, increase hit ratio for in-cache address translation, and minimize expensive writes to flash memory. We have conducted extensive trace-driven simulations to evaluate S-FTL and compared it with other state-of-the-art FTL schemes. Our experiments show that S-FTL can reduce accesses to the flash for address translation by up to 70% and reduce response time of SSD by up to 25%, compared with the state-of-the-art FTL strategies such as FAST and DFTL.","Ash,
Hard disks,
Random access memory,
Throughput,
Writing,
Prefetching,
Electronic mail"
Create weak learners with small neural networks by balanced ensemble learning,"It has been shown that as the number of weak learners in a majority voting model is increased so does its generalization if those weak learners are uncorrelated or negatively correlated. Although some learning algorithms including bagging and boosting have been developed to create such weak learners, learners trained by these learning algorithms are actually not so weak in many applications. This paper presents a simple balanced ensemble learning method for producing weak learners. The idea of balanced ensemble learning is to change the learning force in the training process so that the training data points near to the decision boundaries would push the decision boundaries further while the training data points far away from the decision boundaries would drag the decision boundaries to themselves. The experimental results suggest that balanced ensemble learning is able to create learners being both weak and negatively correlated.","Training,
Training data,
Correlation,
Error analysis,
Bagging,
Boosting"
Distributed Construction of Configuration Spaces for Real-Time Haptic Deformation Modeling,"Haptic rendering is an important area of research that enables the user to employ haptic perception in human-computer interaction. An important motivation here is to use the human touch to study the behavior of various models. However, the high refresh rate needed for a stable haptic interaction on the one hand and the high-computational-cost characteristic for the simulation of numerous phenomena on the other hand represent a big issue. In this paper, an approach based on the distributed construction of configuration spaces is presented. The main idea behind this approach is to profit from employing a high-performance environment (e.g., computational grid) to overcome or at least moderate the high-frequency issue. The approach is presented using nonlinear deformation models, which are essential for realistic modeling of soft tissues. A distributed algorithm is presented, and its properties are evaluated quantitatively.","Haptic interfaces,
Deformable models,
Rendering (computer graphics),
Humans,
Computational modeling,
Computer science,
Permission,
Visual perception,
Computational efficiency,
Grid computing"
AeroRP performance in highly-dynamic airborne networks using 3D Gauss-Markov mobility model,"Emerging airborne networks require domain-specific routing protocols to cope with the challenges faced by the highly-dynamic aeronautical environment. We present an ns-3 based performance comparison of the AeroRP protocol with conventional MANET routing protocols. To simulate a highly-dynamic airborne network, accurate mobility models are needed for the physical movement of nodes. The fundamental problem with many synthetic mobility models is their random, memoryless behavior. Airborne ad hoc networks require a flexible memory-based 3-dimensional mobility model. Therefore, we have implemented a 3-dimensional Gauss-Markov mobility model in ns-3 that appears to be more realistic than memoryless models such as random waypoint and random walk. Using this model, we are able to simulate the airborne networking environment with greater realism than was previously possible and show that AeroRP has several advantages over other MANET routing protocols.",
Equivalent Permeability of Step-Lap Joints of Transformer Cores: Computational and Experimental Considerations,"The paper develops an efficient computational method for establishing equivalent characteristics of magnetic joints of transformer cores, with special emphasis on step-lap design. By introducing an equivalent material, the method allows the real three-dimensional structure of the laminated thin sheets to be treated computationally as a two-dimensional problem and enables comparative analysis of designs. The characteristics of the equivalent material are established by minimizing the magnetic energy of the system. To verify the proposed approach, a series of experiments have been conducted. First, the anisotropic characteristics of the step-lap were established, and then space components of the flux density at specified positions measured. This enabled detailed analysis of the flux distribution in the step-lap region, in particular the way in which the flux travels between the laminations close to the air-gap steps. Encouraging correlation between the homogenized 2-D model and experiment has been observed.","Joints,
Lamination,
Coils,
Air gaps,
Materials,
Magnetic cores,
Three dimensional displays"
Dynamics of fractional-order neural networks,"In this paper we discuss the stability analysis for fractional-order neural networks of Hopfield type. The stability domain of a steady state is completely characterized with respect to some characteristic parameters of the system, in the case of a two-dimensional network and of a network of n ≥ 3 neurons with ring structure. The values of the characteristic parameters for which Hopf bifurcations occur are identified. Numerical simulations are given which substantiate the theoretical findings and suggest possible routes towards chaos when the fractional order of the system increases.","Biological neural networks,
Steady-state,
Eigenvalues and eigenfunctions,
Asymptotic stability,
Bifurcation,
Stability analysis,
Neurons"
Joint Network Coding and Scheduling for Media Streaming Over Multiuser Wireless Networks,"We formulate the problem of network-coding (NC)-based scheduling for media transmission to multiple users over a wireless-local-area-network-like or WiMAX-like network as a Markov decision process (MDP). NC is used to minimize the packet losses that resulted from unreliable wireless channel conditions, whereas the MDP is employed to find the optimal policy for transmissions of unequally important media packets. Based on this, a dynamic programming technique is used to give an optimal transmission policy. However, this dynamic programming technique quickly leads to computational intractability, even for scenarios with a moderate number of receivers. To address this problem, we further propose a simulation-based dynamic programming algorithm that has a much lower run time yet empirically converges quickly to the optimal solution.","Receivers,
Streaming media,
Bandwidth,
Delay,
Ad hoc networks,
Wireless networks"
Green network technologies and the art of trading-off,"In this contribution, we focus on energy-aware devices able to reduce their energy requirements by adapting their performance. We propose an analytical model to accurately represent the impact of green network technologies (i.e., low power idle and adaptive rate) on network- and energy-aware performance indexes. The model has been validated with experimental results, performed by using energy-aware software routers and real-world traffic traces. The achieved results demonstrate how the proposed model can effectively represent energy- and network-aware performance indexes. Moreover, also an optimization procedure based on the model has been proposed and experimentally evaluated. The procedure aims at dynamically adapting the energy-aware device configuration to minimize energy consumption, while coping with incoming traffic volumes and meeting network performance constraints.","Servers,
Performance evaluation,
Power demand,
Analytical models,
Optimization,
Performance analysis,
Program processors"
High Throughput Data Mapping for Coarse-Grained Reconfigurable Architectures,"Coarse-grained reconfigurable arrays (CGRAs) are a very promising platform, providing both up to 10-100 MOps/mW of power efficiency and software programmability. However, this promise of CGRAs critically hinges on the effectiveness of application mapping onto CGRA platforms. While previous solutions have greatly improved the computation speed, they have largely ignored the impact of the local memory architecture on the achievable power and performance. This paper motivates the need for memory-aware application mapping for CGRAs, and proposes an effective solution for application mapping that considers the effects of various memory architecture parameters including the number of banks, local memory size, and the communication bandwidth between the local memory and the external main memory. Further we propose efficient methods to handle dependent data on a double-buffering local memory, which is necessary for recurrent loops. Our proposed solution achieves 59% reduction in the energy-delay product, which factors into about 47% and 22% reduction in the energy consumption and runtime, respectively, as compared to memory-unaware mapping for realistic local memory architectures. We also show that our scheme scales across a range of applications and memory parameters, and the runtime overhead of handling recurrent loops by our proposed methods can be less than 1%.","Arrays,
Memory architecture,
Memory management,
Network architecture"
Estimating Dominance in Multi-Party Meetings Using Speaker Diarization,"With the increase in cheap commercially available sensors, recording meetings is becoming an increasingly practical option. With this trend comes the need to summarize the recorded data in semantically meaningful ways. Here, we investigate the task of automatically measuring dominance in small group meetings when only a single audio source is available. Past research has found that speaking length as a single feature, provides a very good estimate of dominance. For these tasks we use speaker segmentations generated by our automated faster than real-time speaker diarization algorithm, where the number of speakers is not known beforehand. From user-annotated data, we analyze how the inherent variability of the annotations affects the performance of our dominance estimation method. We primarily focus on examining of how the performance of the speaker diarization and our dominance tasks vary under different experimental conditions and computationally efficient strategies, and how this would impact on a practical implementation of such a system. Despite the use of a state-of-the-art speaker diarization algorithm, speaker segments can be noisy. On conducting experiments on almost 5 hours of audio-visual meeting data, our results show that the dominance estimation is robust to increasing diarization noise.","Humans,
Microphones,
Audio recording,
Data analysis,
Performance analysis,
Art,
Noise robustness,
Read only memory,
Speech processing,
Psychology"
A Complementary Modularized Ramp Metering Approach Based on Iterative Learning Control and ALINEA,"Ramp metering is an effective tool for traffic management on freeway networks. In this paper, we apply iterative learning control (ILC) to address ramp metering in a macroscopic-level freeway environment. By formulating the original ramp metering problem as an output regulating and disturbance rejection problem, ILC has been applied to control the traffic response. The learning mechanism is further combined with Asservissement Linéaire d'Entrée Autoroutière (ALINEA) in a complementary manner to achieve the desired control performance. The ILC-based ramp metering strategy and the modified modularized ramp metering approach based on ILC and ALINEA in the presence of input constraints are also analyzed to highlight the advantages and the robustness of the proposed methods. Extensive simulations are given to verify the effectiveness of the proposed approaches.","Traffic control,
Mathematical model,
Convergence,
Learning systems,
Feedforward neural networks"
First-exit model predictive control of fast discontinuous dynamics: Application to ball bouncing,"We extend model-predictive control so as to make it applicable to robotic tasks such as legged locomotion, hand manipulation and ball bouncing. The online optimal control problem is defined in a first-exit rather than the usual finite-horizon setting. The exit manifold corresponds to changes in contact state. In this way the need for online optimization through dynamic discontinuities is avoided. Instead the effects of discontinuities are incorporated in a final cost which is tuned offline. The new method is demonstrated on the task of 3D ball bouncing. Even though our robot is mechanically limited, it bounces one ball robustly and recovers from a wide range of disturbances, and can also bounce two balls with the same paddle. This is possible due to intelligent responses computed online, without relying on pre-existing plans.","Trajectory,
Robot kinematics,
Optimization,
MATLAB,
Computational modeling,
Real time systems"
Combining Perceptual Features With Diffusion Distance for Face Recognition,"Face recognition and identification is a very active research area nowadays due to its importance in both human computer and social interaction. Psychological studies suggest that face recognition by human beings can be featural, configurational, and holistic. In this paper, by incorporating spatially structured features into a histogram-based face-recognition framework, we intend to pursue consistent performance of face recognition. In our proposed approach, while diffusion distance is computed over a pair of human face images, the shape descriptions of these images are built using Gabor filters that consist of a number of scales and levels. It demonstrates that the use of perceptual features by Gabor filtering in combination with diffusion distance enables the system performance to be significantly improved, compared to several classical algorithms. The oriented Gabor filters lead to discriminative image representations that are then used to classify human faces in the database.",
Trace-Oriented Feature Analysis for Large-Scale Text Data Dimension Reduction,"Dimension reduction for large-scale text data is attracting much attention nowadays due to the rapid growth of the World Wide Web. We can categorize those popular dimension reduction algorithms into two groups: feature extraction and feature selection algorithms. In the former, new features are combined from their original features through algebraic transformation. Though many of them have been validated to be effective, these algorithms are typically associated with high computational overhead, making them difficult to be applied on real-world text data. In the latter, subsets of features are selected directly. These algorithms are widely used in real-world tasks owing to their efficiency, but are often based on greedy strategies rather than optimal solutions. An important problem remains: it has been troublesome to integrate these two types of algorithms into a single framework, making it difficult to reap the benefits from both. In this paper, we formulate the two algorithm categories through a unified optimization framework, under which we develop a novel feature selection algorithm called Trace-Oriented Feature Analysis (TOFA). In detail, we integrate the objective functions of several state-of-the-art feature extraction algorithms into a unified one under the optimization framework, and then we propose to optimize this objective function in the solution space of feature selection algorithms for dimensionality reduction. Since the proposed objective function of TOFA integrates many prominent feature extraction algorithms' objective functions, such as unsupervised Principal Component Analysis (PCA) and supervised Maximum Margin Criterion (MMC), TOFA can handle both supervised and unsupervised problems. In addition, by tuning a weight value, TOFA is also suitable to solve semisupervised learning problems. Experimental results on several real-world data sets validate the effectiveness and efficiency of TOFA in text data for dimensionality reduction purpose.","Large-scale systems,
Feature extraction,
Algorithm design and analysis,
Text processing,
Principal component analysis,
Text analysis,
Information analysis,
Clustering algorithms,
Web sites,
Semisupervised learning"
The Restricted Isometry Property for block diagonal matrices,"In compressive sensing (CS), the Restricted Isometry Property (RIP) is a powerful condition on measurement operators which ensures robust recovery of sparse vectors is possible from noisy, undersampled measurements via computationally tractable algorithms. Early papers in CS showed that Gaussian random matrices satisfy the RIP with high probability, but such matrices are usually undesirable in practical applications due to storage limitations, computational considerations, or the mismatch of such matrices with certain measurement architectures. To alleviate some or all of these difficulties, recent research efforts have focused on structured random matrices. In this paper, we study block diagonal measurement matrices where each block on the main diagonal is itself a Gaussian random matrix. The main result of this paper shows that such matrices can indeed satisfy the RIP but that the requisite number of measurements depends on the coherence of the basis in which the signals are sparse. In the best case-for signals that are sparse in the frequency domain-these matrices perform nearly as well as dense Gaussian random matrices despite having many fewer nonzero entries.","Sparse matrices,
Random variables,
Noise measurement,
Coherence,
Frequency domain analysis,
Vectors,
Sensors"
Hybrid Cone-Beam Tomographic Reconstruction: Incorporation of Prior Anatomical Models to Compensate for Missing Data,"We propose a method for improving the quality of cone-beam tomographic reconstruction done with a C-arm. C-arm scans frequently suffer from incomplete information due to image truncation, limited scan length, or other limitations. Our proposed “hybrid reconstruction” method injects information from a prior anatomical model, derived from a subject-specific computed tomography (CT) or from a statistical database (atlas), where the C-arm X-ray data is missing. This significantly reduces reconstruction artifacts with little loss of true information from the X-ray projections. The methods consist of constructing anatomical models, fast rendering of digitally reconstructed radiograph (DRR) projections of the models, rigid or deformable registration of the model and the X-ray images, and fusion of the DRR and X-ray projections, all prior to a conventional filtered back-projection algorithm. Our experiments, conducted with a mobile image intensifier C-arm, demonstrate visually and quantitatively the contribution of data fusion to image quality, which we assess through comparison to a “ground truth” CT. Importantly, we show that a significantly improved reconstruction can be obtained from a C-arm scan as short as 90° by complementing the observed projections with DRRs of two prior models, namely an atlas and a preoperative same-patient CT. The hybrid reconstruction principles are applicable to other types of C-arms as well.",
Nanotechnology-based trusted remote sensing,We present a new nanotechnology PPUF-based architecture for trusted remote sensing. Current public physical unclonable function designs encompass complex circuits requiring high measurement accuracy and whose size slows down the authentication process. Our novel nanotechnology-based architecture ensures fast authentication through partial simulation while maintaining robust security. We authenticate over partitions in the design space in order to alleviate the authentication burden while still ensuring attack by simulation is entirely ineffective. We contribute new nanotechnology-based security protocols for authentication and time-stamping for trusted remote sensing.,"Authentication,
Remote sensing,
Nanotechnology,
Pins,
Integrated circuit modeling,
Cryptography"
A Reconfigurable FIR Filter Architecture to Trade Off Filter Performance for Dynamic Power Consumption,"This paper presents an architectural approach to the design of low power reconfigurable finite impulse response (FIR) filter. The approach is well suited when the filter order is fixed and not changed for particular applications, and efficient trade-off between power savings and filter performance can be made using the proposed architecture. Generally, FIR filter has large amplitude variations in input data and coefficients. Considering the amplitude of both the filter coefficients and inputs, the proposed FIR filter dynamically changes the filter order. Mathematical analysis on power savings and filter performance degradation and its experimental results show that the proposed approach achieves significant power savings without seriously compromising the filter performance. The power savings is up to 41.9% with minor performance degradation, and the area overhead of the proposed scheme is less than 5.3% compared to the conventional approach.","Finite impulse response filter,
Degradation,
Power demand,
Mathematical analysis,
Reconfigurable architectures"
Real-time plane extraction from depth images with the Randomized Hough Transform,"Depth cameras, like the Microsoft Kinect system, are valuable sensors for mobile robotics since their data enables a highly detailed perception of the environmental structure. Certainly, their amount of data is often too high to be processed in real-time by the limited resources of mobile robots. One way of using these sensors is to reduce the amount of data by extracting features like planes from the raw depth images. In this work we present a method to extract planes from depth images based on the Randomized Hough Transformation, which is specially adapted to the properties of the Kinect sensor. Therefore we use a noise model of the sensor to solve the task of finding proper parameter metrics for the Randomized Hough Transform. As a result, our approach extracts the planes from a depth image in less than one millisecond on the platform of a mobile robot and is therefore real-time capable.","Sensors,
Vectors,
Noise,
Transforms,
Real time systems,
Image sensors,
Adaptation models"
More on the Stopping and Minimum Distances of Array Codes,"For q an odd prime and 1≤ m ≤ q, two specific binary qm × q2 parity-check matrices denoted by HP(m, q) and HI(m, q) are considered. The corresponding binary codes, CP(m, q) and CI(m, q), respectively, are called proper and improper array codes with parameters m and q. Given a parity-check matrix H representing a binary code C, let s(H) denote the stopping distance of H and d(C) be the minimum Hamming distance of C. It is known that that s(HI(m, q)) = s(HP(m, q)) = d(CI(m, q)) = d(CP(m, q)) for m ≤ 3. In this paper, we show that these equalities do not hold for all values of m and q. In particular, although s(HP(4, 7)) = d(CP(4, 7)) = 8 we have s(HI(4, 7)) = 9 and d(CI(4, 7)) = 10. It is also shown that s(HP(5,1))dCP(5, 11)) = 10 while s(HI(5,11)) = 11 and d(CI(5, 11)) = 12. This suggests that in many cases the improper array codes would perform better than the proper array codes over the AWGN and binary erasure channels. Performance results are given which confirm this claim. The combinatorial structure of the eight-element stopping sets for H(m ≥ 4,q >; 5) is also determined.","Arrays,
Computers,
Equations,
Iterative decoding,
Maximum likelihood decoding,
Materials"
SDC testbed: Software defined communications testbed for wireless radio and optical networking,"This paper describes the development of a new Software Defined Communications (SDC) testbed architecture. SDC aims to generalize the area of software defined radio to include propagation media not exclusively limited to radio frequencies (optical, ultrasonic, etc.). This SDC platform leverages existing and custom hardware in combination with reference software applications in order to provide a complete research and development platform. This platform can be used to implement current and future standards that make use of highly demanding communications techniques, including ultrawideband (UWB) radio and free-space optical communications. This paper describes the commercial and custom hardware that is being integrated into the platform, including the baseband hardware and the modular transceiver frontends. Furthermore, the paper describes the software development currently in progress with this platform, including the integration of available open source designs into the platform, and the development of custom IP for scalable OFDM PHY implementations in radio and optical communications. We seek to create a complete research platform for the commercial and academic wireless communities, capable of delivering the highest possible performance and flexibility while providing the necessary development tools and reference designs in order to minimize system learning curve and development cost.","Field programmable gate arrays,
Hardware,
Software,
MIMO,
Transceivers,
Radio frequency,
Optical sensors"
Subspace-Based Cooperative Spectrum Sensing for Cognitive Radios,"Accurate and efficient spectrum sensing is critical in providing the cognitive radios with radio environmental awareness in order to improve the efficiency of spectrum utilization. Since narrowband sensing techniques only concentrate on one band at a time with prefixed band locations and bandwidth, wideband sensing is relatively more efficient. Considering the adverse effects of shadowing and multipath fading, in this paper, a cooperative wideband spectrum sensing algorithm based on the subspace method is proposed to detect the presence of a number of primary users in the band of interest. Specifically based on the collected samples of the received signals over multiple antennas, each secondary user estimates the number of primary user signals and their carrier frequencies using the subspace method. Before fusing all local estimates, the fusion center needs to determine which estimates belong to which primary users. The k -means algorithm built on the minimum description length principle is proposed for the data association problem, which can further eliminate false alarms. A linear unbiased estimator is proposed for data fusion and it reduces to a weighted sum of local estimates that belong to the same primary user. Experiments are conducted to demonstrate the efficiency of the proposed algorithm in detecting the correct number of primary users and estimating their carrier frequencies.","Sensors,
Antennas,
Wideband,
Fading,
Cognitive radio,
Frequency estimation"
Progress in Development of Superconducting Fault Current Limiting Transformer (SFCLT),"We have been developing Superconducting Fault Current Limiting Transformer (SFCLT), which has multifunction of both a superconducting transformer in a steady state as well as a superconducting fault current limiter in a fault condition. This paper introduces the progress in our SFCLT project since 1998, from Step-1 to the latest Step-5, with the concept, design, fabrication and test results of SFCLT. In the latest Step-5, we developed a 2 MVA, 22/6.6 kV class SFCLT with YBCO coated conductors and verified the fundamental function as a transformer, effective current limiting function as a fault current limiter, and recovery characteristics after the fault clearance with its operational criterion.","High temperature superconductors,
Fault currents,
Limiting,
Impedance,
Conductors,
Circuit faults,
Power system stability"
Modeling of Ionizing Radiation-Induced Degradation in Multiple Gate Field Effect Transistors,"The radiation response of advanced non-planar multiple gate field effect transistors (MuGFETs) has been shown to have a strong dependence on fin width (W). The incorporation of total ionizing dose (TID) effects into a physics-based surface-potential compact model allows for the effects of radiation-induced degradation in MuGFET devices to be modeled in circuit simulators, e.g., SPICE. A set of extracted parameters are used in conjunction with closed-form expressions for the surface potential, thereby enabling accurate modeling of the radiation-response and its dependence on W . Total ionizing dose (TID) experiments and two-dimensional (2D) TCAD simulations are used to validate the compact modeling approach presented in this paper.","Integrated circuit modeling,
Logic gates,
Silicon,
FinFETs,
Mathematical model,
Data models,
Degradation"
The Geometry of Reflectance Symmetries,"Different materials reflect light in different ways, and this reflectance interacts with shape, lighting, and viewpoint to determine an object's image. Common materials exhibit diverse reflectance effects, and this is a significant source of difficulty for image analysis. One strategy for dealing with this diversity is to build computational tools that exploit reflectance symmetries, such as reciprocity and isotropy, that are exhibited by broad classes of materials. By building tools that exploit these symmetries, one can create vision systems that are more likely to succeed in real-world, non-Lambertian environments. In this paper, we develop a framework for representing and exploiting reflectance symmetries. We analyze the conditions for distinct surface points to have local view and lighting conditions that are equivalent under these symmetries, and we represent these conditions in terms of the geometric structure they induce on the Gaussian sphere and its abstraction, the projective plane. We also study the behavior of these structures under perturbations of surface shape and explore applications to both calibrated and uncalibrated photometric stereo.","Lighting,
Reflectivity,
Artificial neural networks,
Surface reconstruction,
Calibration,
Photometry"
Graph-Theoretical Constructions for Graph Entropy and Network Coding Based Communications,"The guessing number of a directed graph (digraph), equivalent to the entropy of that digraph, was introduced as a direct criterion on the solvability of a network coding instance. This paper makes two contributions on the guessing number. First, we introduce an undirected graph on all possible configurations of the digraph, referred to as the guessing graph, which encapsulates the essence of dependence amongst configurations. We prove that the guessing number of a digraph is equal to the logarithm of the independence number of its guessing graph. Therefore, network coding solvability is no more a problem on the operations made by each node, but is simplified into a problem on the messages that can transit through the network. By studying the guessing graph of a given digraph, and how to combine digraphs or alphabets, we are thus able to derive bounds on the guessing number of digraphs. Second, we construct specific digraphs with high guessing numbers, yielding network coding instances where a large amount of information can transit. We first propose a construction of digraphs with finite parameters based on cyclic codes, with guessing number equal to the degree of the generator polynomial. We then construct an infinite class of digraphs with arbitrary girth for which the ratio between the linear guessing number and the number of vertices tends to one, despite these digraphs being arbitrarily sparse. These constructions yield solvable network coding instances with a relatively small number of intermediate nodes for which the node operations are known and linear, although these instances are sparse and the sources are arbitrarily far from their corresponding sinks.","Network coding,
Games,
Protocols,
Entropy,
Encoding,
Error correction codes,
Unicast"
Pattern- and Network-Based Classification Techniques for Multichannel Medical Data Signals to Improve Brain Diagnosis,"There is an urgent need for a quick screening process that could help neurologists diagnose and determine whether a patient is epileptic versus simply demonstrating symptoms linked to epilepsy but actually stemming from a different illness. An inaccurate diagnosis could have fatal consequences, particularly in operating rooms and intensive care units. Electroencephalogram (EEG) has been traditionally used, as a gold standard, to diagnose patients by evaluating those brain functions that might correspond to epilepsy and other brain disorders. This research therefore focuses on developing new classification techniques for multichannel EEG recordings. Two time-series classification techniques, namely, Support Feature Machine (SFM) and Network-Based Support Vector Machine (SVM) (NSVM), are proposed in this paper to predict from EEG readings whether a person is epileptic or nonepileptic. The SFM approach is an optimization model that maximizes classification accuracy by selecting a group of electrodes (features) that has strong class separability based on time-series similarity measures and correctly classifies EEG samples in the training phase. The NSVM approach integrates a new network-based model for multidimensional time-series data with traditional SVMs to exploit both the spatial and temporal characteristics of EEG data. The proposed techniques are tested on two EEG data sets acquired from ten and five patients, respectively. Compared with other commonly used classification techniques such as SVM and decision trees, the proposed SFM and NSVM techniques provide very promising and practical results and require much less time and memory resources than traditional techniques. This study is a necessary application of data mining to advance the diagnosis and treatment of human epilepsy.","Electroencephalography,
Training,
Epilepsy,
Electrodes,
Support vector machines,
Nearest neighbor searches,
Time series analysis"
Improved GART Neural Network Model for Pattern Classification and Rule Extraction With Application to Power Systems,"Generalized adaptive resonance theory (GART) is a neural network model that is capable of online learning and is effective in tackling pattern classification tasks. In this paper, we propose an improved GART model (IGART), and demonstrate its applicability to power systems. IGART enhances the dynamics of GART in several aspects, which include the use of the Laplacian likelihood function, a new vigilance function, a new match-tracking mechanism, an ordering algorithm for determining the sequence of training data, and a rule extraction capability to elicit if-then rules from the network. To assess the effectiveness of IGART and to compare its performances with those from other methods, three datasets that are related to power systems are employed. The experimental results demonstrate the usefulness of IGART with the rule extraction capability in undertaking classification problems in power systems engineering.","Artificial neural networks,
Modeling,
Power systems,
Pattern classification"
A wearable system for the seismocardiogram assessment in daily life conditions,"Seismocardiogram (SCG) is the recording of the minute body accelerations induced by the heart activity, and reflects mechanical aspects of heart contraction and blood ejection. So far, most of the available systems for the SCG assessment are designed to be used in a laboratory or in controlled behavioral and environmental conditions. In this paper we propose a modified version of a textile-based wearable device for the unobtrusive recording of ECG, respiration and accelerometric data (the MagIC system), to assess the 3d sternal SCG in daily life. SCG is characterized by an extremely low magnitude of the accelerations (in the order of g × 10-3), and is masked by major body accelerations induced by locomotion. Thus in daily life recordings, SCG can be measured whenever the subject is still. We observed that about 30 seconds of motionless behavior are sufficient for a stable estimate of the average SCG waveform, independently from the subject's posture. Since it is likely that during spontaneous behavior the subject may stay still for at least 30 seconds several times in a day, it is expected that the SCG could be repeatedly estimated and tracked over time through a prolonged data recording. These observations represent the first testing of the system in the assessment of SCG out of a laboratory environment, and open the possibility to perform SCG studies in a wide range of everyday conditions without interfering with the subject's activity tasks.","Electrocardiography,
Three dimensional displays,
Accelerometers,
Heart,
Acceleration,
Textiles,
Laboratories"
Decomposition methods for large scale LP decoding,"Feldman et al. (IEEE Trans. Inform. Theory, Mar. 2005) showed that linear programming (LP) can be used to decode linear error correcting codes. The bit-error-rate performance of LP decoding is comparable to state-of-the-art BP decoders, but has significantly stronger theoretical guarantees. However, LP decoding when implemented with standard LP solvers does not easily scale to the block lengths of modern error correcting codes. In this paper we draw on decomposition methods from optimization theory to develop efficient distributed algorithms for LP decoding. The key enabling technical result is a nearly linear time algorithm for two-norm projection onto the parity polytope. This allows us to use LP decoding, with all its theoretical guarantees, to decode large-scale error correcting codes efficiently.","Vectors,
Maximum likelihood decoding,
Iterative decoding,
Projection algorithms,
Algorithm design and analysis"
ES2: A cloud data storage system for supporting both OLTP and OLAP,"Cloud computing represents a paradigm shift driven by the increasing demand of Web based applications for elastic, scalable and efficient system architectures that can efficiently support their ever-growing data volume and large-scale data analysis. A typical data management system has to deal with real-time updates by individual users, and as well as periodical large scale analytical processing, indexing, and data extraction. While such operations may take place in the same domain, the design and development of the systems have somehow evolved independently for transactional and periodical analytical processing. Such a system-level separation has resulted in problems such as data freshness as well as serious data storage redundancy. Ideally, it would be more efficient to apply ad-hoc analytical processing on the same data directly. However, to the best of our knowledge, such an approach has not been adopted in real implementation. Intrigued by such an observation, we have designed and implemented epiC, an elastic power-aware data-itensive Cloud platform for supporting both data intensive analytical operations (ref. as OLAP) and online transactions (ref. as OLTP). In this paper, we present ES2 - the elastic data storage system of epiC, which is designed to support both functionalities within the same storage. We present the system architecture and the functions of each system component, and experimental results which demonstrate the efficiency of the system.","Distributed databases,
Indexing,
Catalogs,
Data models,
Access control"
An approach to energy-error tradeoffs in approximate ripple carry adders,"Given a 16-bit or 32-bit overclocked ripple-carry adder, we minimize error by allocating multiple supply voltages to the gates. We solve the error minimization problem for a fixed energy budget using a binned geometric program solution (BGPS). A solution found via BGPS outperforms the two best prior approaches, uniform voltage scaling and biased voltage scaling, reducing error by as much as a factor of 2.58X and by a median of 1.58X in 90 nm transistor technology.","Logic gates,
Adders,
Energy consumption,
Delay,
Propagation delay,
Voltage control,
Optimization"
Modeling and solving the train load planning problem in seaport container terminals,"In this paper we present two mathematical formulations and a heuristic approach for the train load planning problem of import containers at a seaport container terminal. The problem consists of determining how to assign a set of containers of different length and weight to the wagons of a train in order to satisfy capacity constraints of both the wagons and the train, while minimizing the rehandling operations in the stocking area where containers are waiting for being loaded on trains and maximizing the train utilization. Some computational results will be reported in the paper in which the heuristic approach is compared with the solution of the mathematical programming formulation.","Containers,
Loading,
Planning,
Integrated circuits,
Load modeling,
Cranes,
Clustering algorithms"
Articulatory Knowledge in the Recognition of Dysarthric Speech,"Disabled speech is not compatible with modern generative and acoustic-only models of speech recognition (ASR). This work considers the use of theoretical and empirical knowledge of the vocal tract for atypical speech in labeling segmented and unsegmented sequences. These combined models are compared against discriminative models such as neural networks, support vector machines, and conditional random fields. Results show significant improvements in accuracy over the baseline through the use of production knowledge. Furthermore, although the statistics of vocal tract movement do not appear to be transferable between regular and disabled speakers, transforming the space of the former given knowledge of the latter before retraining gives high accuracy. This work may be applied within components of assistive software for speakers with dysarthria.","Speech,
Speech recognition,
Hidden Markov models,
Acoustics,
Databases,
Tongue,
Accuracy"
"SplitScreen: Enabling efficient, distributed malware detection","We present the design and implementation of a novel anti-malware system called SplitScreen. SplitScreen performs an additional screening step prior to the signature matching phase found in existing approaches. The screening step filters out most non-infected files (90%) and also identifies malware signatures that are not of interest (99%). The screening step significantly improves end-to-end performance because safe files are quickly identified and are not processed further, and malware files can subsequently be scanned using only the signatures that are necessary. Our approach naturally leads to a network-based anti-malware solution in which clients only receive signatures they needed, not every malware signature ever created as with current approaches. We have implemented SplitScreen as an extension to ClamAV, the most popular open source anti-malware software. For the current number of signatures, our implementation is 2x faster and requires 2x less memory than the original ClamAV. These gaps widen as the number of signatures grows.","Malware,
Vectors,
Pattern matching,
Databases,
Servers,
Memory management,
Computers"
Video Alignment for Change Detection,"In this work, we address the problem of aligning two video sequences. Such alignment refers to synchronization, i.e., the establishment of temporal correspondence between frames of the first and second video, followed by spatial registration of all the temporally corresponding frames. Video synchronization and alignment have been attempted before, but most often in the relatively simple cases of fixed or rigidly attached cameras and simultaneous acquisition. In addition, restrictive assumptions have been applied, including linear time correspondence or the knowledge of the complete trajectories of corresponding scene points; to some extent, these assumptions limit the practical applicability of any solutions developed. We intend to solve the more general problem of aligning video sequences recorded by independently moving cameras that follow similar trajectories, based only on the fusion of image intensity and GPS information. The novelty of our approach is to pose the synchronization as a MAP inference problem on a Bayesian network including the observations from these two sensor types, which have been proved complementary. Alignment results are presented in the context of videos recorded from vehicles driving along the same track at different times, for different road types. In addition, we explore two applications of the proposed video alignment method, both based on change detection between aligned videos. One is the detection of vehicles, which could be of use in ADAS. The other is online difference spotting videos of surveillance rounds.",
Runtime Power Management of 3-D Multi-Core Architectures Under Peak Power and Temperature Constraints,"3-D integration is a new technology that overcomes the limitations of 2-D integrated circuits, e.g., power and delay induced from long interconnect wires, by stacking multiple dies to increase logic integration density. However, chip-level power and peak temperature are the major performance limiters in 3-D multi-core architectures. In this paper, we propose a runtime power management method for both peak power and temperature-constrained 3-D multi-core systems in order to maximize the instruction throughput. The proposed method exploits dynamic temperature slack (defined as peak temperature constraint minus current temperature) and workload characteristics (e.g., instructions per cycle and memory-boundness) as well as thermal characteristics of 3-D stacking architectures. Compared with existing thermal-aware power management solutions for 3-D multi-core systems, our method yields up to 34.2% (average 18.5%) performance improvement in terms of instructions per second without significant additional energy consumption.",
Fast efficient algorithm for enhancement of low lighting video,"We describe a novel and effective video enhancement algorithm for low lighting video. The algorithm works by first inverting an input low-lighting video and then applying an optimized image de-haze algorithm on the inverted video. To facilitate faster computation, temporal correlations between subsequent frames are utilized to expedite the calculation of key algorithm parameters. Simulation results show excellent enhancement results and 4× speed up as compared with the frame-wise enhancement algorithms.","Lighting,
Image color analysis,
Acceleration,
Cameras,
Equations,
Video sequences,
Mathematical model"
2D Principal Component Analysis for Face and Facial-Expression Recognition,"Although it shows enormous potential as a feature extractor, 2D principal component analysis produces numerous coefficients. Using a feature-selection algorithm based on a multiobjective genetic algorithm to analyze and discard irrelevant coefficients offers a solution that considerably reduces the number of coefficients, while also improving recognition rates.","Face recognition,
Principal component analysis,
Feature extraction,
Covariance matrix,
Databases,
Face,
Accuracy"
Bootstrapping opportunistic networks using social roles,"Opportunistic routing protocols can enable message delivery in disconnected networks of mobile devices. To conserve energy in mobile environments, such routing protocols must minimise unnecessary message-forwarding. This paper presents an opportunistic routing protocol that leverages social role information. We compute node roles from a social network graph to identify nodes with similar contact relationships, and use these roles to determine routing decisions. By using pre-existing social network information, such as online social network friends, to determine roles, we show that our protocol can bootstrap a new opportunistic network without the delay incurred by encounter-history-based routing protocols such as SimbetTS. Simulations with four real-world datasets show improved performance over SimbetTS, with performance approaching Epidemic routing in some scenarios.","Routing protocols,
Routing,
Social network services,
Batteries,
History,
Communities"
Acculock: Accurate and efficient detection of data races,"Happens-before detectors are precise but can be too conservative to detect certain data races in repeated test runs as they are sensitive to thread interleaving. By making the opposite tradeoffs, lockset detectors can detect more races but are not precise (by reporting false positives). For both types of detectors, happens-before detectors run more slowly as they use expensive vector clocks. Existing hybrid race detectors (combining lockset and happens-before) alleviate some of the limitations in both analysis techniques at the cost of additional analysis overhead. Recently, due to FastTrack, epoch-based happens-before and lockset detectors now exhibit comparable performance. It is the time to rethink how to design a hybrid race detector to balance precision and coverage, by leveraging the lightweightness of epoch clocks. Acculock is the first such a solution. Acculock analyzes a program by reasoning about the subset of the happens-before relation observed with lock acquires and releases excluded, thereby reducing its sensitivity to thread interleaving. When such a weaker happens-before relation is violated, Acculock applies a new efficient lockset algorithm to enforce a lock-based synchronization discipline by distinguishing the locks protecting reads and writes. The key motivation behind is to ensure that Acculock can improve happens-before detectors by discovering also data races in alternate thread interleavings when analyzing one program execution while limiting false warnings thus incurred in a controlled manner. In addition, Acculock achieves these objectives by maintaining comparable performance as FastTrack, the fastest happens-before detector. All these properties of Acculock are validated and confirmed by comparing it against six other detectors, all implemented in Jikes RVM using 11 benchmark programs.","Detectors,
Clocks,
Synchronization,
Instruction sets,
Copper,
Algorithm design and analysis"
Impact of packet loss on CACC string stability performance,"Recent development in wireless technology enables communication between vehicles. The concept of Co-operative Adaptive Cruise Control (CACC) - which uses wireless communication between vehicles - aims at string stable behaviour in a platoon of vehicles. “String stability” means any non-zero position, speed, and acceleration errors of an individual vehicle in a string do not amplify when they propagate upstream. In this paper, we will discuss the string stability of CACC and evaluate its performance with various packet loss ratios, beacon sending frequencies and time headway in simulations. The simulation framework is built up with a controller prototype, a traffic simulator, and a network simulator.","Vehicles,
Acceleration,
Stability analysis,
Wireless communication,
Time frequency analysis,
Wireless sensor networks,
Roads"
Rounding Semidefinite Programming Hierarchies via Global Correlation,"We show a new way to round vector solutions of semidefinite programming (SDP) hierarchies into integral solutions, based on a connection between these hierarchies and the spectrum of the in- put graph. We demonstrate the utility of our method by providing a new SDP-hierarchy based algorithm for constraint satisfaction problems with 2-variable constraints (2-CSP's). More concretely, we show for every 2-CSP instance 3, a rounding algorithm for r rounds of the Lasserre SDP hierarchy for 3 that obtains an integral solution which is at most ε worse than the relaxation's value (normalized to lie in [0, 1]), as long as r >; k·rank≥θ(3)/ poly(ε), where k is the alphabet size of J, θ = poly(ε/k), and rank≥θ(J) denotes the number of eigenvalues larger than θ in the normalized adjacency matrix of the constraint graph of J. In the case that J is a Unique Games instance, the threshold θ is only a polynomial in ε, and is independent of the alphabet size. Also in this case, we can give a non-trivial bound on the number of rounds for every instance. In particular our result yields an SDP-hierarchy based algorithm that matches the performance of the recent subexponential algorithm of Arora, Barak and Steurer (FOCS 2010) in the worst case, but runs faster on a natural family of instances, thus further restricting the set of possible hard instances for Khot's Unique Games Conjecture. Our algorithm actually requires less than the nolO(r) constraints specified by the rth level of the Lasserre hierarchy, and in some cases r rounds of our program can be evaluated in time 2O(r) poly(n).","Games,
Random variables,
Approximation methods,
Approximation algorithms,
Correlation,
Vectors,
Noise measurement"
The Next Wave of Sustainable IT,"Sustainable IT is developing into a discipline that's focused on the long-term importance of IT as a source of market-based innovative solutions to address societal problems. Increasingly, how companies impact society through their economic, environmental, and social actions defines their risks and opportunities, differentiates their products, and impacts their growth potential. The SITS framework provides a roadmap for IT managers on their new journey. Sustainability is a megatrend that follows a logical progression that organizations can anticipate to develop market-based innovative sustainability solutions. Organizations will need to demonstrate the long-term return on investments for new sustainable IT solutions. Traditional management metrics (cheaper, faster, and better solutions) don't capture the value of service-oriented sustainable IT solutions for this demonstrations developing into a discipline that's focused on the long-term importance of IT as a source of market-based innovative solutions to address societal problems. Increasingly, how companies impact society through their economic, environmental, and social actions defines their risks and opportunities, differentiates their products, and impacts their growth potential. The SITS framework provides a roadmap for IT managers on their new journey. Sustainability is a megatrend that follows a logical progression that organizations can anticipate to develop market-based innovative sustainability solutions. Organizations will need to demonstrate the long-term return on investments for new sustainable IT solutions. Traditional management metrics (cheaper, faster, and better solutions) don't capture the value of service-oriented sustainable IT solutions for this demonstration. We need research that addresses the intangibility and perishability of IT services.",
Adaptive Methodologies for Energy-Efficient Object Detection and Tracking With Battery-Powered Embedded Smart Cameras,"Battery-powered wireless embedded smart cameras have limited processing power, memory and energy. Since video processing tasks consume considerable amount of energy, it is essential to have lightweight algorithms to increase the energy efficiency of camera nodes. Moreover, just grabbing and buffering a frame require significant amount of energy. Thus, it is not sufficient to only focus on the vision algorithms. Methodologies are needed to determine when and how long a camera can be idle. In this paper, we first present a feedback method for detection and tracking, which provides significant savings in processing time. We take advantage of these savings by sending the microprocessor to idle state at the end of processing a frame. Then, we present an adaptive methodology that can send the camera to idle state not only when the scene is empty but also when there are target objects. Idle state duration is adaptively changed based on the speeds of tracked objects. We then introduce a combined method that employs the feedback method and the adaptive methodology together, and provides further savings in energy consumption. We provide a detailed comparison of these methods, and present experimental results showing the gains in processing time as well as the significant savings in energy consumption and increase in battery life.","Cameras,
Smart cameras,
Microprocessors,
Energy consumption,
Wireless communication,
Wireless sensor networks,
Pixel"
Following and interpreting narrated guided tours,"We describe a robotic tour-taking capability enabling a robot to acquire local knowledge of a human-occupied environment. A tour-taking robot autonomously follows a human guide through an environment, interpreting the guide's spoken utterances and the shared spatiotemporal context in order to acquire a spatially segmented and semantically labeled metrical-topological representation of the environment. The described tour-taking capability enables scalable deployment of mobile robots into human-occupied environments, and natural human-robot interaction for commanded mobility. Our primary contributions are an efficient, socially acceptable autonomous tour-following behavior and a tour interpretation algorithm that partitions a map into spaces labeled according to the guide's utterances. The tour-taking behavior is demonstrated in a multi-floor office building and evaluated by assessing the comfort of the tour guides, and by comparing the robot's map partitions to those produced by humans.","Humans,
Semantics,
Wheelchairs,
Mobile robots,
Simultaneous localization and mapping,
Laser radar"
Subpixel-Based Image Down-Sampling With Min-Max Directional Error for Stripe Display,"Subpixel-based down-sampling is a method that can potentially improve the apparent resolution of a down-scaled image by controlling individual subpixels rather than pixels. However, the increased luminance resolution often comes at the price of chrominance distortion. A major challenge is to suppress color fringing artifacts while maintaining sharpness. In this paper, we formulate the subpixel-based down-sampling as a Min-Max problem (Min-Max Directional Error) which we call MMDE. Unfortunately, the solution of MMDE is computational intensive, especially for large images. We thus relax the MMDE by approximating the maximization operation based on HVS, which we call MMDE with Visual Relaxation (MMDE-VR). Although MMDE-VR can reduce the computational complexity of MMDE largely, it is still not acceptable for real-time implementation. We make a further simplifying assumption based on the edge relationship of neighboring pixels, which we call MMDE with Edge Relaxation (MMDE-ER). Simulation results show that MMDE-VR and MMDE-ER can give significant sharper images compared with the conventional pixel-based down-sampling methods, with little color fringing artifacts.",
Device-architecture co-optimization of STT-RAM based memory for low power embedded systems,"Spin-transfer torque random access memory (STT-RAM) is a fast, scalable, durable non-volatile memory which can be embedded into standard CMOS process. A wide range of write speeds from 1ns to 100ns have been reported for STT-RAM. The switching current of magnetic tunnel junction (MTJ) (which is the storage element of STT-RAM) is inversely proportional to the write pulse width. In this work, we propose a methodology to design STT-RAM for different optimization goals such as read performance, write performance and write energy by leveraging the trade-off between write current and write time of MTJ. We take the typical in-plane MTJ and advanced perpendicular MTJ (PMTJ) as our optimization targets. Our study shows that reducing write pulse width will harm read latency and energy. It is observed that “sweet spots” of write pulse width which minimize the write energy or write latency of STT-RAM caches may exist. The optimal write pulse width depends on MTJ specifications, STT-RAM capacity and I/O width. The simulation results indicate that by utilizing PMTJ, the optimized STT-RAM can compete against SRAM and DRAM as universal memory replacement in low power embedded systems.","Switches,
Random access memory,
Computer architecture,
Transistors,
Microprocessors,
Magnetic tunneling,
Sensors"
Games as personality profiling tools,"In this paper we investigate whether a personality profile can be determined by observing a player's behavior in a game. Five personality traits are used to define a personality profile. They are adopted from the Five Factor Model of personality. The five traits are measured by the NEO-PI-R questionnaire. For our purpose, we developed a game module for the game Neverwinter Nights. The module automatically stores a player's behavioral data. Experimental trials were run measuring the behavior of 44 participants. The experiment produced game behavior scores for 275 game variables per player. Correlation analysis shows relationships between all five personality traits and the video game data. From these results, we may conclude that a video game can be used to create an adequate personality profile of a player.","Games,
Correlation,
Atmospheric measurements,
Particle measurements,
Training,
Computational intelligence,
Humans"
Parallel Programmable Asynchronous Neighborhood Mechanism for Kohonen SOM Implemented in CMOS Technology,"We present a new programmable neighborhood mechanism for hardware implemented Kohonen self-organizing maps (SOMs) with three different map topologies realized on a single chip. The proposed circuit comes as a fully parallel and asynchronous architecture. The mechanism is very fast. In a medium sized map with several hundreds neurons implemented in the complementary metal-oxide semiconductor 0.18 μm technology, all neurons start adapting the weights after no more than 11 ns. The adaptation is then carried out in parallel. This is an evident advantage in comparison with the commonly used software-realized SOMs. The circuit is robust against the process, supply voltage and environment temperature variations. Due to a simple structure, it features low energy consumption of a few pJ per neuron per a single learning pattern. In this paper, we discuss different aspects of hardware realization, such as a suitable selection of the map topology and the initial neighborhood range, as the optimization of these parameters is essential when looking from the circuit complexity point of view. For the optimal values of these parameters, the chip area and the power dissipation can be reduced even by 60% and 80%, respectively, without affecting the quality of learning.","Neurons,
Hardware,
Artificial neural networks,
Parallel programming,
Topology,
CMOS technology,
Self organizing feature maps"
Moving Region Segmentation From Compressed Video Using Global Motion Estimation and Markov Random Fields,"In this paper, we propose an unsupervised segmentation algorithm for extracting moving regions from compressed video using global motion estimation (GME) and Markov random field (MRF) classification. First, motion vectors (MVs) are compensated from global motion and quantized into several representative classes, from which MRF priors are estimated. Then, a coarse segmentation map of the MV field is obtained using a maximum a posteriori estimate of the MRF label process. Finally, the boundaries of segmented moving regions are refined using color and edge information. The algorithm has been validated on a number of test sequences, and experimental results are provided to demonstrate its advantages over state-of-the-art methods.","Motion segmentation,
Pixel,
Noise,
Quantization,
Image edge detection,
Markov random fields,
Motion estimation"
Kernel sparse representation with local patterns for face recognition,"In this paper we propose a novel kernel sparse representation classification (SRC) framework and utilize the local binary pattern (LBP) descriptor in this framework for robust face recognition. First we develop a kernel coordinate descent (KCD) algorithm for 11 minimization in the kernel space, which is based on the covariance update technique. Then we extract LBP descriptors from each image and apply two types of kernels (χ2 distance based and Hamming distance based) with the proposed KCD algorithm under the SRC framework for face recognition. Experiments on both the Extended Yale B and the PIE face databases show that the proposed method is more robust against noise, occlusion, and illumination variations, even with small number of training samples.","Kernel,
Face recognition,
Noise,
Training,
Lighting,
Databases,
Histograms"
Metadata Distribution and Consistency Techniques for Large-Scale Cluster File Systems,"Most supercomputers nowadays are based on large clusters, which call for sophisticated, scalable, and decentralized metadata processing techniques. From the perspective of maximizing metadata throughput, an ideal metadata distribution policy should automatically balance the namespace locality and even distribution without manual intervention. None of existing metadata distribution schemes is designed to make such a balance. We propose a novel metadata distribution policy, Dynamic Dir-Grain (DDG), which seeks to balance the requirements of keeping namespace locality and even distribution of the load by dynamic partitioning of the namespace into size-adjustable hierarchical units. Extensive simulation and measurement results show that DDG policies with a proper granularity significantly outperform traditional techniques such as the Random policy and the Subtree policy by 40 percent to 62 times. In addition, from the perspective of file system reliability, metadata consistency is an equally important issue. However, it is complicated by dynamic metadata distribution. Metadata consistency of cross-metadata server operations cannot be solved by traditional metadata journaling on each server. While traditional two-phase commit (2PC) algorithm can be used, it is too costly for distributed file systems. We proposed a consistent metadata processing protocol, S2PC-MP, which combines the two-phase commit algorithm with metadata processing to reduce overheads. Our measurement results show that S2PC-MP not only ensures fast recovery, but also greatly reduces fail-free execution overheads.","Servers,
File systems,
Decision support systems,
Protocols,
Manuals,
Heuristic algorithms,
Reliability"
Optimal utilization of storage and the induced price elasticity of demand in the presence of ramp constraints,"This paper is concerned with optimal utilization of storage, characterization of the economic value of storage in the presence of ramp-rate constraints and stochastically-varying electricity prices, and characterization of the price elasticity of demand induced by optimal utilization of storage. The ramp constraints limit the charging and discharging rate of storage, and can be due to the physical limitations of the storage device or the power lines. Such constraints make analytical characterization of optimal policies particularly difficult. In this paper, the optimal utilization problem is addressed in a finite-horizon stochastic dynamic programming framework, and an analytical characterization of the value function along with recursive formulas for computation of the associated optimal policy are derived. It is shown that the value function associated with the dynamic programming problem is a piecewise linear convex function of the storage state, i.e., the amount of stored energy. Furthermore, while the economic value of storage capacity is a non-decreasing function of price volatility, it is shown that due to finite ramping rates, the value of storage saturates quickly as the capacity increases, regardless of price volatility. Finally, it is shown that optimal utilization of storage by consumers could induce a considerable amount of price elasticity, particularly near the average price.","Biological system modeling,
Economics,
Elasticity,
Dynamic programming,
Real time systems,
Energy storage,
Electricity"
Analysis of Double-Negative (DNG) Bandwidths for Metamaterials Composed of Three-Dimensional Periodic Arrays of Two Different Magnetodielectric Spheres Arbitrarily Arranged on a Simple Tetragonal Lattice,"Based on the theory describing traveling waves on three-dimensional (3-D) periodic arrays of two sets of magnetodielectric spheres arbitrarily arranged on a simple tetragonal lattice, dispersion diagrams of seven different arrangements of the spheres are analyzed for three combinations of sphere types: I) dielectric spheres with equal permittivity but different radius; II) dielectric spheres with equal radius but different permittivity; and III) one set of spheres is purely dielectric while the other set is magnetic. Results show that the maximum bandwidths of the DNG region provided by different spheres arrangements for spheres combinations I-III are, respectively, 0.21%, 0.069%, and 7.403%. Compared to results reported in previous literature, analysis of these possible arrangements of the spheres shows similar narrow double-negative (DNG) bandwidths for spheres combinations I and II, and wider DNG bandwidths for spheres combination III. Although purely dielectric materials with relative permittivity much greater than one are readily available, the usefulness of purely dielectric DNG metamaterials still depends on whether the narrow bandwidths achievable are acceptable for the particular applications. Since purely magnetic materials with relative permeability much greater than one above 1 GHz are not currently available, the practicality of fabricating DNG metamaterials using arrays with spheres combination III is questionable for radio frequency (RF) applications, at least at present, despite the fact that this combination yields much wider DNG bandwidths than those of spheres combinations I and II.","Magnetic materials,
Metamaterials,
Magnetic resonance,
Periodic structures,
Three dimensional displays,
Dielectrics,
Lattices"
Scene classification with a sparse set of salient regions,"This work proposes an approach for scene classification by extracting and matching visual features only at the focuses of visual attention instead of the entire scene. Analysis over a database of natural scenes demonstrates that regions proposed by the saliency-based model of visual attention are robust to image transformations. Using a nearest neighbor classifier and a distance measure defined over the salient regions, we obtained 97.35% and 78.28% classification rates with SIFT and C2 features from the HMAX model at 5 salient regions covering at most 31% of the image. Classification with features extracted from the entire image results in 99.3% and 82.32% using SIFT and C2 features, respectively. Comparing attentional and adhoc approaches shows that classification rate of the first approach is 0.95 of the second. Overall, our results prove that efficient scene classification, in terms of reducing the complexity of feature extraction is possible without a significant drop in performance.","Feature extraction,
Visualization,
Computational modeling,
Detectors,
Image recognition,
Computational complexity,
Biology"
Parameter determination of Photovoltaic Cells from field testing data using particle swarm optimization,"This paper presents a swarm intelligence approach to extract equivalent circuit parameters of Photovoltaic (PV) Cells. The circuit model of a PV cell is non-linear and transcendental, which makes it difficult to solve using conventional numerical methods. Particle swarm optimization (PSO) was applied to extract the solar cell parameters. It has been confirmed that the proposed approach can obtain good parameter precision under the variations of solar insolation and environmental temperature.",
PASS: Privacy-preserving authentication scheme for smart grid network,"A smart grid power system is capable of adjusting the amount of electricity generated based on real-time requests from the smart meters of customers, thus avoiding excess electricity generation and facilitating reliable and effective transmission of electricity. To ensure that requests are sent from a valid user, all request messages must be authenticated. On the other hand, by analyzing the electricity usage pattern of a customer, the daily habit of the customer, such as when he is away, may be revealed. Thus, a proper privacy preserving mechanism has to be adopted. This paper attempts to develop a scheme to address these two seemingly contradicting requirements efficiently. By using a tamper-resistant device at the smart appliance and pseudo identities, we derive a privacy preserving authentication scheme to solve the problem. The authentication process is made very efficient by means of Hash-based Message Authentication Code (HMAC). Through simulation, we show that with our scheme, the transmission and signature verification delay induced are very small and the message overhead is only 20 bytes per request message. With our efficient verification process, even under attack, the substation can effectively drop all attack messages, allowing 6 times more valid messages to reach the control center when compared to the case without any verification. Thus our scheme is both efficient and effective.","Home appliances,
Substations,
Smart grids,
Electricity,
Public key,
Privacy"
Smartphone-based applications for investigating falls and mobility,"The aim of this study is to develop a system for investigating human falls and mobility based on a Smartphone platform. We have designed and tested a set of software applications building on the inertial data captured from the tri-axial accelerometer sensor embedded in the Smartphone. We will describe here two applications: a fall detection and management application, and an application for the administration of a popular and standardized test in the field of human mobility assessment, namely the Timed-Up-and-Go test.",
On the Measurement and Calculation of Horizontal Electric Fields From Lightning,"In this paper, we discuss two issues related to the measurement and calculation of the horizontal electric fields from lightning. On the one hand, there is an inherent difficulty in measuring the horizontal electric field component from lightning because of the overshadowing effect of the vertical electric field component which, depending on the distance to the lightning channel, the ground conductivity, and the height of the observation point can be one to two orders of magnitude larger than the horizontal electric field component. Consequently, even a small tilt of the measuring antenna would result in a noticeable contamination of the measured horizontal waveform. This may explain the fact that data on horizontal electric fields are very scarce. Numerical simulations show that, for a ground conductivity of 0.0025 S/m, the resulting error for a one-degree sensor tilt in the field peak is about 20% for distances ranging from 60 to 500 m. For strikes to a 100-m-tall tower, the resulting errors are found to be slightly smaller (about 10% to 15% for the first peak). The second issue dealt with in this paper is the computation methods of the horizontal electric field. In this regard, some authors have emphasized the importance of taking into account the so-called conduction current in the calculation of nearby horizontal electric fields. We show in this paper that the conducted contribution is automatically taken into account when using the general solutions of Maxwell's equations or obtained by exact numerical simulations. In this case, there is no need to consider separately any other contributions because the solution yields the total horizontal electric field, taking into account both the radiation from the channel and the current flowing into the ground. However, a “conducted contribution” needs indeed to be taken into account separately when high-frequency approximate solutions are used for the evaluation of the electric field. At very close distances to the lightning strike location, the current distribution in the ground may be highly nonuniform because of surface arcing and plasma channel formations. Given the random nature of these phenomena, it is virtually impossible to gain detailed knowledge of the current distribution and, hence, to evaluate the resulting horizontal electric field near the strike point. Based on the results and discussion presented in this paper, we recommend taking special care when measuring the horizontal electric field from lightning to minimize the contaminating effect of the vertical electric field. It is important that both components (vertical and horizontal) be measured simultaneously to evaluate possible contamination of the horizontal field.","Lightning,
Pollution measurement,
Current measurement,
Sea measurements,
Time domain analysis,
Antenna measurements"
Automated Assembly for Mesoscale Parts,"This paper describes a test-bed for planar micro and mesoscale manipulation tasks and a framework for planning based on quasi-static models of mechanical systems with intermittent frictional contacts. We show how planar peg-in-the-hole assembly tasks can be designed using randomized motion planning techniques with Mason's models for quasi-static manipulation. Simulation and experimental results are presented in support of our methodology. We develop this further into a systematic approach to incorporating uncertainty into planning manipulation tasks with frictional contacts. We again consider the canonical problem of assembling a peg into a hole at the mesoscale using probes with minimal actuation but with visual feedback from an optical microscope. We consider three sources of uncertainty. First, because of errors in sensing position and orientation of the parts to be assembled, we must consider uncertainty in the sensed configuration of the system. Second, there is uncertainty because of errors in actuation. Third, there are geometric and physical parameters characterizing the environment that are unknown. We discuss the synthesis of robust planning primitives using a single degree-of-freedom probe and the automated generation of plans for mesoscale manipulation. We show simulation and experimental results of our work.",
Tracking by Third-Order Tensor Representation,"This paper proposes a robust tracking algorithm by third-order tensor representation and adaptive appearance modeling. In this method, the target in each video frame is represented by a third-order tensor. This representation preserves the spatial correlation inside the target region and can integrate multiple appearance cues for target description. Based on this representation, a multilinear subspace is learned online to model the target appearance variations during tracking. Compared to other methods, our approach can detect local spatial structure in the target tensor space and fuse information from different feature spaces. Therefore, the learned appearance model is more discriminative when there are significant appearance variations of the target or when the background gets cluttered. Applying the multilinear algebra, our appearance model can efficiently be learned and updated online, without causing high-dimensional data-learning problems. Then, tracking is implemented in the Bayesian inference framework, where a likelihood model is defined to measure the similarity between a test sample and the learned appearance model, and a particle filter is used to recursively estimate the target state over time. Theoretic analysis and experiments compared with other state-of-the-art methods demonstrate the effectiveness of the proposed approach.","Tensile stress,
Target tracking,
Robustness,
Fuses,
Algebra,
Particle tracking,
Bayesian methods,
Particle measurements,
Time measurement,
Testing"
Gyrokinetic toroidal simulations on leading multi- and manycore HPC systems,"The gyrokinetic Particle-in-Cell (PIC) method is a critical computational tool enabling petascale fusion simulation re- search. In this work, we present novel multi- and manycore-centric optimizations to enhance performance of GTC, a PIC-based production code for studying plasma microturbulence in tokamak devices. Our optimizations encompass all six GTC sub-routines and include multi-level particle and grid decompositions designed to improve multi-node parallel scaling, particle binning for improved load balance, GPU acceleration of key subroutines, and memory-centric optimizations to improve single-node scaling and reduce memory utilization. The new hybrid MPI-OpenMP and MPI-OpenMP-CUDA GTC versions achieve up to a 2× speedup over the production Fortran code on four parallel systems - clusters based on the AMD Magny-Cours, Intel Nehalem-EP, IBM BlueGene/P, and NVIDIA Fermi architectures. Finally, strong scaling experiments provide insight into parallel scalability, memory utilization, and programmability trade-offs for large-scale gyrokinetic PIC simulations, while attaining a 1.6× speedup on 49,152 XE6 cores.","Graphics processing unit,
Optimization,
Computational modeling,
Kernel,
Instruction sets,
Programming,
Parallel processing"
Online multiple support instance tracking,"We propose an online tracking algorithm in which the support instances are selected adaptively within the multiple instance learning framework. The support instances are selected from training 1-norm support vector machines in a feature space, thereby learning large margin classifiers for visual tracking. An algorithm is presented to update the support instances by taking image data obtained previously and recently into account. In addition, a forgetting factor is introduced to weigh the contribution of support instances obtained at different time stamps. Experimental results demonstrate that our tracking algorithm is robust in handling occlusion, abrupt motion and illumination.",
Optimal Placement of Fault Indicators Using the Immune Algorithm,"This paper examines the application of the immune algorithm for the problem of optimal placement of fault indicators to minimize the total cost of customer service outage and investment cost of fault indicators. The reliability index of each service zone is derived to solve the expected energy not served due to fault contingency, and the customer interruption cost is then determined according to the customer type and power consumption within the service zone. To demonstrate the effectiveness of the proposed IA methodology and solve the optimal placement of fault indicators, a practical distribution feeder of Taiwan Power Company is selected for computer simulation to explore the cost benefit of fault indicator placement.","Cost function,
Automation,
Power system restoration,
Customer service,
Investments,
Power system economics,
Power generation economics,
Power system reliability,
Fault detection,
Energy consumption"
Near Optimal Column-Based Matrix Reconstruction,"We consider low-rank reconstruction of a matrix using a subset of its columns and we present asymptotically optimal algorithms for both spectral norm and Frobenius norm reconstruction. The main tools we introduce to obtain our results are: (i) the use of fast approximate SVD-like decompositions for column-based matrix reconstruction, and (ii) two deterministic algorithms for selecting rows from matrices with orthonormal columns, building upon the sparse representation theorem for decompositions of the identity that appeared in [1].","Approximation methods,
Vectors,
Approximation algorithms,
Matrix decomposition,
Sparse matrices,
Symmetric matrices,
Accuracy"
Matrix Multiplication Using Quantum-Dot Cellular Automata to Implement Conventional Microelectronics,"Quantum-dot cellular automata (QCA) shows promise as a postsilicon CMOS, low-power computational technology. Nevertheless, to generalize QCA for next-generation digital devices, the ability to implement conventional programmable circuits based on nor, and , and or gates is necessary. To this end, we devise a new QCA structure, the QCA matrix multiplier (MM), employing the standard Coulomb blocked, five quantum-dot QCA cell and quasi-adiabatic switching for sequential data latching in the QCA cells. Our structure can multiply two N × M matrices, using one input and one bidirectional input/output data line. The calculation is highly parallelizable, and it is possible to achieve reduced calculation time in exchange for increasing numbers of parallel MM units. We show convergent, ab initio simulation results using the intercellular Hartree approximation for one, three, and nine MM units. The structure can generally implement any programmable logic array or any matrix multiplication-based operation.","Clocks,
Quantum dots,
Logic gates,
Automata,
Programmable logic arrays,
Computer architecture,
Switches"
VAMPIRE: Vessel assessment and measurement platform for images of the REtina,"We present VAMPIRE, a software application for efficient, semi-automatic quantification of retinal vessel properties with large collections of fundus camera images. VAMPIRE is also an international collaborative project of four image processing groups and five clinical centres. The system provides automatic detection of retinal landmarks (optic disc, vasculature), and quantifies key parameters used frequently in investigative studies: vessel width, vessel branching coefficients, and tortuosity. The ultimate vision is to make VAMPIRE available as a public tool, to support quantification and analysis of large collections of fundus camera images.",
"Mining large graphs: Algorithms, inference, and discoveries","How do we find patterns and anomalies, on graphs with billions of nodes and edges, which do not fit in memory? How to use parallelism for such terabyte-scale graphs? In this work, we focus on inference, which often corresponds, intuitively, to “guilt by association” scenarios. For example, if a person is a drug-abuser, probably its friends are so, too; if a node in a social network is of male gender, his dates are probably females. We show how to do inference on such huge graphs through our proposed HADOOP Line graph Fixed Point (HA-LFP), an efficient parallel algorithm for sparse billion-scale graphs, using the HADOOP platform. Our contributions include (a) the design of HA-LFP, observing that it corresponds to a fixed point on a line graph induced from the original graph; (b) scalability analysis, showing that our algorithm scales up well with the number of edges, as well as with the number of machines; and (c) experimental results on two private, as well as two of the largest publicly available graphs - the Web Graphs from Yahoo! (6.6 billion edges and 0.24 Tera bytes), and the Twitter graph (3.7 billion edges and 0.13 Tera bytes). We evaluated our algorithm using M45, one of the top 50 fastest supercomputers in the world, and we report patterns and anomalies discovered by our algorithm, which would be invisible otherwise.","Equations,
Algorithm design and analysis,
Belief propagation,
Inference algorithms,
Data mining,
Convergence,
Scalability"
Achieving Proportional Fairness via AP Power Control in Multi-Rate WLANs,"In this paper, we consider how to achieve proportional fairness in multi-rate 802.11 WLANs by investigating an integrated problem of power control and AP Association in order to provide an effective tradeoff between network throughput and fairness. Since jointly considering power control and AP association for proportional fairness is NP-hard, we propose a centralized heuristic approach. By introducing a new concept of AP utility, we establish the relationship between the network utility and the AP utility according to proportional fairness. This relationship is exploited to design an algorithm PCAP to optimize the network utility by increasing the average and decreasing the variance of the AP utility. Extensive simulation study is performed and the results demonstrate that PCAP yields a significant improvement in terms of throughput, fairness, and power consumption compared to other popular power control algorithms.","Power control,
Throughput,
Interference,
Bandwidth,
Bit rate,
Signal to noise ratio,
IEEE 802.11 Standards"
A Large-Deviation Analysis of the Maximum-Likelihood Learning of Markov Tree Structures,"The problem of maximum-likelihood (ML) estimation of discrete tree-structured distributions is considered. Chow and Liu established that ML-estimation reduces to the construction of a maximum-weight spanning tree using the empirical mutual information quantities as the edge weights. Using the theory of large-deviations, we analyze the exponent associated with the error probability of the event that the ML-estimate of the Markov tree structure differs from the true tree structure, given a set of independently drawn samples. By exploiting the fact that the output of ML-estimation is a tree, we establish that the error exponent is equal to the exponential rate of decay of a single dominant crossover event. We prove that in this dominant crossover event, a non-neighbor node pair replaces a true edge of the distribution that is along the path of edges in the true tree graph connecting the nodes in the non-neighbor pair. Using ideas from Euclidean information theory, we then analyze the scenario of ML-estimation in the very noisy learning regime and show that the error exponent can be approximated as a ratio, which is interpreted as the signal-to-noise ratio (SNR) for learning tree distributions. We show via numerical experiments that in this regime, our SNR approximation is accurate.","Markov processes,
Mutual information,
Graphical models,
Maximum likelihood estimation,
Approximation methods,
Signal to noise ratio,
Error probability"
An efficient algorithm of adjustable delay buffer insertion for clock skew minimization in multiple dynamic supply voltage designs,"Power consumption is known to be a crucial issue in current IC designs. To tackle this problem, multiple dynamic supply voltage (MDSV) designs are proposed as an efficient solution in modern IC designs. However, the increasing variability of clock skew during the switching of power modes leads to an increase in the complication of clock skew reduction in MDSV designs. In this paper, we propose a tunable clock tree structure by adopting the adjustable delay buffers (ADBs). The ADBs can be used to produce additional delays, hence the clock latencies and skew become tunable in a clock tree. Importing a buffered clock tree, the ADBs with delay value assignments are inserted to reduce clock skew in MDSV designs. An efficient algorithm of ADB insertion for the minimization of clock skew, area, and runtime in MDSV designs has been presented. Comparing with the state-of-the-art algorithm, experimental results show maximum 42.40% area overhead improvement and 117.84× runtime speedup.","Delay,
Clocks,
Algorithm design and analysis,
Transistors,
Benchmark testing,
Merging,
Switches"
Data clustering with modified K-means algorithm,"This paper presents a data clustering approach using modified K-Means algorithm based on the improvement of the sensitivity of initial center (seed point) of clusters. This algorithm partitions the whole space into different segments and calculates the frequency of data point in each segment. The segment which shows maximum frequency of data point will have the maximum probability to contain the centroid of cluster. The number of cluster's centroid (k) will be provided by the user in the same manner like the traditional K-mean algorithm and the number of division will be k*k (`k' vertically as well as `k' horizontally). If the highest frequency of data point is same in different segments and the upper bound of segment crosses the threshold `k' then merging of different segments become mandatory and then take the highest k segment for calculating the initial centroid (seed point) of clusters. In this paper we also define a threshold distance for each cluster's centroid to compare the distance between data point and cluster's centroid with this threshold distance through which we can minimize the computational effort during calculation of distance between data point and cluster's centroid. It is shown that how the modified k-mean algorithm will decrease the complexity & the effort of numerical calculation, maintaining the easiness of implementing the k-mean algorithm. It assigns the data point to their appropriate class or cluster more effectively.","Clustering algorithms,
Partitioning algorithms,
Data mining,
Algorithm design and analysis,
Mathematical model,
Equations,
Machine learning algorithms"
CA-Tree: A Hierarchical Structure for Efficient and Scalable Coassociation-Based Cluster Ensembles,"Cluster ensembles have attracted a lot of research interests in recent years, and their applications continue to expand. Among the various algorithms for cluster ensembles, those based on coassociation matrices are probably the ones studied and used the most because coassociation matrices are easy to understand and implement. However, the main limitation of coassociation matrices as the data structure for combining multiple clusterings is the complexity that is at least quadratic to the number of patterns N. In this paper, we propose CA-tree, which is a dendogram-like hierarchical data structure, to facilitate efficient and scalable cluster ensembles for coassociation-matrix-based algorithms. All the properties of the CA-tree are derived from base cluster labels and do not require the access to the original data features. We then apply a threshold to the CA-tree to obtain a set of nodes, which are then used in place of the original patterns for ensemble-clustering algorithms. The experiments demonstrate that the complexity for coassociation-based cluster ensembles can be reduced to close to linear to N with minimal loss on clustering accuracy.","Clustering algorithms,
Complexity theory,
Prototypes,
Partitioning algorithms,
Upper bound,
Buildings,
Diversity reception"
Ergodic Fading Z-Interference Channels Without State Information at Transmitters,"This paper studies the capacity region of a two-user ergodic interference channel with fading, where only one user is subject to interference from the other user, and the channel state information (CSI) is only available at the receivers. A layered erasure model with arbitrary fading statistics is studied first, whose capacity region is completely determined as a polygon. Each dominant rate pair can be regarded as the outcome of a tradeoff between the rate of the interference-free user and the rate loss its interference causes the other user. Using insights from the layered erasure model, inner and outer bounds of the capacity region are provided for fading Gaussian Z-interference channels. The gap between the inner and outer bounds is no more than 12.8 bits per channel use per user, regardless of the signal-to-noise ratio (SNR) and fading statistics.","Fading,
Interference,
Transmitters,
Receivers,
Integrated circuit modeling,
Adaptation model"
A 1-GHz Digital PLL With a 3-ps Resolution Floating-Point-Number TDC in a 0.18- \mu\hbox{m} CMOS,"A new concept of floating-point-number representation is implemented in a time-to-digital converter (TDC), which adaptively scales its resolution according to the amount of input difference. With a fixed 6-bit significand number, the TDC provides five cases of the exponent (x1, x2, x4, x8, and x16) to indicate the scale information. A digital phase-locked loop (PLL) with the TDC is implemented in a 0.18-μm CMOS. The TDC shows the minimum resolution of 3 ps with a total conversion range of 3.5 ns, the maximum operating frequency of 80 MHz, and the power consumption of 18 mW at 75 MHz. The PLL shows a lock range of 0.9-1.25 GHz and a root-mean-square jitter of 3.5 ps at 1.2 GHz.","Jitter,
Phase locked loops,
CMOS integrated circuits,
Converters,
Delay,
Phase frequency detector,
Solid state circuits"
Gallium nitride-on-silicon micromechanical overtone resonators and filters,"In this paper, for the first time, we report on high-performance GaN-on-silicon micromechanical resonators and filters. A GaN-on-silicon resonator is reported which exhibits a quality factor of 1850 at 802.5 MHz, resulting in an f×Q value twice the highest reported for GaN-based resonators to date. The effective coupling coefficient for the GaN resonator is extracted to be 1.7%, which is among the best reported in the literature.","Gallium nitride,
Silicon,
Resonator filters,
Resonant frequency,
Film bulk acoustic resonators,
Electrodes"
Compressive Sensing SAR Image Reconstruction Based on Bayesian Framework and Evolutionary Computation,"Compressive sensing (CS) is a theory that one may achieve an exact signal reconstruction from sufficient CS measurements taken from a sparse signal. However, in practical applications, the transform coefficients of SAR images usually have weak sparsity. Exactly reconstructing these images is very challenging. A new Bayesian evolutionary pursuit algorithm (BEPA) is proposed in this paper. A signal is represented as the sum of a main signal and some residual signals, and the generalized Gaussian distribution (GGD) is employed as the prior of the main signal and the residual signals. BEPA decomposes the residual iteratively and estimates the maximum a posteriori of the main signal and the residual signals by solving a sequence of subproblems to achieve the approximate CS reconstruction of the signal. Under the assumption of GGD with the parameter 0 <; p <; 1, the evolutionary algorithm (EA) is introduced to CS reconstruction for the first time. The better reconstruction performance can be achieved by searching the global optimal solutions of subproblems with EA. Numerical experiments demonstrate that the important features of SAR images (e.g., the point and line targets) can be well preserved by our algorithm, and the superior reconstruction performance can be obtained at the same time.",
Automatically exploring how uncertainty impacts behavior of dynamically adaptive systems,"A dynamically adaptive system (DAS) monitors itself and its execution environment to evaluate requirements satisfaction at run time. Unanticipated environmental conditions may produce sensory inputs that alter the self-assessment capabilities of a DAS in unpredictable and undesirable ways. Moreover, it is impossible for a human to know or enumerate all possible combinations of system and environmental conditions that a DAS may encounter throughout its lifetime. This paper introduces Loki, an approach for automatically discovering combinations of environmental conditions that produce requirements violations and latent behaviors in a DAS. By anticipating adverse environmental conditions that might arise at run time, Loki facilitates the identification of goals with inadequate obstacle mitigations or insufficient constraints to prevent such unwanted behaviors. We apply Loki to an autonomous vehicle system and describe several undesirable behaviors discovered.","Monitoring,
Unified modeling language,
Evolutionary computation,
Adaptation models,
Noise,
Adaptive systems,
Noise measurement"
Fingerprinting-based radio localization in indoor environments using multiple wireless technologies,"Localizing a user is a fundamental problem that arises in many potential applications. The use of wireless technologies for locating a user has been a trend in recent years. Most existing approaches use RSSI to localize the user. In general, one of the several existing wireless standards such as ZigBee, Bluetooth or Wi-Fi, is chosen as the target standard. An interesting question that has practical implications is whether there is any benefit in using more than one wireless technology to perform the localization. In this paper we present a study on the advantages and challenges of using multiple wireless technologies to perform localization in indoor environments. We use real ZigBee, Wi-Fi and Bluetooth compliant devices. In our study we analyse results obtained using the fingerprint method. The performance of each technology alone and the performance of the technologies combined are also investigated. We also analyse how the number of wireless devices used affects the quality of localization and show that, for all technologies, more beacons lead to less error. Finally, we show how interference among technologies may lead to lower localization accuracy.",
Wireless acoustic wave sensors and systems for harsh environment applications,"This paper reviews current progress in the area of wireless microwave acoustic sensor technology, and discusses advances in wireless interrogation systems that can operate in harsh environments. The use of wireless, battery-free, low maintenance surface acoustic wave (SAW) sensors has been successfully demonstrated in applications including high temperature turbine engines and inflatable aerospace structures. Wireless interrogation of multiple sensors up to 910°C has been established and sensor tests in gas turbine engine are reported. This paper elaborates on several aspects of the technology, including: high-temperature thin-film electrode and sensor development, temperature cycling, thermal-shock behavior, testing in turbine engine environments, sensor packaging and attachment, wireless operation, and adaptation to energy and industrial applications.",
Using comparative human descriptions for soft biometrics,"Soft biometrics is a new form of biometric identification which utilizes labeled physical or behavioral traits. Al though these traits intuitively have less discriminatory capability than mensurate approaches, they offer several ad vantages over traditional biometric techniques. Soft bio metric traits can be typically described as labels and measurements which can be understood by people, allowing retrieval and recognition based solely on human descriptions. Although being a key component of eyewitness evidence, conventional human descriptions can be considered to be unreliable. A novel method of obtaining human descriptions will be introduced which utilizes visual comparisons between subjects. The Elo rating system is used to infer relative measurements of subjects' traits based on the comparative human descriptions. This innovative approach to obtaining human descriptions has been shown to counter many problems associated with categorical (absolute) labels. The resulting soft biometric signatures have been demonstrated to be robust and allow accurate retrieval of subjects in video data and show that elapsed time can have little effect on comparative descriptions.","Equations,
Estimation,
Robustness,
Hip,
Educational institutions"
On Symmetric Boolean Functions With High Algebraic Immunity on Even Number of Variables,"In this paper, we put forward an efficient method to study the symmetric Boolean functions with high algebraic immunity on even number of variables. We obtain some powerful necessary conditions for symmetric Boolean functions to achieve high algebraic immunity by studying the weight support of some specific types of Boolean functions of low degrees. With these results, we prove that the algebraic immunity of a large class of symmetric correlation immune Boolean functions, namely the symmetric palindromic functions, is not high. Besides, we construct all symmetric Boolean functions with maximum algebraic immunity and give a description for those with submaximum algebraic immunity. We also determine the Hamming weight, degrees and nonlinearity of the symmetric Boolean functions with maximum algebraic immunity.","Boolean functions,
Artificial intelligence,
Hamming weight,
Cryptography,
Education,
Measurement,
Correlation"
Ensuring data storage security through a novel third party auditor scheme in cloud computing,"Cloud computing technology has been looked upon as the next-generation architecture of IT solution. It enables the users to move their data and application software to the network which is different from traditional solutions. Due to this IT services are not under logical, physical and users' controls, it brings many new different security challenges. Ensuring data storage security is one more urgent of them. The representative network architecture for cloud data storage includes a third party auditor which affords trustful authentication for user to operate their data security in cloud. In this paper, we study the problem of data storage security in cloud computing. A novel third party auditor scheme is proposed. The obvious advantage of our scheme is the cloud service provider can offer the functions which were provided by the traditional third party auditor and make it trustful. So it indeed reduces the constitution's complexity in Cloud Computing.","Cloud computing,
Servers,
Authentication,
Memory,
Computer architecture,
Cryptography"
A New Symmetric Key Cryptography Algorithm Using Extended MSA Method: DJSA Symmetric Key Algorithm,"In the present work the authors introduced a new symmetric key cryptographic method for encryption as well as decryption of any file such as binary file, text file or any other file. Nath et. al. (1) developed an algorithm called MSA for encryption and decryption of any file using a random key square matrix containing 256 elements. The weak point of MSA algorithm is that if someone applies the brute force method then he has to give a trial for factorial 256 to find the actual key matrix. Now in the modern world this number of trial runs may not be impossible for the hacker. To get rid of this problem here the authors suggest a better algorithm than MSA. In the present method the authors considered the size of the key matrix to be 65536 and in each cell we store 2 characters pattern instead of 1 character unlike MSA method. If someone wants to give a brute force method to find our actual key then one has to give a trial for factorial 65536 runs! Theoretically this is an intractable problem. Moreover the authors have also introduced multiple encryptions here to make the system more secured. This method will be suitable in any business house, government sectors, communication network, defense network system, sensor networks etc. In the present work the authors have introduced a square key matrix of size 256 by 256 where in each cell there are all possible 2-lettered words (ASCII code 0-255). The total number of words possible is 65536. The key matrix is then randomized using the method proposed by Nath et. al(1). The user has to enter some secret text-key. The maximum length of the text key should be 16 characters long. To calculate the randomization number and the number of encryption to be done is calculated from the text-key using a method proposed by Nath et.al(1). The present method will be most suitable for encryption of a file whose size is less than or equal to 2MB. If the file size is very big then we suggest choosing small encryption number to speed up the system.","Encryption,
Barium,
Public key cryptography,
Communication networks,
Computer science,
Educational institutions"
Efficient information-theoretic graph pruning for graph-based SLAM with laser range finders,"In graph-based SLAM, the pose graph encodes the poses of the robot during data acquisition as well as spatial constraints between them. The size of the pose graph has a substantial influence on the runtime and the memory requirements of a SLAM system, which hinders long-term mapping. In this paper, we address the problem of efficient information-theoretic compression of pose graphs. Our approach estimates the expected information gain of laser measurements with respect to the resulting occupancy grid map. It allows for restricting the size of the pose graph depending on the information that the robot acquires about the environment or based on a given memory limit, which results in an any-space SLAM system. When discarding laser scans, our approach marginalizes out the corresponding pose nodes from the graph. To avoid a densely connected pose graph, which would result from exact marginalization, we propose an approximation to marginalization that is based on local Chow-Liu trees and maintains a sparse graph. Real world experiments suggest that our approach effectively reduces the growth of the pose graph while minimizing the loss of information in the resulting grid map.","Measurement by laser beam,
Simultaneous localization and mapping,
Approximation methods,
Lasers,
Mutual information,
Laser beams"
Multiscale - Patient-Specific Artery and Atherogenesis Models,"In this work, we present a platform for the development of multiscale patient-specific artery and atherogenesis models. The platform, called ARTool, integrates technologies of 3-D image reconstruction from various image modalities, blood flow and biological models of mass transfer, plaque characterization, and plaque growth. Patient images are acquired for the development of the 3-D model of the patient specific arteries. Then, blood flow is modeled within the arterial models for the calculation of the wall shear stress distribution (WSS). WSS is combined with other patient-specific parameters for the development of the plaque progression models. Real-time simulation can be performed for same cases in grid environment. The platform is evaluated using both animal and human data.","Mathematical model,
Arteries,
Image reconstruction,
Biological system modeling,
Three dimensional displays,
Blood flow,
Equations"
Support Vector Selection and Adaptation for Remote Sensing Classification,"Classification of nonlinearly separable data by nonlinear support vector machines (SVMs) is often a difficult task, particularly due to the necessity of choosing a convenient kernel type. Moreover, in order to get the optimum classification performance with the nonlinear SVM, a kernel and its parameters should be determined in advance. In this paper, we propose a new classification method called support vector selection and adaptation (SVSA) which is applicable to both linearly and nonlinearly separable data without choosing any kernel type. The method consists of two steps: selection and adaptation. In the selection step, first, the support vectors are obtained by a linear SVM. Then, these support vectors are classified by using the K-nearest neighbor method, and some of them are rejected if they are misclassified. In the adaptation step, the remaining support vectors are iteratively adapted with respect to the training data to generate the reference vectors. Afterward, classification of the test data is carried out by 1-nearest neighbor with the reference vectors. The SVSA method was applied to some synthetic data, multisource Colorado data, post-earthquake remote sensing data, and hyperspectral data. The experimental results showed that the SVSA is competitive with the traditional SVM with both linearly and nonlinearly separable data.",
Sparse concept coding for visual analysis,"We consider the problem of image representation for visual analysis. When representing images as vectors, the feature space is of very high dimensionality, which makes it difficult for applying statistical techniques for visual analysis. To tackle this problem, matrix factorization techniques, such as Singular Vector Decomposition (SVD) and Non-negative Matrix Factorization (NMF), received an increasing amount of interest in recent years. Matrix factorization is an unsupervised learning technique, which finds a basis set capturing high-level semantics in the data and learns coordinates in terms of the basis set. However, the representations obtained by them are highly dense and can not capture the intrinsic geometric structure in the data. In this paper, we propose a novel method, called Sparse Concept Coding (SCC), for image representation and analysis. Inspired from the recent developments on manifold learning and sparse coding, SCC provides a sparse representation which can capture the intrinsic geometric structure of the image space. Extensive experimental results on image clustering have shown that the proposed approach provides a better representation with respect to the semantic structure.","Sparse matrices,
Encoding,
Manifolds,
Matrix decomposition,
Semantics,
Algorithm design and analysis,
Optimization"
An adaptive brain-computer interface for humanoid robot control,"Recent advances in neuroscience and humanoid robotics have allowed initial demonstrations of brain-computer interfaces (BCIs) for controlling humanoid robots. However, previous BCIs have relied on higher-level control based on fixed pre-wired behaviors. On the other hand, low-level control can be tedious, imposing a high cognitive load on the BCI user. To address these problems, we previously proposed an adaptive hierarchical approach to brain-computer interfacing: users teach the BCI system new skills on-the-fly; these skills can later be invoked directly as high-level commands, relieving the user of tedious control. In this paper, we explore the application of hierarchical BCIs to the task of controlling a PR2 humanoid robot and teaching it new skills. We further explore the use of explicitly-defined sequences of commands as a way for the user to define a more complex task involving multiple state spaces. We report results from three subjects who used a hierarchical electroencephalogram (EEG)-based BCI to successfully train and control the PR2 humanoid robot in a simulated household task maneuvering the robot's arm to pour milk over a bowl of cereal. We present the first demonstration of training a hierarchical BCI for a non-navigational task. This is also the first demonstration of using one to train a more complex task involving multiple state spaces.","Humanoid robots,
Trajectory,
Training,
Grippers,
Humans,
Dairy products"
Design and Analysis of Varactor-Less Interpolative-Phase-Tuning Millimeter-Wave LC Oscillators with Multiphase Outputs,"An interpolative-phase-tuning (IPT) technique is proposed to tune the frequency of millimeter-wave (MMW) LC-based ring oscillators without using varactor. As a key feature, the tradeoff between tank Q and tuning range of the proposed IPT oscillators is independent of the operation frequency, which makes the IPT technique suitable for applications at MMW frequencies. Moreover, the IPT oscillators can achieve larger frequency tuning range and much better phase accuracy over the tuning range as compared to the conventional gm-coupled LC oscillators for multiphase generation. Two IPT oscillator prototypes are designed and implemented in a 0.13-μm CMOS process. The first one operates at 50 GHz with eight output phases and measures phase noise of -103.7 dBc/Hz at 1-MHz offset and -127.8 dBc/Hz at 10-MHz offset, tuning range of 6.8%, and figure of merit (FOM) of 186.4 dB while occupying chip area of 0.36 mm2. The second prototype oscillates at 60 GHz with four output phases and measures phase noise of -95.5 dBc/Hz at 1-MHz offset, -120.6 dBc/Hz at 10-MHz offset, tuning range of 9%, and FOM of 180.6 dB with chip area of 0.2 mm2.","Tuning,
Phase noise,
Ring oscillators,
Delay,
Varactors"
Rank-Constrained Schur-Convex Optimization With Multiple Trace/Log-Det Constraints,"Rank-constrained optimization problems have received an increasing intensity of interest recently, because many optimization problems in communications and signal processing applications can be cast into a rank-constrained optimization problem. However, due to the nonconvex nature of rank constraints, a systematic solution to general rank-constrained problems has remained open for a long time. In this paper, we focus on a rank-constrained optimization problem with a Schur-convex/concave objective function and multiple trace/log-determinant constraints. We first derive a structural result on the optimal solution of the rank-constrained problem using majorization theory. Based on the solution structure, we transform the rank-constrained problem into an equivalent problem with a unitary constraint. After that, we derive an iterative projected steepest descent algorithm which converges to a local optimal solution. Furthermore, we shall show that under some special cases, we can derive a closed-form global optimal solution. The numerical results show the superior performance of our proposed technique over the baseline schemes.",
Which Networks are Least Susceptible to Cascading Failures?,"The spread of a cascading failure through a network is an issue that comes up in many domains - in the contagious failures that spread among financial institutions during a financial crisis, through nodes of a power grid or communication network during a widespread outage, or through a human population during the outbreak of an epidemic disease. Here we study a natural model of threshold contagion: each node v is assigned a numerical threshold ℓ(v) drawn independently from an underlying distribution μ, and v will fail as soon as ℓ(v) of its neighbors fail. Despite the simplicity of the formulation, it has been very challenging to analyze the failure processes that arise from arbitrary threshold distributions; even qualitative questions concerning which graphs are the most resilient to cascading failures in these models have been difficult to resolve. Here we develop a set of new techniques for analyzing the failure probabilities of nodes in arbitrary graphs under this model, and we compare different graphs G according to their μ-risk, defined as the maximum failure probability of any node in G when thresholds are drawn from μ. We find that the space of threshold distributions has a surprisingly rich structure when we consider the risk that these thresholds induce on different graphs: small shifts in the distribution of the thresholds can favor graphs with a maximally clustered structure (i.e., cliques), those with a maximally branching structure (trees), or even intermediate hybrids.","Labeling,
Power system faults,
Power system protection,
Educational institutions,
Analytical models,
Resilience,
Electric shock"
Characterizing multi-threaded applications based on shared-resource contention,"For higher processing and computing power, chip multiprocessors (CMPs) have become the new mainstream architecture. This shift to CMPs has created many challenges for fully utilizing the power of multiple execution cores. One of these challenges is managing contention for shared resources. Most of the recent research address contention for shared resources by single-threaded applications. However, as CMPs scale up to many cores, the trend of application design has shifted towards multi-threaded programming and new parallel models to fully utilize the underlying hardware. There are differences between how single- and multi-threaded applications contend for shared resources. Therefore, to develop approaches to reduce shared resource contention for emerging multi-threaded applications, it is crucial to understand how their performances are affected by contention for a particular shared resource. In this research, we propose and evaluate a general methodology for characterizing multi-threaded applications by determining the effect of shared-resource contention on performance. To demonstrate the methodology, we characterize the applications in the widely used PARSEC benchmark suite for shared-memory resource contention. The characterization reveals several interesting aspects of the benchmark suite. Three of twelve PARSEC benchmarks exhibit no contention for cache resources. Nine of the benchmarks exhibit contention for the L2-cache. Of these nine, only three exhibit contention between their own threads-most contention is because of competition with a co-runner. Interestingly, contention for the Front Side Bus is a major factor with all but two of the benchmarks and degrades performance by more than 11%.",
Dynamic Game Difficulty Scaling Using Adaptive Behavior-Based AI,"Games are played by a wide variety of audiences. Different individuals will play with different gaming styles and employ different strategic approaches. This often involves interacting with nonplayer characters that are controlled by the game AI. From a developer's standpoint, it is important to design a game AI that is able to satisfy the variety of players that will interact with the game. Thus, an adaptive game AI that can scale the difficulty of the game according to the proficiency of the player has greater potential to customize a personalized and entertaining game experience compared to a static game AI. In particular, dynamic game difficulty scaling refers to the use of an adaptive game AI that performs game adaptations in real time during the game session. This paper presents two adaptive algorithms that use ideas from reinforcement learning and evolutionary computation to improve player satisfaction by scaling the difficulty of the game AI while the game is being played. The effects of varying the learning and mutation rates are examined and a general rule of thumb for the parameters is proposed. The proposed algorithms are demonstrated to be capable of matching its opponents in terms of mean scores and winning percentages. Both algorithms are able to generalize well to a variety of opponents.","Games,
Artificial intelligence,
Humans,
Real time systems,
Pixel,
Vehicles,
Adaptation model"
A Class of Hybrid LAPACK Algorithms for Multicore and GPU Architectures,"Three out of the top four supercomputers in the November 2010 TOP500 list of the world's most powerful supercomputers use NVIDIA GPUs to accelerate computations. Ninety-five systems from the list are using processors with six or more cores. Three-hundred-sixty-five systems use quad-core processor-based systems. Thirty-seven systems are using dual-core processors. The large-scale enabling of hybrid graphics processing unit (GPU)-based multicore platforms for computational science by developing fundamental numerical libraries (in particular, libraries in the area of dense linear algebra) for them has been underway for some time. We present a class of algorithms based largely on software infrastructures that have already been developed for homogeneous multicores and hybrid GPU-based computing. The algorithms extend what is currently available in the Matrix Algebra for GPU and Multicore Architectures (MAGMA) Library for performing Cholesky, QR, and LU factorizations using a single core or socket and a single GPU. The extensions occur in two areas. First, panels factored on the CPU using LAPACK are, instead, done in parallel using a highly optimized dynamic asynchronous scheduled algorithm on some number of CPU cores. Second, the remaining CPU cores are used to update the rightmost panels of the matrix in parallel.","Graphics processing unit,
Multicore processing,
Heuristic algorithms,
Sockets,
Libraries,
Dynamic scheduling"
Automatic Aneurysm Neck Detection Using Surface Voronoi Diagrams,"A new automatic approach for saccular intracranial aneurysm isolation is proposed in this work. Due to the inter- and intra-observer variability in manual delineation of the aneurysm neck, a definition based on a minimum cost path around the aneurysm sac is proposed that copes with this variability and is able to make consistent measurements along different data sets, as well as to automate and speedup the analysis of cerebral aneurysms. The method is based on the computation of a minimal path along a scalar field obtained on the vessel surface, to find the aneurysm neck in a robust and fast manner. The computation of the scalar field on the surface is obtained using a fast marching approach with a speed function based on the exponential of the distance from the centerline bifurcation between the aneurysm dome and the parent vessels. In order to assure a correct topology of the aneurysm sac, the neck computation is constrained to a region defined by a surface Voronoi diagram obtained from the branches of the vessel centerline. We validate this method comparing our results in 26 real cases with manual aneurysm isolation obtained using a cut-plane, and also with results obtained using manual delineations from three different observers by comparing typical morphological measures.","Aneurysm,
Neck,
Bifurcation,
Arteries,
Manuals,
Euclidean distance"
A Brain-Computer Interface for classifying EEG correlates of chronic mental stress,"In this paper, a Brain-Computer Interface (BCI) for classifying EEG correlates of chronic mental stress is proposed. Data from 8 EEG channels are collected from 26 healthy right-handed students during university examination period and after the examination whereby the former is considered to be relatively more stressful to students than the latter. The mental stress level are measured using the Perceived Stress Scale 14 (PSS-14) and categorized into stressed and stress-free groups. The proposed BCI is then used to classify the subjects' mental stress level on EEG features extracted using the Higuchi's fractal dimension of EEG, Gaussian mixtures of EEG spectrogram, and Magnitude Square Coherence Estimation (MSCE) between the EEG channels. Classification on the EEG features are then performed using the K-Nearest Neighbor (K-NN) and Support Vector Machine (SVM). The performance of the proposed BCI is then evaluated from the inter-subject classification accuracy using leave-one-out validation. The results showed that the proposed BCI using features extracted by MSCE yielded a promising inter-subject validation accuracy of over 90% in classifying the EEG correlates of chronic mental stress.","Electroencephalography,
Stress,
Feature extraction,
Accuracy,
Sensitivity,
Support vector machines,
Educational institutions"
Modeling Defibrillation of the Heart: Approaches and Insights,"Cardiac defibrillation, as accomplished nowadays by automatic, implantable devices (ICDs), constitutes the most important means of combating sudden cardiac death. While ICD therapy has proved to be efficient and reliable, defibrillation is a traumatic experience. Thus, research on defibrillation mechanisms, particularly aimed at lowering defibrillation voltage, remains an important topic. Advancing our understanding towards a full appreciation of the mechanisms by which a shock interacts with the heart is the most promising approach to achieve this goal. The aim of this paper is to assess the current state-of-the-art in ventricular defibrillation modeling, focusing on both numerical modeling approaches and major insights that have been obtained using defibrillation models, primarily those of realistic ventricular geometry. The paper showcases the contributions that modeling and simulation have made to our understanding of the defibrillation process. The review thus provides an example of biophysically based computational modeling of the heart (i.e., cardiac defibrillation) that has advanced the understanding of cardiac electrophysiological interaction at the organ level and has the potential to contribute to the betterment of the clinical practice of defibrillation.","Computational modeling,
Electric shock,
Biological system modeling,
Heart,
Extracellular,
Mathematical model,
Defibrillation"
Minimax Robust Quickest Change Detection,"The popular criteria of optimality for quickest change detection procedures are the Lorden criterion, the Pollak criterion, and the Bayesian criterion. In this paper, a robust version of these quickest change detection problems is considered when the pre-change and post-change distributions are not known exactly but belong to known uncertainty classes of distributions. For uncertainty classes that satisfy a specific condition, it is shown that one can identify least favorable distributions (LFDs) from the uncertainty classes, such that the detection rule designed for the LFDs is optimal for the robust problem in a minimax sense. The condition is similar to that required for the identification of LFDs for the robust hypothesis testing problem originally studied by Huber. An upper bound on the delay incurred by the robust test is also obtained in the asymptotic setting under the Lorden criterion of optimality. This bound quantifies the delay penalty incurred to guarantee robustness. When the LFDs can be identified, the proposed test is easier to implement than the CUSUM test based on the Generalized Likelihood Ratio (GLR) statistic which is a popular approach for such robust change detection problems. The proposed test is also shown to give better performance than the GLR test in simulations for some parameter values.","Robustness,
Delay,
Uncertainty,
Bayesian methods,
Random variables,
Upper bound,
Joints"
Pilot-Aided IQ Imbalance Compensation for OFDM Systems Operating Over Doubly Selective Channels,"In this paper, pilot-aided in-phase and quadrature-phase (IQ) imbalance compensation for orthogonal frequency division multiplexing (OFDM) systems operating over doubly selective channels is addressed. Based on a reformulated system model and the least squares (LS) criterion, a joint IQ imbalance and channel estimation method is developed, and the corresponding compensation scheme is also proposed. Moreover, to further enhance the compensation performance, an iterative compensation algorithm is derived via an expectation-maximization (EM) algorithm. Simulation results show that the iterative compensation algorithm initialized by the proposed LS compensation scheme converges in a few iterations and its performance after convergence is close to the ideal case with perfect IQ imbalance and channel state information.","Channel estimation,
OFDM,
Joints,
Noise,
Time domain analysis,
Receivers,
Radio transmitters"
Motion-Induced Phase Error Estimation and Correction in 3D Diffusion Tensor Imaging,"A multishot data acquisition strategy is one way to mitigate B0 distortion and T2* blurring for high-resolution diffusion-weighted magnetic resonance imaging experiments. However, different object motions that take place during different shots cause phase inconsistencies in the data, leading to significant image artifacts. This work proposes a maximum likelihood estimation and k-space correction of motion-induced phase errors in 3D multishot diffusion tensor imaging. The proposed error estimation is robust, unbiased, and approaches the Cramer-Rao lower bound. For rigid body motion, the proposed correction effectively removes motion-induced phase errors regardless of the k-space trajectory used and gives comparable performance to the more computationally expensive 3D iterative nonlinear phase error correction method. The method has been extended to handle multichannel data collected using phased-array coils. Simulation and in vivo data are shown to demonstrate the performance of the method.","Three dimensional displays,
Cramer-Rao bounds,
Biomedical imaging,
Trajectory,
Motion control,
Image resolution,
Error analysis"
Incorporation of a Left Ventricle Finite Element Model Defining Infarction Into the XCAT Imaging Phantom,"The 4D extended cardiac-torso (XCAT) phantom was developed to provide a realistic and flexible model of the human anatomy and cardiac and respiratory motions for use in medical imaging research. A prior limitation to the phantom was that it did not accurately simulate altered functions of the heart that result from cardiac pathologies such as coronary artery disease (CAD). We overcame this limitation in a previous study by combining the phantom with a finite-element (FE) mechanical model of the left ventricle (LV) capable of more realistically simulating regional defects caused by ischemia. In the present work, we extend this model giving it the ability to accurately simulate motion abnormalities caused by myocardial infarction (MI), a far more complex situation in terms of altered mechanics compared with the modeling of acute ischemia. The FE model geometry is based on high resolution CT images of a normal male subject. An anterior region was defined as infarcted and the material properties and fiber distribution were altered, according to the bio-physiological properties of two types of infarction, i.e., fibrous and remodeled infarction (30% thinner wall than fibrous case). Compared with the original, surface-based 4D beating heart model of the XCAT, where regional abnormalities are modeled by simply scaling down the motion in those regions, the FE model was found to provide a more accurate representation of the abnormal motion of the LV due to the effects of fibrous infarction as well as depicting the motion of remodeled infarction. In particular, the FE models allow for the accurate depiction of dyskinetic motion. The average circumferential strain results were found to be consistent with measured dyskinetic experimental results. Combined with the 4D XCAT phantom, the FE model can be used to produce realistic multimodality sets of imaging data from a variety of patients in which the normal or abnormal cardiac function is accurately represented.","Strain,
Phantoms,
Solid modeling,
Myocardium,
Finite element methods,
Heart,
Tensile stress"
Complex network inspired fault-tolerant NoC architectures with wireless links,"The Network-on-Chip (NoC) paradigm has emerged as a scalable interconnection infrastructure for modern multi-core chips. However, with growing levels of integration, the traditional NoCs suffer from high latency and energy dissipation in on-chip data transfer due to conventional metal/dielectric based interconnects. Three-dimensional integration, on-chip photonic, RF and wireless links have been proposed as radical low-power and low-latency alternatives to the conventional planar wire-based designs. Wireless NoCs with Carbon Nanotube (CNT) antennas are shown to outperform traditional wire based NoCs by several orders of magnitude in power dissipation and latency. However such transformative technologies will be prone to high levels of faults and failures due to various issues related to manufacturing and integration. On the other hand, several naturally occurring complex networks such as colonies of microbes and the internet are known to be inherently fault-tolerant against high rates of failures and harsh environments. This paper proposes to adopt such complex network based architectures to minimize the effect of wireless link failures on the performance of the NoC. Through cycle accurate simulations it is shown that the wireless NoC architectures inspired by natural complex networks perform better than their conventional wired counterparts even in the presence of a high degree of faults.",
Personalization of a Cardiac Electrophysiology Model Using Optical Mapping and MRI for Prediction of Changes With Pacing,"Computer models of cardiac electrophysiology (EP) can be a very efficient tool to better understand the mechanisms of arrhythmias. Quantitative adjustment of such models to experimental data (personalization) is needed in order to test their realism and predictive power, but it remains challenging at the organ scale. In this paper, we propose a framework for the personalization of a 3-D cardiac EP model, the Mitchell-Schaeffer (MS) model, and evaluate its volumetric predictive power under various pacing scenarios. The personalization was performed on ex vivo large porcine healthy hearts using diffusion tensor MRI (DT-MRI) and optical mapping data. The MS model was simulated on a 3-D mesh incorporating local fiber orientations, built from DT-MRI. The 3-D model parameters were optimized using features such as 2-D epicardial depolarization and repolarization maps, extracted from the optical mapping. We also evaluated the sensitivity of our personalization framework to different pacing locations and showed results on its robustness. Further, we evaluated volumetric model predictions for various epi- and endocardial pacing scenarios. We demonstrated promising results with a mean personalization error around 5 ms and a mean prediction error around 10 ms (5% of the total depolarization time). Finally, we discussed the potential translation of such work to clinical data and pathological hearts.",
Demand response model and its effects on voltage profile of a distribution system,This paper develops a model for Demand Response (DR) by utilizing consumer behavior modeling considering different scenarios and levels of consumer rationality. Consumer behavior modeling has been done by developing extensive demand-price elasticity matrices for different types of consumers. These Price Elasticity Matrices (PEMs) are utilized to calculate the level of demand response for a given consumer. DR thus obtained is applied to a real world distribution network considering a day-ahead real time pricing scenario to study the effects of demand reduction on system voltage. Results show considerable boost in system voltage that paves way for further demand curtailment through demand side management techniques like Volt/Var Control (VVC).,
An SVM based classification approach to speech separation,"Monaural speech separation is a very challenging task. CASA-based systems utilize acoustic features to produce a time-frequency (T-F) mask. In this study, we propose a classification approach to monaural separation problem. Our feature set consists of pitch-based features and amplitude modulation spectrum features, which can discriminate both voiced and unvoiced speech from nonspeech interference. We employ support vector machines (SVMs) followed by a re-thresholding method to classify each T-F unit as either target-dominated or interference-dominated. An auditory segmentation stage is then utilized to improve SVM-generated results. Systematic evaluations show that our approach produces high quality binary masks and outperforms a previous system in terms of classification accuracy.",
Efficient accelerometer-based swimming exercise tracking,"The study concentrates on tracking swimming exercises based on the data of 3D accelerometer and shows that human activities can be tracked accurately using low sampling rates. The tracking of swimming exercise is done in three phases: first the swimming style and turns are recognized, secondly the number of strokes are counted and thirdly the intensity of swimming is estimated. Tracking is done using efficient methods because the methods presented in the study are designed for light applications which do not allow heavy computing. To keep tracking as light as possible it is studied what is the lowest sampling frequency that can be used and still obtain accurate results. Moreover, two different sensor placements (wrist and upper back) are compared. The results of the study show that tracking can be done with high accuracy using simple methods that are fast to calculate and with a really low sampling frequency. It is shown that an upper back-worn sensor is more accurate than a wrist-worn one when the swimming style is recognized, but when the number of strokes is counted and intensity estimated, the sensors give approximately equally accurate results.",
Fast H.264 Encoding Based on Statistical Learning,"H.264/AVC, the latest video coding standard of the Joint Video Team, greatly outperforms previous standards in terms of coding bitrate and video quality, because it adopts several new techniques. However, the computational complexity is also considerably increased due to these new components. In this paper, we propose fast algorithms based on statistical learning to reduce the computational cost involved in three main components in H.264 encoder, i.e., intermode decision, multi-reference motion estimation (ME), and intra-mode prediction. First, representative features are extracted to build the learning models. Then, an offline pre-classification approach is used to determine the best results from the extracted features, thus a significant amount of computation is reduced based on the classification strategy. The proposed statistical learning-based approach is applied to the aforementioned three main components in H.264 encoder to speed up the computation. Experimental results show that the ME time of the proposed system is significantly sped up with 12 times faster than the conventional fast ME algorithm of H.264, and the total encoding time of the proposed encoder is greatly reduced with about four times faster than the fast encoder EPZS in the H.264 reference code with negligible video quality degradation.",
Introduction to CPM-SC-FDMA: A Novel Multiple-Access Power-Efficient Transmission Scheme,"This paper presents a novel multiple-access modulation scheme which combines key characteristics of single carrier frequency division multiple access (SC-FDMA) with continuous phase modulation (CPM) in order to generate a power efficient waveform. CPM-SC-FDMA is developed based upon the observation that the samples from a CPM waveform may be treated as ""data symbols"" taken from a constant-envelope encoder. As with any encoder output, these samples may be precoded using the Discrete Fourier Transform and transmitted using SC-FDMA. Having originated from a constant envelope CPM waveform, CPM-SC-FDMA can potentially retain much of the power efficiency of CPM-thus resulting in a lower peak-to-average power ratio (PAPR) than conventional SC-FDMA. In this paper, we account for the information rate, memory, power efficiency, bit error rate (BER) performance and spectral occupancy of CPM-SC-FDMA. In addition, we investigate the impact of amplifier nonlinearity on BER performance as the number of users increases. Finally, we provide a detailed numerical comparison with a commensurate convolutionally coded QPSK-SC-FDMA scheme (CC-QPSK-SC-FDMA). We show a CPM-SC-FDMA scheme that provides an overall gain of up to 4 dB relative to the CC-QPSK-SC-FDMA scheme over a frequency-selective channel.",
A Parallel Simulated Annealing Approach to Band Selection for High-Dimensional Remote Sensing Images,"In this paper a parallel band selection approach, referred to as parallel simulated annealing band selection (PSABS), is presented for high-dimensional remote sensing images. The approach is based on the simulated annealing band selection (SABS) scheme which is originally designed to group highly correlated hyperspectral bands into a smaller subset of modules regardless of the original order in terms of wavelengths. SABS selects sets of correlated hyperspectral bands based on simulated annealing (SA) algorithm and utilizes the inherent separability of different classes to reduce dimensionality. In order to be effective, the proposed PSABS is introduced to improve the computational performance by using parallel computing technique. It allows multiple Markov chains (MMC) to be traced simultaneously and fully utilizes the parallelism of SABS to create a set of SABS modules on each parallel node. Two parallel implementations, namely the message passing interface (MPI) cluster-based library and the open multi-processing (OpenMP) multicore-based application programming interface, are applied to three different MMC techniques: non-interacting MMC, periodic exchange MMC and asynchronous MMC for evaluation. The effectiveness of the proposed PSABS is evaluated by NASA MODIS/ASTER (MASTER) airborne simulator data sets and airborne synthetic aperture radar (SAR) images for land cover classification during the Pacrim II campaign in the experiments. The results demonstrated that the MMC techniques of PSABS can significantly improve the computational performance and provide a more reliable quality of solution compared to the original SABS method.",
Classes of attacks in VANET,"Last few years, vehicular network has been taken more attention of researchers and automotive industries due to life saving factor. Vehicular Ad hoc Network (VANET) needs security to implement the wireless environment and serves users with safety and non safety applications. Attackers generate different attacks in this life saving vehicular network. In this paper, we propose five different classes of attacks and every class is expected to provide better perspective for the VANET security. The main contribution of this paper is the proposed solution for classification and identification of different attacks in VANET.","Vehicles,
Safety,
Roads,
Computer crime,
Accidents,
Ad hoc networks"
The use of artificial neural networks in the analysis and prediction of stock prices,"In recent years there has been a significant growth of interest in the incorporation of historical series of variables related to stock prediction into mathematical models or computational algorithms in order to generate predictions or indications about expected price movements. The objective of this study was to utilize artificial neural networks to predict the closing price of the stock PETR4 which is traded on BM&FBOVESPA. Three stages were used to generate the prediction: obtainment of the samples, pre-processing, and prediction. 32 different configurations were created by varying the window size and prediction horizon. The best performance was obtained with 5 days of quotes and a prediction horizon of 1 day where the mean squared error was 0.0129.","Forecasting,
Biological neural networks,
Time series analysis,
Indexes,
Macroeconomics,
Stock markets"
Using Ant Programming Guided by Grammar for Building Rule-Based Classifiers,"The extraction of comprehensible knowledge is one of the major challenges in many domains. In this paper, an ant programming (AP) framework, which is capable of mining classification rules easily comprehensible by humans, and, therefore, capable of supporting expert-domain decisions, is presented. The algorithm proposed, called grammar based ant programming (GBAP), is the first AP algorithm developed for the extraction of classification rules, and it is guided by a context-free grammar that ensures the creation of new valid individuals. To compute the transition probability of each available movement, this new model introduces the use of two complementary heuristic functions, instead of just one, as typical ant-based algorithms do. The selection of a consequent for each rule mined and the selection of the rules that make up the classifier are based on the use of a niching approach. The performance of GBAP is compared against other classification techniques on 18 varied data sets. Experimental results show that our approach produces comprehensible rules and competitive or better accuracy values than those achieved by the other classification algorithms compared with it.",
Progressive Band Dimensionality Expansion and Reduction Via Band Prioritization for Hyperspectral Imagery,"Processing enormous hyperspectral data results in high computational complexity. Band selection (BS) is one common practice to accomplish this goal. However, determining the number of bands to be selected and finding appropriate bands for BS are very challenging since it requires an exhaustive search. Instead of directly dealing with these two issues, this paper introduces a new approach, called progressive band dimensionality process (PBDP) which performs progressive band dimensionality expansion and reduction via band prioritization (BP) which prioritizes the hyperspectral bands according to their priority scores calculated by a specific BP criterion. Two dual processes, referred to as forward PBDP (FPBDP) which performs band expansion in a forward manner and backward PBDP (BPBDP) which performs band dimensionality reduction in a backward manner. By virtue of its progressive nature the PBDP can be implemented by high computing performance while avoiding excessive computing time required by finding an optimal subset from all possible band subset combinations out of full bands. As a consequence, PBDP provides band selection with an advantage of not being trapped in high computational complexity resulting from solving combinatorial mathematics problems. A key to success in PBDP is how to design BP criteria to meet various applications. To address this need, four categories of BP are derived from different designing rationales, second order statistics, higher-order statistics, classification, and band correlation/dependence.","Hyperspectral imaging,
Correlation,
Entropy,
Eigenvalues and eigenfunctions,
Signal to noise ratio,
Matrix converters"
Enhancing architectural recovery using concerns,"Architectures of implemented software systems tend to drift and erode as they are maintained and evolved. To properly understand such systems, their architectures must be recovered from implementation-level artifacts. Many techniques for architectural recovery have been proposed, but their degrees of automation and accuracy remain unsatisfactory. To alleviate these shortcomings, we present a machine learning-based technique for recovering an architectural view containing a system's components and connectors. Our approach differs from other architectural recovery work in that we rely on recovered software concerns to help identify components and connectors. A concern is a software system's role, responsibility, concept, or purpose. We posit that, by recovering concerns, we can improve the correctness of recovered components, increase the automation of connector recovery, and provide more comprehensible representations of architectures.","Software,
Computer architecture,
Libraries,
Supervised learning,
Meteorology,
Sockets"
A Network of Dynamic Probabilistic Models for Human Interaction Analysis,"We propose a novel method of analyzing human interactions based on the walking trajectories of human subjects, which provide elementary and necessary components for understanding and interpretation of complex human interactions in visual surveillance tasks. Our principal assumption is that an interaction episode is composed of meaningful small unit interactions, which we call “sub-interactions”. We model each sub-interaction by a dynamic probabilistic model and propose a modified factorial hidden Markov model (HMM) with factored observations. The complete interaction is represented with a network of dynamic probabilistic models (DPMs) by an ordered concatenation of sub-interaction models. The rationale for this approach is that it is more effective in utilizing common components, i.e., sub-interaction models, to describe complex interaction patterns. By assembling these sub-interaction models in a network, possibly with a mixture of different types of DPMs, such as standard HMMs, variants of HMMs, dynamic Bayesian networks, and so on, we can design a robust model for the analysis of human interactions. We show the feasibility and effectiveness of the proposed method by analyzing the structure of network of DPMs and its success on four different databases: a self-collected dataset, Tsinghua University's dataset, the public domain CAVIAR dataset, and the Edinburgh Informatics Forum Pedestrian dataset.","Hidden Markov models,
Computational modeling,
Humans,
Probabilistic logic,
Heuristic algorithms,
Analytical models,
Yttrium"
Optimal hard fusion strategies for cognitive radio networks,"Optimization of hard fusion spectrum sensing using the k-out-of-N rule is considered. Two different setups are used to derive the optimal k. A throughput optimization setup is defined by minimizing the probability of false alarm subject to a probability of detection constraint representing the interference of a cognitive radio with the primary user, and an interference management setup is considered by maximizing the probability of detection subject to a false alarm rate constraint. It is shown that the underlying problems can be simplified to equality constrained optimization problems and an algorithm to solve them is presented. We show the throughput optimization and interference management setups are dual. The simulation results show the majority rule is optimal or near optimal for the desirable range of false alarm and detection rates for a cognitive radio network. Furthermore, an energy efficient setup is considered where the number of cognitive radios is to be minimized for the AND and the OR rule and a certain probability of detection and false alarm constraint. The simulation results show that the OR rule outperforms the AND rule in terms of energy efficiency.","Cognitive radio,
Optimization,
Interference,
Throughput,
Detectors,
Simulation"
Enhancing Learning in Introductory Computer Science Courses Through SCALE: An Empirical Study,"The work presented in this paper aims to support and promote the learning process in introductory computer science courses through the Web-based, adaptive, activity-oriented learning environment known as Supporting Collaboration and Adaptation in a Learning Environment (SCALE). The environment engages students actively in the learning process and supports them with multiple informative and tutoring feedback components. The exploitation of appropriately developed educational material, which was provided through SCALE, showed that SCALE can be a valuable tool for supporting the learning process in introductory computer science courses.","Materials,
Computer science,
Context,
Telecommunications,
Informatics,
Education,
Laboratories"
Energy-aware Standby-Sparing Technique for periodic real-time applications,"In this paper, we present an energy-aware standby-sparing technique for periodic real-time applications. A standby-sparing system consists of a primary processor where the application tasks are executed using Dynamic Voltage Scaling (DVS) to save energy, and a spare processor where the backup tasks are executed at maximum voltage/frequency, should there be a need. In our framework, we employ Earliest-Deadline-First (EDF) and Earliest-Deadline-Late (EDL) scheduling policies on the primary and spare CPUs, respectively. The use of EDL on the spare CPU allows delaying the backup tasks on the spare CPU as much as possible, enabling energy savings. We develop static and dynamic algorithms based on these principles, and evaluate their performance experimentally. Our simulation results show significant energy savings compared to existing reliability-aware power management (RAPM) techniques for most execution scenarios.","Schedules,
Reliability,
Transient analysis,
Real time systems,
Circuit faults,
Voltage control,
Time frequency analysis"
"GOrevenge: A Novel Generic Reverse Engineering Method for the Identification of Critical Molecular Players, Through the Use of Ontologies","The ever-increasing use of ontologies in modern biological analysis and interpretation facilitates the understanding of the cellular procedures, their hierarchical organization, and their potential interactions at a system's level. Currently, the gene ontology serves as a paradigm, where through the annotation of whole genomes of certain organisms, genes subsets selected, either from high-throughput experiments or with an established pivotal role regarding the probed disease, can act as a starting point for the exploration of their underlying functional interconnections. This may also aid the elucidation of hidden regulatory mechanisms among genes. Reverse engineering the functional relevance of genes to specific cellular pathways and vice versa, through the exploitation of the inner structure of the ontological vocabularies, may help impart insight regarding the identification and prioritization of the critical role of specific genes. The proposed graph-theoretical method is showcased in a pancreatic cancer and a T-cell acute lymphoblastic leukemia gene set, incorporating edge and Resnik semantic similarity metrics, and systematically evaluated regarding its performance.",
Ground Bouncing Noise Suppression Techniques for Data Preserving Sequential MTCMOS Circuits,"Ground distribution network noise produced during sleep-to-active mode transitions is an important reliability concern in standard multi-threshold CMOS (MTCMOS) circuits. Different noise-aware sequential MTCMOS circuits are explored in this paper. A low-leakage data retention sleep mode is implemented with smaller centralized sleep transistors to suppress the ground bouncing noise produced during reactivation events in sequential MTCMOS circuits. Ground bouncing noise, leakage power consumption, data stability, and area overheads of different sequential MTCMOS circuits are evaluated with a 90-nm CMOS technology. The peak amplitude of ground bouncing noise is reduced by up to 94.16% with the noise-aware MTCMOS techniques as compared to the conventional Mutoh flip-flop. The application space of different data retention MTCMOS circuit techniques is identified with various design metrics in this paper.","Circuit noise,
Integrated circuit noise,
Flip-flops,
Energy consumption,
CMOS technology,
Space technology,
Sequential circuits,
Circuit stability,
Noise reduction,
Noise level"
Reexamining Lucas-Kanade method for real-time independent motion detection: Application to the iCub humanoid robot,"Visual motion is a simple yet powerful cue widely used by biological systems to improve their perception and adaptation to the environment. Examples of tasks that greatly benefit from the ability to detect movement are object segmentation, 3D scene reconstruction and control of attention. In computer vision several algorithms for computing visual motion and optic flow exist. However their application in robotics is not straightforward as in these platforms visual motion is often dominated by (self) motion produced by the movement of the robot (egomotion) making it difficult to disambiguate between motion induced by the scene dynamics or by the own actions of the robot. Independent motion detection is an active field in computer vision and robotics, however approaches in this area typically require that some models of both the environment and the robot visual system are available and are hardly suitable for real-time control. In this paper we describe the motionCUT, a derivation of the Lucas-Kanade optical flow algorithm that allows detecting moving objects, irrespectively of the egomotion produced by the robot. Our method is purely visual and does not require information other than the images coming from the cameras. As such it can be easily adapted to any robotic platform. The system was tested on a stereo tracking task on the iCub humanoid robot, demonstrating that the algorithm performs well and can easily execute in real-time.","Optical imaging,
Robots,
Adaptive optics,
Head,
Cameras,
Tracking,
Optical computing"
Measuring Security,"The field of computer and communications security begs for a foundational science to guide system design and to reveal the safety, security, and possible fragility of the complex systems we depend on today. To achieve this goal, we must devise suitable metrics for objectively comparing and evaluating the security of system designs and organizations.","Measurement,
Computer security,
Statistics,
Cryptography,
Computational modeling,
Economics,
Information analysis"
A fine-grained technique of NBTI-aware voltage scaling and body biasing for standard cell based designs,"As the technology scales, the increase of circuit delay over time due to NBTI (negative bias temperature instability) effect is not negligible any more. It has been known that voltage scaling is an effective scheme that is able to mitigate the NBTI effect. However, a careful control of voltage scaling is required not to increase the dissipation of dynamic power significantly. On the other hand, body biasing can also be used to mitigate the NBTI effect by lowering down the threshold voltage, but its effectiveness is limited, as will be demonstrated in this work, and it increases the leakage power. This work addresses an important problem of minimizing the power consumption of circuit while controlling the NBTI induced delay increase to meet the circuit timing constraint by simultaneously utilizing the effects of voltage scaling and body biasing on both NBTI and power consumption. Precisely, we solve the problem of finding a set of supply and body biasing voltage values to apply circuit clusters on standard cell based design to minimize the total power consumption while satisfying the constraint of circuit life time, considering the NBTI induced delay factor in circuit timing computation. By a comprehensive analysis on the relations between the values of supply and body biasing voltages and the values of the resulting power consumption and NBTI induced delay, we precisely formulate the problem, and transform it into a problem of convex optimization to solve it efficiently. Through extensive experimentation using ISCAS benchmark designs, it is shown that the proposed approach to the simultaneous exploitation of supply voltage and body biasing is able to produce designs with 14% and 8% reduced energy consumption on average over the designs produced by the design time NBTI-aware guard-banding based voltage scaling and the run time NBTI-aware voltage scaling, respectively.","Delay,
Threshold voltage,
Logic gates,
Convex functions,
Voltage control,
Energy consumption"
Robust Automatic Knee MR Slice Positioning Through Redundant and Hierarchical Anatomy Detection,"Diagnostic magnetic resonance (MR) image quality is highly dependent on the position and orientation of the slice groups, due to the intrinsic high in-slice and low through-slice resolutions of MR imaging. Hence, the higher speed, accuracy, and reproducibility of automatic slice positioning , make it highly desirable over manual slice positioning. However, imaging artifacts, diseases, joint articulation, variations across ages and demographics as well as the extremely high performance requirements prevent state-of-the-art methods, such as volumetric registration, to be an off-the-shelf solution. In this paper, we address all these issues through an automatic slice positioning framework based on redundant and hierarchical learning. Our method has two hallmarks that are specifically designed to achieve high robustness and accuracy. 1) A redundant set of anatomy detectors are learned to provide local appearance cues. These detections are pruned and assembled according to a distributed anatomy model, which captures group-wise spatial configurations among anatomy primitives. This strategy brings about a high level of robustness and works even if a large portion of the target is distorted, missing, or occluded. 2) The detectors are learned and invoked in a hierarchical fashion, with each local detection scheduled and iterated according to its intrinsic invariance property. This iterative alignment process is shown to dramatically improve alignment accuracy. The proposed system is extensively validated on a large dataset including 744 clinical MR scans. Compared to state-of-the-art methods, our method exhibits superior performance in terms of robustness, accuracy, and reproducibility. The methodology is general and can be applied to other anatomies and other imaging modalities.","Knee,
Human anatomy,
Pattern recognition,
Image analysis,
Three dimensional displays,
Magnetic resonance imaging,
Computer aided analysis,
Detectors"
Analysis and Computer-Aided Simulation of Cogging Force Characteristic of a Linear Electromagnetic Launcher With Tubular Transverse Flux Machine,"This paper investigates a linear electromagnetic launcher with tubular transverse flux permanent-magnet linear machine (TFPMLM). Special focus is given on its cogging force characteristic, including the theoretical analysis and computer-aided simulation. Both 3-D and equivalent 2-D finite-element analyses are performed to calculate the cogging force, and the results are compared. It is shown that the proposed 3-D to 2-D equivalence can predict the cogging force of the tubular TFPMLM in an accurate and fast way.","Electromagnetic analysis,
Computational modeling,
Analytical models,
Computer simulation,
Forging,
Electromagnetic forces,
Electromagnetic launching,
Finite element methods,
Stators,
Teeth"
Brain computer interface based 3D game for attention training and rehabilitation,"This paper presents a novel approach which uses brain computer interface (BCI) technology to translate the user's mental conditions, especially the attention state, into game control. Leveraging on BCI engine to measure a user's attention level to control a virtual hand's movement and utilizing 3D animation technique, the proposed system is significant for training those who suffering from Attention Deficit Hyperactivity Disorder (ADHD). Comparing to robotic based system, the proposed system is cost-effective, interesting, and ease of use. It also can be extended for rehabilitating the people with neurological disorders, such as those debilitating traumatic events. Potentially, millions people may benefit from the system. The system structure and experimental results will be illustrated in this paper. To our knowledge, no same system is reported yet.","Games,
Electroencephalography,
Three dimensional displays,
Brain modeling,
Solid modeling,
Training,
Fingers"
Exploring memory energy optimizations in smartphones,"Recent development of sophisticated smartphones has made them indispensable part of our everyday life. However, advances in battery technology cannot keep up with the demand for longer battery life. Subsequently, energy efficiency has become one of the most important factors in designing smartphones. Multitasking and better multimedia features in the mobile applications continuously push memory requirements further, making energy optimizations for memory critical. Mobile RAM is already optimized for energy efficiency at the hardware level. It also provides power state switching interfaces to the operating system which enables the OS level energy optimizations. Many RAM optimizations have been explored for computer systems and in this paper we explore their applicability to smartphone hardware. In addition, we apply those optimizations to the newly emerging Phase Change Memory and study their energy efficiency and performance. Finally, we propose a hybrid approach to take the advantage of both Mobile RAM and Phase Change Memory. Results show that our hybrid mechanism can save more than 98% of memory energy as compared to the standard smartphone system with negligible impact on user experience.","Phase change materials,
Memory management,
Random access memory,
Smart phones,
Energy consumption,
Mobile communication,
Energy management"
Speculative Parallel Pattern Matching,"Intrusion prevention systems (IPSs) determine whether incoming traffic matches a database of signatures, where each signature is a regular expression and represents an attack or a vulnerability. IPSs need to keep up with ever-increasing line speeds, which has lead to the use of custom hardware. A major bottleneck that IPSs face is that they scan incoming packets one byte at a time, which limits their throughput and latency. In this paper, we present a method to search for arbitrary regular expressions by scanning multiple bytes in parallel using speculation. We break the packet in several chunks, opportunistically scan them in parallel, and if the speculation is wrong, correct it later. We present algorithms that apply speculation in single-threaded software running on commodity processors as well as algorithms for parallel hardware. Experimental results show that speculation leads to improvements in latency and throughput in both cases.",
The Elastic Ratio: Introducing Curvature Into Ratio-Based Image Segmentation,"We present the first ratio-based image segmentation method that allows imposing curvature regularity of the region boundary. Our approach is a generalization of the ratio framework pioneered by Jermyn and Ishikawa so as to allow penalty functions that take into account the local curvature of the curve. The key idea is to cast the segmentation problem as one of finding cyclic paths of minimal ratio in a graph where each graph node represents a line segment. Among ratios whose discrete counterparts can be globally minimized with our approach, we focus in particular on the elastic ratio ∫0L(C)∇I(C(s))·(C'(s))⊥ds /vL(C)+ ∫0L(C)|κC(s)|qds that depends, given an image I, on the oriented boundary C of the segmented region candidate. Minimizing this ratio amounts to finding a curve, neither small nor too curvy, through which the brightness flux is maximal. We prove the existence of minimizers for this criterion among continuous curves with mild regularity assumptions. We also prove that the discrete minimizers provided by our graph-based algorithm converge, as the resolution increases, to continuous minimizers. In contrast to most existing segmentation methods with computable and meaningful, i.e., nondegenerate, global optima, the proposed approach is fully unsupervised in the sense that it does not require any kind of user input such as seed nodes. Numerical experiments demonstrate that curvature regularity allows substantial improvement of the quality of segmentations. Furthermore, our results allow drawing conclusions about global optima of a parameterization-independent version of the snakes functional: the proposed algorithm allows determining parameter values where the functional has a meaningful solution and simultaneously provides the corresponding global solution.",
Single-Channel and Multi-Channel Sinusoidal Audio Coding Using Compressed Sensing,"Compressed sensing (CS) samples signals at a much lower rate than the Nyquist rate if they are sparse in some basis. In this paper, the CS methodology is applied to sinusoidally modeled audio signals. As this model is sparse by definition in the frequency domain (being equal to the sum of a small number of sinusoids), we investigate whether CS can be used to encode audio signals at low bitrates. In contrast to encoding the sinusoidal parameters (amplitude, frequency, phase) as current state-of-the-art methods do, we propose encoding few randomly selected samples of the time-domain description of the sinusoidal component (per signal segment). The potential of applying compressed sensing both to single-channel and multi-channel audio coding is examined. The listening test results are encouraging, indicating that the proposed approach can achieve comparable performance to that of state-of-the-art methods. Given that CS can lead to novel coding systems where the sampling and compression operations are combined into one low-complexity step, the proposed methodology can be considered as an important step towards applying the CS framework to audio coding applications.","Psychoacoustic models,
Compressed sensing,
Quantization,
Frequency estimation,
Frequency domain analysis,
Audio coding"
Temporal Sequence Parameters in Isodistributional Surrogate Data: Model and Exact Expressions,"In this paper, a set of formulae for the temporal spontaneous baroreceptor reflex (sBRR) sequence parameters in isodistributional (ID) surrogate data is derived. This is facilitated by representing successive positive or negative amplitude changes as a Markov chain model. The obtained analytical tool measures the effect of random fluctuations on the overall number of sequences, estimated from the original biomedical time series. The formulae are tested using ID surrogates of systolic blood pressure and pulse-interval signals recorded from 13 healthy male Wistar rats at baseline conditions.",
Following human guidance to cooperatively carry a large object,"Carrying a large object like a table is a task that cannot be solved by a single robot or a single human, but that requires two workers, for example one human and one robot. For this human-robot cooperation, the robot must perceive the human and synchronize with its motion. It also must perceive the object to carry. In this paper, we present an approach that uses arm compliance to follow the human guidance on a fast time scale and moves the robot base to restore a nominal position for the arms. For perceiving the object, we acquire a model of it using an RGB- D camera and match this model with the current measurements. This real-time object pose estimate is suitable for approaching and grasping it, as well as for the detection of object lifting and lowering to the ground again. We evaluate our approach in lab experiments using a robot that has an anthropomorphic upper body and an omnidirectional base. We also report on the successful public demonstration of our approach in the ©Home league at RoboCup 2011.",
Optical Dispersion Models for Time-Domain Modeling of Metal-Dielectric Nanostructures,"We discuss second-order complex Padé approximants which give a systematic approach to time-domain modeling of dispersive dielectric functions. These approximants, which also reduce to the classical Drude, Lorentz, Sellmeier, critical points and other models upon appropriate truncation, are used to compare frequency domain (FD) versus time-domain (TD) simulations of local optical responses and the transmission-reflection spectra for a plasmonic nanostructure. A comparison is also made using auxiliary differential equations (ADE), and second order recursive convolution (RC) formulations embedded in finite-difference, finite-volume, and finite-element time-domain solvers.","Time domain analysis,
Dispersion,
Finite difference methods,
Computational modeling,
Media,
Numerical models,
Mathematical model"
Multichannel Audio Coding Based on Analysis by Synthesis,"Spatial hearing enables translation of an auditory scene into a perceived 3-D image by interpreting the acoustic cues related to the sounding objects, their locations, and the physical characteristics of the space. Spatial audio production requires multichannel audio signals in order to convey this information and increase the realism of a real or virtual environment for applications such as the home entertainment, virtual reality, and remote collaboration. As demand to spatial audio continues to expand, efficient coding of multichannel audio content becomes more and more important. This paper provides an overview of some well-known multichannel audio coding techniques and presents a new coding framework for improving the objective fidelity of the decoded signals. A closed-loop encoding system based on analysis-by-synthesis (AbS) principle applied on the MPEG surround (MPS) architecture is described. Comparison results are presented, which show that significant improvements can be achieved with a closed-loop system instead of the conventional open-loop system.","Audio coding,
Spatial resolution,
MONOS devices,
Transform coding,
Rendering (computer graphics),
Acoustics,
Three dimensional displays"
Buoy-to-ship experimental measurements over sea at 5.8 GHz near urban environments,"Current marine wireless communication systems used for monitoring applications based on buoys suffer from lots of weakness. Many research works concern the design and development of new technological applications to improve marine communications. Particularly, a wireless communication system based on WiMAX standard at the 5.8 GHz band (license-exempt band) could be a good candidate. As an initial task, a propagation channel measurement campaign in maritime environments was carried out to investigate the impact of the wireless channel in different situations. This work provides large scale path loss measurements over sea around urban environments. In particular, a radio link between a buoy and a ship at 5.8 GHz is studied. NLOS (Non-Line-Of-Sight) paths are investigated in depth and they are compared to LOS (Line-Of-Sight) paths. The designed measurement system is described and the experimental measurements are shown. An empirical model is obtained using these experimental data and the key wireless channel parameters are analyzed. In addition, the empirical model is compared to the free space and two-ray theoretical models. This investigation is useful, among others, for planning Worldwide Interoperability for Microwave Access (WiMAX) networks offshore around these challenge environments.","Sea measurements,
Loss measurement,
WiMAX,
Atmospheric measurements,
Propagation losses,
Antenna measurements"
Spoofing or Jamming: Performance Analysis of a Tactical Cognitive Radio Adversary,"The tradeoff between spoofing and jamming a cognitive radio network by an intelligent adversary is analyzed in this paper. Due to the vulnerabilities of spectrum sensing noted in recent studies, a cognitive radio can be attacked during the sensing interval by an adversary who puts spoofing signals in unused bands. Further, once secondary users access unused bands, the adversary can use traditional jamming to interfere with them during transmission. For an energy-constrained intelligent adversary, a two step procedure is formulated to distribute the energy between spoofing and jamming, such that the average sum throughput of the secondary users is minimized. That is, we optimally spoof in the sensing duration and then optimally jam in the transmission slot. In a cluster-based cognitive radio network, when the number of spectral vacancies required by secondary users increases, the optimal attack for the intelligent adversary will shift from jamming only, to a combination of spoofing and jamming, to spoofing only.","Jamming,
Sensors,
Throughput,
Cognitive radio,
Noise,
Joints,
Data communication"
Evolutionary Multiobjective Footstep Planning for Humanoid Robots,"This paper proposes a novel evolutionary multiobjective footstep planner for humanoid robots. First, a footstep planner using a univector field navigation method is proposed to provide a command state (CS), which is to be an input of a modifiable walking pattern generator (MWPG) at each footstep. Then, the MWPG generates corresponding trajectories for every leg joint of the humanoid robot at each footstep to follow the CS. Second, a multiobjective evolutionary algorithm (MOEA) is employed to optimize the univector fields satisfying multiple objectives in navigation. Finally, a preference-based selection algorithm based on a fuzzy measure and fuzzy integral is proposed to select the preferred one out of various nondominated solutions obtained by the MOEA. The effectiveness of the proposed evolutionary multiobjective footstep planner is demonstrated through computer simulations for a simulation model of a small-sized humanoid robot, HanSaRam-VIII.","Humanoid robots,
Navigation,
Leg,
Trajectory,
Foot,
Planning"
VADANA: A dense dataset for facial image analysis,"Analysis of face images has been the topic of in-depth research with wide spread applications. Face recognition, verification, age progression studies are some of the topics under study. In order to facilitate comparison and benchmarking of different approaches, various datasets have been released. For the specific topics of face verification with age progression, aging pattern extraction and age estimation, only two public datasets are currently available. The FGNET and MORPH datasets contain a large number of subjects, but only a few images are available for each subject. We present a new dataset, VADANA, which complements them by providing a large number of high quality digital images for each subject within and across ages (depth vs. breadth). It provides the largest number of intrapersonal pairs, essential for better training and testing. The images also offer a natural range of pose, expression and illumination variation. A parallel version with aligned faces is also created. Additionally, we provide relationships between subjects. We demonstrate the difference and difficulty of VADANA by testing with state-of-the-art algorithms. Our findings from experiments show how VADANA can aid further research on different types of verification algorithms. The variety of characteristics our data offers facilitate testing and benchmarking of other facial analysis algorithms.","Face,
Training,
Lighting,
Databases,
Algorithm design and analysis,
Testing,
Aging"
Modelling and analysis of network resilience,"As the Internet becomes increasingly important to all aspects of society, the consequences of disruption become increasingly severe. Thus it is critical to increase the resilience and survivability of the future network. We define resilience as the ability of the network to provide desired service even when challenged by attacks, large-scale disasters, and other failures. This paper describes a comprehensive methodology to evaluate network resilience using a combination of analytical and simulation techniques with the goal of improving the resilience and survivability of the Future Internet.","Resilience,
Topology,
Network topology,
Internet,
Measurement,
Analytical models,
Generators"
Secure wireless communications via cooperative relaying and jamming,"We consider secure wireless communications between a source and a destination aided by a multi-antenna relay, in the presence of an eavesdropper. In particular, two cooperation schemes of the relay are explored: cooperative relaying (CR) and cooperative jamming (CJ). We first investigate the transmit weight optimization of CR and CJ, for both cases with and without the eavesdropper's channel state information (ECSI). Then, for the case with ECSI, we derive the conditions under which CR achieves a higher secrecy rate than CJ; for the case without ECSI, we compare the secrecy rates of CR and CJ in high transmit power regimes. Building on this, we propose a novel hybrid scheme in which the relay utilizes both CR and CJ, and study the power allocation of the relay between CR and CJ for maximizing the secrecy rate.","Relays,
Jamming,
Hybrid power systems,
Resource management,
Wireless communication,
Security,
Array signal processing"
Optimization of economic load dispatch for a microgrid using evolutionary computation,"Economic load dispatch of a microgrid system is a highly nonlinear and multi-objective problem. The two objectives are minimizing the emission of the thermal generators and minimizing the total operating cost. This microgrid system consists of thermal generators, wind turbines and polymer electrolyte membrane (PEM) fuel cells. Two state-of-the-art multi-objective methods, strength pareto evolutionary algorithm 2 (SPEA2) and non-dominated sorting genetic algorithm (NSGA-II), are adopted to perform the optimization. The results show that SPEA2 has a faster convergence speed and NSGA-II has a better convergence eventually for large number of generations. It is suggested that SPEA2 is recommended if time is the most important concern. However, if the accuracy of the results is top priority, NSGA-II is preferred.",
Floorplanning for Partially Reconfigurable FPGAs,"Partial reconfiguration on heterogeneous field-programmable gate arrays with millions of gates yields better utilization of its different types of resources by swapping in and out the appropriate modules of one or more applications at any instant of time. Given a schedule of sub-task instances where each instance is specified as a netlist of active modules, reconfiguration overhead can be reduced by fixing the position and shapes of modules common across all instances. We propose a global floorplan generation method PartialHeteroFP to obtain same positions for the common modules across all instances such that the heterogeneous resource requirements of all modules in each instance are satisfied, and the total half-perimeter wirelength over all instances is minimal. Experimental results establish that the proposed PartialHeteroFP produces floorplans very fast, with 100% match of common modules and thereby minimizing the partial reconfiguration overhead.",
A smooth control law for graceful motion of differential wheeled mobile robots in 2D environment,"Although recent progress in 2D mobile robot navigation has been significant, the great majority of existing work focuses only on ensuring that the robot reaches its goal. But to make autonomous navigation truly successful, the “quality” of planned motion is important as well. Here, we develop and analyze a pose-following kinematic control law applicable to unicycle-type robots, such that the robot can generate intuitive, fast, smooth, and comfortable trajectories. The Lyapunov-based feedback control law is derived via singular perturbation. It is made up of three components: (i) egocentric polar coordinates with respect to an observer on the vehicle, (ii) a slow subsystem which describes the position of the vehicle, where the reference heading is obtained via state feedback, and (iii) a fast subsystem which describes the steering of the vehicle, where the vehicle heading is exponentially stabilized to the obtained reference heading. The resulting path is a smooth and intuitive curve, globally converging to an arbitrary target pose without singularities, from any given initial pose. Furthermore, we present a simple path following strategy based on the proposed control law to satisfy arbitrary velocity, acceleration and jerk bounds imposed by the user. Such requirements are important to any autonomous vehicle so as to avoid actuator overload and to make the path physically realizable, and they are critical for applications like autonomous wheelchairs where passengers can be physically fragile.",
Contextual Object Localization With Multiple Kernel Nearest Neighbor,"Recently, many object localization models have shown that incorporating contextual cues can greatly improve accuracy over using appearance features alone. Therefore, many of these models have explored different types of contextual sources, but only considering one level of contextual interaction at the time. Thus, what context could truly contribute to object localization, through integrating cues from all levels, simultaneously, remains an open question. Moreover, the relative importance of the different contextual levels and appearance features across different object classes remains to be explored. Here we introduce a novel framework for multiple class object localization that incorporates different levels of contextual interactions. We study contextual interactions at the pixel, region and object level based upon three different sources of context: semantic, boundary support, and contextual neighborhoods. Our framework learns a single similarity metric from multiple kernels, combining pixel and region interactions with appearance features, and then applies a conditional random field to incorporate object level interactions. To effectively integrate different types of feature descriptions, we extend the large margin nearest neighbor to a novel algorithm that supports multiple kernels. We perform experiments on three challenging image databases: Graz-02, MSRC and PASCAL VOC 2007. Experimental results show that our model outperforms current state-of-the-art contextual frameworks and reveals individual contributions for each contextual interaction level as well as appearance features, indicating their relative importance for object localization.",
Nonblocking and Safe Control of Discrete-Event Systems Modeled as Extended Finite Automata,"Extended Finite Automata (EFA), i.e., finite automata extended with variables, are a suitable modeling framework for discrete event systems owing to their compactness, resulting from the use of variables. In this paper, we propose a symbolic algorithm that efficiently synthesizes a supervisor for a plant modeled by an EFA and a specification defined by another EFA. The principle of the algorithm is to iteratively strengthen the guards of the plant EFA so that forbidden or blocking states become unreachable in the controlled plant. As a consequence of the algorithm, the controlled behavior is modeled by an EFA having the same structure as the plant EFA, having stronger guards and is shown to be maximally permissive. We illustrate our algorithm via a simple manufacturing example.",
Enforcing similarity constraints with integer programming for better scene text recognition,"The recognition of text in everyday scenes is made difficult by viewing conditions, unusual fonts, and lack of linguistic context. Most methods integrate a priori appearance information and some sort of hard or soft constraint on the allowable strings. Weinman and Learned-Miller showed that the similarity among characters, as a supplement to the appearance of the characters with respect to a model, could be used to improve scene text recognition. In this work, we make further improvements to scene text recognition by taking a novel approach to the incorporation of similarity. In particular, we train a similarity expert that learns to classify each pair of characters as equivalent or not. After removing logical inconsistencies in an equivalence graph, we formulate the search for the maximum likelihood interpretation of a sign as an integer program. We incorporate the equivalence information as constraints in the integer program and build an optimization criterion out of appearance features and character bigrams. Finally, we take the optimal solution from the integer program, and compare all “nearby” solutions using a probability model for strings derived from search engine queries. We demonstrate word error reductions of more than 30% relative to previous methods on the same data set.",
Rapid and accurate 3D selection by progressive refinement,"Issues such as hand and tracker jitter negatively affect user performance with the ray-casting selection technique in 3D environments. This makes it difficult for users to perform tasks that require them to select objects that have a small visible area, since small targets require high levels of precision. We introduce an approach to address this issue that uses progressive refinement of the set of selectable objects to reduce the required precision of the task. We present a design space of progressive refinement techniques and an exemplar technique called Sphere-casting refined by QUAD-menu (SQUAD). We explore the tradeoffs between progressive refinement and immediate selection techniques in an evaluation comparing SQUAD to ray-casting. Both an analytical evaluation based on a distal pointing model and an empirical evaluation demonstrate that progressive refinement selection can be better than immediate selection. SQUAD was much more accurate than ray-casting, and SQUAD was faster than ray-casting with small targets and less cluttered environments.","Visualization,
Three dimensional displays,
Target tracking,
Accuracy,
Casting,
Jitter"
Utility-based resource allocation for virtual machines in Cloud computing,"One of the challenges of Infrastructure-as-a-Service Clouds is how to dynamically allocate resources to virtual machines such that quality of service constraints are satisfied and operating costs are minimized. The tradeoff between these two conflicting goals can be expressed by a utility function. In this paper, a two-tier resource management approach based on adequate utility functions is presented, consisting of local controllers that dynamically allocate CPU shares to virtual machines to maximize a local node utility function and a global controller that initiates live migrations of virtual machines to other physical nodes to maximize a global system utility function. Experimental results show the benefits of the proposed approach in Cloud computing environments.","Resource management,
Quality of service,
Heuristic algorithms,
Stability analysis,
Virtual machining,
Cloud computing,
Turning"
OBSERVE: Occupancy-based system for efficient reduction of HVAC energy,"Heating, cooling and ventilation accounts for 35% energy usage in the United States. Currently, most modern buildings still condition rooms assuming maximum occupancy rather than actual usage. As a result, rooms are often over-conditioned needlessly. Thus, in order to achieve efficient conditioning, we require knowledge of occupancy. This paper shows how real time occupancy data from a wireless sensor network can be used to create occupancy models which in turn can be integrated into building conditioning system for usage based demand control conditioning strategies. Using strategies based on sensor network occupancy model predictions, we show that it is possible to achieve 42% annual energy savings while still maintaining American Society of Heating, Refrigerating and Air-Conditioning (ASHRAE) comfort standards.",
Performance modeling and analysis of flash-based storage devices,"Flash-based solid-state drives (SSDs) will become key components in future storage systems. An accurate performance model will not only help understand the state-of-the-art of SSDs, but also provide the research tools for exploring the design space of such storage systems. Although over the years many performance models were developed for hard drives, the architectural differences between two device families prevent these models from being effective for SSDs. The hard drive performance models cannot account for several unique characteristics of SSDs, e.g., low latency, slow update, and expensive block-level erase. In this paper, we utilize the black-box modeling approach to analyze and evaluate SSD performance, including latency, bandwidth, and throughput, as it requires minimal a priori information about the storage devices. We construct the black-box models, using both synthetic workloads and real-world traces, on three SSDs, as well as an SSD RAID. We find that, while the black-box approach may produce less desirable performance predictions for hard disks, a black-box SSD model with a comprehensive set of workload characteristics can produce accurate predictions for latency, bandwidth, and throughput with small errors.","Performance evaluation,
Bandwidth,
Throughput,
Ash,
Predictive models,
Hard disks,
Mathematical model"
Design and Stability Analysis for Anytime Control via Stochastic Scheduling,"In this paper, we consider the problem of designing controllers for linear plants to be implemented in embedded platforms under stringent real-time constraints. These include preemptive scheduling schemes, under which the execution time allowed for control software tasks is uncertain. In a conservative Hard Real-Time (HRT) design approach, only a control algorithm that (in the worst case) is executable within the minimum time slot guaranteed by the scheduler would be employed. In the spirit of modern Soft Real-Time (SRT) approaches, we consider here an ""anytime control"" design technique, based on a hierarchy of controllers for the same plant. Higher controllers in the hierarchy provide better closed-loop performance, while typically requiring longer execution time. Stochastic models of the scheduler and of algorithm execution times are used to infer probabilities that controllers of different complexity can be executed at different periods. We propose a strategy for choosing among executable controllers, maximizing the usage of higher controllers, which affords better exploitation of the computational platform than the HRT design while guaranteeing stability (in a suitable stochastic sense). Results on the robustness with respect to uncertainties affecting the scheduler model, and on bumpless transfer for tracking problems are also reported. Simulation results on the control of two prototypical mechanical systems show that performance is substantially enhanced by our anytime control technique w.r.t. worst case-based scheduling.","Stability analysis,
Stochastic processes,
Scheduling algorithm,
Processor scheduling,
Algorithm design and analysis,
Control design,
Robustness,
Uncertainty,
Closed loop systems,
Computational modeling"
Sparse representation based band selection for hyperspectral images,"Hyperspectral images consist of large number of spectral bands but many of which contain redundant information. Therefore, band selection has been a common practice to reduce the dimensionality of the data space for cutting down the computational cost and alleviating from the Hughes phenomenon. This paper presents a new technique for band selection where a sparse representation of the hyperspectral image data is pursued through an existing algorithm, K-SVD, that decomposes the image data into the multiplication of an overcomplete dictionary (or signature matrix) and the coefficient matrix. The coefficient matrix, that possesses the sparsity property, reveals how importantly each band contributes in forming the hyperspectral data. By calculating the histogram of the coefficient matrix, we select the top K bands that appear more frequently than others to serve the need for dimensionality reduction and at the same time preserving the physical meaning of the selected bands. We refer to the proposed band selection algorithm based on sparse representation as SpaBS. Through experimental evaluation, we first use synthetic data to validate the sparsity property of the coefficient matrix. We then apply SpaBS on real hyperspectral data and use classification accuracy as a metric to evaluate its performance. Compared to other unsupervised band selection algorithms like PCA and ICA, SpaBS presents higher classification accuracy with a stable performance.","Hyperspectral imaging,
Sparse matrices,
Dictionaries,
Histograms,
Conferences,
Accuracy"
Compact Inverted-F Antenna With Meander Shorting Strip for Laptop Computer WLAN Applications,"In this letter, a novel compact inverted-F antenna with dual-band property for WLAN applications is presented. It comes with a C-shaped radiator and two meander shorting strips, which only occupy a small size of 35 (L)3 (W) mm to be easily embedded inside a laptop computer as an internal antenna. This design can radiate with two operating bands covering 2.38-2.54 and 4.99-5.96 GHz. By properly forming these two shorting strips, the effects due to the antenna near the external casing can be suitably tackled for actual application. Nearly omnidirectional coverage to enhance the communication quality can be obtained with our design. Therefore, the proposed antenna with a compact size is well suitable for WLAN operation in a laptop computer.","Antennas,
Wireless LAN,
Antenna measurements,
Portable computers,
Dual band,
Frequency measurement"
Mutual coupling suppression in closely spaced antennas,"A technique to significantly reduce the mutual coupling between closely spaced antennas operating at the same frequency band is presented. The method comprises the use of two ground-plane side walls that are erected vertically next to adjacent antennas. The side walls are defected with a lattice pattern of slots to form a defected wall structure (DWS). In addition, the adjacent antennas sharing a common ground plane are separated with a pair of slits in the ground plane. This technique implemented on closely packed antenna suppresses surface waves in the antenna's operation band and can provide isolation of 56'dB, which was achieved with a DWS loaded with mushroom-shape slots separating two microstrip patch antennas. In this case, the inter-antenna spacing (centre to centre) is 0.272'o and ground-plane size is 0.606 × 0.370 ×o2. Also investigated is the number of DWS slot loadings on isolation between adjacent antennas. Furthermore, the proposed technique is shown to substantially reduce mutual coupling between planar inverted-F antennas (PIFAs) and monopoles. The measured results validate the proposed technique and vindicate the simulation results.",
Optimal location queries in road network databases,"Optimal location (OL) queries are a type of spatial queries particularly useful for the strategic planning of resources. Given a set of existing facilities and a set of clients, an OL query asks for a location to build a new facility that optimizes a certain cost metric (defined based on the distances between the clients and the facilities). Several techniques have been proposed to address OL queries, assuming that all clients and facilities reside in an Lp space. In practice, however, movements between spatial locations are usually confined by the underlying road network, and hence, the actual distance between two locations can differ significantly from their Lp distance. Motivated by the deficiency of the existing techniques, this paper presents the first study on OL queries in road networks. We propose a unified framework that addresses three variants of OL queries that find important applications in practice, and we instantiate the framework with several novel query processing algorithms. We demonstrate the efficiency of our solutions through extensive experiments with real data.","Roads,
Artificial neural networks,
Measurement,
Algorithm design and analysis,
Cities and towns,
Equations,
Query processing"
Moving object tracking system based on camshift and Kalman filter,"To accomplish real-time tracking of moving objects requirements, and overcome the defect of occlusion in the process of tracking moving object, this paper presents a set of real-time tracking system. The tracking system uses a combination of camshift and kalman filter algorithm. When the moving object is a large area blocked, the velocity of moving object is applied linear prediction to kalman filter tracking. When the camera moves, we can quickly find the target in this tracking system. The experimental results show that : this system designed for tracking moving targets has good robustness.","Target tracking,
Kalman filters,
Algorithm design and analysis,
Prediction algorithms,
Cameras,
Robustness"
Active Queue Management for Flow Fairness and Stable Queue Length,"Two major goals of queue management are flow fairness and queue-length stability However, most prior works dealt with these goals independently. In this paper, we show that both goals can be effectively achieved at the same time. We propose a novel scheme that realizes flow fairness and queue-length stability. In the proposed scheme, high-bandwidth flows are identified via a multilevel caching technique. Then, we calculate the base drop probability for resolving congestion with a stable queue, and apply it to individual flows differently depending on their sending rates. Via extensive simulations, we show that the proposed scheme effectively realizes flow fairness between unresponsive and TCP flows, and among heterogeneous TCP flows, while maintaining a stable queue.",
Computing the Tree of Life: Leveraging the Power of Desktop and Service Grids,"The trend in life sciences research, particularly in molecular evolutionary systematics, is toward larger data sets and ever-more detailed evolutionary models, which can generate substantial computational loads. Over the past several years we have developed a grid computing system aimed at providing researchers the computational power needed to complete such analyses in a timely manner. Our grid system, known as The Lattice Project, was the first to combine two models of grid computing - the service model, which mainly federates large institutional HPC resources, and the desktop model, which harnesses the power of PCs volunteered by the general public. Recently we have developed a ""science portal"" style web interface that makes it easier than ever for phylogenetic analyses to be completed using GARLI, a popular program that uses a maximum likelihood method to infer the evolutionary history of organisms on the basis of genetic sequence data. This paper describes our approach to scheduling thousands of GARLI jobs with diverse requirements to heterogeneous grid resources, which include volunteer computers running BOINC software. A key component of this system provides a priori GARLI runtime estimates using machine learning with random forests.","Runtime,
Computational modeling,
Phylogeny,
Grid computing,
Lattices,
Software,
Vegetation"
Cloud computing and its key techniques,"With the development of parallel computing, distributed computing, grid computing, a new computing model appeared, called cloud computing. It aims to share data, calculations, and services transparently among users of a massive grid. It became a hot issue for its advantages such as “reduce costs”, “increase business flexibility” and/or “provide business continuity”. In this paper, we described what is cloud computing and took Google's cloud computing techniques as an example, summed up key techniques, such as data storage technology (Google File System), data management technology (BigTable), as well as programming model and task scheduling model (Map-Reduce), used in cloud computing, and then some example of cloud computing vendors were illustrated and compared.","Cloud computing,
Google,
Servers,
Hardware,
Computational modeling,
File systems"
Distributed coordination and data fusion for underwater search,"This paper presents coordination and data fusion methods for teams of vehicles performing target search tasks without guaranteed communication. A fully distributed team planning algorithm is proposed that utilizes limited shared information as it becomes available, and data fusion techniques are introduced for merging estimates of the target's position from vehicles that regain contact after long periods of time. The proposed data fusion techniques are shown to avoid overcounting information, which ensures that combining data from different vehicles will not decrease the performance of the search. Motivated by the underwater search domain, a realistic underwater acoustic communication channel is used to determine the probability of successful data transfer between two locations. The channel model is integrated into a simulation of multiple autonomous vehicles in both open ocean and harbor search scenarios. The simulated experiments demonstrate that distributed coordination with limited communication significantly improves team performance versus prior techniques that continually maintain connectivity.",
"A Miniature, High Precision Conductivity and Temperature Sensor System for Ocean Monitoring","A miniature high precision conductivity and temperature (CT) sensor system has been developed for ocean salinity monitoring. The CT sensor is manufactured using micro fabrication technology. A novel seven-electrode conductivity cell has been developed which has no field leakage. This is combined with a platinum resistor temperature bridge to produce an integrated CT sensor. A generic impedance measurement circuit has been developed, with three-parameter sine fitting algorithm. It has a 1 month battery life at 10 s sampling interval. Calibration results show that the initial CT accuracies are ±0.03 mS/cm and ±0.01°C, respectively. Testing of the CT sensor has been performed in the north Atlantic and revealed drift in sensor readings after five weeks of operation.","Temperature measurement,
Conductivity,
Electrodes,
Temperature sensors,
Resistors,
Voltage measurement,
Calibration"
Reduced-Complexity Soft-Decision Aided Space-Time Shift Keying,"In this letter, we propose to reduce the detection complexity of soft-decision aided Space-Time Shift Keying (STSK). More explicitly, we propose a vector-by-vector based STSK detector, which exhibits a lower complexity compared to the classic block-by-block based Space-Time Modulation (STM) detector. We further operate the STSK detector on a symbol-by-symbol basis, so that a near-capacity performance may be achieved with the aid of channel coding at a reduced complexity.","Detectors,
Complexity theory,
Binary phase shift keying,
Quadrature amplitude modulation,
Indexes,
Dispersion"
Fin Width and Bias Dependence of the Response of Triple-Gate MOSFETs to Total Dose Irradiation,The total ionizing dose response of triple-gate MOSFETs is investigated for various fin widths and bias conditions. Experiments and simulations are used to analyze the buildup of trapped charge in the buried oxide and its impact on the threshold-voltage shift and subthreshold-slope degradation. The higher total-dose tolerance of multiple-gate FinFETs with narrow fins is attributed to lateral gate control over the electrostatic potential in the body and especially at the Si fin/BOX interface. It is demonstrated that ON-state irradiation is the worst-case bias configuration for triple-gate MOSFETs through extensive experimental analysis.,"Logic gates,
MOSFETs,
Radiation effects,
FinFETs,
Degradation"
State-of-the-art in offline signature verification system,"Biometrics can be classified into two types Behavioral (signature verification, keystroke dynamics, etc.) and Physiological (iris characteristics, fingerprint, etc.). Handwritten signature is one of the first few biometrics used even before computers. Signature verification is widely studied and discussed using two approaches. On-line approach and offline approach. Offline systems are more applicable and easy to use in comparison with on-line systems in many parts of the world however it is considered more difficult than on-line verification due to the lack of dynamic information. This paper presents the State-of-the-Art about offline signature verification system; this biometric identification method that had more attraction in recent years because of its necessity for use in daily life routines and when the signature needs to be immediately verified like bank checks. In this paper, we present signature forgery types, features types and recent methods used for features extraction in signature verification systems and approaches used for verification in signature systems. Then we discuss these approaches and for which type of forgeries its suitable. Finally, we suggest new interesting ideas to be incorporated in the future.",
The streaming capacity of sparsely-connected P2P systems with distributed control,"Peer-to-Peer (P2P) streaming technologies can take advantage of the upload capacity of clients, and hence can scale to large content distribution networks with lower cost. A fundamental question for P2P streaming systems is the maximum streaming rate that all users can sustain. Prior works have studied the optimal streaming rate for a complete network, where every peer is assumed to communicate with all other peers. This is however an impractical assumption in real systems. In this paper, we are interested in the achievable streaming rate when each peer can only connect to a small number of neighbors. We show that even with a random peer selection algorithm and uniform rate allocation, as long as each peer maintains Ω(log N) downstream neighbors, where N is the total number of peers in the system, the system can asymptotically achieve a streaming rate that is close to the optimal streaming rate of a complete network.We then extend our analysis to multi-channel P2P networks, and we study the scenario where “helpers” from channels with excessive upload capacity can help peers in channels with insufficient upload capacity. We show that by letting each peer select Ω(log N) neighbors randomly from either the peers in the same channel or from the helpers, we can achieve a close-to-optimal streaming capacity region. Simulation results are provided to verify our analysis.",
Joint transceiver design and user grouping in a MIMO interfering broadcast channel,"Consider a MIMO interfering broadcast channel (multi-cellular network) where each base station transmits signals to the users in its own cell. The basic problem is to design linear transmit/receive beamformers that can maximize the system throughput in the presence of both inter and intra cell interference. To ensure user fairness in the system, we consider the joint user grouping, power allocation and beamformer design problem by maximizing a system utility which aims to strike a suitable trade-off between the user fairness and system throughput. We propose a simple algorithm to solve this nonconcave utility maximization problem and establish its convergence. The simulation results show that the proposed algorithm significantly outperforms the SVD-MMSE method and some other approaches in terms of system throughput while respecting user fairness. The proposed algorithm exhibits fast convergence and is amenable to distributed implementation with limited information exchange.",
Secure data transmission using video Steganography,"It is very essential to transmit important data like banking and military information in a secure manner. Video Steganography is the process of hiding some secret information inside a video. The addition of this information to the video is not recognizable by the human eye as the change of a pixel color is negligible. This paper aims to provide an efficient and a secure method for video Steganography. The proposed method creates an index for the secret information and the index is placed in a frame of the video itself. With the help of this index, the frames containing the secret information are located. Hence, during the extraction process, instead of analyzing the entire video, the frames containing the secret data are analyzed with the help of index at the receiving end. When steganographed by this method, the probability of finding the hidden information by an attacker is lesser when compared to the normal method of hiding information frame-by-frame in a sequential manner. It also reduces the computational time taken for the extraction process.",
Explaining the Sustainability of Digital Ecosystems based on the Wiki Model Through Critical-Mass Theory,"This paper investigates the sustainability of a type of digital ecosystem, namely, knowledge-sharing communities built on the wiki model. Sustainability is hypothesized to result from the participation of contributors with varying levels of resources and interests. The differences in resources and interests, according to the critical-mass theory, enable such communities to overcome typical start-up and growth problems. This paper describes a preliminary empirical test of the critical-mass theory in this context, with Wikipedia as a test case that demonstrates sustainability as well as resource and interest heterogeneity, based on a survey of 78 Wikipedians. The characteristic patterns of success exhibited in Wikipedia are expected to inform the management of other wiki-based information assets.","Ecosystems,
Wikipedia,
Testing,
Permission,
Collaborative work,
Online Communities/Technical Collaboration,
Asset management,
Communication system control,
Control systems,
Computer mediated communication"
Automatic Multishot Operation of an Electromagnetic Launcher,"The Naval Research Laboratory has developed an automatic electromagnetic launcher system for countermeasure deployment. The launcher operates at 1 Hz and can fire bursts of one to six 44-mm2 projectiles. The launcher is controlled from a computer that permits selection of the bank charging voltage and the number of shots. The present experimental setup consists of a railgun, an autoloader, and a rapid charger with computer control.","Rails,
Projectiles,
Railguns,
Capacitors,
Copper,
Loading,
Electromagnetics"
A Reconfigurable Quad-Band CMOS Class E Power Amplifier for Mobile and Wireless Applications,This paper proposes a new design technique for a reconfigurable CMOS Class E power amplifier (PA) by selectively activating the transistor cells in the array of power transistors. The activated transistors will be used for amplification and the non-activated transistors will be used for input/output matching and switching capacitance for Class E operation. The quad-band PA for 1.9/2.3/2.6/3.5 GHz has been implemented in a 0.18 μm CMOS technology using the technique without any switch or tunable circuit. This PA obtains output powers of 24.2/23.8/23.4/ 20.5 dBm and efficiency of 48.2/44.3/40.9/35.6% at 1.9/2.3/2.6/ 3.5 GHz. The total MMIC chip size is as small as 0.92 × 1.75 mm2 for the reconfigurable quad-band operation.,
"FIST: A fast, lightweight, FPGA-friendly packet latency estimator for NoC modeling in full-system simulations","FIST (Fast Interconnect Simulation Techniques) is a fast and simple packet latency estimator to replace time-consuming detailed Network-on-Chip (NoC) models in full-system performance simulators. FIST combines ideas from analytical network modeling and execution-driven simulation models. The main idea is to abstractly model each router as a load-delay curve and sum load-dependent delay at each visited router to obtain a packet's latency by tracking each router's load at runtime. The resulting latency estimator can accurately capture subtle load-dependent behaviors of a NoC but is much simpler than a full-blown execution-driven model. We study two variations of FIST in the context of a software-based, cycle-level simulation of a tiled chip-multiprocessor (CMP). We evaluate FIST's accuracy and performance relative to the CMP simulator's original execution-driven 2D-mesh NoC model. A static FIST approach (trained offine using uniform random synthetic traffic) achieves less than 6% average error in packet latency and up to 43× average speedup for a 16×16 mesh. A dynamic FIST approach that adds periodic online training reduces the average packet latency error to less than 2% and still maintains an average speedup of up to 18× for a 16×16 mesh. Moreover, an FPGA-based realization of FIST can simulate 2D-mesh networks up to 24×24 nodes, at 3 to 4 orders of magnitude speedup over software-based simulators.",
Calvin: Deterministic or not? Free will to choose,"Most shared memory systems maximize performance by unpredictably resolving memory races. Unpredictable memory races can lead to nondeterminism in parallel programs, which can suffer from hard-to-reproduce hiesenbugs. We introduce Calvin, a shared memory model capable of executing in a conventional nondeterministic mode when performance is paramount and a deterministic mode when execution repeatability is important. Unlike prior hardware proposals for deterministic execution, Calvin exploits the flexibility of a memory consistency model weaker than sequential consistency. Specifically, Calvin logically orders memory operations into strata that are compatible with the Total Store Order (TSO). Calvin is also designed with the needs of future power-aware processors in mind, and does not require any speculation support. We develop a Calvin-MIST implementation that uses an unordered coalescing write cache, multiple-write coherence protocol, and delayed (timebomb) invalidations while maintaining TSO compatibility. Results show that Calvin-MIST can execute workloads in conventional mode at speeds comparable to a conventional system (providing compatibility) or execute deterministically for a modest average slowdown of less than 20% (when determinism is valued).",
A dynamically reconfigurable architecture for smart grids,"This paper introduces a proposal for a smart grid management platform built on the distributed programming paradigm. Besides it is based on an information model and event architecture. The information model defines a set of clear interfaces to manage every ""grid node"". We built an actual implementation of a low-cost embeddable control/meter device that may even be attached to individual appliances. These devices behave as conventional autonomous remote distributed objects and provide full support for the information model and also for integration with the communication middleware. The resulting event architecture provides great flexibility to manage information flows from services and applications.","Smart grids,
Observers,
Middleware,
Hardware,
Protocols,
Proposals,
Home appliances"
Characterizing WiFi link performance in open outdoor networks,"We present an experimental performance evaluation study of WiFi links in an open-space outdoor environment. We consider a large scale wireless sensor network scenario of seismic data collection from sensors that are buried in ground and a set of access points (APs) form the hierarchical aggregation layer and the backbone of the network. We conduct two different link characterization studies. First, we evaluate the links between the sensor nodes and a wireless AP using IEEE 802.11a/b/g. We construct the path loss model and investigate the reachability distance of this link for different protocols and different sensor node antenna heights. We then characterize the long distance wireless backhaul links between the APs. We use 802.11n and high gain directional antenna for high throughput and long distance. We evaluate how different PHY and MAC layer enhancements of 802.11n impacts its performance in an open outdoor environment. We observed up to 148 Mb/s throughput at 800 meter line-of-sight links without sophisticated tuning of antenna orientation. We believe our findings can be a benchmark for WiFi based outdoor network deployment, especially for high throughput long distance links.","IEEE 802.11n Standard,
Throughput,
Antennas,
MIMO,
Wireless communication,
Antenna measurements"
Probability Estimation in the Rare-Events Regime,"We address the problem of estimating the probability of an observed string that is drawn i.i.d. from an unknown distribution. Motivated by models of natural language, we consider the regime in which the length of the observed string and the size of the underlying alphabet are comparably large. In this regime, the maximum likelihood distribution tends to overestimate the probability of the observed letters, so the Good-Turing probability estimator is typically used instead. We show that when used to estimate the sequence probability, the Good-Turing estimator is not consistent in this regime. We then introduce a novel sequence probability estimator that is consistent. This estimator also yields consistent estimators for other quantities of interest and a consistent universal classifier.","Entropy,
Estimation,
Natural languages,
Markov processes,
Probability distribution,
Data models,
Approximation methods"
"A study and comparison of OLSR, AODV and TORA routing protocols in ad hoc networks","Mobile Ad hoc Network (MANET) is a collection of mobile nodes in which the wireless links are frequently broken down due to mobility and dynamic infrastructure. Routing is a significant issue and challenge in ad hoc networks. Many routing protocols have been proposed like OLSR, AODV, DSR, ZRP, and TORA so far to improve the routing performance and reliability. This research paper describes the characteristics of ad hoc routing protocols OLSR, AODV and TORA based on the performance metrics like packet delivery ratio, end-to-end delay, routing overload by increasing number of nodes in the network. This comparative study proves that AODV, TORA performs well in dense networks than OLSR in terms of packet delivery ratio.","Routing protocols,
Routing,
Delay,
Mobile ad hoc networks,
Mobile computing"
"High level synthesis of stereo matching: Productivity, performance, and software constraints","FPGAs are an attractive platform for applications with high computation demand and low energy consumption requirements. However, design effort for FPGA implementations remains high - often an order of magnitude larger than design effort using high level languages. Instead of this time-consuming process, high level synthesis (HLS) tools generate hardware implementations from high level languages (HLL) such as C/C++/SystemC. Such tools reduce design effort: high level descriptions are more compact and less error prone. HLS tools promise hardware development abstracted from software designer knowledge of the implementation platform. In this paper, we examine several implementations of stereo matching, an active area of computer vision research that uses techniques also common for image de-noising, image retrieval, feature matching and face recognition. We present an unbiased evaluation of the suitability of using HLS for typical stereo matching software, usability and productivity of AutoPilot (a state of the art HLS tool), and the performance of designs produced by AutoPilot. Based on our study, we provide guidelines for software design, limitations of mapping general purpose software to hardware using HLS, and future directions for HLS tool development. For the stereo matching algorithms, we demonstrate between 3.5X and 67.9X speedup over software (but less than achievable by manual RTL design) with a five-fold reduction in design effort vs. manual hardware design.","Arrays,
Software,
Optimization,
Hardware,
Stereo vision,
Software algorithms,
Pipeline processing"
Ambulatory Estimation of Knee-Joint Kinematics in Anatomical Coordinate System Using Accelerometers and Magnetometers,"Knee-joint kinematics analysis using an optimal sensor set and a reliable algorithm would be useful in the gait analysis. An original approach for ambulatory estimation of knee-joint angles in anatomical coordinate system is presented, which is composed of a physical-sensor-difference-based algorithm and virtual-sensor-difference-based algorithm. To test the approach, a wearable monitoring system composed of accelerometers and magnetometers was developed and evaluated on lower limb. The flexion/extension (f/e), abduction/adduction (a/a), and inversion/extension (i/e) rotation angles of the knee joint in the anatomical joint coordinate system were estimated. In this method, since there is no integration of angular acceleration or angular velocity, the result is not distorted by offset and drift. The three knee-joint angles within the anatomical coordinate system are independent of the orders, which must be considered when Euler angles are used. Besides, since there are no physical sensors implanted in the knee joint based on the virtual-sensor-difference-based algorithm, it is feasible to analyze knee-joint kinematics with less numbers and types of sensors than those mentioned in some others methods. Compared with results from the reference system, the developed wearable sensor system is available to do gait analysis with fewer sensors and high degree of accuracy.","Joints,
Knee,
Acceleration,
Accelerometers,
Thigh,
Kinematics,
Magnetic fields"
Geometrically Induced Force Interaction for Three-Dimensional Deformable Models,"In this paper, we propose a novel 3-D deformable model that is based upon a geometrically induced external force field which can be conveniently generalized to arbitrary dimensions. This external force field is based upon hypothesized interactions between the relative geometries of the deformable model and the object boundary characterized by image gradient. The evolution of the deformable model is solved using the level set method so that topological changes are handled automatically. The relative geometrical configurations between the deformable model and the object boundaries contribute to a dynamic vector force field that changes accordingly as the deformable model evolves. The geometrically induced dynamic interaction force has been shown to greatly improve the deformable model performance in acquiring complex geometries and highly concave boundaries, and it gives the deformable model a high invariancy in initialization configurations. The voxel interactions across the whole image domain provide a global view of the object boundary representation, giving the external force a long attraction range. The bidirectionality of the external force field allows the new deformable model to deal with arbitrary cross-boundary initializations, and facilitates the handling of weak edges and broken boundaries. In addition, we show that by enhancing the geometrical interaction field with a nonlocal edge-preserving algorithm, the new deformable model can effectively overcome image noise. We provide a comparative study on the segmentation of various geometries with different topologies from both synthetic and real images, and show that the proposed method achieves significant improvements against existing image gradient techniques.","Force,
Deformable models,
Image edge detection,
Three dimensional displays,
Geometry,
Image segmentation,
Active contours"
Transmission Capacity of Spectrum Sharing Ad Hoc Networks with Multiple Antennas,"Two coexisting ad hoc networks, primary and secondary, are considered, where each node of the primary network has a single antenna, while each node of the secondary network is equipped with multiple antennas. Using multiple antennas, each secondary transmitter uses some of its spatial transmit degrees of freedom (STDOF) to null its interference towards the primary receivers, while each secondary receiver employs interference cancelation using some of its spatial receive degrees of freedom (SRDOF). This paper derives the optimal STDOF for nulling and SRDOF for interference cancelation that maximize the scaling of the transmission capacity of the secondary network with respect to the number of antennas, when the secondary network operates under an outage constraint at the primary receivers. With a single receive antenna, using a fraction of the total STDOF for nulling at each secondary transmitter maximizes the transmission capacity. With multiple transmit and receive antennas and fixing all but one STDOF for nulling, using a fraction of the total SRDOF to cancel the nearest interferers maximizes the transmission capacity of the secondary network.","Transmitting antennas,
Receiving antennas,
Interference,
Ad hoc networks"
Image-Based Variational Meshing,"In medical simulations involving tissue deformation, the finite element method (FEM) is a widely used technique, where the size, shape, and placement of the elements in a model are important factors that affect the interpolation and numerical errors of a solution. Conventional model generation schemes for FEM consist of a segmentation step delineating the anatomy followed by a meshing step generating elements conforming to this segmentation. In this paper, a single-step model generation technique is proposed based on optimization. Starting from an initial mesh covering the domain of interest, the mesh nodes are adjusted to minimize an objective function which penalizes intra-element intensity variations and poor element geometry for the entire mesh. Trade-offs between mesh geometry quality and intra-element variance are achieved by adjusting the relative weights of the geometric and intensity variation components of the cost function. This meshing approach enables a more accurate rendering of shapes with fewer elements and provides more accurate models for deformation simulation, especially when the image intensities represent a mechanical feature of the tissue such as the elastic modulus. The use of the proposed mesh optimization is demonstrated in 2-D and 3-D on synthetic phantoms, MR images of the brain, and CT images of the kidney. A comparison with previous meshing techniques that do not account for image intensity is also provided demonstrating the benefits of our approach.","Deformable models,
Shape,
Geometry,
Medical simulation,
Finite element methods,
Interpolation,
Anatomy,
Cost function,
Rendering (computer graphics),
Brain modeling"
PowerSleep: A Smart Power-Saving Scheme With Sleep for Servers Under Response Time Constraint,"Reducing the power consumption while maintaining the response time constraint has been an important goal in server system design. One of the techniques widely explored in the literature to achieve this goal is dynamic voltage scaling (DVS). However, DVS is not efficient in modern systems where the overall power consumption includes a large portion of static power consumption. In this paper, we aim to reduce the static power consumption by dynamic power management (DPM) with sleep model in addition to DVS. To maximize the sleep efficiency, we propose PowerSleep, a smart power-saving scheme by carefully choosing an execution speed for the server with DVS and sleep periods while putting the system in the sleep power mode with DPM. By modeling the system with M/G/1/PS queuing model and further significant extensions, we present how to minimize the mean power consumption of the server under the given mean response time constraint. Simulation results show that our smart PowerSleep scheme significantly outperforms the simple power-saving scheme which adopts sleep mode.","Servers,
Time factors,
Power demand,
Voltage control,
Queueing analysis,
Delay"
Towards a light-weight message authentication mechanism tailored for Smart Grid communications,"Smart Grid (SG) technology, which aims at bringing the world's aging electric grids into the 21st century by utilizing intelligent transmission and distributed networks, has been gaining momentum in recent years. Despite its attractive features, the SG technology remains vulnerable to some security threats, such as spoofing and man-in-the-middle attacks. In this paper, to address these potential security issues, we propose a light-weight and secure message authentication mechanism. The proposed mechanism is based on Diffie-Hellman key establishment protocol and hash-based message authentication code, which allows various smart meters at different points of the SG to make mutual authentication and achieve message authentication with low latency and few signal message exchanges. Detailed security analysis shows it can satisfy the desirable security requirements. In addition, extensive computer-based simulation also demonstrates its efficiency.","Base stations,
Logic gates,
WiMAX,
Power generation"
Ruru: A spatial and interactive visual programming language for novice robot programming,"Robots are useful tools for teaching novices programming as real and immediate outcomes of programs can be seen. However robot software development has unique problems making aspects of programming difficult compared with general software development. These problems include the robot platform, the robot's environment and its interaction in three-dimensional space and the fact that events occur in real time. We describe Ruru, a novel visual language that addresses these difficulties through a principled approach to its design. It also visualizes robot inputs intuitively in real time and allows the intuitive amendment of parameters. This improves its usefulness and user friendliness as a tool for teaching novices programming.","Visualization,
Robot sensing systems,
Shape,
Semantics,
Programming,
Collision avoidance"
Development of a Point-of-Care Testing Platform With a Nanogap-Embedded Separated Double-Gate Field Effect Transistor Array and Its Readout System for Detection of Avian Influenza,"Label-free electrical detection of avian influenza (AI) is demonstrated for the development of a point-of-care testing (POCT) platform. For a new POCT platform, a novel field effect transistor (FET)-based biosensor array was fabricated with conventional complementary metal-oxide-semiconductor (CMOS) technology. Nanogap-embedded separated double-gate FETs (nanogap-DGFETs) were realized in a 6×6 array as a biosensor cartridge. Moreover, the low-noise readout circuit was designed and fabricated using a 0.35- μm standard CMOS process. The AI antigen and antibody were bound with the aid of silica-binding proteins (SBP) in the nanogap of the biosensor device. Because the gate dielectric constant was increased by the immobilized biomolecules, the threshold voltage of the nanogap-DGFET was reduced while the drain-to-source current was enhanced. Drain-to-source currents of the nanogap-DGFET array were successfully acquired using the fabricated readout circuitry and measurement setup. This platform is suitable for a simple and effective label-free detection of AI in POCT applications.","Biosensors,
FETs,
Testing,
Molecular biophysics,
Logic gates,
Nanobioscience,
Electrodes"
Interactive Visual Analysis of Heterogeneous Scientific Data across an Interface,"We present a systematic approach to the interactive visual analysis of heterogeneous scientific data. The data consist of two interrelated parts given on spatial grids over time (e.g., atmosphere and ocean part from a coupled climate model). By integrating both data parts in a framework of coordinated multiple views (with linking and brushing), the joint investigation of features across the data parts is enabled. An interface is constructed between the data parts that specifies 1) which grid cells in one part are related to grid cells in the other part, and vice versa, 2) how selections (in terms of feature extraction via brushing) are transferred between the two parts, and 3) how an update mechanism keeps the feature specification in both data parts consistent during the analysis. We also propose strategies for visual analysis that result in an iterative refinement of features specified across both data parts. Our approach is demonstrated in the context of a complex simulation of fluid-structure interaction and a multirun climate simulation.","Visualization,
Data models,
Solids,
Data visualization,
Computational modeling,
Atmospheric modeling,
Analytical models"
Morse theory and formation control,"Formation shape control for a collection of point agents is concerned with devising decentralized control laws which will ensure that the formation will move so that certain inter-agent distances assume prescribed values. A number of algorithms based on steepest descent of an error function have been suggested for various problems, and all display the existence of incorrect equilibria, though often the equilibria are saddle points or unstable. This paper introduces Morse theory as a tool for analyzing the number of such equilibria. A key conclusion is that for two-dimensional rigid formations of point agents, there will always be incorrect equilibria associated with any steepest descent law.",
Improving communication performance in dense linear algebra via topology aware collectives,"Recent results have shown that topology aware mapping reduces network contention in communication-intensive kernels on massively parallel machines. We demonstrate that on mesh interconnects, topology aware mapping also allows for the utilization of highly-efficient topology aware collectives. We map novel 2.5D dense linear algebra algorithms to exploit rectangular collectives on cuboid partitions allocated by a Blue Gene/P supercomputer. Our mappings allow the algorithms to exploit optimized line multicasts and reductions. Commonly used 2D algorithms cannot be mapped in this fashion. On 16,384 nodes (65,536 cores) of Blue Gene/P, 2.5D algorithms that exploit rectangular collectives are sig- nificantly faster than 2D matrix multiplication (MM) and LU factorization, up to 8.7x and 2.1x, respectively. These speed-ups are due to communication reduction (up to 95.6% for 2.5D MM with respect to 2D MM). We also derive LogP- based novel performance models for rectangular broadcasts and reductions. Using those, we model the performance of matrix multiplication and LU factorization on a hypothetical exascale architecture.","Partitioning algorithms,
Topology,
Three dimensional displays,
Algorithm design and analysis,
Bandwidth,
Linear algebra,
Network topology"
Design Optimization of Vehicle Control Networks,"The advancement of electronic technology has made significant contributions to the safety and convenience of modern vehicles. New intelligent functionalities of vehicles have been implemented in a number of electronic control units (ECUs) that are connected to each in vehicle control networks (VCNs). However, with the rapid increase in the number of ECUs, VCNs currently face several challenges, e.g., design complexity, space constraints, system reliability, and interdependency. Considering these factors, the complexity of the VCN design problem exponentially increases, which means that the problem cannot be solved within a reasonable time using conventional optimization techniques. In this paper, we report a new methodology for the optimal design of VCNs. An analytical model was derived to examine the fundamental characteristics of the VCN design problem. Compared with the case of a conventional data network, which typically considers temporal scheduling over a fixed physical topology, the VCN design problem should also consider spatial constraints, e.g., volume, position, and weight. Moreover, the spatial constraints change during the solving procedure. Such temporal and spatial joint optimization problems with varying constraints incur extremely high computational complexity. To tackle the high complexity, this paper proposes a fast solution based on a repeated-matching method, which reduces the problem complexity from O(NNN) to O(NN3). By applying our methodology to a number of different real-world VCN design scenarios, this proposal can produce a 1% near-optimal design within a significantly reduced time.","Vehicles,
Optimization,
Resource management,
Reliability,
Timing,
Complexity theory,
Wiring"
Visually bootstrapped generalized ICP,"This paper reports a novel algorithm for boot strapping the automatic registration of unstructured 3D point clouds collected using co-registered 3D lidar and omnidirectional camera imagery. Here, we exploit the co-registration of the 3D point cloud with the available camera imagery to associate high dimensional feature descriptors such as scale invariant feature transform (SIFT) or speeded up robust features (SURF) to the 3D points. We first establish putative point correspondence in the high dimensional feature space and then use these correspondences in a random sample consensus (RANSAC) framework to obtain an initial rigid body transformation that aligns the two scans. This initial transformation is then refined in a generalized iterative closest point (ICP) framework. The proposed method is completely data driven and does not require any initial guess on the transformation. We present results from a real world dataset collected by a vehicle equipped with a 3D laser scanner and an omnidirectional camera.","Three dimensional displays,
Iterative closest point algorithm,
Laser radar,
Cameras,
Image color analysis,
Feature extraction,
Robustness"
Classification of traffic video based on a spatiotemporal orientation analysis,"This paper describes a system for classifying traffic congestion videos based on their observed visual dynamics. Central to the proposed system is treating traffic flow identification as an instance of dynamic texture classification. More specifically, a recent discriminative model of dynamic textures is adapted for the special case of traffic flows. This approach avoids the need for segmentation, tracking and motion estimation that typify extant approaches. Classification is based on matching distributions (or histograms) of spacetime orientation structure. Empirical evaluation on a publicly available data set shows high classification performance and robustness to typical environmental conditions (e.g., variable lighting).","Vehicle dynamics,
Spatiotemporal phenomena,
Energy measurement,
Dynamics,
Real time systems,
Lighting,
Robustness"
A novel feature descriptor based on the shearlet transform,"Problems such as image classification, object detection and recognition rely on low-level feature descriptors to represent visual information. Several feature extraction methods have been proposed, including the Histograms of Oriented Gradients (HOG), which captures edge information by analyzing the distribution of intensity gradients and their directions. In addition to directions, the analysis of edge at different scales provides valuable information. Shearlet transforms provide a general framework for analyzing and representing data with anisotropic information at multiple scales. As a consequence, signal singularities, such as edges, can be precisely detected and located in images. Based on the idea of employing histograms to estimate the distribution of edge orientations and on the accurate multi-scale analysis provided by shearlet transforms, we propose a feature descriptor called Histograms of Shearlet Coefficients (HSC). Experimental results comparing HOG with HSC show that HSC provides significantly better results for the problems of texture classification and face identification.","Histograms,
Image edge detection,
Face,
Feature extraction,
Humans,
Wavelet transforms"
The STeTSiMS STT-RAM simulation and modeling system,"There is growing interest in emerging non-volatile memory technologies such as Phase-Change Memory, Memristors, and Spin-Transfer Torque RAM (STT-RAM). STT-RAM, in particular, is experiencing rapid development that can be difficult for memory systems researchers to take advantage of. What is needed are techniques that enable designers to explore the potential of recent STT-RAM designs and adjust the performance without needing a detailed understanding of the physics. In this paper, we present the STeTSiMS STT-RAM Simulation and Modeling System to assist memory systems researchers. After providing background on the operation of STT-RAM magnetic tunnel junctions (MTJs), we demonstrate how to fit three different published MTJ models to our model and normalize their characteristics with respect to common metrics. The high-speed switching behavior of the designs is evaluated using macromagnetic simulations. We have also added a first-order model for STT-RAM memory arrays to the CACTI memory modeling tool, which we then use to evaluate the performance, energy consumption, and area for: (i) a high-performance cache, (ii) a high-capacity cache, and (iii) a high-density memory.",
A framework for global vehicle localization using stereo images and satellite and road maps,"We present a framework for global vehicle localization and 3D point cloud reconstruction that combines stereo visual odometry, satellite images, and road maps under a particle-filtering architecture. The framework focuses on the general vehicle localization scenario without the use of global positioning system for urban and rural environments and with the presence of moving objects. The main novelties of our approach are using road maps and rendering accurate top views using stereo reconstruction, and match these views with the satellite images in order to eliminate drifts and obtain accurate global localization. We show that our method is practicable by presenting experimental results on a 2 km road where mostly specific road features do not exist.","Roads,
Vehicles,
Satellites,
Stereo vision,
Cameras,
Estimation,
Image reconstruction"
Reducing Handover Delay by Location Management in Mobile WiMAX Multicast and Broadcast Services,"Mobile Worldwide Interoperability for Microwave Access (WiMAX) includes a multimedia multicast/broadcast service (MBS), but delay-sensitive applications such as video and audio streaming require the combination of efficient handling of wireless-link bandwidth and reduced handover delays, which remains a challenge. To reduce the handover delay in the MBS, the IEEE 802.16e standard introduces an MBS zone, which is a group of base stations that are broadcasting the same multicast packets. However, this raises the MBS traffic load on Mobile WiMAX networks, particularly the wireless part. This paper presents an MBS architecture that is based on location-management areas (LMAs), which can increase the sizes of MBS zones to reduce the average handover delay without too much bandwidth waste. An analytical model is developed to quantify service-disruption time, bandwidth usage, and blocking probability for different sizes of MBS zones and LMAs while considering user mobility, user distribution, and MBS session popularity. Using this model, we also propose how to determine the best sizes of MBS zones and LMAs, along with performance guarantees. Analytical and simulation results demonstrate that our LMA-based MBS scheme can achieve a bandwidth-efficient multicast delivery while retaining an acceptable service-disruption time.","Delay,
Bandwidth,
WiMAX,
Mobile communication,
Planning,
Streaming media"
Learning Low-Dimensional Signal Models,"Sampling, coding, and streaming even the most essential data, e.g., in medical imaging and weather-monitoring applications, produce a data deluge that severely stresses the avail able analog-to-digital converter, communication bandwidth, and digital-storage resources. Surprisingly, while the ambient data dimension is large in many problems, the relevant information in the data can reside in a much lower dimensional space. This observation has led to several important theoretical and algorithmic developments under different low-dimensional modeling frameworks, such as compressive sensing (CS), matrix completion, and general factor-model representations. These approaches have enabled new measurement systems, tools, and methods for information extraction from dimensionality-reduced or incomplete data. A key aspect of maximizing the potential of such techniques is to develop appropriate data models. In this article, we investigate this challenge from the perspective of nonparametric Bayesian analysis.","Data models,
Manifolds,
Bayesian methods,
Monitoring,
Training data,
Analytical models"
Discriminative learning of relaxed hierarchy for large-scale visual recognition,"In the real visual world, the number of categories a classifier needs to discriminate is on the order of hundreds or thousands. For example, the SUN dataset [24] contains 899 scene categories and ImageNet [6] has 15,589 synsets. Designing a multiclass classifier that is both accurate and fast at test time is an extremely important problem in both machine learning and computer vision communities. To achieve a good trade-off between accuracy and speed, we adopt the relaxed hierarchy structure from [15], where a set of binary classifiers are organized in a tree or DAG (directed acyclic graph) structure. At each node, classes are colored into positive and negative groups which are separated by a binary classifier while a subset of confusing classes is ignored. We color the classes and learn the induced binary classifier simultaneously using a unified and principled max-margin optimization. We provide an analysis on generalization error to justify our design. Our method has been tested on both Caltech-256 (object recognition) [9] and the SUN dataset (scene classification) [24], and shows significant improvement over existing methods.",
Signal Compensation and Compressed Sensing for Magnetization-Prepared MR Angiography,"Magnetization-prepared acquisitions offer a trade-off between image contrast and scan efficiency for magnetic resonance imaging. Because the prepared signals gradually decay, the contrast can be improved by frequently repeating the preparation, which in turn significantly increases the scan time. A common solution is to perform the data collection progressing from low- to high-spatial-frequency samples following each preparation. Unfortunately, this leads to loss of spatial resolution, and thereby image blurring. In this work, a new technique is proposed that first corrects the signal decay in high-frequency data to mitigate the resolution loss and improve the image contrast without reducing the scan efficiency. The proposed technique then employs a sparsity-based nonlinear reconstruction to further improve the image quality. In addition to reducing the amplified high-frequency noise, this reconstruction extrapolates missing k-space samples in the case of undersampled compressed-sensing acquisitions. The technique is successfully demonstrated for noncontrast-enhanced flow-independent angiography of the lower extremities, an application that substantially benefits from both the signal compensation and the nonlinear reconstruction.","Muscles,
Blood,
Magnetization,
Image reconstruction,
Magnetic resonance imaging,
Transient analysis,
Noise"
A Hardware-in-the-Loop Simulation Platform for the Verification and Validation of Safety Control Systems,"Verification and validation (V&V) of safety control system quality and performance is required prior to installing control system hardware within nuclear power plants (NPPs). Thus, the objective of the hardware-in-the-loop (HIL) platform introduced in this paper is to verify the functionality of these safety control systems. The developed platform provides a flexible simulated testing environment which enables synchronized coupling between the real and simulated world. Within the platform, National Instruments (NI) data acquisition (DAQ) hardware provides an interface between a programmable electronic system under test (SUT) and a simulation computer. Further, NI LabVIEW resides on this remote DAQ workstation for signal conversion and routing between Ethernet and standard industrial signals as well as for user interface. The platform is applied to the testing of a simplified implementation of Canadian Deuterium Uranium (CANDU) shutdown system no. 1 (SDS1) which monitors only the steam generator level of the simulated NPP. CANDU NPP simulation is performed on a Darlington NPP desktop training simulator provided by Ontario Power Generation (OPG). Simplified SDS1 logic is implemented on an Invensys Tricon v9 programmable logic controller (PLC) to test the performance of both the safety controller and the implemented logic. Prior to HIL simulation, platform availability of over 95% is achieved for the configuration used during the V&V of the PLC. Comparison of HIL simulation results to benchmark simulations shows good operational performance of the PLC following a postulated initiating event (PIE).","Computational modeling,
Data acquisition,
Safety,
Control systems,
Hardware,
Ethernet networks,
Software"
"Design and Free-Space Measurements of Broadband, Low-Loss Negative-Permeability and Negative-Index Media","We present the design and measurement of broadband, volumetric negative-permeability and negative-refractive-index (NRI) media. Both of these media are fabricated using standard printed-circuit-board techniques and operate at X-band frequencies. The S-parameters of four-cell slabs of the negative-permeability and NRI media are measured, and the material parameters of the NRI lens are extracted. The four-cell-thick (λ0/3) NRI lens exhibits a backward-wave bandwidth of 41.2% and a total loss of 0.67 dB at the operating frequency (where μr ≈ -1). Super-resolved focusing in free space is also demonstrated, and spatial frequencies beyond the free-space wavenumber are recovered over a bandwidth of 7.4%. A focus with a half-power beamwidth of 0.27λ0 is achieved at 10.435 GHz.","Bandwidth,
Slabs,
Permeability,
Wires,
Lenses,
Permittivity,
Resonant frequency"
Crowdsourcing human-robot interaction: Application from virtual to physical worlds,"The ability for robots to engage in interactive behavior with a broad range of people is critical for future development of social robotic applications. In this paper, we propose the use of online games as a means of generating large-scale data corpora for human-robot interaction research in order to create robust and diverse interaction models. We describe a data collection approach based on a multiplayer game that was used to collect movement, action and dialog data from hundreds of online users. We then study how these records of human-human interaction collected in a virtual world can be used to generate contextually correct social and task-oriented behaviors for a robot collaborating with a human in a similar real-world environment. We evaluate the resulting behavior model using a physical robot in the Boston Museum of Science, and show that the robot successfully performs the collaborative task and that its behavior is strongly influenced by patterns in the crowdsourced dataset.","Games,
Humans,
Robot sensing systems,
Collaboration,
Cognition,
Libraries"
Generalized Likelihood Ratios for Testing the Properness of Quaternion Gaussian Vectors,"In a recent paper, the second-order statistical analysis of quaternion random vectors has shown that there exist two different kinds of quaternion widely linear processing, which are associated with the two main types of quaternion properness. In this paper, we consider the problem of determining, from a finite number of independent vector observations, whether a quaternion Gaussian vector is proper or not. Specifically, we derive three generalized likelihood ratio tests (GLRTs) for testing the two main kinds of quaternion properness and show that the GLRTs reduce to the estimation of three previously proposed quaternion improperness measures. Interestingly, the three GLRT statistics (improperness measures) can be interpreted as an estimate of the entropy loss due to the quaternion improperness. Additionally, we analyze the case in which the orthogonal basis for the representation of the quaternion vector is unknown, which results in the problem of estimating the principal \BBC-properness direction, i.e., the pure unit quaternion minimizing the \BBC -improperness measure. Although this estimation problem is not convex, we propose a technique based on successive convex approximations, which can be solved in closed form. Finally, some simulation examples illustrate the performance and practical application of the proposed tests.",
BiTA/SWCE: Image Enhancement With Bilateral Tone Adjustment and Saliency Weighted Contrast Enhancement,"Researchers have proposed various image enhancement methods to make images better correlate to the human visual system. This letter proposed an innovative image enhancement framework that combines bilateral tone adjustment (BiTA) and saliency-weighted contrast enhancement (SWCE) methods. Unlike most curve-based global contrast enhancement methods, BiTA enhances the mid-tone regions that normally contain important scenes, in addition to the bright and dark regions. For local contrast enhancement, SWCE integrates the concept of image saliency into a simple filter-based contrast enhancement method. Regions with higher saliency values, which indicate that the regions have a higher extent of human interest, deserve a greater degree of enhancement. In addition, this letter presents the ratio of saliency-weighted relative entropy to noise to evaluate the enhancement quality. Simulation results show that the proposed schemes achieve high contrast enhancement with little noise and great image quality.","Pixel,
Entropy,
Humans,
Noise,
Image enhancement,
Histograms,
Image color analysis"
The feasibility of using thermal strain imaging to regulate energy delivery during intracardiac radio-frequency ablation,"A method is introduced to monitor cardiac ablative therapy by examining slope changes in the thermal strain curve caused by speed of sound variations with temperature. The sound speed of water-bearing tissue such as cardiac muscle increases with temperature. However, at temperatures above about 50°C, there is no further increase in the sound speed and the temperature coefficient may become slightly negative. For ablation therapy, an irreversible injury to tissue and a complete heart block occurs in the range of 48 to 50°C for a short period in accordance with the well-known Arrhenius equation. Using these two properties, we propose a potential tool to detect the moment when tissue damage occurs by using the reduced slope in the thermal strain curve as a function of heating time. We have illustrated the feasibility of this method initially using porcine myocardium in vitro. The method was further demonstrated in vivo, using a specially equipped ablation tip and an 11-MHz microlinear intracardiac echocardiography (ICE) array mounted on the tip of a catheter. The thermal strain curves showed a plateau, strongly suggesting that the temperature reached at least 50°C.","Strain,
Temperature measurement,
Heating,
Temperature sensors,
Catheters,
Ultrasonic imaging,
Arrays"
On the Randomness of Independent Experiments,"Smooth entropies characterize basic information-theoretic properties of random variables, such as the number of bits required to store them or the amount of uniform randomness that can be extracted from them (possibly with respect to side information). In this paper, explicit and almost tight bounds on the smooth entropies of n-fold product distributions, Pn, are derived. These bounds are expressed in terms of the Shannon entropy of a single distribution, P . The results can be seen as an extension of the asymptotic equipartition property (AEP).","Entropy,
Random variables,
Data mining,
Data compression,
Markov processes,
Probability distribution,
Encoding"
The 100-kJ Modular Pulsed Power Units for Railgun,"A 3.2-MJ pulsed power supply system for railgun has been built. The power supply system consists of 32 pulse forming units (PFUs) of 100 kJ each. Each PUF can be triggered and controlled independently by the center computer by fiber optic transmitters. The maximum total current of the 3.2-MJ supply system reaches 500 kA. The new PFU is smaller than the former one. The PFU is composed of two capacitors, a set of semiconducting switches (thyristor and crowbar diode), an inductor, a safety device, a local controller and data acquisition circuit, a current coil, and coaxial cables. The modular PFU is designed for a maximum charging voltage of 10 kV and the peak current up to 50 kA/module. In order to reduce the influence of the electromagnetic interference and the electromagnetic force and to provide the high flexibility reliability, the arrangement of components and the configuration of the pulsed power module have been improved. A local data acquisition circuit in each PFU can record and save the discharging current and the voltage of the capacitor itself and upload test data to the computer by fiber optics. This paper describes the stack configuration, the test facility, and the prototype arrangement of 32 modular pulsed power units.","Thyristors,
Capacitors,
Power supplies,
Railguns,
Inductors,
Computers,
Optical switches"
A dynamic scheduling framework for emerging heterogeneous systems,"A trend that has materialized, and has given rise to much attention, is of the increasingly heterogeneous computing platforms. Recently, it has become very common for a desktop or a notebook computer to be equipped with both a multi-core CPU and a GPU. Application development for exploiting the aggregate computing power of such an environment is a major challenge today. Particularly, we need dynamic work distribution schemes that are adaptable to different computation and communication patterns in applications, and to various heterogeneous configurations. This paper describes a general dynamic scheduling framework for mapping applications with different communication patterns to heterogeneous architectures. We first make key observations about the architectural tradeoffs among heterogeneous resources and the communication pattern of an application, and then infer constraints for the dynamic scheduler. We then present a novel cost model for choosing the optimal chunk size in a heterogeneous configuration. Finally, based on general framework and cost model we provide optimized work distribution schemes to further improve the performance.","Graphics processing unit,
Central Processing Unit,
Instruction sets,
Dynamic scheduling,
Kernel,
Mathematical model,
Computer architecture"
Phase Symmetry Approach Applied to Children Heart Chambers Segmentation: A Comparative Study,"Segmentation of echocardiographic images presents a great challenge because these images contain strong speckle noise and artifacts. Besides, most ultrasound segmentation methods are semiautomatic, requiring initial contour to be manually identified in the images. In this paper, we propose an algorithm based on the phase symmetry approach and level set evolution, in order to extract simultaneously all heart cavities in a fully automatic way. The level set evolution uses a new logarithmic-based stopping function, which demonstrates to perform well in the boundary extraction. We compared our method with other level set approaches, the watershed technique, and the manual segmentation made by two physicians. The experimental work was based on echocardiography images of children. Similarity metrics, namely Pratt function, pixel mean error, and similarity angle have been used for the performance evaluation of the different methods. The results indicate that our method has a performance of at least 4% superior to the other methods able to segment the four chambers. Even for the two worst boundary extraction cases (right ventricle and left atrium), the performance of the proposed method is still better than the other techniques.","Image segmentation,
Level set,
Image edge detection,
Pixel,
Measurement,
Medical services,
Cavity resonators"
A Variable Bandwidth Filter for Estimation of Instantaneous Frequency and Reconstruction of Signals With Time-Varying Spectral Content,"The notion of “instantaneous frequency” is utilized in processing signals with time-varying spectral content. Specifically, a variable bandwidth filter (VBF) and some related spectral analysis tools are proposed to handle a multicomponent signal whose components interact with each other in the time-frequency (TF) domain. In the analysis, a multicomponent signal is decomposed into its components by estimating local instantaneous frequencies (IFs). In order to construct the proposed filter, we define a differential operator composed of the derivative operator and a positive time-varying coefficient. An extended Fourier transform (EFT) and its functional relations are derived to exploit the newly defined differential operator and the VBF in some weighted vector spaces. Further, a heterogeneous TF distribution is constructed by a short-time EFT to utilize as a criterion for identifying whether an estimated IF is intrinsic or not and repairing a suspect estimate of IF. To confirm usefulness of the EFT and the VBF, we conduct several numerical simulations for spectral localization of an AM-FM signal and for estimation of local IFs, and then, for decomposition of a multicomponent signal into its components with their resolving powers to be compared.","Time frequency analysis,
Convolution,
Bandwidth,
Fourier transforms,
Kernel,
Wiener filter"
A Distributed Sensor Selection Mechanism for Cooperative Spectrum Sensing,"In a cognitive sensor network (CSN), selfish sensors can choose to conduct cooperative spectrum sensing (CSS) or local spectrum sensing (LSS). CSS usually improves sensing performance at the price of delay and energy consumption. A selfish sensor only decides to conduct CSS if it is more profitable than performing LSS. A key issue is how to achieve a desired decision outcome that maximizes spectrum utilization under the requirement of self-interest maximization and primary user (PU) protection. To address this problem, we formulate the interactive deciding of sensors as a noncooperative game, and Nash equilibrium (NE) corresponds to a stable decision outcome that no sensor has an incentive to resist unilaterally. It is shown that the desired decision outcome can be obtained by solving a constrained nonlinear 0-1 programming problem. We derive the desired decision outcome for homogenous sensors, and then develop a sensor selection mechanism for heterogeneous sensors to achieve the desired decision outcome in a distributed fashion. The proposed mechanism is shown to have a relatively low complexity. Computer simulations are carried out to validate the effectiveness of the proposed approaches.","Sensors,
Delay,
Nash equilibrium,
Game theory,
Energy consumption"
A Supervised Framework for Keyword Extraction From Meeting Transcripts,"This paper presents a supervised framework for extracting keywords from meeting transcripts, a genre that is significantly different from written text or other speech domains such as broadcast news. In addition to the traditional frequency- or position-based clues, we investigate a variety of novel features, including linguistically motivated term specificity features, decision-making sentence-related features, prosodic prominence scores, as well as a group of features derived from summary sentences. To generate better system summaries, we propose a feedback loop mechanism under a supervised framework to leverage the relationship between keywords and summary sentences. Experiments are performed on the ICSI meeting corpus using both human transcripts and automatic speech recognition (ASR) outputs. Results have shown that our proposed supervised framework is able to outperform both unsupervised term frequency inverse document frequency (TF-IDF) weighting and a supervised keyphrase extraction system which is known for its satisfying performance on written text. We conduct extensive analysis to demonstrate the effectiveness of the newly proposed features and the feedback mechanism used to generate summaries. Furthermore, we show promising results using n-best recognition output to address the problems of recognition errors.","Frequency,
Automatic speech recognition,
Natural languages,
USA Councils,
Feedback loop,
Humans,
Supervised learning,
Voice mail,
Digital audio broadcasting,
Data mining"
Spreading Code Design of Adaptive Non-Contiguous SOFDM for Dynamic Spectrum Access,"In a dynamic spectrum access (DSA) network, multi-carrier-based cognitive radio transceivers need to deactivate some of their subcarriers to avoid interference to primary users. In a mobile environment, the spread orthogonal frequency-division multiplexing (SOFDM) system has demonstrated excellent performance in multipath fading channels, outperforming the traditional OFDM system due to the diversity gain. The traditional SOFDM uses Hadamard-Walsh code as the spreading code set, in which case, when deactivating subcarriers, orthogonality among different spreading codes will be lost, leading to poor bit error ratio (BER) performance. The performance of the SOFDM system can be improved by using adaptive spreading code adjustment to compensate for the loss of orthogonality. Because Hadamard-Walsh codes only exist for certain code length, in many cases, the SOFDM system based on Hadamard-Walsh code set needs to deactivate more subcarriers. Otherwise, loss of orthogonality cannot be eliminated. Instead, it can only be minimized. Moreover, deactivating more subcarriers will force the system to reduce the data rate. By treating the system as subsystems, we can generate binary orthogonal code set based on Hadamard-Walsh code to maintain the data rate. On the other hand, if the spreading code is not limited to be binary, orthogonal carrier interferometry (CI) codes exist for code length of any integer. Hence, by applying non-contiguous SOFDM (NC-SOFDM) with CI code to DSA, the loss of orthogonality among spreading codes caused by deactivating subcarriers can be eliminated. In this paper, we propose two novel spread coding schemes for NC-SOFDM for cognitive radio in a DSA network. The new spreading code sets help the system to maintain the same data rate as that of the traditional OFDM and improve the performance by exploiting the diversity gain and eliminating the orthogonality loss. The NC-SOFDM with the proposed spreading code outperforms the traditional NC-OFDM and the adaptive NC-SOFDM with Hadamard-Walsh code.","Error correction,
Error correction codes,
Cognitive radio,
OFDM,
Diversity methods,
Performance loss,
Transceivers,
Interference,
Frequency division multiplexing,
Fading"
3D Pose tracking of walker users' lower limb with a structured-light camera on a moving platform,"Tracking and understanding human gait is an important step towards improving elderly mobility and safety. Our research team is developing a vision-based tracking system that estimates the 3D pose of a wheeled walker user's lower limbs with a depth sensor, Kinect, mounted on the moving walker. Our tracker estimates 3D poses from depth images of the lower limbs in the coronal plane in a dynamic, uncontrolled environment. We employ a probabilistic approach based on particle filtering, with a measurement model that works directly in the 3D space and another measurement model that works in the projected image space. Empirical results show that combining both measurements, assuming independence between them, yields tracking results that are better than with either one alone. Experiments are conducted to evaluate the performance of the tracking system with different users. We demonstrate that the tracker is robust against unfavorable conditions such as partial occlusion, missing observations, and deformable tracking target. Also, our tracker does not require user intervention or manual initialization commonly required in most trackers.","Cameras,
Three dimensional displays,
Hidden Markov models,
Leg,
Solid modeling,
Target tracking"
EQS: An Elastic and Scalable Message Queue for the Cloud,"With the emergence of cloud computing, on-demand resources usage is made possible. This allows applications to elastically scale out according to the load. One design pattern that suits this paradigm is the event-driven architecture (EDA) in which messages are sent asynchronously between distributed application instances using message queues. However, existing message queues are only able to scale for a certain number of clients and are not able to scale out elastically. We present the Elastic Queue Service (EQS), an elastic message queue architecture and a scaling algorithm which can be adapted to any message queue in order to make it scale elastically. EQS architecture is layered onto multiple distributed components and its management components can be integrated with the cloud infrastructure management. We have implemented a prototype of EQS and deployed it on a cloud infrastructure. A series of load testings have validated our elastic scaling algorithm and show that EQS is able to scale out in order to adapt to an applied load. We then discuss about the elastic scaling of the management layers of EQS and their possible integration with the cloud infrastructure management.",
Computational intelligence and tower defence games,"The aim of this paper is to introduce the use of Tower Defence (TD) games in Computational Intelligence (CI) research. We show how TD games can provide an important test-bed for the often under-represented casual games research area. Additionally, the use of CI in the TD games has the potential to create a more interesting, interactive and ongoing game experience for casual gamers. We present a definition of the current state and development of TD games, and include a classification of TD game components. We then describe some potential ways CI can be used to augment the TD experience. Finally, a prototype TD game based on experience driven procedural content generation is presented.","Games,
Poles and towers,
Creep,
Resource management,
Real time systems,
Humans,
Computational intelligence"
Interacting maps for fast visual interpretation,"Biological systems process visual input using a distributed representation, with different areas encoding different aspects of the visual interpretation. While current engineering habits tempt us to think of this processing in terms of a pipelined sequence of filters and other feed-forward processing stages, cortical anatomy suggests quite a different architecture, using strong recurrent connectivity between visual areas. Here we design a network to interpret input from a neuromorphic sensor by means of recurrently interconnected areas, each of which encodes a different aspect of the visual interpretation, such as light intensity or optic flow. As each area of the network tries to be consistent with the information in neighboring areas, the visual interpretation converges towards global mutual consistency. Rather than applying input in a traditional feed-forward manner, the sensory input is only used to weakly influence the information flowing both ways through the middle of the network. Even with this seemingly weak use of input, this network of interacting maps is able to maintain its interpretation of the visual scene in real time, proving the viability of this interacting map approach to computation.",
Capacity of Gaussian channels with duty cycle and power constraints,"In many wireless communication systems, radios are subject to duty cycle constraint, that is, a radio only actively transmits signals over a fraction of the time. For example, it is desirable to have a small duty cycle in some low power systems; a half-duplex radio cannot keep transmitting if it wishes to receive useful signals; and a cognitive radio needs to listen and detect primary users frequently. This work studies the capacity of scalar discrete-time Gaussian channels subject to duty cycle constraint as well as average transmit power constraint. The duty cycle constraint can be regarded as a requirement on the minimum fraction of nontransmission or zero symbols in each codeword. A unique discrete input distribution is shown to achieve the channel capacity. In many situations, numerical results demonstrate that using the optimal input can improve the capacity by a large margin compared to using Gaussian signaling over a deterministic transmission schedule, which is capacity-achieving in the absence of the duty cycle constraint. This is in part because the positions of the nontransmission symbol in a codeword can convey information. The results suggest that, under the duty cycle constraint, departing from the usual paradigm of intermittent packet transmissions may yield substantial gain.",
Semantics of Ranking Queries for Probabilistic Data,"Recently, there have been several attempts to propose definitions and algorithms for ranking queries on probabilistic data. However, these lack many intuitive properties of a top-k over deterministic data. We define several fundamental properties, including exact-k, containment, unique rank, value invariance, and stability, which are satisfied by ranking queries on certain data. We argue that these properties should also be carefully studied in defining ranking queries in probabilistic data, and fulfilled by definition for ranking uncertain data for most applications. We propose an intuitive new ranking definition based on the observation that the ranks of a tuple across all possible worlds represent a well-founded rank distribution. We studied the ranking definitions based on the expectation, the median, and other statistics of this rank distribution for a tuple and derived the expected rank, median rank, and quantile rank correspondingly. We are able to prove that the expected rank, median rank, and quantile rank satisfy all these properties for a ranking query. We provide efficient solutions to compute such rankings across the major models of uncertain data, such as attribute-level and tuple-level uncertainty. Finally, a comprehensive experimental study confirms the effectiveness of our approach.",
Output consensus for networks of non-identical introspective agents,"In this paper, we consider three problems, namely, the output consensus problem, the model-reference output consensus problem, and the regulation of output consensus problem, for a network of non-identical right-invertible linear agents. The network provides each agent with a linear combination of multiple agents' outputs. We assume that all the agents are introspective, meaning that they have access to their own local measurements. Under this assumption, we then propose a distributed linear protocol to solve each problem for a broad class of network topologies, including not only Laplacian topologies for a directed graph which contains a directed spanning tree, but a wide family of asymmetric topologies.","Protocols,
Network topology,
Eigenvalues and eigenfunctions,
Trajectory,
Synchronization,
Linear systems,
Topology"
A comparative study of congestion control algorithms in IPv6 Wireless Sensor Networks,"In Wireless Sensor Networks (WSNs), congestion can cause a plethora of malfunctions such as packet loss, lower throughput and energy inefficiency, potentially resulting in reduced deployment lifetime and under-performing applications. This has led to several proposals describing congestion control (CC) mechanisms for sensor networks. Furthermore, the WSN research community has made significant efforts towards power saving MAC protocols with Radio Duty Cycling (RDC). However, careful study of previous work reveals that RDC schemes are often neglected during the design and evaluation of congestion control algorithms. In this paper, we argue that the presence (or lack) of RDC can drastically influence the performance of congestion detection. In addition, most WSN CC mechanisms are evaluated under traditional sensor network topologies and protocols (e.g. trickle data dissemination, tree data collection). The emerging IPv6 over Low power Wireless Personal Area Networks (6LoWPAN) and related standards pose a new requirement: we now need to investigate if previous findings regarding congestion control are still applicable. In this context, this paper contributes a comprehensive evaluation of existing congestion detection mechanisms in a simulated, multi-node 6LoWPAN sensor network. We present results from two sets of experiments, differentiated by the presence or lack of RDC.",
Twins 3D face recognition challenge,"Existing 3D face recognition algorithms have achieved high enough performances against public datasets like FRGC v2, that it is difficult to achieve further significant increases in recognition performance. However, the 3D TEC dataset is a more challenging dataset which consists of 3D scans of 107 pairs of twins that were acquired in a single session, with each subject having a scan of a neutral expression and a smiling expression. The combination of factors related to the facial similarity of identical twins and the variation in facial expression makes this a challenging dataset. We conduct experiments using state of the art face recognition algorithms and present the results. Our results indicate that 3D face recognition of identical twins in the presence of varying facial expressions is far from a solved problem, but that good performance is possible.","Probes,
Face"
"Turn-Around-Point Long-Period Fiber Gratings Fabricated by CO
2
Laser Point-by-Point Irradiations","High order mode long-period fiber gratings (LPFGs) were fabricated for the first time, to our knowledge, by point-by-point CO2 laser irradiations. With this method, turn-around-point LPFGs working in various circumstances can be easily fabricated by adjusting the inscription period. Effects of fabrication parameters on the characteristics of the resulted LPFGs have been studied. Tenth-order LPFGs have been fabricated and demonstrated for temperature sensing.","Optical fiber sensors,
Optical fiber dispersion,
Fiber lasers,
Optical fibers,
Temperature sensors,
Fiber gratings,
Laser modes"
Low-Complexity Multiple-Component Turbo-Decoding-Aided Hybrid ARQ,"Previous research has focused on improving the throughput of hybrid automatic repeat request (HARQ) schemes. However, since turbo codes have been introduced into HARQ schemes, their complexity has increased owing to the iterative Bahl-Cocke-Jelinek-Raviv (BCJR) operations that are required following each retransmission. This paper explores the complexity of turbo HARQ schemes and proposes a new early stopping (ES) approach for iterative decoding based on mutual information (MI), which dynamically determines the appropriate number of BCJR operations to be performed following each incremental redundancy (IR) transmission. We demonstrate that the proposed ES-based multiple-component turbo code (MCTC)-aided and systematic twin-component turbo code (TCTC)-assisted HARQ schemes exhibit 60%-85% reduced complexity for signal-to-noise ratios (SNRs) below -2 dB without degrading the packet-loss ratio (PLR) and the throughput.","Throughput,
Complexity theory,
Decoding,
Iterative decoding,
Polynomials,
Convergence,
Turbo codes"
Design of a Wireless Sensor Network Based Monitoring System for Home Automation,"This paper presents the design and implementation of a wireless monitoring system for building smart room architectures in home environments. The proposed system consists of wireless sensor nodes and actuator nodes which are organized into a monitoring network by ZigBee protocols. A base station and some general wireless nodes have been developed to form a prototype system. Various sensor and actuator modules have also been implemented to enable some typical indoor monitoring applications such as resident tracking, energy-efficient home appliance control and home security. The proposed system provides a flexible solution for us to make our living spaces more intelligent.","Wireless sensor networks,
Robot sensing systems,
Wireless communication,
Monitoring,
Base stations,
Communication system security,
Actuators"
Implementation of the 7-point checklist for melanoma detection on smart handheld devices,"In this paper we implement the 7-point checklist, a set of dermoscopic criteria widely used by clinicians for melanoma detection, on smart handheld devices, such as the Apple iPhone and iPad. The application developed is using sophisticated image processing and pattern recognition algorithms, yet it is light enough to run on a handheld device with limited memory and computational speed. When combined with a commercially available handheld dermoscope that provides proper lesion illumination, this application provides a truly self-contained handheld system for melanoma detection. Such a device can be used in a clinical setting for routine skin screening, or as an assistive diagnostic device in underserved areas and in developing countries with limited healthcare infrastructure.","Malignant tumors,
Image color analysis,
Feature extraction,
Lesions,
Histograms,
Skin,
Handheld computers"
Structured Max-Margin Learning for Inter-Related Classifier Training and Multilabel Image Annotation,"In this paper, a structured max-margin learning algorithm is developed to achieve more effective training of a large number of inter-related classifiers for multilabel image annotation application. To leverage multilabel images for classifier training, each multilabel image is partitioned into a set of image instances (image regions or image patches) and an automatic instance label identification algorithm is developed to assign multiple labels (which are given at the image level) to the most relevant image instances. A K-way min-max cut algorithm is developed for automatic instance clustering and kernel weight determination, where multiple base kernels are seamlessly combined to address the issue of huge intra-concept visual diversity more effectively. Second, a visual concept network is constructed for characterizing the inter-concept visual similarity contexts more precisely in the high-dimensional multimodal feature space. The visual concept network is used to determine the inter-related learning tasks directly in the feature space rather than in the label space because feature space is the common space for classifier training and image classification. Third, a parallel computing platform is developed to achieve more effective learning of a large number of inter-related classifiers over the visual concept network. A structured max-margin learning algorithm is developed by incorporating the visual concept network, max-margin Markov networks and multitask learning to address the issue of huge inter-concept visual similarity more effectively. By leveraging the inter-concept visual similarity contexts for inter-related classifier training, our structured max-margin learning algorithm can significantly enhance the discrimination power of the inter-related classifiers. Our experiments have also obtained very positive results for a large number of object classes and image concepts.",
Cyberphysical Systems: Workload Modeling and Design Optimization,"Built to interact with the physical world, a cyberphysical system (CPS) must be efficient, reliable, and safe. To optimize such systems, a science of CPS design considering workload characteristics (e.g., self-similarity and nonstationarity) must be established. CPS modeling and design are greatly improved when statistical physics approaches - such as master equations, renormalization group theory, and fractional derivatives - are implemented in the optimization loop.","Fractals,
Mathematical model,
Equations,
Stochastic processes,
Computational modeling,
Cyberspace,
Workflow management software"
Car-Rec: A real time car recognition system,"Recent advances in computer vision have significantly reduced the difficulty of object classification and recognition. Robust feature detector and descriptor algorithms are particularly useful, forming the basis for many recognition and classification applications. These algorithms have been used in divergent bag-of-words and structural matching approaches. This work demonstrates a recognition application, based upon the SURF feature descriptor algorithm, which fuses bag-of-words and structural verification techniques. The resulting system is applied to the domain of car recognition and achieves accurate (>; 90%) and real-time performance when searching databases containing thousands of images.",
Focus-Tunable Microlens Arrays Fabricated on Spherical Surfaces,"We present microlens arrays consisting of multiple focus-tunable microlenses omnidirectionally fabricated on spherical surfaces, to realize large field of view. Thin flexible polymer bridges connecting adjacent microlenses are designed to reduce the wrapping stress and deformation of the microlens array. Each microlens, formed via water-oil interface, is individually tuned by a thermo-responsive hydrogel actuator. The range of the focal length of each microlens in this array varied from millimeters to infinity. A prototype of optical imaging system based on such a microlens array on a spherical surface, including a charged-coupled device camera, a fiber bundle, and a 3-D rotational stage, is demonstrated as well.","Lenses,
Microoptics,
Polymers,
Bridges,
Stress,
Apertures,
Fabrication"
Design of a Data-Driven Predictive Controller for Start-up Process of AMT Vehicles,"In this paper, a data-driven predictive controller is designed for the start-up process of vehicles with automated manual transmissions (AMTs). It is obtained directly from the input-output data of a driveline simulation model constructed by the commercial software AMESim. In order to obtain offset-free control for the reference input, the predictor equation is gained with incremental inputs and outputs. Because of the physical characteristics, the input and output constraints are considered explicitly in the problem formulation. The contradictory requirements of less friction losses and less driveline shock are included in the objective function. The designed controller is tested under nominal conditions and changed conditions. The simulation results show that, during the start-up process, the AMT clutch with the proposed controller works very well, and the process meets the control objectives: fast clutch lockup time, small friction losses, and the preservation of driver comfort, i.e., smooth acceleration of the vehicle. At the same time, the closed-loop system has the ability to reject uncertainties, such as the vehicle mass and road grade.","Vehicle dynamics,
Automotive engineering,
Friction,
Process control,
Predictive control"
Beyond connectivity - new metrics to evaluate robustness of networks,"Robustness or fault-tolerance capability of a network is an important design parameter in both wired and wireless networks. Connectivity of a network is traditionally considered to be the primary metric for evaluation of its fault-tolerance capability. However, connectivity κ(G) (for random faults) or region-based connectivity κR(G) (for spatially correlated or region-based faults, where the faults are confined to a region R) of a network G, does not provide any information about the network state, (i.e., whether the network is connected or not) once the number of faults exceeds κ(G) or κR(G). If the number of faults exceeds κ(G) or κR(G), one would like to know, (i) the number of connected components into which G decomposes, (ii) the size of the largest connected component, (iii) the size of the smallest connected component. In this paper, we introduce a set of new metrics that computes these values. We focus on one particular metric called region-based component decomposition number (RBCDN), that measures the number of connected components in which the network decomposes once all the nodes of a region fail. We study the computational complexity of finding RBCDN of a network. In addition, we study the problem of least cost design of a network with a target value of RBCDN. We show that the optimal design problem is NP-complete and present an approximation algorithm with a performance bound of O(log K + 4log n), where n denotes the number of nodes in the graph and K denotes a target value of RBCDN. We evaluate the performance of our algorithm by comparing it with the performance of the optimal solution. Experimental results demonstrate that our algorithm produces near optimal solution in a fraction of time needed to find an optimal solution.",
Are fuzzy description logics with general concept inclusion axioms decidable?,"This paper concentrates on a fuzzy Description Logic with product t-norm and involutive negation. It does not answer the question posed in its title for this logic, but it gives strong indications that the answer might in fact be ""no."" On the one hand, it shows that an algorithm that was claimed to answer the question affirmatively for this logic is actually incorrect. On the other hand, it proves undecidability of a variant of this logic.","Ontologies,
Semantics,
Cost accounting,
Cognition,
Syntactics,
Complexity theory"
Precoding by Pairing Subchannels to Increase MIMO Capacity With Discrete Input Alphabets,"We consider Gaussian multiple-input multiple-output (MIMO) channels with discrete input alphabets. We propose a non diagonal precoder based on the X-Codes in to increase the mutual information. The MIMO channel is transformed into a set of parallel subchannels using singular value decomposition (SVD) and X-Codes are then used to pair the subchannels. X-Codes are fully characterized by the pairings and a 2 × 2 real rotation matrix for each pair (parameterized with a single angle). This precoding structure enables us to express the total mutual information as a sum of the mutual information of all the pairs. The problem of finding the optimal precoder with the above structure, which maximizes the total mutual information, is solved by: i) optimizing the rotation angle and the power allocation within each pair and ii) finding the optimal pairing and power allocation among the pairs. It is shown that the mutual information achieved with the proposed pairing scheme is very close to that achieved with the optimal pre coder by Cruz et al., and is significantly better than Mercury/waterfllling strategy by Lozano et al. Our approach greatly simplifies both the precoder optimization and the detection complexity, making it suitable for practical applications.",
Predicting Pedestrian Counts in Crowded Scenes With Rich and High-Dimensional Features,"Estimating the number of pedestrians in surveillance images and videos has important applications in intelligent transportation systems. This problem is particularly challenging when the scenes are densely crowded, in which the techniques of tracking a single pedestrian has limited effectiveness. Alternative approaches employ statistical learning algorithms to infer pedestrian counts directly from visual features computed on images or scenes. In this paper, we describe a system for predicting pedestrian counts that significantly extends the utility of those ideas. Our approach incorporates a richer set of features for statistical modeling. While these features give rise to regression problems in a high-dimensional space, we leverage learning techniques to reduce dimensionality while still attaining high accuracy for predicting the number of pedestrians. Empirical results have validated our strategy. Specifically, our system outperforms state-of-the-art methods on standard benchmark tasks by a large margin.",
Bias Field Inconsistency Correction of Motion-Scattered Multislice MRI for Improved 3D Image Reconstruction,"A common solution to clinical MR imaging in the presence of large anatomical motion is to use fast multislice 2D studies to reduce slice acquisition time and provide clinically usable slice data. Recently, techniques have been developed which retrospectively correct large scale 3D motion between individual slices allowing the formation of a geometrically correct 3D volume from the multiple slice stacks. One challenge, however, in the final reconstruction process is the possibility of varying intensity bias in the slice data, typically due to the motion of the anatomy relative to imaging coils. As a result, slices which cover the same region of anatomy at different times may exhibit different sensitivity. This bias field inconsistency can induce artifacts in the final 3D reconstruction that can impact both clinical interpretation of key tissue boundaries and the automated analysis of the data. Here we describe a framework to estimate and correct the bias field inconsistency in each slice collectively across all motion corrupted image slices. Experiments using synthetic and clinical data show that the proposed method reduces intensity variability in tissues and improves the distinction between key tissue types.","Three dimensional displays,
Image reconstruction,
Imaging,
Nonhomogeneous media,
Coils,
Bismuth,
Sensitivity"
Convergence of Cyclic and Almost-Cyclic Learning With Momentum for Feedforward Neural Networks,"Two backpropagation algorithms with momentum for feedforward neural networks with a single hidden layer are considered. It is assumed that the training samples are supplied to the network in a cyclic or an almost-cyclic fashion in the learning procedure, i.e., in each training cycle, each sample of the training set is supplied in a fixed or a stochastic order respectively to the network exactly once. A restart strategy for the momentum is adopted such that the momentum coefficient is set to zero at the beginning of each training cycle. Corresponding weak and strong convergence results are then proved, indicating that the gradient of the error function goes to zero and the weight sequence goes to a fixed point, respectively. The convergence conditions on the learning rate, the momentum coefficient, and the activation functions are much relaxed compared with those of the existing results.",
A Cross-Layer Scheme for Solving Hidden Device Problem in IEEE 802.15.4 Wireless Sensor Networks,"The IEEE 802.15.4 standard is designed to achieve low-power transmissions in low-rate and short-distance wireless personal area networks (WPANs). For the sake of reducing the control overheads, the modified CSMA/CA protocol used by 802.15.4 does not have the hidden device protection mechanism, such as RTS/CTS mechanism. Previous studies indicated that the probability of any two devices in an infrastructure network unheard of each other is around 41%. Therefore, the hidden device problem (HDP) results in inefficient data transmission and serious power consumption issues in WPAN. In this paper, we propose a cross-layer detection and allocation (CL-DNA) scheme to solve the HDP in IEEE 802.15.4 without the cost of extra control overhead in data transmissions. The proposed scheme detects relationships of hidden devices based on the overlapped signals and then allocates the hidden devices into distinct subperiods for transmissions. Simulation results validated by mathematical analysis show that the proposed scheme significantly improves the goodput with the reduction in power consumption.","Sensors,
Wireless sensor networks,
Network topology,
Power demand,
Topology,
Interference,
Data communication"
Unmixing Dynamic Fluorescence Diffuse Optical Tomography Images With Independent Component Analysis,"Dynamic fluorescence diffuse optical tomography (D-FDOT) is important for drug delivery research. However, the low spatial resolution of FDOT and the complex kinetics of drug limit the ability of D-FDOT in resolving metabolic processes of drug throughout whole body of small animals. In this paper, we propose an independent component analysis (ICA)-based method to perform D-FDOT studies. When applied to D-FDOT images, ICA not only generates a set of independent components (ICs) which can illustrate functional structures with different kinetic behaviors, but also provides a set of associated time courses (TCs) which can represent normalized time courses of drug in corresponding functional structures. Further, the drug concentration in specific functional structure at different time points can be recovered by an inverse ICA transformation. To evaluate the performance of the proposed algorithm in the study of drug kinetics at whole-body level, simulation study and phantom experiment are both performed on a full-angle FDOT imaging system with line-shaped excitation pattern. In simulation study, the nanoparticle delivery of indocynaine green (ICG) throughout whole body of a digital mouse is simulated and imaged. In phantom experiment, four tubes containing different ICG concentrations are imaged and used to imitate the uptake and excretion of ICG in organs. The results suggest that we can not only illustrate ICG distributions in different functional structures, but also recover ICG concentrations in specific functional structure at different time points, when ICA is applied to D-FDOT images.","Fluorescence,
Electron tubes,
Drugs,
Biological systems,
Image reconstruction,
Tomography"
Pulse Delay Via Tunable White Light Cavities Using Fiber-Optic Resonators,"Previously, we proposed a data buffering system that makes use of a pair of white light cavities. For application to telecommunication systems, it would be convenient to realize such a device using fiber-optic resonators. In this paper, we present the design of such a system, where the white light cavity effect is produced by using stimulated Brillouin scattering. The system consists of a pair of fiber-optic white light cavities placed in series. As in the original proposal, the delay time can be controlled independently of the bandwidth of the data pulses. Furthermore, we show how the bandwidth of the system can be made as large as several times the Brillouin frequency shift. We also show that the net delay achievable in such a buffer can be significantly larger than what can be achieved using a conventional recirculating loop buffer.",
A Training System of Orientation and Mobility for Blind People Using Acoustic Virtual Reality,"A new auditory orientation training system was developed for blind people using acoustic virtual reality (VR) based on a head-related transfer function (HRTF) simulation. The present training system can reproduce a virtual training environment for orientation and mobility (O&M) instruction, and the trainee can walk through the virtual training environment safely by listening to sounds such as vehicles, stores, ambient noise, etc., three-dimensionally through headphones. The system can reproduce not only sound sources but also sound reflection and insulation, so that the trainee can learn both sound location and obstacle perception skills. The virtual training environment is described in extensible markup language (XML), and the O&M instructor can edit it easily according to the training curriculum. Evaluation experiments were conducted to test the efficiency of some features of the system. Thirty subjects who had not acquired O&M skills attended the experiments. The subjects were separated into three groups: a no-training group, a virtual-training group using the present system, and a real-training group in real environments. The results suggested that virtual-training can reduce “veering” more than real-training and also can reduce stress as much as real training. The subjective technical and anxiety scores also improved.","Training,
Roads,
Coils,
Magnetic heads,
Acoustics,
Knee,
Stress measurement"
Coordinate Rotation Based Low Complexity N-D FastICA Algorithm and Architecture,"This paper proposes a low complexity n-dimensional (nD) FastICA algorithm and architecture by introducing the concept of coordinate rotation where n ≥ 2. The proposed algorithm can merge the two key steps of conventional FastICA-preprocessing and update and is therefore capable of reducing the hardware complexity of the conventional FastICA significantly as demonstrated in this paper. Hardware implementation can further be simplified due to the recursive nature of the proposed algorithm where the same 2D hardware module can be used as the fundamental core to implement nD architecture. Together with the algorithm formulation, its functionality is also validated and hardware complexity is analyzed and compared with the conventional nD FastICA.","Signal processing algorithms,
Computer architecture,
Complexity theory,
Hardware,
Three dimensional displays,
Estimation,
Algorithm design and analysis"
Robust Multifactor Speech Feature Extraction Based on Gabor Analysis,"The performance of speech recognition systems relies on the consistency and adaptation of the speech feature in complex conditions during the training and testing stages. Traditional systems usually perform poorly under adverse noisy conditions and are not applicable to most real world problems. In this paper, we investigate the speech feature extraction problem in a noisy environment and propose a novel approach based on Gabor filtering and tensor factorization. Recent physiological and psychoacoustic experimental results suggest that the localized spectro-temporal features are essential for auditory perception. To explore this property, we represent the speech signal by using a general higher order tensor and employ two-dimensional Gabor functions with different scales and directions to analyze the localized patches of the power spectrogram. Then the Nonnegative Tensor PCA with sparse constraints is proposed to learn the projection matrices from multiple interrelated feature subspaces. The objective of the sparse constraints is to preserve the statistical characteristic of clean speech data by finding projection matrices of speech subspaces and reduce the noise components which have distributions different from those of clean speech. A multifactor analysis method is proposed to extract robust sparse features by processing the data samples in tensor structure. The simulation results indicate that our proposed method is able to improve the speech recognition performance, especially in noisy environments, compared with the traditional speech feature extraction methods.","Tensile stress,
Speech,
Feature extraction,
Speech recognition,
Sparse matrices,
Optimization,
Principal component analysis"
On the ergodic secrecy capacity of the wiretap channel under imperfect main channel estimation,"The ergodic secrecy capacity of the wiretap channel is known when the main channel (between the transmitter and the legitimate receiver) state information (CSI) is perfect at the transmitter and the coherence period is sufficiently large to enable random coding arguments in each block. In a fast fading scenario, when the codeword length spans many coherence periods, the secrecy capacity is still not known. In this paper, we present a framework that characterizes this secrecy capacity under imperfect main channel estimation at the transmitter. Inner and outer bounds on the ergodic secrecy capacity are derived for a class of independent identically distributed (i.i.d.) fading channels. The achievable rate is a simple on-off scheme using a Gaussian input. The upper bound is obtained using an appropriate correlation scheme of the main and the eavesdropper channels. The upper and the lower bounds coincide with recently derived ones in the perfect main CSI extreme. Furthermore, the lower bound matches the upper bound in no main CSI extreme, where the secrecy capacity is equal to zero. Numerical results are provided for independent identically distributed (i.i.d.) Rayleigh fading channels.","Integrated circuits,
Channel estimation,
Signal to noise ratio,
Cryptography,
Antennas"
An Automatic Spike Detection System Based on Elimination of False Positives Using the Large-Area Context in the Scalp EEG,"Most automatic spike detection systems in the scalp electroencephalogram (EEG) focused on the characteristics of “spike.” However, the characteristics of “false positives” (FPs) have not been fully studied. In this paper, we proposed a system that contains a series of algorithms to eliminate FPs and a template method to confirm spikes. The system used large area context available on 49 channels from two common montages. The impact of slow-waves after spikes was taken into consideration, as well as the information from single channel, multichannel, and whole recording. Two types of FPs were identified in this paper. The ones from typical artifacts were identified by analysis of background EEG activities, and the ones from other EEG activities were declared by spatial and temporal characteristics of spike activities. Finally, a multichannel template method was used to assess the performance of the proposed system. The system was evaluated using 17 routine EEG recordings. Spike activities were observed in six of them. Effective multichannel templates were extracted from four recordings containing frequent spikes. The least selectivity was 92.6% and the most false positive rate was 0.26 min-1. Proposed algorithms for elimination of FPs are also suitable for other algorithms to enhance performance since most FPs can be identified while few true spikes are eliminated.","Electrodes,
Electroencephalography,
Correlation,
Transient analysis,
Electromyography,
Scalp,
Inspection"
FIRM: Feedback controller-based information-state roadmap - A framework for motion planning under uncertainty,"Direct transformation of sampling-based motion planning methods to the Information-state (belief) space is a challenge. The main bottleneck for roadmap-based techniques in belief space is that the incurred costs on different edges of the graph are not independent of each other. In this paper, we generalize the Probabilistic RoadMap (PRM) framework to obtain a Feedback controller-based Information-state RoadMap (FIRM) that takes into account motion and sensing uncertainty in planning. The FIRM nodes and edges lie in belief space and the crucial feature of FIRM is that the costs associated with different edges of FIRM are independent of each other. Therefore, this construct essentially breaks the “curse of history” in the original Partially Observable Markov Decision Process (POMDP), which models the planning problem. Further, we show how obstacles can be rigorously incorporated into planning on FIRM. All these properties stem from utilizing feedback controllers in the construction of FIRM.","Bismuth,
Planning,
Aerospace electronics,
Markov processes,
History,
Adaptive control,
Uncertainty"
On MMSE and MAP Denoising Under Sparse Representation Modeling Over a Unitary Dictionary,"Among the many ways to model signals, a recent approach that draws considerable attention is sparse representation modeling. In this model, the signal is assumed to be generated as a random linear combination of a few atoms from a prespecified dictionary. In this work, two Bayesian denoising algorithms are analyzed for this model-the maximum a posteriori probability (MAP) and the minimum-mean-squared-error (MMSE) estimators, both under the assumption that the dictionary is unitary. It is well known that both these estimators lead to a scalar shrinkage on the transformed coefficients, albeit with a different response curve. We derive explicit expressions for the estimation-error for these two estimators. Upper bounds on these errors are developed and tied to the expected error of the so-called oracle estimator, for which the support is assumed to be known. This analysis establishes a worst-case gain-factor between the MAP/MMSE estimation errors and that of the oracle.","Equations,
Mathematical model,
Dictionaries,
Signal processing algorithms,
Noise reduction,
Vectors,
Estimation"
Practical and Secure Multidimensional Query Framework in Tiered Sensor Networks,"The two-tier architecture consisting of a small number of resource-abundant storage nodes in the upper tier and a large number of sensors in the lower tier could be promising for large-scale sensor networks in terms of resource efficiency, network capacity, network management complexity, etc. In this architecture, each sensor having multiple sensing capabilities periodically forwards the multidimensional sensed data to the storage node, which responds to the queries, such as range query, top-k query, and skyline query. Unfortunately, node compromises pose the great challenge of securing the data collection; the sensed data could be leaked to or could be manipulated by the compromised nodes. Furthermore, chunks of the sensed data could be dropped maliciously, resulting in an incomplete query result, which is the most difficult security breach. Here, we propose a simple yet effective hash tree-based framework, under which data confidentiality, query result authenticity, and query result completeness can be guaranteed simultaneously. In addition, the subtree sampling technique, which could be of independent interest to the other applications, is proposed to efficiently identify the compromised nodes. Last, analytical and extensive simulation studies are conducted to evaluate the performance and security of our methods. Prototype implementation on TelosB mote demonstrates the practicality of our proposed methods.",
Learning a mixture of sparse distance metrics for classification and dimensionality reduction,"This paper extends the neighborhood components analysis method (NCA) to learning a mixture of sparse distance metrics for classification and dimensionality reduction. We emphasize two important properties in the recent learning literature, locality and sparsity, and (1) pursue a set of local distance metrics by maximizing a conditional likelihood of observed data; and (2) add ℓ1-norm of eigenvalues of the distance metric to favor low rank matrices of fewer parameters. Experimental results on standard UCI machine learning datasets, face recognition datasets, and image categorization datasets demonstrate the feasibility of our approach for both distance metric learning and dimensionality reduction.",
Various approaches in analyzing Android applications with its permission-based security models,"Permission-based security models use a computer security technique that allows the administrator and operating system to restrict applications to access specific resources. The restrictions used in this model are not designed by the users, but instead are designed by developers or administrators. Therefore, the user's system security is dependent on the user's belief that the developers and administrators are legitimate, which can be easily exploited by malicious developers. In this paper, we perform a high-level contextual analysis and an exploration of Android applications based on their implementation of permission-based security models by applying network visualization techniques and clustering algorithms. Throughout the analysis, we discover several phenomena that verify past research, and new potentials in permission-based security models that may provide additional security to the users.","Security,
Smart phones,
Androids,
Humanoid robots,
Visualization,
Data visualization,
Computational modeling"
Recognition of false alarms in fall detection systems,"Falls are a major cause of hospitalization and injury-related deaths among the elderly population. The detrimental effects of falls, as well as the negative impact on health services costs, have led to a great interest on fall detection systems by the health-care industry. The most promising approaches are those based on a wearable device that monitors the movements of the patient, recognizes a fall and triggers an alarm. Unfortunately such techniques suffer from the problem of false alarms: some activities of daily living are erroneously reported as falls, thus reducing the confidence of the user. This paper presents a novel approach for improving the detection accuracy which is based on the idea of identifying specific movement patterns into the acceleration data. Using a single accelerometer, our system can recognize these patterns and use them to distinguish activities of daily living from real falls; thus the number of false alarms is reduced.",
Macrodynamics Analysis of Migration Behaviors in Large-Scale Mobile Agent Systems for the Future Internet,"Network services in the future Internet are required to be highly available, ubiquitous, self-managing, and adaptable to dynamic environments. A promising way to implement such network services is combining mobile agent approaches with ecosystem-inspired evolutionary approaches. However, this perspective is still far from being practically implemented. An important reason is a lack of fundamental theory on macrodynamics of mobile agents in the new paradigm. This paper considers a type of large-scale mobile agent system and discusses the macrodynamics mainly affected by mobile agents' migration behaviors in the systems. The study benefits not only the design of composite services emerged from mobile agents in a type of ecosystem-inspired network architecture but also the future deployment of an Internet-scale system that holds myriads of mobile agents, hosts, and migratory behaviors of mobile agents.",
BirdVis: Visualizing and Understanding Bird Populations,"Birds are unrivaled windows into biotic processes at all levels and are proven indicators of ecological well-being. Understanding the determinants of species distributions and their dynamics is an important aspect of ecology and is critical for conservation and management. Through crowdsourcing, since 2002, the eBird project has been collecting bird observation records. These observations, together with local-scale environmental covariates such as climate, habitat, and vegetation phenology have been a valuable resource for a global community of educators, land managers, ornithologists, and conservation biologists. By associating environmental inputs with observed patterns of bird occurrence, predictive models have been developed that provide a statistical framework to harness available data for predicting species distributions and making inferences about species-habitat associations. Understanding these models, however, is challenging because they require scientists to quantify and compare multiscale spatialtemporal patterns. A large series of coordinated or sequential plots must be generated, individually programmed, and manually composed for analysis. This hampers the exploration and is a barrier to making the cross-species comparisons that are essential for coordinating conservation and extracting important ecological information. To address these limitations, as part of a collaboration among computer scientists, statisticians, biologists and ornithologists, we have developed BirdVis, an interactive visualization system that supports the analysis of spatio-temporal bird distribution models. BirdVis leverages visualization techniques and uses them in a novel way to better assist users in the exploration of interdependencies among model parameters. Furthermore, the system allows for comparative visualization through coordinated views, providing an intuitive interface to identify relevant correlations and patterns. We justify our design decisions and present case studies that show how BirdVis has helped scientists obtain new evidence for existing hypotheses, as well as formulate new hypotheses in their domain.","Tag clouds,
Biological system modeling,
Data visualization,
Predictive models,
Ornithology,
Spatial databases"
Secrecy Throughput of MANETs Under Passive and Active Attacks,"The secrecy throughput of mobile ad hoc networks (MANETs) with malicious nodes is investigated. The MANET consists of n legitimate mobile nodes and m malicious nodes. Transmissions between legitimate nodes are subject to a delay constraint D. A model under passive attack is first studied, in which the malicious nodes are assumed to be eavesdroppers that only listen to transmission without actively injecting signals. An information-theoretic approach for security is applied to achieve secure communication among legitimate nodes in MANETs with transmissions being kept perfectly secure from eavesdroppers. A critical threshold on the number of malicious nodes (m) is identified such that when m = o(√{nD}), i.e., limn→∞m/√{nD} = 0, the optimal secrecy throughput equals that of MANETs without malicious nodes, i.e., the impact of the presence of malicious nodes on the network throughput is negligible; and when m = Ω(√{nD}poly(n)), i.e., limn→∞m/(√{nD}poly(n)) ≥ c for a positive constant c, the optimal secrecy throughput is limited by the number of malicious nodes. A model under active attack is further studied, in which the malicious nodes actively attack the network by transmitting modified packets to the destination nodes. It is shown that to guarantee the same throughput as the model under passive attack, the model under active attack needs to satisfy more stringent condition on the number of malicious nodes.","Ad hoc networks,
Mobile computing,
Throughput,
Security,
Receivers,
Encoding,
Delay"
The Implementation of a Low-Power Biomedical Signal Processor for Real-Time Epileptic Seizure Detection on Absence Animal Models,"Epilepsy is one of the most common neurological disorders, with a worldwide prevalence of approximately 1%. A considerable portion of epilepsy patients cannot be treated sufficiently by today's available therapies. Implantable closed-loop neurostimulation is an innovative and effective method for seizure control. A real-time seizure detector is the kernel of a closed-loop seizure controller. In this paper, a low-power biomedical signal processor based on reduced instruction set computer (RISC) architecture for real-time seizure detection is implemented to achieve low-power consumption and perform continuous and real-time processing. The low-power processor is implemented in a 0.18
μ
m complementary–metal–oxide semiconductor technology to verify functionality and capability. The measurement results show the implemented processor can reduce over 90% power consumption compared with our previous prototype, which was implemented on an enhanced 8051 microprocessor. This seizure detector was applied to the continuous EEG signals of four Long–Evans rats with spontaneous absence seizures. It also processed 24 h long-term and uninterrupted EEG sequence. The developed seizure detector can be applied for online seizure monitoring and integrated with an electrical stimulator to perform a closed-loop seizure controller in the future.","Electroencephalography,
Real time systems,
Feature extraction,
Biomedical signal processing,
Epilepsy,
Detection algorithms,
Reduced instruction set computing"
Indoor localization using pedestrian dead reckoning updated with RFID-based fiducials,"We describe a low-cost wearable system that tracks the location of individuals indoors using commonly available inertial navigation sensors fused with radio frequency identification (RFID) tags placed around the smart environment. While conventional pedestrian dead reckoning (PDR) calculated with an inertial measurement unit (IMU) is susceptible to sensor drift inaccuracies, the proposed wearable prototype fuses the drift-sensitive IMU with a RFID tag reader. Passive RFID tags placed throughout the smart-building then act as fiducial markers that update the physical locations of each user, thereby correcting positional errors and sensor inaccuracy. Experimental measurements taken for a 55 m × 20 m 2D floor space indicate an over 1200% improvement in average error rate of the proposed RFID-fused system over dead reckoning alone.","Passive RFID tags,
Dead reckoning,
Accelerometers,
Conferences,
Electronic mail"
Data-Based Identification and Control of Nonlinear Systems via Piecewise Affine Approximation,"The piecewise affine (PWA) model represents an attractive model structure for approximating nonlinear systems. In this paper, a procedure for obtaining the PWA autoregressive exogenous (ARX) (autoregressive systems with exogenous inputs) models of nonlinear systems is proposed. Two key parameters defining a PWARX model, namely, the parameters of locally affine subsystems and the partition of the regressor space, are estimated, the former through a least-squares-based identification method using multiple models, and the latter using standard procedures such as neural network classifier or support vector machine classifier. Having obtained the PWARX model of the nonlinear system, a controller is then derived to control the system for reference tracking. Both simulation and experimental studies show that the proposed algorithm can indeed provide accurate PWA approximation of nonlinear systems, and the designed controller provides good tracking performance.","Cost function,
Nonlinear systems,
Autoregressive processes,
Control systems,
Data models,
Approximation methods,
Switching systems,
System identification"
Impact of controlled plug-in EVs on microgrids: A military microgrid example,"Increasing concerns about energy security and reliability are intensifying the interest in microgrid and vehicle-to-grid (V2G) technologies. Although the role of V2G technology within the context of optimal scheduling for larger grids has received much attention in the literature, its role within the regulation of microgrids has not yet been studied extensively. In this paper, we focus on the voltage and frequency regulation problem. We develop a microgrid model that is representative of the microgrid architecture considered in the SPIDERS (Smart Power Infrastructure Demonstration for Energy Reliability and Security) project of the Department of Defense. The model is parameterized to reflect the characteristics of Camp Smith, HI, the targeted installation of the SPIDERS project, and the long term Army goals regarding renewable energy penetration and reduction in fuel consumption. The model is augmented by power, frequency, and voltage control algorithms for the inverters that connect microsources to the microgrid. It also incorporates charging/discharging control algorithms for plug-in electric vehicles (PEVs) to take advantage of their capacity as both controllable loads and sources. Using this model, we study the impact of PEVs on the microgrid at different penetration levels and for different control parameters, with the aim of identifying the conditions needed for the vehicle-to-grid technology to have a positive impact on microgrid performance.","Voltage control,
Inverters,
Frequency control,
Mathematical model,
Equations,
Renewable energy resources,
Security"
Probability Density of the Received Power in Mobile Networks,"Probability density of the received power is well analyzed for wireless networks with static nodes. However, most of the present days networks are mobile and not much exploration has been done on statistical analysis of the received power for mobile networks in particular, for the network with random moving patterns. In this paper, we derive probability density of the received power for mobile networks with random mobility models. We consider the power received at an access point from a particular mobile node. Two mobility models are considered: Random Direction (RD) model and Random way-point (RWP) model. Wireless channel is assumed to have a small scale fading of Rayleigh distribution and path loss exponent of 4. 3D, 2D and 1D deployment of nodes are considered. Our findings show that the probability density of the received power for RD mobility models for all the three deployment topologies are weighted confluent hypergeometric functions. In case of RWP mobility models, the received power probability density for all the three deployment topologies are linear combinations of confluent hypergeometric functions. The analytical results are validated through NS2 simulations and a reasonably good match is found between analytical and simulation results.","Probability density function,
Mobile communication,
Mobile computing,
Three dimensional displays,
Network topology,
Fading channels,
Network topology"
Trajectories of Electrical Engineering and Computer Engineering Students by Race and Gender,"Electrical engineering (EE) is one of the largest engineering disciplines. Computer engineering (CpE) has a similar curriculum, but different demographics and student outcomes. Using a dataset from universities in the U.S. that includes over 70 000 students who majored in engineering, this paper describes the out comes for students matriculating in and migrating into EE and CpE so as to inform the decision making of faculty, department heads, and deans. Although men consistently outnumber women in EE and CpE, the rates of matriculation and six-year graduation vary by race and gender. EE is the most popular choice for Asian and Black students (males and females) at matriculation, but while Asians graduate at high rates, Blacks (particularly males) are not retained. Retention is higher in EE than in CpE despite the similarity of the curricula. Graduation rates are lower than expected for women of all races in CpE and for Hispanic women in EE. By the third semester, some students of all races and genders have left their matriculation major, but others have migrated in from other majors, compensating for some of this loss. CpE students are more likely than EE students to switch to another major. Trajectories of EE and CpE students are racialized and distinct. CpE loses more students and attracts fewer students than EE. These findings il lustrate the importance of disaggregating by engineering major as well as race and gender to improve recruitment and retention overall.","Computers,
Educational institutions,
Switches,
Trajectory,
Electrical engineering,
Engineering students"
Synthesis of Wideband Multicoupled Resonators Filters,A method for the synthesis of multicoupled resonators filters with frequency-dependent couplings is presented. A circuit model of the filter that accurately represents the frequency responses over a very wide frequency band is postulated. The two-port parameters of the filter based on the circuit model are obtained by circuit analysis. The values of the circuit elements are synthesized by equating the two-port parameters obtained from the circuit analysis and the filtering characteristic function. Solutions similar to the narrowband case (where all the couplings are assumed frequency independent) are obtained analytically when all coupling elements are either inductive or capacitive. The synthesis technique is generalized to include all types of coupling elements. Several examples of wideband filters are given to demonstrate the synthesis techniques.,"Couplings,
Integrated circuit modeling,
Symmetric matrices,
Filtering theory,
Wideband,
Polynomials"
Optimal Design of Oversampled Synthesis FBs With Lattice Structure Constraints,"Oversampled filter banks (FBs) with lattice structure allow fast implementation and guarantee the linear phase and perfect reconstruction property. For such FBs, the synthesis FB is not unique. This nonuniqueness provides extra design freedom for optimal reduction of subband noise required in many applications. However, the existing design methods of synthesis FB for optimal reduction of subband noise cannot guarantee the linear phase and lattice structure property. This paper studies the design of oversampled synthesis FBs with guaranteed lattice structure for optimal reduction of subband noise. Based on a state space parameterization of all synthesis FBs with lattice structure, the explicit formulae are derived to find the optimal solution for noise reduction. Numerical examples are presented to demonstrate the effectiveness of the new design methods obtained.","Lattices,
Noise,
Noise reduction,
Optimization,
Design methodology,
Correlation,
Symmetric matrices"
Iterative Tensor Voting for Perceptual Grouping of Ill-Defined Curvilinear Structures,"In this paper, a novel approach is proposed for perceptual grouping and localization of ill-defined curvilinear structures. Our approach builds upon the tensor voting and the iterative voting frameworks. Its efficacy lies on iterative refinements of curvilinear structures by gradually shifting from an exploratory to an exploitative mode. Such a mode shifting is achieved by reducing the aperture of the tensor voting fields, which is shown to improve curve grouping and inference by enhancing the concentration of the votes over promising, salient structures. The proposed technique is validated on delineating adherens junctions that are imaged through fluorescence microscopy. However, the method is also applicable for screening other organisms based on characteristics of their cell wall structures. Adherens junctions maintain tissue structural integrity and cell-cell interactions. Visually, they exhibit fibrous patterns that may be diffused, heterogeneous in fluorescence intensity, or punctate and frequently perceptual. Besides the application to real data, the proposed method is compared to prior methods on synthetic and annotated real data, showing high precision rates.","Tensile stress,
Kernel,
Pixel,
Junctions,
Iterative methods,
Surfaces,
Image segmentation"
New computer interface combining gaze tracking and brainwave measurements,"We present a new computer interface that combines gaze tracking with brainwave measurements in an integrated head-mounted device. This interface is novel in the following four ways compared to previous works. First, because the system is designed as a single head-mounted device, both the brainwave data and eye images for gaze tracking can be acquired by wearing only one device that includes a sensing node and an eye image-capturing camera. Second, the noise in the brainwave data caused by blinking is removed by a blink detection system in the eye camera. Third, the sensitivity of a gaze-based navigation speed is appropriately controlled on the basis of the level of attention estimated by analyzing the brainwave. Fourth, performance and usability of the interface are validated by objective evaluating and subjective surveys. From experimental results, we confirmed that the proposed system shows promising performance and usability as a new computer interface1.","Navigation,
Three dimensional displays,
Monitoring,
Electrodes,
Cameras,
Mice,
Sensitivity"
Identifying Social Influence in Networks Using Randomized Experiments,"The recent availability of massive amounts of networked data generated by email, instant messaging, mobile phone communications, micro blogs, and online social networks is enabling studies of population-level human interaction on scales orders of magnitude greater than what was previ ously possible.1'2 One important goal of applying statistical inference techniques to large networked datasets is to understand how behavioral conta gions spread in human social networks. More pre cisely, understanding how people influence or are influenced by their peers can help us understand the ebb and flow of market trends, product adoption and diffusion, the spread of health behaviors such as smoking and exercise, the productivity of information workers, and whether particular indi viduals in a social network have a disproportion ate amount of influence on the system.","Social factors,
Social network services,
Behavioral science,
Peer to peer computing,
Facebook"
"An Ultrasonic Transducer Interface IC With Integrated Push-Pull 40 Vpp, 400 mA Current Output, 8-bit DAC and Integrated HV Multiplexer","We present an ultrasonic transducer interface IC that includes an 8-bit, 40 Vpp, 400 mA current output DAC for arbitrary waveform transducer excitation and a ±25 V analog multiplexer. The IC was fabricated using a 0.35 μm, 50 V CMOS process. The design eliminates the need for an external power amplifier as the piezoelectric transducer is driven directly from a segmented push-pull current output DAC, which simplifies the overall system design. This approach has the advantage of simple and rapid glitch-free power-up/down, which is especially important in integrated high-output-power drivers. The DAC has been evaluated when operating at a 150 MHz sampling rate with a ±400 mA output current and a 50 Ω load. Measured performance includes 37 dB SNDR and 46 dB SFDR at 10 MHz output frequency. By implementing an additional reference DAC and extending the receiver isolation switch into an analog multiplexer, we enable on-line calibration for the purpose of reducing the driver and receiver signal path uncertainty. Measurements show a greater than ten-fold improvement in delay uncertainty to approximately 20 ps for temperature variations of 0 to 70 degrees Celsius.","Switches,
Driver circuits,
Transducers,
Clocks,
Delay,
Impedance,
Receivers"
The impact of social groups on the capacity of wireless networks,"The capacity of a wireless network with n nodes is studied when nodes communicate with one another in the context of social groups. Each node is assumed to have at least one local contact in each of the four directions of the plane in which the wireless network operates, and q(n) independent long-range social contacts forming its social group, one of which it selects randomly as its destination. The distance between source and the members of its social group follows a power-law distribution with parameter α, and communication between any two nodes takes place only within the physical transmission range; hence, source-destination communication takes place over multi-hop paths. The order capacity of such a composite network is derived as a function of the number of nodes (n), the social-group concentration (α), and the size of social groups (q(n)). It is shown that the maximum order capacity is attained when α ≥ 3, which makes social groups localized geographically, and that a wireless network can be scale-free when social groups are localized and independent of the number of nodes in the network, i.e., q(n) is independent of n.","Wireless networks,
Social network services,
Random variables,
Throughput,
Context,
Electronic mail"
AMIC: An Expandable Front-End for Gamma-Ray Detectors With Light Distribution Analysis Capabilities,"A novel CMOS integrated front-end architecture is presented throughout this paper. It is designed to be used with detectors based on continuous scintillation crystals plus position sensitive photomultiplier. Its structure aims at carrying out an analog computation which extracts fundamental information of the detected event. This fact allows us to avoid an individual acquisition of every input channel so that a large increase of inputs is feasible. In order to accomplish the processing task, a current buffer delivers a copy of each input signal to several computation blocks. Those processing units implement current mode analog filtering operations with a digitally programmable 8-bit precision coefficient for each front-end input. Output currents are summed and sent to the output stage where a buffered current output is provided. A voltage signal is also available by means of a rail-to-rail transresistance amplifier. The final goal is to obtain several moments of the light distribution on the detector surface. Each one provides useful information, such as energy, position, depth of interaction (from the light distribution width), skewness (deformation due to border effect), etc. Since the computation is purely additive, the current outputs can be used as inputs to other equal devices thus creating a fully expandable architecture.","Detectors,
Spatial resolution,
Computer architecture,
Noise,
Crystals,
Current measurement,
Bandwidth"
A new symmetry-based method for mid-sagittal plane extraction in neuroimages,"The estimation of the mid-sagittal plane (MSP) is a known problem with several applications in neuroimage analysis. As advance to the state-of-the-art, we present a considerably better approach for MSP extraction based on bilateral symmetry maximization and a more suitable error metric to compare MSP estimation methods. The proposed method was quantitatively evaluated using three other state-of-the-art approaches as baselines and a heterogeneous dataset with 164 clinical images. It outperformed the others in accuracy and precision, being well succeeded on all images. Besides, it does not present limitations with respect to the imaging protocol and initial position of the head, and it is one of the fastest methods in the literature, taking around 30 seconds on a regular workstation.","Image edge detection,
Measurement,
Biomedical imaging,
Accuracy,
Three dimensional displays,
Robustness"
Identity obfuscation in graphs through the information theoretic lens,"Analyzing the structure of social networks is of interest in a wide range of disciplines, but such activity is limited by the fact that these data represent sensitive information and can not be published in their raw form. One of the approaches to sanitize network data is to randomly add or remove edges from the graph. Recent studies have quantified the level of anonymity that is obtained by random perturbation by means of a-posteriori belief probabilities and, by conducting experiments on small datasets, arrived at the conclusion that random perturbation can not achieve meaningful levels of anonymity without deteriorating the graph features. We offer a new information-theoretic perspective on this issue. We make an essential distinction between image and preimage anonymity and propose a more accurate quantification, based on entropy, of the anonymity level that is provided by the perturbed network. We explain why the entropy-based quantification, which is global, is more adequate than the previously used local quantification based on a-posteriori belief. We also prove that the anonymity level quantified by means of entropy is always greater than or equal to the one based on a-posteriori belief probabilities. In addition, we introduce and explore the method of random sparsification, which randomly removes edges, without adding new ones. Extensive experimentation on several very large datasets shows that randomization techniques for identity obfuscation are back in the game, as they may achieve meaningful levels of anonymity while still preserving features of the original graph.","Entropy,
Probability distribution,
Privacy,
Social network services,
Gallium,
Uncertainty,
Random variables"
Place recognition in 3D scans using a combination of bag of words and point feature based relative pose estimation,"Place recognition, i.e., the ability to recognize previously seen parts of the environment, is one of the fundamental tasks in mobile robotics. The wide range of applications of place recognition includes localization (determine the initial pose), SLAM (detect loop closures), and change detection in dynamic environments. In the past, only relatively little work has been carried out to attack this problem using 3D range data and the majority of approaches focuses on detecting similar structures without estimating relative poses. In this paper, we present an algorithm based on 3D range data that is able to reliably detect previously seen parts of the environment and at the same time calculates an accurate transformation between the corresponding scan-pairs. Our system uses the estimated transformation to evaluate a candidate and in this way to more robustly reject false positives for place recognition. We present an extensive set of experiments using publicly available datasets in which we compare our system to other state-of-the-art approaches.","Three dimensional displays,
Feature extraction,
Databases,
Simultaneous localization and mapping,
Trajectory,
Robustness"
Anonymous communication with network coding against traffic analysis attack,"Flow untraceability is one critical requirement for anonymous communication with network coding, which prevents malicious attackers with wiretapping and traffic analysis abilities from relating the senders to the receivers, using linear dependency of the received packets. There have recently been proposals advocating encryptions on the Global Encoding Vectors (GEV) of network coding to thwart such attacks. Nevertheless, there has been no exploration of the capability of networking coding itself, to constitute more efficient and effective algorithms which guarantee anonymity. In this paper, we design a novel, simple, and effective linear network coding mechanism (ALNCode) to achieve flow untraceability in a communication network with multiple unicast flows. With solid theoretical analysis, we first show that linear network coding (LNC) can be applied to thwart traffic analysis attacks without the need of encrypting GEVs. Our key idea is to mix multiple flows at their intersection nodes by generating downstream GEVs from the common basis of upstream GEVs belonging to multiple flows, in order to hide the correlation of upstream and downstream GEVs in each flow. We then design a deterministic LNC scheme to implement our idea, by which the downstream GEVs produced are guaranteed to obfuscate their correlation with the corresponding upstream GEVs. We also give extensive theoretical analysis on the intersection probability of GEV bases and the influential factors to the effectiveness of our scheme, as well as the algorithm complexity to support its efficiency.",
Content management in a mobile ad hoc network: Beyond opportunistic strategy,"We study the challenging problem of strategic content placement in a dynamic MANET. Existing content placement techniques cannot cope with such network dynamics since they are designed for fixed networks. Opportunistic caching approaches are insufficient as they do not actively manage contents for certain goals. In this paper, we present a novel content management approach called LACMA, which leverages the location information available to mobile devices via GPS. The main idea of LACMA is to bind data to geographic location (as opposed to network nodes). This location-based strategy decouples the content placement problem from the changing network topology, and allows us to design an optimization framework even in a dynamic MANET environment. We present key components of LACMA used for strategic content placement and content-location binding (through proactive content push). We evaluate LACMA and compare its performance with existing caching schemes and show that LACMA considerably outperforms existing schemes over a wide range of scenarios.","Mobile ad hoc networks,
Content management,
Network topology,
Maintenance engineering,
Algorithm design and analysis,
TV"
Performance and Yield Benefits of Quasi-Planar Bulk CMOS Technology for 6-T SRAM at the 22-nm Node,"The performance and threshold voltage variability of quasi-planar bulk MOSFETs are compared against those of conventional bulk MOSFETs, via three-dimensional (3-D) device simulations with gate line-edge roughness and atomistic doping profiles, at 25 nm gate length. The nominal performance of six transistor (6-T) SRAM cells is studied via 3-D simulation of full cell structures. Compact (analytical) modeling is used to estimate SRAM cell yields. As compared to conventional bulk CMOS technology, quasi-planar bulk CMOS technology provides for enhanced SRAM cell performance and yield, and hence facilitates reductions in cell area and operating voltage. It also enables a notchless 6-T SRAM cell design which is advantageous for improved lithographic printability and either smaller area or lower standby power, and is projected to achieve 6-sigma cell yields at operating voltages down to ~0.8 V.","MOSFETs,
Logic gates,
Random access memory,
CMOS integrated circuits,
CMOS technology,
Performance evaluation"
"Integration of SiP-Based 60-GHz 4 \,\times\,4 Antenna Array With CMOS OOK Transmitter and LNA","An integrated system-in-package-based 60-GHz 4 × 4 antenna array with CMOS on-off keying (OOK) transmitter and low-noise amplifier (LNA) is investigated. The 4 × 4 circular polarized array exhibits a wide impedance bandwidth (VSWR <; 2) and 3-dB axial ratio bandwidth of over 8 GHz using a strip line sequential rotation feeding scheme. It has a beam-shaped pattern with a 3-dB beamwidth of 20° and a peak gain of 16.8 dBi. The modulators in 90-nm CMOS includes 60-GHz oscillators and switchable amplifiers to achieve the OOK modulation. The key features of the circuits are small power consumption and size. By applying a bond wire compensation scheme, the LNA and 60-GHz CMOS modulator are successfully integrated into the low-temperature co-fired ceramic package with 2-mil 500-μm-long bond wires. The measurement results for the antenna array with LNA shows a peak gain of ~ 35 dBi. The 60-GHz CMOS modulator is tested at a data rate of 2 Gb/s and the bit-error performance of the system is also demonstrated. The energy usage of 60-GHz modulator at 2 Gb/s is only 13.2 pj/bit for the modulator.","Oscillators,
Arrays,
Switches,
Antenna arrays,
Frequency modulation"
Using neighbor and tag estimations for redundant reader eliminations in RFID networks,"Deployments of Radio Frequency Identification (RFID) networks are anticipated to be dense and ad-hoc. These deployments usually involve redundant readers having overlapping interrogation zones and, hence, causing immense reader collisions. Elimination of redundant readers, from the network, is of utmost importance as otherwise they affect the lifetime and the operational capacity of the overall RFID network. In this paper, we propose a light-weight greedy algorithm that detects and eliminates redundant readers from the network. Our algorithm uses the ratio of tag counts to the number of neighboring readers of each reader to estimate the likelihood for that reader to be redundant. The proposed algorithm is highly scalable and poses a minimal communication overhead as compared with existing schemes in the literature.",
Parameter Exploration in Science and Engineering Using Many-Task Computing,"Robust scientific methods require the exploration of the parameter space of a system (some of which can be run in parallel on distributed resources), and may involve complete state space exploration, experimental design, or numerical optimization techniques. Many-Task Computing (MTC) provides a framework for performing robust design, because it supports the execution of a large number of otherwise independent processes. Further, scientific workflow engines facilitate the specification and execution of complex software pipelines, such as those found in real science and engineering design problems. However, most existing workflow engines do not support a wide range of experimentation techniques, nor do they support a large number of independent tasks. In this paper, we discuss Nimrod/K - a set of add in components and a new run time machine for a general workflow engine, Kepler. Nimrod/K provides an execution architecture based on the tagged dataflow concepts, developed in 1980s for highly parallel machines. This is embodied in a new Kepler ""Director” that supports many-task computing by orchestrating execution of tasks on on clusters, Grids, and Clouds. Further, Nimrod/K provides a set of ""Actors” that facilitate the various modes of parameter exploration discussed above. We demonstrate the power of Nimrod/K to solve real problems in cardiac science.",
A domain independent Genetic Programming approach to automatic feature extraction for image classification,"In this paper we explore the application of Genetic Programming (GP) to the problem of domain-independent image feature extraction and classification. We propose a new GP based image classification system that extracts image features autonomously, and compare its performance against a baseline GP-based classifier system that uses human-extracted features. We found that the proposed system has a similar performance to the baseline system, and that GP is capable of evolving a single program that can both extract useful features and use those features to classify an image.","Feature extraction,
Pixel,
Humans,
Accuracy,
Filtering,
Genetic programming,
Object detection"
An inner-product lower-bound estimate for dynamic time warping,"In this paper, we present a lower-bound estimate for dynamic time warping (DTW) on time series consisting of multi-dimensional posterior probability vectors known as posteriorgrams. We develop a lower-bound estimate based on the inner-product distance that has been found to be an effective metric for computing similarities between posteriorgrams. In addition to deriving the lower-bound estimate, we show how it can be efficiently used in an admissible K nearest neighbor (KNN) search for spotting matching sequences. We quantify the amount of computational savings achieved by performing a set of unsupervised spoken keyword spotting experiments using Gaussian mixture model posteriorgrams. In these experiments the proposed lower-bound estimate eliminates 89% of the DTW previously required calculations without affecting overall keyword detection performance.","Speech,
Speech recognition,
Hidden Markov models,
Glass,
Time series analysis,
Training,
Keyword search"
Vertically Integrated Three-Pole Filter/Antennas for Array Applications,"Integration of high-quality (Q)-factor cavity filters with high-efficiency slot antennas for array applications is presented in this letter. This proposed integration technique exhibits near-zero transition loss between the filter and antenna, and therefore improves the total efficiency of the filter/antenna system. The filter and antenna are vertically integrated to reduce the footprint that is necessary for array applications. The fabricated filter/antenna unit cell has a center frequency of 10.07 GHz and a bandwidth of 5.5%. Using the proposed integrated filter/antenna structure, a 2 × 2 array is designed, fabricated, and measured. Very close agreement is found in between the measurement and simulation results in terms of reflection coefficient, gain, and radiation patterns. The approach demonstrated in this letter can be applied for filter/antennas with higher orders and at higher frequencies.","Resonator filters,
Antenna measurements,
Microwave filters,
Cavity resonators,
Slot antennas,
Arrays"
An analytical performance model of MapReduce,"MapReduce is a distributed computing framework. Its application in distributed systems is a rapidly emerging field. Although this framework can leverage clusters to improve computing performance, tuning it is still challenging. Most current works related to MapReduce performance are based on system monitoring and simulation, and lack analytical performance models. In this paper, we propose a simple and general MapReduce performance model for better understanding the impact of each component on overall program performance, and verify it in a small cluster. The results indicate that our model can predict the performance of MapReduce system and its relation to the configuration. According to our model, performance can be improved significantly by modifying Map split granularity and number of reducers without modifying the framework. The model also points out potential bottlenecks of the framework and future improvement for better performance.","Computational modeling,
Analytical models,
Pipelines,
Data models,
Companies,
Predictive models,
Distributed databases"
State space pruning for reliability evaluation using binary particle swarm optimization,"State space pruning is a methodology that has been successfully applied to improve the computational efficiency and convergence of Monte Carlo Simulation (MCS) when computing the reliability indices of composite power systems. This methodology increases performance of MCS by pruning state spaces in such a manner that a new state space with a higher density of failure states than the original state space is created. A method that was previously proposed to increase the efficiency of MCS was the use of Population-based Intelligent Search (PIS), specifically Genetic Algorithms (GA), to prune the state space. This paper extends these ideas to another PIS methodology: Binary Particle Swarm Optimization (BPSO). The results of this study show that BPSO is highly effective in pruning the state space and improving the convergence of MCS. This method is tested using the IEEE reliability test system.","Reliability,
Convergence,
Power system reliability,
Generators,
Genetic algorithms,
Particle swarm optimization"
Integration of Fuzzy Spatial Information in Tracking Based on Particle Filtering,"In this paper, we propose a novel method to introduce spatial information in particle filters. This information may be expressed as spatial relations (orientation, distance, etc.), velocity, scaling, or shape information. Spatial information is modeled in a generic fuzzy-set framework. The fuzzy models are then introduced in the particle filter and automatically define transition and prior spatial distributions. We also propose an efficient importance distribution to produce relevant particles, which is dedicated to the proposed fuzzy framework. The fuzzy modeling provides flexibility both in the semantics of information and in the transitions from one instant to another one. This allows one to take into account situations where a tracked object changes its direction in a quite abrupt way and where poor prior information on dynamics is available, as demonstrated on synthetic data. As an illustration, two tests on real video sequences are performed in this paper. The first one concerns a classical tracking problem and shows that our approach efficiently tracks objects with complex and unknown dynamics, outperforming classical filtering techniques while using only a small number of particles. In the second experiment, we show the flexibility of our approach for modeling: Fuzzy shapes are modeled in a generic way and allow the tracking of objects with changing shape.","Fuzzy sets,
Shape,
Mathematical model,
Adaptation model,
Zirconium,
Semantics,
Pragmatics"
Active focal zone sharpening for high-precision treatment using histotripsy,"The goal of this study is to develop a focal zone sharpening strategy that produces more precise lesions for pulsed cavitational ultrasound therapy, or histotripsy. Precise and well-confined lesions were produced by locally suppressing cavitation in the periphery of the treatment focus without affecting cavitation in the center. The local suppression of cavitation was achieved using cavitation nuclei preconditioning pulses to actively control cavitation in the periphery of the focus. A 1-MHz 513-element therapeutic array was used to generate both the therapy and the nuclei preconditioning pulses. For therapy, 10-cycle bursts at 100-Hz pulse repetition frequency with P-/P+ pressure of 21/76 MPa were delivered to the geometric focus of the therapeutic array. For nuclei preconditioning, a different pulse was delivered to an annular region immediately surrounding the focus before each therapy pulse. A parametric study on the effective pressure, pulse duration, and delivery time of the preconditioning pulse was conducted in red blood cell-gel phantoms, where cavitational damage was indicated by the color change resulting from local cell lysis. Results showed that a short-duration (20 μs) preconditioning pulse at a medium pressure (P-/P+ pressure of 7.2/13.6 MPa) delivered shortly before (30 μs) the therapy pulse substantially suppressed the peripheral damage by 77 ± 13% while complete fractionation in the focal center was maintained. High-speed imaging of the bubble cloud showed a substantial decrease in the maximum width of the bubble cloud by 48 ± 24% using focal zone sharpening. Experiments in ex vivo livers confirmed that highly confined lesions were produced in real tissues as well as in the phantoms. This study demonstrated the feasibility of active focal zone sharpening using cavitation nuclei preconditioning, allowing for increased treatment precision compared with the natural focal width of the therapy transducer.","Lesions,
Medical treatment,
Arrays,
Phantoms,
Ultrasonic imaging,
Laser beams,
Pixel"
Performance Characteristics and Metrics for Intra-Pulse Radar-Embedded Communication,"Low probability of intercept (LPI) communication generally relies on the presence of noise to obfuscate a covert signal through the use of spectral spreading or hopping. In contrast, this paper addresses the use of ambient interference from other man-made emissions as a means to mask the presence of covert communication. Specifically, the high power, wide bandwidth, and repeating structure of pulsed radar systems provide an advantageous framework within which to embed a communication signal. The operating paradigm considered here is that of an RF tag/transponder that is illuminated by the radar and intends to covertly communicate with the radar or some other desired receiver while being masked by the ambient radar backscatter to avoid detection by an intercept receiver. Communication takes place on an intra-pulse (or individual pulse) basis to maximize the data rate. The impact of multipath, and its exploitation using time reversal to achieve spatio-temporal focusing, is considered. The processing gain for the destination receiver and intercept receiver are derived analytically and subsequently used to optimize the parameterization of communication symbol design.","Military communication,
Receivers,
Noise measurement,
Radar scattering,
Lighting"
Constellation Precoded Multiple Beamforming,"Beamforming techniques that employ Singular Value Decomposition (SVD) are commonly used in Multi-Input Multi-Output (MIMO) wireless communication systems. In the absence of channel coding, when a single symbol is transmitted, these systems achieve the full diversity order provided by the channel; whereas when multiple symbols are simultaneously transmitted, this property is lost. When channel coding is employed, full diversity order can be achieved. For example, when Bit-Interleaved Coded Modulation (BICM) is combined with this technique, full diversity order of NM in an M x N MIMO channel transmitting S parallel streams is possible, provided a condition on S and the BICM convolutional code rate is satisfied. In this paper, we present constellation precoded multiple beamforming which can achieve the full diversity order both with BICM-coded and uncoded SVD systems. We provide an analytical proof of this property. To reduce the computational complexity of Maximum Likelihood (ML) decoding in this system, we employ Sphere Decoding (SD). We report an SD technique that reduces the computational complexity beyond commonly used approaches to SD. This technique achieves several orders of magnitude reduction in computational complexity not only with respect to conventional ML decoding but also, with respect to conventional SD.","Array signal processing,
Complexity theory,
MIMO,
Interleaved codes,
Indexes,
Upper bound,
Maximum likelihood decoding"
Cooperative Downlink Multicell Preprocessing Relying on Reduced-Rate Back-Haul Data Exchange,"Different-complexity multicell preprocessing (MCP) schemes employing distributed signal-to-interference leakage-plus-noise ratio (SILNR) precoding techniques are proposed, which require reduced back-haul data exchange in comparison with the conventional MCP structure. Our results demonstrate that the proposed structures are capable of increasing the throughput achievable in the cell-edge area while offering different geographic rate profile distributions, as well as meeting different delay requirements.",
Chip-to-wafer (C2W) 3D integration with well-controlled template alignment and wafer-level bonding,"This paper presents on a novel chip-to-wafer (C2W) three-dimensional (3D) integration technology with well-controlled template alignment and wafer-level bonding, enabling precise alignment, few thermal cycles and high throughput of 3D system fabrication. The key processes are investigated and discussed in detail, including chip edge definition, template fabrication, C2W alignment and wafer-level bonding. The C2W 3D integration technology is successfully demonstrated using Cu daisy chains, a patterned thick benzocyclobutene (BCB) layer on the wafer as the alignment template, and wafer-level C2W Cu-Cu bonding. An alignment accuracy less than 2 μm is achieved. The FIB-SEM images reveal that Cu grains cross the original Cu-Cu bonding interface to form strong bonding. The measured I-V characteristics of daisy chains show a linear ohmic behavior, and the specific contact resistance of Cu-Cu bonding structures is on the order of 10-8 ohm-cm2, suggesting good electric contacts.","Bonding,
Copper,
Three dimensional displays,
Etching,
Accuracy,
Resistance"
A Pulse Width Modulation technique for reducing switching frequency for modular multilevel converter,"In this paper, a Pulse Width Modulation (PWM) technique for modular multilevel converter has been explored. The PWM technique is implemented using carrier based level shifted PWM strategy. It does not necessitate the calculation of duty cycles, and can be easily implemented in a DSP. With the proposed technique, harmonics in the phase voltage is shifted to twice the switching frequency. Thus, the devices of the converter can be switched at a reduced switching frequency to maintain the same output voltage quality. A detailed explanation of the carrier based level shifted PWM for implementing the proposed technique is included in the paper. This is verified by computer simulation on a 6.6 kV, 6 MW drive system.",
PERFUME: Power and performance guarantee with fuzzy MIMO control in virtualized servers,"It is important but challenging to assure the performance of multi-tier Internet applications with the power consumption cap of virtualized server clusters mainly due to system complexity of shared infrastructure and dynamic and bursty nature of workloads. This paper presents PERFUME, a system that simultaneously guarantees power and performance targets with flexible tradeoffs while assuring control accuracy and system stability. Based on the proposed fuzzy MIMO control technique, it accurately controls both the throughput and percentile-based response time of multi-tier applications due to its novel fuzzy modeling that integrates strengths of fuzzy logic, MIMO control and artificial neural network. It is self-adaptive to highly dynamic and bursty workloads due to online learning of control model parameters using a computationally efficient weighted recursive least-squares method. We implement PERFUME in a testbed of virtualized blade servers hosting two multi-tier RUBiS applications. Experimental results demonstrate its control accuracy, system stability, flexibility in selecting tradeoffs between conflicting targets and robustness against highly dynamic variation and burstiness in workloads. It outperforms a representative utility based approach in providing guarantee of the system throughput, percentile-based response time and power budget in the face of highly dynamic and bursty workloads.","Servers,
Power demand,
Adaptation model,
Time factors,
MIMO,
Virtual machining,
Throughput"
Generalized Constraint Neural Network Regression Model Subject to Linear Priors,"This paper is reports an extension of our previous investigations on adding transparency to neural networks. We focus on a class of linear priors (LPs), such as symmetry, ranking list, boundary, monotonicity, etc., which represent either linear-equality or linear-inequality priors. A generalized constraint neural network-LPs (GCNN-LPs) model is studied. Unlike other existing modeling approaches, the GCNN-LP model exhibits its advantages. First, any LP is embedded by an explicitly structural mode, which may add a higher degree of transparency than using a pure algorithm mode. Second, a direct elimination and least squares approach is adopted to study the model, which produces better performances in both accuracy and computational cost over the Lagrange multiplier techniques in experiments. Specific attention is paid to both “hard (strictly satisfied)” and “soft (weakly satisfied)” constraints for regression problems. Numerical investigations are made on synthetic examples as well as on the real-world datasets. Simulation results demonstrate the effectiveness of the proposed modeling approach in comparison with other existing approaches.","Neural networks,
Training,
Regression analysis,
Radial basis function networks,
Adaptation models,
Machine learning,
Data mining"
Pareto-Based Dominant Graph: An Efficient Indexing Structure to Answer Top-K Queries,"Given a record set D and a query score function F, a top-k query returns k records from D, whose values of function F on their attributes are the highest. In this paper, we investigate the intrinsic connection between top-k queries and dominant relationships between records, and based on which, we propose an efficient layer-based indexing structure, Pareto-Based Dominant Graph (DG), to improve the query efficiency. Specifically, DG is built offline to express the dominant relationship between records and top-k query is implemented as a graph traversal problem, i.e., Traveler algorithm. We prove theoretically that the size of search space (that is the number of retrieved records from the record set to answer top-k query) in our algorithm is directly related to the cardinality of skyline points in the record set (see Theorem 3). Considering I/O cost, we propose cluster-based storage schema to reduce I/O cost in Traveler algorithm. We also propose the cost estimation methods in this paper. Based on cost analysis, we propose an optimization technique, pseudorecord, to further improve the search efficiency. In order to handle the top-k query in the high-dimension record set, we also propose N-Way Traveler algorithm. In order to handle DG maintenance efficiently, we propose “Insertion” and “Deletion” algorithms for DG. Finally, extensive experiments demonstrate that our proposed methods have significant improvement over its counterparts, including both classical and state art of top-k algorithms.","Algorithm design and analysis,
Indexes,
Clustering algorithms,
Space exploration,
Maintenance engineering,
Aggregates"
Mitigating TSV-induced substrate noise in 3-D ICs using GND plugs,"Through-silicon vias (TSVs) in 3-D ICs are a major source of substrate noise, causing performance degradation of neighboring active devices. To reduce this noise, we propose using a tungsten-filled ground plug, a TSV-like structure that connects to ground (GND) and that partially or completely extends through the substrate. We evaluate the impact of plug size and placement on noise isolation. We compare the GND plug technique with two other noise mitigation techniques: using a thicker dielectric liner and using a backside ground plane. Our study demonstrates that the GND plug is a superior technology, effective in mitigating TSV-induced substrate noise by an order of magnitude when compared to the other two techniques. The GND plug offers a more practical noise isolation approach than using a backside ground plane. When compared with increased dielectric thickness, the GND plug offers a 33% reduction in foot print and permits a significantly reduced keep out zone.","Noise,
Substrates,
Plugs,
Through-silicon vias,
Dielectrics,
Transient analysis,
Silicon"
Configurable Multimode Embedded Floating-Point Units for FPGAs,"Performance of field-programmable gate arrays (FPGAs) used for floating-point applications is poor due to the complexity of floating-point arithmetic. Implementing floating-point units (FPUs) on FPGAs consume a large amount of resources. This makes FPGAs less attractive for use in floating-point intensive applications. Therefore, there is a need for embedded FPUs in FPGAs. However, if unutilized, embedded FPUs waste space on the FPGA die. To overcome this issue, we propose a flexible multimode embedded FPU for FPGAs that can be configured to perform a wide range of operations. The floating-point adder and multiplier in our embedded FPU can each be configured to perform one double-precision operation or two single-precision operations in parallel. To increase flexibility further, access to the large integer multiplier, adder and shifters in the FPU is provided. Benchmark circuits were implemented on both a standard Xilinx Virtex-II FPGA and on our FPGA with embedded FPU blocks. The results using our embedded FPUs showed a mean area improvement of 5.5 times and a mean delay improvement of 5.8 times for the double-precision benchmarks, and a mean area improvement of 3.8 times and a mean delay improvement of 4.2 times for the single-precision benchmarks. The embedded FPUs were also shown to provide significant area and delay benefits for fixed-point and integer circuits.","Field programmable gate arrays,
Adders,
Computer architecture,
Hardware,
Delay,
Benchmark testing,
Routing"
Silhouette Segmentation in Multiple Views,"In this paper, we present a method for extracting consistent foreground regions when multiple views of a scene are available. We propose a framework that automatically identifies such regions in images under the assumption that, in each image, background and foreground regions present different color properties. To achieve this task, monocular color information is not sufficient and we exploit the spatial consistency constraint that several image projections of the same space region must satisfy. Combining the monocular color consistency constraint with multiview spatial constraints allows us to automatically and simultaneously segment the foreground and background regions in multiview images. In contrast to standard background subtraction methods, the proposed approach does not require a priori knowledge of the background nor user interaction. Experimental results under realistic scenarios demonstrate the effectiveness of the method for multiple camera set ups.","Pixel,
Image color analysis,
Image segmentation,
Three dimensional displays,
Shape,
Cameras,
Silicon"
Cloud software upgrades: Challenges and opportunities,"The fast evolution pace for cloud computing software is on a collision course with our growing reliance on cloud computing. On one hand, cloud software must have the agility to evolve rapidly, in order to remain competitive; on the other hand, more and more critical services become dependent on the cloud and demand high availability through firm Service Level Agreements (SLAs) for cloud infrastructures. This race between the needs to increase both the cloud upgrade frequency and the service availability is unsustainable. In this paper we highlight challenges and opportunities for upgrades in the cloud. We survey the release histories of several cloud applications to analyze their evolution pace, and we discuss the shortcomings with current cloud upgrade mechanisms. We outline several solutions for sustaining this evolution while improving availability, by focusing on the novel characteristics of cloud computing. By discussing several promising directions for realizing this vision, we propose a research agenda for the future of software upgrades in the cloud.","Availability,
Cloud computing,
Encyclopedias,
Electronic publishing"
Hybrid CDN-P2P architectures for live video streaming: Comparative study of connected and unconnected meshes,"There are two main scalable methods for streaming live video over the Internet: Content Delivery Networks (CDNs) and Peer-to-Peer (P2P) networks. Though both have their own problems, P2P streaming systems challenge delivering video with constant quality and CDNs approaches require deployment of large number of servers throughout the Internet that is costly. Recently, using hybrid architectures based on both CDN and P2P networks has shown to be an efficient approach for large-scale video distribution over the Internet. This paper is compared the performance of two main hybrid CDN-P2P architectures includes: (i) CDN-P2P unconnected mesh in which independent P2P mesh networks are constructed under each CDN node, and (ii) CDN-P2P connected mesh in which CDN nodes and peers participate in construction of a single P2P mesh network. The comparison is preformed in addition, to the pure mesh-based P2P video streaming, using extensive simulation and based on different QoS metrics.",
Illumination estimation and cast shadow detection through a higher-order graphical model,"In this paper, we propose a novel framework to jointly recover the illumination environment and an estimate of the cast shadows in a scene from a single image, given coarse 3D geometry. We describe a higher-order Markov Random Field (MRF) illumination model, which combines low-level shadow evidence with high-level prior knowledge for the joint estimation of cast shadows and the illumination environment. First, a rough illumination estimate and the structure of the graphical model in the illumination space is determined through a voting procedure. Then, a higher order approach is considered where illumination sources are coupled with the observed image and the latent variables corresponding to the shadow detection. We examine two inference methods in order to effectively minimize the MRF energy of our model. Experimental evaluation shows that our approach is robust to rough knowledge of geometry and reflectance and inaccurate initial shadow estimates. We demonstrate the power of our MRF illumination model on various datasets and show that we can estimate the illumination in images of objects belonging to the same class using the same coarse 3D model to represent all instances of the class.","Lighting,
Light sources,
Geometry,
Three dimensional displays,
Estimation,
Proposals,
Image edge detection"
New Symmetric Key Cryptographic Algorithm Using Combined Bit Manipulation and MSA Encryption Algorithm: NJJSAA Symmetric Key Algorithm,"In the present work the authors have introduced a new advanced symmetric key cryptographic method called NJJSAA. The authors introduced new bit manipulation method for data encryption and decryption of any file. Nath et al already developed some symmetric key methods where they have used some randomized key matrix for encryption and decryption methods. In the present work the authors have used a bit manipulation method which include bit exchange, right shift and XOR operation on the incoming bits. To exchange bits the authors used a randomized key matrix of size (16×16) using the method developed by Nath et al. The present method allows the multiple encryption and multiple decryption. To initiate the encryption process a user has to enter a text-key which may be maximum of 16 characters long. From the text-key the authors have calculated randomization number and the encryption number. The method used was developed by Nath et al. A slight change in the text-key will change the randomization number and the encryption number quite a lot. Multiple encryption using bit exchange, bit right shift and XOR operations makes the system very secured. The present method is a block cipher method and it can be applied to encrypt data in sensor network or in mobile network. The advantage of the present method is that one can apply this method on top of any other standard algorithm such as DES, AES or RSA. The method is suitable to encrypt any large or small file. There is a scope to further enhance the present method of encryption.",
Energy-aware service execution,"The energy consumption of ICT infrastructures has increased considerably in the recent years. This has resulted in extensive research on dynamic power management strategies as well as data centre design and placement. The main problem with most of the proposed or existing approaches is that they do not fully take the distributed nature of and strong logical dependencies between executed services into account. However, without a comprehensive knowledge of the wider relationships between services, local power management strategies may be ineffectual or can even result in high aggregate energy cost. Understanding this relationship is useful for fine-grained energy-aware computing. For example, services that run on underutilised servers can be stopped or seamlessly migrated to other servers, so that the underutilised servers can be turned off. Alternatively, a re-binding process can be used if the cost of service migration is high. Such advantages can be fully exploited if the dependency between services is properly understood and meaningfully modelled. This paper introduces a conceptual architecture for an energy-aware service execution platform and compares three optimisation mechanisms to support dynamic service migration and rebinding.","Servers,
Energy consumption,
Power demand,
Hardware,
Delay,
Monitoring,
Computer architecture"
"A Cross-Layer Framework for Overhead Reduction, Traffic Scheduling, and Burst Allocation in IEEE 802.16 OFDMA Networks","IEEE 802.16 orthogonal frequency-division multiple access (OFDMA) downlink subframes have a special 2-D channel-time structure. Allocation resources from such a 2-D structure incur extra control overheads that hurt network performance. Existing solutions try to improve network performance by designing either the scheduler in the medium access control layer or the burst allocator in the physical layer, but the efficiency of overhead reduction is limited. In this paper, we point out the necessity of “codesigning” both the scheduler and the burst allocator to efficiently reduce overheads and improve network performance. Under the partial-usage-of-subcarriers model, we propose a cross-layer framework that covers overhead reduction, real-time and non-real-time traffic scheduling, and burst allocation. The framework includes a two-tier priority-based scheduler and a bucket-based burst allocator, which is more complete and efficient than prior studies. Both the scheduler and the burst allocator are tightly coupled together to solve the problem of arranging resources to data traffic. Given available space and bucket design from the burst allocator, the scheduler can well utilize the frame resource, reduce real-time traffic delays, and maintain fairness. On the other hand, with priority knowledge and resource assignment from the scheduler, the burst allocator can efficiently arrange downlink bursts to satisfy traffic requirements with low complexity. Through analysis, the cross-layer framework is validated to give an upper bound to overheads and achieve high network performance. Extensive simulation results verify that the cross-layer framework significantly increases network throughput, maintains long-term fairness, alleviates real-time traffic delays, and enhances frame utilization.","Real time systems,
Downlink,
Resource management,
Throughput,
Delay,
IEEE 802.16 Standards,
Arrays"
Development of the wireless ultra-miniaturized inertial measurement unit WB-4: Preliminary performance evaluation,"This paper presents the preliminary performance evaluation of our new wireless ultra-miniaturized inertial measurement unit (IMU) WB-4 by compared with the Vicon motion capture system. The WB-4 IMU primarily contains a mother board for motion sensing, a Bluetooth module for wireless data transmission with PC, and a Li-Polymer battery for power supply. The mother board is provided with a microcontroller and 9-axis inertial sensors (miniaturized MEMS accelerometer, gyroscope and magnetometer) to measure orientation. A quaternion-based extended Kalman filter (EKF) integrated with an R-Adaptive algorithm for automatic estimation of the measurement covariance matrix is implemented for the sensor fusion to retrieve the attitude. The experimental results showed that the wireless ultra-miniaturized WB-4 IMU could provide high accuracy performance at the angles of roll and pitch. The yaw angle which has reasonable performance needs to be further evaluated.",
Codes for a distributed caching based Video-on-Demand system,"We study the role of codes in the optimization and design of a large-scale Video-on-Demand (VoD) system based on distributed caching, that we have architected and built at Berkeley. We show how network codes can convert a combinatorial problem into a tractable one, and enable a fully distributed algorithm that jointly optimizes the three-fold problem of cache content placement, cache-to-users topology selection, and cache-to-users rate-allocation. While a description of the general VoD system optimization and design can be found in [1], this paper focuses on the critical role of codes in enabling our VoD system. Specifically, we motivate and describe a specific class of network codes, called DRESS codes, that offer desirable tradeoffs between cache-to-user and cache-to-cache communication aspects of the problem needed to sustain a scalable VoD system.",
PowerRush: A linear simulator for power grid,"As the increasing size of power grids, IR drop analysis has become more computationally challenging both in runtime and memory consumption. In this paper, we propose a linear complexity simulator named PowerRush, which consists of an efficient SPICE Parser, a robust circuit Builder and a linear solver. The proposed solver is a pure algebraic method which can provide an optimal convergence without geometric information. It is implemented by Algebraic Multigrid Preconditioned Conjugate Gradient method, in which an aggregation based algebraic multigrid with K-Cycle acceleration is adopted as a preconditioner to improve the robustness of conjugate gradient iterative method. In multigrid scheme, double pairwise aggregation technique is applied to the matrix graph in coarsening procedure to ensure low setup cost and memory requirement. Further, a K-Cycle multigrid scheme is adopted to provide Krylov subspace acceleration at each level to guarantee optimal or near optimal convergence. Experimental results on real power grids have shown that PowerRush has a linear complexity in runtime cost and memory consumption. The DC analysis of a 60 Million nodes power grid can be solved by PowerRush for 0.01mV accuracy in 170 seconds with 21.89GB memory used.",
New Sequential Partial-Update Least Mean M-Estimate Algorithms for Robust Adaptive System Identification in Impulsive Noise,The sequential partial-update least mean square (S-LMS)-based algorithms are efficient methods for reducing the arithmetic complexity in adaptive system identification and other industrial informatics applications. They are also attractive in acoustic applications where long impulse responses are encountered. A limitation of these algorithms is their degraded performances in an impulsive noise environment. This paper proposes new robust counterparts for the S-LMS family based on M-estimation. The proposed sequential least mean M-estimate (S-LMM) family of algorithms employ nonlinearity to improve their robustness to impulsive noise. Another contribution of this paper is the presentation of a convergence performance analysis for the S-LMS/S-LMM family for Gaussian inputs and additive Gaussian or contaminated Gaussian noises. The analysis is important for engineers to understand the behaviors of these algorithms and to select appropriate parameters for practical realizations. The theoretical analyses reveal the advantages of input normalization and the M-estimation in combating impulsive noise. Computer simulations on system identification and joint active noise and acoustic echo cancellations in automobiles with double-talk are conducted to verify the theoretical results and the effectiveness of the proposed algorithms.,"Algorithm design and analysis,
Signal processing algorithms,
System identification,
Least mean squares methods,
Adaptive filters"
Temperature Aware Dynamic Workload Scheduling in Multisocket CPU Servers,"In this paper, we propose a multitier approach for significantly lowering the cooling costs associated with fan subsystems without compromising the system performance. Our technique manages the fan speed by intelligently allocating the workload at the core level as well as at the CPU socket level. At the core level we propose a proactive dynamic thermal management scheme. We introduce a new predictor that utilizes the band-limited property of the temperature frequency spectrum. A big advantage of our predictor is that it does not require the costly training phase and still maintains high accuracy. At the socket level, we use control theoretic approach to develop a stable scheduler that reduces the cooling costs further by providing a better thermal distribution. Our thermal management scheme incorporates runtime workload characterization to perform efficient thermally aware scheduling. The experimental results show that our approach delivers an average cooling energy savings of 80% compared to the state of the art techniques. The reported results also show that our formal technique maintains stability while heuristic solutions fail in this aspect.","Sockets,
Cooling,
Thermal management,
Servers,
Temperature,
Heating,
Dynamic scheduling"
Azimuthal Mode Coupling in Coaxial Waveguides and Cavities With Longitudinally Corrugated Insert,"Coaxial resonant cavities with longitudinal corrugations on the inner conductor are used in high-frequency high-power gyrotrons as means to reduce the number of possible competing modes. For a sufficiently large number of corrugations, the analytical approach usually treats the surface corrugation as a homogeneous surface impedance to obtain simple formulas for the characteristic equation and field components. These formulas can be introduced to interaction codes in a quite straightforward way. Full-wave approaches that account for the azimuthal periodicity of the structure and consider azimuthal spatial harmonics to describe the field distributions have been also employed, increasing though the complexity of the solution and the effort given in numerical calculations. In this paper, a full-wave code is used in an attempt to identify the way that the azimuthal spatial terms contribute to the reformation of the eigenvalue spectrum and propose a criterion for the selection of the spatial terms that should be taken into account for accurate enough calculations.","Eigenvalues and eigenfunctions,
Harmonic analysis,
Cavity resonators,
Corrugated surfaces,
Mathematical model,
Indexes,
Equations"
Evaluation of gyroscope-embedded mobile phones,"Many mobile phone applications such as pedometers and navigation systems rely on orientation sensors that most smartphones are now equipped with. Unfortunately, these sensors rely on measured accelerometer and magnetic field data to determine the orientation. Thus, accelerations upon the phone which arise from everyday use alter orientation information. Similarly, external magnetic interferences from indoor/urban settings affect the heading calculation, resulting in inaccurate directional information. The inability to determine the orientation during everyday use inhibits many potential mobile applications development. In this work, we exploit the newly built-in gyroscope in the Nexus S smartphone to address the interference problems associated with the orientation sensor. We first perform drift error analysis and apply this to gyroscope calculations. We test simple as well as complex rotations seen in walking applications. We lastly test the gyroscope's resistance to described interferences. Experiments show angular calculations with percent error no larger than 6% from actual rotated values. Further, we are able to determine the phone's orientation at any time, in magnetically-interfered areas, with the phone accelerating. With this accurate information we can virtually orient the phone to better use mobile-acquired data. This shows that the presence of a gyroscope in smartphones will certainly aid in numerous applications.","Gyroscopes,
Magnetic sensors,
Acceleration,
Accelerometers,
Mobile handsets,
Mobile communication"
Home automation design using 6LoWPAN wireless sensor networks,"Wireless sensor and actuator networks (WS&ANs) are a new technology based on networks of small radio-enabled embedded devices that are being deployed in areas such as environmental monitoring, vehicle tracking, building management, body monitoring and other applications. Power sources for network nodes are often limited, which imposes restrictions on hardware resources and their use by the underlying embedded software. We propose a new wireless sensor network architecture that is especially designed for the task of home automation. Our system relies on a low power WS&AN that employs energy harvesting techniques to maximize node lifetime and an embedded residential gateway that offers user interaction and secure connectivity to the outside world. The advantages of our system are its scalability, low power, self sufficiency and versatility.","Logic gates,
Wireless sensor networks,
Monitoring,
Home automation,
Batteries,
Energy harvesting,
Hardware"
Video Super-Resolution Using Simultaneous Motion and Intensity Calculations,"In this paper, we propose an energy-based algorithm for motion-compensated video super-resolution (VSR) targeted on upscaling of standard definition (SD) video to high-definition (HD) video. Since the motion (flow field) of the image sequence is generally unknown, we introduce a formulation for the joint estimation of a super-resolution (SR) sequence and its flow field. Via the calculus of variations, this leads to a coupled system of partial differential equations for image sequence and motion estimation. We solve a simplified form of this system and, as a by-product, we indeed provide a motion field for super-resolved sequences. To the best of our knowledge, computing super-resolved flows has not been done before. Most advanced SR methods found in literature cannot be applied to general video with arbitrary scene content and/or arbitrary optical flows, as it is possible with our simultaneous VSR method. A series of experiments shows that our method outperforms other VSR methods when dealing with general video input and that it continues to provide good results even for large scaling factors up to 8 × 8.","Spatial resolution,
Image sequences,
Signal resolution,
Optical imaging,
Interpolation,
Spatiotemporal phenomena"
Fault-Tolerant Bipancyclicity of Faulty Hypercubes Under the Generalized Conditional-Fault Model,"Let F_v be a set of faulty nodes in an n-dimensional hypercube, denoted by Q_n. Also, let F_e be a set of faulty edges in which at least one end-node of each edge is faulty. An edge in Q_n is said to be critical if it is either fault-free or in F_e. In this paper, we prove that, for up to 2n-4 faulty nodes and/or edges, an n-dimensional hypercube contains a fault-free cycle of every even length from 4 to 2^n-2oF_vo in which each node is incident to at least two critical edges. Our result improves on the previously best known results reported in the literature.","Hypercubes,
Signal processing algorithms,
Fault tolerance,
Fault tolerant systems,
Algorithm design and analysis,
Program processors,
Embedded systems"
Tardos Fingerprinting Codes in the Combined Digit Model,"We formalize a new attack model for collusion secure codes, incorporating attacks on the underlying watermarking scheme as well as cut-and-paste attacks traditionally considered for collusion secure codes. We use this model to analyze the collusion resistance of two versions of the Tardos code, both for binary and nonbinary alphabets. The model allows us to consider different signal processing attacks on the content, namely the addition of noise and averaging attacks. The latter may result in content segments that have multiple watermarks embedded. We study two versions of the q-ary Tardos code in which the accusation method has been modified so as to allow for the detection of multiple symbols in the same content segment. We show that both variants yield efficient codes in the new model, parametrized for realistic attacker strengths.","Watermarking,
Detectors,
Analytical models,
Noise,
Mathematical model"
Corrective Gradient Refinement for mobile robot localization,"Particle filters for mobile robot localization must balance computational requirements and accuracy of localization. Increasing the number of particles in a particle filter improves accuracy, but also increases the computational requirements. Hence, we investigate a different paradigm to better utilize particles than to increase their numbers. To this end, we introduce the Corrective Gradient Refinement (CGR) algorithm that uses the state space gradients of the observation model to improve accuracy while maintaining low computational requirements. We develop an observation model for mobile robot localization using point cloud sensors (LIDAR and depth cameras) with vector maps. This observation model is then used to analytically compute the state space gradients necessary for CGR. We show experimentally that the resulting complete localization algorithm is more accurate than the Sampling/Importance Resampling Monte Carlo Localization algorithm, while requiring fewer particles.","Computational modeling,
Proposals,
Sensors,
Robots,
Accuracy,
Vectors,
Three dimensional displays"
SCC: A Flexible Architecture for Many-Core Platform Research,"The Single-chip Cloud Computer (SCC) experimental processor by Intel Labs is a ""concept vehicle"" aimed at scaling future multicore processors and serving as a software research platform.","Cloud computing,
Software development,
Software architecture"
Survey: Real-Time Tumor Motion Prediction for Image-Guided Radiation Treatment,"Tumor motion caused by patient breathing creates challenges for accurate radiation dose delivery to a tumor while sparing healthy tissues. Image-guided radiation therapy (IGRT) helps, but there's a lag time between tumor position acquisition and dose delivered to that position. An efficient and accurate predictive model is thus an essential requirement for IGRT success.","Tumors,
Artificial neural networks,
Adaptive filters,
Predictive models,
Nonlinear filters,
Maximum likelihood detection,
Kalman filters,
Biomedical image processing"
Textured 3D face recognition using biological vision-based facial representation and optimized weighted sum fusion,"This paper proposes a novel biological vision-based facial description, namely Perceived Facial Images (PFIs), aiming to highlight intra-class and inter-class variations of both facial range and texture images for textured 3D face recognition. These generated PFIs simulate the response of complex neurons to gradient information within a certain neighborhood and possess the properties of being highly distinctive and robust to affine illumination and geometric transformation. Based on such an intermediate facial representation, SIFT-based matching is further carried out to calculate similarity scores between a given probe face and the gallery ones. Because the facial description generates a PFI for each quantized gradient orientation of range and texture faces, we then propose a score level fusion strategy which optimizes the weights using a genetic algorithm in a learning step. Evaluated on the entire FRGC v2.0 database, the rank-one recognition rate using only 3D or 2D modality is 95.5% and 95.9%, respectively; while fusing both modalities, i.e. range and texture-based PFIs, the final accuracy is 98.0%, demonstrating the effectiveness of the proposed biological vision-based facial description and the optimized weighted sum fusion.","Face,
Three dimensional displays,
Face recognition,
Neurons,
Lighting,
Solid modeling"
Modeling Short-Channel Effect of Elliptical Gate-All-Around MOSFET by Effective Radius,"Gate-all-around (GAA) MOSFETs with elliptical cross section are studied in this letter. From the solution of the Poisson equation, an effective radius concept (Reff) is proposed to convert elliptical GAA MOSFETs into equivalent circular GAA MOSFETs for the study of short-channel effect. The Reff approach is used to estimate the subthreshold swing, drain-induced barrier lowering, and Qon/Qoff ratio of elliptical GAA MOSFETs. The predictions are validated by numerical 3-D TCAD simulations, and good agreement is achieved. Reff is also simplified to an area-to-perimeter ratio of the channel under some special conditions, and its physical meaning is explained.","MOSFET circuits,
Logic gates,
Numerical models,
Electron devices,
Silicon,
Mathematical model,
Predictive models"
Detection of Critical Current Distribution of YBCO-Coated Conductors Using Permanent Magnet Method,"We developed a non-destructive and contactless system for measuring the critical current (Ic) in YBa2Cu3O7-δ (YBCO)-coated conductors by using a permanent magnet (Sm2Co17). This Ic measurement method is based on the repulsive force (Fr) between the magnet and the shielding current in high-temperature superconductor-coated conductors. We measured Fr using a high-resolution load sensor and found that accurate Fr could be determined without the effect of thick copper film on the YBCO thin film and Hastelloy tape of the substrate. We can determine Ic from Fr0, which is the maximum repulsive force determined from an extrapolated value of the Fr vs. L curve for L = 0 mm, described in our previous paper. We show that the permanent magnet method can be used to determine the longitudinal Ic distribution and large-scale defects in YBCO-coated conductors. In addition, it turned out from this experiment that the permanent magnet method was effective to rapidly measure the longitudinal Ic distribution of long-scale coated conductors.",
Anomalous Loss Performance for Mixed Real-Time and TCP Traffic in Routers With Very Small Buffers,"In the past few years there has been vigorous debate regarding the size of buffers required at core Internet routers. Recent arguments supported by theory and experimentation show that under certain conditions, core router buffer sizes of a few tens of packets suffice for realizing acceptable end-to-end TCP throughputs. This is a significant step toward the realization of optical packet switched (OPS) networks, which are inherently limited in their ability to buffer optical signals. However, prior studies have largely ignored the presence of real-time traffic, which is increasing in importance as a source of revenue for Internet service providers. In this paper, we study the interaction that happens between real-time (open-loop) and TCP (closed-loop) traffic when they multiplex at buffers of very small size (few tens of packets) and make a significant discovery - namely that in a specific range of buffer size, real-time traffic losses increase as buffer size becomes larger. Our contributions pertaining to this anomalous behavior are threefold. First, we exhibit this anomalous loss performance for real-time traffic via extensive simulations using synthetic traffic and real video traces. Second, we develop quantitative models that reveal the dynamics of buffer sharing between real-time and TCP traffic that lead to this behavior. Third, we show how various factors such as the nature of real-time traffic, mixture of long-lived and short-lived TCP flows, and packet sizes impact the severity of the anomaly. Our study is the first to consider interactions between real-time and TCP traffic in very small (potentially all-optical) buffers and informs router manufacturers and network operators of the factors to consider when dimensioning such small buffer sizes for desired performance balance between real-time and TCP traffic.","Optical buffering,
Real time systems,
Throughput,
Optical packet switching,
Optical switches,
Internet,
Streaming media"
Ultrametric Semantics of Reactive Programs,"We describe a denotational model of higher-order functional reactive programming using ultra metric spaces and non expansive maps, which provide a natural Cartesian closed generalization of causal stream functions and guarded recursive definitions. We define a type theory corresponding to this semantics and show that it satisfies normalization. Finally, we show how to efficiently implement reactive programs written in this language using an imperatively updated data flow graph, and give a separation logic proof that this low-level implementation is correct with respect to the high-level semantics.","Semantics,
Calculus,
Bismuth,
Mathematical model,
Syntactics,
Delay"
A novel hybrid excitation flux switching synchronous machine for a high-speed hybrid electric vehicle applications,"Hybrid excitation machines (HEMs) that consist of permanent magnet (PM) and field excitation coil (FEC) as their main flux sources has several attractive features compared to interior permanent magnet synchronous machines (IPMSM) conventionally employed in hybrid electric vehicles (HEVs). Among various types of HEM, the machine with both permanent magnet and field excitation coil located on the stator has the advantage of robust rotor structure similar as switch reluctance machine (SRM). In addition, the variable flux control capabilities from field excitation coil make this machine becoming more attractive to be applied for high-speed motor drive systems, coupled with reduction gear. This HEM can be categorized as hybrid excitation flux switching synchronous machine (HEFSSM). In this paper, a novel 12Slot-10Pole HEFSSM where the field excitation coil is wounded in radial direction in the stator is proposed for traction drives in HEVs. The design target of the proposed machine is a maximum torque of 210Nm with reduction gear ratio of 4:1, a maximum power of 123kW, a maximum power density more than 3.5kW/kg, and a maximum speed of 20,000r/min with similar restrictions and specifications in IPMSM used for LEXUS RX400h. The deterministic design optimization method based on 2D-FEA is used to treat design parameters defined in rotor, armature coil slot and field excitation coil slot until the target performances are achieved, under maximum current density condition for both armature coil and field excitation coil. The final results show that the final design HEFSSM is able to keep the same torque density in existing IPMSM installed on a commercial SUV-HEV.","Rotors,
Torque,
Coils,
Stators,
Hybrid electric vehicles,
Traction motors,
Permanent magnets"
Store-and-Feedforward Adaptive Gaming System for Hand-Finger Motion Tracking in Telerehabilitation,"This paper presents a telerehabilitation system that encompasses a webcam and store-and-feedforward adaptive gaming system for tracking finger-hand movement of patients during local and remote therapy sessions. Gaming-event signals and webcam images are recorded as part of a gaming session and then forwarded to an online healthcare content management system (CMS) that separates incoming information into individual patient records. The CMS makes it possible for clinicians to log in remotely and review gathered data using online reports that are provided to help with signal and image analysis using various numerical measures and plotting functions. Signals from a 6 degree-of-freedom magnetic motion tracking system provide a basis for video-game sprite control. The MMT provides a path for motion signals between common objects manipulated by a patient and a computer game. During a therapy session, a webcam that captures images of the hand together with a number of performance metrics provides insight into the quality, efficiency, and skill of a patient.","Games,
Tracking,
Hardware,
Software,
Content management,
Databases,
Instruments"
An analysis of mOSAIC ontology for Cloud resources annotation,"The easiness of managing and configuring resources and the low cost needed for setup and maintaining Cloud services have made Cloud Computing widespread. Several commercial vendors now offer solutions based on Cloud architectures. More and more providers offer new different services every month, following their customers needs. Anyway, it is very hard to find a single provider which offers all services needed by end users. Furthermore, different vendors propose different architectures for their Cloud systems and usually these are not compatible. Very few efforts have been done in order to propose a unified standard for Cloud Computing. This is a problem, since different Cloud systems and vendors have different ways to describe and invoke their services, to specify requirements and to communicate. Hence a way to provide a common access to Cloud services and to discover and use required services in Cloud federations is appealing. mOSAIC project addresses these problems by defining a common ontology and it aims at developing an open-source platform that enables applications to negotiate Cloud services as requested by users. The main problem in defining the mOSAIC ontology is in the heterogeneity of terms used by Clouds vendors, and in the number of standards which refer to Cloud Systems with different terminology. In this work the mOSAIC Cloud Ontology is described. It has been built by analysing Cloud standards and proposals. The Ontology has been then refined by introducing individuals from real Cloud systems.","Cloud computing,
Ontologies,
NIST,
Computer architecture,
Unified modeling language,
Taxonomy"
Predicting the Virtual Temperature of Web-Blog Articles as a Measurement Tool for Online Popularity,"A Blog provides commentary, news, or content on a particular subject. The important part of many blogs is interactive format. Sometimes, there is a heated debate on a topic, any article becomes a political or sociological issue. However, users not pay much attention to most articles. So, how we can predict the popularity of articles in advance and what is a standard for popularity? In this paper, we propose a methodology to predict the popularity of an article. First, we use an analogy between the virtual temperature and the popularity of the on-line articles. Thus, we define four different types of discrete temperature scale, such as explosive, hot, warm, and cold, according to the number of reviews in the saturated state of the article. We are concerned with how to predict the final temperature of the submitted articles in the internet Web-blog space. An experimental data set was collected from the articles submitted to ""SEOPRISE"", a well known political discussion blog in Korea that more than 50,000 users visit per day. The hit count is used as a factor to predict the popularity, analogous to the number of viewers in the popularity of movies. We calculated the saturation point using the variation of hit count over the lifetime. We derived a sound regression model to predict the popularity temperature of the subject article in terms of the hit counts at the saturation point via the correlation coefficient of hourly hit count and hit count of the saturation point. We can predict the popularity temperature of Internet discussion articles using the hit count of the saturation point with more than 70% accuracy, exploiting only the first 30 minutes' information. Because of low predictive value of explosive, the results of prediction were worse than we think. In the hot, warm, and cold categories, we can predict more than 86% accuracy from 30 minutes and more than 90% accuracy from 70 minutes.","Blogs,
Correlation,
Explosives,
Predictive models,
Mathematical model,
Motion pictures,
Error analysis"
Analysis of an Adaptive Sampler Based on Weber's Law,"Weber's law suggests a logarithmic relationship between perceptual stimuli and human perception. The Weber sampler is an adaptive, nonuniform sampling mechanism that exploits Weber's law to sample the signal at a minimum rate without significant perceptual degradation. In this paper, we introduce and analyze a regularized Weber sampler for smooth deterministic signals as well as smooth random processes. While analysis for a fixed Weber constant δ is analytically intractable except for some special cases, we exploit the fact that the Weber constant is usually small. Under suitable assumptions, for deterministic signals, we provide analytical approximations to the number of samples in a unit time interval and the intersample times. For a random signal, we give analytical approximations to the expectation and probability distribution function of the respective quantities. Our class of deterministic as well as random signals is quite wide, and in particular covers bandlimited signals and signals satisfying second order ordinary differential equations. We also present a number of simulations to demonstrate that our approximations are good up to a Weber constant of 0.2, which is the regime of practical interest. Our results provide a source model for the Weber sampler, which can be used in the study of transmission of perceptual stimuli signals over communication links.","Approximation methods,
Haptic interfaces,
Humans,
Quantization,
Communication networks,
Mathematical model,
Visualization"
An adaptive approach to impact analysis from change requests to source code,"The paper presents an adaptive approach to perform impact analysis from a given change request (e.g., a bug report) to source code. Given a textual change request, a single snapshot (release) of source code, indexed using Latent Semantic Indexing, is used to estimate the impact set. Additionally, the approach configures the best-fit combination of information retrieval, dynamic analysis, and data mining of past source code commits to produce an improved impact set. The tandem operation of the three techniques sets it apart from other related solutions.","Software,
Couplings,
Maintenance engineering,
History,
Association rules,
Indexing"
Generating Missions and Spaces for Adaptable Play Experiences,"This paper investigates strategies to generate levels for action-adventure games. For this genre, level design is more critical than for rule-driven genres such as simulation or rogue-like role-playing games, for which procedural level generation has been successful in the past. The approach outlined by this article distinguishes between missions and spaces as two separate structures that need to be generated in two individual steps. It discusses the merits of different types of generative grammars for each individual step in the process. Notably, the approach acknowledges that the online generation of levels needs to be tailored strictly to the actual experience of a player. Therefore, the approach incorporates techniques to establish and exploit player models in actual play.","Games,
Space missions,
Grammar,
Special issues and sections,
IEEE Transactions on Computational Intelligence and AI in Games,
Tiles,
Algorithm design and analysis"
Locality Sensitive Outlier Detection: A ranking driven approach,"Outlier detection is fundamental to a variety of database and analytic tasks. Recently, distance-based outlier detection has emerged as a viable and scalable alternative to traditional statistical and geometric approaches. In this article we explore the role of ranking for the efficient discovery of distance-based outliers from large high dimensional data sets. Specifically, we develop a light-weight ranking scheme that is powered by locality sensitive hashing, which reorders the database points according to their likelihood of being an outlier. We provide theoretical arguments to justify the rationale for the approach and subsequently conduct an extensive empirical study highlighting the effectiveness of our approach over extant solutions. We show that our ranking scheme improves the efficiency of the distance-based outlier discovery process by up to 5-fold. Furthermore, we find that using our approach the top outliers can often be isolated very quickly, typically by scanning less than 3% of the data set.",
An evolutionary multiobjective optimization approach to component-based software architecture design,"The design of software architecture is one of the difficult tasks in the modern component-based software development which is based on the idea that develop software systems by assembling appropriate off-the-shelf components with a well-defined software architecture. Component-based software development has achieved great success and been extensively applied to a large range of application domains from realtime embedded systems to online web-based applications. In contrast to traditional approaches, it requires software architects to address a large number of non-functional requirements that can be used to quantify the operation of system. Moreover, these quality attributes can be in conflict with each other. In practice, software designers try to come up with a set of different architectural designs and then identify good architectures among them. With the increasing scale of architecture, this process becomes time-consuming and error-prone. Consequently architects could easily end up with some suboptimal designs because of large and combinatorial search space. In this paper, we introduce AQOSA (Automated Quality-driven Optimization of Software Architecture) toolkit, which integrates modeling technologies, performance analysis techniques, and advanced evolutionary multiobjective optimization algorithms (i.e. NSGA-II, SPEA2, and SMS-EMOA) to improve non-functional properties of systems in an automated manner.",
On the stability of switched behavioral systems,In this paper we study switched systems from a behavioral point of view. We define a switched behavioral system in terms of a bank of behaviors without referring to the notion of state. Moreover we give sufficient conditions for the stability of a switched behavior in terms of the behaviors in the underlying bank.,"Switches,
Lyapunov methods,
Trajectory,
Polynomials,
Stability analysis,
Switched systems,
Differential equations"
Land-Mine Detection With Ground-Penetrating Radar Using Multistream Discrete Hidden Markov Models,"We propose a multistream discrete hidden Markov model (DHMM) framework and apply it to the problem of land-mine detection using ground-penetrating radar (GPR). We hypothesize that each signature (mine or nonmine) can be characterized better by multiple synchronous sequences representing features that capture different environments and different radar characteristics. This paper is motivated by the fact that mines and clutter objects can have different characteristics depending on the mine type, soil and weather conditions, and burial depth. Thus, ideally different sets of specialized feature extraction mechanisms may be needed to achieve high detection and low false alarm rates. In order to fuse the different modalities, a multistream DHMM that includes a stream relevance weighting component is developed. The relevance weight of each stream depends on the symbols and the states. We reformulate the Baum-Welch and the minimum classification error/gradient probabilistic descent learning algorithms to include stream relevance weights and partial state probabilities. We generalize their objective functions and derive the necessary conditions to update all model parameters simultaneously. The results on a synthetic data set and a collection of GPR signatures show that the proposed multistream DHMM framework outperforms the basic single-stream DHMM where all the streams are treated equally important.",
Multitask Learning for Protein Subcellular Location Prediction,"Protein subcellular localization is concerned with predicting the location of a protein within a cell using computational methods. The location information can indicate key functionalities of proteins. Thus, accurate prediction of subcellular localizations of proteins can help the prediction of protein functions and genome annotations, as well as the identification of drug targets. Machine learning methods such as Support Vector Machines (SVMs) have been used in the past for the problem of protein subcellular localization, but have been shown to suffer from a lack of annotated training data in each species under study. To overcome this data sparsity problem, we observe that because some of the organisms may be related to each other, there may be some commonalities across different organisms that can be discovered and used to help boost the data in each localization task. In this paper, we formulate protein subcellular localization problem as one of multitask learning across different organisms. We adapt and compare two specializations of the multitask learning algorithms on 20 different organisms. Our experimental results show that multitask learning performs much better than the traditional single-task methods. Among the different multitask learning methods, we found that the multitask kernels and supertype kernels under multitask learning that share parameters perform slightly better than multitask learning by sharing latent features. The most significant improvement in terms of localization accuracy is about 25 percent. We find that if the organisms are very different or are remotely related from a biological point of view, then jointly training the multiple models cannot lead to significant improvement. However, if they are closely related biologically, the multitask learning can do much better than individual learning.","Proteins,
Organisms,
Bioinformatics,
Biological information theory,
Genomics,
Drugs,
Learning systems,
Kernel,
Cells (biology),
Biomembranes"
PLS-Based Gene Selection and Identification of Tumor-Specific Genes,"In view of the characteristics of high-dimensional small sample, strong relevance, and high noise of the identification of tumor-specific genes on microarray, a novel partial least squares (PLS) based gene-selection method, which synthesizes genetic relatedness and is suitable for multicategory classification, is presented. Using the explanation difference of independent variables on dependent variable (class), we define three indicators for global gene selection, which takes into accounts the combined effects of all the genes and the correlation among the genes. Integrated with the linear kernel support vector classifier (SVC), the proposed method is tested by MIT acute myeloid leukemia/acute lymphoblastic leukemia (AML/ALL) and small round blue cell tumors (SRBCT) data sets. A subset of specific genes with small numbers and high identification are obtained. The results indicate that our proposed PLS-based method for tumor-specific genes selection is highly efficient. Compared to the literature, the selected specific genes from both two-category dataset AML/ALL and multicategory dataset SRBCT are credible. Further investigation shows that the proposed gene-selection method is robust. Overall, the proposed method can effectively solve feature-selection problem on high-dimensional small sample. At the same time, it has good performance for multicategory classification as well.","Least squares methods,
Mathematical model,
Tumors,
Gene expression"
Providing End-to-End Secure Communications in Wireless Sensor Networks,"In many Wireless Sensor Networks (WSNs), providing end to end secure communications between sensors and the sink is important for secure network management. While there have been many works devoted to hop by hop secure communications, the issue of end to end secure communications is largely ignored. In this paper, we design an end to end secure communication protocol in randomly deployed WSNs. Specifically, our protocol is based on a methodology called differentiated key pre-distribution. The core idea is to distribute different number of keys to different sensors to enhance the resilience of certain links. This feature is leveraged during routing, where nodes route through those links with higher resilience. Using rigorous theoretical analysis, we derive an expression for the quality of end to end secure communications, and use it to determine optimum protocol parameters. Extensive performance evaluation illustrates that our solutions can provide highly secure communications between sensor nodes and the sink in randomly deployed WSNs. We also provide detailed discussion on a potential attack (i.e. biased node capturing attack) to our solutions, and propose several countermeasures to this attack.",
Power-Efficient Hardware Architecture of K-Means Clustering With Bayesian-Information-Criterion Processor for Multimedia Processing Applications,"A power-efficient K-Means hardware architecture that can automatically estimate the number of clusters in the clustering process is proposed. The contributions of this work include two main aspects. The first is the integration of the hierarchical data sampling in the hardware to accelerate the clustering speed. The second is the development of the “Bayesian-Information-Criterion (BIC) Processor” to estimate the number of clusters of K-Means. The architecture of the “BIC Processor” is designed based on the simplification of the BIC computations, and the precision of the logarithm function is also analyzed. The experiments show that the proposed architecture can be employed in different multimedia applications, such as motion segmentation and edge-adaptive noise reduction. Besides, the gate count of the hardware is 51 K with the 90-nm complimentary metal-oxide-semiconductor technology. It is also shown that this work can achieve high efficiency compared with a GPU, and the power consumption scales well with the number of clusters and the number of dimensions. The power consumption ranges between 10.72 and 12.95 mW in different modes when the operating frequency is 233 MHz.",
Design criteria for lattice network coding,"The compute-and-forward (C-F) relaying strategy proposed by Nazer and Gastpar is a powerful new approach to physical-layer network coding. Nazer-Gastpars construction of C-F codes relies on asymptotically-good lattice partitions that require the dimension of lattices to tend to infinity. Yet it remains unclear how such C-F codes can be constructed and analyzed under practical constraints. Motivated by this, an algebraic approach was taken to compute-and-forward, which provides a framework to study C-F codes constructed from finite-dimensional lattice partitions. Building on the algebraic framework, this paper moves one step further; it aims to derive the design criteria for the C-F codes constructed from finite-dimensional lattice partitions (also referred to as lattice network codes). It is shown that the receiver parameters {aℓ} and α should be chosen such that the quantity Q = |α|2 + SNRΣℓ=1L ||αhℓ - αℓ||2 is minimized, and the lattice partition should be designed such that the minimum inter-coset distance is maximized. These design criteria imply that finding the optimal receiver parameters is equivalent to solving a shortest vector problem, and designing good lattice partitions can be reduced to the design of good linear codes for complex Construction A.","Lattices,
Receivers,
Network coding,
Decoding,
Hypercubes,
Linear code,
Human computer interaction"
Smart grid communication requirements for the high voltage power system,"The vision of a smarter grid very much depends on a fast communication infrastructure that can provide near realtime data delivery and can handle security issues. These issues become more and more critical when we imagine having phasor measurement units everywhere in the power grid. The latency and bandwidth requirements for smart grid are two very critical issues among these. This paper attempts to provide a simulation approach to understand these issues. A possible communication structure is then presented with the results on the latency and bandwidth for IEEE 14 bus, 30 bus, and 57 bus systems.",
Multispectral interest points for RGB-NIR image registration,"This paper explores the use of joint colour and near-infrared (NIR) information for feature based matching and image registration. In particular, we investigate multispectral generalisations of two popular interest point detectors (Harris and difference of Gaussians), and show that these give a marked improvement in performance when the extra NIR channel is available. We also look at the problem of multimodal RGB to NIR registration, and propose a variant of the SIFT descriptor that gives improved performance.","Detectors,
Image color analysis,
Joints,
Conferences,
Laplace equations,
Computer vision"
