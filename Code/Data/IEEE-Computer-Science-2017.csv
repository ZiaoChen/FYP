Title,Abstract,Keywords
Structural Minimax Probability Machine,"Minimax probability machine (MPM) is an interesting discriminative classifier based on generative prior knowledge. It can directly estimate the probabilistic accuracy bound by minimizing the maximum probability of misclassification. The structural information of data is an effective way to represent prior knowledge, and has been found to be vital for designing classifiers in real-world problems. However, MPM only considers the prior probability distribution of each class with a given mean and covariance matrix, which does not efficiently exploit the structural information of data. In this paper, we use two finite mixture models to capture the structural information of the data from binary classification. For each subdistribution in a finite mixture model, only its mean and covariance matrix are assumed to be known. Based on the finite mixture models, we propose a structural MPM (SMPM). SMPM can be solved effectively by a sequence of the second-order cone programming problems. Moreover, we extend a linear model of SMPM to a nonlinear model by exploiting kernelization techniques. We also show that the SMPM can be interpreted as a large margin classifier and can be transformed to support vector machine and maxi-min margin machine under certain special conditions. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of SMPM.",
Effective and Efficient Global Context Verification for Image Copy Detection,"To detect illegal copies of copyrighted images, recent copy detection methods mostly rely on the bag-of-visual-words (BOW) model, in which local features are quantized into visual words for image matching. However, both the limited discriminability of local features and the BOW quantization errors will lead to many false local matches, which make it hard to distinguish similar images from copies. Geometric consistency verification is a popular technology for reducing the false matches, but it neglects global context information of local features and thus cannot solve this problem well. To address this problem, this paper proposes a global context verification scheme to filter false matches for copy detection. More specifically, after obtaining initial scale invariant feature transform (SIFT) matches between images based on the BOW quantization, the overlapping region-based global context descriptor (OR-GCD) is proposed for the verification of these matches to filter false matches. The OR-GCD not only encodes relatively rich global context information of SIFT features but also has good robustness and efficiency. Thus, it allows an effective and efficient verification. Furthermore, a fast image similarity measurement based on random verification is proposed to efficiently implement copy detection. In addition, we also extend the proposed method for partial-duplicate image detection. Extensive experiments demonstrate that our method achieves higher accuracy than the state-of-the-art methods, and has comparable efficiency to the baseline method based on the BOW quantization.",
Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,"State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network(RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features-using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3], our detection system has a frame rate of 5 fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.",
Event-Triggered Fault Detection of Nonlinear Networked Systems,"This paper investigates the problem of fault detection for nonlinear discrete-time networked systems under an event-triggered scheme. A polynomial fuzzy fault detection filter is designed to generate a residual signal and detect faults in the system. A novel polynomial event-triggered scheme is proposed to determine the transmission of the signal. A fault detection filter is designed to guarantee that the residual system is asymptotically stable and satisfies the desired performance. Polynomial approximated membership functions obtained by Taylor series are employed for filtering analysis. Furthermore, sufficient conditions are represented in terms of sum of squares (SOSs) and can be solved by SOS tools in MATLAB environment. A numerical example is provided to demonstrate the effectiveness of the proposed results.",
Adaptive Fuzzy Control for Nonstrict-Feedback Systems With Input Saturation and Output Constraint,"This paper presents an adaptive fuzzy control approach for a category of uncertain nonstrict-feedback systems with input saturation and output constraint. A variable separation approach is introduced to overcome the difficulty arising from the nonstrict-feedback structure. The problem of input saturation is solved by introducing an auxiliary design system, and output constraint is handled by utilizing a barrier Lyapunov function. Combing fuzzy logic system with the adaptive backstepping technique, the semi-global boundedness of all variables in the closed-loop systems is guaranteed, and the tracking error is driven to the origin with a small neighborhood. The stability of the closed-loop systems is proved, and the simulation results reveal the effectiveness of the proposed approach.","Adaptive systems,
Backstepping,
Fuzzy control,
Nonlinear systems,
Closed loop systems,
Artificial neural networks,
Process control"
Fully Convolutional Networks for Semantic Segmentation,"Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional networks achieve improved segmentation of PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image.",
Energy-Aware Data Allocation With Hybrid Memory for Mobile Cloud Systems,"Resource scheduling is one of the most important issues in mobile cloud computing due to the constraints in memory, CPU, and bandwidth. High energy consumption and low performance of memory accesses have become overwhelming obstacles for chip multiprocessor (CMP) systems used in cloud systems. In order to address the daunting “memory wall” problem, hybrid on-chip memory architecture has been widely investigated recently. Due to its advantages in size, real-time predictability, power, and software controllability, scratchpad memory (SPM) is a promising technique to replace the hardware cache and bridge the processor-memory gap for CMP systems. In this paper, we present a novel hybrid on-chip SPM that consists of a static random access memory (RAM), a magnetic RAM (MRAM), and a zero-capacitor RAM for CMP systems by fully taking advantages of the benefits of each type of memory. To reduce memory access latency, energy consumption, and the number of write operations to MRAM, we also propose a novel multidimensional dynamic programming data allocation (MDPDA) algorithm to strategically allocate data blocks to each memory. Experimental results show that the proposed MDPDA algorithm can efficiently reduce the memory access cost and extend the lifetime of MRAM.",
Health-CPS: Healthcare Cyber-Physical System Assisted by Cloud and Big Data,"The advances in information technology have witnessed great progress on healthcare technologies in various domains nowadays. However, these new technologies have also made healthcare data not only much bigger but also much more difficult to handle and process. Moreover, because the data are created from a variety of devices within a short time span, the characteristics of these data are that they are stored in different formats and created quickly, which can, to a large extent, be regarded as a big data problem. To provide a more convenient service and environment of healthcare, this paper proposes a cyber-physical system for patient-centric healthcare applications and services, called Health-CPS, built on cloud and big data analytics technologies. This system consists of a data collection layer with a unified standard, a data management layer for distributed storage and parallel computing, and a data-oriented service layer. The results of this study show that the technologies of cloud and big data can be used to enhance the performance of the healthcare system so that humans can then enjoy various smart healthcare applications and services.",
Neural Control of Bimanual Robots With Guaranteed Global Stability and Motion Precision,"Robots with coordinated dual arms are able to perform more complicated tasks that a single manipulator could hardly achieve. However, more rigorous motion precision is required to guarantee effective cooperation between the dual arms, especially when they grasp a common object. In this case, the internal forces applied on the object must also be considered in addition to the external forces. Therefore, a prescribed tracking performance at both transient and steady states is first specified, and then, a controller is synthesized to rigorously guarantee the specified motion performance. In the presence of unknown dynamics of both the robot arms and the manipulated object, the neural network approximation technique is employed to compensate for uncertainties. In order to extend the semiglobal stability achieved by conventional neural control to global stability, a switching mechanism is integrated into the control design. Effectiveness of the proposed control design has been shown through experiments carried out on the Baxter Robot.",
Vibration Control of a Flexible Robotic Manipulator in the Presence of Input Deadzone,"In this paper, a neural network (NN) controller is designed to suppress the vibration of a flexible robotic manipulator system with input deadzone. The NN aims to approximate the unknown robotic manipulator dynamics and eliminate the effects of input deadzone in the actuators. In order to describe the system more accurately, the model of the flexible manipulator is constructed based on the lumping spring-mass method. Full state feedback NN control is proposed first and output feedback NN control with a high-gain observer is then devised to make the proposed control scheme more practical. The effect of input deadzone is approximated by a radial basis function neural network (RBFNN) and the unknown dynamics of the manipulator is approximated by another RBFNN. The proposed NN control is able to compensate for the estimated deadzone effect and track the desired trajectory. For the stability analysis, the Lyapunov's direct method is used to ensure uniform ultimate boundedness (UUB) of the closed-loop system. Simulations are given to verify the control performance of the NN controllers comparing with the proportional derivative (PD) controller. At last, the experiments are conducted on the Quanser platform to further prove the feasibility and control performance of the NN controllers.",
iPrivacy: Image Privacy Protection by Identifying Sensitive Objects via Deep Multi-Task Learning,"To achieve automatic recommendation of privacy settings for image sharing, a new tool called iPrivacy (image privacy) is developed for releasing the burden from users on setting the privacy preferences when they share their images for special moments. Specifically, this paper consists of the following contributions: 1) massive social images and their privacy settings are leveraged to learn the object-privacy relatedness effectively and identify a set of privacy-sensitive object classes automatically; 2) a deep multi-task learning algorithm is developed to jointly learn more representative deep convolutional neural networks and more discriminative tree classifier, so that we can achieve fast and accurate detection of large numbers of privacy-sensitive object classes; 3) automatic recommendation of privacy settings for image sharing can be achieved by detecting the underlying privacy-sensitive objects from the images being shared, recognizing their classes, and identifying their privacy settings according to the object-privacy relatedness; and 4) one simple solution for image privacy protection is provided by blurring the privacy-sensitive objects automatically. We have conducted extensive experimental studies on real-world images and the results have demonstrated both the efficiency and effectiveness of our proposed approach.","Privacy,
Object recognition,
Visualization,
Object detection,
Semantics,
Image segmentation,
Prediction algorithms"
Adaptive Fuzzy Backstepping Tracking Control for Strict-Feedback Systems With Input Delay,"This paper investigates the problem of adaptive fuzzy tracking control for nonlinear strict-feedback systems with input delay and output constraint. Input delay is handled based on the information of Pade approximation and output constraint problem is solved by barrier Lypaunov function. Some adaptive parameters of the controller need to be updated online through considering the norm of membership function vector instead of all sub-vectors. A novel adaptive fuzzy tracking control scheme is developed to guarantee all variables of the closed-loop systems are semiglobally uniformly ultimately bounded, and the tracking error can be adjusted around the origin with a small neighborhood. The stability of the closed-loop systems is proved and simulation results are given to demonstrate the effectiveness of the proposed control approach.",
Hierarchical Clustering Multi-Task Learning for Joint Human Action Grouping and Recognition,"This paper proposes a hierarchical clustering multi-task learning (HC-MTL) method for joint human action grouping and recognition. Specifically, we formulate the objective function into the group-wise least square loss regularized by low rank and sparsity with respect to two latent variables, model parameters and grouping information, for joint optimization. To handle this non-convex optimization, we decompose it into two sub-tasks, multi-task learning and task relatedness discovery. First, we convert this non-convex objective function into the convex formulation by fixing the latent grouping information. This new objective function focuses on multi-task learning by strengthening the shared-action relationship and action-specific feature learning. Second, we leverage the learned model parameters for the task relatedness measure and clustering. In this way, HC-MTL can attain both optimal action models and group discovery by alternating iteratively. The proposed method is validated on three kinds of challenging datasets, including six realistic action datasets (Hollywood2, YouTube, UCF Sports, UCF50, HMDB51
&
UCF101), two constrained datasets (KTH
&
TJU), and two multi-view datasets (MV-TJU
&
IXMAS). The extensive experimental results show that: 1) HC-MTL can produce competing performances to the state of the arts for action recognition and grouping; 2) HC-MTL can overcome the difficulty in heuristic action grouping simply based on human knowledge; 3) HC-MTL can avoid the possible inconsistency between the subjective action grouping depending on human knowledge and objective action grouping based on the feature subspace distributions of multiple actions. Comparison with the popular clustered multi-task learning further reveals that the discovered latent relatedness by HC-MTL aids inducing the group-wise multi-task learning and boosts the performance. To the best of our knowledge, ours is the first work that breaks the assumption that all actions are either independent for individual learning or correlated for joint modeling and proposes HC-MTL for automated, joint action grouping and modeling.",
Bi-Level Semantic Representation Analysis for Multimedia Event Detection,"Multimedia event detection has been one of the major endeavors in video event analysis. A variety of approaches have been proposed recently to tackle this problem. Among others, using semantic representation has been accredited for its promising performance and desirable ability for human-understandable reasoning. To generate semantic representation, we usually utilize several external image/video archives and apply the concept detectors trained on them to the event videos. Due to the intrinsic difference of these archives, the resulted representation is presumable to have different predicting capabilities for a certain event. Notwithstanding, not much work is available for assessing the efficacy of semantic representation from the source-level. On the other hand, it is plausible to perceive that some concepts are noisy for detecting a specific event. Motivated by these two shortcomings, we propose a bi-level semantic representation analyzing method. Regarding source-level, our method learns weights of semantic representation attained from different multimedia archives. Meanwhile, it restrains the negative influence of noisy or irrelevant concepts in the overall concept-level. In addition, we particularly focus on efficient multimedia event detection with few positive examples, which is highly appreciated in the real-world scenario. We perform extensive experiments on the challenging TRECVID MED 2013 and 2014 datasets with encouraging results that validate the efficacy of our proposed approach.","Semantics,
Detectors,
Training,
Multimedia communication,
Event detection,
Noise measurement,
Streaming media"
Robust Joint Graph Sparse Coding for Unsupervised Spectral Feature Selection,"In this paper, we propose a new unsupervised spectral feature selection model by embedding a graph regularizer into the framework of joint sparse regression for preserving the local structures of data. To do this, we first extract the bases of training data by previous dictionary learning methods and, then, map original data into the basis space to generate their new representations, by proposing a novel joint graph sparse coding (JGSC) model. In JGSC, we first formulate its objective function by simultaneously taking subspace learning and joint sparse regression into account, then, design a new optimization solution to solve the resulting objective function, and further prove the convergence of the proposed solution. Furthermore, we extend JGSC to a robust JGSC (RJGSC) via replacing the least square loss function with a robust loss function, for achieving the same goals and also avoiding the impact of outliers. Finally, experimental results on real data sets showed that both JGSC and RJGSC outperformed the state-of-the-art algorithms in terms of k -nearest neighbor classification performance.","Manifolds,
Computational modeling,
Learning systems,
Linear programming,
Robustness,
Data models,
Encoding"
Analysis of Energy-Efficient Connected Target Coverage Algorithms for Industrial Wireless Sensor Networks,"Recent breakthroughs in wireless technologies have greatly spurred the emergence of industrial wireless sensor networks (IWSNs). To facilitate the adaptation of IWSNs to industrial applications, concerns about networks' full coverage and connectivity must be addressed to fulfill reliability and real-time requirements. Although connected target coverage (CTC) algorithms in general sensor networks have been extensively studied, little attention has been paid to reveal both the applicability and limitations of different coverage strategies from an industrial viewpoint. In this paper, we analyze characteristics of four recent energy-efficient coverage strategies by carefully choosing four representative connected coverage algorithms: 1) communication weighted greedy cover; 2) optimized connected coverage heuristic; 3) overlapped target and connected coverage; and 4) adjustable range set covers. Through a detailed comparison in terms of network lifetime, coverage time, average energy consumption, ratio of dead nodes, etc., characteristics of basic design ideas used to optimize coverage and network connectivity of IWSNs are embodied. Various network parameters are simulated in a noisy environment to obtain the optimal network coverage. The most appropriate industrial field for each algorithm is also described based on coverage properties. Our study aims to provide IWSNs designers with useful insights to choose an appropriate coverage strategy and achieve expected performance indicators in different industrial applications.","Algorithm design and analysis,
Sensors,
Wireless sensor networks,
Informatics,
Reliability,
Monitoring,
Noise measurement"
Efficient Computation for Sparse Load Shifting in Demand Side Management,"This paper introduces a distributed algorithm for sparse load shifting in demand-side management with a focus on the scheduling problem of residential smart appliances. By the sparse load shifting strategy, customers' discomfort is reduced. Although there are many game theoretic models for the demand-side management problem, the computational efficiency of finding Nash equilibrium that globally minimizes the total energy consumption cost and the peak-to-average ratio is still an outstanding issue. We develop a bidirectional framework for solving the demand-side management problem in a distributed way to substantially improve the search efficiency. A Newton method is employed to accelerate the centralized coordination of demand side management strategies that superlinearly converge to a better Nash equilibrium minimizing the peak-to-average ratio. Furthermore, dual fast gradient and convex relaxation are applied to tackle the sub-problem for customers' best response, which is able to relieve customers' discomfort from load shifting or interrupting. Detailed results from illustrative case studies are presented and discussed, which shows the costs of energy consumption and daily peak demand by our algorithm are reduced. Finally, some conclusions are drawn.",
Compact Supervisory Control of Discrete Event Systems by Petri Nets With Data Inhibitor Arcs,"This work proposes a novel structure in Petri nets, namely data inhibitor arcs, and their application to the optimal supervisory control of Petri nets. A data inhibitor arc is an arc from a place to a transition labeled with a set of integers. A transition is disabled by a data inhibitor arc if the number of tokens in the place is in the set of integers labeled on it. Its formal definitions and properties are given. Then, we propose a method to design an optimal Petri net supervisor with data inhibitor arcs to prevent a system from reaching illegal markings with respect to control specifications. Two techniques are developed to reduce the supervisor structure by compressing the number of control places. Finally, a number of examples are used to illustrate the proposed approaches and experimental results show that they can obtain optimal Petri net supervisors for the net models that cannot be optimally controlled by pure net supervisors. A significant result is that the proposed approach can always lead to an optimal supervisor with only one control place for bounded Petri nets on the premise that such a supervisor exists.",
Event-Based Distributed H_{\infty } Filtering Networks of 2-DOF Quarter-Car Suspension Systems,"This paper is concerned with the problem of vertical attitude estimation of a two-degree-of-freedom quarter-car suspension system by designing a distributed filtering network, where several distributed filters estimate vehicle heave motion cooperatively under consideration of external disturbance, network channel noises, and measurement error. The sampled data are transmitted through wireless networks. In order to reduce network traffic load and save communication resources, a novel periodic event-triggered sampling scheme is proposed, under which data are transmitted only when the proposed triggering condition is violated. Codesign of event-triggered and distributed filters is derived to guarantee well H∞ robustness to the system noises considered above. Finally, the experiments are given to show the effectiveness of the proposed filtering system.",
Energy-Harvesting-Aided Spectrum Sensing and Data Transmission in Heterogeneous Cognitive Radio Sensor Network,"The incorporation of cognitive radio (CR) and energy harvesting (EH) capabilities in wireless sensor networks enables spectrum and energy-efficient heterogeneous CR sensor networks (HCRSNs). The new networking paradigm of HCRSNs consists of EH-enabled spectrum sensors and battery-powered data sensors. Spectrum sensors can cooperatively scan the licensed spectrum for available channels, whereas data sensors monitor an area of interest and transmit sensed data to the sink over those channels. In this paper, we propose a resource-allocation solution for the HCRSN to achieve the sustainability of spectrum sensors and conserve the energy of data sensors. The proposed solution is achieved by two algorithms that operate in tandem: a spectrum sensor scheduling (SSS) algorithm and a data sensor resource allocation (DSRA) algorithm. The SSS algorithm allocates channels to spectrum sensors such that the average detected available time for the channels is maximized, while the EH dynamics are considered and primary user (PU) transmissions are protected. The DSRA algorithm allocates the transmission time, power, and channels such that the energy consumption of the data sensors is minimized. Extensive simulation results demonstrate that the energy consumption of the data sensors can be significantly reduced, while maintaining the sustainability of the spectrum sensors.",
Algorithm-Dependent Generalization Bounds for Multi-Task Learning,"Often, tasks are collected for multi-task learning (MTL) because they share similar feature structures. Based on this observation, in this paper, we present novel algorithm-dependent generalization bounds for MTL by exploiting the notion of algorithmic stability. We focus on the performance of one particular task and the average performance over multiple tasks by analyzing the generalization ability of a common parameter that is shared in MTL. When focusing on one particular task, with the help of a mild assumption on the feature structures, we interpret the function of the other tasks as a regularizer that produces a specific inductive bias. The algorithm for learning the common parameter, as well as the predictor, is thereby uniformly stable with respect to the domain of the particular task and has a generalization bound with a fast convergence rate of order O(1/n), where n is the sample size of the particular task. When focusing on the average performance over multiple tasks, we prove that a similar inductive bias exists under certain conditions on the feature structures. Thus, the corresponding algorithm for learning the common parameter is also uniformly stable with respect to the domains of the multiple tasks, and its generalization bound is of the order O(1/T), where T is the number of tasks. These theoretical analyses naturally show that the similarity of feature structures in MTL will lead to specific regularizations for predicting, which enables the learning algorithms to generalize fast and correctly from a few examples.","Algorithm design and analysis,
Stability analysis,
Complexity theory,
Convergence,
Prediction algorithms,
Training,
Electronic mail"
Air-Breathing Hypersonic Vehicle Tracking Control Based on Adaptive Dynamic Programming,"In this paper, we propose a data-driven supplementary control approach with adaptive learning capability for air-breathing hypersonic vehicle tracking control based on action-dependent heuristic dynamic programming (ADHDP). The control action is generated by the combination of sliding mode control (SMC) and the ADHDP controller to track the desired velocity and the desired altitude. In particular, the ADHDP controller observes the differences between the actual velocity/altitude and the desired velocity/altitude, and then provides a supplementary control action accordingly. The ADHDP controller does not rely on the accurate mathematical model function and is data driven. Meanwhile, it is capable to adjust its parameters online over time under various working conditions, which is very suitable for hypersonic vehicle system with parameter uncertainties and disturbances. We verify the adaptive supplementary control approach versus the traditional SMC in the cruising flight, and provide three simulation studies to illustrate the improved performance with the proposed approach.","Aerodynamics,
Uncertainty,
Vehicles,
Atmospheric modeling,
Nonlinear dynamical systems,
Uncertain systems,
Force"
Nuclear Norm Based Matrix Regression with Applications to Face Recognition with Occlusion and Illumination Changes,"Recently, regression analysis has become a popular tool for face recognition. Most existing regression methods use the one-dimensional, pixel-based error model, which characterizes the representation error individually, pixel by pixel, and thus neglects the two-dimensional structure of the error image. We observe that occlusion and illumination changes generally lead, approximately, to a low-rank error image. In order to make use of this low-rank structural information, this paper presents a two-dimensional image-matrix-based error model, namely, nuclear norm based matrix regression (NMR), for face representation and classification. NMR uses the minimal nuclear norm of representation error image as a criterion, and the alternating direction method of multipliers (ADMM) to calculate the regression coefficients. We further develop a fast ADMM algorithm to solve the approximate NMR model and show it has a quadratic rate of convergence. We experiment using five popular face image databases: the Extended Yale B, AR, EURECOM, Multi-PIE and FRGC. Experimental results demonstrate the performance advantage of NMR over the state-of-the-art regression-based methods for face recognition in the presence of occlusion and illumination variations.","Robustness,
Face recognition,
Lighting,
Nuclear magnetic resonance,
Robustness,
Matrix converters,
Encoding,
Convex functions,
Regression analysis"
Source Estimation Using Coprime Array: A Sparse Reconstruction Perspective,"Direction-of-arrival (DOA), power, and achievable degrees-of-freedom (DOFs) are fundamental parameters for source estimation. In this paper, we propose a novel sparse reconstruction-based source estimation algorithm by using a coprime array. Specifically, a difference coarray is derived from a coprime array as the foundation for increasing the number of DOFs, and a virtual uniform linear subarray covariance matrix sparse reconstruction-based optimization problem is formulated for DOA estimation. Meanwhile, a modified sliding window scheme is devised to remove the spurious peaks from the reconstructed sparse spatial spectrum, and the power estimation is enhanced through a least squares problem. Simulation results demonstrate the effectiveness of the proposed algorithm in terms of DOA estimation and power estimation as well as the achievable DOFs.","Estimation,
Sensor arrays,
Direction-of-arrival estimation,
Covariance matrices,
Image reconstruction,
Linear matrix inequalities"
Feature Interaction Augmented Sparse Learning for Fast Kinect Motion Detection,"The Kinect sensing devices have been widely used in current Human-Computer Interaction entertainment. A fundamental issue involved is to detect users' motions accurately and quickly. In this paper, we tackle it by proposing a linear algorithm, which is augmented by feature interaction. The linear property guarantees its speed whereas feature interaction captures the higher order effect from the data to enhance its accuracy. The Schatten-p norm is leveraged to integrate the main linear effect and the higher order nonlinear effect by mining the correlation between them. The resulted classification model is a desirable combination of speed and accuracy. We propose a novel solution to solve our objective function. Experiments are performed on three public Kinect-based entertainment data sets related to fitness and gaming. The results show that our method has its advantage for motion detection in a real-time Kinect entertaining environment.","Skeleton,
Feature extraction,
Motion detection,
Real-time systems,
Data mining,
Entertainment industry,
Sensors"
CSI-Based Fingerprinting for Indoor Localization: A Deep Learning Approach,"With the fast-growing demand of location-based services in indoor environments, indoor positioning based on fingerprinting has attracted significant interest due to its high accuracy. In this paper, we present a novel deep-learning-based indoor fingerprinting system using channel state information (CSI), which is termed DeepFi. Based on three hypotheses on CSI, the DeepFi system architecture includes an offline training phase and an online localization phase. In the offline training phase, deep learning is utilized to train all the weights of a deep network as fingerprints. Moreover, a greedy learning algorithm is used to train the weights layer by layer to reduce complexity. In the online localization phase, we use a probabilistic method based on the radial basis function to obtain the estimated location. Experimental results are presented to confirm that DeepFi can effectively reduce location error, compared with three existing methods in two representative indoor environments.","Training,
Machine learning,
IEEE 802.11 Standard,
Indoor environments,
Fading channels,
Antennas,
Complexity theory"
Revealing Event Saliency in Unconstrained Video Collection,"Recent progresses in multimedia event detection have enabled us to find videos about a predefined event from a large-scale video collection. Research towards more intrinsic unsupervised video understanding is an interesting but understudied field. Specifically, given a collection of videos sharing a common event of interest, the goal is to discover the salient fragments, i.e., the curt video fragments that can concisely portray the underlying event of interest, from each video. To explore this novel direction, this paper proposes an unsupervised event saliency revealing framework. It first extracts features from multiple modalities to represent each shot in the given video collection. Then, these shots are clustered to build the cluster-level event saliency revealing framework, which explores useful information cues (i.e., the intra-cluster prior, inter-cluster discriminability, and inter-cluster smoothness) by a concise optimization model. Compared with the existing methods, our approach could highlight the intrinsic stimulus of the unseen event within a video in an unsupervised fashion. Thus, it could potentially benefit to a wide range of multimedia tasks like video browsing, understanding, and search. To quantitatively verify the proposed method, we systematically compare the method to a number of baseline methods on the TRECVID benchmarks. Experimental results have demonstrated its effectiveness and efficiency.","Event detection,
Multimedia communication,
Streaming media,
Optimization,
Benchmark testing,
Semantics,
Noise measurement"
Pulse-Modulated Intermittent Control in Consensus of Multiagent Systems,"This paper proposes a control framework, called pulse-modulated intermittent control, which unifies impulsive control and sampled control. Specifically, the concept of pulse function is introduced to characterize the control/rest intervals and the amplitude of the control. By choosing some specified functions as the pulse function, the proposed control scheme can be reduced to sampled control or impulsive control. The proposed control framework is applied to consensus problems of multiagent systems. Using discretization approaches and stability theory, several necessary and sufficient conditions are established to ensure the consensus of the controlled system. The results show that consensus depends not only on the network topology, the sampling period and the control gains, but also the pulse function. Moreover, a lower bound of the asymptotic convergence factor is derived as well. For a given pulse function and an undirected graph, an optimal control gain is designed to achieve the fastest convergence. In addition, impulsive control and sampled control are revisited in the proposed control framework. Finally, some numerical examples are given to verify the effectiveness of theoretical results.","Multi-agent systems,
Control systems,
Convergence,
Eigenvalues and eigenfunctions,
Laplace equations,
Asymptotic stability"
Success Probability of the Babai Estimators for Box-Constrained Integer Linear Models,"In many applications including communications, one may encounter a linear model where the parameter vector x̂ is an integer vector in a box. To estimate x̂, a typical method is to solve a box-constrained integer least squares problem. However, due to its high complexity, the box-constrained Babai integer point xBB is commonly used as a suboptimal solution. In this paper, we first derive formulas for the success probability PBB of xBB and the success probability POB of the ordinary Babai integer point xOB when x̂ is uniformly distributed over the constraint box. Some properties of PBB and POB and the relationship between them are studied. Then, we investigate the effects of some column permutation strategies on PBB. In addition to V-BLAST and SQRD, we also consider the permutation strategy involved in the LLL lattice reduction, to be referred to as LLL-P. On the one hand, we show that when the noise is relatively small, LLL-P always increases PBB and argue why both V-BLAST and SQRD often increase PBB; and on the other hand, we show that when the noise is relatively large, LLL-P always decreases PBB and argue why both V-BLAST and SQRD often decrease PBB. We also derive a column permutation invariant bound on PBB, which is an upper bound and a lower bound under these two opposite conditions, respectively. Numerical results demonstrate our findings. Finally, we consider a conjecture concerning xOB proposed by Ma et al. We first construct an example to show that the conjecture does not hold in general, and then show that it does hold under some conditions.","Zinc,
Search methods,
Oils,
Signal to noise ratio,
Algorithm design and analysis,
Complexity theory,
Upper bound"
A Time Delay Compensation Method Based on Area Equivalence For Active Damping of an LCL -Type Converter,"Control of the LCL-type three-phase grid-connected converter is difficult due to high resonance peak of the LCL filter. Active damping is the state-of-the-art solution to this problem, but the damping performance will be affected by the inherent time delay of digital control, especially for high-power low switching frequency applications. Based on a discrete-time stability analysis of an LCL-type converter with capacitor-current-feedback active damping, a simple and effective time delay compensation method, which is based on area equalization concept, is proposed. The method can reduce the negative impact of the computation delay significantly. It has the potential to serve as a general solution to time delay compensation of a digitally controlled PWM converter. The validity of the proposed method is proved by experimental results.","Delays,
Damping,
Pulse width modulation,
Delay effects,
Power harmonic filters,
Stability analysis,
Switches"
Constructing the L2-Graph for Robust Subspace Learning and Subspace Clustering,"Under the framework of graph-based learning, the key to robust subspace clustering and subspace learning is to obtain a good similarity graph that eliminates the effects of errors and retains only connections between the data points from the same subspace (i.e., intrasubspace data points). Recent works achieve good performance by modeling errors into their objective functions to remove the errors from the inputs. However, these approaches face the limitations that the structure of errors should be known prior and a complex convex problem must be solved. In this paper, we present a novel method to eliminate the effects of the errors from the projection space (representation) rather than from the input space. We first prove that ℓ1-, ℓ2-, ℓ∞-, and nuclear-norm-based linear projection spaces share the property of intrasubspace projection dominance, i.e., the coefficients over intrasubspace data points are larger than those over intersubspace data points. Based on this property, we introduce a method to construct a sparse similarity graph, called L2-graph. The subspace clustering and subspace learning algorithms are developed upon L2-graph. We conduct comprehensive experiment on subspace learning, image clustering, and motion segmentation and consider several quantitative benchmarks classification/clustering accuracy, normalized mutual information, and running time. Results show that L2-graph outperforms many state-of-the-art methods in our experiments, including L1-graph, low rank representation (LRR), and latent LRR, least square regression, sparse subspace clustering, and locally linear representation.","Robustness,
Clustering algorithms,
Feature extraction,
Linear programming,
Motion segmentation,
Computer vision,
Sparse matrices"
Privacy-Preserving Smart Semantic Search Based on Conceptual Graphs Over Encrypted Outsourced Data,"Searchable encryption is an important research area in cloud computing. However, most existing efficient and reliable ciphertext search schemes are based on keywords or shallow semantic parsing, which are not smart enough to meet with users' search intention. Therefore, in this paper, we propose a content-aware search scheme, which can make semantic search more smart. First, we introduce conceptual graphs (CGs) as a knowledge representation tool. Then, we present our two schemes (PRSCG and PRSCG-TF) based on CGs according to different scenarios. In order to conduct numerical calculation, we transfer original CGs into their linear form with some modification and map them to numerical vectors. Second, we employ the technology of multi-keyword ranked search over encrypted cloud data as the basis against two threat models and raise PRSCG and PRSCG-TF to resolve the problem of privacy-preserving smart semantic search based on CGs. Finally, we choose a real-world data set: CNN data set to test our scheme. We also analyze the privacy and efficiency of proposed schemes in detail. The experiment results show that our proposed schemes are efficient.","Semantics,
Servers,
Search problems,
Encryption,
Indexes,
Data models"
SiGe HBT Technology: Future Trends and TCAD-Based Roadmap,"A technology roadmap for the electrical performance of high-speed silicon-germanium (SiGe) heterojunction bipolar transistors (HBTs) is presented based on combining the results of various 1-D, 2-D, and 3-D technology computer-aided design (TCAD) simulation tools with geometry scalable compact modeling. The latter, including all known parasitic effects, enables the accurate determination of the figures of merit for both devices and selected benchmark circuits. The presented roadmap defines five major technology nodes with the maximum oscillation frequency of a typical high-frequency device structure as the main device design target under the constraints of various other parameters for generating the doping profiles and for defining the lateral scaling factors. An extensive and consistent set of technology and electrical parameters is provided along with the obtained scaling rules. The expected fabrication-related challenges and possible solutions for achieving the predicted performance are being discussed. It is hoped that the presented roadmap will be useful not only for foundries and equipment manufacturers but also for circuit and system designers enabling better predictions of the capability of SiGe-BiCMOS process technology for new millimeter-wave (mm-wave) and terahertz (THz) applications.",
Prediction and Validation of Disease Genes Using HeteSim Scores,"Deciphering the gene disease association is an important goal in biomedical research. In this paper, we use a novel relevance measure, called HeteSim, to prioritize candidate disease genes. Two methods based on heterogeneous networks constructed using protein-protein interaction, gene-phenotype associations, and phenotype-phenotype similarity, are presented. In HeteSim_MultiPath (HSMP), HeteSim scores of different paths are combined with a constant that dampens the contributions of longer paths. In HeteSim_SVM (HSSVM), HeteSim scores are combined with a machine learning method. The 3-fold experiments show that our non-machine learning method HSMP performs better than the existing non-machine learning methods, our machine learning method HSSVM obtains similar accuracy with the best existing machine learning method CATAPULT. From the analysis of the top 10 predicted genes for different diseases, we found that HSSVM avoid the disadvantage of the existing machine learning based methods, which always predict similar genes for different diseases. The data sets and Matlab code for the two methods are freely available for download at http://lab.malab.cn/data/HeteSim/index.jsp.","Diseases,
Heterogeneous networks,
Learning systems,
Proteins,
Couplings,
Databases,
Grippers"
A Big Data Architecture Design for Smart Grids Based on Random Matrix Theory,"Model-based analysis tools, built on assumptions and simplifications, are difficult to handle smart grids with data characterized by volume, velocity, variety, and veracity (i.e., 4Vs data). This paper, using random matrix theory (RMT), motivates data-driven tools to perceive the complex grids in high-dimension; meanwhile, an architecture with detailed procedures is proposed. In algorithm perspective, the architecture performs a high-dimensional analysis and compares the findings with RMT predictions to conduct anomaly detections. Mean spectral radius (MSR), as a statistical indicator, is defined to reflect the correlations of system data in different dimensions. In management mode perspective, a group-work mode is discussed for smart grids operation. This mode breaks through regional limitations for energy flows and data flows, and makes advanced big data analyses possible. For a specific large-scale zone-dividing system with multiple connected utilities, each site, operating under the group-work mode, is able to work out the regional MSR only with its own measured/simulated data. The large-scale interconnected system, in this way, is naturally decoupled from statistical parameters perspective, rather than from engineering models perspective. Furthermore, a comparative analysis of these distributed MSRs, even with imperceptible different raw data, will produce a contour line to detect the event and locate the source. It demonstrates that the architecture is compatible with the block calculation only using the regional small database; beyond that, this architecture, as a data-driven solution, is sensitive to system situation awareness, and practical for real large-scale interconnected systems. Five case studies and their visualizations validate the designed architecture in various fields of power systems. To our best knowledge, this paper is the first attempt to apply big data technology into smart grids.","Big data,
Smart grids,
Data models,
Mathematical model,
Correlation,
Computer architecture"
Manipulability Optimization of Redundant Manipulators Using Dynamic Neural Networks,"For solving the singularity problem arising in the control of manipulators, an efficient way is to maximize its manipulability. However, it is challenging to optimize manipulability effectively because it is a nonconvex function to the joint angles of a robotic arm. In addition, the involvement of an inversion operation in the expression of manipulability makes it even hard for timely optimization due to the intensively computational burden for matrix inversion. In this paper, we make progress on real-time manipulability optimization by establishing a dynamic neural network for recurrent calculation of manipulability-maximal control actions for redundant manipulators under physical constraints in an inverse-free manner. By expressing position tracking and matrix inversion as equality constraints, physical limits as inequality constraints, and velocity-level manipulability measure, which is affine to the joint velocities, as the objective function, the manipulability optimization scheme is further formulated as a constrained quadratic program. Then, a dynamic neural network with rigorously provable convergence is constructed to solve such a problem online. Computer simulations are conducted and show that, compared to the existing methods, the proposed scheme can raise the manipulability almost 40% on average, which substantiates the efficacy, accuracy, and superiority of the proposed manipulability optimization scheme.","Neural networks,
Optimization,
Manipulator dynamics,
Redundancy,
Kinematics"
SeDaSC: Secure Data Sharing in Clouds,"Cloud storage is an application of clouds that liberates organizations from establishing in-house data storage systems. However, cloud storage gives rise to security concerns. In case of group-shared data, the data face both cloud-specific and conventional insider threats. Secure data sharing among a group that counters insider threats of legitimate yet malicious users is an important research issue. In this paper, we propose the Secure Data Sharing in Clouds (SeDaSC) methodology that provides: 1) data confidentiality and integrity; 2) access control; 3) data sharing (forwarding) without using compute-intensive reencryption; 4) insider threat security; and 5) forward and backward access control. The SeDaSC methodology encrypts a file with a single encryption key. Two different key shares for each of the users are generated, with the user only getting one share. The possession of a single share of a key allows the SeDaSC methodology to counter the insider threats. The other key share is stored by a trusted third party, which is called the cryptographic server. The SeDaSC methodology is applicable to conventional and mobile cloud computing environments. We implement a working prototype of the SeDaSC methodology and evaluate its performance based on the time consumed during various operations. We formally verify the working of SeDaSC by using high-level Petri nets, the Satisfiability Modulo Theories Library, and a Z3 solver. The results proved to be encouraging and show that SeDaSC has the potential to be effectively used for secure data sharing in the cloud.",
Data Exfiltration From Internet of Things Devices: iOS Devices as Case Studies,"Increasingly, big data (including sensitive and commercial-in-confidence data) is being accessible and stored on a range of Internet of Things (IoT) devices, such as our mobile devices. Therefore, any vulnerability in IoT devices, operating system or software can be exploited by cybercriminals seeking to exfiltrate our data. In this paper, we use iOS devices as case studies and highlight the potential for pairing mode in iOS devices (which allows the establishment of a trusted relationship between an iOS device and a personal computer) to be exploited for covert data exfiltration. In our three case studies, we demonstrate how an attacker could exfiltrate data from a paired iOS device by abusing a library and a command line tool distributed with iTunes. With the aim of avoiding similar attacks in the future, we present two recommendations.","Security,
Internet of things,
Media,
Big data,
File systems,
Microcomputers"
CAIS: A Copy Adjustable Incentive Scheme in Community-Based Socially Aware Networking,"Socially aware networking (SAN) is a new communication paradigm, in which the social characteristics of mobile nodes are exploited to improve the performance of data distribution. In SAN, mobile carriers may exhibit selfish behaviors and refuse to relay messages for others for various reasons, such as limited resources (e.g., buffer, energy, and bandwidth) or social relationships. Several incentive schemes have recently been investigated to stimulate selfish users for cooperation in data forwarding. However, a majority of the existing methods have not fully studied nodes' social relationships in their selfish behaviors. In this paper, we propose a copy adjustable incentive scheme (CAIS), which adopts the virtual credit concept to stimulate selfish nodes to cooperate in data forwarding. In CAIS, we consider a network in which the nodes are divided into certain communities based on their social relationships. Then, we apply two types of credits, i.e., social credit and nonsocial credit, to reward the nodes when they relay data for other nodes inside their community or outsiders, respectively. Based on our mechanism, the number of messages a node can replicate to other nodes is adjusted according to its cooperation level and earned credits. To further improve the performance of CAIS, a single-copy data replication policy is employed, which manages the credit distribution of each node according to its available resources. The results of our extensive experiments using both synthetic and trace-driven simulations illustrate that CAIS copes well with node selfishness in community-based networks and outperforms other benchmark protocols with high data delivery ratio, low communication overhead, and short data delivery latency.",
Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising,"The discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (DnCNNs) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. Specifically, residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. Different from the existing discriminative denoising models which usually train a specific model for additive white Gaussian noise at a certain noise level, our DnCNN model is able to handle Gaussian denoising with unknown noise level (i.e., blind Gaussian denoising). With the residual learning strategy, DnCNN implicitly removes the latent clean image in the hidden layers. This property motivates us to train a single DnCNN model to tackle with several general image denoising tasks, such as Gaussian denoising, single image super-resolution, and JPEG image deblocking. Our extensive experiments demonstrate that our DnCNN model can not only exhibit high effectiveness in several general image denoising tasks, but also be efficiently implemented by benefiting from GPU computing.","Noise reduction,
Image denoising,
Training,
Computational modeling,
Noise level,
Neural networks,
Transform coding"
GaN-on-Si Power Technology: Devices and Applications,"In this paper, we present a comprehensive review and discussion of the state-of-the-art device technology and application development of GaN-on-Si power electronics. Several device technologies for realizing normally off operation that is highly desirable for power switching applications are presented. In addition, the examples of circuit applications that can greatly benefit from the superior performance of GaN power devices are demonstrated. Comparison with other competing power device technology, such as Si superjunction-MOSFET and SiC MOSFET, is also presented and analyzed. Critical issues for commercialization of GaN-on-Si power devices are discussed with regard to cost, reliability, and ease of use.","Gallium nitride,
Silicon,
Logic gates,
HEMTs,
MOSFET,
Substrates,
Switches"
Investigation of Gallium Nitride Devices in High-Frequency LLC Resonant Converters,"Newly emerged gallium nitride (GaN) devices feature ultrafast switching speed and low on-state resistance that potentially provide significant improvements for power converters. This paper investigates the benefits of GaN devices in an LLC resonant converter and quantitatively evaluates GaN devices' capabilities to improve converter efficiency. First, the relationship of device and converter design parameters to the device loss is established based on an analytical model of LLC resonant converter operating at the resonance. Due to the low effective output capacitance of GaN devices, the GaN-based design demonstrates about 50% device loss reduction compared with the Si-based design. Second, a new perspective on the extra transformer winding loss due to the asymmetrical primary-side and secondary-side current is proposed. The device and design parameters are tied to the winding loss based on the winding loss model in the finite element analysis (FEA) simulation. Compared with the Si-based design, the winding loss is reduced by 18% in the GaN-based design. Finally, in order to verify the GaN device benefits experimentally, 400- to 12-V, 300-W, 1-MHz GaN-based and Si-based LLC resonant converter prototypes are built and tested. One percent efficiency improvement, which is 24.8% loss reduction, is achieved in the GaN-based converter.","Gallium nitride,
Windings,
Magnetic resonance,
HEMTs,
Capacitance,
Silicon"
Dual-Mode Index Modulation Aided OFDM,"Index modulation has become a promising technique in the context of orthogonal frequency division multiplexing (OFDM), whereby the specific activation of the frequency domain subcarriers is used for implicitly conveying extra information, hence improving the achievable throughput at a given bit error ratio (BER) performance. In this paper, a dual-mode OFDM technique (DM-OFDM) is proposed, which is combined with index modulation and enhances the attainable throughput of conventional index-modulation-based OFDM. In particular, the subcarriers are divided into several subblocks, and in each subblock, all the subcarriers are partitioned into two groups, modulated by a pair of distinguishable modem-mode constellations, respectively. Hence, the information bits are conveyed not only by the classic constellation symbols, but also implicitly by the specific activated subcarrier indices, representing the subcarriers' constellation mode. At the receiver, a maximum likelihood (ML) detector and a reduced-complexity near optimal log-likelihood ratio-based detector are invoked for demodulation. The minimum distance between the different legitimate realizations of the OFDM subblocks is calculated for characterizing the performance of DM-OFDM. Then, the associated theoretical analysis based on the pairwise error probability is carried out for estimating the BER of DM-OFDM. Furthermore, the simulation results confirm that at a given throughput, DM-OFDM achieves a considerably better BER performance than other OFDM systems using index modulation, while imposing the same or lower computational complexity. The results also demonstrate that the performance of the proposed low-complexity detector is indistinguishable from that of the ML detector, provided that the system's signal to noise ratio is sufficiently high.","Indexes,
OFDM,
Detectors,
Phase shift keying,
Throughput,
Signal to noise ratio"
Unsupervised Visual Hashing with Semantic Assistant for Content-Based Image Retrieval,"As an emerging technology to support scalable content-based image retrieval (CBIR), hashing has recently received great attention and became a very active research domain. In this study, we propose a novel unsupervised visual hashing approach called semantic-assisted visual hashing (SAVH). Distinguished from semi-supervised and supervised visual hashing, its core idea is to effectively extract the rich semantics latently embedded in auxiliary texts of images to boost the effectiveness of visual hashing without any explicit semantic labels. To achieve the target, a unified unsupervised framework is developed to learn hash codes by simultaneously preserving visual similarities of images, integrating the semantic assistance from auxiliary texts on modeling high-order relationships of inter-images, and characterizing the correlations between images and shared topics. Our performance study on three publicly available image collections: Wiki, MIR Flickr, and NUS-WIDE indicates that SAVH can achieve superior performance over several state-of-the-art techniques.","Visualization,
Semantics,
Correlation,
Boats,
Image retrieval,
Oceans,
Flickr"
An Event-Triggered ADP Control Approach for Continuous-Time System With Unknown Internal States,"This paper proposes a novel event-triggered adaptive dynamic programming (ADP) control method for nonlinear continuous-time system with unknown internal states. Comparing with the traditional ADP design with a fixed sample period, the event-triggered method samples the state and updates the controller only when it is necessary. Therefore, the computation cost and transmission load are reduced. Usually, the event-triggered method is based on the system entire state which is either infeasible or very difficult to obtain in practice applications. This paper integrates a neural-network-based observer to recover the system internal states from the measurable feedback. Both the proposed observer and the controller are aperiodically updated according to the designed triggering condition. Neural network techniques are applied to estimate the performance index and help calculate the control action. The stability analysis of the proposed method is also demonstrated by Lyapunov construct for both the continuous and jump dynamics. The simulation results verify the theoretical analysis and justify the efficiency of the proposed method.","Observers,
Performance analysis,
Stability analysis,
Optimal control,
Nonlinear dynamical systems,
Neural networks,
Control design"
Adaptive Intelligent Control of Nonaffine Nonlinear Time-Delay Systems With Dynamic Uncertainties,"Adaptive neural intelligent control is investigated for a class of pure-feedback nonlinear time-delay systems with unmodeled dynamics in nonlower-triangular form, which views the lower-triangular structure as a special structure. A variable partition technique is applied to surmount the difficulty in the nonlinear functions of whole state variables. By utilizing the backstepping recursive design approach and the universal approximation capability of neural networks, an adaptive neural controller is systemically designed. Then, based on the utilization of Lyapunov-Krasovskii functionals, the semiglobally uniform boundedness of all closed-loop signals is guaranteed. Finally, the suggested control method is verified through a numerical example. The main advantage of this paper is that an intelligent control method is developed for pure-feedback nonlinear systems with state time delay, unmodeled dynamics and nonlower triangular form. Further developments will focus on how to deal with the problem of output feedback control of pure-feedback nonlinear time-delay systems with unmodeled dynamics and nonlower-triangular structure.","Adaptive systems,
Control systems,
Nonlinear dynamical systems,
Backstepping,
Neural networks,
Delay effects"
Optimal Cloudlet Placement and User to Cloudlet Allocation in Wireless Metropolitan Area Networks,"Mobile applications are becoming increasingly computation-intensive, while the computing capability of portable mobile devices is limited. A powerful way to reduce the completion time of an application in a mobile device is to offload its tasks to nearby cloudlets, which consist of clusters of computers. Although there is a significant body of research in mobile cloudlet offloading technology, there has been very little attention paid to how cloudlets should be placed in a given network to optimize mobile application performance. In this paper we study cloudlet placement and mobile user allocation to the cloudlets in a wireless metropolitan area network (WMAN). We devise an algorithm for the problem, which enables the placement of the cloudlets at user dense regions of the WMAN, and assigns mobile users to the placed cloudlets while balancing their workload. We also conduct experiments through simulation. The simulation results indicate that the performance of the proposed algorithm is very promising.",
User Association in Massive MIMO HetNets,"Massive multiple-input-multiple-output (MIMO) and small cell are both recognized as key technologies for the future fifth-generation wireless systems. In this paper, we investigate the problem of user association in a heterogeneous network (HetNet) with massive MIMO and small cells, where the macro base station (BS) is equipped with a massive MIMO, and the picocell BSs are equipped with regular MIMOs. We first develop centralized user association algorithms with proven optimality, considering various objectives such as rate maximization, proportional fairness, and joint user association and resource allocation. We then develop a repeated game model, which leads to distributed user association algorithms with proven convergence to the Nash equilibrium. We demonstrate the efficacy of these optimal schemes by comparing with several greedy algorithms through simulations.",
Understanding the Performance and Potential of Cloud Computing for Scientific Applications,"Commercial clouds bring a great opportunity to the scientific computing area. Scientific applications usually require significant resources, however not all scientists have access to sufficient high-end computing systems. Cloud computing has gained the attention of scientists as a competitive resource to run HPC applications at a potentially lower cost. But as a different infrastructure, it is unclear whether clouds are capable of running scientific applications with a reasonable performance per money spent. This work provides a comprehensive evaluation of EC2 cloud in different aspects. We first analyze the potentials of the cloud by evaluating the raw performance of different services of AWS such as compute, memory, network and I/O. Based on the findings on the raw performance, we then evaluate the performance of the scientific applications running in the cloud. Finally, we compare the performance of AWS with a private cloud, in order to find the root cause of its limitations while running scientific applications. This paper aims to assess the ability of the cloud to perform well, as well as to evaluate the cost of the cloud in terms of both raw performance and scientific applications performance. Furthermore, we evaluate other services including S3, EBS and DynamoDB among many AWS services in order to assess the abilities of those to be used by scientific applications and frameworks. We also evaluate a real scientific computing application through the Swift parallel scripting system at scale. Armed with both detailed benchmarks to gauge expected performance and a detailed monetary cost analysis, we expect this paper will be a recipe cookbook for scientists to help them decide where to deploy and run their scientific applications between public clouds, private clouds, or hybrid clouds.","Cloud computing,
Bandwidth,
Benchmark testing,
Virtualization,
Scientific computing,
Measurement,
Virtual machining"
On Theoretical Modeling of Sensor Cloud: A Paradigm Shift From Wireless Sensor Network,"This paper focuses on the theoretical modeling of sensor cloud, which is one of the first attempts in this direction. We endeavor to theoretically characterize virtualization, which is a fundamental mechanism for operations within the sensor-cloud architecture. Existing related research works on sensor cloud have primarily focused on the ideology and the challenges that wireless sensor network (WSN)-based applications typically encounter. However, none of the works has addressed theoretical characterization and analysis, which can be used for building models for solving different problems to be encountered in using sensor cloud. We present a mathematical formulation of sensor cloud, which is very important for studying the behavior of WSN-based applications in the sensor-cloud platform. We also suggested a paradigm shift of technology from traditional WSNs to sensor-cloud architecture. A detailed analysis is made based on the performance metrics, i.e., energy consumption, fault tolerance, and lifetime of a sensor node. A thorough evaluation of the cost effectiveness of sensor cloud is also done by examining the cash inflow and outflow characteristics from the perspective of every actor of the sensor cloud. Analytical results show that the sensor-cloud architecture outperforms a traditional WSN, by increasing the sensor lifetime by 3.25% and decreasing the energy consumption by 36.68%. We also observe that the technology shift to sensor cloud reduces the expenditure of an end user by 14.72%, on average.",
Sensing Time Optimization and Power Control for Energy Efficient Cognitive Small Cell With Imperfect Hybrid Spectrum Sensing,"Cognitive radio enabled small cell network is an emerging technology to address the exponential increase of mobile traffic demand in next generation mobile communications. Recently, many technological issues, such as resource allocation and interference mitigation pertaining to cognitive small cell network have been studied, but most studies focus on maximizing spectral efficiency. Different from the existing works, we investigate the power control and sensing time optimization problem in a cognitive small cell network, where the cross-tier interference mitigation, imperfect hybrid spectrum sensing, and energy efficiency are considered. The optimization of energy efficient sensing time and power allocation is formulated as a non-convex optimization problem. We solve the proposed problem in an asymptotically optimal manner. An iterative power control algorithm and a near optimal sensing time scheme are developed by considering imperfect hybrid spectrum sensing, cross-tier interference mitigation, minimum data rate requirement, and energy efficiency. Simulation results are presented to verify the effectiveness of the proposed algorithms for energy efficient resource allocation in the cognitive small cell network.",
A Sharp Condition for Exact Support Recovery With Orthogonal Matching Pursuit,"Support recovery of sparse signals from noisy measurements with orthogonal matching pursuit (OMP) has been extensively studied. In this paper, we show that for any K-sparse signal x, if a sensing matrix A satisfies the restricted isometry property (RIP) with restricted isometry constant δK+ 1 <; 1/√K + 1, then under some constraints on the minimum magnitude of nonzero elements of x, OMP exactly recovers the support of x from its measurements y = Ax + v in K iterations, where v is a noise vector that is ℓ2 or ℓ∞ bounded. This sufficient condition is sharp in terms of δK+ 1 since for any given positive integer K and any 1/√K + 1 ≤ δ <; 1, there always exists a matrix A satisfying the RIP with δK+ 1 = δ for which OMP fails to recover a K-sparse signal x in K iterations. Also, our constraints on the minimum magnitude of nonzero elements of x are weaker than existing ones. Moreover, we propose worst case necessary conditions for the exact support recovery of x, characterized by the minimum magnitude of the nonzero elements of x.",
Event-Triggered State Estimation for Discrete-Time Multidelayed Neural Networks With Stochastic Parameters and Incomplete Measurements,"In this paper, the event-triggered state estimation problem is investigated for a class of discrete-time multidelayed neural networks with stochastic parameters and incomplete measurements. In order to cater for more realistic transmission process of the neural signals, we make the first attempt to introduce a set of stochastic variables to characterize the random fluctuations of system parameters. In the addressed neural network model, the delays among the interconnections are allowed to be different, which are more general than those in the existing literature. The incomplete information under consideration includes randomly occurring sensor saturations and quantizations. For the purpose of energy saving, an event-triggered state estimator is constructed and a sufficient condition is given under which the estimation error dynamics is exponentially ultimately bounded in the mean square. It is worth noting that the ultimate boundedness of the error dynamics is explicitly estimated. The characterization of the desired estimator gain is designed in terms of the solution to a certain matrix inequality. Finally, a numerical simulation example is presented to illustrate the effectiveness of the proposed event-triggered state estimation scheme.",
Robotic Room-Level Localization Using Multiple Sets of Sonar Measurements,"In this paper, we aim to achieve robust and cost-effective room-level localization for the indoor mobile robot. It is unrealistic to obtain precise localization information from the sonar sensors because of the sparseness and uncertainty. Our attempts show that the room-level localization can be achieved using sonar sensors by accumulating the sonar data to overcome the limitations of sensor performance. To this end, we formulate the room-level localization as a joint sparse coding problem, which encourages the coding vectors to share the common room sparsity, but different locations. We systematically evaluate the performance of the different coding strategies on the collected sonar measurement data set.","Sonar measurements,
Robot sensing systems,
Encoding,
Mobile robots"
Distributed Optimization Based on a Multiagent System in the Presence of Communication Delays,"In this paper, distributed optimization is addressed based on a continuous-time multiagent system in the presence of time-varying communication delays. First, the relationship between optimal solutions and the equilibrium points of the multiagent system with time delay is revealed. Next, delay-dependent and delay-independent sufficient conditions in form of linear matrix inequality are derived for ascertaining convergence to optimal solutions, in the cases of slow-varying delay and fast-varying delay. Furthermore, a set of conditions are also obtained for the delay-free case. In addition, a sampled-data communication scheme is presented based on the conditions for the fast varying delay systems. Simulation results are presented to substantiate the theoretical results. An application for distributed parameter estimation is also given.",
Green Video Transmission in the Mobile Cloud Networks,"Video transmission is an indispensable component of most applications related to the mobile cloud networks (MCNs). However, because of the complexity of the communication environment and the limitation of resources, attempts to develop an effective solution for video transmission in the MCN face certain difficulties. In this paper, we propose a novel green video transmission (GVT) algorithm that uses video clustering and channel assignment to assist in video transmission. A video clustering model is designed based on game theory to classify the different video parts stored in mobile devices. Using the results of video clustering, the GVT algorithm provides the function of channel assignment, and its assignment process depends on the content of the video to improve channel utilization in the MCN. Extensive simulations are carried out to evaluate the GVT with several performance criteria. Our analysis and simulations show that the proposed GTV demonstrates a superior video transmission performance compared with the existing methods.","Mobile handsets,
Cloud computing,
Mobile communication,
Channel allocation,
Mobile computing,
Servers,
Clustering algorithms"
EndoNet: A Deep Architecture for Recognition Tasks on Laparoscopic Videos,"Surgical workflow recognition has numerous potential medical applications, such as the automatic indexing of surgical video databases and the optimization of real-time operating room scheduling, among others. As a result, surgical phase recognition has been studied in the context of several kinds of surgeries, such as cataract, neurological, and laparoscopic surgeries. In the literature, two types of features are typically used to perform this task: visual features and tool usage signals. However, the used visual features are mostly handcrafted. Furthermore, the tool usage signals are usually collected via a manual annotation process or by using additional equipment. In this paper, we propose a novel method for phase recognition that uses a convolutional neural network (CNN) to automatically learn features from cholecystectomy videos and that relies uniquely on visual information. In previous studies, it has been shown that the tool usage signals can provide valuable information in performing the phase recognition task. Thus, we present a novel CNN architecture, called EndoNet, that is designed to carry out the phase recognition and tool presence detection tasks in a multi-task manner. To the best of our knowledge, this is the first work proposing to use a CNN for multiple recognition tasks on laparoscopic videos. Experimental comparisons to other methods show that EndoNet yields state-of-the-art results for both tasks.","Videos,
Surgery,
Visualization,
Feature extraction,
Laparoscopes,
Computer architecture,
Image recognition"
Co-Saliency Detection via a Self-Paced Multiple-Instance Learning Framework,"As an interesting and emerging topic, co-saliency detection aims at simultaneously extracting common salient objects from a group of images. On one hand, traditional co-saliency detection approaches rely heavily on human knowledge for designing handcrafted metrics to possibly reflect the faithful properties of the co-salient regions. Such strategies, however, always suffer from poor generalization capability to flexibly adapt various scenarios in real applications. On the other hand, most current methods pursue cosaliency detection in unsupervised fashions. This, however, tends to weaken their performance in real complex scenarios because they are lack of robust learning mechanism to make full use of the weak labels of each image. To alleviate these two problems, this paper proposes a new SP-MIL framework for co-saliency detection, which integrates both multiple instance learning (MIL) and self-paced learning (SPL) into a unified learning framework. Specifically, for the first problem, we formulate the co-saliency detection problem as a MIL paradigm to learn the discriminative classifiers to detect the co-saliency object in the “instance-level”. The formulated MIL component facilitates our method capable of automatically producing the proper metrics to measure the intra-image contrast and the inter-image consistency for detecting co-saliency in a purely self-learning way. For the second problem, the embedded SPL paradigm is able to alleviate the data ambiguity under the weak supervision of co-saliency detection and guide a robust learning manner in complex scenarios. Experiments on benchmark datasets together with multiple extended computer vision applications demonstrate the superiority of the proposed framework beyond the state-of-the-arts.",
United Complex Centrality for Identification of Essential Proteins from PPI Networks,"Essential proteins are indispensable for the survival or reproduction of an organism. Identification of essential proteins is not only necessary for the understanding of the minimal requirements for cellular life, but also important for the disease study and drug design. With the development of high-throughput techniques, a large number of protein-protein interaction data are available, which promotes the studies of essential proteins from the network level. Up to now, though a series of computational methods have been proposed, the prediction precision still needs to be improved. In this paper, we propose a new method, United complex Centrality (UC), to identify essential proteins by integrating the protein complexes with the topological features of protein-protein interaction (PPI) networks. By analyzing the relationship between the essential proteins and the known protein complexes of S. cerevisiae and human, we find that the proteins in complexes are more likely to be essential compared with the proteins not included in any complexes and the proteins appeared in multiple complexes are more inclined to be essential compared to those only appeared in a single complex. Considering that some protein complexes generated by computational methods are inaccurate, we also provide a modified version of UC with parameter alpha, named UC-P. The experimental results show that protein complex information can help identify the essential proteins more accurate both for the PPI network of S. cerevisiae and that of human. The proposed method UC performs obviously better than the eight previously proposed methods (DC, IC, EC, SC, BC, CC, NC, and LAC) for identifying essential proteins.","Proteins,
Bioinformatics,
Databases,
IEEE transactions,
Computational biology,
Integrated circuits"
Social-Oriented Adaptive Transmission in Opportunistic Internet of Smartphones,"Stable and reliable wireless communication is one of the critical demands for smart cities to connect people and devices. Although intelligent terminals can be leveraged to deliver and exchange data through Internet, poor network coverage and expensive network access challenge the deployment of network infrastructure. In this paper, we propose a social-oriented smartphone-based adaptive transmission mechanism to improve the network connectivity and throughput in Internet of Things (IoTs) for smart cities. First, a social-oriented double-auction-based relay selection scheme is investigated to stimulate the relay smartphones to forward packets for others so that the network connectivity can be strengthened. Furthermore, for the sake of achieving high throughput in smartphone-based IoTs, the relay method selection is determined by integrating various kinds of transmission schemes in an optimal fashion to make full use of wireless spectrum resource. Due to its high computational complexity, a firefly-algorithm-based scheme is investigated, by which the formulated NP-complete problem can be solved effectively. Simulation results demonstrate the superiority of our proposed method.",
Stacked Convolutional Denoising Auto-Encoders for Feature Representation,"Deep networks have achieved excellent performance in learning representation from visual data. However, the supervised deep models like convolutional neural network require large quantities of labeled data, which are very expensive to obtain. To solve this problem, this paper proposes an unsupervised deep network, called the stacked convolutional denoising auto-encoders, which can map images to hierarchical representations without any label information. The network, optimized by layer-wise training, is constructed by stacking layers of denoising auto-encoders in a convolutional way. In each layer, high dimensional feature maps are generated by convolving features of the lower layer with kernels learned by a denoising auto-encoder. The auto-encoder is trained on patches extracted from feature maps in the lower layer to learn robust feature detectors. To better train the large network, a layer-wise whitening technique is introduced into the model. Before each convolutional layer, a whitening layer is embedded to sphere the input data. By layers of mapping, raw images are transformed into high-level feature representations which would boost the performance of the subsequent support vector machine classifier. The proposed algorithm is evaluated by extensive experimentations and demonstrates superior classification performance to state-of-the-art unsupervised networks.",
Cost-Efficient Strategies for Restraining Rumor Spreading in Mobile Social Networks,"With the popularity of mobile devices, mobile social networks (MSNs) have become an important platform for information dissemination. However, the spread of rumors in MSNs present a massive social threat. Currently, there are two kinds of methods to address this: blocking rumors at influential users and spreading truth to clarify rumors. However, most existing works either overlook the cost of various methods or only consider different methods individually. This paper proposes a heterogeneous-network-based epidemic model that incorporates the two kinds of methods to describe rumor spreading in MSNs. Moreover, two cost-efficient strategies are designed to restrain rumors. The first strategy is the real-time optimization strategy that minimizes the rumor-restraining cost by optimally combining various rumor-restraining methods such that a rumor can be extinct within an expected time period. The second strategy is the pulse spreading truth and continuous blocking rumor strategy that restrains rumor spreading through spreading truth periodically. The two strategies can restrain rumors in a continuous or periodical manner and guarantee cost efficiency. The experiments toward the Digg2009 data set demonstrate the effectiveness of the proposed model and the efficiency of the two strategies.",
Generalized Precoding-Aided Quadrature Spatial Modulation,"In this paper, we propose a novel scheme, which is called generalized precoding-aided quadrature spatial modulation (GPQSM), that extends the conventional quadrature spatial modulation to the receiver side. In GPQSM, spatial modulation works in both the in-phase and quadrature parts of the received signals, thus conveying additional information bits compared with conventional generalized precoding-aided spatial modulation (GPSM). The proposed scheme is general and can degenerate into the conventional multiple-input multiple-output (MIMO) scheme. A closed-form upper bound on the average bit error probability of GPQSM is derived. Simulation results verify the theoretical analysis and show that GPQSM outperforms the conventional GPSM scheme and the MIMO scheme under the same spectral efficiency.",
Networking for Big Data: A Survey,"Complementary to the fancy big data applications, networking for big data is an indispensable supporting platform for these applications in practice. This emerging research branch has gained extensive attention from both academia and industry in recent years. In this new territory, researchers are facing many unprecedented theoretical and practical challenges. We are therefore motivated to solicit the latest works in this area, aiming to pave a comprehensive and solid starting ground for interested readers. We first clarify the definition of networking for big data based on the cross disciplinary nature and integrated needs of the domain. Second, we present the current understanding of big data from different levels, including its formation, networking features, mathematical representations, and the networking technologies. Third, we discuss the challenges and opportunities from various perspectives in this hopeful field. We further summarize the lessons we learned based on the survey. We humbly hope this paper will shed light for forthcoming researchers to further explore the uncharted part of this promising land.",
An Overview and Deep Investigation on Sampled-Data-Based Event-Triggered Control and Filtering for Networked Systems,"This paper provides an overview and makes a deep investigation on sampled-data-based event-triggered control and filtering for networked systems. Compared with some existing event-triggered and self-triggered schemes, a sampled-data-based event-triggered scheme can ensure a positive minimum inter-event time and make it possible to jointly design suitable feedback controllers and event-triggered threshold parameters. Thus, more attention has been paid to the sampled-data-based event-triggered scheme. A deep investigation is first made on the sampled-data-based event-triggered scheme. Then, recent results on sampled-data-based event-triggered state feedback control, dynamic output feedback control, H∞ filtering for networked systems are surveyed and analyzed. An overview on sampled-data-based event-triggered consensus for distributed multiagent systems is given. Finally, some challenging issues are addressed to direct the future research.","Adaptive control,
Informatics,
Communication networks,
Closed loop systems,
Delays,
State feedback"
Data-Driven Tracking Control With Adaptive Dynamic Programming for a Class of Continuous-Time Nonlinear Systems,"A data-driven adaptive tracking control approach is proposed for a class of continuous-time nonlinear systems using a recent developed goal representation heuristic dynamic programming (GrHDP) architecture. The major focus of this paper is on designing a multivariable tracking scheme, including the filter-based action network (FAN) architecture, and the stability analysis in continuous-time fashion. In this design, the FAN is used to observe the system function, and then generates the corresponding control action together with the reference signals. The goal network will provide an internal reward signal adaptively based on the current system states and the control action. This internal reward signal is assigned as the input for the critic network, which approximates the cost function over time. We demonstrate its improved tracking performance in comparison with the existing heuristic dynamic programming (HDP) approach under the same parameter and environment settings. The simulation results of the multivariable tracking control on two examples have been presented to show that the proposed scheme can achieve better control in terms of learning speed and overall performance.",
Exploring Representativeness and Informativeness for Active Learning,"How can we find a general way to choose the most suitable samples for training a classifier? Even with very limited prior information? Active learning, which can be regarded as an iterative optimization procedure, plays a key role to construct a refined training set to improve the classification performance in a variety of applications, such as text analysis, image recognition, social network modeling, etc. Although combining representativeness and informativeness of samples has been proven promising for active sampling, state-of-the-art methods perform well under certain data structures. Then can we find a way to fuse the two active sampling criteria without any assumption on data? This paper proposes a general active learning framework that effectively fuses the two criteria. Inspired by a two-sample discrepancy problem, triple measures are elaborately designed to guarantee that the query samples not only possess the representativeness of the unlabeled data but also reveal the diversity of the labeled data. Any appropriate similarity measure can be employed to construct the triple measures. Meanwhile, an uncertain measure is leveraged to generate the informativeness criterion, which can be carried out in different ways. Rooted in this framework, a practical active learning algorithm is proposed, which exploits a radial basis function together with the estimated probabilities to construct the triple measures and a modified best-versus-second-best strategy to construct the uncertain measure, respectively. Experimental results on benchmark datasets demonstrate that our algorithm consistently achieves superior performance over the state-of-the-art active learning algorithms.","Measurement uncertainty,
Uncertainty,
Algorithm design and analysis,
Training,
Data models,
Data structures,
Fuses"
Containment Maneuvering of Marine Surface Vehicles With Multiple Parameterized Paths via Spatial-Temporal Decoupling,"The containment maneuvering of marine surface vehicles has two objectives. The first one is to force the marine vehicles to follow a convex hull spanned by multiple parameterized paths. The second one is to meet the requirement of a desired dynamic behavior along multiple paths during containment. A modular design approach to the containment maneuvering of marine surface vehicles is presented. At first, an estimator module using a recurrent neural network is proposed to estimate the unknown kinetics induced by model uncertainty, unmodeled dynamics, and environmental disturbances. Next, a controller module is developed based on a distributed path maneuvering design and a linear tracking differentiator. Finally, two path update laws based on a maneuvering error feedback and a filtering update scheme, respectively, are constructed. The estimator-controller pair forms a cascade system, which is proved to be input-to-state stable. The developed controller has a desirable spatial-temporal decoupling property, and geometric and dynamic objectives can be achieved separately. Results of comparative studies are provided to substantiate the efficacy of the proposed method.",
Robust Iterative Learning Control for Nonrepetitive Uncertain Systems,"This technical note proposes a robust iterative learning control (ILC) strategy to regulate iteratively-operated, finite-duration nonrepetitive systems characterized by iteration-varying uncertainties in initial states, external disturbances, plant model matrices and desired reference trajectories. Our convergence analysis exploits results on input-to-state stability of discrete parameterized systems. For a class of multiple-input, multiple-output discrete-time linear systems, with all iteration-varying uncertainties bounded, we give one condition that ensures boundedness of all system trajectories and an additional, second condition that ensures convergence of tracking error. Notably, we do not require the standard ILC contraction mapping requirement to hold at each iteration. Moreover, we show that it is possible to achieve perfect output tracking if the iteration-varying uncertainties all converge with increasing iteration.","Trajectory,
Convergence,
Robustness,
Uncertainty,
Iterative learning control,
Stability analysis,
MIMO"
Differential Evolution With Event-Triggered Impulsive Control,"Differential evolution (DE) is a simple but powerful evolutionary algorithm, which has been widely and successfully used in various areas. In this paper, an event-triggered impulsive (ETI) control scheme is introduced to improve the performance of DE. Impulsive control (IPC), the concept of which derives from control theory, aims at regulating the states of a network by instantly adjusting the states of a fraction of nodes at certain instants, and these instants are determined by event-triggered mechanism (ETM). By introducing IPC and ETM into DE, we hope to change the search performance of the population in a positive way after revising the positions of some individuals at certain moments. At the end of each generation, the IPC operation is triggered when the update rate of the population declines or equals to zero. In detail, inspired by the concepts of IPC, two types of impulses are presented within the framework of DE in this paper: 1) stabilizing impulses and 2) destabilizing impulses. Stabilizing impulses help the individuals with lower rankings instantly move to a desired state determined by the individuals with better fitness values. Destabilizing impulses randomly alter the positions of inferior individuals within the range of the current population. By means of intelligently modifying the positions of a part of individuals with these two kinds of impulses, both exploitation and exploration abilities of the whole population can be meliorated. In addition, the proposed ETI is flexible to be incorporated into several state-of-the-art DE variants. Experimental results over the IEEE Congress on Evolutionary Computation (CEC) 2014 benchmark functions exhibit that the developed scheme is simple yet effective, which significantly improves the performance of the considered DE algorithms.","Sociology,
Statistics,
Optimization,
Control theory,
Evolutionary computation,
Sun"
Medium Access Control for Wireless Body Area Networks with QoS Provisioning and Energy Efficient Design,"With the promising applications in e-Health and entertainment services, wireless body area network (WBAN) has attracted significant interest. One critical challenge for WBAN is to track and maintain the quality of service (QoS), e.g., delivery probability and latency, under the dynamic environment dictated by human mobility. Another important issue is to ensure the energy efficiency within such a resource-constrained network. In this paper, a new medium access control (MAC) protocol is proposed to tackle these two important challenges. We adopt a TDMA-based protocol and dynamically adjust the transmission order and transmission duration of the nodes based on channel status and application context of WBAN. The slot allocation is optimized by minimizing energy consumption of the nodes, subject to the delivery probability and throughput constraints. Moreover, we design a new synchronization scheme to reduce the synchronization overhead. Through developing an analytical model, we analyze how the protocol can adapt to different latency requirements in the healthcare monitoring service. Simulations results show that the proposed protocol outperforms CA-MAC and IEEE 802.15.6 MAC in terms of QoS and energy efficiency under extensive conditions. It also demonstrates more effective performance in highly heterogeneous WBAN.","Wireless communication,
Body area networks,
Media Access Protocol,
Quality of service,
Context,
Time division multiple access,
Wireless sensor networks"
WiFall: Device-Free Fall Detection by Wireless Networks,"Injuries that are caused by falls have been regarded as one of the major health threats to the independent living for the elderly. Conventional fall detection systems have various limitations. In this work, we first look for the correlations between different radio signal variations and activities by analyzing radio propagation model. Based on our observation, we propose WiFall, a truly unobtrusive fall detection system. WiFall employs physical layer Channel State Information (CSI) as the indicator of activities. It can detect fall of the human without hardware modification, extra environmental setup, or any wearable device. We implement WiFall on desktops equipped with commodity 802.11n NIC, and evaluate the performance in three typical indoor scenarios with several layouts of transmitter-receiver (Tx-Rx) links. In our area of interest, WiFall can achieve fall detection for a single person with high accuracy. As demonstrated by the experimental results, WiFall yields 90 percent detection precision with a false alarm rate of 15 percent on average using a one-class SVM classifier in all testing scenarios. It can also achieve average 94 percent fall detection precisions with 13 percent false alarm using Random Forest algorithm.","Wireless communication,
Wireless sensor networks,
Motion detection,
Senior citizens,
Channel state information,
Sensors,
IEEE 802.11 Standard"
Object-Level Video Advertising: An Optimization Framework,"In this paper, we present new models and algorithms for object-level video advertising. A framework that aims to embed content-relevant ads within a video stream is investigated in this context. First, a comprehensive optimization model is designed to minimize intrusiveness to viewers when ads are inserted in a video. For human clothing advertising, we design a deep convolutional neural network using face features to recognize human genders in a video stream. Human parts alignment is then implemented to extract human part features that are used for clothing retrieval. Second, we develop a heuristic algorithm to solve the proposed optimization problem. For comparison, we also employ the genetic algorithm to find solutions approaching the global optimum. Our novel framework is examined in various types of videos. Experimental results demonstrate the effectiveness of the proposed method for object-level video advertising.","Advertising,
Optimization,
Receivers,
Feature extraction,
Clothing,
Genetic algorithms,
Informatics"
A Survey on Activity Detection and Classification Using Wearable Sensors,"Activity detection and classification are very important for autonomous monitoring of humans for applications, including assistive living, rehabilitation, and surveillance. Wearable sensors have found wide-spread use in recent years due to their ever-decreasing cost, ease of deployment and use, and ability to provide continuous monitoring as opposed to sensors installed at fixed locations. Since many smart phones are now equipped with a variety of sensors, such as accelerometer, gyroscope, and camera, it has become more feasible to develop activity monitoring algorithms employing one or more of these sensors with increased accessibility. We provide a complete and comprehensive survey on activity classification with wearable sensors, covering a variety of sensing modalities, including accelerometer, gyroscope, pressure sensors, and camera- and depth-based systems. We discuss differences in activity types tackled by this breadth of sensing modalities. For example, accelerometer, gyroscope, and magnetometer systems have a history of addressing whole body motion or global type activities, whereas camera systems provide the context necessary to classify local interactions, or interactions of individuals with objects. We also found that these single sensing modalities laid the foundation for hybrid works that tackle a mix of global and local interaction-type activities. In addition to the type of sensors and type of activities classified, we provide details on each wearable system that include on-body sensor location, employed learning approach, and extent of experimental setup. We further discuss where the processing is performed, i.e., local versus remote processing, for different systems. This is one of the first surveys to provide such breadth of coverage across different wearable sensor systems for activity classification.","Wearable sensors,
Sensor systems,
Accelerometers,
Cameras,
Monitoring,
Magnetic sensors"
Continuous Probability Distribution Prediction of Image Emotions via Multitask Shared Sparse Regression,"Previous works on image emotion analysis mainly focused on predicting the dominant emotion category or the average dimension values of an image for affective image classification and regression. However, this is often insufficient in various real-world applications, as the emotions that are evoked in viewers by an image are highly subjective and different. In this paper, we propose to predict the continuous probability distribution of image emotions which are represented in dimensional valence-arousal space. We carried out large-scale statistical analysis on the constructed Image-Emotion-Social-Net dataset, on which we observed that the emotion distribution can be well-modeled by a Gaussian mixture model. This model is estimated by an expectation-maximization algorithm with specified initializations. Then, we extract commonly used emotion features at different levels for each image. Finally, we formalize the emotion distribution prediction task as a shared sparse regression (SSR) problem and extend it to multitask settings, named multitask shared sparse regression (MTSSR), to explore the latent information between different prediction tasks. SSR and MTSSR are optimized by iteratively reweighted least squares. Experiments are conducted on the Image-Emotion-Social-Net dataset with comparisons to three alternative baselines. The quantitative results demonstrate the superiority of the proposed method.",
Joint Energy Minimization and Resource Allocation in C-RAN with Mobile Cloud,"Cloud radio access network (C-RAN) has emerged as a potential candidate of the next generation access network technology to address the increasing mobile traffic, while mobile cloud computing (MCC) offers a prospective solution to the resource-limited mobile user in executing computation intensive tasks. Taking full advantages of above two cloud-based techniques, C-RAN with MCC are presented in this paper to enhance both performance and energy efficiencies. In particular, this paper studies the joint energy minimization and resource allocation in C-RAN with MCC under the time constraints of the given tasks. We first review the energy and time model of the computation and communication. Then, we formulate the joint energy minimization into a non-convex optimization with the constraints of task executing time, transmitting power, computation capacity and fronthaul data rates. This non-convex optimization is then reformulated into an equivalent convex problem based on weighted minimum mean square error (WMMSE). The iterative algorithm is finally given to deal with the joint resource allocation in C-RAN with mobile cloud. Simulation results confirm that the proposed energy minimization and resource allocation solution can improve the system performance and save energy.",
Neural Network-Based Adaptive Leader-Following Consensus Control for a Class of Nonlinear Multiagent State-Delay Systems,"Compared with the existing neural network (NN) or fuzzy logic system (FLS) based adaptive consensus methods, the proposed approach can greatly alleviate the computation burden because it needs only to update a few adaptive parameters online. In the multiagent agreement control, the system uncertainties derive from the unknown nonlinear dynamics are counteracted by employing the adaptive NNs; the state delays are compensated by designing a Lyapunov-Krasovskii functional. Finally, based on Lyapunov stability theory, it is demonstrated that the proposed consensus scheme can steer a multiagent system synchronizing to the predefined reference signals. Two simulation examples, a numerical multiagent system and a practical multimanipulator system, are carried out to further verify and testify the effectiveness of the proposed agreement approach.",
A Review of False Data Injection Attacks Against Modern Power Systems,"With rapid advances in sensor, computer, and communication networks, modern power systems have become complicated cyber-physical systems. Assessing and enhancing cyber-physical system security is, therefore, of utmost importance for the future electricity grid. In a successful false data injection attack (FDIA), an attacker compromises measurements from grid sensors in such a way that undetected errors are introduced into estimates of state variables such as bus voltage angles and magnitudes. In evading detection by commonly employed residue-based bad data detection tests, FDIAs are capable of severely threatening power system security. Since the first published research on FDIAs in 2009, research into FDIA-based cyber-attacks has been extensive. This paper gives a comprehensive review of state-of-the-art in FDIAs against modern power systems. This paper first summarizes the theoretical basis of FDIAs, and then discusses both the physical and the economic impacts of a successful FDIA. This paper presents the basic defense strategies against FDIAs and discusses some potential future research directions in this field.","Power systems,
State estimation,
Security,
Voltage measurement,
Economics,
Computational modeling,
Power measurement"
"A Survey on Energy Internet: Architecture, Approach, and Emerging Technologies","Energy crisis and carbon emission have become two seriously concerned issues universally. As a feasible solution, Energy Internet (EI) has aroused global concern once proposed. EI is a new power generation developing a vision of evolution of smart grids into the Internet. The communication infrastructure is an essential component to the implementation of EI. A scalable and permanent communication infrastructure is crucial in both construction and operation of EI. In this paper, we present an introduction and the motivation to the evolution from smart grid to EI. We also introduce a representative EI architecture, i.e., the future renewable electric energy delivery and management system. Four critical EI features are emphasized. Then, we summarize the essential requirements that EI systems have to meet. With several key supporting technologies, EI shall realize the optimal utilization of highly scalable and distributed green energy resources, so that the situation of severe energy source crisis and carbon emission can be efficiently relieved. Since an EI system might have extensively distributed consumers and devices, the guarantee of its reliability and security is extremely significant. The further specific exploration for challenges, including reliability and security, will be stated in this paper.",
3-D Memristor Crossbars for Analog and Neuromorphic Computing Applications,"We report a monolithically integrated 3-D metal-oxide memristor crossbar circuit suitable for analog, and in particular, neuromorphic computing applications. The demonstrated crossbar is based on Pt/Al2O3/TiO2-x/TiN/Pt memristors and consists of a stack of two passive 10 × 10 crossbars with shared middle electrodes. The fabrication process has a low, less than 175°C, temperature budget and includes a planarization step performed before the deposition of the second crossbar layer. These features greatly improve yield and uniformity of the crosspoint devices and allows for utilizing such a fabrication process for integration with CMOS circuits as well as for stacking of multiple crossbar layers. Furthermore, the integrated crosspoint memristors are optimized for analog computing applications allowing successful forming and switching of all 200 devices in the demonstrated crossbar circuit, and, most importantly, precise tuning of the devices' conductance values within the dynamic range of operation. We believe that the demonstrated work is an important milestone toward the implementation of analog artificial neural networks, specifically, those based on 3-D CMOL circuits.","Electrodes,
Memristors,
Fabrication,
Planarization,
Tuning,
Threshold voltage,
Neuromorphics"
"K
-Clique Community Detection in Social Networks Based on Formal Concept Analysis","With the advent of ubiquitous sensing and networking, future social networks turn into cyber-physical interactions, which are attached with associated social attributes. Therefore, social network analysis is advancing the interconnections among cyber, physical, and social spaces. Community detection is an important issue in social network analysis. Users in a social network usually have some social interactions with their friends in a community because of their common interests or similar profiles. In this paper, an efficient algorithm of k-clique community detection using formal concept analysis (FCA) - a typical computational intelligence technique, namely, FCA-based k-clique community detection algorithm, is proposed. First, a formal context is constructed from a given social network by a modified adjacency matrix. Second, we define a type of special concept named k-equiconcept, which has the same k-size of extent and intent in a formal concept lattice. Then, we prove that the k-clique detection problem is equivalent to finding the k-equiconcepts. Finally, the efficient algorithms for detecting the k-cliques and k-clique communities are devised by virtue of k-equiconcepts and k-intent concepts, respectively. Experimental results demonstrate that the proposed algorithm has a higher F-measure value and significantly reduces the computational cost compared with previous works. In addition, a correlation between k and the number of k-clique communities is investigated.",
A Locality-Constrained and Label Embedding Dictionary Learning Algorithm for Image Classification,"Locality and label information of training samples play an important role in image classification. However, previous dictionary learning algorithms do not take the locality and label information of atoms into account together in the learning process, and thus their performance is limited. In this paper, a discriminative dictionary learning algorithm, called the locality-constrained and label embedding dictionary learning (LCLE-DL) algorithm, was proposed for image classification. First, the locality information was preserved using the graph Laplacian matrix of the learned dictionary instead of the conventional one derived from the training samples. Then, the label embedding term was constructed using the label information of atoms instead of the classification error term, which contained discriminating information of the learned dictionary. The optimal coding coefficients derived by the locality-based and label-based reconstruction were effective for image classification. Experimental results demonstrated that the LCLE-DL algorithm can achieve better performance than some state-of-the-art algorithms.",
Crowdsourcing based Description of Urban Emergency Events using Social Media Big Data,"Crowdsourcing is a process of acquisition, integration, and analysis of big and heterogeneous data generated by a diversity of sources in urban spaces, such as sensors, devices, vehicles, buildings, and human. Especially, nowadays, no countries, no communities, and no person are immune to urban emergency events. Detection about urban emergency events, e.g., fires, storms, traffic jams is of great importance to protect the security of humans. Recently, social media feeds are rapidly emerging as a novel platform for providing and dissemination of information that is often geographic. The content from social media usually includes references to urban emergency events occurring at, or affecting specific locations. In this paper, in order to detect and describe the real time urban emergency event, the 5W (What, Where, When, Who, and Why) model is proposed. Firstly, users of social media are set as the target of crowd sourcing. Secondly, the spatial and temporal information from the social media are extracted to detect the real time event. Thirdly, a GIS based annotation of the detected urban emergency event is shown. The proposed method is evaluated with extensive case studies based on real urban emergency events. The results show the accuracy and efficiency of the proposed method.","Sensors,
Fires,
Real-time systems,
Media,
Cities and towns,
Social network services,
Crowdsourcing"
Energy Optimization With Dynamic Task Scheduling Mobile Cloud Computing,"The smartphone is a typical cyberphysical system (CPS). It must be low energy consuming and highly reliable to deal with the simple but frequent interactions with the cloud, which constitutes the cloud-integrated CPS. Dynamic voltage scaling (DVS) has emerged as a critical technique to leverage power management by lowering the supply voltage and frequency of processors. In this paper, based on the DVS technique, we propose a novel Energy-aware Dynamic Task Scheduling (EDTS) algorithm to minimize the total energy consumption for smartphones, while satisfying stringent time constraints and the probability constraint for applications. Experimental results indicate that the EDTS algorithm can significantly reduce energy consumption for CPS, as compared to the critical path scheduling method and the parallelism-based scheduling algorithm.","Heuristic algorithms,
Energy consumption,
Dynamic scheduling,
Timing,
Schedules,
Processor scheduling"
Collective Data-Sanitization for Preventing Sensitive Information Inference Attacks in Social Networks,"Releasing social network data could seriously breach user privacy. User profile and friendship relations are inherently private. Unfortunately, it is possible to predict sensitive information carried in released data latently by utilizing data mining techniques. Therefore, sanitizing network data prior to release is necessary. In this paper, we explore how to launch an inference attack exploiting social networks with a mixture of non-sensitive attributes and social relationships. We map this issue to a collective classification problem and propose a collective inference model. In our model, an attacker utilizes user profile and social relationships in a collective manner to predict sensitive information of related victims in a released social network dataset. To protect against such attacks, we propose a data sanitization method collectively manipulating user profile and friendship relations. The key novel idea lies that besides sanitizing friendship relations, the proposed method can take advantages of various data-manipulating methods. We show that we can easily reduce adversary’s prediction accuracy on sensitive information, while resulting in less accuracy decrease on non-sensitive information towards three social network datasets. To the best of our knowledge, this is the first work that employs collective methods involving various data-manipulating methods and social relationships to protect against inference attacks in social networks.","Data privacy,
Privacy,
Facebook,
Motion pictures,
Knowledge engineering"
Full-Diversity Dispersion Matrices From Algebraic Field Extensions for Differential Spatial Modulation,"We consider differential spatial modulation (DSM) operating in a block fading environment and propose sparse unitary dispersion matrices (DMs) using algebraic field extensions. The proposed DM sets are capable of exploiting full transmit diversity and, in contrast to the existing schemes, can be constructed for systems having an arbitrary number of transmit antennas. More specifically, two schemes are proposed: 1) field-extension-based DSM (FE-DSM), where only a single conventional symbol is transmitted per space-time block; and 2) FE-DSM striking a diversity-rate tradeoff (FE-DSM-DR), where multiple symbols are transmitted in each space-time block at the cost of a reduced transmit diversity gain. Furthermore, the FE-DSM scheme is analytically shown to achieve full transmit diversity, and both proposed schemes are shown to impose decoding complexity, which is independent of the size of the signal set. It is observed from our simulation results that the proposed FE-DSM scheme suffers no performance loss compared with the existing DM-based DSM (DM-DSM) scheme, whereas FE-DSM-DR is observed to give a better bit-error-ratio performance at higher data rates than its DM-DSM counterpart. Specifically, at data rates of 2.25 and 2.75 bits per channel use, FE-DSM-DR is observed to achieve about 1- and 2-dB signal-to-noise ratio (SNR) gain with respect to its DM-DSM counterpart.","Complexity theory,
Modulation,
Receivers,
Dispersion,
MIMO,
Radio frequency,
Encoding"
Game-Theoretic Market-Driven Smart Home Scheduling Considering Energy Balancing,"In a smart community infrastructure that consists of multiple smart homes, smart controllers schedule various home appliances to balance energy consumption and reduce electricity bills of customers. In this paper, the impact of the smart home scheduling to the electricity market is analyzed with a new smart-home-aware bi-level market model. In this model, the customers schedule home appliances for bill reduction at the community level, whereas aggregators minimize the energy purchasing expense from utilities at the market level, both of which consider the smart home scheduling impacts. A game-theoretic algorithm is proposed to solve this formulation that handles the bidirectional influence between both levels. Comparing with the electricity market without smart home scheduling, our proposed infrastructure balances the energy load through reducing the peak-to-average ratio by up to 35.9%, whereas the average customer bill is reduced by up to 34.3%.","Smart homes,
Communities,
Home appliances,
Generators,
Pricing,
Energy consumption,
Games"
Nopol: Automatic Repair of Conditional Statement Bugs in Java Programs,"We propose Nopol, an approach to automatic repair of buggy conditional statements (i.e., if-then-else statements). This approach takes a buggy program as well as a test suite as input and generates a patch with a conditional expression as output. The test suite is required to contain passing test cases to model the expected behavior of the program and at least one failing test case that reveals the bug to be repaired. The process of Nopol consists of three major phases. First, Nopol employs angelic fix localization to identify expected values of a condition during the test execution. Second, runtime trace collection is used to collect variables and their actual values, including primitive data types and objected-oriented features (e.g., nullness checks), to serve as building blocks for patch generation. Third, Nopol encodes these collected data into an instance of a Satisfiability Modulo Theory (SMT) problem; then a feasible solution to the SMT instance is translated back into a code patch. We evaluate Nopol on 22 real-world bugs (16 bugs with buggy if conditions and six bugs with missing preconditions) on two large open-source projects, namely Apache Commons Math and Apache Commons Lang. Empirical analysis on these bugs shows that our approach can effectively fix bugs with buggy if conditions and missing preconditions. We illustrate the capabilities and limitations of Nopol using case studies of real bug fixes.","Maintenance engineering,
Computer bugs,
Runtime,
Java,
Encoding,
Open source software,
Indexes"
Object Detection Networks on Convolutional Feature Maps,"Most object detectors contain two important components: a feature extractor and an object classifier. The feature extractor has rapidly evolved with significant research efforts leading to better deep convolutional architectures. The object classifier, however, has not received much attention and many recent systems (like SPPnet and Fast/Faster R-CNN) use simple multi-layer perceptrons. This paper demonstrates that carefully designing deep networks for object classification is just as important. We experiment with region-wise classifier networks that use shared, region-independent convolutional features. We call them “Networks on Convolutional feature maps” (NoCs). We discover that aside from deep feature maps, a deep and convolutional per-region classifier is of particular importance for object detection, whereas latest superior image classification models (such as ResNets and GoogLeNets) do not directly lead to good detection accuracy without using such a per-region classifier. We show by experiments that despite the effective ResNets and Faster R-CNN systems, the design of NoCs is an essential element for the 1st-place winning entries in ImageNet and MS COCO challenges 2015.",
Generalized Dual-Mode Index Modulation Aided OFDM,"Dual-mode index modulation aided orthogonal frequency division multiplexing (DM-OFDM) is recently proposed, where subcarriers are partitioned into OFDM subblocks, divided into two groups within each subblock, and modulated by two differentiable constellation alphabets. In DM-OFDM, additional bits can be transmitted through indices of subcarriers modulated by the same constellation alphabet. In this letter, generalized DM-OFDM (GDM-OFDM) is proposed, where the number of subcarriers modulated by the same constellation mode in each subblock is alterable. By applying such enhancements, the spectral efficiency can be improved at the cost of marginal performance loss. Moreover, since the bit error rate performance of GDM-OFDM degrades at low signal-to-noise ratios, an interleaving technique is employed to address this issue. At the receiver, a maximum-likelihood detector and a reduced-complexity log-likelihood ratio detector are employed for demodulation. Simulation results demonstrate that the proposed GDM-OFDM is capable of enhancing the spectral efficiency compared with DM-OFDM at the cost of negligible performance loss, and the interleaved GDM-OFDM can harvest on performance gain over GDM-OFDM.",
Scheduling of Single-Arm Cluster Tools for an Atomic Layer Deposition Process With Residency Time Constraints,"In semiconductor manufacturing, there are wafer fabrication processes with wafer revisiting. Some of them must meet wafer residency time constraints. Taking atomic layer deposition (ALD) as a typical wafer revisiting process, this paper studies the challenging scheduling problem of single-arm cluster tools for the ALD process with wafer residency time constraints. It is found that there are only several scheduling strategies that are applicable to this problem and one needs to apply each of them to decide whether a feasible schedule can be found or not. This work, for each applicable strategy, performs the schedulability analysis and derives the schedulability conditions for such tools for the first time. It proposes scheduling algorithms to obtain an optimal schedule efficiently if such conditions are met. It finally gives illustrative examples to show the application of the proposed concepts and approach.","Schedules,
Robots,
Optimal scheduling,
Time factors,
Semiconductor device modeling,
Petri nets,
Job shop scheduling"
Fundamental Limits of Parallel Optical Wireless Channels: Capacity Results and Outage Formulation,"Multi-channel (MC) optical wireless communication (OWC) systems employing wave-division multiplexing for outdoors free-space optical communications, or multi-user time-division multiple access for indoors visible-light communications, e.g., can be modeled as parallel channels. Multi-input multi-output OWC systems can also be transformed, possibly with some performance loss, to parallel channels using pre-/post-coding. Studying the performance of such MC-OWC systems requires characterizing the capacity of the underlying parallel channels. In this paper, upper and lower bounds on the capacity of constant parallel OWC channels with a total average intensity constraint are derived. Then, this paper focuses on finding intensity allocations that maximize the lower bounds given channel-state information at the transmitter (CSIT). Due to its nonconvexity, the Karush-Kuhn-Tucker conditions are used to describe a list of candidate allocations. Instead searching exhaustively for the best solution, low-complexity near-optimal algorithms are proposed. The resulting optimized lower bound nearly coincides with capacity at high signal-to-noise ratio (SNR). Under a quasi-static channel model and in the absence of CSIT, outage probability upper and lower bounds are derived. Those bounds also meet at high SNR, thus characterizing the outage capacity in this regime. Finally, the results are extended to a system with both average and peak intensity constraints.",
Energy-Aware Load Balancing and Application Scaling for the Cloud Ecosystem,"In this paper, we introduce an energy-aware operation model used for load balancing and application scaling on a cloud. The basic philosophy of our approach is defining an energy-optimal operation regime and attempting to maximize the number of servers operating in this regime. Idle and lightly-loaded servers are switched to one of the sleep states to save energy. The load balancing and scaling algorithms also exploit some of the most desirable features of server consolidation mechanisms discussed in the literature.",
A Hierarchical Active Balancing Architecture for Lithium-Ion Batteries,"This paper proposes a hierarchical active balancing architecture for the series-connected lithium-ion batteries. The key point of the architecture is that by grouping the battery string into different packs and introducing the top layer, the coupled influence among the cells in different packs is eliminated, which reduces the required balancing time and the energy loss. The repeated charging and discharging problem is avoided, which is beneficial for increasing the state-of-health. Moreover, the proposed architecture can lower the current rating of the balancing circuits, which helps decrease the required cost and improve the system efficiency. On the basis of the architecture, a balancing control using the state-of-charge of each cell is proposed to achieve the balance for all the cells. Furthermore, to deliver the energy from one pack to any other pack bidirectionally, a multidirectional multiport converter along with the current control method is proposed to serve as the top layer. This converter is different from the conventional three-port converter as it can achieve the arbitrary current flow direction control for any number of ports. The experimental results based on 24 series-connected 200-Ah lithium-ion batteries verified the benefits of the proposed architecture and the balancing circuits. After balancing, 4.1% of the total energy of the battery string is saved. Compared to the conventional adjacent cell-to-cell architecture, the proposed architecture can decrease the balancing time and the energy loss during the balancing process by 27.6% and 44.0%, respectively. In addition, the current rating and the cost of the balancing circuits in the proposed architecture is only 37.5% and 11.5% of that in other references.","Computer architecture,
Batteries,
Energy loss,
Bidirectional control,
Renewable energy sources"
Toward Dependable Embedded Model Predictive Control,"While model predictive control (MPC) is the industrially preferred method for advanced control in the process industries, it has not found much use in consumer products and safety-critical embedded systems applications in industries such as automotive, aerospace, medical, and robotics. The main barriers are implementability and dependability, where important factors are implementation of advanced numerical optimization algorithms on resource-limited embedded computing platforms and the associated complexity of verification. This challenge comes from a requirement of the use of ultrareliable hardware and software architectures in safety-critical applications, low-cost hardware in consumer products, or both. This paper surveys the state-of-the-art in the emerging field of dependable embedded MPC, and discusses some key challenges related to its design, implementation, and verification. A novel result is the study of a simulator-based performance monitoring and control selection method that monitors and predicts MPC performance and switches to a highly reliable backup controller in cases when the MPC experiences performance issues.","Safety,
Computer architecture,
Software,
Optimization,
Control systems,
Hardware,
Software algorithms"
Exploiting Adversarial Jamming Signals for Energy Harvesting in Interference Networks,"Anti-jamming interference alignment (IA) is an effective method for battling adversarial jammers for IA networks. Nevertheless, the number of antennas may not be enough to make it feasible in anti-jamming IA. Besides, the abundant power from the jammers and interferences, which used to be deemed as a harmful factor, can be exploited for energy harvesting (EH) by the legitimate users as a power supply. Thus, in this paper, we propose an anti-jamming opportunistic IA (OIA) scheme with wireless EH, which optimizes the transmission rate and EH together. In the proposed scheme, to make the anti-jamming IA network feasible, we select some of the users to transmit information at each time slot, and EH is performed by the other unselected users. Furthermore, to improve the performance of the proposed scheme, EH is also performed by the selected users, and the transmit power and power partition coefficient are jointly optimized to minimize the total transmit power of the OIA network. To reduce the computational complexity of the joint optimization, a suboptimal algorithm is also developed with much lower complexity. Extensive simulation results are presented to show the effectiveness of the proposed anti-jamming OIA scheme with wireless EH.","Jamming,
Interference,
Receivers,
Wireless networks,
Energy harvesting,
Optimization"
The Crowd in Requirements Engineering: The Landscape and Challenges,"Crowd-based requirements engineering (CrowdRE) could significantly change RE. Performing RE activities such as elicitation with the crowd of stakeholders turns RE into a participatory effort, leads to more accurate requirements, and ultimately boosts software quality. Although any stakeholder in the crowd can contribute, CrowdRE emphasizes one stakeholder group whose role is often trivialized: users. CrowdRE empowers the management of requirements, such as their prioritization and segmentation, in a dynamic, evolved style through collecting and harnessing a continuous flow of user feedback and monitoring data on the usage context. To analyze the large amount of data obtained from the crowd, automated approaches are key. This article presents current research topics in CrowdRE; discusses the benefits, challenges, and lessons learned from projects and experiments; and assesses how to apply the methods and tools in industrial contexts. This article is part of a special issue on Crowdsourcing for Software Engineering.","Software development,
Context awareness,
Monitoring,
Context modeling,
Stakeholders,
Crowdsourcing,
Software engineering"
Revisiting Co-Saliency Detection: A Novel Approach Based on Two-Stage Multi-View Spectral Rotation Co-clustering,"With the goal of discovering the common and salient objects from the given image group, co-saliency detection has received tremendous research interest in recent years. However, as most of the existing co-saliency detection methods are performed based on the assumption that all the images in the given image group should contain co-salient objects in only one category, they can hardly be applied in practice, particularly for the large-scale image set obtained from the Internet. To address this problem, this paper revisits the co-saliency detection task and advances its development into a new phase, where the problem setting is generalized to allow the image group to contain objects in arbitrary number of categories and the algorithms need to simultaneously detect multi-class co-salient objects from such complex data. To solve this new challenge, we decompose it into two sub-problems, i.e., how to identify subgroups of relevant images and how to discover relevant co-salient objects from each subgroup, and propose a novel co-saliency detection framework to correspondingly address the two sub-problems via two-stage multi-view spectral rotation co-clustering. Comprehensive experiments on two publically available benchmarks demonstrate the effectiveness of the proposed approach. Notably, it can even outperform the state-of-the-art co-saliency detection methods, which are performed based on the image subgroups carefully separated by the human labor.","Proposals,
Object detection,
Clustering algorithms,
Benchmark testing,
Algorithm design and analysis,
Internet,
Visualization"
Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation,"We propose a unified approach for bottom-up hierarchical image segmentation and object proposal generation for recognition, called Multiscale Combinatorial Grouping (MCG). For this purpose, we first develop a fast normalized cuts algorithm. We then propose a high-performance hierarchical segmenter that makes effective use of multiscale information. Finally, we propose a grouping strategy that combines our multiscale regions into highly-accurate object proposals by exploring efficiently their combinatorial space. We also present Single-scale Combinatorial Grouping (SCG), a faster version of MCG that produces competitive proposals in under five seconds per image. We conduct an extensive and comprehensive empirical validation on the BSDS500, SegVOC12, SBD, and COCO datasets, showing that MCG produces state-of-the-art contours, hierarchical regions, and object proposals.",
A Distributed Networked Approach for Fault Detection of Large-Scale Systems,"Networked systems present some key new challenges in the development of fault-diagnosis architectures. This paper proposes a novel distributed networked fault detection methodology for large-scale interconnected systems. The proposed formulation incorporates a synchronization methodology with a filtering approach in order to reduce the effect of measurement noise and time delays on the fault detection performance. The proposed approach allows the monitoring of multirate systems, where asynchronous and delayed measurements are available. This is achieved through the development of a virtual sensor scheme with a model-based resynchronization algorithm and a delay compensation strategy for distributed fault-diagnostic units. The monitoring architecture exploits an adaptive approximator with learning capabilities for handling uncertainties in the interconnection dynamics. A consensus-based estimator with time-varying weights is introduced, for improving fault detectability in the case of variables shared among more than one subsystem. Furthermore, time-varying threshold functions are designed to prevent false-positive alarms. Analytical fault detectability sufficient conditions are derived, and extensive simulation results are presented to illustrate the effectiveness of the distributed fault detection technique.","Fault detection,
Fault diagnosis,
Delays,
Monitoring,
Large-scale systems,
Mathematical model,
Noise measurement"
A Lightweight Privacy-Preserving Data Aggregation Scheme for Fog Computing-Enhanced IoT,"Fog computing-enhanced Internet of Things (IoT) has recently received considerable attention, as the fog devices deployed at the network edge can not only provide low latency, location awareness but also improve real-time and quality of services in IoT application scenarios. Privacy-preserving data aggregation is one of typical fog computing applications in IoT, and many privacy-preserving data aggregation schemes have been proposed in the past years. However, most of them only support data aggregation for homogeneous IoT devices, and cannot aggregate hybrid IoT devices' data into one in some real IoT applications. To address this challenge, in this paper, we present a lightweight privacy-preserving data aggregation scheme, called Lightweight Privacy-preserving Data Aggregation, for fog computing-enhanced IoT. The proposed LPDA is characterized by employing the homomorphic Paillier encryption, Chinese Remainder Theorem, and one-way hash chain techniques to not only aggregate hybrid IoT devices' data into one, but also early filter injected false data at the network edge. Detailed security analysis shows LPDA is really secure and privacy-enhanced with differential privacy techniques. In addition, extensive performance evaluations are conducted, and the results indicate LPDA is really lightweight in fog computing-enhanced IoT.","cryptography,
data aggregation,
data privacy,
Internet of Things"
Coordinated Beamforming for Multi-Cell MIMO-NOMA,"In this letter, two novel coordinated beamforming techniques are developed to enhance the performance of non-orthogonal multiple access combined with multiple-input multiple-output communication in the presence of inter-cell interference. The proposed schemes successfully deal with inter-cell interference, and increase the cell-edge users' throughput, which in turn improves user fairness. In addition, they increase the number of served users, which makes them suitable for 5G networks where massive connectivity and higher spectral efficiency are required. Numerical results confirm the effectiveness of the proposed algorithms.","Interference,
NOMA,
Array signal processing,
Indexes,
MIMO,
Throughput,
Downlink"
Robust Visual Tracking via Basis Matching,"Most existing tracking approaches are based on either the tracking by detection framework or the tracking by matching framework. The former needs to learn a discriminative classifier using positive and negative samples, which will cause tracking drift due to unreliable samples. The latter usually performs tracking by matching local interest points between a target candidate and the tracked target, which is not robust to target appearance changes over time. In this paper, we propose a novel tracking by matching framework for robust tracking based on basis matching rather than point matching. In particular, we learn the target model from target images using a set of Gabor basis functions, which have large responses on the corresponding spatial positions after a max pooling. During tracking, a target candidate is evaluated by computing the responses of the Gabor basis functions on their corresponding spatial positions. The experimental results on a set of challenging sequences validate that the performance of the proposed tracking method outperforms those of several state-of-the-art methods.",
A Three-Level Space Vector Modulation Scheme for Paralleled Converters to Reduce Circulating Current and Common-Mode Voltage,"For high-power applications, paralleling converters is a popular approach to increase the power capacity of the system. Circulating current has been a major concern for the implementation of paralleled converters. This paper proposes a three-level space vector modulation (SVM) scheme for a system with two paralleled voltage-source converters (VSCs) with common-mode inductor (CMI) or single-phase inductors. The proposed scheme aims to reduce the zero-sequence circulating current (ZSCC) and the magnitude of common-mode voltage (CMV) of the system simultaneously. The ZSCC patterns with respect to modulation schemes are first analyzed to provide a clear understanding of the generation of ZSCC. Based on the analysis, the proposed three-level modulation scheme is introduced. Furthermore, performance regarding the ZSCC peak value, impact on the common-mode current (CMC), CMI scaling analysis, and switching losses are analyzed and compared with the existing methods. The proposed method has been verified in both simulation and experiment.",
Generalized-Spatial-Modulation-Based Reduced-RF-Chain Millimeter-Wave Communications,"A generalized spatial modulation (GSM)-based millimeter-wave communications system is proposed. The GSM transmitter is characterized by a lower number of radio frequency (RF) chains than the number of transmit antennas; hence, it is capable of reducing both the transmitter cost and the energy consumption. The antenna array alignment is optimized so as to maximize the rank of the channel matrix encountered. Furthermore, we employ an array of analog beamformers, which allows us to benefit both from the beamforming gain and from the GSM scheme's high rate. It is demonstrated that the constrained capacity of the GSM transmitter equipped with as few as two RF chains is capable of approaching the performance of the full-RF spatial multiplexing having eight RF chains.","GSM,
Receivers,
Radio frequency,
MIMO,
Radio transmitters,
Transmitting antennas"
Anonymous Authentication for Wireless Body Area Networks With Provable Security,"Advances in wireless communications, embedded systems, and integrated circuit technologies have enabled the wireless body area network (WBAN) to become a promising networking paradigm. Over the last decade, as an important part of the Internet of Things, we have witnessed WBANs playing an increasing role in modern medical systems because of its capabilities to collect real-time biomedical data through intelligent medical sensors in or around the patients' body and send the collected data to remote medical personnel for clinical diagnostics. WBANs not only bring us conveniences but also bring along the challenge of keeping data's confidentiality and preserving patients' privacy. In the past few years, several anonymous authentication (AA) schemes for WBANs were proposed to enhance security by protecting patients' identities and by encrypting medical data. However, many of these schemes are not secure enough. First, we review the most recent AA scheme for WBANs and point out that it is not secure for medical applications by proposing an impersonation attack. After that, we propose a new AA scheme for WBANs and prove that it is provably secure. Our detailed analysis results demonstrate that our proposed AA scheme not only overcomes the security weaknesses in previous schemes but also has the same computation costs at a client side.",
Learning on Big Graph: Label Inference and Regularization with Anchor Hierarchy,"Several models have been proposed to cope with the rapidly increasing size of data, such as Anchor Graph Regularization (AGR). The AGR approach significantly accelerates graph-based learning by exploring a set of anchors. However, when a dataset becomes much larger, AGR still faces a big graph which brings dramatically increasing computational costs. To overcome this issue, we propose a novel Hierarchical Anchor Graph Regularization (HAGR) approach by exploring multiple-layer anchors with a pyramid-style structure. In HAGR, the labels of datapoints are inferred from the coarsest anchors layer by layer in a coarse-to-fine manner. The label smoothness regularization is performed on all datapoints, and we demonstrate that the optimization process only involves a small-size reduced Laplacian matrix. We also introduce a fast approach to construct our hierarchical anchor graph based on an approximate nearest neighbor search technique. Experiments on million-scale datasets demonstrate the effectiveness and efficiency of the proposed HAGR approach over existing methods. Results show that the HAGR approach is even able to achieve a good performance within 3 minutes in an 8-million-example classification task.",
Event-Driven Adaptive Robust Control of Nonlinear Systems With Uncertainties Through NDP Strategy,"In this paper, we construct an event-driven adaptive robust control approach for continuous-time uncertain nonlinear systems through a neural dynamic programming (NDP) strategy. Through system transformation and theoretical analysis, the robustness of the original uncertain system can be achieved by designing an event-driven optimal controller with respect to the nominal system under a suitable triggering condition. In addition, it is also observed that the event-driven controller has a certain degree of gain margin. Then, the NDP technique is employed to perform the main controller design task, followed by the uniform ultimate boundedness stability proof with the feedback action of the event-driven adaptive control law. The comparative effect of the present control strategy is also illustrated via two simulation examples. The established method provides a new avenue of combining adaptive dynamic programming-based self-learning control, event-triggered adaptive control, and robust control, to investigate the nonlinear adaptive robust feedback design under uncertain environment.","Robustness,
Optimal control,
Nonlinear systems,
Cost function,
Robust control,
Adaptive systems,
Uncertainty"
Maximizing the Performance of 650-V p-GaN Gate HEMTs: Dynamic RON Characterization and Circuit Design Considerations,"The systematic characterization of a 650-V/13-A enhancement-mode GaN power transistor with p-GaN gate is presented. Critical device parameters such as ON-resistance RON and threshold voltage VTH are evaluated under both static and dynamic (i.e., switching) operating conditions. The dynamic RON is found to exhibit different dependence on the gate drive voltage VGS from the static RON. While reasonably suppressed at higher VGS of 5 and 6 V, the degradation in dynamic RON is significantly larger at lower VGS of 3-4 V, which is attributed to the positive shift in VTH under switching operations. In addition to characterization of discrete devices, a custom-designed double-pulse test circuit with 400-V, 10-A test capability is built to evaluate the transient switching performance of the p-GaN gate power transistors. Optimal gate drive conditions are proposed to: 1) provide sufficient gate over-drive to minimize the impact of the VTH shift on the dynamic RON ; and 2) leave enough headroom to save the device from excessive gate stresses. Moreover, gate drive circuit design and board layout considerations are also discussed by taking into account the fast switching characteristics of GaN devices.","Logic gates,
HEMTs,
MODFETs,
Gallium nitride,
Silicon,
MOSFET,
Switches"
"A Survey on Internet of Things: Architecture, Enabling Technologies, Security and Privacy, and Applications","Fog/edge computing has been proposed to be integrated with Internet of Things (IoT) to enable computing services devices deployed at network edge, aiming to improve the user's experience and resilience of the services in case of failures. With the advantage of distributed architecture and close to end-users, fog/edge computing can provide faster response and greater quality of service for IoT applications. Thus, fog/edge computing-based IoT becomes future infrastructure on IoT development. To develop fog/edge computing-based IoT infrastructure, the architecture, enabling techniques, and issues related to IoT should be investigated first, and then the integration of fog/edge computing and IoT should be explored. To this end, this paper conducts a comprehensive overview of IoT with respect to system architecture, enabling technologies, security and privacy issues, and present the integration of fog/edge computing and IoT, and applications. Particularly, this paper first explores the relationship between cyber-physical systems and IoT, both of which play important roles in realizing an intelligent cyber-physical world. Then, existing architectures, enabling technologies, and security and privacy issues in IoT are presented to enhance the understanding of the state of the art IoT development. To investigate the fog/edge computing-based IoT, this paper also investigate the relationship between IoT and fog/edge computing, and discuss issues in fog/edge computing-based IoT. Finally, several applications, including the smart grid, smart transportation, and smart cities, are presented to demonstrate how fog/edge computing-based IoT to be implemented in real-world applications.","3G mobile communication,
cellular radio,
cyber-physical systems,
data privacy,
Internet of Things,
mobile computing"
Understanding Subtitles by Character-Level Sequence-to-Sequence Learning,"This paper presents a character-level seque-nce-to-sequence learning method, RNNembed. This method allows the system to read raw characters, instead of words generated by preprocessing steps, into a pure single neural network model under an end-to-end framework. Specifically, we embed a recurrent neural network into an encoder-decoder framework and generate character-level sequence representation as input. The dimension of input feature space can be significantly reduced as well as avoiding the need to handle unknown or rare words in sequences. In the language model, we improve the basic structure of a gated recurrent unit by adding an output gate, which is used for filtering out unimportant information involved in the attention scheme of the alignment model. Our proposed method was examined in a large-scale dataset on an English-to-Chinese translation task. Experimental results demonstrate that the proposed approach achieves a translation performance comparable, or close, to conventional word-based and phrase-based systems.",
Distributed Tracking of Nonlinear Multiagent Systems Under Directed Switching Topology: An Observer-Based Protocol,"This paper deals with a consensus tracking problem for multiagent systems (MASs) with Lipschitz-type nonlinear dynamics and directed switching topology. Unlike most existing works where the relative full state measurements of neighboring agents are utilized, it is assumed that only the relative output measurements of neighboring agents are available for coordination. To achieve consensus tracking in the considered MASs, a new class of observer-based protocols is proposed. By appropriately constructing some topology-dependent multiple Lyapunov functions, it is theoretically shown that distributed consensus tracking in the closed-loop MASs equipped with the designed protocols can be ensured if each possible topology contains a directed spanning tree rooted at the leader and the dwell time for the switchings among different topology is less than a derived positive quantity. Interestingly, it is found that the communication topology for observers' states may be independent with that of the feedback signals. The derived results are further extended to the case of directed switching topology with only average dwell time constraints. Finally, the effectiveness of the analytical results is demonstrated via numerical simulations.","Topology,
Switches,
Protocols,
Nonlinear dynamical systems,
Symmetric matrices,
Observers,
Linear matrix inequalities"
Simultaneous Wireless Information and Power Transfer in Cooperative Relay Networks With Rateless Codes,"This paper investigates the simultaneous wireless information and power transfer (SWIPT) in cooperative relay networks, where a relay harvests energy from the radio frequency (RF) signals transmitted by a source and then uses the harvested energy to assist the information transmission from the source to its destination. Both source and relay transmissions use rateless codes (RCs), which allow the destination to employ any of the two information receiving strategies, i.e., the mutual information accumulation (IA) and the energy accumulation (EA). The SWIPT-enabled relay employs three different SWIPT receiver architectures, the ideal receiver, and two practical receivers (i.e., the power splitting (PS) receiver and the time switch (TS) receiver). Accordingly, three relaying protocols, namely, the ideal protocol, PS protocol, and TS protocol, are presented. To explore the system performance limits with these three protocols, optimization problems are formulated to maximize their achievable information rates. For the ideal protocol, explicit expressions of the optimal solutions are derived. For the PS protocol, a linear-search algorithm is designed to solve the nonconvex problems. For the TS protocol, two solving methods are presented. Numerical experiments are carried out to validate our analysis and algorithms, which show that, with the same SWIPT receiver, the IA-based system outperforms the EA-based system, whereas with the same information receiving strategy, the PS protocol outperforms the TS protocol. Moreover, compared with nonrateless-coded systems, the proposed protocols exhibit considerable performance gains. Moreover, the effects of the relay position on system performance are also discussed, which provides insights on SWIPT-enabled relay systems.",
Imperfect Information Dynamic Stackelberg Game Based Resource Allocation Using Hidden Markov for Cloud Computing,"Existing static grid resource scheduling algorithms, which are limited to minimizing the makespan, cannot meet the needs of resource scheduling required by cloud computing. Current cloud infrastructure solutions provide operational support at the level of resource infrastructure only. When hardware resources form the virtual resource pool, virtual machines are deployed for use transparently. Considering the competing characteristics of multi-tenant environments in cloud computing, this paper proposes a cloud resource allocation model based on an imperfect information Stackelberg game (CSAM-IISG) using a hidden Markov model (HMM) in a cloud computing environment. CSAM-IISG was shown to increase the profit of both the resource supplier and the applicant. Firstly, we used the HMM to predict the service provider’s current bid using the historical resources based on demand. Through predicting the bid dynamically, an imperfect information Stackelberg game (IISG) was established. The IISG motivates service providers to choose the optimal bidding strategy according to the overall utility, achieving maximum profits. Based on the unit prices of different types of resources, a resource allocation model is proposed to guarantee optimal gains for the infrastructure supplier. The proposed resource allocation model can support synchronous allocation for both multi-service providers and various resources. The simulation results demonstrated that the predicted price was close to the actual transaction price, which was lower than the actual value in the game model. The proposed model was shown to increase the profits of service providers and infrastructure suppliers simultaneously.","Cloud computing,
Resource management,
Hidden Markov models,
Computational modeling,
Processor scheduling,
Games,
Dynamic scheduling"
Joint Pricing and Capacity Planning in the IaaS Cloud Market,"In the cloud context, pricing and capacity planning are two important factors to the profit of the infrastructure-as-a-service (IaaS) providers. This paper investigates the problem of joint pricing and capacity planning in the IaaS provider market with a set of software-as-a-service (SaaS) providers, where each SaaS provider leases the virtual machines (VMs) from the IaaS providers to provide cloud-based application services to its end-users. We study two market models, one with a monopoly IaaS provider market, the other with multiple-IaaS-provider market. For the monopoly IaaS provider market, we first study the SaaS providers' optimal decisions in terms of the amount of end-user requests to admit and the number of VMs to lease, given the resource price charged by the IaaS provider. Based on the best responses of the SaaS providers, we then derive the optimal solution to the problem of joint pricing and capacity planning to maximize the IaaS provider's profit. Next, for the market with multiple IaaS providers, we formulate the pricing and capacity planning competition among the IaaS providers as a three-stage Stackelberg game. We explore the existence and uniqueness of Nash equilibrium, and derive the conditions under which there exists a unique Nash equilibrium. Finally, we develop an iterative algorithm to achieve the Nash equilibrium.","Pricing,
Cloud computing,
Servers,
Monopoly,
Capacity planning,
Software as a service,
Biological system modeling"
Analysis of the Modulation Strategy for the Minimization of the Leakage Current in the PV Grid-Connected Cascaded Multilevel Inverter,"This paper presents a pulse width modulation (PWM) technique for the minimization of the leakage current in the grid-connected/stand-alone transformerless photovoltaic (PV)-cascaded multilevel inverter (CMLI). The proposed PWM technique is integrated with the MPPT algorithm and is applied to the five-level CMLI. Furthermore, using the proposed PWM technique the high-frequency voltage transitions in the terminal and common mode voltages are minimized. Thus, the proposed PWM technique minimizes the leakage current of the PV array and electromagnetic interference filter requirement in the system without addition of any extra switches. Furthermore, this paper also presents the analysis for the terminal voltage across the PV array and the common mode voltage of the inverter based on the switching function. Using the given analysis, the effect of the PWM technique can be analyzed, as it directly links the switching function with the common mode voltage and leakage current. Also, the proposed PWM technique requires reduced number of carrier waves compared to the conventional sinusoidal pulse width modulation technique for the given CMLI. Complete details of the working principle and analysis with the support of simulation and experimental results of the proposed PWM technique are presented in this paper.",
Weighted Joint Sparse Representation for Removing Mixed Noise in Image,"Joint sparse representation (JSR) has shown great potential in various image processing and computer vision tasks. Nevertheless, the conventional JSR is fragile to outliers. In this paper, we propose a weighted JSR (WJSR) model to simultaneously encode a set of data samples that are drawn from the same subspace but corrupted with noise and outliers. Our model is desirable to exploit the common information shared by these data samples while reducing the influence of outliers. To solve the WJSR model, we further introduce a greedy algorithm called weighted simultaneous orthogonal matching pursuit to efficiently approximate the global optimal solution. Then, we apply the WJSR for mixed noise removal by jointly coding the grouped nonlocal similar image patches. The denoising performance is further improved by incorporating it with the global prior and the sparse errors into a unified framework. Experimental results show that our denoising method is superior to several state-of-the-art mixed noise removal methods.",
"A Survey on Mobile Edge Networks: Convergence of Computing, Caching and Communications","As the explosive growth of smart devices and the advent of many new applications, traffic volume has been growing exponentially. The traditional centralized network architecture cannot accommodate such user demands due to heavy burden on the backhaul links and long latency. Therefore, new architectures, which bring network functions and contents to the network edge, are proposed, i.e., mobile edge computing and caching. Mobile edge networks provide cloud computing and caching capabilities at the edge of cellular networks. In this survey, we make an exhaustive review on the state-of-the-art research efforts on mobile edge networks. We first give an overview of mobile edge networks, including definition, architecture, and advantages. Next, a comprehensive survey of issues on computing, caching, and communication techniques at the network edge is presented. The applications and use cases of mobile edge networks are discussed. Subsequently, the key enablers of mobile edge networks, such as cloud technology, SDN/NFV, and smart devices are discussed. Finally, open research challenges and future directions are presented as well.","Mobile communication,
Cloud computing,
Mobile computing,
Edge computing,
Computer architecture,
Network architecture,
Mobile handsets"
Automated Insider Threat Detection System Using User and Role-Based Profile Assessment,"Organizations are experiencing an ever-growing concern of how to identify and defend against insider threats. Those who have authorized access to sensitive organizational data are placed in a position of power that could well be abused and could cause significant damage to an organization. This could range from financial theft and intellectual property theft to the destruction of property and business reputation. Traditional intrusion detection systems are neither designed nor capable of identifying those who act maliciously within an organization. In this paper, we describe an automated system that is capable of detecting insider threats within an organization. We define a tree-structure profiling approach that incorporates the details of activities conducted by each user and each job role and then use this to obtain a consistent representation of features that provide a rich description of the user's behavior. Deviation can be assessed based on the amount of variance that each user exhibits across multiple attributes, compared against their peers. We have performed experimentation using ten synthetic data-driven scenarios and found that the system can identify anomalous behavior that may be indicative of a potential threat. We also show how our detection system can be combined with visual analytics tools to support further investigation by an analyst.","Organizations,
Electronic mail,
Computer security,
Feature extraction,
Intellectual property,
Psychology"
Optimal Linear Cyber-Attack on Remote State Estimation,"Recent years have witnessed the surge of interest of security issues in cyber-physical systems. In this paper, we consider malicious cyber attacks in a remote state estimation application where a smart sensor node transmits data to a remote estimator equipped with a false data detector. It is assumed that all the sensor data can be observed and modified by the malicious attacker and a residue-based detection algorithm is used at the remote side to detect data anomalies. We propose a linear deception attack strategy and present the corresponding feasibility constraint which guarantees that the attacker is able to successfully inject false data without being detected. The evolution of the estimation error covariance at the remote estimator is derived and the degradation of system performance under the proposed linear attack policy is analyzed. Furthermore, we obtain a closed-form expression of the optimal attack strategy among all linear attacks. Comparison of attack strategies through simulated examples are provided to illustrate the theoretical results.",
Multiple ECG Fiducial Points-Based Random Binary Sequence Generation for Securing Wireless Body Area Networks,"Generating random binary sequences (BSes) is a fundamental requirement in cryptography. A BS is a sequence of
N
bits, and each bit has a value of 0 or 1. For securing sensors within wireless body area networks (WBANs), electrocardiogram (ECG)-based BS generation methods have been widely investigated in which interpulse intervals (IPIs) from each heartbeat cycle are processed to produce BSes. Using these IPI-based methods to generate a 128-bit BS in real time normally takes around half a minute. In order to improve the time efficiency of such methods, this paper presents an ECG multiple fiducial-points based binary sequence generation (MFBSG) algorithm. The technique of discrete wavelet transforms is employed to detect arrival time of these fiducial points, such as P, Q, R, S, and T peaks. Time intervals between them, including RR, RQ, RS, RP, and RT intervals, are then calculated based on this arrival time, and are used as ECG features to generate random BSes with low latency. According to our analysis on real ECG data, these ECG feature values exhibit the property of randomness and, thus, can be utilized to generate random BSes. Compared with the schemes that solely rely on IPIs to generate BSes, this MFBSG algorithm uses five feature values from one heart beat cycle, and can be up to five times faster than the solely IPI-based methods. So, it achieves a design goal of low latency. According to our analysis, the complexity of the algorithm is comparable to that of fast Fourier transforms. These randomly generated ECG BSes can be used as security keys for encryption or authentication in a WBAN system.","Electrocardiography,
Wavelet transforms,
Algorithm design and analysis,
Feature extraction,
Wireless communication,
Body area networks"
Disease Prediction by Machine Learning Over Big Data From Healthcare Communities,"With big data growth in biomedical and healthcare communities, accurate analysis of medical data benefits early disease detection, patient care, and community services. However, the analysis accuracy is reduced when the quality of medical data is incomplete. Moreover, different regions exhibit unique characteristics of certain regional diseases, which may weaken the prediction of disease outbreaks. In this paper, we streamline machine learning algorithms for effective prediction of chronic disease outbreak in disease-frequent communities. We experiment the modified prediction models over real-life hospital data collected from central China in 2013-2015. To overcome the difficulty of incomplete data, we use a latent factor model to reconstruct the missing data. We experiment on a regional chronic disease of cerebral infarction. We propose a new convolutional neural network (CNN)-based multimodal disease risk prediction algorithm using structured and unstructured data from hospital. To the best of our knowledge, none of the existing work focused on both data types in the area of medical big data analytics. Compared with several typical prediction algorithms, the prediction accuracy of our proposed algorithm reaches 94.8% with a convergence speed, which is faster than that of the CNN-based unimodal disease risk prediction algorithm.",
Load Balancing Under Heavy Traffic in RPL Routing Protocol for Low Power and Lossy Networks,"RPL is an IPv6 routing protocol for low-power and lossy networks (LLNs) designed to meet the requirements of a wide range of LLN applications including smart grid AMIs, industrial and environmental monitoring, and wireless sensor networks. RPL allows bidirectional end-to-end IPv6 communication on resource constrained LLN devices, leading to the concept of the Internet of Things (IoT) with thousands and millions of devices interconnected through multihop mesh networks. In this article, we investigate the load balancing and congestion problem of RPL. Specifically, we show that most of the packet losses under heavy traffic are due to congestion, and a serious load balancing problem appears in RPL in terms of routing parent selection. To overcome this problem, this article proposes a simple yet effective queue utilization based RPL (QU-RPL) that achieves load balancing and significantly improves the end-to-end packet delivery performance compared to the standard RPL. QU-RPL is designed for each node to select its parent node considering the queue utilization of its neighbor nodes as well as their hop distances to an LLN border router (LBR). Owing to its load balancing capability, QURPL is very effective in lowering queue losses and increasing the packet delivery ratio. We implement QU-RPL on a low-power embedded platform, and verify all of our findings through experimental measurements on a real testbed of a multihop LLN over IEEE 802.15.4. We present the impact of each design element of QU-RPL on performance in detail, and also show that QU-RPL reduces the queue loss by up to 84 percent and improves the packet delivery ratio by up to 147 percent compared to the standard RPL.","Routing,
Measurement,
Load management,
Mobile computing,
Internet of things,
IEEE 802.15 Standard"
An Efficient Method for Traffic Sign Recognition Based on Extreme Learning Machine,"This paper proposes a computationally efficient method for traffic sign recognition (TSR). This proposed method consists of two modules: (1) extraction of histogram of oriented gradient variant (HOGv) feature and (2) a single classifier trained by extreme learning machine (ELM) algorithm. The presented HOGv feature keeps a good balance between redundancy and local details such that it can represent distinctive shapes better. The classifier is a single-hidden-layer feedforward network. Based on ELM algorithm, the connection between input and hidden layers realizes the random feature mapping while only the weights between hidden and output layers are trained. As a result, layer-by-layer tuning is not required. Meanwhile, the norm of output weights is included in the cost function. Therefore, the ELM-based classifier can achieve an optimal and generalized solution for multiclass TSR. Furthermore, it can balance the recognition accuracy and computational cost. Three datasets, including the German TSR benchmark dataset, the Belgium traffic sign classification dataset and the revised mapping and assessing the state of traffic infrastructure (revised MASTIF) dataset, are used to evaluate this proposed method. Experimental results have shown that this proposed method obtains not only high recognition accuracy but also extremely high computational efficiency in both training and recognition processes in these three datasets.","Feature extraction,
Training,
Robustness,
Computational efficiency,
Neural networks,
Histograms,
Shape"
Enabling Semantic Search based on Conceptual Graphs over Encrypted Outsourced Data,"Currently, searchable encryption is a hot topic in the field of cloud computing. The existing achievements are mainly focused on keyword-based search schemes, and almost all of them depend on predefined keywords extracted in the phases of index construction and query. However, keyword-based search schemes ignore the semantic representation information of users’ retrieval and cannot completely match users’ search intention. Therefore, how to design a content-based search scheme and make semantic search more effective and context-aware is a difficult challenge. In this paper, for the first time, we define and solve the problems of semantic search based on conceptual graphs(CGs) over encrypted outsourced data in clouding computing (SSCG).We firstly employ the efficient measure of ”sentence scoring” in text summarization and Tregex to extract the most important and simplified topic sentences from documents. We then convert these simplified sentences into CGs. To perform quantitative calculation of CGs, we design a new method that can map CGs to vectors. Next, we rank the returned results based on ”text summarization score”. Furthermore, we propose a basic idea for SSCG and give a significantly improved scheme to satisfy the security guarantee of searchable symmetric encryption (SSE). Finally, we choose a real-world dataset – ie., the CNN dataset to test our scheme. The results obtained from the experiment show the effectiveness of our proposed scheme.","Semantics,
Servers,
Indexes,
Encryption,
Cloud computing,
Search problems"
Variance-Constrained Distributed Filtering for Time-Varying Systems With Multiplicative Noises and Deception Attacks Over Sensor Networks,"This paper is concerned with the variance-constrained distributed filtering problem for a class of time-varying systems subject to multiplicative noises, unknown but bounded disturbances and deception attacks over sensor networks. The available measurements at each sensing node are collected not only from the individual sensor but also from its neighbors according to the given topology. A new deception attack model is proposed where the malicious signals are injected by the adversary into both control and measurement data during the process of information transmission via the communication network. By resorting to the recursive linear matrix inequality approach, a sufficient condition is established for the existence of the desired filter satisfying the prespecified requirements on the estimation error variance. Subsequently, an optimization problem is formulated in order to seek the filter parameters ensuring the locally optimal filtering performance at each time instant. Finally, an illustrative example is presented to demonstrate the effectiveness and applicability of the proposed algorithm.",
A Novel Cloud-Based Platform for Implementation of Oblivious Power Routing for Clusters of Microgrids,"There has been an increasing demand for connectivity of the clusters of microgrids to increase their flexibility and security. This paper presents a framework for implementation, simulation, and evaluation of a novel power routing algorithm for clusters of microgrids. The presumed cluster is composed of multiple direct current (dc) microgrids connected together through multi-terminal dc system in a meshed network. In this structure, the energy is redirected from the microgrid with excessive power generation capacity to the microgrid which has power shortage to supply its internal loads. The key contribution of this paper is that each microgrid in the cluster is unaware of the current state and other flows of the cluster. In this approach, the optimal power flow problem is solved for the system while managing congestion and mitigating power losses. The proposed methodology works for both radial and non-radial networks regardless of the network topology, scale, and number of microgrids involved in the cluster. Therefore, it is also well suited for large-scale optimal power routing problems that will emerge in the future clusters of microgrids. The effectiveness of the proposed algorithm is verified by MATLAB simulation. We also present a comprehensive cloud-based platform for further implementation of the proposed algorithm on the OPAL-RT real-time digital simulation system. The communication paths between the microgrids and the cloud environment can be emulated by OMNeT++.",
"A Survey of Multi-Objective Optimization in Wireless Sensor Networks: Metrics, Algorithms, and Open Problems","Wireless sensor networks (WSNs) have attracted substantial research interest, especially in the context of performing monitoring and surveillance tasks. However, it is challenging to strike compelling tradeoffs amongst the various conflicting optimization criteria, such as the network's energy dissipation, packet-loss rate, coverage, and lifetime. This paper provides a tutorial and survey of recent research and development efforts addressing this issue by using the technique of multi-objective optimization (MOO). First, we provide an overview of the main optimization objectives used in WSNs. Then, we elaborate on various prevalent approaches conceived for MOO, such as the family of mathematical programming-based scalarization methods, the family of heuristics/metaheuristics-based optimization algorithms, and a variety of other advanced optimization techniques. Furthermore, we summarize a range of recent studies of MOO in the context of WSNs, which are intended to provide useful guidelines for researchers to understand the referenced literature. Finally, we discuss a range of open problems to be tackled by future research.","Wireless sensor networks,
Optimization,
Tutorials,
Genetic algorithms,
Measurement,
Evolutionary computation,
Context"
Long-Term Recurrent Convolutional Networks for Visual Recognition and Description,"Models based on deep convolutional networks have dominated recent image interpretation tasks; we investigate whether models which are also recurrent are effective for tasks involving sequences, visual and otherwise. We describe a class of recurrent convolutional architectures which is end-to-end trainable and suitable for large-scale visual understanding tasks, and demonstrate the value of these models for activity recognition, image captioning, and video description. In contrast to previous models which assume a fixed visual representation or perform simple temporal averaging for sequential processing, recurrent convolutional models are “doubly deep” in that they learn compositional representations in space and time. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Differentiable recurrent models are appealing in that they can directly map variable-length inputs (e.g., videos) to variable-length outputs (e.g., natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent sequence models are directly connected to modern visual convolutional network models and can be jointly trained to learn temporal dynamics and convolutional perceptual representations. Our results show that such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined or optimized.",
SD-MAC: Spectrum Database-Driven MAC Protocol for Cognitive Machine-to-Machine Networks,"Recently, machine-to-machine (M2M) communications has become an emerging paradigm that provides ubiquitous connectivity among numerous devices to support diverse communication applications. To address crucial issues in M2M networks, i.e., spectrum scarcity, massive access, and low-power and reliable communications, cognitive radio technology is promised and integrated with M2M communication networks, which is called cognitive M2M (CM2M). In this paper, we propose a database-driven medium access control (MAC) protocol for CM2M networks. In this protocol, devices are capable of obtaining spectrum information from the spectrum database or from the local sensing process. Considering the fading channel scenario, the proposed MAC protocol controls devices to adaptively sense and access the available spectrum channels. The adaptive sensing and access processes are modeled as optimal decision processes by maximizing the network throughput. An iterative adaptive dynamic programming algorithm is developed to find the optimal sensing and access policies for devices. Simulation results show that the proposed MAC protocol can provide reliability guarantees for obtaining high network throughput while reducing the interference to primary systems.","Sensors,
Media Access Protocol,
Databases,
Fading channels,
Adaptation models,
Signal to noise ratio"
A 3D Steganalytic Algorithm and Steganalysis-Resistant Watermarking,"We propose a simple yet efficient steganalytic algorithm for watermarks embedded by two state-of-the-art 3D watermarking algorithms by Cho et al. The main observation is that while in a clean model the means/variances of Cho et al.’s normalized histogram bins are expected to follow a Gaussian distribution, in a marked model their distribution will be bimodal. The proposed algorithm estimates the number of bins through an exhaustive search and then the presence of a watermark is decided by a tailor made normality test or a
t
-test. We also propose a modification of Cho et al.’s watermarking algorithms with the watermark embedded by changing the histogram of the radial coordinates of the vertices. Rather than targeting a continuous statistics such as the mean or variance of the values in a bin, the proposed watermarking modifies a discrete statistic, which here is the height of the histogram bin, to achieve watermark embedding. Experimental results demonstrate that the modified algorithm offers not only better resistance against the steganalytic attack we developed, but also an improved robustness/capacity trade-off.","Watermarking,
Three-dimensional displays,
Robustness,
Histograms,
Solid modeling,
Standards,
Algorithm design and analysis"
Calculation of Siphons and Minimal Siphons in Petri Nets Based on Semi-Tensor Product of Matrices,"In this paper, we address the problems of enumerating siphons and minimal siphons in ordinary Petri nets (PNs) by resorting to the semi-tensor product (STP) of matrices. First, a matrix equation, called the siphon equation (SE), is established by using STP. Second, an algorithm is proposed to calculate all siphons in ordinary PNs. An example is presented to illustrate the theoretical results and show that the proposed method is more effective than other existing methods in calculating all siphons of PNs. Third, an efficient recursion algorithm is also proposed, which can be applied to computing all minimal siphons for any ordinary PNs. Last, some results on the computational complexity of the proposed algorithms, in this paper, are provided, as well as experimental results.","Mathematical model,
Petri nets,
Computers,
Algorithm design and analysis,
System recovery,
Control engineering,
Complexity theory"
Short-Term State Forecasting-Aided Method for Detection of Smart Grid General False Data Injection Attacks,"Successful detection of false data injection attacks (FDIAs) is essential for ensuring secure power grids operation and control. First, this paper extends the approximate dc model to a more general linear model that can handle both supervisory control and data acquisition and phasor measurement unit measurements. Then, a general FDIA based on this model is derived and the error tolerance of such attacks is discussed. To detect such attacks, a method based on short-term state forecasting considering temporal correlation is proposed. Furthermore, a statistics-based measurement consistency test method is presented to check the consistency between the forecasted measurements and the received measurements. This measurement consistency test is further integrated with ∞-norm and L2-norm-based measurement residual analysis to construct the proposed detection metric. The proposed detector addresses the shortcoming of previous detectors in terms of handling critical measurements. Besides, the removal problem of attacked measurements, which may cause the system to become unobservable, is addressed effectively by the proposed method through forecasted measurements. Numerical tests on IEEE 14-bus and 118-bus test systems verify the effectiveness and performance of the proposed method.","Detectors,
Phasor measurement units,
Forecasting,
Computer hacking,
Pollution measurement,
Current measurement,
Correlation"
Sequential Discrete Hashing for Scalable Cross-Modality Similarity Retrieval,"With the dramatic development of the Internet, how to exploit large-scale retrieval techniques for multimodal web data has become one of the most popular but challenging problems in computer vision and multimedia. Recently, hashing methods are used for fast nearest neighbor search in large-scale data spaces, by embedding high-dimensional feature descriptors into a similarity preserving Hamming space with a low dimension. Inspired by this, in this paper, we introduce a novel supervised cross-modality hashing framework, which can generate unified binary codes for instances represented in different modalities. Particularly, in the learning phase, each bit of a code can be sequentially learned with a discrete optimization scheme that jointly minimizes its empirical loss based on a boosting strategy. In a bitwise manner, hash functions are then learned for each modality, mapping the corresponding representations into unified hash codes. We regard this approach as cross-modality sequential discrete hashing (CSDH), which can effectively reduce the quantization errors arisen in the oversimplified rounding-off step and thus lead to high-quality binary codes. In the test phase, a simple fusion scheme is utilized to generate a unified hash code for final retrieval by merging the predicted hashing results of an unseen instance from different modalities. The proposed CSDH has been systematically evaluated on three standard data sets: Wiki, MIRFlickr, and NUS-WIDE, and the results show that our method significantly outperforms the state-of-the-art multimodality hashing techniques.","Binary codes,
Optimization,
Boosting,
Semantics,
Quantization (signal),
Data structures,
Electronic mail"
Model-Based Fault Detection and Identification for Switching Power Converters,"We present the analysis, design, and experimental validation of a model-based fault detection and identification (FDI) method for switching power converters using a model-based state estimator approach. The proposed FDI approach is general in that it can be used to detect and identify arbitrary faults in components and sensors in a broad class of switching power converters. The FDI approach is experimentally demonstrated on a nanogrid prototype with a 380-V dc distribution bus. The nanogrid consists of four different switching power converters, including a buck converter, an interleaved boost converter, a single-phase rectifier, and a three-phase inverter. We construct a library of fault signatures for possible component and sensor faults in all four converters. The FDI algorithm successfully achieves fault detection in under 400
μ
s and fault identification in under 10 ms for faults in each converter. The proposed FDI approach enables a flexible and scalable solution for improving fault tolerance and awareness in power electronics systems.","Switches,
Circuit faults,
Buildings,
Fault detection,
Sensors,
Fault diagnosis,
Topology"
Automated Melanoma Recognition in Dermoscopy Images via Very Deep Residual Networks,"Automated melanoma recognition in dermoscopy images is a very challenging task due to the low contrast of skin lesions, the huge intraclass variation of melanomas, the high degree of visual similarity between melanoma and non-melanoma lesions, and the existence of many artifacts in the image. In order to meet these challenges, we propose a novel method for melanoma recognition by leveraging very deep convolutional neural networks (CNNs). Compared with existing methods employing either low-level hand-crafted features or CNNs with shallower architectures, our substantially deeper networks (more than 50 layers) can acquire richer and more discriminative features for more accurate recognition. To take full advantage of very deep networks, we propose a set of schemes to ensure effective training and learning under limited training data. First, we apply the residual learning to cope with the degradation and overfitting problems when a network goes deeper. This technique can ensure that our networks benefit from the performance gains achieved by increasing network depth. Then, we construct a fully convolutional residual network (FCRN) for accurate skin lesion segmentation, and further enhance its capability by incorporating a multi-scale contextual information integration scheme. Finally, we seamlessly integrate the proposed FCRN (for segmentation) and other very deep residual networks (for classification) to form a two-stage framework. This framework enables the classification network to extract more representative and specific features based on segmented results instead of the whole dermoscopy images, further alleviating the insufficiency of training data. The proposed framework is extensively evaluated on ISBI 2016 Skin Lesion Analysis Towards Melanoma Detection Challenge dataset. Experimental results demonstrate the significant performance gains of the proposed framework, ranking the first in classification and the second in segmentation among 25 teams and 28 teams, respectively. This study corroborates that very deep CNNs with effective training mechanisms can be employed to solve complicated medical image analysis tasks, even with limited training data.",
"Distributed Continuous-Time Optimization: Nonuniform Gradient Gains, Finite-Time Convergence, and Convex Constraint Set","In this paper, a distributed optimization problem with general differentiable convex objective functions is studied for continuous-time multi-agent systems with single-integrator dynamics. The objective is for multiple agents to cooperatively optimize a team objective function formed by a sum of local objective functions with only local interaction and information while explicitly taking into account nonuniform gradient gains, finite-time convergence, and a common convex constraint set. First, a distributed nonsmooth algorithm is introduced for a special class of convex objective functions that have a quadratic-like form. It is shown that all agents reach a consensus in finite time while minimizing the team objective function asymptotically. Second, a distributed algorithm is presented for general differentiable convex objective functions, in which the interaction gains of each agent can be self-adjusted based on local states. A corresponding condition is then given to guarantee that all agents reach a consensus in finite time while minimizing the team objective function asymptotically. Third, a distributed optimization algorithm with state-dependent gradient gains is given for general differentiable convex objective functions. It is shown that the distributed continuous-time optimization problem can be solved even though the gradient gains are not identical. Fourth, a distributed tracking algorithm combined with a distributed estimation algorithm is given for general differentiable convex objective functions. It is shown that all agents reach a consensus while minimizing the team objective function in finite time. Fifth, as an extension of the previous results, a distributed constrained optimization algorithm with nonuniform gradient gains and a distributed constrained finite-time optimization algorithm are given. It is shown that both algorithms can be used to solve a distributed continuous-time optimization problem with a common convex constraint set. Numerical examples are included to illustrate the obtained theoretical results.",
Cascading Power Outages Propagate Locally in an Influence Graph That is Not the Actual Grid Topology,"In a cascading power transmission outage, component outages propagate nonlocally; after one component outages, the next failure may be very distant, both topologically and geographically. As a result, simple models of topological contagion do not accurately represent the propagation of cascades in power systems. However, cascading power outages do follow patterns, some of which are useful in understanding and reducing blackout risk. This paper describes a method by which the data from many cascading failure simulations can be transformed into a graph-based model of influences that provides actionable information about the many ways that cascades propagate in a particular system. The resulting “influence graph” model is Markovian, in that component outage probabilities depend only on the outages that occurred in the prior generation. To validate the model, we compare the distribution of cascade sizes resulting from n-2 contingencies in a 2896 branch test case to cascade sizes in the influence graph. The two distributions are remarkably similar. In addition, we derive an equation with which one can quickly identify modifications to the proposed system that will substantially reduce cascade propagation. With this equation, one can quickly identify critical components that can be improved to substantially reduce the risk of large cascading blackouts.","Power system faults,
Data models,
Power system protection,
Mathematical model,
Power grids,
Stress"
Negative Capacitance FinFET With Sub-20-mV/decade Subthreshold Slope and Minimal Hysteresis of 0.48 V,"In this letter, an n-type short-channel negative capacitance FinFET (NC-FinFET) with a hysteresis window of 0.48 V, an on-/off-current ratio of 107, and a sub20-mV/decade average subthreshold slope (SSavg) that is intended to overcome the Boltzmann limit (i.e., the physical limit in the SS, which is 60 mV/decade at 300 K), is experimentally demonstrated vs. a baseline FinFET with an SSavg of ~105 mV/decade. In our testing, we confirmed that the large hysteresis window in a short-channel NC-FinFET can be suppressed by using an appropriate source/drain extension length (Lext). As Lext in the NC-FinFET is increased, the gate-to-source/drain capacitance (CGS/CGD) decreased and the hysteresis window narrows.","Capacitance,
FinFETs,
Hysteresis,
Capacitors,
Logic gates,
Switches"
Preserving the Location Privacy of Secondary Users in Cooperative Spectrum Sensing,"Cooperative spectrum sensing, despite its effectiveness in enabling dynamic spectrum access, suffers from location privacy threats, merely because secondary users (SUs)' sensing reports that need to be shared with a fusion center to make spectrum availability decisions are highly correlated to the users' locations. It is therefore important that cooperative spectrum sensing schemes be empowered with privacy preserving capabilities so as to provide SUs with incentives for participating in the sensing task. In this paper, we propose privacy preserving protocols that make use of various cryptographic mechanisms to preserve the location privacy of SUs while performing reliable and efficient spectrum sensing. We also present cost-performance tradeoffs. The first consists on using an additional architectural entity at the benefit of incurring lower computation overhead by relying only on symmetric cryptography. The second consists on using an additional secure comparison protocol at the benefit of incurring lesser architectural cost by not requiring extra entities. Our schemes can also adapt to the case of a malicious fusion center as we discuss in this paper. We also show that not only are our proposed schemes secure and more efficient than existing alternatives, but also achieve fault tolerance and are robust against sporadic network topological changes.","Sensors,
Privacy,
Protocols,
Context,
Cryptography,
Reliability"
Robust Cooperative Secure Beamforming for Simultaneous Wireless Information and Power Transfer in Amplify-and-Forward Relay Networks,"In this paper, we investigate cooperative secure beamforming for simultaneous wireless information and power transfer (SWIPT) in amplify-and-forward (AF) relay networks. We propose a joint cooperative beamforming (CB) and energy signal (CB-ES) scheme for providing both secure communication and efficient wireless energy transfer. By considering colluding eavesdroppers with imperfect channel state information (CSI), we formulate an optimization problem for maximizing the secrecy rate between the source and the legitimate information receiver (IR) under both the power constraints at the relays and the wireless power transfer constraint at the energy-harvesting receiver (ER). Since such a problem is nonconvex and hard to tackle, we propose a two-level optimization approach that involves a 1-D search and the semidefinite relaxation (SDR) technique to solve this problem. The proposed robust scheme is compared with some other nonrobust schemes, such as a CB and artificial noise (CB-AN) scheme and a perfect scheme. Simulation results show that the proposed robust scheme achieves better worst-case secrecy rate performance than the other nonrobust schemes and the CB-AN scheme, while it approaches the perfect scheme.","Robustness,
Array signal processing,
Wireless communication,
Communication system security,
Relay networks (telecommunications),
Security"
Distributed Aggregate Privacy-Preserving Authentication in VANETs,"Existing secure and privacy-preserving vehicular communication protocols in vehicular ad hoc networks face the challenges of being fast and not depending on ideal tamper-proof devices (TPDs) embedded in vehicles. To address these challenges, we propose a vehicular authentication protocol referred to as distributedaggregate privacy-preserving authentication. The proposed protocol is based on our new multiple trusted authority one-time identity-based aggregate signature technique. With this technique a vehicle can verify many messages simultaneously and their signatures can be compressed into a single one that greatly reduces the storage space needed by a vehicle or a data collector (e.g., the traffic management authority). Instead of ideal TPDs, our protocol only requires realistic TPDs and hence is more practical.",
Decentralized Reactive Power Compensation Using Nash Bargaining Solution,"We consider a distributed reactive power compensation problem in a distribution network in which users locally generate reactive power using distributed generation units to contribute to the local voltage control. We model and analyze the interaction between one electric utility company and multiple users by using the Nash bargaining theory. On one hand, users determine the amount of active and reactive power generation for their distributed generation units. On the other hand, the electric utility company offers reimbursement for each user based on the amount of reactive power dispatched by that user. We first quantify the benefit for the electric utility company and users in the reactive power compensation problem. Then we derive the optimal solution for the active and reactive power generation, as well as reimbursement for each user under two different bargaining protocols, namely sequential bargaining and concurrent bargaining. Numerical results show that both the electric utility company and users benefit from the proposed decentralized reactive power compensation mechanism, and the overall system efficiency is improved.","Reactive power,
Companies,
Power industry,
Power demand,
Distributed power generation,
Substations"
Autoregressive Moving Average Graph Filtering,"One of the cornerstones of the field of signal processing on graphs are graph filters, direct analogs of classical filters, but intended for signals defined on graphs. This paper brings forth new insights on the distributed graph filtering problem. We design a family of autoregressive moving average (ARMA) recursions, which are able to approximate any desired graph frequency response, and give exact solutions for specific graph signal denoising and interpolation problems. The philosophy to design the ARMA coefficients independently from the underlying graph renders the ARMA graph filters suitable in static and, particularly, time-varying settings. The latter occur when the graph signal and/or graph topology are changing over time. We show that in case of a time-varying graph signal, our approach extends naturally to a two-dimensional filter, operating concurrently in the graph and regular time domain. We also derive the graph filter behavior, as well as sufficient conditions for filter stability when the graph and signal are time varying. The analytical and numerical results presented in this paper illustrate that ARMA graph filters are practically appealing for static and time-varying settings, as predicted by theoretical derivations.","Frequency response,
Frequency-domain analysis,
Convergence,
Laplace equations,
Interpolation,
Topology,
Eigenvalues and eigenfunctions"
"Software Defined Networking Architecture, Security and Energy Efficiency: A Survey","Software-defined networking (SDN) is an emerging paradigm, which breaks the vertical integration in traditional networks to provide the flexibility to program the network through (logical) centralized network control. SDN has the capability to adapt its network parameters on the fly based on its operating environment. The decoupled structure of SDN serves as a solution for managing the network with more flexibility and ease. In SDN, the centralized cost effective architecture provides network visibility which helps to achieve efficient resource utilization and high performance. Due to the increasingly pervasive existence of smart programmable devices in the network, SDN provides security, energy efficiency, and network virtualization for enhancing the overall network performance. We present various security threats that are resolved by SDN and new threats that arise as a result of SDN implementation. The recent security attacks and countermeasures in SDN are also summarized in the form of tables. We also provide a survey on the different strategies that are implemented to achieve energy efficiency and network security through SDN implementation. In an effort to anticipate the future evolution of this new paradigm, we discuss the main ongoing research efforts, challenges, and research trends in this area. With this paper, readers can have a more thorough understanding of SDN architecture, different security attacks and countermeasures, and energy efficiency.","Security,
Virtualization,
Computer architecture,
Control systems,
Software,
Energy consumption,
Servers"
Secrecy Capacity Analysis Over \alpha - \mu Fading Channels,"In this letter, we study the secrecy capacity of the classic Wyner's model over the α - μ fading channels, where α and μ specify the nonlinearity and clustering of fading channels, respectively. The average secrecy capacity (ASC) is derived in closed-form by using the extended generalized bivariate Fox's H-function. Moreover, the asymptotic analysis of ASC in high signal-to-noise ratio (SNR) regime is conducted. The asymptotic results unveil that the ASC follows the scaling law of Θ (ln ρ), where p stands for the ratio between the average powers of main channels and eavesdropping channels. Moreover, the ASC can be enhanced by increasing the transmit SNR, while there exists a ceiling of ASC as the SNRs at both sides are improved simultaneously. The accuracy of the analytical results is validated by Monte-Carlo simulations. The numerical results show that rigorous fading channels are beneficial to the secrecy performance, that is, serious nonlinearity (small α) and sparse clustering (small μ) will lead to the improvement of ASC.",
Channel Estimation and Self-Interference Cancelation in Full-Duplex Communication Systems,"This paper presents a two-stage self-interference (SI) cancellation for full-duplex multi-input-multi-output (MIMO) communications systems. By exploiting the SI channel sparsity, a compressed-sensing-based SI channel estimation technique is developed and used in the first SI-cancellation radio-frequency (RF) stage to reduce the SI power prior to the receiver low-noise amplifier (LNA) and the analog-to-digital converter (ADC) to avoid overloading. Subsequently, a subspace-based algorithm is proposed to jointly estimate the coefficients of both the residual SI and intended channels and transceiver impairments for the second SI-cancellation baseband stage to further reduce the residual SI. Unlike other previous works, the intended signal is taken into consideration during the estimation process to reduce the overhead. It is demonstrated that the SI channel coefficients can be perfectly estimated with no knowledge of the intended signal, and only a few training symbols are needed for ambiguity removal in intended-channel estimation. Simulation results show that the proposed algorithms outperform the least square (LS) algorithms and offer the remarkable signal-to-residual-SI-and-noise ratio (SINR) approaching the signal-to-noise ratio (SNR).","Silicon,
Channel estimation,
Transceivers,
Radio frequency,
Baseband,
Signal to noise ratio,
Transmitters"
"A Medium-Voltage Hybrid DC Circuit Breaker, Part I: Solid-State Main Breaker Based on 15 kV SiC Emitter Turn-OFF Thyristor","This paper discusses the design of a 10 kV and 200 A hybrid dc circuit breaker suitable for the protection of the dc power systems in electric ships. The proposed hybrid dc circuit breaker employs a Thompson coil based ultrafast mechanical switch (MS) with the assistance of two additional solid-state power devices. A low-voltage (80 V) metal-oxide-semiconductor field-effect transistors (MOSFETs)-based commutating switch (CS) is series connected with the MS to realize the zero current turn-OFF of the MS. In this way, the arcing issue with the MS is avoided. A 15 kV SiC emitter turn-OFF thyristor-based main breaker (MB) is parallel connected with the MS and CS branch to interrupt the fault current. A stack of MOVs parallel with the MB are used to clamp the voltage across the hybrid dc circuit breaker during interruption. This paper focuses on the electronic parts of the hybrid dc circuit breaker, and a companion paper will elucidate the principle and operation of the fast acting MS and the overall operation of the hybrid dc circuit breaker. The selection and design of both the high-voltage and low-voltage electronic components in the hybrid dc circuit breaker are presented in this paper. The turn-OFF capability of the MB with and without snubber circuit is experimentally tested, validating its suitability for the hybrid dc circuit breaker application. The CSs' conduction performances are tested up to 200 A, and its current commutating during fault current interruption is also analyzed. Finally, the hybrid dc circuit breaker demonstrated a fast current interruption within 2 ms at 7 kV and 100 A.","Circuit breakers,
Silicon carbide,
Fault currents,
Interrupters,
Low voltage,
Hybrid power systems,
Silicon"
Disturbance Observer Based Composite Learning Fuzzy Control of Nonlinear Systems with Unknown Dead Zone,"This paper investigates the disturbance observer-based composite fuzzy control of a class of uncertain nonlinear systems with unknown dead zone. With fuzzy logic system approximating the unknown nonlinearities, composite learning is constructed on the basis of a serial-parallel identifier. By introducing the intermediate signal, the disturbance observer is developed to provide efficient learning of the compounded disturbance which includes the effect of time-varying disturbance, fuzzy approximation error, and unknown dead zone. Based on the disturbance estimation and fuzzy approximation, the adaptive fuzzy controller is synthesized with novel updating law. The stability analysis of the closed-loop system is rigorously established via Lyapunov approach. The performance of the proposed controller is verified via simulation that faster convergence and higher precision are obtained.","Observers,
Nonlinear systems,
Fuzzy control,
Time-varying systems,
Approximation error,
Fuzzy logic"
Predicting Protein Functions by Using Unbalanced Random Walk Algorithm on Three Biological Networks,"With the gap between the sequence data and their functional annotations becomes increasing wider, many computational methods have been proposed to annotate functions for unknown proteins. However, designing effective methods to make good use of various biological resources is still a big challenge for researchers due to function diversity of proteins. In this work, we propose a new method named ThrRW, which takes several steps of random walking on three different biological networks: protein interaction network (PIN), domain co-occurrence network (DCN), and functional interrelationship network (FIN), respectively, so as to infer functional information from neighbors in the corresponding networks. With respect to the topological and structural differences of the three networks, the number of walking steps in the three networks will be different. In the course of working, the functional information will be transferred from one network to another according to the associations between the nodes in different networks. The results of experiment on S. cerevisiae data show that our method achieves better prediction performance not only than the methods that consider both PIN data and GO term similarities, but also than the methods using both PIN data and protein domain information, which verifies the effectiveness of our method on integrating multiple biological data sources.",
Resource Allocation for D2D Communications Underlay in Rayleigh Fading Channels,"Device-to-device (D2D) communication has attracted substantial research attention recently, due to its potential to improve coverage, spectrum efficiency, and energy efficiency within the existing cellular infrastructure. One major challenge for spectrum resource sharing in D2D underlay lies in the mutual interference between cellular user equipments (CUEs) and D2D user equipments (DUEs). Considering this mutual interference constraint, this work investigates the problem of optimal matching of D2D links and CUEs to form spectrum-sharing partners to maximize ergodic sum rates under transmit power and outage constraints. Unlike previous works, full channel-state information (CSI) is not required. To solve the resulting high-complexity problem, candidate DUE sets are first narrowed down according to required outage probability constraints, which are used to construct a simplified bipartite graph. The weight of the bipartite graph is characterized as the maximization of ergodic sum rate of the associated D2D and cellular links under outage constraints for which a low-complexity algorithm is proposed to solve the nonconvex problem. After constructing the bipartite graph, the Hungarian algorithm is used to determine the optimal pairing between D2D links and CUEs. Numerical results demonstrate that the proposed algorithm can improve the outage-constrained spectrum efficiency of D2D networks with practical complexity.","Quality of service,
Interference,
Resource management,
Fading channels,
Bipartite graph,
Channel estimation,
Power control"
A Wireless Headstage for Combined Optogenetics and Multichannel Electrophysiological Recording,"This paper presents a wireless headstage with real-time spike detection and data compression for combined optogenetics and multichannel electrophysiological recording. The proposed headstage, which is intended to perform both optical stimulation and electrophysiological recordings simultaneously in freely moving transgenic rodents, is entirely built with commercial off-the-shelf components, and includes 32 recording channels and 32 optical stimulation channels. It can detect, compress and transmit full action potential waveforms over 32 channels in parallel and in real time using an embedded digital signal processor based on a low-power field programmable gate array and a Microblaze microprocessor softcore. Such a processor implements a complete digital spike detector featuring a novel adaptive threshold based on a Sigma-delta control loop, and a wavelet data compression module using a new dynamic coefficient re-quantization technique achieving large compression ratios with higher signal quality. Simultaneous optical stimulation and recording have been performed in-vivo using an optrode featuring 8 microelectrodes and 1 implantable fiber coupled to a 465-nm LED, in the somatosensory cortex and the Hippocampus of a transgenic mouse expressing ChannelRhodospin (Thy1::ChR2-YFP line 4) under anesthetized conditions. Experimental results show that the proposed headstage can trigger neuron activity while collecting, detecting and compressing single cell microvolt amplitude activity from multiple channels in parallel while achieving overall compression ratios above 500. This is the first reported high-channel count wireless optogenetic device providing simultaneous optical stimulation and recording. Measured characteristics show that the proposed headstage can achieve up to 100% of true positive detection rate for signal-to-noise ratio (SNR) down to 15 dB, while achieving up to 97.28% at SNR as low as 5 dB. The implemented prototype features a lifespan of up to 105 minutes, and uses a lightweight (2.8 g) and compact (17 × 18 × 10 mm3) rigid-flex printed circuit board.",
An Energy-Efficient Architecture for the Internet of Things (IoT),"Internet of things (IoT) is a smart technology that connects anything anywhere at any time. Such ubiquitous nature of IoT is responsible for draining out energy from its resources. Therefore, the energy efficiency of IoT resources has emerged as a major research issue. In this paper, an energy-efficien t architecture for IoT has been proposed, which consists of three layers, namely, sensing and control, information processing, and presentation. The architectural design allows the system to predict the sleep interval of sensors based upon their remaining battery level, their previous usage history, and quality of information required for a particular application. The predicted value can be used to boost the utilization of cloud resources by reprovisioning the allocated resources when the corresponding sensory nodes are in sleep mode. This mechanism allows the energy-efficient utilization of all the IoT resources. The experimental results show a significant amount of energy saving in the case of sensor nodes and improved resource utilization of cloud resources.",
Riemannian Gaussian Distributions on the Space of Symmetric Positive Definite Matrices,"Data, which lie in the space Pm, of m × m symmetric positive definite matrices, (sometimes called tensor data), play a fundamental role in applications, including medical imaging, computer vision, and radar signal processing. An open challenge, for these applications, is to find a class of probability distributions, which is able to capture the statistical properties of data in Pm, as they arise in real-world situations. The present paper meets this challenge by introducing Riemannian Gaussian distributions on Pm. Distributions of this kind were first considered by Pennec in 2006. However, the present paper gives an exact expression of their probability density function for the first time in existing literature. This leads to two original contributions. First, a detailed study of statistical inference for Riemannian Gaussian distributions, uncovering the connection between the maximum likelihood estimation and the concept of Riemannian centre of mass, widely used in applications. Second, the derivation and the implementation of an expectation-maximisation algorithm, for the estimation of mixtures of Riemannian Gaussian distributions. The paper applies this new algorithm, to the classification of data in Pm, (concretely, to the problem of texture classification, in computer vision), showing that it yields significantly better performance, in comparison to recent approaches.",
Dynamic Adaptive Replacement Policy in Shared Last-Level Cache of DRAM/PCM Hybrid Memory for Big Data Storage,"The increasing demand on the main memory capacity is one of the main big data challenges. Dynamic random access memory (DRAM) does not represent the best choice for a main memory, due to high power consumption and low density. However, the nonvolatile memory, such as the phase-change memory (PCM), represents an additional choice because of the low power consumption and high-density characteristic. Nevertheless, the high access latency and limited write endurance have disabled the PCM to replace the DRAM currently. Therefore, a hybrid memory, which combines both the DRAM and the PCM, has become a good alternative to the traditional DRAM memory. Both DRAM and PCM disadvantages are challenges for the hybrid memory. In this paper, a dynamic adaptive replacement policy (DARP) in the shared last-level cache for the DRAM/PCM hybrid main memory is proposed. The DARP distinguishes the cache data into the PCM data and the DRAM data, then, the algorithm adopts different replacement policies for each data type. Specifically, for the PCM data, the least recently used (LRU) replacement policy is adopted, and for the DRAM data, the DARP is employed according to the process behavior. Experimental results have shown that the DARP improved the memory access efficiency by 25.4%.","Phase change materials,
Random access memory,
Informatics,
Power demand,
Big data,
Memory management,
Nonvolatile memory"
Wireless-Powered Sensor Networks: How to Realize,"In this paper, we study a multi-antenna wireless-powered sensor network (WPSN), in which a power beacon wirelessly transfers electric energy to a sensor node via an electromagnetic wave. We have implemented a real-life multi-antenna WPSN testbed and conducted extensive experiments on the testbed. The key technology for the high-efficiency WPSN is an adaptive energy beamforming scheme that dynamically steers a microwave beam towards a sensor node. We propose a receive power-based channel estimation and energy beamforming algorithm. In addition, an adaptive duty cycle control algorithm is proposed to prevent energy storage of a sensor node from being depleted. The proposed duty cycle control algorithm is designed based on a proportional-integral-derivative controller. These algorithms are all implemented in the multi-antenna WPSN testbed. By experiments, we validate the feasibility of the multi-antenna WPSN, and show the performance of the proposed algorithms.","Radio frequency,
Energy exchange,
Channel estimation,
Array signal processing,
Energy storage,
Transmitting antennas,
Energy harvesting"
Approximate Computing using Multiple-Access Single-Charge Associative Memory,"Memory-based computing using associative memory is a promising way to reduce the energy consumption of important classes of streaming applications by avoiding redundant computations. A set of frequent patterns that represent basic functions are pre-stored in Ternary Content Addressable Memory (TCAM) and reused. The primary limitation to using associative memory in modern parallel processors is the large search energy required by TCAMs. In TCAMs, all rows that match, except hit rows, precharge and discharge for every search operation, resulting in high energy consumption. In this paper, we propose a new Multiple-Access Single-Charge (MASC) TCAM architecture which is capable of searching TCAM contents multiple times with only a single precharge cycle. In contrast to previous designs, the MASC TCAM keeps the match-line voltage of all miss-rows high and uses their charge for the next search operation, while only the hit rows discharge. We use periodic refresh to control the accuracy of the search. We also implement a new type of approximate associative memory by setting longer refresh times for MASC TCAMs, which yields search results within 1-2 bit Hamming distances of the exact value. To further decrease the energy consumption of MASC TCAM and reduce the area, we implement MASC with crossbar TCAMs. Our evaluation on AMD Southern Island GPU shows that using MASC (crossbar MASC) associative memory can improve the average floating point units energy efficiency by 33.4%, 38.1%, and 36.7% (37.7%, 42.6%, and 43.1%) for exact matching, selective 1-HD and 2-HD approximations respectively, providing an acceptable quality of service (PSNR>30dB and average relative error<10%). This shows that MASC (crossbar MASC) can achieve 1.77X (1.93X) higher energy savings as compared to the state of the art implementation of GPGPU that uses voltage overscaling on TCAM.","Associative memory,
Energy consumption,
Nonvolatile memory,
Discharges (electric),
Program processors,
Energy efficiency,
Computer architecture"
Global Synchronization of Multiple Recurrent Neural Networks With Time Delays via Impulsive Interactions,"In this paper, new results on the global synchronization of multiple recurrent neural networks (NNs) with time delays via impulsive interactions are presented. Impulsive interaction means that a number of NNs communicate with each other at impulse instants only, while they are independent at the remaining time. The communication topology among NNs is not required to be always connected and can switch ON and OFF at different impulse instants. By using the concept of sequential connectivity and the properties of stochastic matrices, a set of sufficient conditions depending on time delays is derived to ascertain global synchronization of multiple continuous-time recurrent NNs. In addition, a counterpart on the global synchronization of multiple discrete-time NNs is also discussed. Finally, two examples are presented to illustrate the results.","Synchronization,
Artificial neural networks,
Delay effects,
Couplings,
Topology,
Switches,
Network topology"
Multimodal Estimation of Distribution Algorithms,"Taking the advantage of estimation of distribution algorithms (EDAs) in preserving high diversity, this paper proposes a multimodal EDA. Integrated with clustering strategies for crowding and speciation, two versions of this algorithm are developed, which operate at the niche level. Then these two algorithms are equipped with three distinctive techniques: 1) a dynamic cluster sizing strategy; 2) an alternative utilization of Gaussian and Cauchy distributions to generate offspring; and 3) an adaptive local search. The dynamic cluster sizing affords a potential balance between exploration and exploitation and reduces the sensitivity to the cluster size in the niching methods. Taking advantages of Gaussian and Cauchy distributions, we generate the offspring at the niche level through alternatively using these two distributions. Such utilization can also potentially offer a balance between exploration and exploitation. Further, solution accuracy is enhanced through a new local search scheme probabilistically conducted around seeds of niches with probabilities determined self-adaptively according to fitness values of these seeds. Extensive experiments conducted on 20 benchmark multimodal problems confirm that both algorithms can achieve competitive performance compared with several state-of-the-art multimodal algorithms, which is supported by nonparametric tests. Especially, the proposed algorithms are very promising for complex problems with many local optima.","Sociology,
Statistics,
Optimization,
Estimation,
Clustering algorithms,
Heuristic algorithms,
Sensitivity"
Blessing of Dimensionality: Recovering Mixture Data via Dictionary Pursuit,"This paper studies the problem of recovering the authentic samples that lie on a union of multiple subspaces from their corrupted observations. Due to the high-dimensional and massive nature of today’s data-driven community, it is arguable that the target matrix (i.e., authentic sample matrix) to recover is often low-rank. In this case, the recently established Robust Principal Component Analysis (RPCA) method already provides us a convenient way to solve the problem of recovering mixture data. However, in general, RPCA is not good enough because the incoherent condition assumed by RPCA is not so consistent with the mixture structure of multiple subspaces. Namely, when the subspace number grows, the row-coherence of data keeps heightening and, accordingly, RPCA degrades. To overcome the challenges arising from mixture data, we suggest to consider LRR in this paper. We elucidate that LRR can well handle mixture data, as long as its dictionary is configured appropriately. More precisely, we mathematically prove that LRR can weaken the dependence on the row-coherence, provided that the dictionary is well-conditioned and has a rank of not too high. In particular, if the dictionary itself is sufficiently low-rank, then the dependence on the row-coherence can be completely removed. These provide some elementary principles for dictionary learning and naturally lead to a practical algorithm for recovering mixture data. Our experiments on randomly generated matrices and real motion sequences show promising results.","Dictionaries,
Principal component analysis,
Coherence,
Learning systems,
Matrix decomposition,
Sparse matrices,
Clustering methods"
An Incremental CFS Algorithm for Clustering Large Data in Industrial Internet of Things,"With the rapid advances of sensing technologies and wireless communications, large amounts of dynamic data pertaining to industrial production are being collected from many sensor nodes deployed in the industrial Internet of Things. Analyzing those data effectively can help to improve the industrial services and mitigate the system unprepared breakdowns. As an important technique of data analysis, clustering attempts to find the underlying pattern structures embedded in unlabeled information. Unfortunately, most of the current clustering techniques that could only deal with static data become infeasible to cluster a significant volume of data in the dynamic industrial applications. To tackle this problem, an incremental clustering algorithm by fast finding and searching of density peaks based on k-mediods is proposed in this paper. In the proposed algorithm, two cluster operations, namely cluster creating and cluster merging, are defined to integrate the current pattern into the previous one for the final clustering result, and k-mediods is employed to modify the clustering centers according to the new arriving objects. Finally, experiments are conducted to validate the proposed scheme on three popular UCI datasets and two real datasets collected from industrial Internet of Things in terms of clustering accuracy and computational time.","data analysis,
Internet of Things,
pattern clustering,
production engineering computing"
Kernel-Based Reconstruction of Graph Signals,"A number of applications in engineering, social sciences, physics, and biology involve inference over networks. In this context, graph signals are widely encountered as descriptors of vertex attributes or features in graph-structured data. Estimating such signals in all vertices given noisy observations of their values on a subset of vertices has been extensively analyzed in the literature of signal processing on graphs (SPoG). This paper advocates kernel regression as a framework generalizing popular SPoG modeling and reconstruction and expanding their capabilities. Formulating signal reconstruction as a regression task on reproducing kernel Hilbert spaces of graph signals permeates benefits from statistical learning, offers fresh insights, and allows for estimators that leverage richer forms of prior information than existing alternatives. A number of SPoG notions such as bandlimitedness, graph filters, and the graph Fourier transform are naturally accommodated in the kernel framework. Additionally, this paper capitalizes on the so-called representer theorem to devise simpler versions of existing Tikhonov regularized estimators, and offers a novel probabilistic interpretation of kernel methods on graphs based on graphical models. Motivated by the challenges of selecting the bandwidth parameter in SPoG estimators or the kernel map in kernel-based methods, this paper further proposes two multikernel approaches with complementary strengths. Whereas the first enables estimation of the unknown bandwidth of bandlimited signals, the second allows for efficient graph filter selection. Numerical tests with synthetic as well as real data demonstrate the merits of the proposed methods relative to state-of-the-art alternatives.",
Objective Quality Prediction of Image Retargeting Algorithms,"Quality assessment of image retargeting results is useful when comparing different methods. However, performing the necessary user studies is a long, cumbersome process. In this paper, we propose a simple yet efficient objective quality assessment method based on five key factors: i) preservation of salient regions; ii) analysis of the influence of artifacts; iii) preservation of the global structure of the image; iv) compliance with well-established aesthetics rules; and v) preservation of symmetry. Experiments on the RetargetMe benchmark, as well as a comprehensive additional user study, demonstrate that our proposed objective quality assessment method outperforms other existing metrics, while correlating better with human judgements. This makes our metric a good predictor of subjective preference.",
User Selection and Power Allocation in Full-Duplex Multicell Networks,"Full-duplex (FD) communications has the potential to double the capacity of a half-duplex (HD) system at the link level. However, in a cellular network, FD operation is not a straightforward extension of HD operations. The increased interference due to a large number of simultaneous transmissions in FD operation and real-time traffic conditions limits the capacity for improvement. Realizing the potential of FD requires careful coordination of resource allocation among the cells, as well as within the cell. In this paper, we propose a distributed resource allocation, i.e., joint user selection and power allocation for an FD multicell system, assuming FD base stations (BSs) and HD user equipment (UE). Due to the complexity of finding the globally optimum solution, a suboptimal solution for UE selection and a novel geometric-programming-based solution for power allocation are proposed. The proposed distributed approach converges quickly and performs almost as well as a centralized solution but with much lower signaling overhead. It provides a hybrid scheduling policy that allows FD operations whenever it is advantageous, but otherwise, it defaults to HD operation. We focus on small-cell systems because they are more suitable for FD operation, given practical self-interference cancelation limits. With practical self-interference cancelation, it is shown that the proposed hybrid FD system achieves nearly twice the throughput improvement for an indoor multicell scenario and about 65% improvement for an outdoor multicell scenario, compared with the HD system.","Interference,
Resource management,
High definition video,
Uplink,
Downlink,
Throughput,
Wireless communication"
A Truncated Prediction Approach to Consensus Control of Lipschitz Nonlinear Multiagent Systems With Input Delay,"This paper deals with the consensus control problem for Lipschitz nonlinear multiagent systems with input delay. A prediction of the agent state over the delay period is approximated by the zero input solution of the agent dynamics. The structure of a linear state feedback control algorithm is assumed for each agent based on such approximated state prediction. By transforming the Laplacian matrix into the real Jordan form, sufficient conditions are established under which the multiagent systems under the proposed control algorithms achieve global consensus. The feedback gain is then designed by solving these conditions with an iterative linear matrix inequality procedure. A simulation study is given to validate the proposed control design.","Delays,
Multi-agent systems,
Eigenvalues and eigenfunctions,
Laplace equations,
Algorithm design and analysis,
Control design"
E-HIPA: An Energy-Efficient Framework for High-Precision Multi-Target-Adaptive Device-Free Localization,"Device-free localization (DFL), which does not require any devices to be attached to target(s), has become an appealing technology for many applications, such as intrusion detection and elderly monitoring. To achieve high localization accuracy, most recent DFL methods rely on collecting a large number of received signal strength (RSS) changes distorted by target(s). Consequently, the incurred high energy consumption renders them infeasible for resource-constraint networks, such as wireless sensor networks. This paper introduces an energy-efficient framework for high-precision multi-target-adaptive device-free localization (E-HIPA). Compared with the existing methods, E-HIPA demands fewer transceivers, applies the compressive sensing (CS) theory to guarantee high localization accuracy with less RSS change measurements. The motivation behind the proposed E-HIPA is the sparse nature of multi-target locations in the spatial domain. Before taking advantage of this intrinsic sparseness, we theoretically prove the validity of the proposed CS-based framework problem formulation. Based on the formulation, the proposed E-HIPA primarily includes an adaptive orthogonal matching pursuit (AOMP) algorithm, by which it is capable of recovering the precise location vector with high probability, even for a more practical scenario with unknown target number. Experimental results via real testbed demonstrate that, compared with the previous state-of-the-art solutions, i.e., RTI, SCPL, and RASS approaches, E-HIPA reduces the energy consumption by up to 69 percent with meter-level localization accuracy.","Transceivers,
Fingerprint recognition,
Monitoring,
Sensors,
Distortion measurement,
Energy efficiency,
Mobile computing"
Approach in Nonintrusive Type I Load Monitoring Using Subtractive Clustering,"In this paper, a low-sampling-rate and nonintrusive appliance loads monitoring (NIALM), which required only few tuning parameters and which is little sensitive to the grid power noise, is presented. Using transformed active power transitions as features, the proposed approach is based on the subtractive clustering and the maximum likelihood classifier. In order to validate the NIALM, a 1 Hz sampling rate experimental data from the reference energy disaggregation dataset is selected. The validation results with six commonly found ON/OFF residential appliances indicate that the proposed approach is effective. In addition, the obtained results from a Monte Carlo simulation suggest that this approach is less sensitive to power grid noise than a K -mean-based NIALM method.","Home appliances,
Clustering algorithms,
Monitoring,
Steady-state,
Noise,
Feature extraction,
Load modeling"
Orchestrating Bulk Data Transfers across Geo-Distributed Datacenters,"As it has become the norm for cloud providers to host multiple datacenters around the globe, significant demands exist for inter-datacenter data transfers in large volumes, e.g., migration of big data. A challenge arises on how to schedule the bulk data transfers at different urgency levels, in order to fully utilize the available inter-datacenter bandwidth. The Software Defined Networking (SDN) paradigm has emerged recently which decouples the control plane from the data paths, enabling potential global optimization of data routing in a network. This paper aims to design a dynamic, highly efficient bulk data transfer service in a geo-distributed datacenter system, and engineer its design and solution algorithms closely within an SDN architecture. We model data transfer demands as delay tolerant migration requests with different finishing deadlines. Thanks to the flexibility provided by SDN, we enable dynamic, optimal routing of distinct chunks within each bulk data transfer (instead of treating each transfer as an infinite flow), which can be temporarily stored at intermediate datacenters to mitigate bandwidth contention with more urgent transfers. An optimal chunk routing optimization model is formulated to solve for the best chunk transfer schedules over time. To derive the optimal schedules in an online fashion, three algorithms are discussed, namely a bandwidth-reserving algorithm, a dynamically-adjusting algorithm, and a future-demand-friendly algorithm, targeting at different levels of optimality and scalability. We build an SDN system based on the Beacon platform and OpenFlow APIs, and carefully engineer our bulk data transfer algorithms in the system. Extensive real-world experiments are carried out to compare the three algorithms as well as those from the existing literature, in terms of routing optimality, computational delay and overhead.",
Question Quality Analysis and Prediction in Community Question Answering Services with Coupled Mutual Reinforcement,"Community question answering services (CQAS) (e.g., Yahoo! Answers) provides a platform where people post questions and answer questions posed by others. Previous works analyzed the answer quality (AQ) based on answer-related features, but neglect the question-related features on AQ. Previous work analyzed how asker- and question-related features affect the question quality (QQ) regarding the amount of attention from users, the number of answers and the question solving latency, but neglect the correlation between QQ and AQ (measured by the rating of the best answer), which is critical to quality of service (QoS). We handle this problem from two aspects. First, we additionally use QQ in measuring AQ, and analyze the correlation between a comprehensive list of features (including answer-related features) and QQ. Second, we propose the first method that estimates the probability for a given question to obtain high AQ. Our analysis on the Yahoo! Answers trace confirmed that the list of our identified features exert influence on AQ, which determines QQ. For the correlation analysis, the previous classification algorithms cannot consider the mutual interactions between multiple (>2) classes of features. We then propose a novel Coupled Semi-Supervised Mutual Reinforcement-based Label Propagation (CSMRLP) algorithm for this purpose. Our extensive experiments show that CSMRLP outperforms the Mutual Reinforcement-based Label Propagation (MRLP) and five other traditional classification algorithms in the accuracy of AQ classification, and the effectiveness of our proposed method in AQ prediction. Finally, we provide suggestions on how to create a question that will receive high AQ, which can be exploited to improve the QoS of CQAS.",
Nonlinear Stabilization Control of Multiple-RTAC Systems Subject to Amplitude-Restricted Actuating Torques Using Only Angular Position Feedback,"Multiple rotational translational actuator (RTAC) systems are nonlinear complicated mechatronic systems introduced to investigate the self-synchronized phenomenon in mechanical engineering, which consist of a series of single-RTAC subsystems connected one by one through elastic springs. This paper studies the globally stabilizing control problem for multiple-RTAC systems by considering that the actuators are constrained in torque amplitudes and velocity signals are unavailable for feedback. More precisely, by carefully analyzing the system energy storage function and respecting the maximum allowable control torques, a novel amplitude-restricted control law is developed without requiring velocity feedback, which can stabilize multiple-RTAC systems from any initial condition theoretically. It is beneficial that the proposed control law does not involve any plant parameters, which consequently makes it insensitive to parameter uncertainties. The stability and convergence characteristics of the designed control system are rigorously supported with Lyapunov techniques. To the best of our knowledge, the proposed controller is the first one that can stabilize a multiple-RTAC system while simultaneously ensuring the practical control amplitude-restricted constraints, by using only output feedback. Both numerical simulation and hardware experiments are included to verify the effectiveness of the proposed control approach.","Actuators,
Springs,
Potential energy,
Rotors,
Output feedback,
Mechatronics,
Hardware"
Stochastic Load Balancing for Virtual Resource Management in Datacenters,"Cloud computing offers a cost-effective and elastic computing paradigm that facilitates large scale data storage and analytics. By deploying virtualization technologies in the datacenter, cloud enables efficient resource management and isolation for various big data applications. Since the hotspots (i.e., overloaded machines) can degrade the performance of these applications, virtual machine migration has been utilized to perform load balancing in the datacenters to eliminate hotspots and guarantee Service Level Agreements (SLAs). However, the previous load balancing schemes make migration decisions based on deterministic resource demand estimation and workload characterization, without considering their stochastic properties. By studying real world traces, we show that the resource demand and workload of virtual machines are highly dynamic and bursty, which can cause these schemes to make inefficient migrations for load balancing. To address this problem, in this paper we propose a stochastic load balancing scheme which aims to provide probabilistic guarantee against the resource overloading with virtual machine migration, while minimizing the total migration overhead. Our scheme effectively addresses the prediction of the distribution of resource demand and the multidimensional resource requirements with stochastic characterization. Moreover, as opposed to the previous works that measure the migration cost without considering the network topology, our scheme explicitly takes into account the distance between the source physical machine and the destination physical machine for a virtual machine migration. The trace-driven experiments show that our scheme outperforms the previous schemes in terms of SLA violation and the migration cost.","Load management,
Cloud computing,
Resource management,
Virtual machining,
Dynamic scheduling,
Estimation,
Probabilistic logic"
Scalable Certificate Revocation Schemes for Smart Grid AMI Networks Using Bloom Filters,"Given the scalability of the advanced metering infrastructure (AMI) networks, maintenance and access of certificate revocation lists (CRLs) pose new challenges. It is inefficient to create one large CRL for all the smart meters (SMs) or create a customized CRL for each SM since too many CRLs will be required. In order to tackle the scalability of the AMI network, we divide the network into clusters of SMs, but there is a tradeoff between the overhead at the certificate authority (CA) and the overhead at the clusters. We use Bloom filters to reduce the size of the CRLs in order to alleviate this tradeoff by increasing the clusters' size with acceptable overhead. However, since Bloom filters suffer from false positives, there is a need to handle this problem so that SMs will not discard important messages due to falsely identifying the certificate of a sender as invalid. To this end, we propose two certificate revocation schemes that can identify and nullify the false positives. While the first scheme requires contacting the gateway to resolve them, the second scheme requires the CA additionally distribute the list of certificates that trigger false positives. Using mathematical models, we have demonstrated that the probability of contacting the gateway in the first scheme and the overhead of the second scheme can be very low by properly designing the Bloom filters. In order to assess the scalability and validate the mathematical formulas, we have implemented the proposed schemes using Visual C. The results indicate that our schemes are much more scalable than the conventional CRL and the mathematical and simulation results are almost identical. Moreover, we simulated the distribution of the CRLs in a wireless mesh-based AMI network using ns-3 network simulator and assessed its distribution overhead.","Logic gates,
Scalability,
Public key,
Smart grids,
Relays,
Companies"
"Non-Orthogonal Multiple Access (NOMA) for Downlink Multiuser MIMO Systems: User Clustering, Beamforming, and Power Allocation","We investigate the application of non-orthogonal multiple access (NOMA) with successive interference cancellation (SIC) in downlink multiuser multiple-input multiple-output (MIMO) cellular systems, where the total number of receive antennas at user equipment (UE) ends in a cell is more than the number of transmit antennas at the base station (BS). We first dynamically group the UE receive antennas into a number of clusters equal to or more than the number of BS transmit antennas. A single beamforming vector is then shared by all the receive antennas in a cluster. We propose a linear beamforming technique in which all the receive antennas can significantly cancel the inter-cluster interference. On the other hand, the receive antennas in each cluster are scheduled on the power domain NOMA basis with SIC at the receiver ends. For inter-cluster and intra-cluster power allocation, we provide dynamic power allocation solutions with an objective to maximizing the overall cell capacity. An extensive performance evaluation is carried out for the proposed MIMO-NOMA system and the results are compared with those for conventional orthogonal multiple access (OMA)-based MIMO systems and other existing MIMO-NOMA solutions. The numerical results quantify the capacity gain of the proposed MIMO-NOMA model over MIMO-OMA and other existing MIMO-NOMA solutions.","NOMA,
Resource management,
Receiving antennas,
Downlink,
Transmitting antennas,
MIMO,
Interference"
Distributed Algorithms to Compute Walrasian Equilibrium in Mobile Crowdsensing,"In this paper, we consider joint pricing and task allocation in a unified mobile crowdsensing system, where all task initiators and mobile users are viewed as peers. From an exchange market point of view, the pricing and task allocation in such a unified system depend only on the supply and demand since no one can dominate the process, with the optimal solution being characterized by the Walrasian equilibrium. This is quite different from existing approaches, where each task initiator builds a specific mobile crowdsensing system and provides an incentive mechanism to maximize his/her own utility. We design distributed algorithms to compute the Walrasian equilibrium under the scenario where one cloud platform is available in the system. We propose to maximize social welfare of the whole system, and dual decomposition is then employed to divide the social welfare maximization problem into a set of subproblems that can be solved by task initiators and mobile users. We prove that the proposed algorithm converges to the optimal solution of social welfare maximization problem. Further, we show that the prices and task allocation obtained by the algorithm also yields a Walrasian equilibrium. Also, the proposed algorithm does not need the cloud to collect private information such as utility functions of task initiators and cost functions of mobile users. Extensive simulations demonstrate the effectiveness of the proposed algorithms.","Mobile communication,
Sensors,
Resource management,
Pricing,
Algorithm design and analysis,
Distributed algorithms,
Optimization"
Salient Object Detection via Structured Matrix Decomposition,"Low-rank recovery models have shown potential for salient object detection, where a matrix is decomposed into a low-rank matrix representing image background and a sparse matrix identifying salient objects. Two deficiencies, however, still exist. First, previous work typically assumes the elements in the sparse matrix are mutually independent, ignoring the spatial and pattern relations of image regions. Second, when the low-rank and sparse matrices are relatively coherent, e.g., when there are similarities between the salient objects and background or when the background is complicated, it is difficult for previous models to disentangle them. To address these problems, we propose a novel structured matrix decomposition model with two structural regularizations: (1) a tree-structured sparsity-inducing regularization that captures the image structure and enforces patches from the same object to have similar saliency values, and (2) a Laplacian regularization that enlarges the gaps between salient objects and the background in feature space. Furthermore, high-level priors are integrated to guide the matrix decomposition and boost the detection. We evaluate our model for salient object detection on five challenging datasets including single object, multiple objects and complex scene images, and show competitive results as compared with 24 state-of-the-art methods in terms of seven performance metrics.",
User-Centric Demand Response Management in the Smart Grid With Multiple Providers,"The smart grid is the next generation power grid with bidirectional communications between the electricity users and the providers. Demand response management is vital in the smart grid to reduce power generation costs as well as to lower the users’ electricity bills. In this paper, we introduce multiple fossil-fuel and multiple renewable energy sources-based utility companies on the supply side, and propose an end-user oriented utility company selection scheme to minimize user costs. We formulate the problem as a game, incorporating the uncertainty associated with the power supply of the renewable sources, and prove that there exists a Nash equilibrium for the game. To further reduce users’ costs, we develop a joint scheme by integrating shiftable load scheduling with utility company selection. We model the joint scheme also as a game, and prove the existence of a Nash equilibrium for the game. For both schemes, we propose distributed algorithms for the users to find the equilibrium of the game using only local information. We evaluate our schemes and compare their performances to two other approaches. The results show that our joint utility company selection and shiftable load scheduling scheme incurs the least cost to the users.","Renewable energy sources,
Games,
Companies,
Smart grids,
Cost function,
Power generation,
Electricity"
Mean-Square H_\infty Consensus Control for a Class of Nonlinear Time-Varying Stochastic Multiagent Systems: The Finite-Horizon Case,"This paper deals with the consensus control problem for a class of nonlinear discrete time-varying stochastic multiagent systems (MASs) over a finite horizon via static output feedback. The measurement output available for the controller is not only from the individual agent itself but also from its neighboring ones according to the given topology. The nonlinearities described by statistical means can encompass several classes of well-studied nonlinearities in the literature. A new index of mean-square consensus performance, which quantifies the deviation level from the state of individual agent to the average value of all agents' states, is proposed to reflect the transient consensus behavior of the MAS. The purpose of the addressed problem is to design a time-varying output feedback controller such that: 1) the H∞ consensus performance defined over a given finite horizon is guaranteed with respect to the additive noises and 2) at each time step, the mean-square consensus performance satisfies the prespecified upper bound constraint. By using a set of recursive matrix inequalities, sufficient conditions are derived for the existence of the desired control scheme for achieving both H∞ and mean-square consensus performance requirements. Finally, a simulation example is utilized to illustrate the usefulness of the proposed control protocol.","Stochastic processes,
Time-varying systems,
Symmetric matrices,
Multi-agent systems,
Topology,
Linear matrix inequalities,
Control systems"
Structured Output-Associated Dictionary Learning for Haptic Understanding,"Haptic sensing and feedback play extremely important roles for humans and robots to perceive, understand, and manipulate the world. Since many properties perceived by the haptic sensors can be characterized by adjectives, it is reasonable to develop a set of haptic adjectives for the haptic understanding. This formulates the haptic understanding as a multilabel classification problem. In this paper, we exploit the intrinsic relation between different adjective labels and develop a novel dictionary learning method which is improved by introducing the structured output association information. Such a method makes use of the label correlation information and is more suitable for the multilabel haptic understanding task. In addition, we develop two iterative algorithms to solve the dictionary learning and classifier design problems, respectively. Finally, we perform extensive experimental validations on the public available haptic sequence dataset Penn Haptic Adjective Corpus 2 and show the advantages of the proposed method.","Haptic interfaces,
Dictionaries,
Object recognition,
Encoding,
Kernel,
Learning systems,
Sensors"
"5G: A Tutorial Overview of Standards, Trials, Challenges, Deployment, and Practice","There is considerable pressure to define the key requirements of 5G, develop 5G standards, and perform technology trials as quickly as possible. Normally, these activities are best done in series but there is a desire to complete these tasks in parallel so that commercial deployments of 5G can begin by 2020. 5G will not be an incremental improvement over its predecessors; it aims to be a revolutionary leap forward in terms of data rates, latency, massive connectivity, network reliability, and energy efficiency. These capabilities are targeted at realizing high-speed connectivity, the Internet of Things, augmented virtual reality, the tactile internet, and so on. The requirements of 5G are expected to be met by new spectrum in the microwave bands (3.3-4.2 GHz), and utilizing large bandwidths available in mm-wave bands, increasing spatial degrees of freedom via large antenna arrays and 3-D MIMO, network densification, and new waveforms that provide scalability and flexibility to meet the varying demands of 5G services. Unlike the one size fits all 4G core networks, the 5G core network must be flexible and adaptable and is expected to simultaneously provide optimized support for the diverse 5G use case categories. In this paper, we provide an overview of 5G research, standardization trials, and deployment challenges. Due to the enormous scope of 5G systems, it is necessary to provide some direction in a tutorial article, and in this overview, the focus is largely user centric, rather than device centric. In addition to surveying the state of play in the area, we identify leading technologies, evaluating their strengths and weaknesses, and outline the key challenges ahead, with research test beds delivering promising performance but pre-commercial trials lagging behind the desired 5G targets.","5G mobile communication,
Computer architecture,
Microprocessors,
Bandwidth,
Antenna arrays,
Tutorials"
Enabling IoT Ecosystems through Platform Interoperability,"Today, the Internet of Things (IoT) comprises vertically oriented platforms for things. Developers who want to use them need to negotiate access individually and adapt to the platform-specific API and information models. Having to perform these actions for each platform often outweighs the possible gains from adapting applications to multiple platforms. This fragmentation of the IoT and the missing interoperability result in high entry barriers for developers and prevent the emergence of broadly accepted IoT ecosystems. The BIG IoT (Bridging the Interoperability Gap of the IoT) project aims to ignite an IoT ecosystem as part of the European Platforms Initiative. As part of the project, researchers have devised an IoT ecosystem architecture. It employs five interoperability patterns that enable cross-platform interoperability and can help establish successful IoT ecosystems.","Internet of things,
Software development,
Ecosystems,
Interoperability"
A Micro-GA Embedded PSO Feature Selection Approach to Intelligent Facial Emotion Recognition,"This paper proposes a facial expression recognition system using evolutionary particle swarm optimization (PSO)-based feature optimization. The system first employs modified local binary patterns, which conduct horizontal and vertical neighborhood pixel comparison, to generate a discriminative initial facial representation. Then, a PSO variant embedded with the concept of a micro genetic algorithm (mGA), called mGA-embedded PSO, is proposed to perform feature optimization. It incorporates a nonreplaceable memory, a small-population secondary swarm, a new velocity updating strategy, a subdimension-based in-depth local facial feature search, and a cooperation of local exploitation and global exploration search mechanism to mitigate the premature convergence problem of conventional PSO. Multiple classifiers are used for recognizing seven facial expressions. Based on a comprehensive study using within- and cross-domain images from the extended Cohn Kanade and MMI benchmark databases, respectively, the empirical results indicate that our proposed system outperforms other state-of-the-art PSO variants, conventional PSO, classical GA, and other related facial expression recognition models reported in the literature by a significant margin.",
Social-Aware Data Dissemination via Device-to-Device Communications: Fusing Social and Mobile Networks with Incentive Constraints,"Nowadays, pervasive mobile devices not only pose new challenges for existing wireless networks to accommodate the surging demands, but also offer new opportunities to support various services. For example, device-to-device (D2D) communications provide a promising paradigm for data dissemination with low resource cost and high energy efficiency. In this paper, we propose a three-phase approach for D2D data dissemination, which exploits social-awareness and opportunistic contacts with user mobility. The proposed approach includes one phase of seed selection and two subsequent phases of data forwarding. In Phase I, we build a social-physical graph model, which combines the social network and the mobile network with opportunistic transmissions. Then we partition the social-physical graph into communities using the Girvan-Newman algorithm based on edge-betweenness, and select seeds for the communities according to vertex-closeness. In Phase II, data forwarding only takes place among socially connected users. In Phase III, the base station intervenes to enable data forwarding among cooperative users. For Phase II and Phase III, we propose the new mechanisms for message selection and cooperation pairing, which take into account both altruistic and selfish behaviors of users. The theoretical analysis for the message selection mechanism proves its truthfulness and approximation ratio in the worst case. Extensive simulation results further demonstrate the effectiveness of the proposed three-phase approach with various synthetic and real tracing datasets.","Social network services,
Relays,
Mobile computing,
Mobile communication,
Games,
Data models"
A Dynamic EV Charging System for Slow Moving Traffic Applications,"Inductive power transfer (IPT) is by far the most popular method to transfer energy wirelessly and has attracted considerable attention in recent times. The Wireless Power Consortium has developed a standard (Qi) for low power consumer electronics, whereas the Society of Automotive Engineers (SAE) is working on a standard (J2954) to charge electric vehicles (EVs) wirelessly. SAE's current efforts are focused only on transferring power to the vehicles at rest (static), whereas no work has been done so far on developing the standards for transferring power to the vehicles on the move (dynamic). This paper presents the magnetic design of an IPT system for a dynamic EV charging application, to continuously deliver a power of 15 kW to an EV, along the direction of travel within the lateral misalignment of ±200 mm. The experimental validation of system operation, however, was conducted at 5 kW. The design aims at distributing the cost and complexity of the system between the primary and secondary sides, while achieving a smooth power transfer profile. In addition, the system is designed to exploit the shielding effect provided by the vehicle, as the field generating components of the system are covered by the vehicle body under all operating conditions.","Vehicles,
Inductors,
Vehicle dynamics,
Topology,
Magnetic resonance,
Coils"
ADDSEN: Adaptive Data Processing and Dissemination for Drone Swarms in Urban Sensing,"We present ADDSEN middleware as a holistic solution for Adaptive Data processing and dissemination for Drone swarms in urban SENsing. To efficiently process sensed data in the middleware, we have proposed a cyber-physical sensing framework using partially ordered knowledge sharing for distributed knowledge management in drone swarms. A reinforcement learning dissemination strategy is implemented in the framework. ADDSEN uses online learning techniques to adaptively balance the broadcast rate and knowledge loss rate periodically. The learned broadcast rate is adapted by executing state transitions during the process of online learning. A strategy function guides state transitions, incorporating a set of variables to reflect changes in link status. In addition, we design a cooperative dissemination method for the task of balancing storage and energy allocation in drone swarms. We implemented ADDSEN in our cyber-physical sensing framework, and evaluation results show that it can achieve both maximal adaptive data processing and dissemination performance, presenting better results than other commonly used dissemination protocols such as periodic, uniform and neighbor protocols in both single-swarm and multi-swarm cases.",
Aging Precursor Identification and Lifetime Estimation for Thermally Aged Discrete Package Silicon Power Switches,"Thermal/power cycles are widely acknowledged methods to accelerate the package related failures. Many studies have focused on one particular aging precursor at a time and continuously monitored it using custom-built circuits. Due to the difficulties in taking sensitive measurements, the reported findings are more on the quantities requiring less sensitive measurements. In this paper, two custom-designed testbeds are used to age a number of power MOSFETs and insulated gate bipolar transistors. An automated curve tracer is utilized to capture parametric variations in I-V curves, parasitic capacitances, and gate charges at certain time intervals. The results suggest that the only viable aging precursors are the on-state voltage drop/on-state resistance, body diode voltage drop, parasitic capacitances, and gate threshold voltage for die attach solder and gate-oxide degradation mechanisms. Based on the experimental results, gate threshold voltage variation is empirically modeled to estimate the remaining useful lifetime of the switches experiencing gate oxide degradation. The model parameters are found by the least squares method applied to inliers determined by the random sample and consensus outlier removal algorithm.","Insulated gate bipolar transistors,
Aging,
MOSFET circuits,
Logic gates,
MOSFET,
Threshold voltage,
Degradation"
Optimal Planning of Loop-Based Microgrid Topology,"In microgrid planning, topological design is a critical concern for ensuring certain features such as high reliability in islanded operation. This paper proposes a graph partitioning and integer programming integrated methodology for the optimal loop-based microgrid topology planning while considering the distributed energy resources in the microgrid. The proposed methodology is applied to a microgrid test system and the planning results are discussed. The results demonstrate that the proposed planning methodology is able to accurately and efficiently determine an optimal loop structure for microgrids, and exhibit the potentials for applying the proposed planning methodology in practical microgrid applications.","Microgrids,
Planning,
Topology,
Network topology,
Reliability,
Energy resources,
Energy storage"
Firefly-Algorithm-Inspired Framework With Band Selection and Extreme Learning Machine for Hyperspectral Image Classification,"A firefly algorithm (FA) inspired band selection and optimized extreme learning machine (ELM) for hyperspectral image classification is proposed. In this framework, FA is to select a subset of original bands to reduce the complexity of the ELM network. It is also adapted to optimize the parameters in ELM (i.e., regularization coefficient C, Gaussian kernel σ, and hidden number of neurons L). Due to very low complexity of ELM, its classification accuracy can be used as the objective function of FA during band selection and parameter optimization. In the experiments, two hyperspectral image datasets acquired by HYDICE and HYMAP are used, and the experiment results indicate that the proposed method can offer better performance, compared with particle swarm optimization and other related band selection algorithms.","Linear programming,
Optimization,
Training,
Hyperspectral imaging,
Brightness,
Neurons"
Learning a No-Reference Quality Assessment Model of Enhanced Images With Big Data,"In this paper, we investigate into the problem of image quality assessment (IQA) and enhancement via machine learning. This issue has long attracted a wide range of attention in computational intelligence and image processing communities, since, for many practical applications, e.g., object detection and recognition, raw images are usually needed to be appropriately enhanced to raise the visual quality (e.g., visibility and contrast). In fact, proper enhancement can noticeably improve the quality of input images, even better than originally captured images, which are generally thought to be of the best quality. In this paper, we present two most important contributions. The first contribution is to develop a new no-reference (NR) IQA model. Given an image, our quality measure first extracts 17 features through analysis of contrast, sharpness, brightness and more, and then yields a measure of visual quality using a regression module, which is learned with big-data training samples that are much bigger than the size of relevant image data sets. The results of experiments on nine data sets validate the superiority and efficiency of our blind metric compared with typical state-of-the-art full-reference, reduced-reference and NA IQA methods. The second contribution is that a robust image enhancement framework is established based on quality optimization. For an input image, by the guidance of the proposed NR-IQA measure, we conduct histogram modification to successively rectify image brightness and contrast to a proper level. Thorough tests demonstrate that our framework can well enhance natural images, low-contrast images, low-light images, and dehazed images. The source code will be released at https://sites.google.com/site/guke198701/publications.","Measurement,
Feature extraction,
Image quality,
Training,
Entropy,
Visualization,
Image enhancement"
Noise Robust Face Image Super-Resolution Through Smooth Sparse Representation,"Face image super-resolution has attracted much attention in recent years. Many algorithms have been proposed. Among them, sparse representation (SR)-based face image super-resolution approaches are able to achieve competitive performance. However, these SR-based approaches only perform well under the condition that the input is noiseless or has small noise. When the input is corrupted by large noise, the reconstruction weights (or coefficients) of the input low-resolution (LR) patches using SR-based approaches will be seriously unstable, thus leading to poor reconstruction results. To this end, in this paper, we propose a novel SR-based face image super-resolution approach that incorporates smooth priors to enforce similar training patches having similar sparse coding coefficients. Specifically, we introduce the fused least absolute shrinkage and selection operator-based smooth constraint and locality-based smooth constraint to the least squares representation-based patch representation in order to obtain stable reconstruction weights, especially when the noise level of the input LR image is high. Experiments are carried out on the benchmark FEI face database and CMU+MIT face database. Visual and quantitative comparisons show that the proposed face image super-resolution method yields superior reconstruction results when the input LR face image is contaminated by strong noise.","Face,
Image resolution,
Image reconstruction,
Training,
Surveillance,
Indexes,
Urban areas"
Stability and Frequency Response Under Stochastic Communication Delays With Applications to Connected Cruise Control Design,"In this paper we investigate connected cruise control in which vehicles rely on ad hoc wireless vehicle-to-vehicle communication to control their longitudinal motion. Intermittencies and packet drops in communication channels are shown to introduce stochastic delays in the feedback loops. Sufficient conditions for almost sure stability of equilibria are derived by analyzing the mean and covariance dynamics. In addition, the concept of nσ string stability is proposed to characterize the input-output response in steady state. The stability results are summarized using stability charts in the plane of the control gains and we demonstrate that the stable regimes shrink when the sampling time or the packet drop ratio increases. The mathematical tools developed allow us to design controllers that can achieve plant stability and string stability in connected vehicle systems despite the presence of stochastically varying delays in the control loop.",
The Many Shades of Negativity,"Complex event detection has been progressively researched in recent years for the broad interest of video indexing and retrieval. To fulfill the purpose of event detection, one needs to train a classifier using both positive and negative examples. Current classifier training treats the negative videos as equally negative. However, we notice that many negative videos resemble the positive videos in different degrees. Intuitively, we may capture more informative cues from the negative videos if we assign them fine-grained labels, thus benefiting the classifier learning. Aiming for this, we use a statistical method on both the positive and negative examples to get the decisive attributes of a specific event. Based on these decisive attributes, we assign the fine-grained labels to negative examples to treat them differently for more effective exploitation. The resulting fine-grained labels may be not optimal to capture the discriminative cues from the negative videos. Hence, we propose to jointly optimize the fine-grained labels with the classifier learning, which brings mutual reciprocality. Meanwhile, the labels of positive examples are supposed to remain unchanged. We thus additionally introduce a constraint for this purpose. On the other hand, the state-of-the-art deep convolutional neural network features are leveraged in our approach for event detection to further boost the performance. Extensive experiments on the challenging TRECVID MED 2014 dataset have validated the efficacy of our proposed approach.",
A Survey of Network Lifetime Maximization Techniques in Wireless Sensor Networks,"Emerging technologies, such as the Internet of Things, smart applications, smart grids, and machine-to-machine networks stimulate the deployment of autonomous, self-configuring, large-scale wireless sensor networks (WSNs). Efficient energy utilization is crucially important in order to maintain a fully operational network for the longest period of time possible. Therefore, network lifetime (NL) maximization techniques have attracted a lot of research attention owing to their importance in terms of extending the flawless operation of battery-constrained WSNs. In this paper, we review the recent developments in WSNs, including their applications, design constraints, and lifetime estimation models. Commencing with the portrayal of rich variety definitions of NL design objective used for WSNs, the family of NL maximization techniques is introduced and some design guidelines with examples are provided to show the potential improvements of the different design criteria.",
A Survey of Heterogeneous Information Network Analysis,"Most real systems consist of a large number of interacting, multi-typed components, while most contemporary researches model them as homogeneous information networks, without distinguishing different types of objects and links in the networks. Recently, more and more researchers begin to consider these interconnected, multi-typed data as heterogeneous information networks, and develop structural analysis approaches by leveraging the rich semantic meaning of structural types of objects and links in the networks. Compared to widely studied homogeneous information network, the heterogeneous information network contains richer structure and semantic information, which provides plenty of opportunities as well as a lot of challenges for data mining. In this paper, we provide a survey of heterogeneous information network analysis. We will introduce basic concepts of heterogeneous information network analysis, examine its developments on different data mining tasks, discuss some advanced topics, and point out some future research directions.","Data mining,
Semantics,
Publishing,
Sun,
Conferences,
Analytical models,
Data models"
Joint Millimeter-Wave Fronthaul and OFDMA Resource Allocation in Ultra-Dense CRAN,"Ultra-dense (UD) wireless networks and cloud radio access networks (CRAN) are two promising network architectures for the emerging fifth-generation wireless communication systems. By jointly employing them, a new appealing network solution is proposed in this paper, termed UD-CRAN. In a UD-CRAN, millimeter-wave (mmWave) wireless fronthaul is preferred for information exchange between the central processor and the distributed remote radio heads (RRHs), due to its lower cost and higher flexibility in deployment, compared with fixed optical links. This motivates our study in this paper on the downlink transmission in a mmWave fronthaul enabled, orthogonal frequency division multiple access (OFDMA)-based UD-CRAN. In particular, the fronthaul is shared among the RRHs via time division multiple access (TDMA), while the RRHs jointly transmit to the users on orthogonal frequency sub-channels using OFDMA. The joint resource allocation over the TDMA-based mmWave fronthaul and OFDMA-based wireless transmission is investigated to maximize the weighted sum rate of all users. Although the problem is non-convex, we propose a Lagrange duality-based solution, which can be efficiently computed with good accuracy. To further reduce the complexity, we also propose a greedy search-based heuristic, which achieves close to optimal performance under practical setups. Finally, we show the significant throughput gains of the proposed joint resource allocation approach compared with other benchmark schemes by simulations.","Resource management,
Wireless communication,
Downlink,
OFDM,
Time division multiple access,
Complexity theory,
Throughput"
No-Reference Quality Metric of Contrast-Distorted Images Based on Information Maximization,"The general purpose of seeing a picture is to attain information as much as possible. With it, we in this paper devise a new no-reference/blind metric for image quality assessment (IQA) of contrast distortion. For local details, we lirst roughly remove predicted regions in an image since unpredicted remains are of much information. We then compute entropy of particular unpredicted areas of maximum information via visual saliency. From global perspective, we compare the image histogram with the uniformly distributed histogram of maximum information via the symmetric Kullback-Leibler divergence. The proposed blind IQA method generates an overall quality estimation of a contrast-distorted image by properly combining local and global considerations. Thorough experiments on live databases/subsets demonstrate the superiority of our training-free blind technique over state-of-the-art fulland no-reference IQA methods. Furthermore, the proposed model is also applied to amend the performance of general-purpose blind quality metrics to a sizable margin.","Visualization,
Entropy,
Brain modeling,
Predictive models,
Image quality,
Histograms"
Durable Address Translation in PCM-Based Flash Storage Systems,"Phase change memory (PCM) is a promising DRAM alternative because of its non-volatility, high density, low standby power and close-to-DRAM performance. These features make PCM an attractive solution to optimize the management of NAND flash memory in embedded systems. However, PCM's limited write endurance hinders its application in embedded systems. Therefore, how to manage flash memory with PCM-particularly guarantee PCM a reasonable lifetime-becomes a challenging issue. In this paper, we propose to partially replace DRAM using PCM to optimize the management of flash memory metadata for better system reliability in the presence of power failure and system crash. To prolong PCM's lifetime, we present a write-activity-aware PCM-assisted flash memory management scheme, called PCM-FTL. By differentiating sequential and random I/O behaviors, a novel two-level mapping mechanism and a customized wear-leveling scheme are developed to reduce writes to PCM and extend its lifetime. We evaluate PCM-FTL with a variety of general-purpose and mobile I/O workloads. Experimental results show that PCM-FTL can significantly reduce write activities and achieve an even distribution of writes in PCM with very low overhead.","Phase change materials,
Random access memory,
Microprocessors,
Embedded systems,
Metadata,
Memory management"
Robust AN-Aided Beamforming and Power Splitting Design for Secure MISO Cognitive Radio With SWIPT,"A multiple-input single-output cognitive radio downlink network is studied with simultaneous wireless information and power transfer. In this network, a secondary user coexists with multiple primary users and multiple energy harvesting receivers. In order to guarantee secure communication and energy harvesting, the problem of robust secure artificial noise-aided beamforming and power splitting design is investigated under imperfect channel state information (CSI). Specifically, the transmit power minimization problem and the max-min fairness energy harvesting problem are formulated for both the bounded CSI error model and the probabilistic CSI error model. These problems are non-convex and challenging to solve. A 1-D search algorithm is proposed to solve these problems based on S-Procedure under the bounded CSI error model and based on Bernstein-type inequalities under the probabilistic CSI error model. It is shown that the optimal robust secure beamforming can be achieved under the bounded CSI error model, whereas a suboptimal beamforming solution can be obtained under the probabilistic CSI error model. A tradeoff is elucidated between the secrecy rate of the secondary user receiver and the energy harvested by the energy harvesting receivers under a max-min fairness criterion.",
Camflow: Managed Data-Sharing for Cloud Services,"A model of cloud services is emerging whereby a few trusted providers manage the underlying hardware and communications whereas many companies build on this infrastructure to offer higher level, cloud-hosted PaaS services and/or SaaS applications. From the start, strong isolation between cloud tenants was seen to be of paramount importance, provided first by virtual machines (VM) and later by containers, which share the operating system (OS) kernel. Increasingly it is the case that applications also require facilities to effect isolation and protection of data managed by those applications. They also require flexible data sharing with other applications, often across the traditional cloud-isolation boundaries; for example, when government, consisting of different departments, provides services to its citizens through a common platform. These concerns relate to the management of data. Traditional access control is application and principal/role specific, applied at policy enforcement points, after which there is no subsequent control over where data flows;a crucial issue once data has left its owner’s control by cloud-hosted applications andwithin cloud-services. Information Flow Control (IFC), in addition, offers system-wide, end-to-end, flow control based on the properties of the data. We discuss the potential of cloud-deployed IFC for enforcing owners’ data flow policy with regard to protection and sharing, aswell as safeguarding against malicious or buggy software. In addition, the audit log associated with IFC provides transparency and offers system-wide visibility over data flows. This helps those responsible to meet their data management obligations, providing evidence of compliance, and aids in the identification ofpolicy errors and misconfigurations. We present our IFC model and describe and evaluate our IFC architecture and implementation (CamFlow). This comprises an OS level implementation of IFC with support for application management, together with an IFC-enabled middleware.","Cloud computing,
Context,
Containers,
Access control,
Computer architecture,
Computational modeling"
Discriminative Multi-instance Multitask Learning for 3D Action Recognition,"As the prosperity of low-cost and easy-operating depth cameras, skeleton-based human action recognition has been extensively studied recently. However, most of the existing methods partially consider that all 3D joints of a human skeleton are identical. Actually, these 3D joints exhibit diverse responses to different action classes, and some joint configurations are more discriminative to distinguish a certain action. In this paper, we propose a discriminative multi-instance multitask learning (MIMTL) framework to discover the intrinsic relationship between joint configurations and action classes. First, a set of discriminative and informative joint configurations for the corresponding action class is captured in multi-instance learning model by regarding the action and the joint configurations as a bag and its instances, respectively. Then, a multitask learning model with group structure constraints is exploited to further reveal the intrinsic relationship between the joint configurations and different action classes. We conduct extensive evaluations of MIMTL using three benchmark 3D action recognition datasets. Experimental results show that our proposed MIMTL framework performs favorably compared with several state-of-the-art approaches.","Three-dimensional displays,
Skeleton,
Solid modeling,
Correlation,
Electronic mail,
Training data,
Hidden Markov models"
Botnets and Internet of Things Security,Recent distributed denial-of-service attacks demonstrate the high vulnerability of Internet of Things (IoT) systems and devices. Addressing this challenge will require scalable security solutions optimized for the IoT ecosystem.,"Botnets,
Internet of things,
Trust management,
Denial of service,
Behavioral sciences"
A Hierarchical Human-Robot Interaction-Planning Framework for Task Allocation in Collaborative Industrial Assembly Processes,"In this letter, we propose a framework for task allocation in human-robot collaborative assembly planning. Our framework distinguishes between two main layers of abstraction and allocation. In the higher layer, we use an abstract world model, incorporating a multiagent human-robot team approach in order to describe the collaborative assembly planning problem. From this, nominal co-ordinated skill sequences for every agent are produced. In order to be able to treat humans and robots as agents of the same form, we move relevant differences/peculiarities into distinct cost functions. The layer beneath handles the concrete skill execution. On atomic level, skills are composed of complex hierarchical and concurrent hybrid state machines, which in turn co-ordinate the real-time behavior of the robot. Their careful design allows to cope with unpredictable events also on decisional level without having to explicitly plan for them, instead one may rely also on manually designed skills. Such events are likely to happen in dynamic and potentially partially known environments, which is especially true in case of human presence.","Collaboration,
Robot kinematics,
Resource management,
Planning,
Service robots,
Geometry"
Random-Walker-Based Collaborative Learning for Hyperspectral Image Classification,"Active learning (AL) and semisupervised learning (SSL) are both promising solutions to hyperspectral image classification. Given a few initial labeled samples, this work combines AL and SSL in a novel manner, aiming to obtain more manually labeled and pseudolabeled samples and use them together with the initial labeled samples to improve the classification performance. First, based on a comparison of the segmentation and spectral-spatial classification results obtained by random walker (RW) and extended RW (ERW) algorithms, the unlabeled samples are separated into two different sets, i.e., low- and high-confidence unlabeled data sets. For the high-confidence unlabeled data, pseudolabeling is performed, which can ensure the correctness and informativeness of the pseudolabeled samples. For the low-confidence unlabeled data, AL is used to select samples. In this way, the samples which are more effective for improvement of classification performance can be labeled in only a few iterations. Finally, with the learned training set and the original hyperspectral image as inputs, the ERW classifier is used to obtain the final classification result. Experiments performed on three real hyperspectral data sets show that the proposed method can achieve competitive classification accuracy even with a very limited number of manually labeled samples.","Hyperspectral imaging,
Training,
Labeling,
Sun,
Support vector machines,
Collaborative work"
Quantized Iterative Learning Consensus Tracking of Digital Networks With Limited Information Communication,"This brief investigates the quantized iterative learning problem for digital networks with time-varying topologies. The information is first encoded as symbolic data and then transmitted. After the data are received, a decoder is used by the receiver to get an estimate of the sender's state. Iterative learning quantized communication is considered in the process of encoding and decoding. A sufficient condition is then presented to achieve the consensus tracking problem in a finite interval using the quantized iterative learning controllers. Finally, simulation results are given to illustrate the usefulness of the developed criterion.","Network topology,
Topology,
Quantization (signal),
Iterative decoding,
Bandwidth,
Matrix decomposition,
Learning systems"
Releasing Network Isolation Problem in Group-Based Industrial Wireless Sensor Networks,"In this paper, we propose a cross-layer optimization scheme named Adjusting the Transmission Radius (ATR), which is based on the Energy Consumed uniformly Connected K-Neighborhood (EC-CKN) sleep scheduling algorithm in wireless sensor networks (WSNs). In particular, we discovered two important problems, namely, the death acceleration problem and the network isolation problem, in EC-CKN-based WSNs. Furthermore, we solve these two problems in ATR, which creates sleeping opportunities for the nodes that cannot get a chance to sleep in the EC-CKN algorithm. Simulation and experimental results show that the network lifetime of ATR-Connected-K-Neighborhood-based WSNs increases by 19%, on average, and the maximum increment is 41%. In addition, four important insights were discovered through this research work and presented in this paper.",
Three-Dimensional Path Planning for Uninhabited Combat Aerial Vehicle Based on Predator-Prey Pigeon-Inspired Optimization in Dynamic Environment,"Three-dimension path planning of uninhabited combat aerial vehicle (UCAV) is a complicated optimal problem, which mainly focused on optimizing the flight route considering the different types of constrains under complex combating environment. A novel predator-prey pigeon-inspired optimization (PPPIO) is proposed to solve the UCAV three-dimension path planning problem in dynamic environment. Pigeon-inspired optimization (PIO) is a new bio-inspired optimization algorithm. In this algorithm, map and compass operator model and landmark operator model are used to search the best result of a function. The prey-predator concept is adopted to improve global best properties and enhance the convergence speed. The characteristics of the optimal path are presented in the form of a cost function. The comparative simulation results show that our proposed PPPIO algorithm is more efficient than the basic PIO, particle swarm optimization (PSO), and different evolution (DE) in solving UCAV three-dimensional path planning problems.",
State Estimation for Discrete-Time Dynamical Networks With Time-Varying Delays and Stochastic Disturbances Under the Round-Robin Protocol,"This paper is concerned with the state estimation problem for a class of nonlinear dynamical networks with time-varying delays subject to the round-robin protocol. The communication between the state estimator and the nodes of the dynamical networks is implemented through a shared constrained network, in which only one node is allowed to send data at each time instant. The round-robin protocol is utilized to orchestrate the transmission order of nodes. By using a switch-based approach, the dynamics of the estimation error is modeled by a periodic parameter-switching system with time-varying delays. The purpose of the problem addressed is to design an estimator, such that the estimation error is exponentially ultimately bounded with a certain asymptotic upper bound in mean square subject to the process noise and exogenous disturbance. Furthermore, such a bound is subsequently minimized by the designed estimator parameters. A novel Lyapunov-like functional is employed to deal with the dynamics analysis issue of the estimation error. Sufficient conditions are established to guarantee the ultimate boundedness of the estimation error in mean square by applying the stochastic analysis approach. Then, the desired estimator gains are characterized by solving a convex problem. Finally, a numerical example is given to illustrate the effectiveness of the estimator design scheme.",
Accurate Equivalent-Circuit Descriptions of Thin Glide-Symmetric Corrugated Metasurfaces,"Thin artificial surfaces that act as high frequency bandgap structures have been recently studied for the design of gap waveguides, hard surfaces, and planar lenses. Here, we propose a circuit-based method to analyze glide-symmetric corrugated metasurfaces that are embedded in a thin parallel plate waveguide. Our closed-form solution is based on rigorous analytical derivations. It achieves remarkable agreement with full-wave solvers, even when the waveguide thickness is extremely thin. In contrast, classical homogenization approaches are shown to be inaccurate for thin waveguides due to the interaction of higher order Floquet modes between the surfaces. Numerical results validate our theoretical analysis and show the utility of the proposed method.",
Hyperspectral Image Classification Using Deep Pixel-Pair Features,"The deep convolutional neural network (CNN) is of great interest recently. It can provide excellent performance in hyperspectral image classification when the number of training samples is sufficiently large. In this paper, a novel pixel-pair method is proposed to significantly increase such a number, ensuring that the advantage of CNN can be actually offered. For a testing pixel, pixel-pairs, constructed by combining the center pixel and each of the surrounding pixels, are classified by the trained CNN, and the final label is then determined by a voting strategy. The proposed method utilizing deep CNN to learn pixel-pair features is expected to have more discriminative power. Experimental results based on several hyperspectral image data sets demonstrate that the proposed method can achieve better classification performance than the conventional deep learning-based method.","Training,
Hyperspectral imaging,
Computer architecture,
Feature extraction,
Tensile stress,
Kernel"
A Maximal Clique Based Multiobjective Evolutionary Algorithm for Overlapping Community Detection,"Detecting community structure has become one important technique for studying complex networks. Although many community detection algorithms have been proposed, most of them focus on separated communities, where each node can belong to only one community. However, in many real-world networks, communities are often overlapped with each other. Developing overlapping community detection algorithms thus becomes necessary. Along this avenue, this paper proposes a maximal clique based multiobjective evolutionary algorithm (MOEA) for overlapping community detection. In this algorithm, a new representation scheme based on the introduced maximal-clique graph is presented. Since the maximal-clique graph is defined by using a set of maximal cliques of original graph as nodes and two maximal cliques are allowed to share the same nodes of the original graph, overlap is an intrinsic property of the maximal-clique graph. Attributing to this property, the new representation scheme allows MOEAs to handle the overlapping community detection problem in a way similar to that of the separated community detection, such that the optimization problems are simplified. As a result, the proposed algorithm could detect overlapping community structure with higher partition accuracy and lower computational cost when compared with the existing ones. The experiments on both synthetic and real-world networks validate the effectiveness and efficiency of the proposed algorithm.","Decoding,
Optimization,
Partitioning algorithms,
Algorithm design and analysis,
Evolutionary computation,
Complex networks,
Detection algorithms"
Data-Mining Model Based Intelligent Differential Microgrid Protection Scheme,"This paper presents a data-mining-based intelligent differential protection scheme for the microgrid. The proposed scheme preprocesses the faulted current and voltage signals using discrete Fourier transform and estimates the most affected sensitive features at both ends of the respective feeder. Furthermore, differential features are computed from the corresponding features at both ends of the feeder and are used to build the decision tree-based data-mining model for registering the final relaying decision. The proposed scheme is extensively validated for fault situations in the standard IEC microgrid model with wide variations in operating parameters for radial and mesh topology in grid-connected and islanded modes of operation. The extensive test results indicate that the proposed intelligent differential relaying scheme can be highly reliable in providing an effective protection measure for safe and secured microgrid operation.","Microgrids,
Fault currents,
Relays,
Topology,
Circuit faults,
Reliability,
Feature extraction"
Diversity Assessment in Many-Objective Optimization,"Maintaining diversity is one important aim of multiobjective optimization. However, diversity for manyobjective optimization problems is less straightforward to define than for multiobjective optimization problems. Inspired by measures for biodiversity, we propose a new diversity metric for many-objective optimization, which is an accumulation of the dissimilarity in the population, where an Lp-norm-based (p<;1) distance is adopted to measure the dissimilarity of solutions. Empirical results demonstrate our proposed metric can more accurately assess the diversity of solutions in various situations. We compare the diversity of the solutions obtained by four popular many-objective evolutionary algorithms using the proposed diversity metric on a large number of benchmark problems with two to ten objectives. The behaviors of different diversity maintenance methodologies in those algorithms are discussed in depth based on the experimental results. Finally, we show that the proposed diversity measure can also be employed for enhancing diversity maintenance or reference set generation in many-objective optimization.","Measurement,
Optimization,
Convergence,
Evolutionary computation,
Maintenance engineering,
Computer science,
Entropy"
Linear Optimal Estimation for Discrete-Time Measurement Delay Systems With Multichannel Multiplicative Noise,"This brief investigates the estimation problem for multiplicative noise systems with measurement delay. Multiplicative noise is usually assumed to be a scalar in existing literature works. We consider multichannel multiplicative noise represented by a diagonal matrix in this brief. First, based on the reorganized innovation approach, the finite-horizon filter is derived in terms of two Riccati difference equations of the same dimension as that of the given system and one Lyapunov difference equation. Then, a sufficient condition for the existence of the steady filter is presented. Finally, we provide a numerical example to demonstrate the efficiency of the proposed approach.","Mathematical model,
Estimation,
Noise measurement,
Delays,
Technological innovation,
Difference equations,
Riccati equations"
Temporal Task Scheduling With Constrained Service Delay for Profit Maximization in Hybrid Clouds,"As cloud computing is becoming growingly popular, consumers' tasks around the world arrive in cloud data centers. A private cloud provider aims to achieve profit maximization by intelligently scheduling tasks while guaranteeing the service delay bound of delay-tolerant tasks. However, the aperiodicity of arrival tasks brings a challenging problem of how to dynamically schedule all arrival tasks given the fact that the capacity of a private cloud provider is limited. Previous works usually provide an admission control to intelligently refuse some of arrival tasks. Nevertheless, this will decrease the throughput of a private cloud, and cause revenue loss. This paper studies the problem of how to maximize the profit of a private cloud in hybrid clouds while guaranteeing the service delay bound of delay-tolerant tasks. We propose a profit maximization algorithm (PMA) to discover the temporal variation of prices in hybrid clouds. The temporal task scheduling provided by PMA can dynamically schedule all arrival tasks to execute in private and public clouds. The sub problem in each iteration of PMA is solved by the proposed hybrid heuristic optimization algorithm, simulated annealing particle swarm optimization (SAPSO). Besides, SAPSO is compared with existing baseline algorithms. Extensive simulation experiments demonstrate that the proposed method can greatly increase the throughput and the profit of a private cloud while guaranteeing the service delay bound.","Cloud computing,
Delays,
Job shop scheduling,
Heuristic algorithms,
Computer architecture,
Processor scheduling"
Moving Real Exergaming Engines on the Web: The webFitForAll Case Study in an Active and Healthy Ageing Living Lab Environment,"Exergames have been the subject of research and technology innovations for a number of years. Different devices and technologies have been utilized to train the body and the mind of senior people or different patient groups. In the past, we presented FitForAll, the protocol efficacy of which was proven through widely taken (controlled) pilots with more than 116 seniors for a period of two months. The current piece of work expands this and presents the first truly web exergaming platform, which is solely based on HTML5 and JavaScript without any browser plugin requirements. The adopted architecture (controller application communication framework) combines a unified solution for input devices such as MS Kinect and Wii Balance Board which may seamlessly be exploited through standard physical exercise protocols (American College of Sports Medicine guidelines) and accommodate high detail logging; this allows for proper pilot testing and usability evaluations in ecologically valid Living Lab environments. The latter type of setups is also used herein for evaluating the web application with more than a dozen of real elderly users following quantitative approaches.",
Velocity-Aware Handover Management in Two-Tier Cellular Networks,"While network densification is considered an important solution to cater the ever-increasing capacity demand, its effect on the handover (HO) rate is overlooked. In dense 5G networks, HO delays may neutralize or even negate the gains offered by network densification. Hence, user mobility imposes a nontrivial challenge to harvest capacity gains via network densification. In this paper, we propose a velocity-aware HO management scheme for two-tier downlink cellular network to mitigate the HO effect on the foreseen densification throughput gains. The proposed HO scheme sacrifices the best base station (BS) connectivity, by skipping HO to some BSs along the user trajectory, to maintain longer connection durations and reduce HO rates. Furthermore, the proposed scheme enables cooperative BS service and strongest interference cancellation to compensate for skipping the best connectivity. To this end, we consider different HO skipping scenarios and develop a velocity-aware mathematical model, via stochastic geometry, to quantify the performance of the proposed HO schemes in terms of the coverage probability and user throughput. The results highlight the HO rate problem in dense cellular environments and show the importance of the proposed HO schemes. Finally, the value of BS cooperation along with handover skipping is quantified for different user mobility profiles.","Cellular networks,
Handover,
Signal to noise ratio,
Interference,
Throughput,
Trajectory"
Capacity-Enhancing Full-Duplex Relay Networks based on Power-Splitting (PS-)SWIPT,"In this paper, we investigate the application of simultaneous wireless information and power transfer (SWIPT) in a full-duplex relay network, where the relay node is wirelessly powered by harvesting a portion of the received signal power from the source node. Different from existing work that has employed time-switching-SWIPT, we propose to use power-splitting-SWIPT. As a result, our proposed approach gives rise to a truly full-duplex relay network, where the information reception and transmission take place simultaneously at the relay node all the time. This more thorough exploitation of the full-duplex feature consequently leads to a significant capacity improvement, compared with existing alternatives in the literature.",
Low-Complexity Downlink User Selection for Massive MIMO Systems,"In this paper, we propose a pair of low-complexity user selection schemes with zero-forcing precoding for multiuser massive multiple-input-multiple-output downlink systems, in which the base station is equipped with a large-scale antenna array. First, we derive approximations of the ergodic sum rates of the systems invoking the conventional random user selection (RUS) and the location-dependent user selection (LUS). Then, the optimal number of simultaneously served user equipments (UEs),i.e., K*, is investigated to maximize the sum rate approximations. Upon exploiting K*, we develop two user selection schemes, namely, K*-RUS and K*-LUS, where K* UEs are selected either randomly or based on their locations. Both the proposed schemes are independent of the instantaneous channel state information of small-scale fading, therefore enjoying the same extremely low computational complexity as that of the conventional RUS scheme. Moreover, both of our proposed schemes achieve significant sum rate improvement over the conventional RUS. In addition, it is worth noting that, like the conventional RUS, the K*-RUS achieves good fairness among UEs.","MIMO,
Downlink,
Channel estimation,
Data communication,
Approximation methods,
Coherence,
Computational complexity"
Probabilistic Small-Cell Caching: Performance Analysis and Optimization,"Small-cell caching utilizes the embedded storage of small-cell base stations (SBSs) to store popular contents for the sake of reducing duplicated content transmissions in networks and for offloading the data traffic from macrocell base stations to SBSs. In this paper, we study a probabilistic small-cell caching strategy, where each SBS caches a subset of contents with a specific caching probability. We consider two kinds of network architectures: 1) The SBSs are always active, which is referred to as the always-on architecture; and 2) the SBSs are activated on demand by mobile users (MUs), which is referred to as the dynamic on-off architecture. We focus our attention on the probability that MUs can successfully download content from the storage of SBSs. First, we derive theoretical results of this successful download probability (SDP) using stochastic geometry theory. Then, we investigate the impact of the SBS parameters, such as the transmission power and deployment intensity on the SDP. Furthermore, we optimize the caching probabilities by maximizing the SDP based on our stochastic geometry analysis. The intrinsic amalgamation of optimization theory and stochastic geometry based analysis leads to our optimal caching strategy, characterized by the resultant closed-form expressions. Our results show that in the always-on architecture, the optimal caching probabilities solely depend on the content request probabilities, while in the dynamic on-off architecture, they also relate to the MU-to-SBS intensity ratio. Interestingly, in both architectures, the optimal caching probabilities are linear functions of the square root of the content request probabilities. Monte-Carlo simulations validate our theoretical analysis and show that the proposed schemes relying on the optimal caching probabilities are capable of achieving substantial SDP improvement, compared with the benchmark schemes.","Network architecture,
Australia,
Probabilistic logic,
Computer architecture,
Electronic mail,
Vehicle dynamics,
Geometry"
Charging and Discharging of Plug-In Electric Vehicles (PEVs) in Vehicle-to-Grid (V2G) Systems: A Cyber Insurance-Based Model,"In addition to being environment friendly, vehicle-to-grid (V2G) systems can help the plug-in electric vehicle (PEV) users in reducing their energy costs and can also help stabilizing energy demand in the power grid. In V2G systems, since the PEV users need to obtain system information (e.g., locations of charging/discharging stations, current load, and supply of the power grid) to achieve the best charging and discharging performance, data communication plays a crucial role. However, since the PEV users are highly mobile, information from V2G systems is not always available for many reasons, e.g., wireless link failures and cyber attacks. Therefore, in this paper, we introduce a novel concept using cyber insurance to “transfer” cyber risks, e.g., unavailable information, of a PEV user to a third party, e.g., a cyber-insurance company. Under the insurance coverage, even without information about V2G systems, a PEV user is always guaranteed the best price for charging/discharging. In particular, we formulate the optimal energy cost problem for the PEV user by adopting a Markov decision process framework. We then propose a learning algorithm to help the PEV user make optimal decisions, e.g., to charge or discharge and to buy or not to buy insurance, in an online fashion. Through simulations, we show that cyber insurance is an efficient solution not only in dealing with cyber risks, but also in maximizing revenue for the PEV user.","Batteries,
Markov processes,
Power grids,
Electric vehicles,
Generators,
Charging stations,
Discharges (electric)"
A Collective Neurodynamic Approach to Distributed Constrained Optimization,"This paper presents a collective neurodynamic approach with multiple interconnected recurrent neural networks (RNNs) for distributed constrained optimization. The objective function of the distributed optimization problems to be solved is a sum of local convex objective functions, which may be nonsmooth. Subject to its local constraints, each local objective function is minimized individually by using an RNN, with consensus among others. In contrast to existing continuous-time distributed optimization methods, the proposed collective neurodynamic approach is capable of solving more general distributed optimization problems. Simulation results on three numerical examples are discussed to substantiate the effectiveness and characteristics of the proposed approach. In addition, an application to the optimal placement problem is delineated to demonstrate the viability of the approach.",
A Unifying Energy-Based Approach to Stability of Power Grids With Market Dynamics,"In this paper, a unifying energy-based approach is provided to the modeling and stability analysis of power systems coupled with market dynamics. We consider a standard model of the power network with a third-order model for the synchronous generators involving voltage dynamics. By applying the primal-dual gradient method to a social welfare optimization, a distributed dynamic pricing algorithm is obtained, which can be naturally formulated in port-Hamiltonian form. By interconnection with the physical model a closed-loop port-Hamiltonian system is obtained, whose properties are exploited to prove asymptotic stability to the set of optimal points. This result is extended to the case that also general nodal power constraints are included into the social welfare problem. Additionally, the case of line congestion and power transmission costs in acyclic networks is covered. Finally, a dynamic pricing algorithm is proposed that does not require knowledge about the power supply and demand.",
"Fast, Ad Hoc Query Evaluations over Multidimensional Geospatial Datasets","Networked observational devices and remote sensing equipment continue to proliferate and contribute to the accumulation of extreme-scale datasets. Both the rate and resolution of the readings produced by these devices have grown over time, exacerbating the issues surrounding their storage and management. In many cases, the sheer scale of the information being maintained makes timely analysis infeasible due to the computational workloads required to process the data. While distributed solutions provide a scalable way to cope with data volumes, the communication and latency involved when inspecting large portions of an overall dataset limit applications that require frequent or rapid responses to incoming queries. This study investigates the challenges associated with providing approximate or exploratory answers to distributed queries. In many situations, this requires striking a balance between response times and error rates to produce meaningful results. To enable these use cases, we outline several expressive query constructs and describe their implementation; rather than relying on summary tables or pre-computed samples, our solution involves a coarse-grained global index that maintains statistics and models the relationships across dimensions in the dataset. To illustrate the benefits of these techniques, we include performance benchmarks on a real-world dataset in a production environment.","Query processing,
Accuracy,
Distributed databases,
Indexes,
Data structures,
Geospatial analysis,
Temperature measurement"
Nonsmooth Feedback Control of Time-Delay Nonlinear Systems: A Dynamic Gain Based Approach,"This technical note addresses the problem of global control for a class of time-delay nonlinear systems. Under a smoothness condition on the system nonlinearities, a delay-independent, non-smooth dynamic state compensator is constructed by developing a dynamic gain based design method. With the help of appropriate Lyapunov-Krasovskii functionals, it is shown that all the states of the time-delay nonlinear system can be regulated to the origin while maintaining boundedness of the closed-loop system. A benchmark example is given to illustrate the effectiveness of the proposed non-smooth feedback controller.","State feedback,
Delays,
Nonlinear dynamical systems,
Closed loop systems,
Adaptive control,
Design methodology"
Interference-Aware Energy Efficiency Maximization in 5G Ultra-Dense Networks,"Ultra-dense networks can further improve the spectrum efficiency (SE) and the energy efficiency (EE). However, the interference avoidance and the green design are becoming more complex due to the intrinsic densification and scalability. It is known that the much denser small cells are deployed, the more cooperation opportunities exist among them. In this paper, we characterize the cooperative behaviors in the Nash bargaining cooperative game-theoretic framework, where we maximize the EE performance with a certain sacrifice of SE performance. We first analyze the relationship between the EE and the SE, based on which we formulate the Nash-product EE maximization problem. We achieve the closed-form sub-optimal SE equilibria to maximize the EE performance with and without the minimum SE constraints. We finally propose a CE2MG algorithm, and numerical results verify the improved EE and fairness of the presented CE2MG algorithm compared with the non-cooperative scheme.","Interference,
Games,
Optimization,
Downlink,
5G mobile communication,
Resource management"
A Fault Tolerance Technique for Combinational Circuits Based on Selective-Transistor Redundancy,"With fabrication technology reaching nanolevels, systems are becoming more prone to manufacturing defects with higher susceptibility to soft errors. This paper is focused on designing combinational circuits for soft error tolerance with minimal area overhead. The idea is based on analyzing random pattern testability of faults in a circuit and protecting sensitive transistors, whose soft error detection probability is relatively high, until desired circuit reliability is achieved or a given area overhead constraint is met. Transistors are protected based on duplicating and sizing a subset of transistors necessary for providing the protection. In addition to that, a novel gate-level reliability evaluation technique is proposed that provides similar results to reliability evaluation at the transistor level (using SPICE) with the orders of magnitude reduction in CPU time. LGSynth'91 benchmark circuits are used to evaluate the proposed algorithm. Simulation results show that the proposed algorithm achieves better reliability than other transistor sizing-based techniques and the triple modular redundancy technique with significantly lower area overhead for 130-nm process technology at a ground level.","Logic gates,
Redundancy,
MOSFET,
Inverters,
Integrated circuit reliability"
Towards Generalized FRI Sampling With an Application to Source Resolution in Radioastronomy,"It is a classic problem to estimate continuous-time sparse signals, like point sources in a direction-of-arrival problem, or pulses in a time-of-flight measurement. The earliest occurrence is the estimation of sinusoids in time series using Prony's method. This is at the root of a substantial line of work on high resolution spectral estimation. The estimation of continuous-time sparse signals from discrete-time samples is the goal of the sampling theory for finite rate of innovation (FRI) signals. Both spectral estimation and FRI sampling usually assume uniform sampling. But not all measurements are obtained uniformly, as exemplified by a concrete radioastronomy problem we set out to solve. Thus, we develop the theory and algorithm to reconstruct sparse signals, typically sum of sinusoids, from nonuniform samples. We achieve this by identifying a linear transformation that relates the unknown uniform samples of sinusoids to the given measurements. These uniform samples are known to satisfy the annihilation equations. A valid solution is then obtained by solving a constrained minimization such that the reconstructed signal is consistent with the given measurements and satisfies the annihilation constraint. Thanks to this new approach, we unify a variety of FRI-based methods. We demonstrate the versatility and robustness of the proposed approach with five FRI reconstruction problems, namely Dirac reconstructions with irregular time or Fourier domain samples, FRI curve reconstructions, Dirac reconstructions on the sphere, and point source reconstructions in radioastronomy. The proposed algorithm improves substantially over state-of-the-art methods and is able to reconstruct point sources accurately from irregularly sampled Fourier measurements under severe noise conditions.","Image reconstruction,
Signal processing algorithms,
Estimation,
Technological innovation,
Robustness,
Fourier transforms,
Noise measurement"
Fusing Meter-Resolution 4-D InSAR Point Clouds and Optical Images for Semantic Urban Infrastructure Monitoring,"Using synthetic aperture radar (SAR) interferometry to monitor long-term millimeter-level deformation of urban infrastructures, such as individual buildings and bridges, is an emerging and important field in remote sensing. In the state-of-the-art methods, deformation parameters are retrieved and monitored on a pixel basis solely in the SAR image domain. However, the inevitable side-looking imaging geometry of SAR results in undesired occlusion and layover in urban area, rendering the current method less competent for a semantic-level monitoring of different urban infrastructures. This paper presents a framework of a semantic-level deformation monitoring by linking the precise deformation estimates of SAR interferometry and the semantic classification labels of optical images via a 3-D geometric fusion and semantic texturing. The proposed approach provides the first “SARptical” point cloud of an urban area, which is the SAR tomography point cloud textured with attributes from optical images. This opens a new perspective of InSAR deformation monitoring. Interesting examples on bridge and railway monitoring are demonstrated.","Optical imaging,
Optical scattering,
Synthetic aperture radar,
Three-dimensional displays,
Optical sensors,
Adaptive optics,
Optical interferometry"
Study on Self-Tuning Tyre Friction Control for Developing Main-Servo Loop Integrated Chassis Control System,"The inherent flexibility of hierarchical structure scheme with main-servo loop control structure is proposed to the problem of integrated chassis control system for the vehicle. It includes both main loop, which calculates and allocates the aim force using the optimal robust control algorithm and servo loop control systems, which track and achieve the target force using the onboard independent brake actuators. In fact, for the brake actuator, the aim friction is obtained by tracking the corresponding slip ratio of target force. For the coefficient of tire-road friction varying with different road surface, to get the nonlinear time-varying target slip ratio, the most famous quasi-static magic formula is proposed to estimate and predict real-time coefficient of different road surface and the constrained hybrid genetic algorithm (GA) is used to identify the key parameters of the magic formula on-line. Then, a self-tuning longitudinal slip ratio controller (LSC) based on the nonsingular and fast terminal sliding mode (NFTSM) control method is designed to improve the tracking accuracy and response speed of the actuators. At last, the proposed integrated chassis control strategies and the self-tuning control strategies are verified by computer simulations.","Friction,
Force,
Tires,
Brakes,
Genetic algorithms,
Vehicle dynamics"
A Comprehensive Study on Cross-View Gait Based Human Identification with Deep CNNs,"This paper studies an approach to gait based human identification via similarity learning by deep convolutional neural networks (CNNs). With a pretty small group of labeled multi-view human walking videos, we can train deep networks to recognize the most discriminative changes of gait patterns which suggest the change of human identity. To the best of our knowledge, this is the first work based on deep CNNs for gait recognition in the literature. Here, we provide an extensive empirical evaluation in terms of various scenarios, namely, cross-view and cross-walking-condition, with different preprocessing approaches and network architectures. The method is first evaluated on the challenging CASIA-B dataset in terms of cross-view gait recognition. Experimental results show that it outperforms the previous state-of-the-art methods by a significant margin. In particular, our method shows advantages when the cross-view angle is large, i.e., no less than 36 degree. And the average recognition rate can reach 94 percent, much better than the previous best result (less than 65 percent). The method is further evaluated on the OU-ISIR gait dataset to test its generalization ability to larger data. OU-ISIR is currently the largest dataset available in the literature for gait recognition, with 4,007 subjects. On this dataset, the average accuracy of our method under identical view conditions is above 98 percent, and the one for cross-view scenarios is above 91 percent. Finally, the method also performs the best on the USF gait dataset, whose gait sequences are imaged in a real outdoor scene. These results show great potential of this method for practical applications.","Gait recognition,
Videos,
Probes,
Face,
Legged locomotion,
Three-dimensional displays,
Feature extraction"
Hybrid CNN and Dictionary-Based Models for Scene Recognition and Domain Adaptation,"Convolutional neural network (CNN) has achieved the state-of-the-art performance in many different visual tasks. Learned from a large-scale training data set, CNN features are much more discriminative and accurate than the handcrafted features. Moreover, CNN features are also transferable among different domains. On the other hand, traditional dictionary-based features (such as BoW and spatial pyramid matching) contain much more local discriminative and structural information, which is implicitly embedded in the images. To further improve the performance, in this paper, we propose to combine CNN with dictionary-based models for scene recognition and visual domain adaptation (DA). Specifically, based on the well-tuned CNN models (e.g., AlexNet and VGG Net), two dictionary-based representations are further constructed, namely, mid-level local representation (MLR) and convolutional Fisher vector (CFV) representation. In MLR, an efficient two-stage clustering method, i.e., weighted spatial and feature space spectral clustering on the parts of a single image followed by clustering all representative parts of all images, is used to generate a class-mixture or a class-specific part dictionary. After that, the part dictionary is used to operate with the multiscale image inputs for generating mid-level representation. In CFV, a multiscale and scale-proportional Gaussian mixture model training strategy is utilized to generate Fisher vectors based on the last convolutional layer of CNN. By integrating the complementary information of MLR, CFV, and the CNN features of the fully connected layer, the state-of-the-art performance can be achieved on scene recognition and DA problems. An interested finding is that our proposed hybrid representation (from VGG net trained on ImageNet) is also complementary to GoogLeNet and/or VGG-11 (trained on Place205) greatly.",
Unsupervised Metric Fusion Over Multiview Data by Graph Random Walk-Based Cross-View Diffusion,"Learning an ideal metric is crucial to many tasks in computer vision. Diverse feature representations may combat this problem from different aspects; as visual data objects described by multiple features can be decomposed into multiple views, thus often provide complementary information. In this paper, we propose a cross-view fusion algorithm that leads to a similarity metric for multiview data by systematically fusing multiple similarity measures. Unlike existing paradigms, we focus on learning distance measure by exploiting a graph structure of data samples, where an input similarity matrix can be improved through a propagation of graph random walk. In particular, we construct multiple graphs with each one corresponding to an individual view, and a cross-view fusion approach based on graph random walk is presented to derive an optimal distance measure by fusing multiple metrics. Our method is scalable to a large amount of data by enforcing sparsity through an anchor graph representation. To adaptively control the effects of different views, we dynamically learn view-specific coefficients, which are leveraged into graph random walk to balance multiviews. However, such a strategy may lead to an over-smooth similarity metric where affinities between dissimilar samples may be enlarged by excessively conducting cross-view fusion. Thus, we figure out a heuristic approach to controlling the iteration number in the fusion process in order to avoid over smoothness. Extensive experiments conducted on real-world data sets validate the effectiveness and efficiency of our approach.","Extraterrestrial measurements,
Image color analysis,
Manifolds,
Scalability,
Learning systems,
Visualization"
Adaptive Influence Maximization in Dynamic Social Networks,"For the purpose of propagating information and ideas through a social network, a seeding strategy aims to find a small set of seed users that are able to maximize the spread of the influence, which is termed influence maximization problem. Despite a large number of works have studied this problem, the existing seeding strategies are limited to the models that cannot fully capture the characteristics of real-world social networks. In fact, due to high-speed data transmission and large population of participants, the diffusion processes in real-world social networks have many aspects of uncertainness. As shown in the experiments, when taking such uncertainness into account, the state-of-the-art seeding strategies are pessimistic as they fail to trace the influence diffusion. In this paper, we study the strategies that select seed users in an adaptive manner. We first formally model the dynamic independent Cascade model and introduce the concept of adaptive seeding strategy. Then, based on the proposed model, we show that a simple greedy adaptive seeding strategy finds an effective solution with a provable performance guarantee. Besides the greedy algorithm, an efficient heuristic algorithm is provided for better scalability. Extensive experiments have been performed on both the real-world networks and synthetic power-law networks. The results herein demonstrate the superiority of the adaptive seeding strategies to other baseline methods.","Social network services,
Integrated circuit modeling,
Biological system modeling,
Adaptation models,
Adaptive systems,
Diffusion processes,
Greedy algorithms"
Preprocessing Design in Pyroelectric Infrared Sensor-Based Human-Tracking System: On Sensor Selection and Calibration,This paper presents an information-gain-based sensor selection approach as well as a sensor sensing probability model-based calibration process for multihuman tracking in distributed binary pyroelectric infrared sensor networks. This research includes three contributions: 1) choose the subset of sensors that can maximize the mutual information between sensors and targets; 2) find the sensor sensing probability model to represent the sensing space for sensor calibration; and 3) provide a factor graph-based message passing scheme for distributed tracking. Our approach can find the solution for sensor selection to optimize the performance of tracking. The sensing probability model is efficiently optimized through the calibration process in order to update the parameters of sensor positions and rotations. An application for mobile calibration and tracking is developed. Simulation and experimental results are provided to validate the proposed framework.,"Target tracking,
Calibration,
Encoding,
Silicon,
Message passing,
Sensor systems"
Waterloo Exploration Database: New Challenges for Image Quality Assessment Models,"The great content diversity of real-world digital images poses a grand challenge to image quality assessment (IQA) models, which are traditionally designed and validated on a handful of commonly used IQA databases with very limited content variation. To test the generalization capability and to facilitate the wide usage of IQA techniques in real-world applications, we establish a large-scale database named the Waterloo Exploration Database, which in its current state contains 4744 pristine natural images and 94 880 distorted images created from them. Instead of collecting the mean opinion score for each image via subjective testing, which is extremely difficult if not impossible, we present three alternative test criteria to evaluate the performance of IQA models, namely, the pristine/distorted image discriminability test, the listwise ranking consistency test, and the pairwise preference consistency test (P-test). We compare 20 well-known IQA models using the proposed criteria, which not only provide a stronger test in a more challenging testing environment for existing models, but also demonstrate the additional benefits of using the proposed database. For example, in the P-test, even for the best performing no-reference IQA model, more than 6 million failure cases against the model are “discovered” automatically out of over 1 billion test pairs. Furthermore, we discuss how the new database may be exploited using innovative approaches in the future, to reveal the weaknesses of existing IQA models, to provide insights on how to improve the models, and to shed light on how the next-generation IQA models may be developed. The database and codes are made publicly available at: https://ece.uwaterloo.ca/~k29ma/exploration/.","Databases,
Distortion,
Testing,
Image coding,
Image quality,
Transform coding,
Digital images"
Cone Beam X-ray Luminescence Computed Tomography Based on Bayesian Method,"X-ray luminescence computed tomography (XLCT), which aims to achieve molecular and functional imaging by X-rays, has recently been proposed as a new imaging modality. Combining the principles of X-ray excitation of luminescence-based probes and optical signal detection, XLCT naturally fuses functional and anatomical images and provides complementary information for a wide range of applications in biomedical research. In order to improve the data acquisition efficiency of previously developed narrow-beam XLCT, a cone beam XLCT (CB-XLCT) mode is adopted here to take advantage of the useful geometric features of cone beam excitation. Practically, a major hurdle in using cone beam X-ray for XLCT is that the inverse problem here is seriously ill-conditioned, hindering us to achieve good image quality. In this paper, we propose a novel Bayesian method to tackle the bottleneck in CB-XLCT reconstruction. The method utilizes a local regularization strategy based on Gaussian Markov random field to mitigate the ill-conditioness of CB-XLCT. An alternating optimization scheme is then used to automatically calculate all the unknown hyperparameters while an iterative coordinate descent algorithm is adopted to reconstruct the image with a voxel-based closed-form solution. Results of numerical simulations and mouse experiments show that the self-adaptive Bayesian method significantly improves the CB-XLCT image quality as compared with conventional methods.",
Mixed-Integer Linear Programming-Based Splitting Strategies for Power System Islanding Operation Considering Network Connectivity,"An efficient splitting strategy is important for the islanding operation of power systems. In this paper, a mixed-integer linear programming (MILP)-based splitting method is proposed. First, the graph theory is employed to transform the splitting problem into a graph partition problem. Then, the graph partition problem is modeled as an MILP optimization problem with consideration to the network connectivity of all subgraphs. The MILP-based splitting strategy can be efficiently computed with existing commercial solvers, and the multiple optimal solutions can be captured with the recursive process. Compared with the splitting methods in the literature, the proposed method is more flexible and efficient, such that the users can select the optimal solution from multiple solutions with different interests and heuristic splitting rules (e.g., with the minimum amount of switched lines). Finally, the effectiveness of the proposed method has been verified with IEEE 30-, 118-, and 300-bus test systems.","Power system stability,
Generators,
Power transmission lines,
Islanding,
Switches,
Optimization"
SINR-Based DoS Attack on Remote State Estimation: A Game-Theoretic Approach,"We consider remote state estimation of cyberphysical systems under signal-to-interference-plus-noise ratio-based denial-of-service attacks. A sensor sends its local estimate to a remote estimator through a wireless network that may suffer interference from an attacker. Both the sensor and the attacker have energy constraints. We first study an associated two-player game when multiple power levels are available. Then, we build a Markov game framework to model the interactive decision-making process based on the current state and information collected from previous time steps. To solve the associated optimality (Bellman) equations, a modified Nash Q-learning algorithm is applied to obtain the optimal solutions. Numerical examples and simulations are provided to demonstrate our results.","Computer crime,
Signal to noise ratio,
Interference,
State estimation,
Markov processes,
Games"
Visualizing High-Dimensional Data: Advances in the Past Decade,"Massive simulations and arrays of sensing devices, in combination with increasing computing resources, have generated large, complex, high-dimensional datasets used to study phenomena across numerous fields of study. Visualization plays an important role in exploring such datasets. We provide a comprehensive survey of advances in high-dimensional data visualization that focuses on the past decade. We aim at providing guidance for data practitioners to navigate through a modular view of the recent advances, inspiring the creation of new visualizations along the enriched visualization pipeline, and identifying future opportunities for visualization research.","Data visualization,
Visualization,
Pipelines,
Principal component analysis,
Data models,
Measurement,
Encoding"
Investigation of In Situ SiN as Gate Dielectric and Surface Passivation for GaN MISHEMTs,"In this paper, we present a systematic investigation of metal-organic chemical vapor depositiongrown in situ SiN as the gate dielectric and surface passivation for AlGaN/GaN metal insulator semiconductor high electron mobility transistors (MISHEMTs). The dielectric constant and breakdown field of the in situ SiN were extracted from devices with varied gate dielectric thicknesses. Using frequency-dependent capacitance-voltage and parallel conductance methods, we obtained a low trap density of ~3 x 1012 cm-2 eV-1 at the SiN/AlGaN interface. The MISHEMTs with a source-drain distance of 3 μm show a maximum drain current of 1560 mA/mm and a high on/off current ratio of 109. The device threshold voltage (Vth) stability was assessed by means of both negative and positive gate stress measurements, as well as temperature-dependent ID-VG measurements. We observed a minimal Vth shift of ~0.4 V under both 3000 s gate stress of VGS = 4 V and up to 200 °C thermal stimulation. Furthermore, combining the in situ SiN with plasma-enhanced chemical vapor deposition SiN, we developed a bilayer passivation scheme for effective suppression of current collapse. Employing the high-quality in situ SiN, we have demonstrated large-area GaN MISHEMTs on Si with a gate width of 20 mm, showing a low off-state leakage of 2 μA/mm at 600 V and a low dynamic/static ON-resistance ratio. The device results show great advantages of employing in situ SiN in D-mode GaN MISHEMTs for high-efficiency power switching applications.",
Self-Adjusting Slot Configurations for Homogeneous and Heterogeneous Hadoop Clusters,"The MapReduce framework and its open source implementation Hadoop have become the defacto platform for scalable analysis on large data sets in recent years. One of the primary concerns in Hadoop is how to minimize the completion length (i.e., makespan) of a set of MapReduce jobs. The current Hadoop only allows static slot configuration, i.e., fixed numbers of map slots and reduce slots throughout the lifetime of a cluster. However, we found that such a static configuration may lead to low system resource utilizations as well as long completion length. Motivated by this, we propose simple yet effective schemes which use slot ratio between map and reduce tasks as a tunable knob for reducing the makespan of a given set. By leveraging the workload information of recently completed jobs, our schemes dynamically allocates resources (or slots) to map and reduce tasks. We implemented the presented schemes in Hadoop V0.20.2 and evaluated them with representative MapReduce benchmarks at Amazon EC2. The experimental results demonstrate the effectiveness and robustness of our schemes under both simple workloads and more complex mixed workloads.","Optimized production technology,
Cloud computing,
Clustering algorithms,
Resource management,
Electronic mail,
Job shop scheduling,
Estimation"
IoT-Based Big Data Storage Systems in Cloud Computing: Perspectives and Challenges,"Internet of Things (IoT) related applications have emerged as an important field for both engineers and researchers, reflecting the magnitude and impact of data-related problems to be solved in contemporary business organizations especially in cloud computing. This paper first provides a functional framework that identifies the acquisition, management, processing and mining areas of IoT big data, and several associated technical modules are defined and described in terms of their key characteristics and capabilities. Then current research in IoT application is analyzed, moreover, the challenges and opportunities associated with IoT big data research are identified. We also report a study of critical IoT application publications and research topics based on related academic and industry publications. Finally, some open issues and some typical examples are given under the proposed IoT-related research framework.","Big Data,
cloud computing,
data acquisition,
data mining,
Internet of Things,
storage management"
Estimating the Propagation of Interdependent Cascading Outages With Multi-Type Branching Processes,"In this paper, the multitype branching process is applied to describe the statistics and interdependencies of line outages, the load shed, and isolated buses. The offspring mean matrix of the multitype branching process is estimated by the Expectation Maximization (EM) algorithm and can quantify the extent of outage propagation. The joint distribution of two types of outages is estimated by the multitype branching process via the Lagrange-Good inversion. The proposed model is tested with data generated by the AC OPA cascading simulations on the IEEE 118-bus system. The largest eigenvalues of the offspring mean matrix indicate that the system is closer to criticality when considering the interdependence of different types of outages. Compared with empirically estimating the joint distribution of the total outages, good estimate is obtained by using the multitype branching process with a much smaller number of cascades, thus greatly improving the efficiency. It is shown that the multitype branching process can effectively predict the distribution of the load shed and isolated buses and their conditional largest possible total outages even when there are no data of them.","Data models,
Load modeling,
Power system faults,
Power system protection,
Eigenvalues and eigenfunctions,
Predictive models"
Leveraging Crowdsourcing for Efficient Malicious Users Detection in Large-Scale Social Networks,"The past few years have witnessed the dramatic popularity of large-scale social networks where malicious nodes detection is one of the fundamental problems. Most existing works focus on actively detecting malicious nodes by verifying signal correlation or behavior consistency. It may not work well in large-scale social networks since the number of users is extremely large and the difference between normal users and malicious users is inconspicuous. In this paper, we propose a novel approach that leverages the power of users to perform the detection task. We design incentive mechanisms to encourage the participation of users under two scenarios: 1) full information and 2) partial information. In full information scenario, we design a specific incentive scheme for users according to their preferences, which can provide the desirable detection result and minimize overall cost. In partial information scenario, assuming that we only have statistical information about users, we first transform the incentive mechanism design to an optimization problem, and then design the optimal incentive scheme under different system parameters by solving the optimization problem. We perform extensive simulations to validate the analysis and demonstrate the impact of system factors on the overall cost.","Social network services,
Internet of things,
Correlation,
Crowdsourcing,
Incentive schemes,
Sensors,
Optimization"
"Electrically Small, Broadside Radiating Huygens Source Antenna Augmented With Internal Non-Foster Elements to Increase Its Bandwidth","A broadside radiating, linearly polarized, electrically small Huygens source antenna system that has a large impedance bandwidth is reported. The bandwidth performance is facilitated by embedding non-Foster components into the near-field resonant parasitic elements of this metamaterial-inspired antenna. High-quality and stable radiation performance characteristics are achieved over the entire operational bandwidth. When the ideal non-Foster components are introduced, the simulated impedance bandwidth witnesses approximately a 17-fold enhancement over the passive case. Within this -10-dB bandwidth, its maximum realized gain, radiation efficiency, and front-to-back ratio (FTBR) are, respectively, 4.00 dB, 88%, and 26.95 dB. When the anticipated actual negative impedance convertor circuits are incorporated, the impedance bandwidth still sustains more than a 10-fold enhancement. The peak realized gain, radiation efficiency, and FTBR values are, respectively, 3.74 dB, 80%, and 28.01 dB, which are very comparable to the ideal values.",
A Steady-State and Generational Evolutionary Algorithm for Dynamic Multiobjective Optimization,"This paper presents a new algorithm, called steady-state and generational evolutionary algorithm, which combines the fast and steadily tracking ability of steady-state algorithms and good diversity preservation of generational algorithms, for handling dynamic multiobjective optimization. Unlike most existing approaches for dynamic multiobjective optimization, the proposed algorithm detects environmental changes and responds to them in a steady-state manner. If a change is detected, it reuses a portion of outdated solutions with good distribution and relocates a number of solutions close to the new Pareto front based on the information collected from previous environments and the new environment. This way, the algorithm can quickly adapt to changing environments and thus is expected to provide a good tracking ability. The proposed algorithm is tested on a number of bi- and three-objective benchmark problems with different dynamic characteristics and difficulties. Experimental results show that the proposed algorithm is very competitive for dynamic multiobjective optimization in comparison with state-of-the-art methods.","Sociology,
Statistics,
Heuristic algorithms,
Optimization,
Steady-state,
Optical fibers,
Evolutionary computation"
A Self-Powered and Optimal SSHI Circuit Integrated With an Active Rectifier for Piezoelectric Energy Harvesting,"This paper presents a piezoelectric energy harvesting circuit, which integrates a Synchronized Switch Harvesting on Inductor (SSHI) circuit and an active rectifier. The major design challenge of the SSHI method is flipping the capacitor voltage at optimal times. The proposed SSHI circuit inserts an active diode on each resonant loop, which ensures flipping of the capacitor voltage at optimal times and eliminates the need to tune the switching time. The diodes of the SSHI circuit are also used as a rectifier to further simplify the controller. The key advantage of the proposed circuit is a simple controller, which leads to low power dissipation of the proposed circuit to result in high efficiency. The proposed circuit is self-powered and capable of starting even when the battery is completely drained. The circuit was fabricated in BiCMOS 0.25 μm technology with a die size of 0.98 × 0.76 mm2. Measured results indicate that the proposed circuit increases the amount of power harvested from a piezoelectric cantilever by 2.1 times when compared with a full bridge (FB) rectifier and achieves a power conversion efficiency of 85%. The proposed circuit dissipates about 24 μW while the controller alone only 1.5 μW.","Capacitors,
RLC circuits,
Transducers,
Inductors,
Energy harvesting,
Switching circuits,
Switches"
Value and Policy Iterations in Optimal Control and Adaptive Dynamic Programming,"In this paper, we consider discrete-time infinite horizon problems of optimal control to a terminal set of states. These are the problems that are often taken as the starting point for adaptive dynamic programming. Under very general assumptions, we establish the uniqueness of the solution of Bellman's equation, and we provide convergence results for value and policy iterations.","Convergence,
Optimal control,
Cost function,
Dynamic programming,
Learning systems,
Indexes,
Shortest path problem"
A Resilient Approach to Distributed Filter Design for Time-Varying Systems Under Stochastic Nonlinearities and Sensor Degradation,"This paper is concerned with the distributed filtering problem for a class of discrete time-varying systems with stochastic nonlinearities and sensor degradation over a finite horizon. A two-step distributed filter algorithm is proposed where the sensor nodes collaboratively estimate the states of the plant by exploiting the information from both the local and the neighboring nodes. The goal of this paper is to design the distributed filters over a wireless sensor network subject to given sporadic communication topology. Moreover, a resilient operation is guaranteed to suppress random perturbations on the actually implemented filter gains. An upper bound is first derived for the filtering error covariance by utilizing an inductive method and such an upper bound is subsequently minimized via iteratively solving a quadratic optimization problem. To account for the topological information of the sensor networks, a novel matrix simplification technique is utilized to preserve the sparsity of the gain matrices in accordance with the given topology, and the analytical parameterization is obtained for the gain matrices of the desired suboptimal filter. Furthermore, a sufficient condition is established to guarantee the mean-square boundedness of the estimation errors. Numerical simulation is carried out to verify the effectiveness of the proposed filtering algorithm.","Degradation,
Wireless sensor networks,
Covariance matrices,
Topology,
Estimation,
Algorithm design and analysis,
Signal processing algorithms"
Fast Channel Tracking for Terahertz Beamspace Massive MIMO Systems,"The recent concept of beamspace multiple input multiple output (MIMO) with discrete lens array can utilize beam selection to reduce the number of radio-frequency chains (RF) required in terahertz (THz) massive MIMO systems. However, to achieve the capacity-approaching performance, beam selection requires information on a beamspace channel of large size. This is difficult to obtain since the user mobility usually leads to the fast variation of THz beamspace channels, and the conventional realtime channel estimation schemes involve unaffordable pilot overhead. To solve this problem, in this paper, we propose the a priori aided (PA) channel tracking scheme. Specifically, by considering a practical user motion model, we first excavate a temporal variation law of the physical direction between the base station and each mobile user. Then, based on this law and the special sparse structure of THz beamspace channels, we propose to utilize the obtained beamspace channels in the previous time slots to predict the prior information of the beamspace channel in the following time slot without channel estimation. Finally, aided by the obtained prior information, the time-varying beamspace channels can be tracked with low pilot overhead. Simulation results verify that to achieve the same accuracy, the proposed PA channel tracking scheme requires much lower pilot overhead and signal-to-noise ratio (SNR) than the conventional schemes.",
Improved Modulation Scheme for Loss Balancing of Three-Level Active NPC Converters,"The three-level neutral point-clamped (NPC) converter has attracted much attention in high-power medium-voltage applications, but it is well-known that the NPC topology suffers from unequal power loss distribution among its semiconductor devices. The power loss unbalance problem becomes especially severe when the converter is operating at low fundamental frequencies. To overcome the loss unbalance problem of the NPC converter, the active NPC (ANPC) technique was introduced. However, it is demonstrated in this paper that in many cases, the conventional modulation method for the ANPC converter only marginally relieves the loss unbalance problem. This paper proposes a new modulation scheme (named the adaptive doubled frequency modulation) for the three-level ANPC converter, which significantly improves the power loss and thermal sharing among the semiconductor devices. The basic idea of the proposed scheme is adaptively adjusting the duty cycles of the switching states for every switching cycle, so as to optimize the power loss distribution. Simulation and experimental results verify this new method.",
"Shape Estimation from Shading, Defocus, and Correspondence Using Light-Field Angular Coherence","Light-field cameras are quickly becoming commodity items, with consumer and industrial applications. They capture many nearby views simultaneously using a single image with a micro-lens array, thereby providing a wealth of cues for depth recovery: defocus, correspondence, and shading. In particular, apart from conventional image shading, one can refocus images after acquisition, and shift one's viewpoint within the sub-apertures of the main lens, effectively obtaining multiple views. We present a principled algorithm for dense depth estimation that combines defocus and correspondence metrics. We then extend our analysis to the additional cue of shading, using it to refine fine details in the shape. By exploiting an all-in-focus image, in which pixels are expected to exhibit angular coherence, we define an optimization framework that integrates photo consistency, depth consistency, and shading consistency. We show that combining all three sources of information: defocus, correspondence, and shading, outperforms state-of-the-art light-field depth estimation algorithms in multiple scenarios.","Estimation,
Shape,
Coherence,
Cameras,
Lighting,
Geometry,
Lenses"
On Emerging Family of Elliptic Curves to Secure Internet of Things: ECC Comes of Age,"Lightweight Elliptic Curve Cryptography (ECC) is a critical component for constructing the security system of Internet of Things (IoT). In this paper, we define an emerging family of lightweight elliptic curves to meet the requirements on some resource-constrained devices. We present the design of a scalable, regular, and highly-optimized ECC library for both MICAz and Tmote Sky nodes, which supports both widely-used key exchange and signature schemes. Our parameterized implementation of elliptic curve group arithmetic supports pseudo-Mersenne prime fields at different security levels with two optimized-specific designs: the high-speed version (HS) and the memory-efficient (ME) version. The former design achieves record times for computation of cryptographic schemes at roughly
80∼128
-bit security levels, while the latter implementation only requires half of the code size of the current best implementation. We also describe our efforts to evaluate the energy consumption and harden our library against some basic side-channel attacks, e.g., timing attacks and simple power analysis (SPA) attacks.",
Combating Full-Duplex Active Eavesdropper: A Hierarchical Game Perspective,"Security is an issue of paramount importance, yet is it a significant challenge for wireless communications, which becomes more intricate when facing a full duplex (FD) active eavesdropper capable of performing eavesdropping and jamming simultaneously. In this paper, we investigate the physical layer security issue in the presence of an FD active eavesdropper, who launches jamming attacks to further improve the eavesdropping. The jamming, however, also results in self-interference at the eavesdropper itself. This security problem is formulated within a hierarchical game framework where the eavesdropper acts as the leader and the legitimate user is the follower. In particular, we first investigate the follower's secrecy rate maximization problem and derive the optimal legitimate transmission strategy. Then, the leader's wiretap rate maximization is expressed as a mathematical program with equilibrium constraints (MPEC). Leveraging the concavity of the follower's problem, we transform the MPEC problem into a single-level optimization and obtain the jamming power allocation strategy by applying the primal-dual interior-point method. Moreover, we analyze the situations where only partial channel state information is available at the legitimate user and the corresponding impacts on the game. Finally, we present extensive simulation results to validate our theoretical analysis.",
Learning Discriminative Binary Codes for Large-scale Cross-modal Retrieval,"Hashing based methods have attracted considerable attention for efficient cross-modal retrieval on large-scale multimedia data. The core problem of cross-modal hashing is how to learn compact binary codes that construct the underlying correlations between heterogeneous features from different modalities. A majority of recent approaches aim at learning hash functions to preserve the pairwise similarities defined by given class labels. However, these methods fail to explicitly explore the discriminative property of class labels during hash function learning. In addition, they usually discard the discrete constraints imposed on the to-be-learned binary codes, and compromise to solve a relaxed problem with quantization to obtain the approximate binary solution. Therefore, the binary codes generated by these methods are suboptimal and less discriminative to different classes. To overcome these drawbacks, we propose a novel cross-modal hashing method, termed discrete cross-modal hashing (DCH), which directly learns discriminative binary codes while retaining the discrete constraints. Specifically, DCH learns modality-specific hash functions for generating unified binary codes, and these binary codes are viewed as representative features for discriminative classification with class labels. An effective discrete optimization algorithm is developed for DCH to jointly learn the modality-specific hash function and the unified binary codes. Extensive experiments on three benchmark data sets highlight the superiority of DCH under various cross-modal scenarios and show its state-of-the-art performance.",
Study of Interface Traps in AlGaN/GaN MISHEMTs Using LPCVD SiNx as Gate Dielectric,"Interface trapping is one of the most notorious effects that limit device performance in GaN-based MIS high electron mobility transistors (MISHEMTs). In this paper, we present a comprehensive study on interface traps in AlGaN/GaN MISHEMTs using low pressure chemical vapor deposition SiNx as gate dielectric. We combined the trapping analysis in MIS diodes and actual MISHEMTs to estimate the interface trap state densities (D11) and their distributions in the device, and to investigate their influence on device electrical properties. Two types of interface traps with different emission time constants, designated as “slow” and “fast” traps, were identified and characterized by means of pulse-mode current-voltage measurements and a frequency dependent conductance method. It was found that “fast” traps located in the device access region could be effectively restrained by passivation using plasma enhanced chemical vapor deposition SiNx. However, “slow” traps, no matter whether located beneath the metal gate or in the access region, were less influenced by passivation. Due to the strong interference of traps in the access region, D11 extraction using the conventional conductance method was not accurate for the lateral GaN-based MIS diodes. A modified small-signal equivalent circuit that includes the impedance of traps in the access region is proposed. Proper passivation for the device access region is essential when using the conductance method for GaN-based MIS devices.","Logic gates,
Passivation,
Aluminum gallium nitride,
Wide band gap semiconductors,
Electron traps,
Dielectrics,
Current measurement"
Fast Tracking the Population of Key Tags in Large-Scale Anonymous RFID Systems,"In large-scale radio frequency identification (RFID)-enabled applications, we sometimes only pay attention to a small set of key tags, instead of all. This paper studies the problem of key tag population tracking, which aims at estimating how many key tags in a given set exist in the current RFID system and how many of them are absent. Previous work is slow to solve this problem due to the serious interference replies from a large number of ordinary (i.e., non-key) tags. However, time-efficiency is a crucial metric to the studied key tag tracking problem. In this paper, we propose a singleton slot-based estimator, which is time-efficient, because the RFID reader only needs to observe the status change of expected singleton slots corresponding to key tags instead of the whole time frame. In practice, the ratio of key tags to all current tags is small, because key members are usually rare. As a result, even when the whole time frame is long, the number of expected singleton slots is limited and the running of our protocol is very fast. To obtain good scalability in large-scale RFID systems, we exploit the sampling idea in the estimation process. A rigorous theoretical analysis shows that the proposed protocol can provide guaranteed estimation accuracy to end users. Extensive simulation results demonstrate that our scheme outperforms the prior protocols by significantly reducing the time cost.",
Image Location Inference by Multisaliency Enhancement,"Locations of images have been widely used in many application scenarios for large geotagged image corpora. As to images that are not geographically tagged, we estimate their locations with the help of the large geotagged image set by content-based image retrieval. Bag-of-words image representation has been utilized widely. However, the individual visual word-based image retrieval approach is not effective in expressing the salient relationships of image region. In this paper, we present an image location estimation approach by multisaliency enhancement. We first extract region-of-interests (ROIs) by mean-shift clustering on the visual words and salient map of the image based on which we further determine the importance of the ROI. Then, we describe each ROI by the spatial descriptors of visual words. Finally, region-based visual phrases are generated to further enhance the saliency in image location estimation. Experiments show the effectiveness of our proposed approach.","Visualization,
Estimation,
Image retrieval,
Feature extraction,
Vocabulary,
Three-dimensional displays,
Solid modeling"
Real-Time Model-Based Estimation of SOC and SOH for Energy Storage Systems,"To obtain a full exploitation of battery potential in energy storage applications, an accurate modeling of electrochemical batteries is needed. In real terms, an accurate knowledge of state of charge (SOC) and state of health (SOH) of the battery pack is needed to allow a precise design of the control algorithms for energy storage systems (ESSs). Initially, a review of effective methods for SOC and SOH assessment has been performed with the aim to analyze pros and cons of standard methods. Then, as the tradeoff between accuracy and complexity of the model is the major concern, a novel technique for SOC and SOH estimation has been proposed. It is based on the development of a battery circuit model and on a procedure for setting the model parameters. Such a procedure performs a real-time comparison between measured and calculated values of the battery voltage while a PI-based observer is used to provide the SOC and SOH actual values. This ensures a good accuracy in a wide range of operating conditions. Moreover, a simple start-up identification process is required based on battery data-sheet exploitation. Because of the low computational burden of the whole algorithm, it can be easily implemented in low-cost control units. An experimental comparison between SOC and SOH estimation performed by suggested and standard methods is able to confirm the consistency of the proposed approach.","Batteries,
Integrated circuit modeling,
Observers,
Discharges (electric),
Computational modeling,
Voltage measurement"
On-Manifold Preintegration for Real-Time Visual--Inertial Odometry,"Current approaches for visual-inertial odometry (VIO) are able to attain highly accurate state estimation via nonlinear optimization. However, real-time optimization quickly becomes infeasible as the trajectory grows over time; this problem is further emphasized by the fact that inertial measurements come at high rate, hence, leading to the fast growth of the number of variables in the optimization. In this paper, we address this issue by preintegrating inertial measurements between selected keyframes into single relative motion constraints. Our first contribution is a preintegration theory that properly addresses the manifold structure of the rotation group. We formally discuss the generative measurement model as well as the nature of the rotation noise and derive the expression for the maximum a posteriori state estimator. Our theoretical development enables the computation of all necessary Jacobians for the optimization and a posteriori bias correction in analytic form. The second contribution is to show that the preintegrated inertial measurement unit model can be seamlessly integrated into a visual-inertial pipeline under the unifying framework of factor graphs. This enables the application of incremental-smoothing algorithms and the use of a structureless model for visual measurements, which avoids optimizing over the 3-D points, further accelerating the computation. We perform an extensive evaluation of our monocular VIO pipeline on real and simulated datasets. The results confirm that our modeling effort leads to an accurate state estimation in real time, outperforming state-of-the-art approaches.","Smoothing methods,
Optimization,
Estimation,
Real-time systems,
Manifolds,
Computational modeling,
Jacobian matrices"
Reliable Filter Design for Sensor Networks Using Type-2 Fuzzy Framework,"This paper studies the problem of reliable filter problem for a category of sensor networks in the framework of interval type-2 fuzzy model. In the filter design, the random link failures, which are caused possibly by missing measurements as well as by probabilistic communication failures, are considered to illustrate more realistic dynamical behaviors of sensor networks. In order to tackle the uncertainties existing in systems, interval type-2 (IT2) fuzzy approach is utilized to establish the model, wherein upper and lower membership functions together with weighting coefficients are employed to express the uncertainties. An distributed IT2 fuzzy filter model is constructed to estimate system states. Using the Lyapunov theory, sufficient conditions have been given to ensure that the filtering error system is mean-square asymptotically stable and satisfies the predefined average

∞
performance level. Moreover, the criteria to design the filter parameters are developed through using cone complementary linearization approach. Finally, a practical example is given to validate the proposed method.","Uncertainty,
Symmetric matrices,
Reliability engineering,
Network topology,
Nonlinear systems,
Stochastic processes"
Distributed Secondary Voltage and Frequency Control for Islanded Microgrids With Uncertain Communication Links,"This paper presents a robust distributed secondary control (DSC) scheme for inverter-based microgrids (MGs) in a distribution sparse network with uncertain communication links. By using the iterative learning mechanics, two discrete-time DSC controllers are designed, which enable all the distributed energy resources (DERs) in an MG to achieve the voltage/frequency restoration and active power sharing accuracy, respectively. In special, the secondary control inputs are merely updated at the end of each round of iteration, and thus, each DER only needs to share information with its neighbors intermittently in a low-bandwidth communication manner. This way, the communication costs are greatly reduced, and some sufficient conditions on the system stability and robustness to the uncertainties are also derived by using the tools of Lyapunov stability theory, algebraic graph theory, and matrix inequality theory. The proposed controllers are implemented on local DERs, and thus, no central controller is required. Moreover, the desired control objective can also be guaranteed even if all DERs are subject to internal uncertainties and external noises including initial voltage and/or frequency resetting errors and measurement disturbances, which then improves the system reliability and robustness. The effectiveness of the proposed DSC scheme is verified by the simulation of an islanded MG in MATLAB/SimPowerSystems.","Voltage control,
Density estimation robust algorithm,
Frequency control,
Voltage measurement,
Stability analysis,
Informatics,
Frequency measurement"
Hyperspectral Image Superresolution by Transfer Learning,"Hyperspectral image superresolution is a highly attractive topic in computer vision and has attracted many researchers' attention. However, nearly all the existing methods assume that multiple observations of the same scene are required with the observed low-resolution hyperspectral image. This limits the application of superresolution. In this paper, we propose a new framework to enhance the resolution of hyperspectral images by exploiting the knowledge from natural images: The relationship between low/high-resolution images is the same as that between low/high-resolution hyperspectral images. In the proposed framework, the mapping between low- and high-resolution images can be learned by deep convolutional neural network and be transferred to hyperspectral image by borrowing the idea of transfer learning. In addition, to study the spectral characteristic between low- and high-resolution hyperspectral image, collaborative nonnegative matrix factorization (CNMF) is proposed to enforce collaborations between the low- and high-resolution hyperspectral images, which encourages the estimated solution to extract the same endmembers with low-resolution hyperspectral image. The experimental results on ground based and remote sensing data suggest that the proposed method achieves comparable performance without requiring any auxiliary images of the same scene.","Spatial resolution,
Hyperspectral imaging,
Collaboration,
Optical imaging"
Content Caching and Distribution in Smart Grid Enabled Wireless Networks,"To facilitate wireless transmission of multimedia content to mobile users, we propose a content caching and distribution framework for smart grid enabled OFDM networks, where each popular multimedia file is coded and distributively stored in multiple energy harvesting enabled serving nodes (SNs), and the green energy distributively harvested by SNs can be shared with each other through the smart grid. The distributive caching, green energy sharing, and the on-grid energy backup have improved the reliability and performance of the wireless multimedia downloading process. To minimize the total on-grid power consumption of the whole network, while guaranteeing that each user can retrieve the whole content, the user association scheme is jointly designed with consideration of resource allocation, including subchannel assignment, power allocation, and power flow among nodes. Simulation results demonstrate that bringing content, green energy, and SN closer to the end user can notably reduce the on-grid energy consumption.","Smart grids,
Green products,
Resource management,
Power demand,
Wireless networks,
Multimedia communication"
Selective Transfer Machine for Personalized Facial Expression Analysis,"Automatic facial action unit (AU) and expression detection from videos is a long-standing problem. The problem is challenging in part because classifiers must generalize to previously unknown subjects that differ markedly in behavior and facial morphology (e.g., heavy versus delicate brows, smooth versus deeply etched wrinkles) from those on which the classifiers are trained. While some progress has been achieved through improvements in choices of features and classifiers, the challenge occasioned by individual differences among people remains. Person-specific classifiers would be a possible solution but for a paucity of training data. Sufficient training data for person-specific classifiers typically is unavailable. This paper addresses the problem of how to personalize a generic classifier without additional labels from the test subject. We propose a transductive learning method, which we refer to as a Selective Transfer Machine (STM), to personalize a generic classifier by attenuating person-specific mismatches. STM achieves this effect by simultaneously learning a classifier and re-weighting the training samples that are most relevant to the test subject. We compared STM to both generic classifiers and cross-domain learning methods on four benchmarks: CK+ [44], GEMEP-FERA [67], RUFACS [4] and GFT [57]. STM outperformed generic classifiers in all.","Training,
Feature extraction,
Gold,
Face,
Hidden Markov models,
Shape,
Training data"
Joint Power Allocation and Strategy Selection for Half-Duplex Relay System,"Decode and forward (DF) and compress and forward (CF) are two efficient cooperation strategies for relay networks. The combination of the DF and CF strategies is promising to improve the achievable rate of cooperative communication systems. To thoroughly aggregate the advantage of the DF and CF strategies, we put forward a joint power allocation and strategy selection (PASS) scheme for the half-duplex relay channel. The PASS scheme is shown to achieve a higher rate compared with a regular hybrid DF/CF scheme. The rate gain obtained in the static relay channel results from actively adjusting and optimizing the relay power, followed by selecting the better strategy between DF and CF. In particular, when the relay receives and transmits in sequential time slots, we characterize the positive rate improvement area of the PASS scheme analytically and give a near-optimal setting for approaching the best rate performance. The PASS scheme is extended to fading relay channels. We show that the rate increment obtained from the PASS scheme is further magnified by employing an advanced relay power allocation technique over channel states. The corresponding optimal power allocation is established based on the concavity of the rate achieved by the PASS scheme in static relay channel. Numerical results are presented to validate the analysis.",
Neuroevolution in Games: State of the Art and Open Challenges,"This paper surveys research on applying neuroevolution (NE) to games. In neuroevolution, artificial neural networks are trained through evolutionary algorithms, taking inspiration from the way biological brains evolved. We analyze the application of NE in games along five different axes, which are the role NE is chosen to play in a game, the different types of neural networks used, the way these networks are evolved, how the fitness is determined and what type of input the network receives. The paper also highlights important open research challenges in the field.",
Multiobjective Multifactorial Optimization in Evolutionary Multitasking,"In recent decades, the field of multiobjective optimization has attracted considerable interest among evolutionary computation researchers. One of the main features that makes evolutionary methods particularly appealing for multiobjective problems is the implicit parallelism offered by a population, which enables simultaneous convergence toward the entire Pareto front. While a plethora of related algorithms have been proposed till date, a common attribute among them is that they focus on efficiently solving only a single optimization problem at a time. Despite the known power of implicit parallelism, seldom has an attempt been made to multitask, i.e., to solve multiple optimization problems simultaneously. It is contended that the notion of evolutionary multitasking leads to the possibility of automated transfer of information across different optimization exercises that may share underlying similarities, thereby facilitating improved convergence characteristics. In particular, the potential for automated transfer is deemed invaluable from the standpoint of engineering design exercises where manual knowledge adaptation and reuse are routine. Accordingly, in this paper, we present a realization of the evolutionary multitasking paradigm within the domain of multiobjective optimization. The efficacy of the associated evolutionary algorithm is demonstrated on some benchmark test functions as well as on a real-world manufacturing process design problem from the composites industry.","Optimization,
Multitasking,
Sociology,
Statistics,
Linear programming,
Parallel processing,
Evolutionary computation"
Development of an EMG-ACC-Based Upper Limb Rehabilitation Training System,"This paper focuses on the development of an upper limb rehabilitation training system designed for use by children with cerebral palsy (CP). It attempts to meet the requirements of in-home training by taking advantage of the combination of portable accelerometers (ACC) and surface electromyography (SEMG) sensors worn on the upper limb to capture functional movements. In the proposed system, the EMG-ACC acquisition device works essentially as wireless game controller, and three rehabilitation games were designed for improving upper limb motor function under a clinician's guidance. The games were developed on the Android platform based on a physical engine called Box2D. The results of a system performance test demonstrated that the developed games can respond to the upper limb actions within 210 ms. Positive questionnaire feedbacks from twenty CP subjects who participated in the game test verified both the feasibility and usability of the system. Results of a long-term game training conducted with three CP subjects demonstrated that CP patients could improve in their game performance through repetitive training, and persistent training was needed to improve and enhance the rehabilitation effect. According to our experimental results, the novel multi-feedback SEMG-ACC-based user interface improved the users' initiative and performance in rehabilitation training.","Games,
Training,
Accelerometers,
Sensors,
Data acquisition,
Thumb"
Cross-Modal Retrieval With CNN Visual Features: A New Baseline,"Recently, convolutional neural network (CNN) visual features have demonstrated their powerful ability as a universal representation for various recognition tasks. In this paper, cross-modal retrieval with CNN visual features is implemented with several classic methods. Specifically, off-the-shelf CNN visual features are extracted from the CNN model, which is pretrained on ImageNet with more than one million images from 1000 object categories, as a generic image representation to tackle cross-modal retrieval. To further enhance the representational ability of CNN visual features, based on the pretrained CNN model on ImageNet, a fine-tuning step is performed by using the open source Caffe CNN library for each target data set. Besides, we propose a deep semantic matching method to address the cross-modal retrieval problem with respect to samples which are annotated with one or multiple labels. Extensive experiments on five popular publicly available data sets well demonstrate the superiority of CNN visual features for cross-modal retrieval.","Visualization,
Feature extraction,
Semantics,
Data models,
Correlation,
Image recognition,
Search problems"
ROSE: Robustness Strategy for Scale-Free Wireless Sensor Networks,"Due to the recent proliferation of cyber-attacks, improving the robustness of wireless sensor networks (WSNs), so that they can withstand node failures has become a critical issue. Scale-free WSNs are important, because they tolerate random attacks very well; however, they can be vulnerable to malicious attacks, which particularly target certain important nodes. To address this shortcoming, this paper first presents a new modeling strategy to generate scale-free network topologies, which considers the constraints in WSNs, such as the communication range and the threshold on the maximum node degree. Then, ROSE, a novel robustness enhancing algorithm for scale-free WSNs, is proposed. Given a scale-free topology, ROSE exploits the position and degree information of nodes to rearrange the edges to resemble an onion-like structure, which has been proven to be robust against malicious attacks. Meanwhile, ROSE keeps the degree of each node in the topology unchanged such that the resulting topology remains scale-free. The extensive experimental results verify that our new modeling strategy indeed generates scale-free network topologies for WSNs, and ROSE can significantly improve the robustness of the network topologies generated by our modeling strategy. Moreover, we compare ROSE with two existing robustness enhancing algorithms, showing that ROSE outperforms both.",
Group Cooperation With Optimal Resource Allocation in Wireless Powered Communication Networks,"This paper considers a wireless powered communication network (WPCN) with group cooperation, where two communication groups cooperate with each other via wireless power transfer and time sharing to fulfill their expected information delivering and achieve “win-win” collaboration. To explore the system performance limits, we formulate optimization problems to maximize the weighted sum-rate (WSR) and minimize the total consumed power. The time assignment, beamforming vector and power allocation are jointly optimized under available power and quality of service requirement constraints of both the groups. For the WSR-maximization, both fixed and flexible power scenarios are investigated. As all problems are non-convex and have no known solution methods, we solve them by using proper variable substitutions and the semi-definite relaxation. We theoretically prove that our proposed solution method guarantees the global optimum for each problem. Numerical results are presented to show the system performance behaviors, which provide some useful insights for future WPCN design. It shows that in such a group cooperation-aware WPCN, optimal time assignment has the greatest effect on the system performance than other factors.",
Near-Optimal Hybrid Processing for Massive MIMO Systems via Matrix Decomposition,"For practical implementation of massive multiple-input multiple-output (MIMO) systems, the hybrid processing (precoding/combining) structure is promising to reduce the high implementation cost and power consumption rendered by large number of radio frequency (RF) chains of the traditional processing structure. The hybrid processing is realized through low-dimensional digital baseband processing combined with analog RF processing enabled by phase shifters. We propose to design hybrid RF and baseband precoders/combiners for multistream transmission in massive MIMO systems, by directly decomposing the predesigned unconstrained digital precoder/combiner of a large dimension. This approach is fundamental and general in the sense that any conventional full RF chain precoding solution of a MIMO system configuration can be converted to a hybrid processing structure by matrix decomposition. The constant amplitude constraint of analog RF processing results in the matrix decomposition problem nonconvex. Based on an alternate optimization technique, the nonconvex matrix decomposition problem can be decoupled into a series of convex subproblems and effectively solved by restricting the phase increment of each entry in the RF precoder/combiner within a small vicinity of its preceding iterate. A singular value decomposition-based technique is proposed to secure an initial point sufficiently close to the global solution of the original nonconvex problem. Through simulation, the convergence of the alternate optimization for such a matrix decomposition-based hybrid processing (MD-HP) scheme is examined, and the performance of the MD-HP scheme is demonstrated to be near-optimal.",
RFID Estimation With Blocker Tags,"With the increasing popularization of radio frequency identification (RFID) technology in the retail and logistics industry, RFID privacy concern has attracted much attention, because a tag responds to queries from readers no matter they are authorized or not. An effective solution is to use a commercially available blocker tag that behaves as if a set of tags with known blocking IDs are present. However, the use of blocker tags makes the classical RFID estimation problem much more challenging, as some genuine tag IDs are covered by the blocker tag and some are not. In this paper, we propose RFID estimation scheme with blocker tags (REB), the first RFID estimation scheme with the presence of blocker tags. REB uses the framed slotted Aloha protocol specified in the EPC C1G2 standard. For each round of the Aloha protocol, REB first executes the protocol on the genuine tags and the blocker tag, and then virtually executes the protocol on the known blocking IDs using the same Aloha protocol parameters. REB conducts statistical inference from the two sets of responses and estimates the number of genuine tags. Rigorous theoretical analysis of parameter settings is proposed to guarantee the required estimation accuracy, meanwhile minimizing the time cost and energy cost of REB. We also reveal a fundamental tradeoff between the time cost and energy cost of REB, which can be flexibly adjusted by the users according to the practical requirements. Extensive experimental results reveal that REB significantly outperforms the state-of-the-art identification protocols in terms of both time efficiency and energy efficiency.","Protocols,
Radiofrequency identification,
Estimation,
Privacy,
Standards,
IEEE transactions,
Art"
Gaussian Multiple Access via Compute-and-Forward,"Lattice codes used under the compute-and-forward paradigm suggest an alternative strategy for the standard Gaussian multiple-access channel (MAC): the receiver successively decodes the integer linear combinations of the messages until it can invert and recover all messages. In this paper, a multiple-access technique called compute-forward multiple access (CFMA) is proposed and analyzed. For the two-user MAC, it is shown that without time-sharing, the entire capacity region can be attained using CFMA with a single-user decoder as soon as the signal-to-noise ratios are above √1+ 2. A partial analysis is given for more than two users. Finally, the strategy is extended to the so-called dirty MAC, where two interfering signals are known non-causally to the two transmitters in a distributed fashion. Our scheme extends the previously known results and gives new achievable rate regions.","Lattices,
Decoding,
Signal to noise ratio,
Encoding,
Receivers,
Transmitters,
Error probability"
Dynamic IaaS Computing Resource Provisioning Strategy with QoS Constraint,"In an IaaS cloud, virtual machines (VMs), also called instances, may be classified as reserved instances and on-demand instances. The reserved instances having long-term commitments and one-time payment are appropriate for the steady or predictable workloads, while for short-term, spiky or unpredictable workloads, the on-demand instances having flexible hourly payment and no long-term commitments may be more suitable for reducing the cost. In this paper, we consider the economical provisioning of reserved and/or on-demand instances for meeting time-varying computing workload of compute-intensive applications. In order to achieve this, we conceive a strategy for determining the amount of the purchased instances dynamically in order to minimize the total computing cost while keeping quality-of-service (QoS). By mapping QoS as the overload probability, we propose a dynamic instance provisioning strategy based on the large deviation principle, which is capable of calculating the minimum number of instances for the upcoming demands subject to the overload probability below a desired threshold. In addition, a reserved instance provisioning strategy for further reducing the total cost is also proposed by applying the autoregressive (AR) model to calculate the number of reserved instances for the average computation requirements. Finally, the simulations are performed based on real workload traces to show the attainable performance of the proposed instance provisioning strategy for the computing service in an IaaS cloud.","Quality of service,
Cloud computing,
Computational modeling,
Dynamic scheduling,
Heuristic algorithms,
Optimization,
Probability"
Adaptive Interval Type-2 Fuzzy Logic Control for PMSM Drives With a Modified Reference Frame,"In this paper, an adaptive interval type-2 fuzzy logic control scheme is proposed for high-performance permanent magnet synchronous machine drives. This strategy combines the power of type-2 fuzzy logic systems with the adaptive control theory to achieve accurate tracking and robustness to higher uncertainties. Unlike other controllers, the proposed strategy does not require electrical transducers and hence, no explicit currents loop regulation is needed, which yields a simplified control scheme. But, this limits the machine's operation range since it results in a higher energy consumption. Therefore, a modified reference frame is also proposed in this paper to decrease the machine's consumption. To better assess the performance of the new reference frame, comparison against its original counterpart is carried-out under the same conditions. Moreover, the stability of the closed-loop control scheme is guaranteed by a Lyapunov theorem. Simulation and experimental results for numerous situations highlight the effectiveness of the proposed controller in standstill, transient, and steady-state conditions.","Fuzzy logic,
Friction,
Adaptation models,
Fuzzy sets,
Uncertainty,
Mathematical model,
Torque"
Isotropic Riemann Solver for a Nonconformal Discontinuous Galerkin Pseudospectral Time-Domain Algorithm,"We present a discontinuous Galerkin pseudospectral time-domain (DG-PSTD) algorithm to solve elastic-/acoustic-wave propagation problems. The developed DG-PSTD algorithm combines the merits of flexibility from a finite-element method and spectral accuracy and efficiency from a high-order pseudospectral method, while having a flavor closer to a finite-volume method. This numerical approach not only uses structured/unstructured conformal meshes but also handles nonconformal meshes (h-adaptivity) with nonuniform approximation orders (p-adaptivity) in different regions, thus leading to high flexibility and efficiency for heterogeneous multiscale problems. To implement the discontinuous Galerkin algorithm, a concise but more general heterogeneous Riemann solver is provided to effectively and accurately resolve the coupling of multiple subdomains for both elastic-elastic/fluid-fluid and fluid-solid coupling. Finally, numerical results demonstrate the flexibility, high accuracy, and efficiency of our method for elastic-/acoustic-wave simulation.",
An Innovative Straight Resonator Incorporating a Vertical Slot as an Efficient Bio-Chemical Sensor,"A compact and integrated label-free refractometric bio-chemical sensor based on silicon-on-insulator (SOI) is proposed and comprehensively studied at the telecommunication wavelength of λ = 1550 nm. This device incorporated a three-dimensional (3D) Fabry-Perot cavity in the nano-scale regime with maximum footprint area around 470 × 473 nm2. A resonance shift (Δλres) of 5.2 nm is reported for an ultrathin (5 nm) bio-layer sensing. Besides, an improved maximum sensitivity (S = 820 nm/RIU) is also achieved for bulk refractive index change in surroundings. As a chemical sensor, very low detection limit (DL = 6.1 × 10-6 RIU) also can be possible to achieve by this device. All the numerical investigations and optimizations were carried out in frequency domain by a numerically efficient and rigorous full vectorial H-field based 2-D and 3-D finite element methods (FEM). A 3D-FEM code is developed and used to find out the wavelength dependencies of the resonator. Possibility of easy CMOS fabrication and integration opportunities make this structure as a prospective and efficient lab-on-chip device.","Finite element analysis,
Sensitivity,
Silicon,
Sensors,
Optical waveguides,
Optical resonators"
Energy Storage Sizing Taking Into Account Forecast Uncertainties and Receding Horizon Operation,"Energy storage systems (ESS) have the potential to be very beneficial for applications such as reducing the ramping of generators, peak shaving, and balancing not only the variability introduced by renewable energy sources, but also the uncertainty introduced by errors in their forecasts. Optimal usage of storage may result in reduced generation costs and an increased use of renewable energy. However, optimally sizing these devices is a challenging problem. This paper aims to provide the tools to optimally size an ESS under the assumption that it will be operated under a model predictive control scheme and that the forecast of the renewable energy resources include prediction errors. A two-stage stochastic model predictive control is formulated and solved, where the optimal usage of the storage is simultaneously determined along with the optimal generation outputs and size of the storage. Wind forecast errors are taken into account in the optimization problem via probabilistic constraints for which an analytical form is derived. This allows for the stochastic optimization problem to be solved directly, without using sampling-based approaches, and sizing the storage to account not only for a wide range of potential scenarios, but also for a wide range of potential forecast errors. In the proposed formulation, we account for the fact that errors in the forecast affect how the device is operated later in the horizon and that a receding horizon scheme is used in operation to optimally use the available storage.",
Public Cloud Storage-Assisted Mobile Social Video Sharing: A Supermodular Game Approach,"Mobile social video sharing enables mobile users to create ultra-short video clips and instantly share them with social friends, which poses significant pressure to the content distribution infrastructure. In this paper, we propose a public cloud-assisted architecture to tackle this problem. In particular, by motivating mobile users to upload videos to the local public cloud to serve requests, and, therefore, having a permission to access friends' videos stored in the cloud, our method can alleviate the traffic burden to the social service providers, while reducing the service latency of mobile users. First, we present a general framework to model the information diffusion and utility function of each user on the proposed architecture, and formulate the problem as a decentralized social utility maximization game. Second, we show that this problem is a supermodular game and there exists at least one socially aware Nash equilibrium (SNE). We then develop two decentralized algorithms to solve this problem. The first algorithm can find an SNE with less computation complexity, and the second algorithm can find the Pareto-optimal SNE with better performance. Finally, through extensive experiments, we demonstrate that the overall system performance can be significantly improved by exploiting the selflessness among social friends.","Mobile communication,
Cloud computing,
Game theory,
Servers,
Streaming media,
Social network services,
Optimization"
A Survey of Self-Organization Mechanisms in Multiagent Systems,"This paper surveys the literature over the last decades in the field of self-organizing multiagent systems. Self-organization has been extensively studied and applied in multiagent systems and other fields, e.g., sensor networks and grid systems. Self-organization mechanisms in other fields have been thoroughly surveyed. However, there has not been a survey of self-organization mechanisms developed for use in multiagent systems. In this paper, we provide a survey of existing literature on self-organization mechanisms in multiagent systems. We also highlight the future work on key research issues in multiagent systems. This paper can serve as a guide and a starting point for anyone who will conduct research on self-organization in multiagent systems. Also, this paper complements existing survey studies on self-organization in multiagent systems.","Multi-agent systems,
Protocols,
Software,
Thermostats,
Heating,
Temperature sensors,
Organizations"
Solving NP-Hard Problems with Physarum-Based Ant Colony System,"NP-hard problems exist in many real world applications. Ant colony optimization (ACO) algorithms can provide approximate solutions for those NP-hard problems, but the performance of ACO algorithms is significantly reduced due to premature convergence and weak robustness, etc. With these observations in mind, this paper proposes a Physarum-based pheromone matrix optimization strategy in ant colony system (ACS) for solving NP-hard problems such as traveling salesman problem (TSP) and 0/1 knapsack problem (0/1 KP). In the Physarum-inspired mathematical model, one of the unique characteristics is that critical tubes can be reserved in the process of network evolution. The optimized updating strategy employs the unique feature and accelerates the positive feedback process in ACS, which contributes to the quick convergence of the optimal solution. Some experiments were conducted using both benchmark and real datasets. The experimental results show that the optimized ACS outperforms other meta-heuristic algorithms in accuracy and robustness for solving TSPs. Meanwhile, the convergence rate and robustness for solving 0/1 KPs are better than those of classical ACS.",
LazyPIM: An Efficient Cache Coherence Mechanism for Processing-in-Memory,"Processing-in-memory (PIM) architectures cannot use traditional approaches to cache coherence due to the high off-chip traffic consumed by coherence messages. We propose LazyPIM, a new hardware cache coherence mechanism designed specifically for PIM. LazyPIM uses a combination of speculative cache coherence and compressed coherence signatures to greatly reduce the overhead of keeping PIM coherent with the processor. We find that LazyPIM improves average performance across a range of PIM applications by 49.1 percent over the best prior approach, coming within 5.5 percent of an ideal PIM mechanism.","Coherence,
Kernel,
Message systems,
Computer architecture,
Bandwidth,
Random access memory,
Programming"
Evolutionary Dynamic Multiobjective Optimization: Benchmarks and Algorithm Comparisons,"Dynamic multiobjective optimization (DMO) has received growing research interest in recent years since many real-world optimization problems appear to not only have multiple objectives that conflict with each other but also change over time. The time-varying characteristics of these DMO problems (DMOPs) pose new challenges to evolutionary algorithms. Considering the importance of a representative and diverse set of benchmark functions for DMO, in this paper, we propose a new benchmark generator that is able to tune a number of challenging characteristics, including mixed Pareto-optimal front (convexity-concavity), nonmonotonic and time-varying variable-linkages, mixed types of changes, and randomness in type change, which have rarely or not been considered or tested in the literature. A test suite of ten instances with different dynamic features is produced from the generator in this paper. Additionally, a few new performance measures are proposed to evaluate algorithms for DMOPs with different characteristics. Six representative multiobjective evolutionary algorithms from the literature are investigated based on the proposed DMO test suite and performance measures. The experimental results facilitate a better understanding of strengths and weaknesses of these compared algorithms for DMOPs.","Optical fibers,
Benchmark testing,
Generators,
Shape,
Optimization,
Heuristic algorithms,
Approximation algorithms"
PLTD: Patch-Based Low-Rank Tensor Decomposition for Hyperspectral Images,"Recent years has witnessed growing interest in hyperspectral image (HSI) processing. In practice, however, HSIs always suffer from huge data size and mass of redundant information, which hinder their application in many cases. HSI compression is a straightforward way of relieving these problems. However, most of the conventional image encoding algorithms mainly focus on the spatial dimensions, and they need not consider the redundancy in the spectral dimension. In this paper, we propose a novel HSI compression and reconstruction algorithm via patch-based low-rank tensor decomposition (PLTD). Instead of processing the HSI separately by spectral channel or by pixel, we represent each local patch of the HSI as a third-order tensor. Then, the similar tensor patches are grouped by clustering to form a fourth-order tensor per cluster. Since the grouped tensor is assumed to be redundant, each cluster can be approximately decomposed to a coefficient tensor and three dictionary matrices, which leads to a low-rank tensor representation of both the spatial and spectral modes. The reconstructed HSI can then be simply obtained by the product of the coefficient tensor and dictionary matrices per cluster. In this way, the proposed PLTD algorithm simultaneously removes the redundancy in both the spatial and spectral domains in a unified framework. The extensive experimental results on various public HSI datasets demonstrate that the proposed method outperforms the traditional image compression approaches and other tensor-based methods.","Tensile stress,
Image coding,
Dictionaries,
Hyperspectral imaging,
Redundancy,
Correlation,
Matrix decomposition"
From Cloud to Fog Computing: A Review and a Conceptual Live VM Migration Framework,"Fog computing, an extension of cloud computing services to the edge of the network to decrease latency and network congestion, is a relatively recent research trend. Although both cloud and fog offer similar resources and services, the latter is characterized by low latency with a wider spread and geographically distributed nodes to support mobility and real-time interaction. In this paper, we describe the fog computing architecture and review its different services and applications. We then discuss security and privacy issues in fog computing, focusing on service and resource availability. Virtualization is a vital technology in both fog and cloud computing that enables virtual machines (VMs) to coexist in a physical server (host) to share resources. These VMs could be subject to malicious attacks or the physical server hosting it could experience system failure, both of which result in unavailability of services and resources. Therefore, a conceptual smart pre-copy live migration approach is presented for VM migration. Using this approach, we can estimate the downtime after each iteration to determine whether to proceed to the stop-and-copy stage during a system failure or an attack on a fog computing node. This will minimize both the downtime and the migration time to guarantee resource and service availability to the end users of fog computing. Last, future research directions are outlined.",
Bandwidth Enhancement of a Differential-Fed Equilateral Triangular Patch Antenna via Loading of Shorting Posts,"A comprehensive study on the mechanism of bandwidth enhancement for an equilateral triangular microstrip patch antenna (MPA) under differential excitation is presented in this paper. Attributing to the way of differential excitation, the radiation directivity of TM11 mode in such a patch has been improved a lot, and field distributions for both TM10 and TM11 modes are found to be simultaneously excited for radiation. Next, two shorting posts are introduced to this MPA so as to generate an additional mode, i.e., zero mode, which resonates in a frequency between TM10 and TM11 modes. With the proper arrangement of these three modes in proximity to each other, a wide bandwidth for radiation can be satisfactorily achieved. To demonstrate the validity of the proposed concept, a prototype antenna is finally designed and fabricated. As theoretically expected, the impedance bandwidth of the final designed patch antenna has been increased to 50.46% and the gain is around 6.5 dBi. Both simulated and measured results exhibit wide bandwidth and good performance of radiation.",
Low-Rank-Based Nonlocal Adaptive Loop Filter for High-Efficiency Video Compression,"In video coding, the in-loop filtering has emerged as a key module due to its significant improvement on compression performance since H.264/Advanced Video Coding. Existing incorporated in-loop filters in video coding standards mainly take advantage of the local smoothness prior model used for images. In this paper, we propose a novel adaptive loop filter utilizing image nonlocal prior knowledge by imposing the low-rank constraint on similar image patches for compression noise reduction. In the filtering process, the reconstructed frame is first divided into image patch groups according to image patch similarity. The proposed in-loop filtering is formulated as an optimization problem with low-rank constraint for every group of image patches independently. It can be efficiently solved by soft-thresholding singular values of the matrix composed of image patches in the same group. To adapt the properties of the input sequences and bit budget, an adaptive threshold derivation model is established for every group of image patches according to the characteristics of compressed image patches, quantization parameters, and coding modes. Moreover, frame-level and largest coding unit-level control flags are signaled to further improve the adaptability from the sense of rate-distortion optimization. The performance of the proposed in-loop filter is analyzed when it collaborates with the existing in-loop filters in High Efficiency Video Coding. Extensive experimental results show that our proposed in-loop filter can further improve the performance of state-of-the-art video coding standard significantly, with up to 16% bit-rate savings.","Image coding,
Video coding,
Image reconstruction,
Encoding,
Standards,
Rate-distortion,
Adaptation models"
Distributed Convex Optimization for Electric Vehicle Aggregators,"One of the main challenges for electric vehicle (EV) aggregators is the definition of a control infrastructure that scales to large EV numbers. This paper proposes a new optimization framework for achieving computational scalability based on the alternating directions method of multipliers, which allows for distributing the optimization process across several servers/cores. We demonstrate the performance and versatility of our framework by applying it to two relevant aggregator objectives: 1) valley filling; and 2) cost-minimal charging with grid capacity constraints. Our results show that the solving time of our approach scales linearly with the number of controlled EVs and outperforms the centralized optimization benchmark as the fleet size becomes larger.","Scalability,
Convex functions,
Electric vehicles,
Benchmark testing,
Cost function,
Jacobian matrices"
Multi-Category RFID Estimation,"This paper concerns the practically important problem of multi-category radio frequency identification (RFID) estimation: given a set of RFID tags, we want to quickly and accurately estimate the number of tags in each category. However, almost all the existing RFID estimation protocols are dedicated to the estimation problem on a single set, regardless of tag categories. A feasible solution is to separately execute the existing estimation protocols on each category. The execution time of such a serial solution is proportional to the number of categories, and cannot satisfy the delay-stringent application scenarios. Simultaneous RIFD estimation over multiple categories is desirable, and hence, this paper proposes an approach called simultaneous estimation for multi-category RFID systems (SEM). SEM exploits the Manchester-coding mechanism, which is supported by the ISO 18000-6 RFID standard, to decode the combined signals, thereby simultaneously obtaining the reply status of tags from each category. As a result, multiple bit vectors are decoded from just one physical slotted frame. Built on our SEM, many existing excellent estimation protocols can be used to estimate the tag cardinality of each category in a simultaneous manner. To ensure the predefined accuracy, we calculate the variance of the estimate in one round, as well as the variance of the average estimate in multiple rounds. To find the optimal frame size, we propose an efficient binary search-based algorithm. To address significant variance in category sizes, we propose an adaptive partitioning (AP) strategy to group categories of similar sizes together and execute the estimation protocol for each group separately. Compared with the existing protocols, our approach is much faster, meanwhile satisfying the predefined estimation accuracy. For example, with 20 categories, the proposed SEM+AP is about seven times faster than prior estimation schemes. Moreover, our approach is the only one whose normalized estimation time (i.e., time per category) decreases as the number of categories increases.","Estimation,
Radiofrequency identification,
Protocols,
Electronic mail,
Encoding,
Computer science,
IEEE transactions"
A Sliding Mode Based Damping Control of DFIG for Interarea Power Oscillations,"This paper proposes a second-order sliding mode-based damping controller of DFIG for interarea oscillations. The proposed damping control strategy aims to utilize the reactive power modulation ability of DFIG to stabilize the power system in the event of oscillations caused by disturbances. First, the proposed controller is derived based on a two-area power system, and then it is extended to multiarea power systems. Compared with the conventional damping controller, the proposed one is insensitive to modeling uncertainties and parameter variations. Given the wide variation of operation points, the proposed sliding mode-based damping controller demonstrates a better robustness than the conventional damping controller. Simulation results on a two-area power system and a 10-machine 39-bus power system with DFIG-based wind farm integration show the improvement on system performance in interarea oscillation damping and demonstrate the robustness of the proposed control scheme in a wide operation region.","Damping,
Oscillators,
Reactive power,
Power system stability,
Wind farms,
Algorithm design and analysis,
Sliding mode control"
Efficient and Privacy-Preserving Online Medical Prediagnosis Framework Using Nonlinear SVM,"With the advances of machine learning algorithms and the pervasiveness of network terminals, the online medical prediagnosis system, which can provide the diagnosis of healthcare provider anywhere anytime, has attracted considerable interest recently. However, the flourish of online medical prediagnosis system still faces many challenges including information security and privacy preservation. In this paper, we propose an e fficient and privacy-preserving online medical prediagnosis framework, called eDiag, by using nonlinear kernel support vector machine (SVM). With eDiag, the sensitive personal health information can be processed without privacy disclosure during online prediagnosis service. Specifically, based on an improved expression for the nonlinear SVM, an efficient and privacy-preserving classification scheme is introduced with lightweight multiparty random masking and polynomial aggregation techniques. The encrypted user query is directly operated at the service provider without decryption, and the diagnosis result can only be decrypted by user. Through extensive analysis, we show that eDiag can ensure that users' health information and healthcare provider's prediction model are kept confidential, and has significantly less computation and communication overhead than existing schemes. In addition, performance evaluations via implementing eDiag on smartphone and computer demonstrate eDiag's effectiveness in term of real online environment.",
Automatic Subspace Learning via Principal Coefficients Embedding,"In this paper, we address two challenging problems in unsupervised subspace learning: 1) how to automatically identify the feature dimension of the learned subspace (i.e., automatic subspace learning) and 2) how to learn the underlying subspace in the presence of Gaussian noise (i.e., robust subspace learning). We show that these two problems can be simultaneously solved by proposing a new method [(called principal coefficients embedding (PCE)]. For a given data set D ∈ Rm×n, PCE recovers a clean data set D0 ∈ Rm×n from D and simultaneously learns a global reconstruction relation C ∈ Rn×n of D0. By preserving C into an m'-dimensional space, the proposed method obtains a projection matrix that can capture the latent manifold structure of D0, where m' ≪ m is automatically determined by the rank of C with theoretical guarantees. PCE has three advantages: 1) it can automatically determine the feature dimension even though data are sampled from a union of multiple linear subspaces in presence of the Gaussian noise; 2) although the objective function of PCE only considers the Gaussian noise, experimental results show that it is robust to the non-Gaussian noise (e.g., random pixel corruption) and real disguises; and 3) our method has a closed-form solution and can be calculated very fast. Extensive experimental results show the superiority of PCE on a range of databases with respect to the classification accuracy, robustness, and efficiency.","Robustness,
Learning systems,
Gaussian noise,
Training data,
Principal component analysis,
Linear programming,
Estimation"
Nonlinear Discrete Hashing,"In this paper, we propose a nonlinear discrete hashing approach to learn compact binary codes for scalable image search. Instead of seeking a single linear projection in most existing hashing methods, we pursue a multilayer network with nonlinear transformations to capture the local structure of data samples. Unlike most existing hashing methods that adopt an error-prone relaxation to learn the transformations, we directly solve the discrete optimization problem to eliminate the quantization error accumulation. Specifically, to leverage the similarity relationships between data samples and exploit the semantic affinities of manual labels, the binary codes are learned with the objective to: 1) minimize the quantization error between the original data samples and the learned binary codes; 2) preserve the similarity relationships in the learned binary codes; 3) maximize the information content with independent bits; and 4) maximize the accuracy of the predicted labels based on the binary codes. With an alternating optimization, the nonlinear transformation and the discrete quantization are jointly optimized in the hashing learning framework. Experimental results on four datasets including CIFAR10, MNIST, SUN397, and ILSVRC2012 demonstrate that the proposed approach is superior to several state-of-the-art hashing methods.","Binary codes,
Quantization (signal),
Optimization,
Semantics,
Manuals,
Multi-layer neural network,
Data structures"
Neural-Dynamics-Driven Complete Area Coverage Navigation Through Cooperation of Multiple Mobile Robots,"Multiple robots collaboratively achieve a common coverage goal efficiently, which can improve work capacity, share coverage tasks, and reduce completion time. In this paper, a neural dynamics (ND) approach is proposed for complete area coverage navigation by multiple robots. A bioinspired neural network (NN) is designed to model the workspace and guide a swarm of robots for the coverage mission. The dynamics of each neuron in the topologically organized NN is characterized by an ND equation. Each mobile robot regards other robots as moving obstacles. Each robot path is autonomously generated from the neural activity landscape of the NN and the previous robot position. The proposed model algorithm is computationally efficient. The feasibility is validated by simulation, comparison studies, and experiments.",
An Enhanced WLAN Security System With FPGA Implementation for Multimedia Applications,"Maintaining a high level of data security with a low impact on system performance is more challenging in wireless multimedia applications. Protocols that are used for wireless local area network (WLAN) security are known to significantly degrade performance. In this paper, we propose an enhanced security system for a WLAN. Our new design aims to decrease the processing delay and increase both the speed and throughput of the system, thereby making it more efficient for multimedia applications. Our design is based on the idea of offloading computationally intensive encryption and authentication services to the end systems' CPUs. The security operations are performed by the hosts' central processor (which is usually a powerful processor) before delivering the data to a wireless card (which usually has a low-performance processor). By adopting this design, we show that both the delay and the jitter are significantly reduced. At the access point, we improve the performance of network processing hardware for real-time cryptographic processing by using a specialized processor implemented with field-programmable gate array technology. Furthermore, we use enhanced techniques to implement the Counter (CTR) Mode with Cipher Block Chaining Message Authentication Code Protocol (CCMP) and the CTR protocol. Our experiments show that it requires timing in the range of 20-40 μs to perform data encryption and authentication on different end-host CPUs (e.g., Intel Core i5, i7, and AMD 6-Core) as compared with 10-50 ms when performed using the wireless card. Furthermore, when compared with the standard WiFi protected access II (WPA2), results show that our proposed security system improved the speed to up to 3.7 times.","Wireless LAN,
Protocols,
Throughput,
Encryption,
Authentication,
Multimedia communication"
Power-Efficient Kerr Frequency Comb Based Tunable Optical Source,"Our paper reports on a chip-scale optical frequency synthesis, realized by offset-locking of an InP-based widelytunable laser within a low-power coherent receiver to a microresonator-based optical frequency comb. This study is a major step towards the demonstration of a true chip-scale optical frequency synthesizer with <1 Hz frequency resolution, <1 cm3 volume, and <1 W electrical power consumption, being suitable in various real-world applications.",
Evaluation of Graph Sampling: A Visualization Perspective,"Graph sampling is frequently used to address scalability issues when analyzing large graphs. Many algorithms have been proposed to sample graphs, and the performance of these algorithms has been quantified through metrics based on graph structural properties preserved by the sampling: degree distribution, clustering coefficient, and others. However, a perspective that is missing is the impact of these sampling strategies on the resultant visualizations. In this paper, we present the results of three user studies that investigate how sampling strategies influence node-link visualizations of graphs. In particular, five sampling strategies widely used in the graph mining literature are tested to determine how well they preserve visual features in node-link diagrams. Our results show that depending on the sampling strategy used different visual features are preserved. These results provide a complimentary view to metric evaluations conducted in the graph mining literature and provide an impetus to conduct future visualization studies.","Visualization,
Measurement,
Data visualization,
Data mining,
Fires,
Scalability,
Clustering algorithms"
Tidal Volume and Instantaneous Respiration Rate Estimation using a Volumetric Surrogate Signal Acquired via a Smartphone Camera,"Two parameters that a breathing status monitor should provide include tidal volume (VT ) and respiration rate (RR). Recently, we implemented an optical monitoring approach that tracks chest wall movements directly on a smartphone. In this paper, we explore the use of such noncontact optical monitoring to obtain a volumetric surrogate signal, via analysis of intensity changes in the video channels caused by the chest wall movements during breathing, in order to provide not only average RR but also information about VT and to track RR at each time instant (IRR). The algorithm, implemented on an Android smartphone, is used to analyze the video information from the smartphone's camera and provide in real time the chest movement signal from N = 15 healthy volunteers, each breathing at VT ranging from 300 mL to 3 L. These measurements are performed separately for each volunteer. Simultaneous recording of volume signals from a spirometer is regarded as reference. A highly linear relationship between peak-to-peak amplitude of the smartphone-acquired chest movement signal and spirometer VT is found (r2 = 0.951 ± 0.042, mean ± SD). After calibration on a subject-by-subject basis, no statistically significant bias is found in terms of VT estimation; the 95% limits of agreement are -0.348 to 0.376 L, and the rootmean-square error (RMSE) was 0.182 ± 0.107 L. In terms of IRR estimation, a highly linear relation between smartphone estimates and the spirometer reference was found (r2 = 0.999 ± 0.002). The bias, 95% limits of agreement, and RMSE are -0.024 breaths-per-minute (bpm), -0.850 to 0.802 bpm, and 0.414 ±0.178 bpm, respectively. These promising results show the feasibility of developing an inexpensive and portable breathing monitor, which could provide information about IRR as well as VT , when calibrated on an individual basis, using smartphones. Further studies are required to enable practical implementation of the proposed approach.",
DIVERT: A Distributed Vehicular Traffic Re-Routing System for Congestion Avoidance,"Centralized solutions for vehicular traffic re-routing to alleviate congestion suffer from two intrinsic problems: scalability, as the central server has to perform intensive computation and communication with the vehicles in real-time; and privacy, as the drivers have to share their location as well as the origins and destinations of their trips with the server. This article proposes DIVERT, a distributed vehicular re-routing system for congestion avoidance. DIVERT offloads a large part of the re-routing computation at the vehicles, and thus, the re-routing process becomes practical in real-time. To take collaborative re-routing decisions, the vehicles exchange messages over vehicular ad hoc networks. DIVERT is a hybrid system because it still uses a server and Internet communication to determine an accurate global view of the traffic. In addition, DIVERT balances the user privacy with the re-routing effectiveness. The simulation results demonstrate that, compared with a centralized system, the proposed hybrid system increases the user privacy by 92 percent on average. In terms of average travel time, DIVERT's performance is slightly less than that of the centralized system, but it still achieves substantial gains compared to the no re-routing case. In addition, DIVERT reduces the CPU and network load on the server by 99.99 and 95 percent, respectively.","Vehicles,
Privacy,
Servers,
Real-time systems,
Vehicular ad hoc networks,
Roads,
Internet"
Nonrigid Optical Flow Ground Truth for Real-World Scenes With Time-Varying Shading Effects,"In this letter, we present a dense ground truth dataset of nonrigidly deforming real-world scenes. Our dataset contains both long and short video sequences, and enables the quantitatively evaluation for RGB-based tracking and registration methods. To construct ground truth for the RGB sequences, we simultaneously capture Near-Infrared (NIR) image sequences where dense markers-visible only in NIR-represent ground-truth positions. This allows for comparison with automatically tracked RGB positions and the formation of error metrics. Most previous datasets containing nonrigidly deforming sequences are based on synthetic data. Our capture protocol enables us to acquire real-world deforming objects with realistic photometric effects-such as blur and illumination change-as well as occlusion and complex deformations. A public evaluation website is constructed to allow for ranking of RGB-image-based optical flow and other dense tracking algorithms, with various statistical measures. Furthermore, we present an RGB-NIR multispectral optical flow model allowing for energy optimization by adoptively combining featured information from both the RGB and the complementary NIR channels. In our experiments we evaluate eight existing RGB-based optical flow methods on our new dataset. We also evaluate our hybrid optical flow algorithm by comparing to two existing multispectral approaches, as well as varying our input channels across RGB, NIR, and RGB-NIR.","Optical imaging,
Optical variables control,
Cameras,
Optical sensors,
Adaptive optics,
Lighting,
Benchmark testing"
Interference-Constrained Pricing for D2D Networks,"The concept of device-to-device (D2D) communications underlaying cellular networks opens up potential benefits for improving system performance but also brings new challenges, such as interference management. In this paper, we propose a pricing framework for interference management from the D2D users to the cellular system, where the base station (BS) protects itself (or its serving cellular users) by pricing the cross-tier interference caused from the D2D users. A Stackelberg game is formulated to model the interactions between the BS and D2D users. Specifically, the BS sets prices to maximize its revenue (or any desired utility) subject to an interference temperature constraint. For given prices, the D2D users competitively adapt their power allocation strategies for individual utility maximization. We first analyze the competition among the D2D users by noncooperative game theory and an iterative-based distributed power allocation algorithm is proposed. Then, depending on how much network information the BS knows, we develop two optimal algorithms, one for uniform pricing with limited network information and the other for differentiated pricing with global network information. The uniform pricing algorithm can be implemented by a fully distributed manner and requires minimum information exchange between the BS and D2D users, and the differentiated pricing algorithm is partially distributed and requires no iteration between the BS and D2D users. Then, a suboptimal differentiated pricing scheme is proposed to reduce complexity and it can be implemented in a fully distributed fashion. Extensive simulations are conducted to verify the proposed framework and algorithms.","Device-to-device communication,
Interference,
Pricing,
Resource management,
Cellular networks,
Games,
Game theory"
Classification of Multiple Finger Motions During Dynamic Upper Limb Movements,"To better restore human hand function, advanced hand prostheses should be able to deal with a variety of daily living conditions. In this paper, we addressed myoelectric signal variations introduced by different muscle contractions, dynamic arm movements, and outer interfering forces in the practice of pattern recognition-based myoelectric control schemes. We examined four different training paradigms (data-collection protocols) and quantified their effectiveness for obtaining a robust classification. We further depicted the classification accuracy according to different arm/wrist motion primitives. Our results indicate the training paradigm that collects myoelectric signals on dynamic arm postures and varying muscular contractions (DPDE) can largely mitigate the motions' misclassification rate. The misclassification rate of finger motions seems to highly correlate to wrist pronation and supination, rather than different arm positions. Combining proprioceptive information, such as the hand's orientation, with myoelectric signals for classification only slightly alleviates the misclassification rate.",
PlenoPatch: Patch-Based Plenoptic Image Manipulation,"Patch-based image synthesis methods have been successfully applied for various editing tasks on still images, videos and stereo pairs. In this work we extend patch-based synthesis to plenoptic images captured by consumer-level lenselet-based devices for interactive, efficient light field editing. In our method the light field is represented as a set of images captured from different viewpoints. We decompose the central view into different depth layers, and present it to the user for specifying the editing goals. Given an editing task, our method performs patch-based image synthesis on all affected layers of the central view, and then propagates the edits to all other views. Interaction is done through a conventional 2D image editing user interface that is familiar to novice users. Our method correctly handles object boundary occlusion with semi-transparency, thus can generate more realistic results than previous methods. We demonstrate compelling results on a wide range of applications such as hole-filling, object reshuffling and resizing, changing object depth, light field upscaling and parallax magnification.","Cameras,
Image generation,
Image reconstruction,
Visualization,
Image color analysis,
Coherence,
Videos"
A Switched-Coupling-Capacitor Equalizer for Series-Connected Battery Strings,"Due to the low cost, small size, and easy control, the switched-capacitor (SC) equalizer is promising among all types of active cell balancing methods. However, the balancing speed is generally slow and the balancing efficiency is seriously low when the SC equalizer is applied into a long battery string. Therefore, an automatic switched-coupling-capacitor equalizer (SCCE) is proposed, which can realize the any-cells-to-any-cells equalization for a battery string. Only two switches and one capacitor are required for each battery cell. All mosfets are controlled by one pair of complementary pulse width modulation signals, and energy can be automatically and directly delivered from any higher voltage cells to any lower voltage ones without the need of cell monitoring circuits, leading to a high balancing efficiency and speed independent of the cell number and the initial cell voltages. Contrary to the conventional equalizers using additional components for the equalization among modules, the proposed equalizer shares a single converter for the equalization among cells and modules, resulting in smaller size and lower cost. A prototype for four lithium battery cells is implemented, and an experimental comparison between the proposed SCCE and the conventional SC equalizer is presented. Experimental results show the proposed topology exhibits a substantially improved balancing performance, and the measured peak efficiency is 92.7%.",
Psychophysiology-Based QoE Assessment: A Survey,"We present a survey of psychophysiology-based assessment for quality of experience (QoE) in advanced multimedia technologies. We provide a classification of methods relevant to QoE and describe related psychological processes, experimental design considerations, and signal analysis techniques. We summarize multimodal techniques and discuss several important aspects of psychophysiology-based QoE assessment, including the synergies with psychophysical assessment and the need for standardized experimental design. This survey is not considered to be exhaustive but serves as a guideline for those interested to further explore this emerging field of research.",
An Approach for Refocusing of Ground Moving Target Without Target Motion Parameter Estimation,"In synthetic aperture radar (SAR), long integration time may induce range migration and Doppler frequency migration of a received signal, which may degrade the SAR imaging performance of ground moving targets. Most of the conventional algorithms deal with the problems of range migration and Doppler frequency migration based on parameter searching. However, the exhaustive searching of target motion parameters may result in heavy computational burden. To avoid this problem, this paper proposes a new imaging method for ground moving targets without target motion parameter estimation. First, Keystone transform is applied to correct the range walk. Second, range curvature is compensated by the matched filtering function. Third, Doppler frequency migration is compensated via multiplying the data in range- and azimuth-time domains by its reversed conjugate data according to the equal interval sampling of the azimuth slow time, which avoids the searching procedure for target motion parameter estimation. Finally, the signal energy will be well accumulated in the range-Doppler domain, and thus, the moving targets can be efficiently recognized in the focused image. The major advantage of the proposed method is that it can obtain well-focused images of all targets in one processing step without target motion parameter estimation; thus, it is computationally efficient. Both simulated and real data processing results are used to validate the effectiveness of the proposed method.","Doppler effect,
Transforms,
Synthetic aperture radar,
Azimuth,
Parameter estimation,
Imaging"
Indicator analysis of partial discharges measured using various methods in paper-oil insulation,"Results of a comparative analysis of two non-dimensional coefficients, calculated based on signals emitted by partial discharges (PD) are presented in the paper. The PD were generated using setups for modeling of three basic types of PD sources, which can occur in paper-oil insulation in power transformers. The following measuring methods were considered: electrical, ultra-high frequency, acoustic emission, and optical spectrophotometry. All measurements, for each of the PD-source configuration using the various methods, were conducted simultaneously in a laboratory under same measurement conditions. Based on the gathered results it was stated that it is possible to recognize the partial discharges form based on the non-dimensional coefficients, which differ in value for all of the considered methods except for the acoustic emission. The main contribution of the research performed lies in the simplicity of the applied signal processing procedure, which can be adopted to a device or system for diagnosis of partial discharges occurring in paper-oil insulation.",
Dimensionality Reduction and Classification of Hyperspectral Images Using Ensemble Discriminative Local Metric Learning,"The high-dimensional data space of hyperspectral images (HSIs) often result in ill-conditioned formulations, which finally leads to many of the high-dimensional feature spaces being empty and the useful data existing primarily in a subspace. To avoid these problems, we use distance metric learning for dimensionality reduction. The goal of distance metric learning is to incorporate abundant discriminative information by reducing the dimensionality of the data. Considering that global metric learning is not appropriate for all training samples, this paper proposes an ensemble discriminative local metric learning (EDLML) algorithm for HSI analysis. The EDLML algorithm learns robust local metrics from both the training samples and the relative neighborhood of them and considers the different local discriminative distance metrics by dealing with the data region by region. It aims to learn a subspace to keep all the samples in the same class are as near as possible, while those from different classes are separated. The learned local metrics are then used to build an ensemble metric. Experiments on a number of different hyperspectral data sets confirm the effectiveness of the proposed EDLML algorithm compared with that of the other dimension reduction methods.",
An Efficient Privacy-Preserving Outsourced Computation over Public Data,"In this paper, we propose a new efficient privacy-preserving outsourced computation framework over public data, called EPOC. EPOC allows a user to outsource the computation of a function over multi-dimensional public data to the cloud while protecting the privacy of the function and its output. Specifically, we introduce three types of EPOC in order to tradeoff different levels of privacy protection and performance. We present a new cryptosystem called Switchable Homomorphic Encryption with Partially Decryption (SHED) as the core cryptographic primitive for EPOC. We introduce two coding techniques, called message pre-coding technique and message extending and coding technique respectively, for messages encrypted under a composite order group. Furthermore, we propose a Secure Exponent Calculation Protocol with Public Base (SEPB), which serves as the core sub-protocol in EPOC. Detailed security analysis shows that the proposed EPOC achieves the goal of outsourcing computation of a private function over public data without privacy leakage to unauthorized parties. In addition, performance evaluations via extensive simulations demonstrate that EPOC is efficient in both computation and communications.","Cloud computing,
Encryption,
Servers,
Privacy,
Additives,
Public key"
Codes Correcting a Burst of Deletions or Insertions,"This paper studies codes that correct a burst of deletions or insertions. Namely, a code will be called a b-burst-deletion/insertion-correcting code if it can correct a burst of deletions/insertions of any b consecutive bits. While the lower bound on the redundancy of such codes was shown by Levenshtein to be asymptotically log(n) + b - 1, the redundancy of the best code construction by Cheng et al. is b(log(n/b + 1)). In this paper, we close on this gap and provide codes with redundancy at most log(n) + (b - 1) log(log(n)) + b - log(b). We first show that the models of insertions and deletions are equivalent and thus it is enough to study codes correcting a burst of deletions. We then derive a non-asymptotic upper bound on the size of b-burst-deletion-correcting codes and extend the burst deletion model to two more cases: (1) a deletion burst of at most b consecutive bits and (2) a deletion burst of size at most b (not necessarily consecutive). We extend our code construction for the first case and study the second case for b = 3, 4.",
A New Sparse Subspace Clustering Algorithm for Hyperspectral Remote Sensing Imagery,"Robust techniques such as sparse subspace clustering (SSC) have been recently developed for hyperspectral images (HSIs) based on the assumption that pixels belonging to the same land-cover class approximately lie in the same subspace. In order to account for the spatial information contained in HSIs, SSC models incorporating spatial information have become very popular. However, such models are often based on a local averaging constraint, which does not allow for a detailed exploration of the spatial information, thus limiting their discriminative capability and preventing the spatial homogeneity of the clustering results. To address these relevant issues, in this letter, we develop a new and effective ℓ2-norm regularized SSC algorithm which adds a four-neighborhood ℓ2-norm regularizer into the classical SSC model, thus taking full advantage of the spatial-spectral information contained in HSIs. The experimental results confirm the potential of including the spatial information (through the newly added ℓ2-norm regularization term) in the SSC framework, which leads to a significant improvement in the clustering accuracy of SSC when applied to HSIs.","Clustering algorithms,
Sparse matrices,
TV,
Hyperspectral imaging,
Optimization"
A Survey on Legacy and Emerging Technologies for Public Safety Communications,"Effective emergency and natural disaster management depend on the efficient mission-critical voice and data communication between first responders and victims. Land mobile radio system (LMRS) is a legacy narrowband technology used for critical voice communications with limited use for data applications. Recently, long term evolution (LTE) emerged as a broadband communication technology that has a potential to transform the capabilities of public safety technologies by providing broadband, ubiquitous, and mission-critical voice and data support. For example, in the United States, FirstNet is building a nationwide coast-to-coast public safety network based on LTE broadband technology. This paper presents a comparative survey of legacy and the LTE-based public safety networks, and discusses the LMRS-LTE convergence as well as mission-critical push-to-talk over LTE. A simulation study of LMRS and LTE band class 14 technologies is provided using the NS-3 open source tool. An experimental study of APCO-25 and LTE band class 14 is also conducted using software-defined radio to enhance the understanding of the public safety systems. Finally, emerging technologies that may have strong potential for use in public safety networks are reviewed.",
Analysis of the Robustness of Transformerless PV Inverter Topologies to the Choice of Power Devices,"Transformerless topologies are employed in single-phase photovoltaic inverter converters due to their small size and low weight. Avoiding the grid-side transformer requires the modulation technique and the basis topology to be accordingly changed in order to mitigate dc current components in the grid side and the leakage current to ground. This paper carries out a sensitivity analysis of the selected transformerless topologies. This analysis investigates the impact of parameter variations depending on the choice of the employed semiconductor devices and detects the device for each topology, which affects the overall efficiency the most as well as the topology that is affected the most by the parameter variations with respect to the efficiency, leakage current, and grid-side dc current component. It is shown that, based on the proposed statistical analysis procedure, the impact of parameter variability can be analyzed with a reduced computational burden. An approach for the simplification of the comparison of the analyzed topologies is presented. As a result, relevant information for engineers selecting the most suitable power devices for the implementation of a certain transformerless topology is provided. The proposed analysis also allows to assess the robustness of the topologies' performance to the choice of different components when this selections is driven by other factors, such as cost and supply chain management.",
"Topology Discovery in Software Defined Networks: Threats, Taxonomy, and State-of-the-Art","The fundamental role of the software defined networks (SDNs) is to decouple the data plane from the control plane, thus providing a logically centralized visibility of the entire network to the controller. This enables the applications to innovate through network programmability. To establish a centralized visibility, a controller is required to discover a network topology of the entire SDN infrastructure. However, discovering a network topology is challenging due to: 1) the frequent migration of the virtual machines in the data centers; 2) lack of authentication mechanisms; 3) scarcity of the SDN standards; and 4) integration of security mechanisms for the topology discovery. To this end, in this paper, we present a comprehensive survey of the topology discovery and the associated security implications in SDNs. This survey provides discussions related to the possible threats relevant to each layer of the SDN architecture, highlights the role of the topology discovery in the traditional network and SDN, presents a thematic taxonomy of topology discovery in SDN, and provides insights into the potential threats to the topology discovery along with its state-of-the-art solutions in SDN. Finally, this survey also presents future challenges and research directions in the field of SDN topology discovery.","Network topology,
Topology,
Security,
Computer architecture,
Taxonomy,
Tutorials,
Software defined networking"
Hyperspectral Image Classification With Rotation Random Forest Via KPCA,"Random Forest (RF) is a widely used classifier to show a good performance of hyperspectral data classification. However, such performance could be improved by increasing the diversity that characterizes the ensemble architecture. In this paper, we propose a novel ensemble approach, namely rotation random forest via kernel principal component analysis (RoRF-KPCA). In particular, the original feature space is first randomly split into several subsets, and KPCA is performed on each subset to extract high order statistics. The obtained feature sets are merged and used as input to an RF classifier. Finally, the results achieved at each step are fused by a majority vote. Experimental analysis is conducted using real hyperspectral remote sensing images to evaluate the performance of the proposed method in comparison with RF, rotation forest, support vector machines, and RoRF-PCA. The obtained results demonstrate the effectiveness of the proposed method.",
A Survey on Data Center Networking (DCN): Infrastructure and Operations,"Data centers (DCs), owing to the exponential growth of Internet services, have emerged as an irreplaceable and crucial infrastructure to power this ever-growing trend. A DC typically houses a large number of computing and storage nodes, interconnected by a specially designed network, namely, DC network (DCN). The DCN serves as a communication backbone and plays a pivotal role in optimizing DC operations. However, compared to the traditional network, the unique requirements in the DCN, for example, large scale, vast application diversity, high power density, and high reliability, pose significant challenges to its infrastructure and operations. We have observed from the premium publication venues (e.g., journals and system conferences) that increasing research efforts are being devoted to optimize the design and operations of the DCN. In this paper, we aim to present a systematic taxonomy and survey of recent research efforts on the DCN. Specifically, we propose to classify these research efforts into two areas: 1) DCN infrastructure and 2) DCN operations. For the former aspect, we review and compare the list of transmission technologies and network topologies used or proposed in the DCN infrastructure. For the latter aspect, we summarize the existing traffic control techniques in the DCN operations, and survey optimization methods to achieve diverse operational objectives, including high network utilization, fair bandwidth sharing, low service latency, low energy consumption, high resiliency, and etc., for efficient DC operations. We finally conclude this survey by envisioning a few open research opportunities in DCN infrastructure and operations.","Network topology,
Optical switches,
Topology,
Bandwidth,
Wireless communication,
Servers,
Integrated optics"
Energy Harvesting Aided Device-to-Device Communication Underlaying the Cellular Downlink,"The specific family of device-to-device (D2D) communication underlying downlink cellular networks eliminates the reliance on base stations for its transmission by allowing direct transmission between two devices in each other's close proximity that reuse the cellular resource blocks for enhancing the attainable network capacity and spectrum efficiency. By considering downlink resource reuse and energy harvesting (EH), our goal is to maximize the sum-rate of the D2D links, without degrading the quality-of-service requirement of the cellular users. We formulated a sum-rate maximization problem of joint resource block and power allocation for the D2D links, which resulted in a non-convex problem that was then transformed into a more tractable convex optimization problem. Based on the results of our Lagrangian constrained optimization, we propose joint resource block and power allocation algorithms for the D2D links, when there is non-causal (offline) and causal (online) knowledge of the EH profiles at the D2D transmitters. The performance of the algorithms is quantified using simulation results for different network parameters settings, where our online algorithm performs close to the upper bound provided by our offline algorithm.","Resource management,
Copper,
Quality of service,
Energy harvesting,
Downlink,
Optimization,
Transmitters"
Germanium Mid-Infrared Photonic Devices,"Germanium based photonic devices can play a significant role in several applications, particularly in the so-called fingerprint wavelength region. Here, we review our recent results on mid-infrared germanium photonic devices that show promising performance in the 2-7.5 μm wavelength range.",
CrowdSenSim: a Simulation Platform for Mobile Crowdsensing in Realistic Urban Environments,"Smart cities take advantage of recent Information and Communication Technology (ICT) developments to provide added value to existing public services and improve quality of life for the citizens. The Internet of Things (IoT) paradigm makes the Internet more pervasive where objects equipped with computing, storage, and sensing capabilities are interconnected with communication technologies. Because of the widespread diffusion of IoT devices, applying the IoT paradigm to smart cities is an excellent solution to build sustainable ICT platforms. Having citizens involved in the process through mobile crowdsensing (MCS) techniques augments capabilities of these ICT platforms without additional costs. For proper operation, MCS systems require the contribution from a large number of participants. Simulations are therefore a candidate tool to assess the performance of MCS systems. In this paper, we illustrate the design of CrowdSenSim, a simulator for mobile crowdsensing. CrowdSenSim is designed specifically for realistic urban environments and smart cities services. We demonstrate the effectiveness of CrowdSenSim for the most popular MCS sensing paradigms (participatory and opportunistic), and we present its applicability using a smart public street lighting scenario.","Internet of Things,
mobile computing,
public administration"
Facial Expression Recognition Based on Deep Evolutional Spatial-Temporal Networks,"One key challenging issue of facial expression recognition is to capture the dynamic variation of facial physical structure from videos. In this paper, we propose a part-based hierarchical bidirectional recurrent neural network (PHRNN) to analyze the facial expression information of temporal sequences. Our PHRNN models facial morphological variations and dynamical evolution of expressions, which is effective to extract “temporal features” based on facial landmarks (geometry information) from consecutive frames. Meanwhile, in order to complement the still appearance information, a multi-signal convolutional neural network (MSCNN) is proposed to extract “spatial features” from still frames. We use both recognition and verification signals as supervision to calculate different loss functions, which are helpful to increase the variations of different expressions and reduce the differences among identical expressions. This deep evolutional spatial-temporal network (composed of PHRNN and MSCNN) extracts the partial-whole, geometry-appearance, and dynamic-still information, effectively boosting the performance of facial expression recognition. Experimental results show that this method largely outperforms the state-of-the-art ones. On three widely used facial expression databases (CK+, Oulu-CASIA, and MMI), our method reduces the error rates of the previous best ones by 45.5%, 25.8%, and 24.4%, respectively.","Feature extraction,
Face recognition,
Databases,
Recurrent neural networks,
Data mining,
Image recognition"
A PMU Placement Scheme Considering Realistic Costs and Modern Trends in Relaying,"Synchrophasor deployment costs have evolved over time. The cost of upgrading a substation, which is much larger than the cost of an individual device, has emerged as the primary constituent of the total expenditure. Given these circumstances, the optimal phasor measurement unit placement formulation needs to consider not only the number of devices that must be placed at the substations, but also the number of substations that must be upgraded to support those devices. This paper presents an integer linear programming methodology for such a placement scheme while considering realistic costs and practical constraints. The IEEE 30 bus system is used to illustrate the proposed concept, while the IEEE 118, IEEE 300, and Polish 2383 bus systems are used to show the performance of the method under different test environments.",
Multidimensional Convergence in Future 5G Networks,"Future 5G services are characterised by unprecedented need for high rate, ubiquitous availability, ultralow latency, and high reliability. The fragmented network view that is widespread in current networks will not stand the challenge posed by next generations of users. A new vision is required, and this paper provides an insight on how network convergence and application-centric approaches will play a leading role toward enabling the 5G vision. This paper, after expressing the view on the need for an end-to-end approach to network design, brings the reader into a journey on the expected 5G network requirements and outlines some of the work currently carried out by main standardisation bodies. It then proposes the use of the concept of network convergence for providing the overall architectural framework to bring together all the different technologies within a unifying and coherent network ecosystem. The novel interpretation of multidimensional convergence we introduce leads us to the exploration of aspects of node consolidation and converged network architectures, delving into details of optical-wireless integration and future convergence of optical data centre and access-metro networks. We then discuss how ownership models enabling network sharing will be instrumental in realising the 5G vision. This paper concludes with final remarks on the role SDN will play in 5G and on the need for new business models that reflect the application-centric view of the network. Finally, we provide some insight on growing research areas in 5G networking.","5G mobile communication,
Convergence,
Biological system modeling,
Broadband communication,
Next generation networking,
Quality of service,
Reliability"
Asymmetric Binary Coding for Image Search,"Learning to hash has attracted broad research interests in recent computer vision and machine learning studies, due to its ability to accomplish efficient approximate nearest neighbor search. However, the closely related task, maximum inner product search (MIPS), has rarely been studied in this literature. To facilitate the MIPS study, in this paper, we introduce a general binary coding framework based on asymmetric hash functions, named asymmetric inner-product binary coding (AIBC). In particular, AIBC learns two different hash functions, which can reveal the inner products between original data vectors by the generated binary vectors. Although conceptually simple, the associated optimization is very challenging due to the highly nonsmooth nature of the objective that involves sign functions. We tackle the nonsmooth optimization in an alternating manner, by which each single coding function is optimized in an efficient discrete manner. We also simplify the objective by discarding the quadratic regularization term which significantly boosts the learning efficiency. Both problems are optimized in an effective discrete way without continuous relaxations, which produces high-quality hash codes. In addition, we extend the AIBC approach to the supervised hashing scenario, where the inner products of learned binary codes are forced to fit the supervised similarities. Extensive experiments on several benchmark image retrieval databases validate the superiority of the AIBC approaches over many recently proposed hashing algorithms.","Binary codes,
Encoding,
Optimization,
Kernel,
Image coding,
Databases,
Standards"
Impact of GPS Signal Loss and Its Mitigation in Power System Synchronized Measurement Devices,"With the aid of Global Positioning System (GPS), synchronized measurement devices (SMDs) are increasingly deployed across power systems to monitor the status of electric grids by providing accurate measurement data along with unified time stamps. Unfortunately, GPS receivers tend to lose signal lock when certain uncontrollable and unpredictable factors arise. In order to investigate the presence of GPS signal loss (GSL) issues on measurement devices, analysis is performed on historical data from both phasor data concentrators (PDCs) and FNET/GridEye servers. Meanwhile, the impact of GSL on field measurement accuracy has not been previously explored in depth. Through analysis and experimental tests, this paper discovers angle drift caused by GSL, which consequently leads to the total vector error (TVE) exceeding the IEEE standard C37.118.1-2011. Furthermore, a compensation method is proposed to rectify the angle drift and laboratory experiments demonstrate that the proposed method does effectively reduce angle drift and mitigate the impact of GSL in SMDs.","Global Positioning System,
Phasor measurement units,
Synchronization,
Loss measurement,
Receivers"
Challenges of PV Integration in Low-Voltage Secondary Networks,"This paper presents challenges and potential impacts of photovoltaic (PV) integration in the low-voltage downtown secondary networks (downtown networks). In the conventional secondary networks, substation feeders are the sole source of electric power and establish unidirectional power to the downtown network. The network protectors prevent the flow of power from inside the network to the upstream feeder by disconnecting the circuit to protect the feeder transformer against upstream faults. The assumption of unidirectional power flow can be violated by PV generation due to the possibility of excess power inside the network. It is shown in this paper that a large number of network protector trips can occur and, thus, voltage collapse may follow even in low PV penetration levels. In addition, it is demonstrated that the reclose action of the network protector relays is adversely affected by the PV power. Other adverse effects of such distributed-generation units, such as voltage profile, line overloads, and flicker, are also briefly discussed. Finally, a solution is proposed, based on differential currents, to upgrade the network protector relays in order to avoid false trips due to excessive PV power. Part of the New Orleans downtown network is modeled and the study is performed through simulations.",
Towards acceleration of deep convolutional neural networks using stochastic computing,"In recent years, Deep Convolutional Neural Network (DCNN) has become the dominant approach for almost all recognition and detection tasks and outperformed humans on certain tasks. Nevertheless, the high power consumptions and complex topologies have hindered the widespread deployment of DCNNs, particularly in wearable devices and embedded systems with limited area and power budget. This paper presents a fully parallel and scalable hardware-based DCNN design using Stochastic Computing (SC), which leverages the energy-accuracy trade-off through optimizing SC components in different layers. We first conduct a detailed investigation of the Approximate Parallel Counter (APC) based neuron and multiplexer-based neuron using SC, and analyze the impacts of various design parameters, such as bit stream length and input number, on the energy/power/area/accuracy of the neuron cell. Then, from an architecture perspective, the influence of inaccuracy of neurons in different layers on the overall DCNN accuracy (i.e., software accuracy of the entire DCNN) is studied. Accordingly, a structure optimization method is proposed for a general DCNN architecture, in which neurons in different layers are implemented with optimized SC components, so as to reduce the area, power, and energy of the DCNN while maintaining the overall network performance in terms of accuracy. Experimental results show that the proposed approach can find a satisfactory DCNN configuration, which achieves 55X, 151X, and 2X improvement in terms of area, power and energy, respectively, while the error is increased by 2.86%, compared with the conventional binary ASIC implementation.","Neurons,
Computer architecture,
Biological neural networks,
Logic gates,
Embedded systems,
Radiation detectors,
Topology"
Reading the Underlying Information From Massive Metagenomic Sequencing Data,"Microorganisms are everywhere. Recent studies showed that the mixture of microbes or the microbiome on the human body plays important roles in human physiology and diseases. Metagenomic sequencing is a key technology for studying microbiomes. It produces massive amounts of data in the form of short sequencing reads. A single metagenomic sample can contain 10 7 to 10 8 reads of about 100-nucleotide (nt) length each in a typical shotgun metagenomic sequencing study. They contain rich information about microbiomes and their functions, but reading out those information from the huge highly fragmented data has multiple challenges for mathematical models, bioinformatics methods, and computer algorithms. In this paper, we review the basic bioinformatics tasks and existing methods in processing and analyzing metagenomic data, and discuss remaining open challenges and practical observations. The aim of the paper is to provide readers a whole picture of metagenomic data processing and analysis, and a reference and perspective to start with for computational scientists who are interested in this exciting field.","Sequential analysis,
DNA,
Genomics,
Bioinformatics,
Microorganisms,
Diseases,
Microbes"
Three-Phase Power Converter-Based Real-Time Synchronous Generator Emulation,"This paper develops a synchronous generator emulator by using a three-phase voltage source converter for transmission level power system testing. Different interface algorithms are compared, and the voltage type ideal transformer model is selected considering accuracy and stability. At the same time, closed-loop voltage control with current feed-forward is proposed to decrease the emulation error. The emulation is then verified through two different ways. First, the output waveforms of the emulator in experiments are compared with the simulation under the same condition. Second, a transfer function perturbation-based error model is obtained and redefined as the relative error for the amplitude and phase between the emulated and the target system over the frequency range of interest. The major cause of the error is investigated through a quantitative analysis of the error with varying parameters.","Emulation,
Delay effects,
Bandwidth,
Stability criteria,
Power system stability,
Testing"
Resource Management in Cloud Networking Using Economic Analysis and Pricing Models: A Survey,"This paper presents a comprehensive literature review on applications of economic and pricing models for resource management in cloud networking. To achieve sustainable profit advantage, cost reduction, and flexibility in provisioning of cloud resources, resource management in cloud networking requires adaptive and robust designs to address many issues, e.g., resource allocation, bandwidth reservation, request allocation, and workload allocation. Economic and pricing models have received a lot of attention as they can lead to desirable performance in terms of social welfare, fairness, truthfulness, profit, user satisfaction, and resource utilization. This paper reviews applications of the economic and pricing models to develop adaptive algorithms and protocols for resource management in cloud networking. Besides, we survey a variety of incentive mechanisms using the pricing strategies in sharing resources in edge computing. In addition, we consider using pricing models in cloud-based software defined wireless networking. Finally, we highlight important challenges, open issues and future research directions of applying economic and pricing models to cloud networking.",
Microgrid Protection,"The proliferation of distributed energy resources is setting the stage for modern distribution systems to operate as microgrids, which can avoid power disruptions and serve as resources for fast recovery during macrogrid disturbances. Microgrids are, therefore, major assets to improve the grid resilience. However, the offered resilience is seriously undermined if microgrids are not properly protected in the event of faults within their own boundaries. Distribution protective devices cannot reliably protect microgrids due to the variable and often limited short-circuit capacities of microgrids. Moreover, the research on microgrid protection has not led to a commercially available microgrid relay to date and has little prospect of reaching that level in the near future. As a result, the existing options for reliable microgrid protection remain effectively the subtransmission and transmission system protective devices, e.g., directional overcurrent, distance, and differential relays. Although years of operation in macrogrids support these relays, their performance for microgrids is yet to be analyzed. This paper presents such analysis for different relay types by considering various fault and generation conditions in a microgrid. Time-domain simulations are used to identify the scenarios where the relays function correctly as well as the problematic conditions, on which future research should focus. This paper also presents a short review on direct current (dc) microgrids and their protection requirements.","Microgrids,
Relays,
Resilience,
Voltage control,
Power system reliability,
Couplings,
Energy resources,
Power grids"
Power Control of an Energy Harvesting Sensor for Remote State Estimation,"We investigate sensor transmission power control for remote state estimation. Instead of using a conventional sensor, a sensor equipped with an energy harvester which can obtain energy from the external environment is utilized. We formulate power control of the energy harvesting sensor into an infinite time-horizon Markov decision process (MDP). To deal with the computation complexity associated with this multi-dimensional MDP, a continuous-time approach and perturbation analysis are used and a closed-form approximate value function is derived. Based on the approximation, we obtain a closed-form optimal power control solution which has a threshold-based structure. A numerical example is provided to evaluate the estimation performance of the optimal solution compared with other power scheduling schemes.","Power control,
Energy harvesting,
Batteries,
Complexity theory,
Wireless sensor networks,
Kalman filters,
State estimation"
A Decision Variable Clustering-Based Evolutionary Algorithm for Large-scale Many-objective Optimization,"The current literature of evolutionary manyobjective optimization is merely focused on the scalability to the number of objectives, while little work has considered the scalability to the number of decision variables. Nevertheless, many real-world problems can involve both many objectives and large-scale decision variables. To tackle such large-scale many-objective optimization problems, this paper proposes a specially tailored evolutionary algorithm based on a decision variable clustering method. To begin with, the decision variable clustering method divides the decision variables into two types: convergence-related variables and diversity-related variables. Afterwards, to optimize the two types of decision variables, a convergence optimization strategy and a diversity optimization strategy are adopted. In addition, a fast non-dominated sorting approach is developed to further improve the computational efficiency of the proposed algorithm. To assess the performance of the proposed algorithm, empirical experiments have been conducted on a variety of large-scale many-objective optimization problems with up to 10 objectives and 5000 decision variables. Our experimental results demonstrate that the proposed algorithm has significant advantages over several state-of-the-art evolutionary algorithms in terms of the scalability to decision variables on many-objective optimization problems.","Optimization,
Convergence,
Evolutionary computation,
Clustering methods,
Sorting,
Scalability,
Computer science"
RT-Fall: A Real-Time and Contactless Fall Detection System with Commodity WiFi Devices,"This paper presents the design and implementation of RT-Fall, a real-time, contactless, low-cost yet accurate indoor fall detection system using the commodity WiFi devices. RT-Fall exploits the phase and amplitude of the fine-grained Channel State Information (CSI) accessible in commodity WiFi devices, and for the first time fulfills the goal of segmenting and detecting the falls automatically in real-time, which allows users to perform daily activities naturally and continuously without wearing any devices on the body. This work makes two key technical contributions. First, we find that the CSI phase difference over two antennas is a more sensitive base signal than amplitude for activity recognition, which can enable very reliable segmentation of fall and fall-like activities. Second, we discover the sharp power profile decline pattern of the fall in the time-frequency domain and further exploit the insight for new feature extraction and accurate fall segmentation/detection. Experimental results in four indoor scenarios demonstrate that RT-fall consistently outperforms the state-of-the-art approach WiFall with 14 percent higher sensitivity and 10 percent higher specificity on average.","IEEE 802.11 Standard,
Real-time systems,
Wireless sensor networks,
Wireless communication,
Mobile computing,
Sensors,
Feature extraction"
Spectrum Auction for Differential Secondary Wireless Service Provisioning With Time-Dependent Valuation Information,"In this paper, we propose a spectrum auction mechanism for secondary spectrum access in cognitive radio networks. Different from existing works in the literature, the time-dependent buyer valuation information is employed in the proposed mechanism so that the primary spectrum owner (PO) can determine more favorable spectrum allocations and pricing functions in order to maximize the expected auction revenue. In addition, to exploit the temporal spectrum reusability, the proposed mechanism allows each secondary wireless user to declare its specific time preferences, including service starting time, delay tolerance, and service length. By further considering the heterogeneities in secondary wireless service provisioning, the proposed mechanism is able to support heterogeneous forms (continuous or disjointed spectrum usages) of secondary spectrum requests. Specifically, at the beginning of the auction frame, secondary wireless users report their different spectrum usage requests along with the bidding prices, while the PO decides a single-step spectrum allocation and calculates the payment for each winner based on not only the received bids but also the known time-dependent valuation information. Theoretical analyses and simulation results show that the proposed auction mechanism can satisfy all desired economic properties, and can improve the spectrum allocation efficiency and auction revenue compared with counterparts.","Cost accounting,
Resource management,
Delays,
Economics,
Dynamic scheduling,
Cognitive radio"
A Multi-Agent System With a Proportional-Integral Protocol for Distributed Constrained Optimization,"This technical note presents a continuous-time multi-agent system for distributed optimization with an additive objective function composed of individual objective functions subject to bound, equality, and inequality constraints. Each individual objective function is assumed to be convex in the region defined by its local bound constraints only without the need to be globally convex. All agents in the system communicate using a proportional-integral protocol with their output information instead of state information to reduce communication bandwidth. It is proved that all agents with any initial state can reach output consensus at an optimal solution to the given constrained optimization problem, provided that the graph describing the communication links among agents is undirected and connected. It is further proved that the system with only integral protocol is also convergent to the unique optimal solution if each individual objective function is strictly convex. Simulation results are presented to substantiate the theoretical results.","Optimization,
Protocols,
Linear programming,
Multi-agent systems,
Bandwidth,
Neural networks,
Simulation"
Spatial-Aware Collaborative Representation for Hyperspectral Remote Sensing Image Classification,"Representation-residual-based classifiers have attracted much attention in recent years in hyperspectral image (HSI) classification. How to obtain the optimal representa-tion coefficients for the classification task is the key problem of these methods. In this letter, spatial-aware collaborative representation (CR) is proposed for HSI classification. In order to make full use of the spatial-spectral information, we propose a closed-form solution, in which the spatial and spectral features are both utilized to induce the distance-weighted regularization terms. Different from traditional CR-based HSI classification algorithms, which model the spatial feature in a preprocessing or postprocessing stage, we directly incorporate the spatial information by adding a spatial regularization term to the representation objective function. The experimental results on three HSI data sets verify that our proposed approach outperforms the state-of-the-art classifiers.","Training,
Collaboration,
Hyperspectral imaging,
Closed-form solutions,
Linear programming,
Image reconstruction"
HFSP: Bringing Size-Based Scheduling To Hadoop,"Size-based scheduling with aging has been recognized as an effective approach to guarantee fairness and near-optimal system response times. We present HFSP, a scheduler introducing this technique to a real, multi-server, complex, and widely used system such as Hadoop. Size-based scheduling requires a priori job size information, which is not available in Hadoop: HFSP builds such knowledge by estimating it on-line during job execution. Our experiments, which are based on realistic workloads generated via a standard benchmarking suite, pinpoint at a significant decrease in system response times with respect to the widely used Hadoop Fair scheduler, without impacting the fairness of the scheduler, and show that HFSP is largely tolerant to job size estimation errors.","Training,
Aging,
Estimation,
Time factors,
Processor scheduling,
Silicon,
Cloud computing"
Comparative Validation of Polyp Detection Methods in Video Colonoscopy: Results From the MICCAI 2015 Endoscopic Vision Challenge,"Colonoscopy is the gold standard for colon cancer screening though some polyps are still missed, thus preventing early disease detection and treatment. Several computational systems have been proposed to assist polyp detection during colonoscopy but so far without consistent evaluation. The lack of publicly available annotated databases has made it difficult to compare methods and to assess if they achieve performance levels acceptable for clinical use. The Automatic Polyp Detection sub-challenge, conducted as part of the Endoscopic Vision Challenge (http://endovis.grand-challenge.org) at the international conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) in 2015, was an effort to address this need. In this paper, we report the results of this comparative evaluation of polyp detection methods, as well as describe additional experiments to further explore differences between methods. We define performance metrics and provide evaluation databases that allow comparison of multiple methodologies. Results show that convolutional neural networks are the state of the art. Nevertheless, it is also demonstrated that combining different methodologies can lead to an improved overall performance.","Colonoscopy,
Colon,
Cancer,
Lesions,
Endoscopes,
Databases,
Biomedical imaging"
TEES: An Efficient Search Scheme over Encrypted Data on Mobile Cloud,"Cloud storage provides a convenient, massive, and scalable storage at low cost, but data privacy is a major concern that prevents users from storing files on the cloud trustingly. One way of enhancing privacy from data owner point of view is to encrypt the files before outsourcing them onto the cloud and decrypt the files after downloading them. However, data encryption is a heavy overhead for the mobile devices, and data retrieval process incurs a complicated communication between the data user and cloud. Normally with limited bandwidth capacity and limited battery life, these issues introduce heavy overhead to computing and communication as well as a higher power consumption for mobile device users, which makes the encrypted search over mobile cloud very challenging. In this paper, we propose traffic and energy saving encrypted search (TEES), a bandwidth and energy efficient encrypted search architecture over mobile cloud. The proposed architecture offloads the computation from mobile devices to the cloud, and we further optimize the communication between the mobile clients and the cloud. It is demonstrated that the data privacy does not degrade when the performance enhancement methods are applied. Our experiments show that TEES reduces the computation time by 23 to 46 percent and save the energy consumption by 35 to 55 percent per file retrieval, meanwhile the network traffics during the file retrievals are also significantly reduced.","Cloud computing,
Servers,
Indexes,
Mobile communication,
Mobile handsets,
Encryption"
Exponential Decay of Reconstruction Error From Binary Measurements of Sparse Signals,"Binary measurements arise naturally in a variety of statistics and engineering applications. They may be inherent to the problem—for example, in determining the relationship between genetics and the presence or absence of a disease—or they may be a result of extreme quantization. A recent influx of literature has suggested that using prior signal information can greatly improve the ability to reconstruct a signal from binary measurements. This is exemplified by one-bit compressed sensing, which takes the compressed sensing model but assumes that only the sign of each measurement is retained. It has recently been shown that the number of one-bit measurements required for signal estimation mirrors that of unquantized compressed sensing. Indeed, s
-sparse signals in {\mathbb R}^{n}
can be estimated (up to normalization) from \Omega (s \log ~(n/s))
one-bit measurements. Nevertheless, controlling the precise accuracy of the error estimate remains an open challenge. In this paper, we focus on optimizing the decay of the error as a function of the oversampling factor \lambda := m/(s \log (n/s))
, where m
is the number of measurements. It is known that the error in reconstructing sparse signals from standard one-bit measurements is bounded below by \Omega (\lambda ^{-1})
. Without adjusting the measurement procedure, reducing this polynomial error decay rate is impossible. However, we show that an adaptive choice of the thresholds used for quantization can lower the error rate to e^{-\Omega (\lambda )}
. This improves upon guarantees for other methods of adaptive thresholding, such as sigma–delta quantization. We develop a general recursive strategy to achieve this exponential decay and two specific polynomial-time algorithms, which fall into this framework, one based on convex programming and one on hard thresholding. Our work bridges the one-bit compressed sensing model, in which the engineer controls the measurement procedure, to sigma–delta and successive approximation quantization. Moreover, the principle is extendable to signal reconstruction problems in a variety of binary statistical models as well as statistical estimation problems like logistic regression.","Compressed sensing,
Quantization (signal),
Measurement uncertainty,
Electronic mail,
Error analysis,
Signal processing algorithms,
Adaptation models"
Monitoring Nonlinear and Non-Gaussian Processes Using Gaussian Mixture Model-Based Weighted Kernel Independent Component Analysis,"A kernel independent component analysis (KICA) is widely regarded as an effective approach for nonlinear and non-Gaussian process monitoring. However, the KICA-based monitoring methods treat every KIC equally and cannot highlight the useful KICs associated with fault information. Consequently, fault information may not be explored effectively, which may result in degraded fault detection performance. To overcome this problem, we propose a new nonlinear and non-Gaussian process monitoring method using Gaussian mixture model (GMM)-based weighted KICA (WKICA). In particular, in WKICA, GMM is first adopted to estimate the probabilities of the KICs extracted by KICA. The significant KICs embodying the dominant process variation are then discriminated based on the estimated probabilities and assigned with larger weights to capture the significant information during online fault detection. A nonlinear contribution plots method is also developed based on the idea of a sensitivity analysis to help identifying the fault variables after a fault is detected. Simulation studies conducted on a simple four-variable nonlinear system and the Tennessee Eastman benchmark process demonstrate the superiority of the proposed method over the conventional KICA-based method.","Monitoring,
Kernel,
Feature extraction,
Fault detection,
Principal component analysis,
Data mining,
Covariance matrices"
Service-Oriented Architecture on FPGA-Based MPSoC,"The integration of software services-oriented architecture (SOA) and hardware multiprocessor system-on-chip (MPSoC) has been pursued for several years. However, designing and implementing a service-oriented system for diverse applications on a single chip has posed significant challenges due to the heterogeneous architectures, programming interfaces, and software tool chains. To solve the problem, this paper proposes SoSoC, a service-oriented system-on-chip framework that integrates both embedded processors and software defined hardware accelerators s as computing services on a single chip. Modeling and realizing the SOA design principles, SoSoC provides well-defined programming interfaces for programmers to utilize diverse computing resources efficiently. Furthermore, SoSoC can provide task level parallelization and significant speedup to MPSoC chip design paradigms by providing out-of-order execution scheme with hardware accelerators. To evaluate the performance of SoSoC, we implemented a hardware prototype on Xilinx Virtex5 FPGA board with EEMBC benchmarks. Experimental results demonstrate that the service componentization over original version is less than 3 percent, while the speedup for typical software Benchmarks is up to 372x. To show the portability of SoSoC, we implement the convolutional neural network as a case study on both Xilinx Zynq and Altera DE5 FPGA boards. Results show the SoSoC outperforms state-of-the-art literature with great flexibility.","Service-oriented architecture,
Computer architecture,
Hardware,
Field programmable gate arrays,
Semiconductor optical amplifiers,
Programming"
Multi-Objective Particle Swarm Optimization Approach for Cost-Based Feature Selection in Classification,"Feature selection is an important data-preprocessing technique in classification problems such as bioinformatics and signal processing. Generally, there are some situations where a user is interested in not only maximizing the classification performance but also minimizing the cost that may be associated with features. This kind of problem is called cost-based feature selection. However, most existing feature selection approaches treat this task as a single-objective optimization problem. This paper presents the first study of multi-objective particle swarm optimization (PSO) for cost-based feature selection problems. The task of this paper is to generate a Pareto front of nondominated solutions, that is, feature subsets, to meet different requirements of decision-makers in real-world applications. In order to enhance the search capability of the proposed algorithm, a probability-based encoding technology and an effective hybrid operator, together with the ideas of the crowding distance, the external archive, and the Pareto domination relationship, are applied to PSO. The proposed PSO-based multi-objective feature selection algorithm is compared with several multi-objective feature selection algorithms on five benchmark datasets. Experimental results show that the proposed algorithm can automatically evolve a set of nondominated solutions, and it is a highly competitive feature selection method for solving cost-based feature selection problems.",
Spendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors,"Batteryless energy harvesting systems face a twofold challenge in converting incoming energy into forward progress. Not only must such systems contend with inherently weak and fluctuating power sources, but they have very limited temporal windows for capitalizing on transitory periods of above-average power. To maximize forward progress, such systems should aggressively consume energy when it is available, rather than optimizing for peak averagecase efficiency. However, there are multiple ways that a processor can trade between consumption and performance. In this paper, we examine two approaches, frequency scaling and resource scaling, and develop a predictor-driven scheme for dynamically allocating future power budgets between the two techniques. We show that our solution can achieve forward progress equal to 2.08X of the baseline Out-of-Order (OoO) processor with the best static configuration of frequency and resources. The combined technique outperforms either technique in isolation, with frequency-only and resource-only approaches achieving 1.43X and 1.61X forward progress improvements, respectively.","Biological neural networks,
Program processors,
Microarchitecture,
Energy storage,
Energy harvesting,
Computer architecture,
Power demand"
Terahertz-Range Weak Reflection Fiber Optic Structures for Sensing Applications,"This paper describes a series of terahertz-range weak reflection fiber optic structures engineered for distributed temperature and strain sensing applications. Four specific structures are described: an intrinsic Fabry-Perot interferometer, a terahertz-range fiber Bragg grating, a phase-shifted terahertz-range fiber Bragg grating, and a terahertz-range fiber Bragg grating fabricated with an intact optical fiber buffer coating. All four structures were fabricated using a femtosecond laser micromachining system, which inscribed the structures within the core of a single-mode silica optical fiber. Interrogation technique, signal processing, fabrication method, and experimental investigation of each structure are described. The results presented demonstrate that these structures specifically, and terahertz-range optical fiber sensors more generally, hold substantial utility as methods of distributed temperature and strain sensing.","Optical fiber sensors,
Bragg gratings,
Ultrafast optics,
Fiber lasers,
Optical fibers,
Temperature measurement,
Temperature sensors"
Cost-aware Multi Data-Center Bulk Transfers in the Cloud from a Customer-Side Perspective,"Many cloud applications (e.g., data backup and replication, video distribution) require dissemination of large volumes of data from a source data-center to multiple geographically distributed data-centers. Given the high costs of wide-area bandwidth, the overall cost of inter-data-center communication is a major concern in such scenarios. While previous works have focused on optimizing the costs of bulk transfer, most of them use the charging models of Internet service providers, typically based on the 95th percentile of bandwidth consumption. However, public Cloud Service Providers (CSP) follow very different models to charge their customers. First, the cost for transmission is flat and depends on the location of the source and receiver data-centers. Second, CSPs offer discounts once customer transfers exceed certain volume thresholds per data-center. We present a systematic framework, CloudMPcast, that exploits these two aspects of cloud pricing schemes. CloudMPcast constructs overlay distribution trees for bulk-data transfer that both optimizes dollar costs of distribution, and ensures end-to-end data transfer times are not affected. CloudMPCast monitors TCP throughputs between data-centers and only proposes alternative trees that respect original transfer times. After an extensive measurement study, the cost savings range from 10% to 60% for both Azure and EC2 infrastructures, which potentially translates to millions of dollars a year assuming realistic demands.",
Towards MRI-Based Autonomous Robotic US Acquisitions: A First Feasibility Study,"Robotic ultrasound has the potential to assist and guide physicians during interventions. In this work, we present a set of methods and a workflow to enable autonomous MRI-guided ultrasound acquisitions. Our approach uses a structured-light 3D scanner for patient-to-robot and image-to-patient calibration, which in turn is used to plan 3D ultrasound trajectories. These MRI-based trajectories are followed autonomously by the robot and are further refined online using automatic MRI/US registration. Despite the low spatial resolution of structured light scanners, the initial planned acquisition path can be followed with an accuracy of 2.46 ± 0.96 mm. This leads to a good initialization of the MRI/US registration: the 3D-scan-based alignment for planning and acquisition shows an accuracy (distance between planned ultrasound and MRI) of 4.47 mm, and 0.97 mm after an online-update of the calibration based on a closed loop registration.","Ultrasonic imaging,
Three-dimensional displays,
Probes,
Imaging,
Planning,
Manipulators"
Potential- K- Means for Load Balancing and Cost Minimization in Mobile Recycling Network,"Cyber-physical systems usually consist of large numbers of spatially distributed autonomous sensors that monitor physical conditions and communicate with a main location. We consider the problem of positioning mobile storage facilities in a recycling network consisting of two types of nodes: collection points (neighborhood recycling bins) and mobile storage centers, and of finding the optimal number of storage centers. Sensors at the collection points monitor and communicate fill levels to a main location, where the collection points are clustered. We present a variation of K-means, potential-K-means, that assigns each cluster to a storage center while balancing the storage center loads. It minimizes the total network cost, for a fixed number of storage centers. The algorithm is based on an analogy with the gravitational force exerted by masses. The “mass” of a cluster is inversely proportional to its current “size.” An instance is assigned to the cluster whose “mass” minimizes the “gravitational potential” on the instance's position. This decision is a reasonable compromise between instance-cluster distance and cluster ""size.” The proposed algorithm produces smaller total costs than K-means. We show that storage center locations affect the total cost, and thus, very significant savings are achieved through this wireless monitoring of the collection points and dynamical positioning of the storage centers.","Clustering algorithms,
Recycling,
Mobile computing,
Mobile communication,
Algorithm design and analysis,
Sensors,
Electronic waste"
Improved Rule Installation for Real-Time Query Service in Software-Defined Internet of Vehicles,"Internet of Vehicles (IoV) has gained considerable attention from industry and academia due to the development of communication technology and smart city. However, a proprietary and closed way of operating hardware in network equipment slows down the progress of new service deployment and extension in IoV. Moreover, the tightly coupled control and data planes in traditional networks significantly increase the complexity and cost of network management. By proposing a novel architecture, i.e., software-defined IoV (SDIV), we adopt a software-defined network (SDN) architecture to address these problems by leveraging its separation of the control plane from the data one and a uniform way to configure heterogeneous switches. However, IoV characteristics introduce some great challenges in rule installation due to the limited size of flow tables at OpenFlow-enabled switches that are the main SDN component. It is necessary to build compact flow tables for IoV scalability. Accordingly, we develop a novel rule installation mechanism to reduce the number of rules for real-time query services in SDIV. We separate the wired data plane from the wireless one and use multicast addresses in the latter. We introduce a destination-driven model in the wired data plane to reduce the number of rules at switches. Experiments with a real data trace show that the developed approach significantly reduces the number of rules without degrading the performance of data transmissions for real-time query services in IoV.",
Hybrid Energy Storage with Supercapacitor for Cost-Efficient Data Center Power Shaving and Capping,"Recent studies have proposed to dynamically reshape the power demand curve of a data center (i.e., power shaving) with energy storage devices, particularly uninterruptible power supply (UPS) batteries. Power shaving can be used to limit the peak power demand in a data center, in order to reduce both the power infrastructure investment (i.e., cap-ex) and the electricity bills (i.e., op-ex). However, power shaving requires the UPS batteries to be frequently charged/discharged, which is known to compromise the battery lifetime and availability. This paper presents a detailed quantitative study that explores different options to integrate supercapacitor (SC) with batteries for cost-efficient energy storage. Compared with batteries, SC allows more charge/discharge cycles and has a higher power density, which are desirable for fast power shaving. However, SC also has undesirable characteristics (e.g., relatively high self-discharging rate and cost). Therefore, we quantitatively compare three possible energy storage options (i.e., Battery-only, SC-only, and Battery+SC) in detail, with different SC self-discharging rate assumptions. SC options (SC-only and Battery+SC) are shown to be more cost-efficient designs, saving the energy storage cost by 34 percent, on average, compared with Battery-only. For a 10 MW data center in a 10-year period, the savings can be converted to $3 M in total cost of ownership (TCO) reduction by allowing more servers to be deployed. In addition, we also propose the integration of energy storage with dynamic voltage and frequency scaling (DVFS) to cap the peak power demand (i.e., power capping). Specifically, we comparatively studyfour power capping algorithms and discuss their applicable scenarios. Finally, we introduce our proof-of-concept SC physical testbed and present preliminary hardware testing results.",
Predicting microRNA-disease associations based on improved microRNA and disease similarities,"MicroRNAs (miRNAs) are a type of non-coding RNAs with about ~22nt nucleotides. Increasing evidences have shown that miRNAs play critical roles in many human diseases. The identification of human disease-related miRNAs is helpful to explore the underlying pathogenesis of diseases. More and more experimental validated associations between miRNAs and diseases have been reported in the recent studies, which provide useful information for new miRNA-disease association discovery. In this study, we propose a computational framework, KBMF-MDI, to predict the associations between miRNAs and diseases based on their similarities. The sequence and function information of miRNAs are used to measure similarity among miRNAs while the semantic and function information of disease are used to measure similarity among diseases, respectively. In addition, the kernelized Bayesian matrix factorization method is employed to infer potential miRNA-disease associations by integrating these data sources. We applied this method to 6084 known miRNA-disease associations and utilized 5-fold cross validation to evaluate the performance. The experimental results demonstrate that our method can effectively predict unknown miRNA-disease associations.",
MoZo: A Moving Zone Based Routing Protocol Using Pure V2V Communication in VANETs,"Vehicular Ad-hoc Networks (VANETs) are an emerging field, whereby vehicle-to-vehicle communications can enable many new applications such as safety and entertainment services. Most VANET applications are enabled by different routing protocols. The design of such routing protocols, however, is quite challenging due to the dynamic nature of nodes (vehicles) in VANETs. To exploit the unique characteristics of VANET nodes, we design a moving-zone based architecture in which vehicles collaborate with one another to form dynamic moving zones so as to facilitate information dissemination. We propose a novel approach that introduces moving object modeling and indexing techniques from the theory of large moving object databases into the design of VANET routing protocols. The results of extensive simulation studies carried out on real road maps demonstrate the superiority of our approach compared with both clustering and non-clustering based routing protocols.","Vehicles,
Routing protocols,
Routing,
Clustering algorithms,
Vehicular ad hoc networks,
Mobile computing"
Cost-Constrained Dynamic Optimal Electric Vehicle Charging,"Electric vehicles are an integral component of an environmentally sustainable and resilient infrastructure. Successful penetration of electric vehicles requires close coupling between the customers and load serving entities, adaptive energy markets, and technological advancements. In this paper, distribution line over-loading due to vehicle charging has been mitigated using both day-ahead (static) and real-time (dynamic) frameworks, using continuous and discrete charging rates. The proposed solution focuses on valley filling (system perspective) and charging cost reduction (customer perspective). The real-time solution was achieved using a moving horizon optimization technique. In addition to providing charging coordination, the impacts of two different pricing structures were analyzed to ascertain the customer's individual cost optima with respect to the system optima. The results presented strongly indicate that a global pricing structure will not be optimal for all consumers due to their diverse driving habits.",
Energy-Efficient Event Detection by Participatory Sensing Under Budget Constraints,"Dynamic event detection by using participatory sensing paradigms has received growing interests recently, where detection tasks are assigned to smart-device users who can potentially collect needed sensory data from device-equipped sensors. Typical applications include, but are not limited to, noise and air pollution detections, people gathering, even disaster prediction. Given this problem, although many existing centralized solutions are effective and widely used, they usually cause heavy communication overhead. Thus, it is strongly desired to design distributed solutions to reduce energy consumption, while achieving a high level of detection accuracy with limited sensing task budget. In this paper, we first present two novel centralized detection algorithms as the performance benchmark, which make use of the Minimum Cut theory and support vector machine (SVM)-based pattern recognition techniques. Then, we introduce a novel distributed and energy-efficient event detection framework under task budget constraint, where we formulate an optimization problem and derive an optimal utility function. Finally, based on a real trace-driven data set in an urban area of Beijing, extensive simulation results demonstrate the effectiveness of our proposed algorithms.",
Incremental Hashing for Semantic Image Retrieval in Nonstationary Environments,"A very large volume of images is uploaded to the Internet daily. However, current hashing methods for image retrieval are designed for static databases only. They fail to consider the fact that the distribution of images can change when new images are added to the database over time. The changes in the distribution of images include both discovery of a new class and a distribution of images within a class owing to concept drift. Retraining of hash tables using all images in the database requires a large computation effort. This is also biased to old data owing to the huge volume of old images which leads to a poor retrieval performance over time. In this paper, we propose the incremental hashing (ICH) method to deal with the two aforementioned types of changes in the data distribution. The ICH uses a multihashing to retain knowledge coming from images arriving over time and a weight-based ranking to make the retrieval results adaptive to the new data environment. Experimental results show that the proposed method is effective in dealing with changes in the database.",
Near-Optimal Allocation Algorithms for Location-Dependent Tasks in Crowdsensing,"Crowdsensing offers an efficient way to meet the demand in large-scale sensing applications. In crowdsensing, optimal task allocation is challenging since sensing tasks with different requirements of quality of sensing are typically associated with specific locations, and mobile users have time constraints. We show that the allocation problem is NP-hard. We then focus on approximation algorithms and devise an efficient local-ratio-based algorithm (LRBA). Our analysis shows that the approximation ratio of the aggregate rewards obtained by optimal allocation to those by LRBA is 5. This reveals that LRBA is efficient, since a lower (but not tight) bound on the approximation ratio is 4. We extend the results to the general scenario where mobile users are heterogeneous. A distributed version of LRBA, namely DLRBA, is designed, which can be iteratively executed at each mobile user without the need for the platform to collect all the information of mobile users. We prove that both centralized and distributed versions can output the same solution. Extensive simulation results are provided to demonstrate the advantages of our proposed algorithms.",
Lightweight three-factor authentication and key agreement protocol for internet-integrated wireless sensor networks,"Wireless sensor networks (WSNs) will be integrated into the future Internet as one of the components of the Internet of Things, and will become globally addressable by any entity connected to the Internet. Despite the great potential of this integration, it also brings new threats, such as the exposure of sensor nodes to attacks originating from the Internet. In this context, lightweight authentication and key agreement protocols must be in place to enable end-to-end secure communication. Recently, Amin et al. proposed a three-factor mutual authentication protocol for WSNs. However, we identified several flaws in their protocol. We found that their protocol suffers from smart card loss attack where the user identity and password can be guessed using offline brute force techniques. Moreover, the protocol suffers from known session-specific temporary information attack, which leads to the disclosure of session keys in other sessions. Furthermore, the protocol is vulnerable to tracking attack and fails to fulfill user untraceability. To address these deficiencies, we present a lightweight and secure user authentication protocol based on the Rabin cryptosystem, which has the characteristic of computational asymmetry. We conduct a formal verification of our proposed protocol using ProVerif in order to demonstrate that our scheme fulfills the required security properties. We also present a comprehensive heuristic security analysis to show that our protocol is secure against all the possible attacks and provides the desired security features. The results we obtained show that our new protocol is a secure and lightweight solution for authentication and key agreement for Internet-integrated WSNs.","Protocols,
Wireless sensor networks,
Internet,
Authentication,
Smart cards,
Cryptography"
Structured Latent Label Consistent Dictionary Learning for Salient Machine Faults Representation-Based Robust Classification,"This paper investigates the salient machine faults representation-based classification issue by dictionary learning. A novel structured latent label consistent dictionary learning (LLC-DL) model is proposed for joint discriminative salient representation and classification. Our LLC-DL deals with the tasks by solving one objective function that aims to minimize the structured reconstruction error, structured discriminative sparse-code error and classification error simultaneously. Also, LLC-DL decomposes given signals into a sparse reconstruction part over structured latent weighted discriminative dictionary, a salient feature extraction part and an error part fitting noise. Specifically, the dictionary is learnt atom by atom, where each dictionary atom is learnt with a latent vector that reduces the disturbance between interclass atoms. The structured coding coefficients are calculated via minimizing the reconstruction error and discriminative sparse code error simultaneously. The salient representations are learnt by embedding signals onto a projection and a robust linear classifier is then trained over the learned salient features directly so that features can be ensured to be optimal for classification, where robust l2,1-norm imposed on the classifier can make the prediction results more accurate. By including a salient feature extraction term, the classification approach of LLC-DL is very efficient, since there is no need to involve an extra time-consuming sparse reconstruction process with the well-trained dictionary for each test signal. Extensive simulations versify the effectiveness of our algorithm.","Dictionaries,
Feature extraction,
Robustness,
Linear programming,
Encoding,
Informatics,
Classification algorithms"
Tandem Equipment Arranged Architecture with Exhaust Heat Reuse System for Software-Defined Data Center Infrastructure,"In this paper, we propose a novel energy-efficient architecture for software-defined data center infrastructures. In our proposed data center architecture, we include an exhaust heat reuse system that utilizes high-temperature exhaust heat from servers in conditioning humidity and air temperature of office space near the data center. To obtain high-temperature exhaust heat, equipment such as server racks and air conditioners are deployed in tandem so that the aisles are divided into three types: cold, hot, and super-hot. In this paper, to investigate the fundamental characteristics of our proposed data center architecture, we consider various types of data center models and conduct numerical simulations that use results obtained by experiments at an actual data center. Through simulation, we show that the total power consumption by a data center with our proposed architecture is 27 percent lower than that by data center with a conventional architecture. In addition, it is also shown that the proposed tandem equipment arrangement is suitable for obtaining high-temperature exhaust heat and decreasing the total power consumption significantly under a wider range of conditions than in the conventional equipment arrangement.","Servers,
Heating,
Data models,
Atmospheric modeling,
Computer architecture,
Power demand,
Computational modeling"
Historical and impact analysis of API breaking changes: A large-scale study,"Change is a routine in software development. Like any system, libraries also evolve over time. As a consequence, clients are compelled to update and, thus, benefit from the available API improvements. However, some of these API changes may break contracts previously established, resulting in compilation errors and behavioral changes. In this paper, we study a set of questions regarding API breaking changes. Our goal is to measure the amount of breaking changes on real-world libraries and its impact on clients at a large-scale level. We assess (i) the frequency of breaking changes, (ii) the behavior of these changes over time, (iii) the impact on clients, and (iv) the characteristics of libraries with high frequency of breaking changes. Our large-scale analysis on 317 real-world Java libraries, 9K releases, and 260K client applications shows that (i) 14.78% of the API changes break compatibility with previous versions, (ii) the frequency of breaking changes increases over time, (iii) 2.54% of their clients are impacted, and (iv) systems with higher frequency of breaking changes are larger, more popular, and more active. Based on these results, we provide a set of lessons to better support library and client developers in their maintenance tasks.","Libraries,
Java,
Time-frequency analysis,
Contracts,
Software,
Maintenance engineering"
Toward Unobtrusive Patient Handling Activity Recognition for Injury Reduction Among At-Risk Caregivers,"Nurses regularly perform patient handling activities. These activities with awkward postures expose healthcare providers to a high risk of overexertion injury. The recognition of patient handling activities is the first step to reduce injury risk for caregivers. The current practice on workplace activity recognition is based on human observational approach, which is neither accurate nor projectable to a large population. In this paper, we aim at addressing these challenges. Our solution comprises a smart wearable device and a novel spatio-temporal warping (STW) pattern recognition framework. The wearable device, named Smart Insole 2.0, is equipped with a rich set of sensors and can provide an unobtrusive way to automatically capture the information of patient handling activities. The STW pattern recognition framework fully exploits the spatial and temporal characteristics of plantar pressure by calculating a novel warped spatio-temporal distance, to quantify the similarity for the purpose of activity recognition. To validate the effectiveness of our framework, we perform a pilot study with eight subjects, including eight common activities in a nursing room. The experimental results show the overall classification accuracy achieves 91.7%. Meanwhile, the qualitative profile and load level can also be classified with accuracies of 98.3% and 92.5%, respectively.",
Incremental Deployment and Throughput Maximization Routing for a Hybrid SDN,"To explore the advantages of software defined network (SDN), while preserving the legacy networking systems, a natural deployment strategy is to deploy a hybrid SDN incrementally to improve the network performance. In this paper, we address two technical challenges: an incremental deployment strategy and a throughput-maximization routing, for deploying a hybrid network incrementally. For incremental deployment, we propose a heuristic algorithm for deploying a hybrid SDN under the budget constraint, and prove the approximate factor of 1- 1/e. For throughput-maximization routing, we apply a depth-first-search method and a randomized rounding mechanism to solve the multi-commodity h-splittable flow routing problem in a hybrid SDN, where h ≥ 1. We also prove that our method has approximation ratio O(1/log N), where N is the number of links in a hybrid SDN. We then show, by both analysis and simulations, that our algorithms can obtain significant performance gains and perform better than the theoretical worst-case bound. For example, our incremental deployment scheme helps to enhance the throughout about 40% compared with the previous deployment scheme by deploying a small number of SDN devices, and the proposed routing algorithm can improve the throughput about 31% compared with ECMP in hybrid networks.","Routing,
Throughput,
Software,
Approximation algorithms,
Heuristic algorithms,
Performance evaluation,
Computer science"
DeepShape: Deep-Learned Shape Descriptor for 3D Shape Retrieval,"Complex geometric variations of 3D models usually pose great challenges in 3D shape matching and retrieval. In this paper, we propose a novel 3D shape feature learning method to extract high-level shape features that are insensitive to geometric deformations of shapes. Our method uses a discriminative deep auto-encoder to learn deformation-invariant shape features. First, a multiscale shape distribution is computed and used as input to the auto-encoder. We then impose the Fisher discrimination criterion on the neurons in the hidden layer to develop a deep discriminative auto-encoder. Finally, the outputs from the hidden layers of the discriminative auto-encoders at different scales are concatenated to form the shape descriptor. The proposed method is evaluated on four benchmark datasets that contain 3D models with large geometric variations: McGill, SHREC'10 ShapeGoogle, SHREC'14 Human and SHREC'14 Large Scale Comprehensive Retrieval Track Benchmark datasets. Experimental results on the benchmark datasets demonstrate the effectiveness of the proposed method for 3D shape retrieval.","Shape,
Three-dimensional displays,
Heating,
Kernel,
Feature extraction,
Neurons,
Solid modeling"
Design and Implementation of Context Aware Applications With Wireless Sensor Network Support in Urban Train Transportation Environments,"Transportation system is experiencing steady growth, with the aim of providing more efficient, reliable, and comfortable services, in the framework of intelligent transportation systems. Moreover, context aware environments are one of the main drivers in the achievement of smart cities and smart regions. In this paper, wireless sensor networks (WSNs) embedded in urban transportation systems will be analyzed in terms of impact on wireless channel behavior and system performance. An in-house developed 3-D ray launching tool, with the inclusion of in-house human body model as well as with the study of interference levels is employed. Wireless channel estimations indicate an initial infrastructure node density in the order of 1node/150m2 to 1node/500m2 as a function of the employed transceivers. A practical solution has been implemented, combining an Android-based application and a system level architecture over the WSN for urban train transportation environmental monitoring, providing interaction between users and the environment, with the aid of a combined WSN/WLAN platform as well as an implemented software architecture, scalable in terms of user density and future needs.","Wireless sensor networks,
Wireless communication,
Vehicles,
Mobile communication,
Transceivers,
Mobile computing"
The Effect of Information Utilization: Introducing a Novel Guiding Spark in the Fireworks Algorithm,"The fireworks algorithm (FWA) is a competitive swarm intelligence algorithm which has been shown to be very useful in many applications. In this paper, a novel guiding spark (GS) is introduced to further improve its performance by enhancing the information utilization in the FWA. The idea is to use the objective function's information acquired by explosion sparks to construct a guiding vector (GV) with promising direction and adaptive length, and to generate an elite solution called a GS by adding the GV to the position of the firework. The FWA with GS is called the guided FWA (GFWA). Experimental results show that the GS contributes greatly to both exploration and exploitation of the GFWA. The GFWA outperforms previous versions of the FWA and other swarm and evolutionary algorithms on a large variety of test functions and it is also a useful method for large scale optimization. The principle of the GS is very simple but efficient, which can be easily transplanted to other population-based algorithms.",
Deep Multimodal Distance Metric Learning Using Click Constraints for Image Ranking,"How do we retrieve images accurately? Also, how do we rank a group of images precisely and efficiently for specific queries? These problems are critical for researchers and engineers to generate a novel image searching engine. First, it is important to obtain an appropriate description that effectively represent the images. In this paper, multimodal features are considered for describing images. The images unique properties are reflected by visual features, which are correlated to each other. However, semantic gaps always exist between images visual features and semantics. Therefore, we utilize click feature to reduce the semantic gap. The second key issue is learning an appropriate distance metric to combine these multimodal features. This paper develops a novel deep multimodal distance metric learning (Deep-MDML) method. A structured ranking model is adopted to utilize both visual and click features in distance metric learning (DML). Specifically, images and their related ranking results are first collected to form the training set. Multimodal features, including click and visual features, are collected with these images. Next, a group of autoencoders is applied to obtain initially a distance metric in different visual spaces, and an MDML method is used to assign optimal weights for different modalities. Next, we conduct alternating optimization to train the ranking model, which is used for the ranking of new queries with click features. Compared with existing image ranking methods, the proposed method adopts a new ranking model to use multimodal features, including click features and visual features in DML. We operated experiments to analyze the proposed Deep-MDML in two benchmark data sets, and the results validate the effects of the method.","Machine learning,
Distance learning,
Image retrieval,
Semantics,
Ranking (statistics),
Extraterrestrial measurements"
Towards Privacy-preserving Content-based Image Retrieval in Cloud Computing,"Content-based image retrieval (CBIR) applications have been rapidly developed along with the increase in the quantity, availability and importance of images in our daily life. However, the wide deployment of CBIR scheme has been limited by its the severe computation and storage requirement. In this paper, we propose a privacy-preserving content-based image retrieval scheme, which allows the data owner to outsource the image database and CBIR service to the cloud, without revealing the actual content of the database to the cloud server. Local features are utilized to represent the images, and earth mover’s distance (EMD) is employed to evaluate the similarity of images. The EMD computation is essentially a linear programming (LP) problem. The proposed scheme transforms the EMD problem in such a way that the cloud server can solve it without learning the sensitive information. In addition, local sensitive hash (LSH) is utilized to improve the search efficiency. The security analysis and experiments show the security and efficiency of the proposed scheme.","Servers,
Cryptography,
Feature extraction,
Image retrieval,
Earth"
Reactive Magnetron Sputter Deposition of Superconducting Niobium Titanium Nitride Thin Films With Different Target Sizes,"The superconducting critical temperature (Tc > 15 K) of niobium titanium nitride (NbTiN) thin films allows for low-loss circuits up to 1.1 THz, enabling on-chip spectroscopy and multipixel imaging with advanced detectors. The drive for large-scale detector microchips is demanding NbTiN films with uniform properties over an increasingly larger area. This paper provides an experimental comparison between two reactive dc sputter systems with different target sizes: a small target (ø100 mm) and a large target (127 mm × 444.5 mm). This paper focuses on maximizing the Tc of the films and the accompanying I-V characteristics of the sputter plasma, and we find that both systems are capable of depositing films with Tc > 15 K. The resulting film uniformity is presented in a second manuscript in this volume. We find that these films are deposited within the transition from metallic to compound sputtering, at the point where target nitridation most strongly depends on nitrogen flow. Key in the deposition optimization is to increase the system's pumping speed and gas flows to counteract the hysteretic effects induced by the target size. Using the I-V characteristics as a guide proves to be an effective way to optimize a reactive sputter system, for it can show whether the optimal deposition regime is hysteresis-free and accessible.","Nitrogen,
Argon,
Temperature measurement,
Plasmas,
Sputtering,
Compounds,
Superconducting magnets"
Melanoma Classification on Dermoscopy Images Using a Neural Network Ensemble Model,"We develop a novel method for classifying melanocytic tumors as benign or malignant by the analysis of digital dermoscopy images. The algorithm follows three steps: first, lesions are extracted using a self-generating neural network (SGNN); second, features descriptive of tumor color, texture and border are extracted; and third, lesion objects are classified using a classifier based on a neural network ensemble model. In clinical situations, lesions occur that are too large to be entirely contained within the dermoscopy image. To deal with this difficult presentation, new border features are proposed, which are able to effectively characterize border irregularities on both complete lesions and incomplete lesions. In our model, a network ensemble classifier is designed that combines back propagation (BP) neural networks with fuzzy neural networks to achieve improved performance. Experiments are carried out on two diverse dermoscopy databases that include images of both the xanthous and caucasian races. The results show that classification accuracy is greatly enhanced by the use of the new border features and the proposed classifier model.",
Hierarchical and Networked Vehicle Surveillance in ITS: A Survey,"Traffic surveillance has become an important topic in intelligent transportation systems (ITSs), which is aimed at monitoring and managing traffic flow. With the progress in computer vision, video-based surveillance systems have made great advances on traffic surveillance in ITSs. However, the performance of most existing surveillance systems is susceptible to challenging complex traffic scenes (e.g., object occlusion, pose variation, and cluttered background). Moreover, existing related research is mainly on a single video sensor node, which is incapable of addressing the surveillance of traffic road networks. Accordingly, we present a review of the literature on the video-based vehicle surveillance systems in ITSs. We analyze the existing challenges in video-based surveillance systems for the vehicle and present a general architecture for video surveillance systems, i.e., the hierarchical and networked vehicle surveillance, to survey the different existing and potential techniques. Then, different methods are reviewed and discussed with respect to each module. Applications and future developments are discussed to provide future needs of ITS services.",
Shortest Link Scheduling Algorithms in Wireless Networks Under the SINR Model,"This paper considers the shortest link scheduling problem in wireless networks under the signal-to-interferenceplus-noise ratio(SINR) model.We propose an O(log(lmax/lmin))approximation algorithm called shortest link scheduling with power control (SLSPC) with oblivious power assignment and an O(log1+φ(lmax/lmin)-approximation algorithm called shortest link scheduling with uniform or mean power assignment (SLSUM) with uniform or mean power control, where φ > 0 is a constant serving as a regulatory factor for slight transmit power adjustment, and where lmax and lmin denote the lengths of the longest and shortest links, respectively. We conduct a rigorous theoretical performance analysis to analyze the feasibility and approximation factors of the proposed algorithms. We also carry out an extensive comparison-based simulation study, whose results indicate that the performances of SLSPC and SLSUM are superior over the state of the art as the set of the so-called “black and gray” links, which are difficult to schedule and should be sequentially scheduled, is completely removed by adjusting the transmit power appropriately via φ. Our numerical analysis demonstrates that the approximation ratios of our algorithms are tighter than the best known ratios.",
Converter Model for Representing Converter Interfaced Generation in Large Scale Grid Simulations,"This paper addresses the positive sequence modeling of converter-based sources in commercial transient stability analysis software. A simple and computationally economical model of the converter has been developed while ensuring a reliable representation of the detailed converter behavior. This model has been implemented as a user defined model in commercial positive sequence software such as PSLF. The behavior of the proposed model in positive sequence has the same form as the behavior obtained from detailed point on wave simulation. Tests have been carried out on a three-generator nine-bus equivalent system and the 18,205 bus Western Electricity Coordinating Council system to assess the impact and performance of the converters. The behavior of these converter interfaced generation sources for various system contingencies has been investigated.","Voltage control,
Power system stability,
Reactive power,
Computational modeling,
Couplings,
Current control,
Stability analysis"
Dependence Guided Symbolic Execution,"Symbolic execution is a powerful technique for systematically exploring the paths of a program and generating the corresponding test inputs. However, its practical usage is often limited by the path explosion problem, that is, the number of explored paths usually grows exponentially with the increase of program size. In this paper, we argue that for the purpose of fault detection it is not necessary to systematically explore the paths, and propose a new symbolic execution approach to mitigate the path explosion problem by predicting and eliminating the redundant paths based on symbolic value. Our approach can achieve the equivalent fault detection capability as traditional symbolic execution without exhaustive path exploration. In addition, we develop a practical implementation called Dependence Guided Symbolic Execution (DGSE) to soundly approximate our approach. Through exploiting program dependence, DGSE can predict and eliminate the redundant paths at a reasonable computational cost. Our empirical study shows that the redundant paths are abundant and widespread in a program. Compared with traditional symbolic execution, DGSE only explores 6.96 to 96.57 percent of the paths and achieves a speedup of 1.02
×
to 49.56
×
. We have released our tool and the benchmarks used to evaluate DGSE
∗
.",
THz Frequency Modulation by Filamentary Plasma Grating,"The frequency of terahertz pulse induced by dual-color laser-induced plasma filament was measured at different positions of the filament to analyze terahertz generation processes. It was experimentally observed that the most broad frequency bandwidth was attained at the tail of laser-induced plasma filament and more higher frequency components were generated under the intervention of filamentary plasma grating, which was attributed to the increased peak electron density from inelastic collisional ionization, while another infrared pulse was focused on the plasma grating to reaccelerate preformed electrons. The results demonstrated that the electron reacceleration process played an important role in determining terahertz frequency bandwidth.","Plasmas,
Gratings,
Free electron lasers,
Electric fields,
Fluorescence,
Frequency modulation,
Biomedical optical imaging"
On Connectivity and Robustness in Random Intersection Graphs,"Random intersection graphs have received much attention recently and been used in a wide range of applications ranging from key predistribution in wireless sensor networks to modeling social networks. For these graphs, each node is equipped with a set of objects in a random manner, and two nodes have an undirected edge in between if they have at least one object in common. In this paper, we investigate connectivity and robustness in a general random intersection graph model. Specifically, we establish sharp asymptotic zero-one laws for k-connectivity and k-robustness, as well as the asymptotically exact probability of k-connectivity, for any positive integer k. The k -connectivity property quantifies how resilient is the connectivity of a graph against node or edge failures, while k-robustness measures the effectiveness of local-information-based consensus algorithms (which do not use global graph topology information) in the presence of adversarial nodes. In addition to presenting the results under the general random intersection graph model, we consider two special cases of the general model, a binomial random intersection graph and a uniform random intersection graph, which both have numerous applications as well. For these two specialized graphs, we present asymptotically exact probabilities of k-connectivity and asymptotic zero-one laws for k-robustness.","Robustness,
Silicon,
Wireless sensor networks,
Cryptography,
Social network services,
Topology,
Network topology"
Consensus+Innovations Distributed Kalman Filter With Optimized Gains,"In this paper, we address the distributed filtering and prediction of time-varying random fields represented by linear time-invariant (LTI) dynamical systems. The field is observed by a sparsely connected network of agents/sensors collaborating among themselves. We develop a Kalman filter type consensus + innovations distributed linear estimator of the dynamic field termed as Consensus+Innovations Kalman Filter. We analyze the convergence properties of this distributed estimator. We prove that the mean-squared error of the estimator asymptotically converges if the degree of instability of the field dynamics is within a prespecified threshold defined as tracking capacity of the estimator. The tracking capacity is a function of the local observation models and the agent communication network. We design the optimal consensus and innovation gain matrices yielding distributed estimates with minimized mean-squared error. Through numerical evaluations, we show that the distributed estimator with optimal gains converges faster and with approximately 3dB better mean-squared error performance than previous distributed estimators.","Kalman filters,
Temperature sensors,
Temperature measurement,
Estimation,
Physical layer,
Time-varying systems"
An Empirical Comparison of Model Validation Techniques for Defect Prediction Models,"Defect prediction models help software quality assurance teams to allocate their limited resources to the most defect-prone modules. Model validation techniques, such as
k
-fold cross-validation, use historical data to estimate how well a model will perform in the future. However, little is known about how accurate the estimates of model validation techniques tend to be. In this paper, we investigate the bias and variance of model validation techniques in the domain of defect prediction. Analysis of 101 public defect datasets suggests that 77 percent of them are highly susceptible to producing unstable results– - selecting an appropriate model validation technique is a critical experimental design choice. Based on an analysis of 256 studies in the defect prediction literature, we select the 12 most commonly adopted model validation techniques for evaluation. Through a case study of 18 systems, we find that single-repetition holdout validation tends to produce estimates with 46-229 percent more bias and 53-863 percent more variance than the top-ranked model validation techniques. On the other hand, out-of-sample bootstrap validation yields the best balance between the bias and variance of estimates in the context of our study. Therefore, we recommend that future defect prediction studies avoid single-repetition holdout validation, and instead, use out-of-sample bootstrap validation.","Predictive models,
Data models,
Analytical models,
Context,
Context modeling,
Software,
Logistics"
Underlay Spectrum Sharing Techniques With In-Band Full-Duplex Systems Using Improper Gaussian Signaling,"Sharing the spectrum with in-band full-duplex (FD) primary users (PUs) is a challenging and interesting problem in the underlay cognitive radio systems. The self-interference introduced at the primary network may dramatically impede the secondary user (SU) opportunity to access the spectrum. To tackle this problem, we use the so-called improper Gaussian signaling. Particularly, we assume the downlink transmission of a SU that uses improper Gaussian signaling while the FD PU pair implements the regular proper Gaussian signaling. First, we derive a closed-form expression and an upper bound for the SU and PUs outage probabilities, respectively. Second, we optimize the SU signal parameters to minimize its outage probability while maintaining the required PUs quality-of-service based on the average channel state information (CSI). Moreover, we provide the conditions to reap merits from employing improper Gaussian signaling at the SU. Third, we design the SU signal parameters based on the perfect knowledge of its direct link instantaneous CSI and investigate all benefits that can be achieved at both the SU and PUs. Finally, we provide some numerical results that demonstrate the advantages of using improper Gaussian signaling to access the spectrum of the FD PUs.","Receivers,
Quality of service,
Transmitters,
Cognitive radio,
Interference channels"
Fireworks Algorithm with Enhanced Fireworks Interaction,"As a relatively new metaheuristic in swarm intelligence, fireworks algorithm (FWA) has exhibited promising performance on a wide range of optimization problems. This paper aims to improve FWA by enhancing fireworks interaction in three aspects: 1) Developing a new Gaussian mutation operator to make sparks learn from more exemplars; 2) Integrating the regular explosion operator of FWA with the migration operator of biogeography-based optimization (BBO) to increase information sharing; 3) Adopting a new population selection strategy that enables high-quality solutions to have high probabilities of entering the next generation without incurring high computational cost. The combination of the three strategies can significantly enhance fireworks interaction and thus improve solution diversity and suppress premature convergence. Numerical experiments on the CEC 2015 single-objective optimization test problems show the effectiveness of the proposed algorithm. The application to a high-speed train scheduling problem also demonstrates its feasibility in real-world optimization problems.","Algorithm design and analysis,
Fireworks algorithm,
Optimization,
Computational biology,
Sparks"
Attack-Resilient State Estimation for Noisy Dynamical Systems,"Several recent incidents have clearly illustrated the susceptibility of cyberphysical systems (CPS) to attacks, raising attention to security challenges in these systems. The tight interaction between information technology and the physical world has introduced new vulnerabilities that cannot be addressed with the use of standard cryptographic security techniques. Accordingly, the problem of state estimation in the presence of sensor and actuator attacks has attracted significant attention in the past. Unlike the existing work, in this paper, we consider the problem of attackresilient state estimation in the presence of bounded-size noise. We focus on the most general model for sensor attacks where any signal can be injected via compromised sensors. Specifically, we present an I0-based state estimator that can be formulated as a mixed-integer linear program and its convex relaxation based on the I1 norm. For both attack-resilient state estimators, we derive rigorous analytic bounds on the state-estimation errors caused by the presence of noise. Our analysis shows that the worst-case error is linear with the size of the noise and, thus, the attacker cannot exploit the noise to introduce unbounded state-estimation errors. Finally, we show how the I0 and I1-based attack-resilient state estimators can be used for sound attack detection and identification; we provide conditions on the size of attack vectors that ensure correct identification of compromised sensors.","State estimation,
Security,
Symmetric matrices,
Control systems,
Noise measurement,
Standards,
Cyber-physical systems"
A Survey of App Store Analysis for Software Engineering,"App Store Analysis studies information about applications obtained from app stores. App stores provide a wealth of information derived from users that would not exist had the applications been distributed via previous software deployment methods. App Store Analysis combines this non-technical information with technical information to learn trends and behaviours within these forms of software repositories. Findings from App Store Analysis have a direct and actionable impact on the software teams that develop software for app stores, and have led to techniques for requirements engineering, release planning, software design, security and testing. This survey describes and compares the areas of research that have been explored thus far, drawing out common aspects, trends and directions future research should take to address open problems and challenges.",
Four-OAM-Mode Antenna With Traveling-Wave Ring-Slot Structure,"Based on metallic traveling-wave ring-slot structure, an easily realized four-orbital angular momentum (OAM)-mode antenna capable of generating four coaxially propagating waves with OAM modes of l = -3, -2, +2, and +3, respectively, is experimentally demonstrated at 10 GHz. The feeding network is simply implemented using two 90° hybrid couplers. A ring-focus double-reflector with a favorable focus-diameter-ratio is specially designed to gain a high directivity. The main characteristics of the antenna-such as S-parameters, directivity, and near-field radiation-are presented both in simulation and experiment. Employing a pair of four-OAM-mode antennas, the experiment shows that the near-field OAM-based radio communication channels are naturally isolated.",
Multilevel Contextual 3-D CNNs for False Positive Reduction in Pulmonary Nodule Detection,"Objective: False positive reduction is one of the most crucial components in an automated pulmonary nodule detection system, which plays an important role in lung cancer diagnosis and early treatment. The objective of this paper is to effectively address the challenges in this task and therefore to accurately discriminate the true nodules from a large number of candidates. Methods: We propose a novel method employing three-dimensional (3-D) convolutional neural networks (CNNs) for false positive reduction in automated pulmonary nodule detection from volumetric computed tomography (CT) scans. Compared with its 2-D counterparts, the 3-D CNNs can encode richer spatial information and extract more representative features via their hierarchical architecture trained with 3-D samples. More importantly, we further propose a simple yet effective strategy to encode multilevel contextual information to meet the challenges coming with the large variations and hard mimics of pulmonary nodules. Results: The proposed framework has been extensively validated in the LUNA16 challenge held in conjunction with ISBI 2016, where we achieved the highest competition performance metric (CPM) score in the false positive reduction track. Conclusion: Experimental results demonstrated the importance and effectiveness of integrating multilevel contextual information into 3-D CNN framework for automated pulmonary nodule detection in volumetric CT data. Significance: While our method is tailored for pulmonary nodule detection, the proposed framework is general and can be easily extended to many other 3-D object detection tasks from volumetric medical images, where the targeting objects have large variations and are accompanied by a number of hard mimics.","Three-dimensional displays,
Feature extraction,
Two dimensional displays,
Computed tomography,
Kernel,
Cancer,
Lungs"
"Exploiting Interference for Energy Harvesting: A Survey, Research Issues, and Challenges","Interference is one of the fundamental aspects that makes wireless communication challenging, which has attracted great research attention for decades. To solve this interference problem, many interference management (IM) techniques have been developed. Nevertheless, interference can also provide some benefits to wireless networks if it is properly utilized according to the latest research advances. Wireless signal can carry information as well as energy, and thus the redundant resource of interference can be exploited using energy harvesting (EH) to provide the power to support the operation of wireless nodes. In this paper, we provide a comprehensive survey on the research works of exploiting interference for wireless EH. Some fundamental aspects are first reviewed, including the receiver architecture, antenna dimension, network topology, and IM techniques, for wireless EH systems that exploit interference. Then, two IM techniques for wireless EH, beamforming optimization and interference alignment, are discussed in detail. In addition, several research issues are also presented, including the adversarial jamming signal and artificial noise for EH. Finally, some research challenges of exploiting interference for wireless EH are discussed.","Interference,
Energy harvesting,
Receivers,
Radio frequency,
Wireless networks,
Couplings"
A New ADS-B Authentication Framework Based on Efficient Hierarchical Identity-Based Signature with Batch Verification,"Automatic dependent surveillance-broadcast (ADS-B) has become a crucial part of next generation air traffic surveillance technology and will be mandatorily deployed for most of the airspaces worldwide by 2020. Each aircraft equipped with an ADS-B device keeps broadcasting plaintext messages to other aircraft and the ground station controllers once or twice per second. The lack of security measures in ADS-B systems makes it susceptible to different attacks. Among the various security issues, we investigate the integrity and authenticity of ADS-B messages. We propose a new framework for providing ADS-B with authentication based on three-level hierarchical identity-based signature (HIBS) with batch verification. Previous signature-based ADS-B authentication protocols focused on how to generate signatures efficiently, while our schemes can also significantly reduce the verification cost, which is critical to ADS-B systems, since at any time an ADS-B receiver may receive lots of signatures. We design two concrete schemes. The basic scheme supports partial batch verification and the extended scheme provides full batch verification. We give a formal security proof for the extended scheme. Experiment results show that our schemes with batch verification are tremendously more efficient in batch verifying n signatures than verifying n signatures independently. For example, the running time of verifying 100 signatures is 502 and 484 ms for the basic scheme and the extended scheme respectively, while the time is 2500 ms if verifying the signatures independently.","Aircraft,
Authentication,
Aerospace control,
Receivers,
Cryptography,
Phase shift keying"
We Can Track You if You Take the Metro: Tracking Metro Riders Using Accelerometers on Smartphones,"Motion sensors, especially accelerometers, on smartphones have been discovered to be a powerful side channel for spying on users' privacy. In this paper, we reveal a new accelerometer-based side-channel attack which is particularly serious: malware on smartphones can easily exploit the accelerometers to trace metro riders stealthily. We first address the challenge to automatically filter out metro-related data from a mass of miscellaneous accelerometer readings, and then propose a basic attack which leverages an ensemble interval classifier built from supervised learning to infer the riding trajectory of the user. As the supervised learning requires the attacker to collect labeled training data for each station interval, this attack confronts the scalability problem in big cities with a huge metro network. We thus further present an improved attack using semi-supervised learning, which only requires the attacker to collect labeled data for a very small number of distinctive station intervals. We conduct real experiments on a large self-built dataset, which contains more than 120 h of data collected from six metro lines of three major cities. The results show that the inferring accuracy could reach 89% and 94% if the user takes the metro for four and six stations, respectively. We finally discuss possible countermeasures against the proposed attack.","Accelerometers,
Smart phones,
Sensors,
Malware,
Supervised learning,
Urban areas,
Feature extraction"
Reliability Evaluation of Large Scale Battery Energy Storage Systems,"This paper analyzes the reliability of large scale battery storage systems consisting of multiple battery modules. The whole system reliability assessment is based on the reliability evaluation of system components including individual battery modules and power electronic converters. In order to evaluate the reliability of a battery module, a reliability model based on the state of health of individual battery cells is introduced. The state of health of a battery cell is calculated based on the capacity fade of the cell using a weighted Ampere-hour throughput method. A universal generating function-based method is then introduced to evaluate the reliability of the battery module. The reliability model of dc/ac power electronic converters is also presented in this paper. The reliability analysis is conducted for battery storage systems with different system configurations and management strategies, and the influence of system configuration on the reliability of battery system is studied. Comparative studies are conducted for a classic battery energy storage system (BESS) and a reconfigurable BESS (RBESS) to demonstrate the advantages of having a reconfigurable system topology. The comparison results show that the proposed RBESS has higher system reliability and more power outputs than the classic BESS.","Batteries,
Reliability,
Power electronics,
Phase transformers,
Power transformers,
Power grids"
Adaptive Boundary Iterative Learning Control for an Euler-Bernoulli Beam System With Input Constraint,"This paper addresses the vibration control and the input constraint for an Euler-Bernoulli beam system under aperiodic distributed disturbance and aperiodic boundary disturbance. Hyperbolic tangent functions and saturation functions are adopted to tackle the input constraint. A restrained adaptive boundary iterative learning control (ABILC) law is proposed based on a time-weighted Lyapunov-Krasovskii-like composite energy function. In order to deal with the uncertainty of a system parameter and reject the external disturbances, three adaptive laws are designed and learned in the iteration domain. All the system states of the closed-loop system are proved to be bounded in each iteration. Along the iteration axis, the displacements asymptotically converge toward zero. Simulation results are provided to illustrate the effectiveness of the proposed ABILC scheme.",
Finding Equilibria in the Pool-Based Electricity Market With Strategic Wind Power Producers and Network Constraints,"This paper proposes a model to find the equilibria in the short-term electricity market with large-scale wind power penetration. The behavior of each strategic player is modeled through a two-stage mathematical problem with equilibrium constraints (MPEC), where the upper-level problem maximizes the profit of the strategic player and the lower-level problem describes the clearing processes of the day-ahead and real-time markets while considering the network constraints. The joint solution of all the MPECs constitutes an equilibrium problem with equilibrium constraints (EPEC). The uncertain wind power production and demand are represented by a set of plausible scenarios. By using the duality theory and Karush-Kuhn-Tucker condition, each MPEC is transferred into a mixed-integer linear programing problem. The Nash equilibria of the electricity market are obtained by solving the EPEC using Game theory and the diagonalization algorithm. Case studies are performed to show the effectiveness of the proposed model.",
A multi-core CPU and many-core GPU based fast parallel shuffled complex evolution global optimization approach,"In the field of hydrological modelling, the global and automatic parameter calibration has been a hot issue for many years. Among automatic parameter optimization algorithms, the shuffled complex evolution developed at the University of Arizona (SCE-UA) is the most successful method for stably and robustly locating the global “best” parameter values. Ever since the invention of the SCE-UA, the profession suddenly has a consistent way to calibrate watershed models. However, the computational efficiency of the SCE-UA significantly deteriorates when coping with big data and complex models. For the purpose of solving the efficiency problem, the recently emerging heterogeneous parallel computing (parallel computing by using the multi-core CPU and many-core GPU) was applied in the parallelization and acceleration of the SCE-UA. The original serial and proposed parallel SCE-UA were compared to test the performance based on the Griewank benchmark function. The comparison results indicated that the parallel SCE-UA converged much fasterthan the serial version and its optimization accuracy was the same as the serial version. It has a promising application prospect in the field of fast hydrological model parameter optimization.",
Grey Wolf Optimizer Algorithm-Based Tuning of Fuzzy Control Systems With Reduced Parametric Sensitivity,"This paper proposes an innovative tuning approach for fuzzy control systems (CSs) with a reduced parametric sensitivity using the Grey Wolf Optimizer (GWO) algorithm. The CSs consist of servo system processes controlled by Takagi-Sugeno-Kang proportional-integral fuzzy controllers (TSK PI-FCs). The process models have second-order dynamics with an integral component, variable parameters, a saturation, and dead-zone static nonlinearity. The sensitivity analysis employs output sensitivity functions of the sensitivity models defined with respect to the parametric variations of the processes. The GWO algorithm is used in solving the optimization problems, where the objective functions include the output sensitivity functions. GWO's motivation is based on its low-computational cost. The tuning approach is validated in an experimental case study of a position control for a laboratory nonlinear servo system, and TSK PI-FCs with a reduced process small time constant sensitivity are offered.","Tuning,
Sensitivity,
Servomotors,
Heuristic algorithms,
Process control,
Fuzzy control,
Optimization"
A Parallel Random Forest Algorithm for Big Data in a Spark Cloud Computing Environment,"With the emergence of the big data age, the issue of how to obtain valuable knowledge from a dataset efficiently and accurately has attracted increasingly attention from both academia and industry. This paper presents a Parallel Random Forest (PRF) algorithm for big data on the Apache Spark platform. The PRF algorithm is optimized based on a hybrid approach combining dataparallel and task-parallel optimization. From the perspective of data-parallel optimization, a vertical data-partitioning method is performed to reduce the data communication cost effectively, and a data-multiplexing method is performed is performed to allow the training dataset to be reused and diminish the volume of data. From the perspective of task-parallel optimization, a dual parallel approach is carried out in the training process of RF, and a task Directed Acyclic Graph (DAG) is created according to the parallel training process of PRF and the dependence of the Resilient Distributed Datasets (RDD) objects. Then, different task schedulers are invoked for the tasks in the DAG. Moreover, to improve the algorithm's accuracy for large, high-dimensional, and noisy data, we perform a dimension-reduction approach in the training process and a weighted voting approach in the prediction process prior to parallelization. Extensive experimental results indicate the superiority and notable advantages of the PRF algorithm over the relevant algorithms implemented by Spark MLlib and other studies in terms of the classification accuracy, performance, and scalability. With the expansion of the scale of the random forest model and the Spark cluster, the advantage of the PRF algorithm is more obvious.",
A Brain-Computer Interface Based on a Few-Channel EEG-fNIRS Bimodal System,"With the development of the wearable brain-computer interface (BCI), a few-channel BCI system is necessary for its application to daily life. In this paper, we proposed a bimodal BCI system that uses only a few channels of electroencephalograph (EEG) and functional near-infrared spectroscopy (fNIRS) signals to obtain relatively high accuracy. We developed new approaches for signal acquisition and signal processing to improve the performance of this few-channel BCI system. At the signal acquisition stage, source analysis was applied for both EEG and fNIRS signals to select the optimal channels for bimodal signal collection. At the feature extraction stage, phase-space reconstruction was applied to the selected three-channel EEG signals to expand them into multichannel signals, thus allowing the use of the traditional effective common spatial pattern to extract EEG features. For the fNIRS signal, the Hurst exponents for the selected ten channels were calculated and composed of the fNIRS data feature. At the classification stage, EEG and fNIRS features were joined and classified with the support vector machine. The averaged classification accuracy of 12 participants was 81.2% for the bimodal EEG-fNIRS signals, which was significantly higher than that for either single modality.","Electroencephalography,
Detectors,
Spatial resolution,
Electrooculography,
Nickel,
Scalp"
Output Constraint Transfer for Kernelized Correlation Filter in Tracking,"The kernelized correlation filter (KCF) is one of the state-of-the-art object trackers. However, it does not reasonably model the distribution of correlation response during tracking process, which might cause the drifting problem, especially when targets undergo significant appearance changes due to occlusion, camera shaking, and/or deformation. In this paper, we propose an output constraint transfer (OCT) method that by modeling the distribution of correlation response in a Bayesian optimization framework is able to mitigate the drifting problem. OCT builds upon the reasonable assumption that the correlation response to the target image follows a Gaussian distribution, which we exploit to select training samples and reduce model uncertainty. OCT is rooted in a new theory which transfers data distribution to a constraint of the optimized variable, leading to an efficient framework to calculate correlation filters. Extensive experiments on a commonly used tracking benchmark show that the proposed method significantly improves KCF, and achieves better performance than other state-of-the-art trackers. To encourage further developments, the source code is made available.",
The Pictures We Like Are Our Image: Continuous Mapping of Favorite Pictures into Self-Assessed and Attributed Personality Traits,"Flickr allows its users to tag the pictures they like as “favorite”. As a result, many users of the popular photo-sharing platform produce galleries of favorite pictures. This article proposes new approaches, based on Computational Aesthetics, capable to infer the personality traits of Flickr users from the galleries above. In particular, the approaches map low-level features extracted from the pictures into numerical scores corresponding to the Big-Five Traits, both self-assessed and attributed. The experiments were performed over 60,000 pictures tagged as favorite by 300 users (the PsychoFlickr Corpus). The results show that it is possible to predict beyond chance both self-assessed and attributed traits. In line with the state-of-the-art of Personality Computing, these latter are predicted with higher effectiveness (correlation up to 0.68 between actual and predicted traits).","Feature extraction,
Correlation,
Internet,
Facebook,
Media,
Image color analysis"
Cooperative Strategies for Challenged Networks and Applications: A Survey,"Wireless ad hoc networks use mobile devices to deliver services supported by high-speed network connections and high-speed data transmissions in real time. These devices (network nodes) typically act as the network infrastructure to forward data to other nodes from a source to the destination. However, several constraints (e.g., processor, energy consumption, and bandwidth) affect the overall network performance. Cooperation strategies have been considered as a solution to such network limitations and constraints. Recent studies have presented cooperation mechanisms as a solution to unstable network infrastructures where mobile nodes cooperate with each other, forwarding data and performing all the networking functionalities. This paper presents a comprehensive review of the state of the art on cooperation strategies and algorithms for mobile ad hoc networks and delay-tolerant networks. These challenged networks frequently comprise situations where traditional Internet protocols fail to effectively provide desired or expected communication. This paper focuses on cooperation incentive-based approaches for network architectures that support mobile devices and are challenged by mobility constraints such as battery and storage capacity, broadcast constraints, interferences, disconnections, noises, limited bandwidths, and network delays. The surveyed approaches' merits and weaknesses are discussed, and open issues are identified. Finally, conclusions are detailed.","Proposals,
Wireless networks,
Mobile handsets,
Performance evaluation,
Mobile ad hoc networks,
Protocols,
Relays"
A Current Limiting Strategy to Improve Fault Ride-Through of Inverter Interfaced Autonomous Microgrids,"With high penetration of distributed energy resources, fault management strategy is of great importance for the distribution network operation. The objective of this paper is to propose a current and voltage limiting strategy to enhance fault ride-through (FRT) capability of inverter-based islanded microgrids (MGs) in which the effects of inverter control system and inverter topology (four/three-wire) are considered. A three-phase voltage-sourced inverter with multi-loop control system implemented in synchronous, stationary, and natural reference frames is employed in this paper for both four- and three-wire configurations. The proposed strategy provides high voltage and current quality during overcurrent conditions, which is necessary for sensitive loads. Several time-domain simulation studies are conducted to investigate the FRT capability of the proposed strategy against both asymmetrical and symmetrical faults. Moreover, the proposed method is tested on the CIGRE benchmark MG to demonstrate the effectiveness of the proposed limiting strategy.","Inverters,
Limiting,
Voltage control,
Density estimation robust algorithm,
Inductors,
Control systems,
Topology"
Drug-Target Interaction Prediction with Graph Regularized Matrix Factorization,"Experimental determination of drug-target interactions is expensive and time-consuming. Therefore, there is a continuous demand for more accurate predictions of interactions using computational techniques. Algorithms have been devised to infer novel interactions on a global scale where the input to these algorithms is a drug-target network (i.e., a bipartite graph where edges connect pairs of drugs and targets that are known to interact). However, these algorithms had difficulty predicting interactions involving new drugs or targets for which there are no known interactions (i.e., “orphan” nodes in the network). Since data usually lie on or near to low-dimensional non-linear manifolds, we propose two matrix factorization methods that use graph regularization in order to learn such manifolds. In addition, considering that many of the non-occurring edges in the network are actually unknown or missing cases, we developed a preprocessing step to enhance predictions in the “new drug” and “new target” cases by adding edges with intermediate interaction likelihood scores. In our cross validation experiments, our methods achieved better results than three other state-of-the-art methods in most cases. Finally, we simulated some “new drug” and “new target” cases and found that GRMF predicted the left-out interactions reasonably well.",
Dual-frequency Optoelectronic Oscillator for Thermal-Insensitive Interrogation of a FBG Strain Sensor,"We propose and experimentally demonstrate an approach to perform high-speed and high-resolution thermal-insensitive interrogation of a fiber Bragg grating (FBG) strain sensor based on a dual-frequency optoelectronic oscillator (OEO). Two phase-shifted FBGs (PSFBGs) are incorporated in the OEO loop to implement a microwave photonic filter with two passbands based on phase modulation and phase-modulation to intensity-modulation conversion, to generate two microwave signals with their frequencies determined by the center frequencies of the two passbands. When one of the PSFBG is experiencing a strain, a beat frequency between the two microwave signals that is linearly proportional to the strain applied to the sensing PSFBG is obtained. By monitoring the beat frequency using a digital signal processor, the strain is measured. The proposed approach is experimentally demonstrated. High-resolution sensing with a resolution of
0.83 με
that is thermal insensitive is demonstrated.","Strain,
Temperature measurement,
Microwave photonics,
Passband,
Temperature sensors,
Optical reflection"
Adaptive Event-Triggered Control Based on Heuristic Dynamic Programming for Nonlinear Discrete-Time Systems,"This paper presents the design of a novel adaptive event-triggered control method based on the heuristic dynamic programming (HDP) technique for nonlinear discrete-time systems with unknown system dynamics. In the proposed method, the control law is only updated when the event-triggered condition is violated. Compared with the periodic updates in the traditional adaptive dynamic programming (ADP) control, the proposed method can reduce the computation and transmission cost. An actor-critic framework is used to learn the optimal event-triggered control law and the value function. Furthermore, a model network is designed to estimate the system state vector. The main contribution of this paper is to design a new trigger threshold for discrete-time systems. A detailed Lyapunov stability analysis shows that our proposed event-triggered controller can asymptotically stabilize the discrete-time systems. Finally, we test our method on two different discrete-time systems, and the simulation results are included.","Discrete-time systems,
Dynamic programming,
Neural networks,
System dynamics,
Optimal control,
Stability analysis"
Faster-Than-Nyquist Signaling: An Overview,"Faster-than-Nyquist (FTN) signaling can improve the bandwidth utilization. In this paper, we will provide a comprehensive survey on the topic. The history and the applications of FTN signaling are first introduced. Then, the basic principles and the system framework of FTN signaling are presented. Next, more details on transmitter and receiver optimization are discussed. Finally, the current research challenges on FTN signaling are identified and conclusions are provided.","Bandwidth,
Receivers,
OFDM,
Frequency-domain analysis,
Transmitters,
Communication systems,
Modulation"
Modeling and Analysis of Uplink Non-Orthogonal Multiple Access in Large-Scale Cellular Networks Using Poisson Cluster Processes,"Using the theory of Poisson cluster process (PCP), this paper provides a framework to analyze multi-cell uplink non-orthogonal multiple access (NOMA) systems. Specifically, we characterize the rate coverage probability of an NOMA user who is at rank m (in terms of the distance from its serving base station) among all users in a cell and the mean rate coverage probability of all users in a cell. Since the signal-to-interference-plus-noise ratio of the mth user relies on efficient successive interference cancellation (SIC), we consider three scenarios, i.e., perfect SIC (in which the signals of m - 1 interferers who are stronger than the mth user are decoded successfully), imperfect SIC (in which the signals of m - 1 interferers who are stronger than the mth user may or may not be decoded successfully), and imperfect worst case SIC (in which the decoding of the signal of the mth user is always unsuccessful whenever the decoding of its relative m -1 stronger users is unsuccessful). To derive the rate coverage expressions, we first characterize the Laplace transforms of the intra-cluster interferences in closed-form considering various SIC scenarios. The Laplace transform of the inter-cluster interference is then characterized by exploiting distance distributions from geometric probability. The derived expressions are customized for an equivalent OMA system. Finally, numerical results are presented to validate the derived expressions. The worst case SIC assumption provides remarkable simplifications in the mathematical analysis and is found to be highly accurate for higher user target rate requirements. A comparison of Poisson point process-based and PCP-based modeling is also conducted.","NOMA,
Interference,
Silicon carbide,
Uplink,
Downlink,
Analytical models,
Throughput"
Tri-Band Circularly Polarized Annular Slot Antenna for GPS and CNSS Applications,A single-feed tri-band circularly polarized (CP) annular slot antenna is presented. The antenna structure is composed of two non-concentric annular slots that are fed by an L-shaped series step impedance microstrip line configuration. The proposed antenna is designed to operate at the L1 & L2 bands of the Global Positioning System (GPS) and the frequency band of the Compass Navigation Satellite System (CNSS). The measured results show that the impedance bandwidths are good for all bands. And the radiation patterns with good CP characteristics are obtained at the three resonant frequencies.,"Slot antennas,
Global Positioning System,
Microstrip antennas,
Resonant frequency,
Impedance,
Dual band"
Learning Sampling Distributions for Efficient Object Detection,"Object detection is an important task in computer vision and machine intelligence systems. Multistage particle windows (MPW), proposed by Gualdi et al., is an algorithm of fast and accurate object detection. By sampling particle windows (PWs) from a proposal distribution (PD), MPW avoids exhaustively scanning the image. Despite its success, it is unknown how to determine the number of stages and the number of PWs in each stage. Moreover, it has to generate too many PWs in the initialization step and it unnecessarily regenerates too many PWs around object-like regions. In this paper, we attempt to solve the problems of MPW. An important fact we used is that there is a large probability for a randomly generated PW not to contain the object because the object is a sparse event relative to the huge number of candidate windows. Therefore, we design a PD so as to efficiently reject the huge number of nonobject windows. Specifically, we propose the concepts of rejection, acceptance, and ambiguity windows and regions. Then, the concepts are used to form and update a dented uniform distribution and a dented Gaussian distribution. This contrasts to MPW which utilizes only on region of support. The PD of MPW is acceptance-oriented whereas the PD of our method (called iPW) is rejection-oriented. Experimental results on human and face detection demonstrate the efficiency and the effectiveness of the iPW algorithm. The source code is publicly accessible.","Feature extraction,
Object detection,
Support vector machines,
Gaussian distribution,
Algorithm design and analysis,
Cybernetics,
Proposals"
Q-Learning-Based Vulnerability Analysis of Smart Grid Against Sequential Topology Attacks,"Recent studies on sequential attack schemes revealed new smart grid vulnerability that can be exploited by attacks on the network topology. Traditional power systems contingency analysis needs to be expanded to handle the complex risk of cyber-physical attacks. To analyze the transmission grid vulnerability under sequential topology attacks, this paper proposes a Q-learning-based approach to identify critical attack sequences with consideration of physical system behaviors. A realistic power flow cascading outage model is used to simulate the system behavior, where attacker can use the Q-learning to improve the damage of sequential topology attack toward system failures with the least attack efforts. Case studies based on three IEEE test systems have demonstrated the learning ability and effectiveness of Q-learning-based vulnerability analysis.","Smart grids,
Topology,
Security,
Power system faults,
Power system protection"
Real-Time Misbehavior Detection and Mitigation in Cyber-Physical Systems Over WLANs,"In cyber-physical system (CPS) over IEEE 802.11e-based wireless local area networks (WLANs), a misbehaving node can gain significant advantage over other normal nodes in terms of resource sharing by deliberately manipulating its protocol parameters. Due to the random spectrum-access nature of the protocol, it is challenging to detect the misbehaving node accurately and in real-time. Moreover, many existing misbehavior detectors, primarily designed for traditional IEEE 802.11 networks, become inapplicable in IEEE 802.11e networks with heterogeneous network configurations. In this paper, we propose novel real-time and light-weight countermeasures including a hybrid-share misbehavior detector and a packet-dropping-based misbehavior mitigation mechanism for IEEE 802.11e-based CPS. We develop mathematical models for the performance of the proposed detector and mitigation mechanisms. Extensive simulation results show that the proposed mechanisms can achieve a high detection rate and punish a misbehaving node with a high packet dropping rate.","Detectors,
IEEE 802.11e Standard,
Throughput,
Real-time systems,
Analytical models,
Protocols"
Convexity Shape Prior for Binary Segmentation,"Convexity is a known important cue in human vision. We propose shape convexity as a new high-order regularization constraint for binary image segmentation. In the context of discrete optimization, object convexity is represented as a sum of three-clique potentials penalizing any 1-0-1 configuration on all straight lines. We show that these non-submodular potentials can be efficiently optimized using an iterative trust region approach. At each iteration the energy is linearly approximated and globally optimized within a small trust region around the current solution. While the quadratic number of all three-cliques is prohibitively high, we design a dynamic programming technique for evaluating and approximating these cliques in linear time. We also derive a second order approximation model that is more accurate but computationally intensive. We discuss limitations of our local optimization and propose gradual non-submodularization scheme that alleviates some limitations. Our experiments demonstrate general usefulness of the proposed convexity shape prior on synthetic and real image segmentation examples. Unlike standard second-order length regularization, our convexity prior does not have shrinking bias, and is robust to changes in scale and parameter selection.","Shape,
Optimization,
Image segmentation,
Dynamic programming,
Computational modeling,
Standards,
Context"
Arousal and Valence Recognition of Affective Sounds Based on Electrodermal Activity,"Physiological sensors and interfaces for mental healthcare are becoming of great interest in research and commercial fields. Specifically, biomedical sensors and related ad hoc signal processing methods can be profitably used for supporting objective, psychological assessments. However, a simple system able to automatically classify the emotional state of a healthy subject is still missing. To overcome this important limitation, we here propose the use of convex optimization-based electrodermal activity (EDA) framework and clustering algorithms to automatically discern arousal and valence levels induced by affective sound stimuli. EDA recordings were gathered from 25 healthy volunteers, using only one EDA sensor to be placed on fingers. Standardized stimuli were chosen from the International Affective Digitized Sound System database, and grouped into four different levels of arousal (i.e., the levels of emotional intensity) and two levels of valence (i.e., how unpleasant/pleasant a sound can be perceived). Experimental results demonstrated that our system is able to achieve a recognition accuracy of 77.33% on the arousal dimension, and 84% on the valence dimension.","Sensors,
Skin,
Feature extraction,
Extraterrestrial measurements,
Pattern recognition,
Autoregressive processes,
Audio systems"
Wideband Balanced-to-Unbalanced Filtering Power Dividers Based on Coupled Lines,"Three novel wideband balanced-to-unbalanced filtering power dividers based on coupled lines are proposed in this paper. Multifunctional power dividers can replace various cascaded single devices to decrease integration mismatching loss and circuit size. The wideband response can be easily realized by the coupled lines structures. To further improve the differential-mode passband selectivity, open/shorted coupled lines and half-wavelength open stubs are applied to introduce two transmission zeros near the passband, respectively. In addition, a resistor in the middle of two single-ended ports can be used to realize isolation between out ports. To verify the proposed concepts, three prototypes of wideband balanced-to-unbalanced filtering power dividers operating at 2 GHz are designed and fabricated with the 4-dB differential-mode bandwidths of 80.5%, 71.5%, and 80%. All the structures show good performances for differential-mode out-of-band suppression, common-mode suppression, and isolation.","Power dividers,
Wideband,
Passband,
Ports (Computers),
Equivalent circuits,
Filtering"
Optimal Placement of Dynamic Var Sources by Using Empirical Controllability Covariance,"In this paper, the empirical controllability covariance (ECC), which is calculated around the considered operating condition of a power system, is applied to quantify the degree of controllability of system voltages under specific dynamic var source locations. An optimal dynamic var source placement method addressing fault-induced delayed voltage recovery (FIDVR) issues is further formulated as an optimization problem that maximizes the determinant of ECC. The optimization problem is effectively solved by the NOMAD solver, which implements the mesh adaptive direct search algorithm. The proposed method is tested on an NPCC 140-bus system and the results show that the proposed method with fault specified ECC can solve the FIDVR issue caused by the most severe contingency with fewer dynamic var sources than the voltage sensitivity index (VSI)-based method. The proposed method with fault unspecified ECC does not depend on the settings of the contingency and can address more FIDVR issues than the VSI method when placing the same number of SVCs under different fault durations. It is also shown that the proposed method can help mitigate voltage collapse.","Reactive power,
Power system dynamics,
Controllability,
Nonlinear systems,
Sensitivity,
Indexes,
Optimization"
Oxygen Adsorption Effect of Amorphous InGaZnO Thin-Film Transistors,"The effect of oxygen adsorption at the back channel of a-IGZO thin-film transistors (TFTs) is investigated. It is shown that for TFTs with the channel layer sputter-deposited at a high O2/Ar flow rate ratio (RO/Ar), the threshold voltages in vacuum and O2 ambient do not show any difference; for devices fabricated at a low RO/Ar, the threshold voltages in vacuum are lower than those in O2. In addition, the devices in O2 show a more significant threshold voltage shift than those in vacuum do under a positive gate bias stress. The surface-state model is used to explain this observation. It is inferred that the oxygen adsorptions are physical and chemical, respectively, in the high-and low-RO/Ar cases, and the transition from physical to chemical adsorption occurs when a positive gate bias stress is applied.","Adsorption,
Logic gates,
Stress,
Thin film transistors,
Threshold voltage,
Chemicals,
Films"
Transparent Computing: A Promising Network Computing Paradigm,"With the emergence of cloud computing, big data, and mobile networks, the computing paradigm and related technologies have experienced significant development over the past 10 years. Concomitantly, the prevalence of smartphones, wearable devices, and mobile applications has been constantly changing our daily lives. Terminals are evolving toward lightweight, intelligent, highly secure, and convenient devices. As an emerging computing paradigm, cloud computing focuses primarily on providing services through servers and networks but without addressing the inherent challenges and concerns of user terminals, such as energy efficiency, security, and cross-platform compatibility. Consequently, these challenges remain in the era of cloud computing and big data. In this article, the authors present a review to a promise computing paradigm: transparent computing. Similar to cloud computing, transparent computing stores software and user data at specific servers. More specifically, it extends the bus transmission in traditional computer architecture to the network. User interruptions at a terminal are redirected to a specific server through a network connection to request the corresponding instructions and data, which are subsequently executed at the terminal in a page-streaming pattern. By adopting this computing paradigm, user terminals are becoming more lightweight (nearly bare) with enhanced security (dumping after using), improved energy efficiency (no terminal storage), and cross-platform capability (low layer compatibility). This article presents a comprehensive survey and indicates future directions of transparent computing, from traditional terminals to mobile devices.","Servers,
Mobile computing,
Pervasive computing,
Computer hardware,
Heterogeneous networks,
Mobile communications,
Context-aware services,
Big data,
Cloud computing"
SleepSense: A Noncontact and Cost-Effective Sleep Monitoring System,"Quality of sleep is an important indicator of health and well being. Recent developments in the field of in-home sleep monitoring have the potential to enhance a person's sleeping experience and contribute to an overall sense of well being. Existing in-home sleep monitoring devices either fail to provide adequate sleep information or are obtrusive to use. To overcome these obstacles, a noncontact and cost-effective sleep monitoring system, named SleepSense, is proposed for continuous recognition of the sleep status, including on-bed movement, bed exit, and breathing section. SleepSense consists of three parts: a Doppler radar-based sensor, a robust automated radar demodulation module, and a sleep status recognition framework. Herein, several time-domain and frequency-domain features are extracted for the sleep recognition framework. A prototype of SleepSense is presented and evaluated using two sets of experiments. In the short-term controlled experiment, the SleepSense achieves an overall 95.1% accuracy rate in identifying various sleep status. In the 75-minute sleep study, SleepSense demonstrates wide usability in real life. The error rate for breathing rate extraction in this study is only 6.65%. These experimental results indicate that SleepSense is an effective and promising solution for in-home sleep monitoring.","Sleep apnea,
Monitoring,
Doppler radar,
Feature extraction,
Biomedical monitoring,
Demodulation"
Robust Frequency Regulation Capacity Scheduling Algorithm for Electric Vehicles,"Electric vehicles (EVs) have the potential to provide frequency regulation service to an independent system operator (ISO) by changing their real-time charging or discharging power according to an automatic generation control (AGC) signal. Recently, the Federal Energy Regulatory Commission has issued Order 755 to ISOs to introduce a performance-based compensation scheme in the frequency regulation market. The goal is to provide economic incentives for fast ramping resources such as EVs to participate in the market. In this paper, we model the EV frequency regulation service under the performance-based compensation scheme. Thereby, a robust optimization framework is adopted for the formulation of a frequency regulation capacity scheduling problem. Our problem formulation takes into account the performance-based compensation scheme, the random AGC signal, and the dynamic arrival and departure times of the EVs. We propose an efficient algorithm to solve the formulated problem. Simulation results show that the proposed algorithm improves the revenue under the performance-based compensation scheme compared with a benchmark algorithm.","Frequency control,
Automatic generation control,
ISO,
Robustness,
Real-time systems,
Optimization,
Heuristic algorithms"
Integration of Global and Local Metrics for Domain Adaptation Learning Via Dimensionality Reduction,"Domain adaptation learning (DAL) investigates how to perform a task across different domains. In this paper, we present a kernelized local-global approach to solve domain adaptation problems. The basic idea of the proposed method is to consider the global and local information regarding the domains (e.g., maximum mean discrepancy and intraclass distance) and to convert the domain adaptation problem into a bi-object optimization problem via the kernel method. A solution for the optimization problem will help us identify a latent space in which the distributions of the different domains will be close to each other in the global sense, and the local properties of the labeled source samples will be preserved. Therefore, classic classification algorithms can be used to recognize unlabeled target domain data, which has a significant difference on the source samples. Based on the analysis, we validate the proposed algorithm using four different sources of data: synthetic, textual, object, and facial image. The experimental results indicate that the proposed method provides a reasonable means to improve DAL algorithms.","Testing,
Training,
Kernel,
Optimization,
Algorithm design and analysis,
Yttrium,
Measurement"
"A Scalable, Partially Configurable Optical Switch for Data Center Networks","Optical circuit switching may be instrumental in meeting the cost, energy, and aggregate bandwidth requirements of future data center networks. However, conventional MEMS beam-steering cross-connects cannot provide submillisecond switching with the port count necessary for data centers. Here, we investigate a novel noncrossbar selector switch architecture and pupil-division switching layout to improve optical switching performance by relaxing the requirement of arbitrary switch configurability. This architecture and switch design enable MEMS beam-steering micromirrors to scale to microsecond response speeds while supporting high port count and low loss switching, and can realize a number of useful interconnection topologies. We present the design, fabrication, and experimental characterization of a proof-of-principle prototype using a single comb-driven MEMS mirror to achieve 150 μs switching of 61 ports between four preprogrammed interconnection mappings. We demonstrate the scalability of this switch architecture with a detailed optical design of a 2048-port selector switch with 20 μs switching time.","Optical switches,
Ports (Computers),
Optical fibers,
Micromirrors,
Optical fiber devices"
Optimized Day-Ahead Pricing With Renewable Energy Demand-Side Management for Smart Grids,"Internet of Things (IoT) has recently emerged as an enabling technology for context-aware and interconnected “smart things.” Those smart things along with advanced power engineering and wireless communication technologies have realized the possibility of next generation electrical grid, smart grid, which allows users to deploy smart meters, monitoring their electric condition in real time. At the same time, increased environmental consciousness is driving electric companies to replace traditional generators with renewable energy sources which are already productive in user's homes. One of the most incentive ways is for electric companies to institute electricity buying-back schemes to encourage end users to generate more renewable energy. Different from the previous works, we consider renewable energy buying-back schemes with dynamic pricing to achieve the goal of energy efficiency for smart grids. We formulate the dynamic pricing problem as a convex optimization dual problem and propose a day-ahead time-dependent pricing scheme in a distributed manner which provides increased user privacy. The proposed framework seeks to achieve maximum benefits for both users and electric companies. To our best knowledge, this is one of the first attempts to tackle the time-dependent problem for smart grids with consideration of environmental benefits of renewable energy. Numerical results show that our proposed framework can significantly reduce peak time loading and efficiently balance system energy distribution.","Pricing,
Renewable energy sources,
Companies,
Smart grids,
Carbon dioxide,
Energy storage,
Real-time systems"
Common-Mode EMI Noise Modeling and Reduction With Balance Technique for Three-Level Neutral Point Clamped Topology,"This paper develops a common-mode (CM) electromagnetic interference noise model for a three-level neutral point clamped topology. Compared with existing modeling techniques with only one CM noise source, two extra important CM noise sources and their characteristics are identified and derived for an accurate CM noise model. The impedances of CM noise path are also extracted. Based on the developed CM noise model, the CM noise spectrum can be well predicted. The effect of CM noise paths on CM noise is discussed based on two different LCL filters. A CM noise reduction technique with a balance bridge at a large impedance ratio is proposed based on the developed model. The technique can be easily implemented at low cost. Both simulations and experiments validate the developed theory and technique.","Electromagnetic interference,
Topology,
Capacitance,
Switches,
Time-domain analysis,
Legged locomotion,
Impedance"
A Hierarchical Fused Fuzzy Deep Neural Network for Data Classification,"Deep learning (DL) is an emerging and powerful paradigm that allows large-scale task-driven feature learning from big data. However, typical DL is a fully deterministic model that sheds no light on data uncertainty reductions. In this paper, we show how to introduce the concepts of fuzzy learning into DL to overcome the shortcomings of fixed representation. The bulk of the proposed fuzzy system is a hierarchical deep neural network that derives information from both fuzzy and neural representations. Then, the knowledge learnt from these two respective views are fused altogether forming the final data representation to be classified. The effectiveness of the model is verified on three practical tasks of image categorization, high-frequency financial data prediction and brain MRI segmentation that all contain high level of uncertainties in the raw data. The fuzzy dDL paradigm greatly outperforms other nonfuzzy and shallow learning approaches on these tasks.","Biological neural networks,
Uncertainty,
Fuzzy logic,
Neurons,
Tuning,
Fuzzy systems,
Magnetic resonance imaging"
Multimedia Sensing as a Service (MSaaS): Exploring Resource Saving Potentials of at Cloud-Edge IoT and Fogs,"With the popularity of multimedia sensing at cloud edges and the reducing cost of the Internet of Things (IoT) fog devices and systems, new challenges have been posed to efficiently deal with the big data multimedia traffic generated from IoT sensing units. Specifically, in this paper we introduce the concept of multimedia sensing as a service (MSaaS), and propose a generalized premium prioritization-based quality of experience paradigm for wireless big-volumes-of-data (BVDs) multimedia communications, with significant energy saving potentials for future multimedia IoT devices and systems. The key contribution of this new framework is its data diversity flexibility at the application layer, which could be flexibly adopted by future multimedia communication systems. Data dependencies in spatial, frequency and temporal domains are analyzed, and interaction with uplink resource allocation optimization are investigated with regards to wireless communication energy cost estimation. Extensive simulation results demonstrate that the proposed prioritization-based communication paradigm has significant energy saving potentials for BVD MSaaS wireless multimedia communications at cloud edges and fogs.",
Construction of Synergistic Potential Functions on SO(3) With Application to Velocity-Free Hybrid Attitude Stabilization,"We propose a systematic and comprehensive procedure for the construction of synergistic potential functions, which are instrumental in hybrid control design on SO(3). A new map, via angular warping on SO(3), is introduced to generate a central family of potential functions allowing an explicit determination of the critical points and the synergistic gap. Some optimization results on the synergistic gap are also provided. The proposed synergistic potential functions are used for the design of a global velocity-free hybrid attitude stabilization scheme relying solely on inertial vector measurements.","Attitude control,
Asymptotic stability,
Switches,
Velocity measurement,
Manifolds,
Robustness"
Tensor Decomposition for Signal Processing and Machine Learning,"Tensors or multiway arrays are functions of three or more indices (i, j, k, . . . )-similar to matrices (two-way arrays), which are functions of two indices (r, c) for (row, column). Tensors have a rich history, stretching over almost a century, and touching upon numerous disciplines; but they have only recently become ubiquitous in signal and data analytics at the confluence of signal processing, statistics, data mining, and machine learning. This overview article aims to provide a good starting point for researchers and practitioners interested in learning about and working with tensors. As such, it focuses on fundamentals and motivation (using various application examples), aiming to strike an appropriate balance of breadth and depth that will enable someone having taken first graduate courses in matrix algebra and probability to get started doing research and/or developing tensor algorithms and software. Some background in applied optimization is useful but not strictly required. The material covered includes tensor rank and rank decomposition; basic tensor factorization models and their relationships and properties (including fairly good coverage of identifiability); broad coverage of algorithms ranging from alternating optimization to stochastic gradient; statistical performance analysis; and applications ranging from source separation to collaborative filtering, mixture and topic modeling, classification, and multilinear subspace learning.","Tensile stress,
Signal processing algorithms,
Matrix decomposition,
Signal processing,
Optimization,
Tutorials"
Temporally Constrained Group Sparse Learning for Longitudinal Data Analysis in Alzheimer's Disease,"Sparse learning has been widely investigated for analysis of brain images to assist the diagnosis of Alzheimer's disease and its prodromal stage, i.e., mild cognitive impairment. However, most existing sparse learning-based studies only adopt cross-sectional analysis methods, where the sparse model is learned using data from a single time-point. Actually, multiple time-points of data are often available in brain imaging applications, which can be used in some longitudinal analysis methods to better uncover the disease progression patterns. Accordingly, in this paper, we propose a novel temporallyconstrained group sparse learning method aiming for longitudinal analysis with multiple time-points of data. Specifically, we learn a sparse linear regression model by using the imaging data from multiple time-points, where a group regularization term is first employed to group the weights for the same brain region across different time-points together. Furthermore, to reflect the smooth changes between data derived from adjacent time-points, we incorporate two smoothness regularization terms into the objective function, i.e., one fused smoothness term thatrequires that the differences between two successive weight vectors from adjacent time-points should be small, and another output smoothness term thatrequires the differences between outputs of two successive models from adjacent time-points should also be small. We develop an efficient optimization algorithm to solve the proposed objective function. Experimental results on ADNI database demonstrate that, compared with conventional sparse learning-based methods, our proposed method can achieve improved regression performance and also help in discovering disease-related biomarkers.","Magnetic resonance imaging,
Alzheimer's disease,
Data models,
Brain modeling"
Automated Detection of Engagement Using Video-Based Estimation of Facial Expressions and Heart Rate,"We explored how computer vision techniques can be used to detect engagement while students (N = 22) completed a structured writing activity (draft-feedback-review) similar to activities encountered in educational settings. Students provided engagement annotations both concurrently during the writing activity and retrospectively from videos of their faces after the activity. We used computer vision techniques to extract three sets of features from videos, heart rate, Animation Units (from Microsoft Kinect Face Tracker), and local binary patterns in three orthogonal planes (LBP-TOP). These features were used in supervised learning for detection of concurrent and retrospective self-reported engagement. Area under the ROC Curve (AUC) was used to evaluate classifier accuracy using leave-several-students-out cross validation. We achieved an AUC = .758 for concurrent annotations and AUC = .733 for retrospective annotations. The Kinect Face Tracker features produced the best results among the individual channels, but the overall best results were found using a fusion of channels.","Feature extraction,
Biomedical monitoring,
Writing,
Videos,
Heart rate variability,
Sensors"
"Importance of Matching Physical Friction, Hardness, and Texture in Creating Realistic Haptic Virtual Surfaces","Interacting with physical objects through a tool elicits tactile and kinesthetic sensations that comprise your haptic impression of the object. These cues, however, are largely missing from interactions with virtual objects, yielding an unrealistic user experience. This article evaluates the realism of virtual surfaces rendered using haptic models constructed from data recorded during interactions with real surfaces. The models include three components: surface friction, tapping transients, and texture vibrations. We render the virtual surfaces on a SensAble Phantom Omni haptic interface augmented with a Tactile Labs Haptuator for vibration output. We conducted a human-subject study to assess the realism of these virtual surfaces and the importance of the three model components. Following a perceptual discrepancy paradigm, subjects compared each of 15 real surfaces to a full rendering of the same surface plus versions missing each model component. The realism improvement achieved by including friction, tapping, or texture in the rendering was found to directly relate to the intensity of the surface's property in that domain (slipperiness, hardness, or roughness). A subsequent analysis of forces and vibrations measured during interactions with virtual surfaces indicated that the Omni's inherent mechanical properties corrupted the user's haptic experience, decreasing realism of the virtual surface.",
Discontinuous Grid Current Control of Motor Drive System With Single-Phase Diode Rectifier and Small DC-Link Capacitor,"In this paper, a control method for motor drive system without electrolytic capacitor is proposed. Since dc-link capacitor of this motor drive is about 1% of the conventional one, it can satisfy the grid current regulation of IEC61000-3-2 without bulky filter circuits by directly controlling the electric output power of the inverter. However, dc-link voltage of this drive fluctuates as the rectified grid voltage. It causes higher motor current, especially at the low dc-link voltage area, and severely harms the drive efficiency. To solve this problem, proposed method keeps the dc-link voltage higher than certain limit while controlling the output power. It can improve the efficiency of the drive by lowering the d-axis current at low dc-link voltage area, with satisfying the regulation with small grid current harmonics. The proposed method includes the motor current reference generation for the limited dc-link voltage and selection of the limitation value. The improved performance of the proposed method was verified by the experimental results.","Capacitors,
Power harmonic filters,
Motor drives,
Inverters,
Power generation,
Harmonic analysis,
Voltage control"
A Survey of Dictionary Learning Algorithms for Face Recognition,"During the past several years, as one of the most successful applications of sparse coding and dictionary learning, dictionary-based face recognition has received significant attention. Although some surveys of sparse coding and dictionary learning have been reported, there is no specialized survey concerning dictionary learning algorithms for face recognition. This paper provides a survey of dictionary learning algorithms for face recognition. To provide a comprehensive overview, we not only categorize existing dictionary learning algorithms for face recognition but also present details of each category. Since the number of atoms has an important impact on classification performance, we also review the algorithms for selecting the number of atoms. Specifically, we select six typical dictionary learning algorithms with different numbers of atoms to perform experiments on face databases. In summary, this paper provides a broad view of dictionary learning algorithms for face recognition and advances study in this field. It is very useful for readers to understand the profiles of this subject and to grasp the theoretical rationales and potentials as well as their applicability to different cases of face recognition.","Dictionaries,
Face recognition,
Classification algorithms,
Training,
Face,
Encoding,
Image coding"
Origami: A 803-GOp/s/W Convolutional Network Accelerator,"An ever-increasing number of computer vision and image/video processing challenges are being approached using deep convolutional neural networks, obtaining state-of-the-art results in object recognition and detection, semantic segmentation, action recognition, optical flow, and super resolution. Hardware acceleration of these algorithms is essential to adopt these improvements in embedded and mobile computer vision systems. We present a new architecture, design, and implementation, as well as the first reported silicon measurements of such an accelerator, outperforming previous work in terms of power, area, and I/O efficiency. The manufactured device provides up to 196 GOp/s on 3.09
mm
2
of silicon in UMC 65-nm technology and can achieve a power efficiency of 803 GOp/s/W. The massively reduced bandwidth requirements make it the first architecture scalable to TOp/s performance.",
Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration,"Image restoration is a long-standing problem in low-level computer vision with many interesting applications. We describe a flexible learning framework based on the concept of nonlinear reaction diffusion models for various image restoration problems. By embodying recent improvements in nonlinear diffusion models, we propose a dynamic nonlinear reaction diffusion model with time-dependent parameters (i.e., linear filters and influence functions). In contrast to previous nonlinear diffusion models, all the parameters, including the filters and the influence functions, are simultaneously learned from training data through a loss based approach. We call this approach TNRD-Trainable Nonlinear Reaction Diffusion. The TNRD approach is applicable for a variety of image restoration tasks by incorporating appropriate reaction force. We demonstrate its capabilities with three representative applications, Gaussian image denoising, single image super resolution and JPEG deblocking. Experiments show that our trained nonlinear diffusion models largely benefit from the training of the parameters and finally lead to the best reported performance on common test datasets for the tested applications. Our trained models preserve the structural simplicity of diffusion models and take only a small number of diffusion steps, thus are highly efficient. Moreover, they are also well-suited for parallel computation on GPUs, which makes the inference procedure extremely fast.",
On-Chip Dynamic Mode Atomic Force Microscopy: A Silicon-on-Insulator MEMS Approach,"The atomic force microscope (AFM) is an invaluable scientific tool; however, its conventional implementation as a relatively costly macroscale system is a barrier to its more widespread use. A microelectromechanical systems (MEMS) approach to AFM design has the potential to significantly reduce the cost and complexity of the AFM, expanding its utility beyond current applications. This paper presents an on-chip AFM based on a silicon-on-insulator MEMS fabrication process. The device features integrated xy electrostatic actuators and electrothermal sensors as well as an AlN piezoelectric layer for out-of-plane actuation and integrated deflection sensing of a microcantilever. The three-degree-of-freedom design allows the probe scanner to obtain topographic tapping-mode AFM images with an imaging range of up to 8μm × 8μm in closed loop.","Probes,
Sensors,
Micromechanical devices,
Electrostatic actuators,
Fabrication,
Heat sinks"
Security and Privacy in Device-to-Device (D2D) Communication: A Review,"Device-to-device (D2D) communication presents a new paradigm in mobile networking to facilitate data exchange between physically proximate devices. The development of D2D is driven by mobile operators to harvest short range communications for improving network performance and supporting proximity-based services. In this paper, we investigate two fundamental and interrelated aspects of D2D communication, security and privacy, which are essential for the adoption and deployment of D2D. We present an extensive review of the state-of-the-art solutions for enhancing security and privacy in D2D communication. By summarizing the challenges, requirements, and features of different proposals, we identify lessons to be learned from existing studies and derive a set of “best practices.” The primary goal of our work is to equip researchers and developers with a better understanding of the underlying problems and the potential solutions for D2D security and privacy. To inspire follow-up research, we identify open problems and highlight future directions with regard to system and communication design. To the best of our knowledge, this is the first comprehensive review to address the fundamental security and privacy issues in D2D communication.","Device-to-device communication,
Security,
Privacy,
Ad hoc networks,
Mobile computing,
Wireless communication,
Machine-to-machine communications"
An Automatic Tool for Quantification of Nerve Fibers in Corneal Confocal Microscopy Images,"We describe and evaluate an automated software tool for nerve-fiber detection and quantification in corneal confocal microscopy (CCM) images, combining sensitive nerve-fiber detection with morphological descriptors. Method: We have evaluated the tool for quantification of Diabetic Sensorimotor Polyneuropathy (DSPN) using both new and previously published morphological features. The evaluation used 888 images from 176 subjects (84 controls and 92 patients with type 1 diabetes). The patient group was further subdivided into those with (n = 63) and without (n = 29) DSPN. Results: We achieve improved nervefiber detection over previous results (91.7% sensitivity and specificity in identifying nerve-fiber pixels). Automatic quantification of nerve morphology shows a high correlation with previously reported, manually measured, features. Receiver Operating Characteristic (ROC) analysis of both manual and automatic measurement regimes resulted in similar results in distinguishing patients with DSPN from those without: AUC of about 0.77 and 72% sensitivity-specificity at the equal error rate point. Conclusion: Automated quantification of corneal nerves in CCM images provides a sensitive tool for identification of DSPN. Its performance is equivalent to manual quantification, while improving speed and repeatability. Significance: CCM is a novel in vivo imaging modality that has the potential to be a noninvasive and objective image biomarker for peripheral neuropathy. Automatic quantification of nerve morphology is a major step forward in the early diagnosis and assessment of progression, and, in particular, for use in clinical trials to establish therapeutic benefit in diabetic and other peripheral neuropathies.","Diabetes,
Feature extraction,
Biomedical measurement,
Microscopy,
Discrete wavelet transforms,
Training,
Morphology"
mCloud: A Context-Aware Offloading Framework for Heterogeneous Mobile Cloud,"Mobile cloud computing (MCC) has become a significant paradigm for bringing the benefits of cloud computing to mobile devices' proximity. Service availability along with performance enhancement and energy efficiency are primary targets in MCC. This paper proposes a code offloading framework, called mCloud, which consists of mobile devices, nearby cloudlets and public cloud services, to improve the performance and availability of the MCC services. The effect of the mobile device context (e.g., network conditions) on offloading decisions is studied by proposing a context-aware offloading decision algorithm aiming to provide code offloading decisions at runtime on selecting wireless medium and appropriate cloud resources for offloading. We also investigate failure detection and recovery policies for our mCloud system. We explain in details the design and implementation of the mCloud prototype framework. We conduct real experiments on the implemented system to evaluate the performance of the algorithm. Results indicate the system and embedded decision algorithm are able to provide decisions on selecting wireless medium and cloud resources based on different context of the mobile devices, and achieve significant reduction on makespan and energy, with the improved service availability when compared with existing offloading schemes.","Cloud computing,
Mobile communication,
Mobile handsets,
Context,
Performance evaluation,
Ad hoc networks,
Wireless communication"
Hardware-Efficient Built-In Redundancy Analysis for Memory With Various Spares,"Memory capacity continues to increase, and many semiconductor manufacturing companies are trying to stack memory dice for larger memory capacities. Therefore, built-in redundancy analysis (BIRA) is of utmost importance because the probability of fault occurrence increases with a larger memory capacity. A traditional spare structure that consists of simple rows and columns is somewhat inadequate for multiple memory blocks BIRA because the hardware overhead and spare allocation efficiency are degraded. The proposed BIRA uses various types of spares and can achieve a higher yield than a simple row and column spare structure. Herein, we propose a BIRA that can achieve an optimal repair rate using various spare types. The proposed analyzer can exhaustively search not only row and column spare types but also global and local spare types. In addition, this paper proposes a fault-storing content-addressable memory (CAM) structure. The proposed CAM is small and collects faults efficiently. The experimental results show a high repair rate with a small hardware overhead and a short analysis time.","Maintenance engineering,
Hardware,
Redundancy,
Resource management,
Memory management,
Heuristic algorithms,
Built-in self-test"
Misalignment Sensitivity of Strongly Coupled Wireless Power Transfer Systems,"A traditional strongly coupled magnetic resonance (SCMR) system is highly sensitive to the alignment between the transmitter and receiver elements, which is an issue that has limited their applicability in practical wireless power transfer systems. This paper proposes, for the first time, a novel set of SCMR-based topologies that are less sensitive to misalignment while providing large wireless powering efficiencies. Specifically, instead of using planar coils for the transmitter and the receiver, we connect two orthogonal coils together into a 3-D model to provide misalignment insensitivity. Three SCMR systems (standard SCMR, conformal SCMR, and hybrid SCMR systems) are studied and compared to the proposed 3-D SCMR system in terms of angular azimuth, angular elevation, and lateral misalignment. Also, the ranges of these SCMR systems are compared. It is shown that the proposed misalignment system achieves above 40% efficiency for the entire range of 360° of angular misalignment. Also, our results show that the proposed misalignment system provides longer range.","Coils,
Standards,
Resonant frequency,
Transmitters,
Sensitivity,
Receivers"
A Case for Memory Content-Based Detection and Mitigation of Data-Dependent Failures in DRAM,"DRAM cells in close proximity can fail depending on the data content in neighboring cells. These failures are called data-dependent failures. Detecting and mitigating these failures online while the system is running in the field enables optimizations that improve reliability, latency, and energy efficiency of the system. All these optimizations depend on accurately detecting every possible data-dependent failure that could occur with any content in DRAM. Unfortunately, detecting all data-dependent failures requires the knowledge of DRAM internals specific to each DRAM chip. As internal DRAM architecture is not exposed to the system, detecting data-dependent failures at the system-level is a major challenge. Our goal in this work is to decouple the detection and mitigation of data-dependent failures from physical DRAM organization such that it is possible to detect failures without knowledge of DRAM internals. To this end, we propose MEMCON , a memory content-based detection and mitigation mechanism for data-dependent failures in DRAM. MEMCON does not detect every possible data-dependent failure. Instead, it detects and mitigates failures that occur with the current content in memory while the programs are running in the system. Using experimental data from real machines, we demonstrate that MEMCON is an effective and low-overhead system-level detection and mitigation technique for data-dependent failures in DRAM.","Testing,
DRAM chips,
Interference,
System-level design,
Failure analysis,
Content management"
Robust DOA Estimation in the Presence of Miscalibrated Sensors,"In this letter, we propose a robust direction-of-arrival (DOA) estimation algorithm in the context of sparse reconstruction, where some array sensors are miscalibrated. In this case, conventional DOA estimation algorithms suffer from degraded performance or even failed operations. In the proposed approach, the miscalibrated sensor observations are treated as outliers, and a weighting factor is adaptively optimized and applied to each sensor in order to effectively mitigate the effect of the outliers. An algorithm based on the maximum correntropy criterion is then developed to yield robust DOA estimation. The simulation results are presented to verify the effectiveness and superiority of the proposed approach compared with conventional DOA estimation algorithms.","Direction-of-arrival estimation,
Estimation,
Sensor arrays,
Robustness,
Signal processing algorithms,
Covariance matrices"
Research on the Impact of DFIG Virtual Inertia Control on Power System Small-Signal Stability Considering the Phase-Locked Loop,"Doubly fed induction generator (DFIG) wind turbines with virtual inertia control are coupled to power system in dynamic characteristics, and the control input of virtual inertia control is directly affected by the tracking ability of phase-locked loop (PLL). Thus, it is urgent to study the impact of DFIG wind turbines with virtual inertia control on power system small-signal stability considering the effects of PLL. First, based on DFIG operation characteristic and control strategy, a small-signal model of interconnected system with DFIG integration considering PLL and virtual inertial control is established. Second, the attenuation time constants of DFIG state variables are calculated, and according to the attenuation speeds of different state variables and the coupling between them, it is found out that PLL and virtual inertia are the main factors that affect the coupling between DFIG and synchronous generators. And then, considering that both PLL and virtual inertia control will affect the oscillation modes of synchronous generators, analytical method is used to reveal system small-signal stability under the joint effects of the two factors quantitatively. Analysis results show that, for DFIG wind turbines with virtual inertial control, PLL affects system damping mainly by affecting the participation of virtual inertia in the system. The smaller the PI parameters of PLL are, the smaller the participation factor of virtual inertia control state variables in the interarea oscillation mode is, and the bigger the electromechanical oscillation mode damping ratio is. Simulation results verify the reasonableness of the established model and the possibility that virtual inertia control may cause system small-signal stability to deteriorate in multimachine system.",
Decoding Upper Limb Movement Attempt From EEG Measurements of the Contralesional Motor Cortex in Chronic Stroke Patients,"Goal: Stroke survivors usually require motor rehabilitation therapy as, due to the lesion, they completely or partially loss mobility in the limbs. Brain-computer interface technology offers the possibility of decoding the attempt to move paretic limbs in real time to improve existing motor rehabilitation. However, a major difficulty for the practical application of the BCI to stroke survivors is that the brain rhythms that encode the motor states might be diminished due to the lesion. This study investigates the continuous decoding of natural attempt to move the paralyzed upper limb in stroke survivors from electroencephalographic signals of the unaffected contralesional motor cortex. Results: Experiments were carried out with the aid of six severely affected chronic stroke patients performing/attempting self-selected reaching movements of the unaffected/affected upper limb. The electroencephalographic (EEG) analysis showed significant cortical activation on the uninjured motor cortex when moving the contralateral unaffected arm and in the attempt to move the ipsilateral affected arm. Using this activity, significant continuous decoding of movement was obtained in six out of six participants in movements of the unaffected limb, and in four out of six participants in the attempt to move the affected limb. Conclusion: This study showed that it is possible to construct a decoder of the attempt to move the paretic arm for chronic stroke patients using the EEG activity of the healthy contralesional motor cortex. Significance: This decoding model could provide to stroke survivors with a natural, easy, and intuitive way to achieve control of BCIs or robot-assisted rehabilitation devices.",
Robust Shrinkage Normalized Sign Algorithm in an Impulsive Noise Environment,"In this brief, a robust shrinkage normalized sign (RSHNS) algorithm is presented, which uses an optimal step size by minimizing the energy of the noise-free a posteriori error signal and using Price's theorem. To reduce the impact of impulsive noise, the noise-free error signal is estimated by using the robust shrinkage method. It uses two threshold parameters as compared to that in the conventional shrinkage method. Finally, the improved convergence performance of the proposed RSHNS algorithm is demonstrated through simulation results in system identification and echo-cancellation applications.","Robustness,
Convergence,
Algorithm design and analysis,
Adaptive filters,
Optimized production technology,
Adaptation models,
Signal to noise ratio"
Exploiting Opportunistic Scheduling in Uplink Wiretap Networks,"Opportunistic scheduling schemes are investigated for uplink wiretap channels with multiple asymmetrically located legitimate users (LUs) and eavesdroppers. To exploit multiuser diversity, the cumulative distribution function-based scheduling method is leveraged to schedule the transmissions of the LUs. Under this scheduling framework, the closed-form expressions of the secrecy outage probability and ergodic secrecy rate are derived, illustrating the interplay among the system parameters, such as the channel statistics and the number of LUs and eavesdroppers. Through the secrecy outage analysis of the proposed scheduling schemes, we observe that the secrecy throughput is not always maximized with a larger channel access ratio (CAR), and consequently, we design a CAR adjustment scheme to maximize the secrecy throughput while satisfying the required secrecy level. We also prove that under our proposed scheduling schemes, the secrecy diversity order of each LU is equal to the reciprocal of the LU's CAR, implying that full diversity order is achieved, and the ergodic secrecy rate of each LU normalized by its CAR achieves the optimal double-logarithmic growth when the number of LUs increases to infinity.","Automobiles,
Uplink,
Throughput,
Network security,
Physical layer,
Optimal scheduling,
Fading channels"
Secure Multiple Amplify-and-Forward Relaying Over Correlated Fading Channels,"This paper quantifies the impact of correlated fading on secure communication of multiple amplify-and-forward (AF) relaying networks. In such a network, the base station (BS) is equipped with multiple antennas and communicates with the destination through multiple AF relays, while the message from the relays can be overheard by an eavesdropper. We focus on the practical communication scenario, where the main and eavesdropper's channels are correlated. In order to enhance the transmission security, transmit antenna selection is performed at the BS, and the best relay is chosen according to the full- or partial-relay selection criterion, which relies on the dual-hop relay channels or the second-hop relay channels, respectively. For these criteria, we study the impact of correlated fading on the network secrecy performance, by deriving an analytical approximation for the secrecy outage probability and an asymptotic expression for the high main-to-eavesdropper ratio. From these results, it is concluded that the channel correlation is always beneficial to the secrecy performance of full relay selection. However, it deteriorates the secrecy performance if partial-relay selection is used, when the number of antennas at the BS is less than the number of relays.",
"Mobile Edge Cloud System: Architectures, Challenges, and Approaches","Mobile edge cloud (MEC) is a model for enabling on-demand elastic access to, or an interaction with a shared pool of reconfigurable computing resources such as servers, storage, peer devices, applications, and services, at the edge of the wireless network in close proximity to mobile users. It overcomes some obstacles of traditional central clouds by offering wireless network information and local context awareness as well as low latency and bandwidth conservation. This paper presents a comprehensive survey of MEC systems, including the concept, architectures, and technical enablers. First, the MEC applications are explored and classified based on different criteria, the service models and deployment scenarios are reviewed and categorized, and the factors influencing the MEC system design are discussed. Then, the architectures and designs of MEC systems are surveyed, and the technical issues, existing solutions, and approaches are presented. The open challenges and future research directions of MEC are further discussed.","Cloud computing,
Mobile communication,
Mobile computing,
Mobile handsets,
Bandwidth,
Wireless networks"
Event-Triggered Control Systems Under Denial-of-Service Attacks,"In this paper, we propose a systematic design framework for output-based dynamic event-triggered control (ETC) systems under denial-of-service (DoS) attacks. These malicious DoS attacks are intended to interfere with the communication channel causing periods in time at which transmission of measurement data is impossible. We show that the proposed ETC scheme, if well designed, can tolerate a class of DoS signals characterized by frequency and duration properties without jeopardizing the stability, performance and Zeno-freeness of the ETC system. In fact, the design procedure of the ETC condition allows tradeoffs between performance, robustness to DoS attacks, and utilization of communication resources. The main results will be illustrated by means of a numerical example.","Computer crime,
Jamming,
Stability analysis,
Context,
Closed loop systems,
Systematics"
On Data Integrity Attacks Against Real-Time Pricing in Energy-Based Cyber-Physical Systems,"In this paper, we investigate a novel real-time pricing scheme, which considers both renewable energy resources and traditional power resources and could effectively guide the participants to achieve individual welfare maximization in the system. To be specific, we develop a Lagrangian-based approach to transform the global optimization conducted by the power company into distributed optimization problems to obtain explicit energy consumption, supply, and price decisions for individual participants. Also, we show that these distributed problems derived from the global optimization by the power company are consistent with individual welfare maximization problems for end-users and traditional power plants. We also investigate and formalize the vulnerabilities of the real-time pricing scheme by considering two types of data integrity attacks: Ex-ante attacks and Ex-post attacks, which are launched by the adversary before or after the decision-making process. We systematically analyze the welfare impacts of these attacks on the real-time pricing scheme. Through a combination of theoretical analysis and performance evaluation, our data shows that the real-time pricing scheme could effectively guide the participants to achieve welfare maximization, while cyber-attacks could significantly disrupt the results of real-time pricing decisions, imposing welfare reduction on the participants.","Pricing,
Real-time systems,
Power generation,
Renewable energy sources,
Companies,
Energy consumption,
Cyber-physical systems"
Parallel and Distributed Methods for Constrained Nonconvex Optimization-Part II: Applications in Communications and Machine Learning,"In Part I of this paper, we proposed and analyzed a novel algorithmic framework for the minimization of a nonconvex objective function, subject to nonconvex constraints, based on inner convex approximations. This Part II is devoted to the (nontrivial) application of the framework to the following relevant large-scale problems ranging from communications to machine learning: 1) (generalizations of) the rate profile maximization in MIMO interference broadcast networks; 2) the max-min fair multicast multigroup beamforming problem in a multicell environment; and 3) a general nonconvex constrained bi-criteria formulation for k-sparse variable selection in statistical learning; the two criteria are a nonconvex loss objective function, measuring the fitness of the model to data, and the latter is a nonconvex sparsity-inducing constraint in the general form of difference-of-convex (DC) functions, which allows to accomodate in a unified fashion convex and nonconvex surrogates of the 10 function. The proposed algorithms outperform current state-of-the-art schemes for 1)-3) both theoretically and numerically. For instance, they are the first distributed schemes for the class of problems 1) and 2); and they also lead to subproblems enjoying closed form solutions.",
Future Shipboard MVdc System Protection Requirements and Solid-State Protective Device Topological Tradeoffs,"The search for the optimum architecture for shipboard medium voltage dc integrated power systems must take into account the short-circuit protection in addition to overarching goals of efficiency, survivability, reliability of power, and cost effectiveness. Presently, accepted approaches to protection are “unit-based,” which means the power converter(s) feeding the bus coordinate with no-load electromechanical switches to isolate faulted portions of the bus. However, “breaker-based” approaches, which rely upon solid-state circuit breakers for fault mitigation, can result in higher reliability of power and potentially higher survivability. The inherent speed of operation of solid-state protective devices will also play a role in fault isolation, hence reducing stress level on all system components. A comparison study is performed of protective device topologies that are suitable for shipboard distribution systems rated between 4 and 30 kVdc from the perspectives of size and number of passive components required to manage the commutation energy during sudden fault events and packaging scalability to higher current and voltage systems. The implementation assumes a multichip silicon carbide (SiC) 10-kV, 240-A MOSFET/junction barrier Schottkey (JBS) diode module.","Circuit faults,
Marine vehicles,
Power system reliability,
Reliability,
IP networks,
Fault currents,
Solids"
Microwave Imaging Using Normal Electric-Field Components Inside Metallic Resonant Chambers,"A novel 3-D microwave imaging approach performed within a resonant air-filled metallic chamber is introduced and investigated. The new method utilizes the measurements of normal electric-field components at discrete points along the metallic chamber's wall-near the chamber-wall boundary, the normal-field components are dominant, while the tangential components vanish. The inversion algorithm fully incorporates the resonant features of the low-loss chamber. A numerical study is used to quantify the imaging performance of using this technique compared with the traditional unbounded domain imaging. An experimental system is presented where the electric field is collected using 24 antennas distributed in three circumferential layers around an object of interest located inside the circular-cylindrical metallic chamber. For collecting the normal component of the field, two types of linearly polarized antennas are investigated: λ/4 monopole antennas and specially designed reconfigurable antennas (RAs), both projecting perpendicularly out from the chamber walls into the enclosure. The measured data are calibrated and then inverted using a multiplicatively regularized finite-element contrast source inversion algorithm. Using 3-D reconstructions of simple dielectric targets, it is shown that utilizing the RAs improves imaging performance due to a reduction in the modeling error introduced in the inversion algorithm.","Computational modeling,
Antennas,
Dielectrics,
Image reconstruction,
Microwave imaging,
Microwave theory and techniques"
Automatic Nuclei Detection Based on Generalized Laplacian of Gaussian Filters,"Efficient and accurate detection of cell nuclei is an important step toward automatic analysis in histopathology. In this work, we present an automatic technique based on generalized Laplacian of Gaussian (gLoG) filter for nuclei detection in digitized histological images. The proposed technique first generates a bank of gLoG kernels with different scales and orientations and then performs convolution between directional gLoG kernels and the candidate image to obtain a set of response maps. The local maxima of response maps are detected and clustered into different groups by mean-shift algorithm based on their geometrical closeness. The point which has the maximum response in each group is finally selected as the nucleus seed. Experimental results on two datasets show that the proposed technique provides a superior performance in nuclei detection compared to existing techniques.","Kernel,
Skin,
Informatics,
Convolution,
Shape,
Laplace equations,
Clustering algorithms"
Suppressing Zero-Sequence Circulating Current of Modular Interleaved Three-Phase Converters Using Carrier Phase Shift PWM,"Zero-sequence circulating current (ZSCC) has been a major concern for the operation of paralleled converters. Existing ZSCC reduction methods in the literature either suffer poor performances or are too complicated for modular implementation in an arbitrary number of interleaved converters. This paper investigates the application of interleaved carrier phase-shift (ICPS) pulse-width modulation (PWM) in modular interleaved converter system for ZSCC peak value reduction. The generalized study based on the derived ZSCC analytical expression reveals that the ICPS PWM can achieve superior ZSCC peak value reduction performance regardless the number of interleaved converters. Moreover, the impacts of ICPS PWM on the output voltage and current quality are also analyzed based on double Fourier integral. Compared with the conventional interleaved sinusoidal PWM (ISPWM), the output quality with the ICPS PWM can be comparable or even better. Simulation and experimental results show good agreement with the theoretical analysis, verifying the performance of the ICPS PWM.",
Demonstration of RF and Microwave Passive Circuits Through 3-D Printing and Selective Metalization,"The ultimate goal of this paper is to print radio frequency (RF) and microwave structures using a 3-D platform and to pattern metal films on nonplanar structures. To overcome substrate losses, air core substrates that can readily be printed are utilized. To meet the challenge of patterning conductive layers on complex or nonplanar printed structures, two novel self-aligning patterning processes are demonstrated. One is a simple damascene-like process, and the other is a lift-off process using a 3-D printed lift-off mask layer. A range of microwave and RF circuits are designed and demonstrated between 1 and 8 GHz utilizing these processes. Designs are created and simulated using Keysight Advanced Design System and ANSYS High Frequency Structure Simulator. Circuit designs include a simple microstrip transmission line (T-line), coupled-line bandpass filter, circular ring resonator, T-line resonator, resonant cavity structure, and patch antenna. A commercially available 3-D printer and metal sputtering system are used to realize the designs. Both simulated and measured results of these structures are presented.","Substrates,
Air gaps,
Printing,
Fabrication,
Radio frequency,
Dielectric losses,
Propagation losses"
Isotropic Total Variation Regularization of Displacements in Parametric Image Registration,"Spatial regularization is essential in image registration, which is an ill-posed problem. Regularization can help to avoid both physically implausible displacement fields and local minima during optimization. Tikhonov regularization (squared
ℓ
2
-norm) is unable to correctly represent non-smooth displacement fields, that can, for example, occur at sliding interfaces in the thorax and abdomen in image time-series during respiration. In this paper, isotropic Total Variation (TV) regularization is used to enable accurate registration near such interfaces. We further develop the TV-regularization for parametric displacement fields and provide an efficient numerical solution scheme using the Alternating Directions Method of Multipliers (ADMM). The proposed method was successfully applied to four clinical databases which capture breathing motion, including CT lung and MR liver images. It provided accurate registration results for the whole volume. A key strength of our proposed method is that it does not depend on organ masks that are conventionally required by many algorithms to avoid errors at sliding interfaces. Furthermore, our method is robust to parameter selection, allowing the use of the same parameters for all tested databases. The average target registration error (TRE) of our method is superior (10% to 40%) to other techniques in the literature. It provides precise motion quantification and sliding detection with sub-pixel accuracy on the publicly available breathing motion databases (mean TREs of 0.95 mm for DIR 4D CT, 0.96 mm for DIR COPDgene, 0.91 mm for POPI databases).","Lungs,
TV,
Optimization,
Measurement,
Image registration,
Motion segmentation,
Databases"
Location-privacy-aware review publication mechanism for local business service systems,"Local business service systems (LBSS), such as Yelp and Dianping, play an essential role in making decisions like choosing a restaurant for our daily life. These systems heavily rely on individuals' voluntarily submitted reviews to build the reputation for nearby businesses. Unfortunately, the reviews expose users' private information such as visited places to the public and adversaries. Even worse, such location information is always public as it is the basic information of businesses, and adversaries could be anyone ranging from advertisement spammer to physical stalker. This paper formalizes the privacy preserving problem in local business service systems and propose a novel location privacy preserving framework. The framework can preserve users' location privacy in arbitrary local area and can maintain a good utility for both the system and every user. We evaluate our framework thoroughly towards real-world data traces. The results validate that the framework can achieve a good performance.",
Superimposed Sparse Parameter Classifiers for Face Recognition,"In this paper, a novel classifier, called superimposed sparse parameter (SSP) classifier is proposed for face recognition. SSP is motivated by two phase test sample sparse representation (TPTSSR) and linear regression classification (LRC), which can be treated as the extended of sparse representation classification (SRC). SRC uses all the train samples to produce the sparse representation vector for classification. The LRC, which can be interpreted as L2-norm sparse representation, uses the distances between the test sample and the class subspaces for classification. TPTSSR is also L2-norm sparse representation and uses two phase to compute the distance for classification. Instead of the distances, the SSP classifier employs the SSPs, which can be expressed as the sum of the linear regression parameters of each class in iterations, is used for face classification. Further, the fast SSP (FSSP) classifier is also suggested to reduce the computation cost. A mass of experiments on Georgia Tech face database, ORL face database, CVL face database, AR face database, and CASIA face database are used to evaluate the proposed algorithms. The experimental results demonstrate that the proposed methods achieve better recognition rate than the LRC, SRC, collaborative representation-based classification, regularized robust coding, relaxed collaborative representation, support vector machine, and TPTSSR for face recognition under various conditions.","Face,
Databases,
Face recognition,
Linear regression,
Collaboration,
Training,
Prototypes"
Low Overhead Architectures for OMP Compressive Sensing Reconstruction Algorithm,"Orthogonal Matching Pursuit (OMP) is an important compressive sensing (CS) recovery and sparsity inducing algorithm, which has potential in various emerging applications ranging from wearable and mobile computing to real-time analytics processing on servers. Thus application aware OMP algorithm implementation is important. In this paper, we propose two different modifications to OMP algorithm named Thresholding technique for OMP (tOMP) and Gradient Descent OMP (GDOMP) to reduce hardware complexity of OMP algorithm. tOMP modifies identification stage of OMP algorithm to reduce reconstruction time and GDOMP modifies residual update phase to reduce chip area. To demonstrate reconstruction efficiency of proposed OMP modifications, we compare signal-to-reconstruction error rate (SRER), signal-to-noise ratio (PSNR), and Structural Similarity index (SSIM) of previously proposed matching pursuit algorithms such as Subspace Pursuit (SP), Look Ahead OMP (LAOMP), and OMP, with tOMP, and GDOMP. We implemented reconfigurable, parallel, and pipelined architectures for three algorithms including OMP, tOMP, and GDOMP which can reconstruct different data vector sizes ranging from 128 to 1024, on 65 nm CMOS technology operating at 1 V supply voltage. The post place and route analysis on area, power, and latency show that, tOMP requires 33% less reconstruction time, and GDOMP consumes 44% less chip area when compared to OMP ASIC implementation. Compared to previously published work, the proposed architectures achieve 2.1 times improvement in Area-Delay product (ADP) and consume 40% less energy.","Matching pursuit algorithms,
Hardware,
Kernel,
Complexity theory,
Computer architecture,
Big data,
Compressed sensing"
Directivity-Reconfigurable Wideband Two-Arm Spiral Antenna,"This letter reports a novel directivity-reconfigurable wideband antenna in microwave regime. The antenna is formed by encasing liquid metal alloys into a highly stretchable elastomer. A two-arm Archimedean spiral antenna is adopted to implement the concept of optimizing directivity by inflating the elastomer to form a dome-shaped antenna. Microelectromechanical system-based microblowers are employed to pneumatically control the shape of the antenna. The antenna can operate in a wide frequency band from 6.9 to 13.8 GHz. The ability to change the shape of the antenna allows optimizing its radiation pattern by making it more directive in the inflation direction, while its passing band remains wide. The antenna also provides good circular polarization of an electromagnetic wave.","Antenna radiation patterns,
Antenna measurements,
Metals,
Liquids,
Directive antennas,
Spirals"
Programming a Robot for Conformance Grinding of Complex Shapes by Capturing the Tacit Knowledge of a Skilled Operator,"This paper describes a novel methodology to reduce the effort in automating manual surface finishing processes by bridging the knowledge transfer gap of the manual operator's skills to a robot program. Key process variables (KPVs), i.e., contact force, tool path, and feed rate, of the manual operator performing the task are captured with a “sensorized” hand-held belt grinder, while the changes to the work-piece geometry is captured using a 3-D scanner. The entire manual tool-path strategy is segmented into its primitives or primary strategies before programming an equivalent robotic tool-path and strategy. The manual tool-path primitives are imported into computer-aided-manufacturing software where boundary splines are created to generate the robotic tool-paths. An analytical material removal rate (MRR) model is used to scale the extracted manual KPVs such that the parameters can be executed by the robotic platform, while still maintaining an equivalent material removal profile. In the first experimental trial with the designed robotic finishing strategy using this approach, the work-piece could be finished to within 0.7 mm of the desired shape.","Robots,
Force,
Manuals,
Wheels,
Shape,
Surface treatment,
Belts"
Visualization as Seen through its Research Paper Keywords,"We present the results of a comprehensive multi-pass analysis of visualization paper keywords supplied by authors for their papers published in the IEEE Visualization conference series (now called IEEE VIS) between 1990-2015. From this analysis we derived a set of visualization topics that we discuss in the context of the current taxonomy that is used to categorize papers and assign reviewers in the IEEE VIS reviewing process. We point out missing and overemphasized topics in the current taxonomy and start a discussion on the importance of establishing common visualization terminology. Our analysis of research topics in visualization can, thus, serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an online query tool (http://keyvis.org/) that allows visualization researchers to easily browse the 3952 keywords used for IEEE VIS papers since 1990 to find related work or make informed keyword choices.",
Decoding-Delay-Controlled Completion Time Reduction in Instantly Decodable Network Coding,"For several years, the completion time and the decoding delay problems in instantly decodable network coding (IDNC) were considered separately and were thought to act completely against each other. Recently, some works have aimed to balance the effects of these two important IDNC metrics, but none of them studied a further optimization of one by controlling the other. This paper investigates the effect of controlling the decoding delay to reduce the completion time below its currently best known solution in both perfect and imperfect feedback with persistent erasure channels. To solve the problem, the decoding-delay-dependent expressions of the users' and overall completion times are derived in the complete feedback scenario. Although using such expressions to find the optimal overall completion time is NP-hard, this paper proposes two novel heuristics that minimize the probability of increasing the maximum of these decoding-delay-dependent completion time expressions after each transmission through a layered control of their decoding delays. Afterward, this paper extends the study to the imperfect feedback scenario, in which uncertainties at the sender affect its ability to anticipate accurately the decoding delay increase at each user. This paper formulates the problem in such an environment and derives the expression of the minimum increase in the completion time. Simulation results show the performance of the proposed solutions and suggest that both heuristics achieve a lower mean completion time, as compared with the best known heuristics for completion time reduction in perfect and imperfect feedback. The gap in performance becomes more significant as the erasure of the channel increases.","Decoding,
Delays,
Network coding,
Optimization,
Simulation,
Electronic mail"
A Strength Pareto Evolutionary Algorithm Based on Reference Direction for Multiobjective and Many-Objective Optimization,"While Pareto-based multiobjective optimization algorithms continue to show effectiveness for a wide range of practical problems that involve mostly two or three objectives, their limited application for many-objective problems, due to the increasing proportion of nondominated solutions and the lack of sufficient selection pressure, has also been gradually recognized. In this paper, we revive an early developed and computationally expensive strength Pareto-based evolutionary algorithm by introducing an efficient reference direction-based density estimator, a new fitness assignment scheme, and a new environmental selection strategy, for handling both multiobjective and many-objective problems. The performance of the proposed algorithm is validated and compared with some state-of-the-art algorithms on a number of test problems. Experimental studies demonstrate that the proposed method shows very competitive performance on both multiobjective and many-objective problems considered in this paper. Besides, our extensive investigations and discussions reveal an interesting finding, that is, diversity-first-and-convergence-second selection strategies may have great potential to deal with many-objective optimization.","Optimization,
Sociology,
Statistics,
Convergence,
Evolutionary computation,
Genetics,
Computational complexity"
Efficient and Privacy-Preserving Outsourced Calculation of Rational Numbers,"In this paper, we propose a framework for efficient and privacy-preserving outsourced calculation of rational numbers, which we refer to as POCR. Using POCR, a user can securely outsource the storing and processing of rational numbers to a cloud server without compromising the security of the (original) data and the computed results. More specifically, we present a Paillier cryptosystem with threshold decryption (PCTD), the core cryptographic primitive, to reduce the private key exposure risk in POCR. We also present the toolkits required in the privacy preserving calculation of integers and rational numbers to ensure that commonly used outsourced operations can be handled on-the-fly. We then prove that the proposed POCR achieves the goal of secure integer and rational number calculation without resulting in privacy leakage to unauthorized parties, as well as demonstrating the utility and the efficiency of POCR using simulations.",
Application-Aware Dynamic Fine-Grained Resource Provisioning in a Virtualized Cloud Data Center,"A key factor of win-win cloud economy is how to trade off between the application performance from customers and the profit of cloud providers. Current researches on cloud resource allocation do not sufficiently address the issues of minimizing energy cost and maximizing revenue for various applications running in virtualized cloud data centers (VCDCs). This paper presents a new approach to optimize the profit of VCDC based on the service-level agreements (SLAs) between service providers and customers. A precise model of the external and internal request arrival rates is proposed for virtual machines at different service classes. An analytic probabilistic model is then developed for non-steady VCDC states. In addition, a smart controller is developed for fine-grained resource provisioning and sharing among multiple applications. Furthermore, a novel dynamic hybrid metaheuristic algorithm is developed for the formulated profit maximization problem, based on simulated annealing and particle swarm optimization. The proposed algorithm can guarantee that differentiated service qualities can be provided with higher overall performance and lower energy cost. The advantage of the proposed approach is validated with trace-driven simulations.","Resource management,
Cloud computing,
Dynamic scheduling,
Heuristic algorithms,
Optimization,
Computational modeling,
Bismuth"
Using Concept Lattice for Personalized Recommendation System Design,"A novel personalized recommendation system (PRS) based on concept lattice is proposed and used to discover valuable information according to users' requirements and interests quickly and efficiently. The system is divided into the offline part and the online part. In the offline part, the formal context and the concept lattice are constructed from the transaction database, and the association rules based on concept lattice are extracted and stored in the rule library. The new added data are used to update the concept lattice and the rule library regularly. In the online part, the behavior data of target user, the concept lattice and the rule library are used to calculate the ordered recommendation results, which are returned to the user. There are two recommendation methods in the online part, which are recommendations based on association rules and collaborative filtering recommendation. Because of the natural advantages of the concept lattice in data processing and analysis, the PRS we designed possesses better precision and faster response capability, as compared with conventional recommendation system.","Lattices,
Association rules,
Context,
Collaboration,
Motion pictures,
Libraries"
"Source-Level Performance, Energy, Reliability, Power and Thermal (PERPT) Simulation","With ever increasing design complexities, traditional cycle-accurate or instruction-set simulations are often too slow or too inaccurate for system prototyping in early design stages. As an alternative, host-compiled or source-level software simulation has been proposed, but existing approaches have largely focused on timing simulation only. In this paper, we propose a novel source-level simulation infrastructure that provides a full range of performance, energy, reliability, power and thermal (PERPT) estimation. Using a fully automated, retargetable back-annotation framework, intermediate representation code is statically annotated with timing, energy and resource accesses information obtained from low-level references at basic block granularity. The annotated model is natively compiled and combined with a cache model and occupancy analyzer to provide target performance, energy, soft-error vulnerability and power estimations. Finally, generated power traces are fed into thermal models for further temperature estimation. Comprehensive evaluations of our source-level models for PERPT estimations are performed. We applied our approach to PowerPC targets running various industry benchmark suites. source-level simulations are evaluated for different PERPT metrics and with cache models at various levels of detail to explore the speed and accuracy tradeoffs. More than 90% accuracy can be achieved for timing, energy, reliability and power estimation, and an average error of 0.05 K exists in steady-state thermal estimation. Simulation speeds range from 180 to 5740 MIPS for different types of metrics at different abstraction levels.",
Ground Maneuvering Target Imaging and High-Order Motion Parameter Estimation Based on Second-Order Keystone and Generalized Hough-HAF Transform,"This paper proposes a new method to focus a ground moving target with complex motions and estimate its motion parameters in a synthetic aperture radar (SAR) system. In this method, the second-order Keystone transform is applied to correct the range curvature. Then, the Hough transform is applied to estimate the slope of the range walk trajectory, from which the target cross-track velocity is obtained. Finally, a generalized Hough-high-order ambiguity function (GHHAF) transform is applied to transform the target signal into a 2-D time-frequency plane and estimate its slope associated with the third-order Doppler parameter. Compared with the conventional SAR imaging methods using the second-order phase model, the proposed method can obtain better imaging quality since the third-order Doppler frequency migration is effectively eliminated. Both simulated and real data processing results are provided to validate the effectiveness of the proposed algorithm.",
Adaptive Multimodal Continuous Ant Colony Optimization,"Seeking multiple optima simultaneously, which multimodal optimization aims at, has attracted increasing attention but remains challenging. Taking advantage of ant colony optimization (ACO) algorithms in preserving high diversity, this paper intends to extend ACO algorithms to deal with multimodal optimization. First, combined with current niching methods, an adaptive multimodal continuous ACO algorithm is introduced. In this algorithm, an adaptive parameter adjustment is developed, which takes the difference among niches into consideration. Second, to accelerate convergence, a differential evolution mutation operator is alternatively utilized to build base vectors for ants to construct new solutions. Then, to enhance the exploitation, a local search scheme based on Gaussian distribution is self-adaptively performed around the seeds of niches. Together, the proposed algorithm affords a good balance between exploration and exploitation. Extensive experiments on 20 widely used benchmark multimodal functions are conducted to investigate the influence of each algorithmic component and results are compared with several state-of-the-art multimodal algorithms and winners of competitions on multimodal optimization. These comparisons demonstrate the competitive efficiency and effectiveness of the proposed algorithm, especially in dealing with complex problems with high numbers of local optima.","Optimization,
Algorithm design and analysis,
Sociology,
Statistics,
Ant colony optimization,
Clustering algorithms,
Computer science"
Sentiment Computing for the News Event Based on the Social Media Big Data,"The explosive increasing of the social media data on the Web has created and promoted the development of the social media big data mining area welcomed by researchers from both academia and industry. The sentiment computing of news event is a significant component of the social media big data. It has also attracted a lot of researches, which could support many real-world applications, such as public opinion monitoring for governments and news recommendation for Websites. However, existing sentiment computing methods are mainly based on the standard emotion thesaurus or supervised methods, which are not scalable to the social media big data. Therefore, we propose an innovative method to do the sentiment computing for news events. More specially, based on the social media data (i.e., words and emoticons) of a news event, a word emotion association network (WEAN) is built to jointly express its semantic and emotion, which lays the foundation for the news event sentiment computation. Based on WEAN, a word emotion computation algorithm is proposed to obtain the initial words emotion, which are further refined through the standard emotion thesaurus. With the words emotion in hand, we can compute every sentence's sentiment. Experimental results on real-world data sets demonstrate the excellent performance of the proposed method on the emotion computing for news events.","Text mining,
Sentiment computing,
Emotion recognition,
Social network services,
Classification,
Big data,
Data mining"
Toward Non-Intrusive Load Monitoring via Multi-Label Classification,"Demand-side management technology is a key element of the proposed smart grid, which will help utilities make more efficient use of their generation assets by reducing consumers' energy demand during peak load periods. However, although some modern appliances can respond to price signals from the utility companies, there is a vast stock of older appliances that cannot. For such appliances, utilities must infer what appliances are operating in a home, given only the power signals on the main feeder to the home (i.e., the home's power consumption must be disaggregated into individual appliances). We report on an in-depth investigation of multi-label classification algorithms for disaggregating appliances in a power signal. A systematic review of this research topic shows that this class of algorithms has received little attention in the literature, even though it is arguably a more natural fit to the disaggregation problem than the traditional single-label classifiers used to date. We examine a multi-label meta-classification framework (RAkEL), and a bespoke multi-label classification algorithm (MLkNN), employing both time-domain and wavelet-domain feature sets. We test these classifiers on two real houses from the Reference Energy Disaggregation Dataset. We found that the multilabel algorithms are effective and competitive with published results on the datasets.","Home appliances,
Classification algorithms,
Data models,
Monitoring,
Hidden Markov models,
Support vector machines,
Power demand"
MAC Protocols With Wake-Up Radio for Wireless Sensor Networks: A Review,"The use of a low-power wake-up radio in wireless sensor networks is considered in this paper, where relevant medium access control solutions are studied. A variety of asynchronous wake-up MAC protocols have been proposed in the literature, which take advantage of integrating a second radio to the main one for waking it up. However, a complete and a comprehensive survey particularly on these protocols is missing in the literature. This paper aims at filling this gap, proposing a relevant taxonomy, and providing deep analysis and discussions. From both perspectives of energy efficiency and latency reduction, as well as their operation principles, state-of-the-art wake-up MAC protocols are grouped into three main categories: (1) duty cycled wake-up MAC protocols; (2) non-cycled wake-up protocols; and (3) path reservation wake-up protocols. The first category includes two subcategories: (1) static wake-up protocols versus (2) traffic adaptive wake-up protocols. Non-cycled wake-up MAC protocols are again divided into two classes: (1) always-on wake-up protocol and (2) radio-triggered wake-up protocols. The latter is in turn split into two subclasses: (1) passive wake-up MAC protocols versus (2) ultra low power active wake-up MAC protocols. Two schemes could be identified for the last category, (1) broadcast based wake-up versus (2) addressing based wake-up. All these classes are discussed and analyzed in this paper, and canonical protocols are investigated following the proposed taxonomy.",
A Minimal Realization Technique for the Dynamical Structure Function of a Class of LTI Systems,"The dynamical structure function of a linear time invariant (LTI) system reveals causal dependencies among manifest variables without specifying any particular relationships among the unmeasured states of the system. As such, it is a useful representation for complex networks where a coarse description of global system structure is desired without detailing the intricacies of a full state realization. In this paper, we consider the problem of finding a minimal state realization for a given dynamical structure function. Interestingly, some dynamical structure functions require uncontrollable modes in their state realizations to deliver the desired input-output behavior while respecting a specified system structure. As a result, the minimal order necessary to realize a particular dynamical structure function may be greater than that necessary to realize its associated transfer function. Although finding a minimal realization for a given dynamical structure function is difficult in general, we present a straightforward procedure here that works for a simplified class of systems.","Linear systems,
Yttrium,
Control systems,
Heuristic algorithms,
Topology,
Poles and zeros"
Quality Index for Stereoscopic Images by Jointly Evaluating Cyclopean Amplitude and Cyclopean Phase,"With widespread applications of three-dimensional (3-D) technology, measuring quality of experience for 3-D multimedia content plays an increasingly important role. In this paper, we propose a full reference stereo image quality assessment (SIQA) framework which focuses on the innovation of binocular visual properties and applications of low-level features. On one hand, based on the fact that human visual system understands an image mainly according to its low-level features, local phase and local amplitude extracted from phase congruency measurement are employed as primary features. Considering the less prominent performance of amplitude in IQA, visual saliency is applied into the modification on amplitude. On the other hand, by fully considering binocular rivalry phenomena, we create the cyclopean amplitude map and cyclopean phase map. With this method, both image features and binocular visual properties are mutually combined with each other. Meanwhile, a novel binocular modulation function in spatial domain is also adopted into the overall quality prediction of amplitude and phase. Extensive experiments demonstrate that the proposed framework achieves higher consistency with subjective tests than relevant SIQA metrics.","Visualization,
Three-dimensional displays,
Feature extraction,
Measurement,
Stereo image processing,
Distortion,
Image quality"
Rate and Distortion Optimization for Reversible Data Hiding Using Multiple Histogram Shifting,"Histogram shifting (HS) embedding as a typical reversible data hiding scheme is widely investigated due to its high quality of stego-image. For HS-based embedding, the selected side information, i.e., peak and zero bins, usually greatly affects the rate and distortion performance of the stego-image. Due to the massive solution space and burden in distortion computation, conventional HS-based schemes utilize some empirical criterion to determine those side information, which generally could not lead to a globally optimal solution for reversible embedding. In this paper, based on the developed rate and distortion model, the problem of HS-based multiple embedding is formulated as the one of rate and distortion optimization. Two key propositions are then derived to facilitate the fast computation of distortion due to multiple shifting and narrow down the solution space, respectively. Finally, an evolutionary optimization algorithm, i.e., genetic algorithm is employed to search the nearly optimal zero and peak bins. For a given data payload, the proposed scheme could not only adaptively determine the proper number of peak and zero bin pairs but also their corresponding values for HS-based multiple reversible embedding. Compared with previous approaches, experimental results demonstrate the superiority of the proposed scheme in the terms of embedding capacity and stego-image quality.","Distortion,
Histograms,
Rate distortion theory,
Optimization,
Payloads,
Computational modeling,
Genetic algorithms"
A Hand-Held Assistant for Semiautomated Percutaneous Needle Steering,"Objective: Permanent prostate brachytherapy is an effective and popular treatment modality for prostate cancer in which long needles are inserted into the prostate. Challenges associated with manual needle insertion such as needle deflection limit this procedure to primarily treat the entire prostate gland even for patients with localized cancer. In this paper, we present a new semiautomated hand-held needle steering assistant designed to help surgeons improve needle placement accuracy. Methods: Regular clinical brachytherapy needles are connected to a compact device that the surgeon holds. As the surgeon inserts the needle, the device rotates the needle base on a measured and calculated basis in order to produce a desired trajectory of the needle tip. A novel needle-tissue interaction model and a steering algorithm calculate such control actions based on ultrasound images of the needle in tissue. The assistant can also apply controlled longitudinal microvibrations to the needle that reduce needle-tissue friction. Results: Experimental validation of the proposed system in phantom and ex-vivo biological tissue report an average needle targeting accuracy of 0.33 mm over 72 needle insertions in 12 different experimental scenarios. Conclusion: We introduce a new framework for needle steering in prostate brachytherapy in which the surgeon remains in charge of the needle insertion. The device weighs 160 g, making it easy to incorporate with current insertion techniques. Significance: Expected benefits of the proposed system include more precise needle targeting accuracy, which can result in improved focal treatment of prostate cancer.","Needles,
Surgery,
Brachytherapy,
Shafts,
Robots,
Vibrations,
Trajectory"
Unbalanced Control Strategy for A Thyristor-Controlled LC-Coupling Hybrid Active Power Filter in Three-Phase Three-Wire Systems,"This paper proposes a control strategy for a three-phase three-wire thyristor-controlled LC -coupling hybrid active power filter (TCLC-HAPF), which can balance active power and compensate reactive power and harmonic currents under unbalanced loading. Compared with TCLC-HAPF with conventional control strategy, active power filters and hybrid active power filters which either fail to perform satisfactory compensation or require high-rating active inverter part for unbalanced compensation, a control strategy was proposed for TCLC-HAPF to operate with a small rating active inverter part for a variety of loads with satisfactory performance. The control idea is to provide different firing angles for each phase of the thyristor-controlled LC-coupling part (TCLC) to balance active power and compensate reactive power, while the active inverter part aims to compensate harmonic currents. First, the required different TCLC impedances are deduced. Then, independent firing angles referenced to the phase angle of voltage across TCLC are calculated. After angle transformations, final firing angles referenced to phase angle of load voltages are obtained. In this paper, a novel controller for TCLC-HAPF under unbalanced loading is proposed. Simulation and experimental results are provided to verify the effectiveness of the proposed controller in comparison with a state-of-the-art controller.","Inverters,
Reactive power,
Active filters,
Harmonic analysis,
Power harmonic filters,
Firing"
High-Performance 500 V Quasi- and Fully-Vertical GaN-on-Si pn Diodes,"This letter demonstrates quasi- and fully vertical GaN-on-Si pn diodes with record performance. The optimized device structure employs a highly conductive (ND >1020 cm-3) current collecting layer and a lightly carbon-doped drift layer. With this optimization, a differential specific on-resistance (RON) of 0.8-1 mΩ·cm2, a breakdown voltage (BV) over 500 V, and a high forward current (~kA/cm2) were demonstrated. Excellent RON and BV performance up to 300 °C were also obtained. A small reverse recovery time of 50 ns was demonstrated under switching conditions. With Baliga's figure of merit over 0.32 GW/cm2, these devices show the great potential of low-cost GaN-onSi vertical devices for future power applications.","Gallium nitride,
Substrates,
Schottky diodes,
Silicon,
P-i-n diodes,
Performance evaluation,
Leakage currents"
Smart Power Devices and ICs Using GaAs and Wide and Extreme Bandgap Semiconductors,"We evaluate and compare the performance and potential of GaAs and of wide and extreme bandgap semiconductors (SiC, GaN, Ga2O3, and diamond), relative to silicon, for power electronics applications. We examine their device structures and associated materials/process technologies and selectively review the recent experimental demonstrations of high voltage power devices and IC structures of these semiconductors. We discuss the technical obstacles that still need to be addressed and overcome before large-scale commercialization commences.","Silicon,
Silicon carbide,
Gallium arsenide,
Diamond,
Performance evaluation,
Gallium nitride,
Photonic band gap"
No-Reference Quality Assessment of Screen Content Pictures,"Recent years have witnessed a growing number of image and video centric applications on mobile, vehicular, and cloud platforms, involving a wide variety of digital screen content images. Unlike natural scene images captured with modern high fidelity cameras, screen content images are typically composed of fewer colors, simpler shapes, and a larger frequency of thin lines. In this paper, we develop a novel blind/no-reference (NR) model for accessing the perceptual quality of screen content pictures with big data learning. The new model extracts four types of features descriptive of the picture complexity, of screen content statistics, of global brightness quality, and of the sharpness of details. Comparative experiments verify the efficacy of the new model as compared with existing relevant blind picture quality assessment algorithms applied on screen content image databases. A regression module is trained on a considerable number of training samples labeled with objective visual quality predictions delivered by a high-performance full-reference method designed for screen content image quality assessment (IQA). This results in an opinion-unaware NR blind screen content IQA algorithm. Our proposed model delivers computational efficiency and promising performance. The source code of the new model will be available at: https://sites.google.com/site/guke198701/publications.","Distortion,
Computational modeling,
Complexity theory,
Image coding,
Feature extraction,
Predictive models,
Adaptation models"
Utility-Based Cooperative Spectrum Sensing Scheduling in Cognitive Radio Networks,"In this paper, we consider the problem of cooperative spectrum sensing scheduling (C3S) in a cognitive radio network (CRN) when there exist multiple primary channels. Our work focuses on a scenario in which each secondary user (SU) has the freedom to decide whether to participate in cooperative spectrum sensing; if not, the SU becomes a free rider. Such a mechanism can conserve the energy for spectrum sensing at a risk of sacrificing the spectrum sensing performance. To overcome this problem, we address the following two questions: “Which action (contributing to spectrum sensing or not) should be taken?” and “which channel should be sensed?” We model our framework as an evolutionary game in which each SU makes its decision based on its utility history and takes an action more frequently if it brings a relatively higher utility. We also develop a coalition formation algorithm based on the channel status, where each SU always chooses the coalition that brings the most information regarding the status of the corresponding channel. The simulation results demonstrate that the proposed scheme can guarantee the detection probability at a low false alarm rate. The results also indicate that our algorithm can satisfy different requirements by carefully tuning the system parameters.",
Goal-Driven Service Composition in Mobile and Pervasive Computing,"Mobile, pervasive computing environments respond to users’ requirements by providing access to and composition of various services over networked devices. In such an environment, service composition needs to satisfy a request’s goal, and be mobile-aware even throughout service discovery and service execution. A composite service also needs to be adaptable to cope with the environment’s dynamic network topology. Existing composition solutions employ goal-oriented planning to provide flexible composition, and assign service providers at runtime, to avoid composition failure. However, these solutions have limited support for complex service flows and composite service adaptation. This paper proposes a self-organizing, goal-driven service model for task resolution and execution in mobile pervasive environments. In particular, it proposes a decentralized heuristic planning algorithm based on backward-chaining to support flexible service discovery. Further, we introduce an adaptation architecture that allows execution paths to dynamically adapt, which reduces failures, and lessens re-execution effort for failure recovery. Simulation results show the suitability of the proposed mechanism in pervasive computing environments where providers are mobile, and it is uncertain what services are available. Our evaluation additionally reveals the model’s limits with regard to network dynamism and resource constraints.","Pervasive computing,
Planning,
Mobile communication,
Adaptation models,
Computational modeling,
Heuristic algorithms,
Network topology"
A Broadband Dual-Polarized Base Station Antenna With Sturdy Construction,"A broadband dual-polarized base station antenna with sturdy construction is presented in this letter. The antenna mainly contains four parts: main radiator, feeding baluns, bedframe, and reflector. First, two orthogonal dipoles are etched on a substrate as main radiator forming dual polarization. Two baluns are then introduced to excite the printed dipoles. Each balun has four bumps on the edges for electrical connection and fixation. The bedframe is designed to facilitate the installation, and the reflector is finally used to gain unidirectional radiation. Measured results show that the antenna has a 48% impedance bandwidth with reflection coefficient less than -15 dB and port isolation more than 22 dB. A four-element antenna array with 6° ± 2° electrical down tilt is also investigated for wideband base station application. The antenna and its array have the advantages of sturdy construction, high machining accuracy, ease of integration, and low cost. They can be used for broadband base station in the next-generation wireless communication system.",
Paid Prioritization and Its Impact on Net Neutrality,"The net neutrality debate has been centered on the question: should Internet service providers (ISPs) be allowed to differentiate services for Internet content traffic? The concern is that the differentiation imposed by selfish ISPs might discriminate content providers (CPs) and harm social welfare. Although market competition among ISPs would alleviate the problem and moderate the necessity for net neutrality regulations, the problem remains in monopolistic access markets. We focus on such a market and study paid prioritization where CPs voluntarily pay for prioritizing their traffic under shared capacity. We study an ISP's pricing strategy, CPs' choices of priority, and the resulting system equilibrium, based on which we derive the utility of the ISP and CPs as well as social welfare. This paper shows that: 1) an ISP's optimal pricing leads to an efficient differentiation among CPs, such that social welfare is close to its maximum; 2) although ISPs might inhibit capacity deployment in the short run, price regulation could solve this issue; and 3) under medium system scale and capacity cost, ISPs would have strong incentives to expand capacity under paid prioritization. From a welfare perspective, our results suggest that paid prioritization could be superior to the imposition of net neutrality regulations.","Network neutrality,
Internet,
Pricing,
Throughput,
Broadband communication,
Economics,
Measurement"
Revisiting Semi-Supervised Learning for Online Deceptive Review Detection,"With more consumers using online opinion reviews to inform their service decision making, opinion reviews have an economical impact on the bottom line of businesses. Unsurprisingly, opportunistic individuals or groups have attempted to abuse or manipulate online opinion reviews (e.g., spam reviews) to make profits and so on, and that detecting deceptive and fake opinion reviews is a topic of ongoing research interest. In this paper, we explain how semi-supervised learning methods can be used to detect spam reviews, prior to demonstrating its utility using a data set of hotel reviews.",
Caching in the Sky: Proactive Deployment of Cache-Enabled Unmanned Aerial Vehicles for Optimized Quality-of-Experience,"In this paper, the problem of proactive deployment of cache-enabled unmanned aerial vehicles (UAVs) for optimizing the quality-of-experience (QoE) of wireless devices in a cloud radio access network is studied. In the considered model, the network can leverage human-centric information, such as users' visited locations, requested contents, gender, job, and device type to predict the content request distribution, and mobility pattern of each user. Then, given these behavior predictions, the proposed approach seeks to find the user-UAV associations, the optimal UAVs' locations, and the contents to cache at UAVs. This problem is formulated as an optimization problem whose goal is to maximize the users' QoE while minimizing the transmit power used by the UAVs. To solve this problem, a novel algorithm based on the machine learning framework of conceptor-based echo state networks (ESNs) is proposed. Using ESNs, the network can effectively predict each user's content request distribution and its mobility pattern when limited information on the states of users and the network is available. Based on the predictions of the users' content request distribution and their mobility patterns, we derive the optimal locations of UAVs as well as the content to cache at UAVs. Simulation results using real pedestrian mobility patterns from BUPT and actual content transmission data from Youku show that the proposed algorithm can yield 33.3% and 59.6% gains, respectively, in terms of the average transmit power and the percentage of the users with satisfied QoE compared with a benchmark algorithm without caching and a benchmark solution without UAVs.","Prediction algorithms,
Base stations,
Mobile communication,
Wireless communication,
Predictive models,
Unmanned aerial vehicles"
A Deep Convolutional Coupling Network for Change Detection Based on Heterogeneous Optical and Radar Images,"We propose an unsupervised deep convolutional coupling network for change detection based on two heterogeneous images acquired by optical sensors and radars on different dates. Most existing change detection methods are based on homogeneous images. Due to the complementary properties of optical and radar sensors, there is an increasing interest in change detection based on heterogeneous images. The proposed network is symmetric with each side consisting of one convolutional layer and several coupling layers. The two input images connected with the two sides of the network, respectively, are transformed into a feature space where their feature representations become more consistent. In this feature space, the different map is calculated, which then leads to the ultimate detection map by applying a thresholding algorithm. The network parameters are learned by optimizing a coupling function. The learning process is unsupervised, which is different from most existing change detection methods based on heterogeneous images. Experimental results on both homogenous and heterogeneous images demonstrate the promising performance of the proposed network compared with several existing approaches.","Optical sensors,
Optical imaging,
Feature extraction,
Neural networks,
Couplings,
Laser radar"
Searching Trajectories by Regions of Interest,"With the increasing availability of moving-object tracking data, trajectory search is increasingly important. We propose and investigate a novel query type named trajectory search by regions of interest (TSR query). Given an argument set of trajectories, a TSR query takes a set of regions of interest as a parameter and returns the trajectory in the argument set with the highest spatial-density correlation to the query regions. This type of query is useful in many popular applications such as trip planning and recommendation, and location based services in general. TSR query processing faces three challenges: how to model the spatial-density correlation between query regions and data trajectories, how to effectively prune the search space, and how to effectively schedule multiple so-called query sources. To tackle these challenges, a series of new metrics are defined to model spatial-density correlations. An efficient trajectory search algorithm is developed that exploits upper and lower bounds to prune the search space and that adopts a query-source selection strategy, as well as integrates a heuristic search strategy based on priority ranking to schedule multiple query sources. The performance of TSR query processing is studied in extensive experiments based on real and synthetic spatial data.",
Distributed Finite-Time Cooperative Control of Multiple High-Order Nonholonomic Mobile Robots,"The consensus problem of multiple nonholonomic mobile robots in the form of high-order chained structure is considered in this paper. Based on the model features and the finite-time control technique, a finite-time cooperative controller is explicitly constructed which guarantees that the states consensus is achieved in a finite time. As an application of the proposed results, finite-time formation control of multiple wheeled mobile robots is studied and a finite-time formation control algorithm is proposed. To show effectiveness of the proposed approach, a simulation example is given.","Mobile robots,
Algorithm design and analysis,
Convergence,
Decentralized control,
Multi-agent systems,
Indexes"
Bioinspired Ciliary Force Sensor for Robotic Platforms,"The detection of small forces is of great interest in any robotic application that involves interaction with the environment (e.g., objects manipulation, physical human-robot interaction, minimally invasive surgery), since it allows the robot to detect the contacts early on and to act accordingly. In this letter, we present a sensor design inspired by the ciliary structure frequently found in nature, consisting of an array of permanently magnetized cylinders (cilia) patterned over a giant magnetoresistance sensor (GMR). When these cylinders are deformed in shape due to applied forces, the stray magnetic field variation will change the GMR sensor resistivity, thus enabling the electrical measurement of the applied force. In this letter, we present two 3 mm × 3 mm prototypes composed of an array of five cilia with 1 mm of height and 120 and 200 μm of diameter for each prototype. A minimum force of 333 μN was measured. A simulation model for determining the magnetized cylinders average stray magnetic field is also presented.","Robot sensing systems,
Force,
Fabrication,
Deformable models,
Magnetization"
Look Wider to Match Image Patches With Convolutional Neural Networks,"When a human matches two images, the viewer has a natural tendency to view the wide area around the target pixel to obtain clues of right correspondence. However, designing a matching cost function that works on a large window in the same way is difficult. The cost function is typically not intelligent enough to discard the information irrelevant to the target pixel, resulting in undesirable artifacts. In this letter, we propose a novel convolutional neural network (CNN) module to learn a stereo matching cost with a large-sized window. Unlike conventional pooling layers with strides, the proposed per-pixel pyramid-pooling layer can cover a large area without a loss of resolution and detail. Therefore, the learned matching cost function can successfully utilize the information from a large area without introducing the fattening effect. The proposed method is robust despite the presence of weak textures, depth discontinuity, illumination, and exposure difference. The proposed method achieves near-peak performance on the Middlebury benchmark.",
Space-Time and Space-Frequency Block Coded Vector OFDM Modulation,"Vector orthogonal frequency division multiplexing (OFDM) is a promising modulation scheme, which allows for a flexible configuration and connects OFDM and single-carrier frequency domain equalization in a unified framework. In this letter, we design Alamouti-like space-time block coded and space-frequency block coded vector OFDM systems. Based on these schemes, we prove that, with two transmit and one receive antenna, the diversity order of the zero-forcing receiver is fixed to 2 over frequency selective fading channels, while that of the minimum mean square error receiver depends on the channel memory length, the vector block size, and the spectral efficiency.","OFDM,
Frequency-domain analysis,
Receiving antennas,
Frequency diversity,
Indexes"
Wafer Sojourn Time Fluctuation Analysis of Time-Constrained Dual-Arm Cluster Tools With Wafer Revisiting and Activity Time Variation,"A robotic cluster tool involves many activities whose time is subject to some disturbance, thus leading to the activity time variation. It results in wafer sojourn time fluctuation in a process module, which may in turn violate wafer residency time constraints. Some wafer fabrication requires a revisiting process. With wafer revisiting, the effect of activity time variation on wafer sojourn time fluctuation is so complicated that no analysis was reported to the best knowledge of the authors. It is vitally important to accurately analyze it. To do so, this paper adopts a Petri net model to describe the dynamical behavior of cluster tools. With this model, a real-time control policy is proposed to offset the effect of the activity time variation on wafer sojourn time fluctuation as much as possible. Then, the wafer sojourn time delay is analyzed and algorithms are developed to calculate its exact upper bound. With the proposed method, one can check if a given schedule is feasible under bounded activity time variation. Some practical examples are given to show the application of the proposed approach.","Robots,
Semiconductor device modeling,
Time factors,
Optimal scheduling,
Delay effects,
Schedules"
Accuracy Improvement of Extremum Seeking Control,"In this work, we present a modification for the classic and phasor extremum seeking control algorithms in order to improve the accuracy by removing or reducing the convergence error. The modulation signals were replaced by a sum of sinusoids in order to remove the equilibrium shift in the controlled variable of the averaged system. The convergence error is calculated as a function of the number of sinusoids used in the modulation signal. A simulation example is presented to illustrate the improvement.","Convergence,
Modulation,
Optimization,
Kalman filters,
Noise measurement,
Steady-state,
Indexes"
Event-Triggered Optimal Control for Partially Unknown Constrained-Input Systems via Adaptive Dynamic Programming,"Event-triggered control has been an effective tool in dealing with problems with finite communication and computation resources. In this paper, we design an event-triggered control for nonlinear constrained-input continuous-time systems based on the optimal policy. Constraints on controls are handled using a bounded function. To learn the optimal solution with partially unknown dynamics, an online adaptive dynamic programming algorithm is proposed. The identifier network, the critic network, and the actor network are employed to approximate the unknown drift dynamics, the optimal value, and the optimal policy, respectively. The identifier is tuned based on online data, which further trains the critic and actor at triggering instants. A concurrent learning technique repeatedly uses past data to train the critic. Stability of the closed-loop system, and convergence of neural networks to the optimal solutions are proved by Lyapunov analysis. In the end, the algorithm is applied to the overhead crane system to observe the performance. The event-triggered optimal controller with constraints stabilizes the system and consumes much less sampling times.","Heuristic algorithms,
Algorithm design and analysis,
Optimal control,
Convergence,
Robots,
Dynamic programming"
Latent Max-Margin Multitask Learning With Skelets for 3-D Action Recognition,"Recent emergence of low-cost and easy-operating depth cameras has reinvigorated the research in skeleton-based human action recognition. However, most existing approaches overlook the intrinsic interdependencies between skeleton joints and action classes, thus suffering from unsatisfactory recognition performance. In this paper, a novel latent max-margin multitask learning model is proposed for 3-D action recognition. Specifically, we exploit skelets as the mid-level granularity of joints to describe actions. We then apply the learning model to capture the correlations between the latent skelets and action classes each of which accounts for a task. By leveraging structured sparsity inducing regularization, the common information belonging to the same class can be discovered from the latent skelets, while the private information across different classes can also be preserved. The proposed model is evaluated on three challenging action data sets captured by depth cameras. Experimental results show that our model consistently achieves superior performance over recent state-of-the-art approaches.","Skeleton,
Hidden Markov models,
Correlation,
Solid modeling,
Cameras,
Trajectory,
Manifolds"
LZ-End Parsing in Compressed Space,"We present an algorithm that constructs the LZ-End parsing (a variation of LZ77) of a given string of length n in O(n log l) expected time and O(z + l) space, where z is the number of phrases in the parsing and l is the length of the longest phrase. As an option, we can fix l (e.g., to the size of RAM) thus obtaining a reasonable LZ-End approximation with the same functionality and the length of phrases restricted by l. This modified algorithm constructs the parsing in streaming fashion in one left to right pass on the input string w.h.p. and performs one right to left pass to verify the correctness of the result. Experimentally comparing this version to other LZ77-based analogs, we show that it is of practical interest.","Approximation algorithms,
Aerospace electronics,
Upper bound,
Memory management,
Lenses,
Data compression,
Computer science"
Low-Rank Discriminant Embedding for Multiview Learning,"This paper focuses on the specific problem of multiview learning where samples have the same feature set but different probability distributions, e.g., different viewpoints or different modalities. Since samples lying in different distributions cannot be compared directly, this paper aims to learn a latent subspace shared by multiple views assuming that the input views are generated from this latent subspace. Previous approaches usually learn the common subspace by either maximizing the empirical likelihood, or preserving the geometric structure. However, considering the complementarity between the two objectives, this paper proposes a novel approach, named low-rank discriminant embedding (LRDE), for multiview learning by taking full advantage of both sides. By further considering the duality between data points and features of multiview scene, i.e., data points can be grouped based on their distribution on features, while features can be grouped based on their distribution on the data points, LRDE not only deploys low-rank constraints on both sample level and feature level to dig out the shared factors across different views, but also preserves geometric information in both the ambient sample space and the embedding feature space by designing a novel graph structure under the framework of graph embedding. Finally, LRDE jointly optimizes low-rank representation and graph embedding in a unified framework. Comprehensive experiments in both multiview manner and pairwise manner demonstrate that LRDE performs much better than previous approaches proposed in recent literatures.","Face,
Euclidean distance,
Laplace equations,
Kernel,
Training,
Robustness,
Manifolds"
"Through Silicon Via (TSV) Defect Modeling, Measurement, and Analysis","Through silicon via (TSV)-based 3-D integrated circuit has introduced the solution to limitlessly growing demand on high system bandwidth, low power consumption, and small form factor of electronic devices. As the system design aims for higher performance, the physical dimensions of the channels are continuously decreasing. With TSV diameter of less than 10 μm and pitch of several tens of micrometers, the I/O count has increased up to the order of tens of thousands for wide bandwidth data transmission. However, without highly precise fabrication process, such small structures are susceptible to a variety of defects. For the first time, in this paper, we propose a noninvasive defect analysis method for high-speed TSV channel. With designed and fabricated test vehicles, the proposed method is demonstrated with S-parameter and time-domain reflectometry measurement results. In addition, we present equivalent circuit models of TSV daisy-chain structures, including the circuit components for open defect and short defect. With characterized dominant factors in each frequency range, S11 is analyzed to distinguish and locate the defects by the amount of capacitance, resistance, and inductance that the signal experiences. S-parameter measurement sufficiently allows high-frequency defect analysis of TSV channel without destroying the test sample. We experimentally verified the accuracy of the suggested model by comparing the S-parameter results from circuit simulations and measurements. Finally, the model is modified to discuss the effects of open defect and short defect on the electrical characteristics of TSV channel.","Through-silicon vias,
Integrated circuit modeling,
Equivalent circuits,
Scattering parameters,
Resistance,
Capacitance"
Provably Secure Dynamic ID-Based Anonymous Two-Factor Authenticated Key Exchange Protocol With Extended Security Model,"Authenticated key exchange (AKE) protocol allows a user and a server to authenticate each other and generate a session key for the subsequent communications. With the rapid development of low-power and highly-efficient networks, such as pervasive and mobile computing network in recent years, many efficient AKE protocols have been proposed to achieve user privacy and authentication in the communications. Besides secure session key establishment, those AKE protocols offer some other useful functionalities, such as two-factor user authentication and mutual authentication. However, most of them have one or more weaknesses, such as vulnerability against lost-smart-card attack, offline dictionary attack, de-synchronization attack, or the lack of forward secrecy, and user anonymity or untraceability. Furthermore, an AKE scheme under the public key infrastructure may not be suitable for light-weight computational devices, and the security model of AKE does not capture user anonymity and resist lost-smart-card attack. In this paper, we propose a novel dynamic ID-based anonymous two-factor AKE protocol, which addresses all the above issues. Our protocol also supports smart card revocation and password update without centralized storage. Further, we extend the security model of AKE to support user anonymity and resist lost-smart-card attack, and the proposed scheme is provably secure in extended security model. The low-computational and bandwidth cost indicates that our protocol can be deployed for pervasive computing applications and mobile communications in practice.",
Distributed Event-Based Set-Membership Filtering for a Class of Nonlinear Systems With Sensor Saturations Over Sensor Networks,"In this paper, the distributed set-membership filtering problem is investigated for a class of discrete time-varying system with an event-based communication mechanism over sensor networks. The system under consideration is subject to sector-bounded nonlinearity, unknown but bounded noises and sensor saturations. Each intelligent sensing node transmits the data to its neighbors only when certain triggering condition is violated. By means of a set of recursive matrix inequalities, sufficient conditions are derived for the existence of the desired distributed event-based filter which is capable of confining the system state in certain ellipsoidal regions centered at the estimates. Within the established theoretical framework, two additional optimization problems are formulated: one is to seek the minimal ellipsoids (in the sense of matrix trace) for the best filtering performance, and the other is to maximize the triggering threshold so as to reduce the triggering frequency with satisfactory filtering performance. A numerically attractive chaos algorithm is employed to solve the optimization problems. Finally, an illustrative example is presented to demonstrate the effectiveness and applicability of the proposed algorithm.","Time-varying systems,
Sensors,
Ellipsoids,
Topology,
Nonlinear systems,
Optimization,
Network topology"
Innovation Pursuit: A New Approach to Subspace Clustering,"In subspace clustering, a group of data points belonging to a union of subspaces are assigned membership to their respective subspaces. This paper presents a new approach dubbed Innovation Pursuit (iPursuit) to the problem of subspace clustering using a new geometrical idea whereby subspaces are identified based on their relative novelties. We present two frameworks in which the idea of innovation pursuit is used to distinguish the subspaces. Underlying the first framework is an iterative method that finds the subspaces consecutively by solving a series of simple linear optimization problems, each searching for a direction of innovation in the span of the data potentially orthogonal to all subspaces except for the one to be identified in one step of the algorithm. A detailed mathematical analysis is provided establishing sufficient conditions for iPursuit to correctly cluster the data. The proposed approach can provably yield exact clustering even when the subspaces have significant intersections. It is shown that the complexity of the iterative approach scales only linearly in the number of data points and subspaces, and quadratically in the dimension of the subspaces. The second framework integrates iPursuit with spectral clustering to yield a new variant of spectral-clustering-based algorithms. The numerical simulations with both real and synthetic data demonstrate that iPursuit can often outperform the state-of-the-art subspace clustering algorithms, more so for subspaces with significant intersections, and that it significantly improves the state-of-the-art result for subspace-segmentation-based face clustering.","Technological innovation,
Clustering algorithms,
Signal processing algorithms,
Iterative methods,
Data models,
Algorithm design and analysis,
Silicon"
Asynchronous State Estimation for Discrete-Time Switched Complex Networks With Communication Constraints,"This paper is concerned with the asynchronous state estimation for a class of discrete-time switched complex networks with communication constraints. An asynchronous estimator is designed to overcome the difficulty that each node cannot access to the topology/coupling information. Also, the event-based communication, signal quantization, and the random packet dropout problems are studied due to the limited communication resource. With the help of switched system theory and by resorting to some stochastic system analysis method, a sufficient condition is proposed to guarantee the exponential stability of estimation error system in the mean-square sense and a prescribed $H∞ performance level is also ensured. The characterization of the desired estimator gains is derived in terms of the solution to a convex optimization problem. Finally, the effectiveness of the proposed design approach is demonstrated by a simulation example.",
Optoelectronic Oscillators for High Speed and High Resolution Optical Sensing,"An optoelectronic oscillator (OEO) can be employed to perform high speed and ultra-high resolution optical sensing. The fundamental concept is to convert a measurand-dependent wavelength change in the optical domain to a frequency change of an OEO-generated microwave signal in the microwave domain. Since the frequency of a microwave signal can be measured by a digital signal processor at a high speed and high resolution, an OEO-based optical sensor is able to provide optical interrogation at a high speed and ultra-high resolution. In this paper, OEO-based optical sensors proposed for strain, temperature, or transverse load sensing are discussed. The key to implement an OEO-based optical sensor is to implement a microwave photonic filter with a passband having a center frequency that is a function of the optical wavelength change. In this paper, techniques to implement microwave photonic filter for OEO-based optical sensing are discussed.","Microwave filters,
Microwave oscillators,
Microwave photonics,
Optical filters,
Optical fiber sensors,
Microwave measurement"
Coping with Volume and Variety in Temporal Event Sequences: Strategies for Sharpening Analytic Focus,"The growing volume and variety of data presents both opportunities and challenges for visual analytics. Addressing these challenges is needed for big data to provide valuable insights and novel solutions for business, security, social media, and healthcare. In the case of temporal event sequence analytics it is the number of events in the data and variety of temporal sequence patterns that challenges users of visual analytic tools. This paper describes 15 strategies for sharpening analytic focus that analysts can use to reduce the data volume and pattern variety. Four groups of strategies are proposed: (1) extraction strategies, (2) temporal folding, (3) pattern simplification strategies, and (4) iterative strategies. For each strategy, we provide examples of the use and impact of this strategy on volume and/or variety. Examples are selected from 20 case studies gathered from either our own work, the literature, or based on email interviews with individuals who conducted the analyses and developers who observed analysts using the tools. Finally, we discuss how these strategies might be combined and report on the feedback from 10 senior event sequence analysts.","Focusing,
Visual analytics,
Data visualization,
Pattern recognition,
Sequences"
Distributed Optimal Control of Smart Electricity Grids With Congestion Management,"In this paper, we consider the balancing problem in a hierarchical market-based structure for smart energy grids that is based on the Universal Smart Energy Framework. The large-scale introduction of renewable, intermittent energy sources in the power system can create a mismatch between the forecasted (day ahead) and the actual supply and demand. Without a proper control strategy, this deviation could lead to network overloads and commercial losses. We present a multilevel distributed optimal control formulation to the problem, in which the appliances of prosumers that can provide flexibility are optimally dispatched based on local information. The control strategy takes the capacity limitations of the distribution network into account. We provide example simulation results, obtained by distributed model predictive control. We propose a control strategy that aims to minimize the imbalance between forecasted and actual supply and demand in electricity grids. This is important, because the imbalance can lead to commercial losses for the stakeholders. Since the number of agents (i.e., households) in the power network is typically large, centralized controllers are not feasible due to scalability issues. We instead develop a distributed controller that solves the problem using only local information. We demonstrate our algorithm through simulations, which are implemented on a single computer. In practice, households can have smart meters on which the individual controllers run, thereby obtaining the solution in a parallel fashion.","Cogeneration,
Heat pumps,
Smart grids,
Production,
Home appliances,
Resistance heating,
Planning"
Energy-Aware Resource and Revenue Management in Federated Cloud: A Game-Theoretic Approach,"Reduction of energy expenditure is becoming an important issue for a cloud provider (CP) when providing cloud services over the Internet. Federation among CPs, whereby a set of CPs cooperating together to provide virtual machine (VM) instances requested by users, can be an effective solution to address this issue. In this paper, we present an effective capacity-sharing mechanism in a federated cloud environment that can lead to a global energy sustainability policy for the federation and encourages them to cooperate. A coalition game theory was utilized to model various interactions among providers. However, unlike the existing approaches, the proposed game model looks for a set of low-energy-cost CPs in a federation such that the social welfare is maximized and provides a fare and suitable revenue for them. In addition, we consider the demand variations of internal users of a CP when sharing VM resources. Moreover, a detailed analysis of various costs and revenue aspects is presented. Experiment results demonstrated that the proposed game model is able to maximize the social welfare of the CPs while satisfying the fairness and stability properties of the federation.","Games,
Servers,
Mathematical model,
Cloud computing,
Computational modeling,
Collaboration,
Power demand"
A Flexure-Based Parallel Actuation Dual-Stage System for Large-Stroke Nanopositioning,"This paper presents a novel parallel actuation dual-stage system that delivers nanometric positioning over a large displacement. Unlike those traditional dual-stage designs, the translator of fine actuator in the proposed design is mechanically connected to the coarse translator via the flexure mechanism, while the actuation coils of both the coarse and fine actuators lay underneath the translators in parallel. The merits of the proposed parallel actuation dual-stage design are mainly twofold. First, both the coarse and fine actuators utilize the moving-magnet configuration, hence the translators do not need to carry any cables for power supply. Second, the coarse motion can exhibit better dynamics and energy efficiency due to the minimized moving size and weight. In this work, an analytical current-force model is established for the coarse actuator considering higher order harmonic magnetic field, and based on the proposed model, the force ripple of coarse actuator is quantitatively analyzed both in theory and in practical. Furthermore, a disturbance observer is employed in the dual-feedback configuration to deal with the uncertainties with the proved asymptotic stability. The experimental results show that the proposed dual-stage positioning system is capable to achieve 20 nm step resolution with a root mean square error of 13.15 nm, and the 5 mm point-to-point positioning error can achieve less than 40 nm.",
Instantly Decodable Network Coding: From Centralized to Device-to-Device Communications,"From its introduction to its quindecennial, network coding has built a strong reputation for enhancing packet recovery and achieving maximum information flow in both wired and wireless networks. Traditional studies focused on optimizing the throughput of the system by proposing elaborate schemes able to reach the network capacity. With the shift toward distributed computing on mobile devices, performance and complexity become both critical factors that affect the efficiency of a coding strategy. Instantly decodable network coding presents itself as a new paradigm in network coding that trades off these two aspects. This paper review instantly decodable network coding schemes by identifying, categorizing, and evaluating various algorithms proposed in the literature. The first part of the manuscript investigates the conventional centralized systems, in which all decisions are carried out by a central unit, e.g., a base-station. In particular, two successful approaches known as the strict and generalized instantly decodable network are compared in terms of reliability, performance, complexity, and packet selection methodology. The second part considers the use of instantly decodable codes in a device-to-device communication network, in which devices speed up the recovery of the missing packets by exchanging network coded packets. Although the performance improvements are directly proportional to the computational complexity increases, numerous successful schemes from both the performance and complexity viewpoints are identified.","Network coding,
Receivers,
Encoding,
Device-to-device communication,
Delays,
Throughput,
Complexity theory"
Bypassing the Natural Visual-Motor Pathway to Execute Complex Movement Related Tasks Using Interval Type-2 Fuzzy Sets,"In visual-motor coordination, the human brain processes visual stimuli representative of complex motion-related tasks at the occipital lobe to generate the necessary neuronal signals for the parietal and pre-frontal lobes, which in turn generates movement related plans to excite the motor cortex to execute the actual tasks. The paper introduces a novel approach to provide rehabilitative support to patients suffering from neurological damage in their pre-frontal, parietal and/or motor cortex regions. An attempt to bypass the natural visual-motor pathway is undertaken using interval type-2 fuzzy sets to generate the approximate EEG response of the damaged pre-frontal/parietal/motor cortex from the occipital EEG signals. The approximate EEG response is used to trigger a pre-trained joint coordinate generator to obtain the desired joint coordinates of the link end-points of a robot imitating the human subject. The robot arm is here employed as a rehabilitative aid in order to move each link end-points to the desired locations in the reference coordinate system by appropriately activating its links using the well-known inverse kinematics approach. The mean-square positional errors obtained for each link end-points is found within acceptable limits for all experimental subjects including subjects with partial parietal damage, indicating a possible impact of the proposed approach in rehabilitative robotics. Subjective variation in EEG features over different sessions of experimental trials is modeled here using interval type-2 fuzzy sets for its inherent power to handle uncertainty. Experiments undertaken confirm that interval type-2 fuzzy realization outperforms its classical type-1 counterpart and back-propagation neural approaches in all experimental cases, considering link positional error as a metric. The proposed research offers a new opening for the development of possible rehabilitative aids for people with partial impairment in visual-motor coordination.","Electroencephalography,
Fuzzy sets,
Robot kinematics,
Visualization,
Uncertainty,
Robot sensing systems"
Biased Multiobjective Optimization and Decomposition Algorithm,"The bias feature is a major factor that makes a multiobjective optimization problem (MOP) difficult for multiobjective evolutionary algorithms (MOEAs). To deal with this problem feature, an algorithm should carefully balance between exploration and exploitation. The decomposition-based MOEA decomposes an MOP into a number of single objective subproblems and solves them in a collaborative manner. Single objective optimizers can be easily used in this algorithm framework. Covariance matrix adaptation evolution strategy (CMA-ES) has proven to be able to strike good balance between the exploration and the exploitation of search space. This paper proposes a scheme to use both differential evolution (DE) and covariance matrix adaptation in the MOEA based on decomposition. In this scheme, single objective optimization problems are clustered into several groups. To reduce the computational overhead, only one subproblem from each group is selected to optimize by CMA-ES while other subproblems are optimized by DE. When an evolution strategy procedure meets some stopping criteria, it will be reinitialized and used for solving another subproblem in the same group. A set of new multiobjective test problems with bias features are constructed in this paper. Extensive experimental studies show that our proposed algorithm is suitable for dealing with problems with biases.","Optimization,
Covariance matrices,
Evolutionary computation,
Benchmark testing,
Computational modeling,
Computer science,
Sociology"
Rectangular Differential Spatial Modulation for Open-Loop Noncoherent Massive-MIMO Downlink,"In this paper, a novel differential space-time coding scheme is conceived for open-loop noncoherent multiple-input multiple-output (MIMO) downlink scenarios, where the transmission rate increases logarithmically in a scalable manner upon increasing the number of transmit antennas. More specifically, the proposed scheme relies on the projection of a differentially encoded square matrix to its rectangular counterpart and so is capable of reducing the number of symbol intervals needed for block transmission. This is especially beneficial for massive MIMO scenarios, in which the number of transmit antennas is very high. Another advantage exclusive to the presented scheme is that no channel state information (CSI) is required at either the transmitter or the receiver, which eliminates pilot overhead, CSI estimation, CSI feedback, and time-division duplex reciprocity. Furthermore, the rectangular transmission matrix of the proposed scheme contains only a single non-zero element per column, and hence, the transmitter may rely on only a single RF chain, similar to the conventional coherent spatial modulation scheme.","MIMO,
Transmitting antennas,
Receivers,
Encoding,
Downlink,
Modulation"
Optimal Cooperative Content Caching and Delivery Policy for Heterogeneous Cellular Networks,"To address the explosively growing demand for mobile data services in the 5th generation (5G) mobile communication system, it is important to develop efficient content caching and distribution techniques, aiming at significantly reducing redundant data transmissions and improving content delivery efficiency. In heterogeneous cellular network (HetNet), which has been deemed as a promising architectural technique for 5G, caching some popular content items at femto base-stations (FBSs) and even at user equipment (UE) can be exploited to alleviate the burden of backhaul and to reduce the costly transmissions from the macro base-stations to UEs. In this paper, we develop the optimal cooperative content caching and delivery policy, for which FBSs and UEs are all engaged in local content caching. We formulate the cooperative content caching problem as an integer-linear programming problem, and use hierarchical primal-dual decomposition method to decouple the problem into two level optimization problems, which are solved by using the subgradient method. Furthermore, we design the optimal content delivery policy, which is formulated as an unbalanced assignment problem and solved by using Hungarian algorithm. Numerical results have shown that the proposed cooperative content caching and delivery policy can significantly improve content delivery performance in comparison with existing caching strategies.","Mobile computing,
Femtocells,
Servers,
Signal to noise ratio,
5G mobile communication"
Output Feedback Stabilization for Discrete-Time Systems Under Limited Communication,"This paper addresses the output feedback stabilization problem for discrete-time networked control systems with imperfect input channels, i.e., the controller-actuator channels, where both quantization error and packet dropout are involved. A stabilizability condition is first derived for the single-input-single-output (SISO) case. It is shown that stabilization over quantized lossy channel actually involves a trade-off between robust stability control and robust performance control. Furthermore, the results are expanded to triangularly decoupled multiple-input-multiple-output (MIMO) systems and a necessary and sufficient condition is deduced, which also exhibits a compromise between robust stability control and robust performance control in the individual channel as echoing the SISO case.","Quantization (signal),
MIMO,
Stability analysis,
Robustness,
Output feedback,
Loss measurement,
Actuators"
Learning How to Construct Models of Dynamic Systems: An Initial Evaluation of the Dragoon Intelligent Tutoring System,"Constructing models of dynamic systems is an important skill in both mathematics and science instruction. However, it has proved difficult to teach. Dragoon is an intelligent tutoring system intended to quickly and effectively teach this important skill. This paper describes Dragoon and an evaluation of it. The evaluation randomly assigned students in a university class to either Dragoon or baseline instruction that used Dragoon as an editor only. Among students who did use their systems, the tutored students scored reliably higher (p <; .021, d = 1.06) on the post-test than the students who used only the conventional editor-based instruction.",
A New Cloud Computing Architecture for the Classification of Remote Sensing Data,"This paper proposes a new distributed architecture for supervised classification of large volumes of earth observation data on a cloud computing environment. The architecture supports distributed execution, network communication, and fault tolerance in a transparent way to the user. The architecture is composed of three abstraction layers, which support the definition and implementation of applications by researchers from different scientific investigation fields. The implementation of architecture is also discussed. A software prototype (available online), which runs machine learning routines implemented on the cloud using the Waikato Environment for Knowledge Analysis (WEKA), a popular free software licensed under the GNU General Public License, is used for validation. Performance issues are addressed through an experimental analysis in which two supervised classifiers available in WEKA were used: random forest and support vector machines. This paper further describes how to include other classification methods in the available software prototype.","Computer architecture,
Training,
Remote sensing,
Cloud computing,
Data mining,
Programming,
Earth"
Adaptive Fuzzy Leader-Following Consensus Control for Stochastic Multiagent Systems with Heterogeneous Nonlinear Dynamics,"This paper focuses on the leader-following consensus control problem of multiagent systems in random vibration environment. The Itô stochastic systems with heterogeneous unknown dynamics and external disturbances are established to describe the agents in random vibration environment. The fuzzy logic systems are applied to approximate the unknown nonlinear dynamics, and one adaptive parameter is designed to decay the effect of external disturbances. We present a new distributed consensus controller for each follower agent only based on local information that is measured or received from its neighbors and itself. Under the consensus controller, we prove that all the follower agents can keep consensus with the leader, even though only a very small part of follower agents can measure or receive the state information of the leader. Furthermore, the states of all the follower agents are bounded in probability. Finally, the simulation results are provided to illustrate the effectiveness of the designed algorithm.","Multi-agent systems,
Stochastic processes,
Nonlinear dynamical systems,
Fuzzy logic,
Vibrations,
Stochastic systems"
A switched-coupling-capacitor equalizer for series-connected battery strings,"An automatic switched-coupling-capacitor equalizer (SCCE) is proposed, which can realize the any-cells-to-any-cells equalization for a battery string. Only two switches and one capacitor are needed for each battery cell. All MOSFETs are controlled by a pair of complementary PWM signals, and energy can be automatically and directly delivered from any higher voltage cells to any lower voltage ones without the need of monitoring circuits. The inherent advantages of the proposed system are the simple control, high efficiency, and easy modularization. A prototype for four lithium-ion battery cells is implemented, and a comparison between the proposed circuit and the conventional one is presented. Experimental results show the proposed circuit exhibits a substantially improved balancing performance, and the measured peak efficiency is about 92.7%.","Batteries,
Capacitors,
Equalizers,
Couplings,
Switches,
MOSFET,
Voltage control"
Topology-Aware Prediction of Virtual Network Function Resource Requirements,"Network functions virtualization (NFV) continues to gain attention as a paradigm shift in the way telecommunications services are deployed and managed. By separating network function from traditional middleboxes, NFV is expected to lead to reduced capital expenditure and operating expenditure, and to more agile services. However, one of the main challenges to achieving these objectives is how physical resources can be efficiently, autonomously, and dynamically allocated to virtualized network function (VNF) whose resource requirements ebb and flow. In this paper, we propose a graph neural network-based algorithm which exploits VNF forwarding graph topology information to predict future resource requirements for each VNF component (VNFC). The topology information of each VNFC is derived from combining its past resource utilization as well as the modeled effect on the same from VNFCs in its neighborhood. Our proposal has been evaluated using a deployment of a virtualized IP multimedia subsystem, and real VoIP traffic traces, with results showing an average prediction accuracy of 90%, compared to 85% obtained while using traditional feed-forward neural networks. Moreover, compared to a scenario where resources are allocated manually and/or statically, our technique reduces the average number of dropped calls by at least 27% and improves call setup latency by over 29%.","Neural networks,
Topology,
Resource management,
Reliability,
Proposals,
Multimedia communication,
Dynamic scheduling"
"Multihop V2I Communications: A Feasibility Study, Modeling, and Performance Analysis","In typical wireless networks, multihop communication is a method used to establish connectivity between distant nodes. Adapting this technique to vehicular networks requires bypassing several challenging constraints imposed by the nature of vehicular environments (e.g., high mobility and speeds and repetitive link disruptions). This paper revolves around establishing a multihop connectivity path between an isolated source vehicle S and a faraway gateway roadside unit (RSU) D through cooperative vehicles serving as intermediate relays. A stochastic model is formulated for the purpose of deriving an expression for the probability of the existence of a connectivity path between S and D. Then, the dynamic changes in the network topology are carefully examined to present a tight upper bound for the average end-to-end packet delivery delay. Finally, taking into account the inherent contention-based nature of the employed IEEE 802.11p medium access control (MAC) protocol, together with several other limiting factors such as relay unavailability and hidden terminals, the per-hop and the end-to-end throughput expressions are presented. Extensive simulations are conducted for the purpose of validating the proposed model and examining the system's performance.","Vehicles,
Spread spectrum communication,
Delays,
Network topology,
Road transportation,
Mathematical model,
Relays"
FoToNoC: A Folded Torus-Like Network-on-Chip Based Many-Core Systems-on-Chip in the Dark Silicon Era,"Dark silicon refers to the phenomenon that a fraction of a many-core chip has to become “dark” or “dim” in order to guarantee the system to be kept in a safe temperature range and allowable power budget. Techniques have been developed to selectively activate non-adjacent cores on many-core chip to avoid temperature hotspot, while resulting unexpected increase of communication overhead due to the longer average distance between active cores, and in turn affecting application performance and energy efficiency, when Network-on-Chip (NoC) is used as a scalable communication subsystem. To address the brand-new challenges brought by dark silicon, in this paper, we present FoToNoC, a Folded Torus-like NoC, coupled with a hierarchical management strategy for heterogeneous many-core systems. On top of it, objectives of maximizing application performance, energy efficiency and chip reliability are isolated and well achieved by hardware-software co-design in several different phases, including application mapping and scheduling, cluster management and DVFS control. Evaluations on PARSEC benchmark applications demonstrate the significance of the entire strategy. Compared with state-of-the-art approaches, the proposed FoToNoC organization can achieve on average 35.4 and 35.2 percent on communication efficiency and application performance improvement, respectively, when maintaining the safe chip temperature. The hierarchical cluster-based management strategy can further reduce an average 34.6 percent of the total energy consumption with a notable reduction on the chip peak temperature. The significant achievements on system energy efficiency and the reduction on chip temperature of H.264 decoder and DSP-stone benchmarks additionally verify the effectiveness of the proposed methods.","Silicon,
Thermal management,
Reliability,
Computer architecture,
Optimization,
Scheduling,
Transistors"
Multi-Timescale Collaborative Tracking,"We present the multi-timescale collaborative tracker for single object tracking. The tracker simultaneously utilizes different types of “forces”, namely attraction, repulsion and support, to take advantage of their complementary strengths. We model the three forces via three components that are learned from the sample sets with different timescales. The long-term descriptive component attracts the target sample, while the medium-term discriminative component repulses the target from the background. They are collaborated in the appearance model to benefit each other. The short-term regressive component combines the votes of the auxiliary samples to predict the target’s position, forming the context-aware motion model. The appearance model and the motion model collaboratively determine the target state, and the optimal state is estimated by a novel coarse-to-fine search strategy. We have conducted an extensive set of experiments on the standard 50 video benchmark. The results confirm the effectiveness of each component and their collaboration, outperforming current state-of-the-art methods.","Target tracking,
Context modeling,
Support vector machines,
Collaboration,
Object tracking,
Visualization"
Active Deep Learning for Classification of Hyperspectral Images,"Active deep learning classification of hyperspectral images is considered in this paper. Deep learning has achieved success in many applications, but good-quality labeled samples are needed to construct a deep learning network. It is expensive getting good labeled samples in hyperspectral images for remote sensing applications. An active learning algorithm based on a weighted incremental dictionary learning is proposed for such applications. The proposed algorithm selects training samples that maximize two selection criteria, namely representative and uncertainty. This algorithm trains a deep network efficiently by actively selecting training samples at each iteration. The proposed algorithm is applied for the classification of hyperspectral images, and compared with other classification algorithms employing active learning. It is shown that the proposed algorithm is efficient and effective in classifying hyperspectral images.","Training,
Uncertainty,
Machine learning,
Hyperspectral imaging,
Tuning"
Live Data Analytics With Collaborative Edge and Cloud Processing in Wireless IoT Networks,"Recently, big data analytics has received important attention in a variety of application domains including business, finance, space science, healthcare, telecommunication and Internet of Things (IoT). Among these areas, IoT is considered as an important platform in bringing people, processes, data and things/objects together in order to enhance the quality of our everyday lives. However, the key challenges are how to effectively extract useful features from the massive amount of heterogeneous data generated by resource-constrained IoT devices in order to provide real-time information and feedback to the end-users, and how to utilize this data-aware intelligence in enhancing the performance of wireless IoT networks. Although there are parallel advances in cloud computing and edge computing for addressing some issues in data analytics, they have their own benefits and limitations. The convergence of these two computing paradigms, i.e., massive virtually shared pool of computing and storage resources from the cloud and real-time data processing by edge computing, could effectively enable live data analytics in wireless IoT networks. In this regard, we propose a novel framework for coordinated processing between edge and cloud computing/processing by integrating advantages from both the platforms. The proposed framework can exploit the network-wide knowledge and historical information available at the cloud center to guide edge computing units towards satisfying various performance requirements of heterogeneous wireless IoT networks. Starting with the main features, key enablers and the challenges of big data analytics, we provide various synergies and distinctions between cloud and edge processing. More importantly, we identify and describe the potential key enablers for the proposed edge-cloud collaborative framework, the associated key challenges and some interesting future research directions.","cloud computing,
data analysis,
Internet of Things"
Designing Socially-Optimal Rating Protocols for Crowdsourcing Contest Dilemma,"Despite the increasing popularity and the perceived promise of crowdsourcing, its openness presents individuals with an opportunity to exhibit antisocial behavior, such as free-ride and attack to decrease the social welfare, which is considered as a crowdsourcing contest dilemma. Hence, incentive mechanisms are needed to compel rational and selfish individuals to contribute well behavior in tasks. In this paper, we integrate the pricing and reputation schemes to design a novel socially optimal rating protocol based on game theory, in which each player is tagged with a rating to represent its social status, and players are encouraged to contribute good behaviors to increase their ratings, thus receive higher rewards. In particular, we analyze how the players' behaviors are influenced by the incurred costs and the designed payment, as well as their long-term utilities. By quantifying the sufficient and necessary conditions under which all players comply with the social norm in their self-interests, we formulate the rating protocol design problem, and analyze the impacts of the design parameters in order to characterize the optimal design, that maximizes the social welfare to achieve the social optimum. Finally, illustrative results show the validity and effectiveness of our proposed protocol design for crowdsourcing contest dilemma.","Crowdsourcing,
Protocols,
Games,
Pricing,
Monitoring,
Analytical models,
Game theory"
Leveraging Social Communities for Optimizing Cellular Device-to-Device Communications,"Device-to-device (D2D) communications over the licensed wireless spectrum has been recently proposed as a promising technology to meet the capacity crunch of next generation cellular networks. However, due to the high mobility of cellular devices, establishing and ensuring the success of D2D transmission become a major challenge. To this end, in this paper, a novel framework is proposed to enable devices to form multi-hop D2D connections in an effort to maintain sustainable communication in the presence of device mobility. To solve the problem posed by device mobility, in contrast to existing works, which mostly focus on physical domain information, a durable community-based approach is introduced taking social encounters into context. It is shown that the proposed scheme can derive an optimal solution for time sensitive content transmission while also minimizing the cost that the base station pays in order to incentivize users to participate in D2D. Simulation results show that the proposed social community aware approach yields significant performance gain, in terms of the amount of traffic offloaded from the cellular network to the D2D tier, compared with the classical social-unaware methods.","Device-to-device communication,
Interference,
Quality of service,
Signal to noise ratio,
Wireless communication,
Reliability,
Cellular networks"
MPIM: Multi-purpose in-memory processing using configurable resistive memory,"Running Internet of Things applications on general purpose processors results in a large energy and performance overhead, due to the high cost of data movement. Processing in-memory is a promising solution to reduce the data movement cost by processing the data locally inside the memory. In this paper, we design a Multi-Purpose In-Memory Processing (MPIM) system, which can be used as main memory and for processing. MPIM consists of multiple crossbar memories with the capability of efficient in-memory computations. Instead of transferring the large dataset to the processors, MPIM provides two important in-memory processing capabilities: i) data searching for the nearest neighbor ii) bitwise operations including OR, AND and XOR with small analog sense amplifiers. The experimental results show that the MPIM can achieve up to 5.5× energy savings and 19× speedup for the search operations as compared to AMD GPU-based implementation. For bitwise vector processing, we present 11000× energy improvements with 62× speedup over the SIMD-based computation, while outperforming other state-of-the-art in-memory processing techniques.",
Optimal Online Data Dissemination for Resource Constrained Mobile Opportunistic Networks,"Delivery delay and communication costs are two conflicting design issues for mobile opportunistic networks with nonreplenishable energy resources. In this paper, we study the optimal data dissemination for resource constrained mobile opportunistic networks, i.e., the delay-constrained least-cost multicasting in mobile opportunistic networks. We formally formulate the problem and introduce a centralized heuristic algorithm which aims to discover a tree for multicasting, in order to meet the delay constraint and achieve low communication cost. While the above algorithm can be implemented by each individual node, it is intrinsically centralized (requiring global information) and, thus, impractical for real-world implementation. However, it offers useful insights for the development of a distributed scheme. The essence of the centralized approach is to first learn the probabilities to deliver the data along different paths to different nodes and then decide the optimal multicast tree by striking the balance between cost and delivery probability. In mobile opportunistic networks, even if the optimal routing tree can be computed by the centralized solution, it is the “best” only on a statistic basis for a large number of data packets. It is not necessarily the best solution for every individual transmission. Based on the above observation, we develop a distributed online algorithm using optimal stopping theory, in which in each meeting event, nodes make adaptive online decisions on whether this communication opportunity should be exploited to deliver data packets. We carry out simulations to evaluate the scalability of the proposed schemes. Furthermore, we prototype the proposed distributed online multicast algorithm using Nexus tablets and conduct an experiment that involves 37 volunteers and lasts for 21 days to demonstrate its effectiveness.","Delays,
Mobile computing,
Mobile communication,
Multicast communication,
Routing,
Wireless networks"
Harnessing Encrypted Data in Cloud for Secure and Efficient Mobile Image Sharing,"Nowadays, large volumes of multimedia data are outsourced to the cloud to better serve mobile applications. Along with this trend, highly correlated datasets can occur commonly, where the rich information buried in correlated data is useful for many cloud data generation/dissemination services. In light of this, we propose to enable a secure and efficient cloud-assisted image sharing architecture for mobile devices, by leveraging outsourced encrypted image datasets with privacy assurance. Different from traditional image sharing, we aim to provide a mobile-friendly design that saves the transmission cost for mobile clients, by directly utilizing outsourced correlated images to reproduce the image of interest inside the cloud for immediate dissemination. First, we propose a secure and efficient index design that allows the mobile client to securely find from encrypted image datasets the candidate selection pertaining to the image of interest for sharing. We then design two specialized encryption mechanisms that support secure image reproduction from encrypted candidate selection. We formally analyze the security strength of the design. Our experiments explicitly show that both the bandwidth and energy consumptions at the mobile client can be saved, while achieving all service requirements and security guarantees.","Mobile communication,
Cloud computing,
Mobile handsets,
Encryption,
Servers,
Data privacy"
Static and Dynamic Process Change,"Approaches for modifying processes both at buildtime and at runtime are commonly referred to as process change, which play an increasingly important role in the enterprise today, where more than ever before, changing requirements must be rapidly accommodated. Over the years, approaches for supporting process change have received much attention from the research community. In spite of that, no comprehensive survey of this important subject exits. To draw a clear picture that analyzes the status of research in this area, in this paper, we conduct a systematic literature review on process change. The resulting survey sheds light on how to classify approaches for process change, determines what the principal research questions and challenges are, and identifies several research directions for further study.","Process control,
Organizations,
Schedules,
Runtime,
Taxonomy,
Service-oriented architecture"
Robustness Analysis of a Memristive Crossbar PUF Against Modeling Attacks,"In the greater context of computer security, hardware security issues such as integrated circuit counterfeiting, cloning, reverse engineering and piracy have emerged as critical issues due in part to an increasingly globalized supply chain. To help combat hardware security vulnerabilities, a wide range of security primitives have emerged in recent years. A popular example is physical unclonable functions (PUFs) that leverage process variations to provide unique signatures or fingerprints that can be used for authentication or secret key generation. Nanoelectronic technologies, such as the memristor technologies considered here, provide an excellent opportunity to engineer dense, energy-efficient PUF circuits with desirable statistical properties. Here, we specifically focus on the design considerations of a memristive crossbar based PUF that generates response bits as a function of variable memristor switching time. In addition to describing the operation of the crossbar PUF, we also consider its resilience to two specific machine learning attacks, specifically through the use of linear regression and support vector machines. Two circuit design modifications for the crossbar PUF are provided to improve the resilience to machine learning attacks: XORing of response bits and internal column swapping. We show that the design modifications lead to a reduction in the likelihood of successful attack to about 50% (near ideal) even given 5000 iterations for the attack itself. We also provide power estimates and performance considerations for the crossbar PUF based on three specific memristive material stacks: hafnium-oxide, tantalum-oxide, and titanium-oxide.",
Projection-Based Differential Feedback for FDD Massive MIMO Systems,"Channel state information at the transmitter (CSIT) plays a key role in achieving potential gain of massive multiple-input-multiple-output (MIMO) systems. In frequency-division duplex (FDD) systems, CSIT can be obtained through feedback from the receiver. Conventional limited feedback schemes, which have been designed for small-scale MIMO systems, suffer from a prohibitive amount of feedback requirement and encoding complexity when the number of transmit antennas becomes massive. In this paper, a projection-based differential feedback (PBDF) protocol is proposed for FDD massive MIMO systems. In the PBDF framework, the difference between original and predicted vectors is projected, and quantization is performed in a smaller dimensional subspace. With an appropriate projection exploiting spatial and temporal correlation of massive MIMO channels, the feedback amount and encoding complexity can be significantly reduced. The simulation results show that the proposed scheme achieves a large portion of potential throughput gain of massive MIMO systems with a small amount of channel feedback.","MIMO,
Covariance matrices,
Complexity theory,
Training,
Transmitters"
"Microservices in Practice, Part 1: Reality Check and Service Design","Service-oriented architecture (SOA) and microservices insiders Mike Amundsen, James Lewis, and Nicolai Josuttis share their experiences and predictions with department editors Cesare Pautasso and Olaf Zimmermann.","Service-oriented architecture,
Software engineering,
Semiconductor optical amplifiers,
Computer architecture,
Context modeling,
Writing,
Software development"
A Random Trajectory Approach for the Development of Nonstationary Channel Models Capturing Different Scales of Fading,"This paper introduces a new approach to developing stochastic nonstationary channel models, the randomness of which originates from a random trajectory of the mobile station (MS) rather than from the scattering area. The new approach is employed by utilizing a random trajectory model based on the primitives of Brownian fields (BFs), whereas the position of scatterers can be generated from an arbitrarily 2-D distribution function. The employed trajectory model generates random paths along which the MS travels from a given starting point to a fixed predefined destination point. To capture the path loss, the gain of each multipath component is modeled by a negative power law applied to the traveling distance of the corresponding plane wave, whereas the randomness of the path traveled results in large-scale fading. It is shown that the local received power is well approximated by a Gaussian process in logarithmic scale, even for a very limited number of scatterers. It is also shown that the envelope of the complex channel gain follows closely a Suzuki process, indicating that the proposed channel model superimposes small-scale fading and large-scale fading. The local power delay profile (PDP) and the local Doppler power spectral density (PSD) of the channel model are also derived and analyzed.","Channel models,
Trajectory,
Fading channels,
Scattering,
Doppler effect,
Mobile communication,
Computational modeling"
Automatic Memory Control of Multiple Virtual Machines on a Consolidated Server,"Through virtualization, multiple virtual machines (VMs) can coexist and operate on one physical machine. When virtual machines compete for memory, the performances of applications deteriorate, especially those of memory-intensive applications. In this study, we aim to optimize memory control techniques using a balloon driver for server consolidation. Our contribution is three-fold: (1) We design and implement an automatic control system for memory based on a Xen balloon driver. To avoid interference with VM monitor operation, our system works in user mode; therefore, the system is easily applied in practice. (2) We design an adaptive global-scheduling algorithm to regulate memory. This algorithm is based on a dynamic baseline, which can adjust memory allocation according to the memory used by the VMs. (3) We evaluate our optimized solution in a real environment with 10 VMs and well-known benchmarks ( DaCapo and Phoronix Test Suites). Experiments confirm that our system can improve the performance of memory-intensive and disk-intensive applications by up to 500 and 300 percent, respectively. This toolkit has been released for free download as a GNU General Public License v3 software.","Equations,
Servers,
Mathematical model,
Virtual machine monitors,
Heuristic algorithms,
Memory management,
Scheduling algorithms"
Subtask Scheduling for Distributed Robots in Cloud Manufacturing,"Due to the limitation of capacity in an enterprise, cooperation among these enterprises is necessary to handle a complex production task. Cloud manufacturing (CMF) provides a cooperation platform for efficient utilization of distributed manufacturing resources in regional enterprise cluster. However, effective scheduling of tasks or subtasks to these resources is a challenging problem. Based on the analysis on the procedure of task processing, this paper proposes a CMF scheduling model for efficiently exploiting distributed resources, so industrial robots in different enterprises can cooperatively handle a batch of tasks. Specifically, this paper considers the performance of four robot deployment methods, including random deployment, robot-balanced deployment, function-balanced deployment, and location-aware deployment. Furthermore, three subtask-scheduling strategies are derived for three optimization objectives, including load-balance of robots, minimizing overall cost, and minimizing overall processing time. Moreover, these strategies are implemented by genetic algorithm. Simulation results demonstrate that each strategy can achieve the relevant optimization objective. In addition, the results also show that the physical distance between two enterprises can influence the overall cost, and location-aware deployment leads to smaller transportation cost. Location-aware deployment and function-balanced deployment lead to smaller overall processing time for the low-workload state and high-workload state of the system, respectively.",
Visual Analysis of MOOC Forums with iForum,"Discussion forums of Massive Open Online Courses (MOOC) provide great opportunities for students to interact with instructional staff as well as other students. Exploration of MOOC forum data can offer valuable insights for these staff to enhance the course and prepare the next release. However, it is challenging due to the large, complicated, and heterogeneous nature of relevant datasets, which contain multiple dynamically interacting objects such as users, posts, and threads, each one including multiple attributes. In this paper, we present a design study for developing an interactive visual analytics system, called iForum, that allows for effectively discovering and understanding temporal patterns in MOOC forums. The design study was conducted with three domain experts in an iterative manner over one year, including a MOOC instructor and two official teaching assistants. iForum offers a set of novel visualization designs for presenting the three interleaving aspects of MOOC forums (i.e., posts, users, and threads) at three different scales. To demonstrate the effectiveness and usefulness of iForum, we describe a case study involving field experts, in which they use iForum to investigate real MOOC forum data for a course on JAVA programming.","Message systems,
Data visualization,
Visual analytics,
Instruction sets,
Interviews,
Java"
A Hybrid Ray Launching-Diffusion Equation Approach for Propagation Prediction in Complex Indoor Environments,"A novel and efficient deterministic approach to model radiowave propagation channels in complex indoor environments, improving prediction accuracy, is proposed. This technique combines a three-dimensional ray launching algorithm based on geometrical optics with a diffusion equation method based on the equation of transfer. A comparison between the geometrical optics-only approach and the new method considering the diffusion equation has been presented for studying indoor radiowave propagation. The geometrical optics-diffusion equation method achieves better agreement with measurements, while resulting in high computational efficiency, with approximately 40% savings in simulation time.","Mathematical model,
Computational modeling,
Three-dimensional displays,
Absorption,
Solid modeling,
Electromagnetic scattering"
Scheduling Strategy for Multimedia Heterogeneous High-Speed Train Networks,"Recently, the high-speed train has been recognized as a fast and popular public transportation system that brings significant convenience to passengers. How to efficiently provide passengers broadband mobile services, such as voice over IP (VoIP) and multimedia services, is receiving increasing attention. To fulfill passengers' diverse demands, we consider a heterogeneous network (HetNet) structure consisting of trackside access points (TAPs) and base stations (BSs) in a high-speed rail communication system (HRCS). First, we formulate a service-scheduling problem aiming at minimizing the end-to-end delay of VoIP and multimedia services as an infinite-horizon time-average expected delay constraint Markov decision process (CMDP) model. In particular, to provide a suitable scheduling selection scheme, this paper proposes a hybrid scheduling strategy to satisfy various delay requirements. Second, we utilize the martingale theory to obtain the theoretic value of the end-to-end delay bounds under two kinds of scheduling mechanisms: first in first out (FIFO) and earliest deadline first (EDF). In the simulation, we use three kinds of real wireless data traces, namely, VoIP, gaming, and User Datagram Protocol (UDP), to evaluate our algorithms by using the Nakagami-m fading channel. From the results, we verify the optimality of the proposed scheduling algorithm in average end-to-end delay performance over FIFO and EDF and the working principle of the hybrid scheduling strategy. In addition, the martingale end-to-end delay bounds are remarkably tight to the real data trace simulation results.","Delays,
Scheduling,
Optimal scheduling,
Wireless communication,
Multimedia communication,
Rail transportation,
Quality of service"
A Reverberation-Time-Aware Approach to Speech Dereverberation Based on Deep Neural Networks,"A reverberation-time-aware deep-neural-network (DNN)-based speech dereverberation framework is proposed to handle a wide range of reverberation times. There are three key steps in designing a robust system. First, in contrast to sigmoid activation and min-max normalization in state-of-the-art algorithms, a linear activation function at the output layer and global mean-variance normalization of target features are adopted to learn the complicated nonlinear mapping function from reverberant to anechoic speech and to improve the restoration of the low-frequency and intermediate-frequency contents. Next, two key design parameters, namely, frame shift size in speech framing and acoustic context window size at the DNN input, are investigated to show that RT60-dependent parameters are needed in the DNN training stage in order to optimize the system performance in diverse reverberant environments. Finally, the reverberation time is estimated to select the proper frame shift and context window sizes for feature extraction before feeding the log-power spectrum features to the trained DNNs for speech dereverberation. Our experimental results indicate that the proposed framework outperforms the conventional DNNs without taking the reverberation time into account, while achieving a performance only slightly worse than the oracle cases with known reverberation times even for extremely weak and severe reverberant conditions. It also generalizes well to unseen room sizes, loudspeaker and microphone positions, and recorded room impulse responses.",
Enabling Resilient Microgrid Through Programmable Network,"In this paper, we integrate programmable networks in microgrid (MG) to provide flexible and easy-to-manage communication solutions, thus enabling resilient MG operations in face of various cyber and physical disturbances. Specifically, two contributions have been made: 1) establish a novel software-defined networking (SDN) based communication architecture that abstracts the network infrastructure from the upper-level applications to significantly expedite the development of MG applications and 2) create a hardware-in-the-loop cyber-physical platform for evaluating and validating the performance of the presented architecture, control techniques, and SDN-based functionalities. Test results have demonstrated that the new architecture can significantly enhance MG resilience, particularly for those that have high penetration of renewable energy sources.","Microgrids,
Quality of service,
Control systems,
Communication networks,
Computer architecture,
Renewable energy sources,
Software"
Delay and Energy Tradeoff in Energy Harvesting Multi-Hop Wireless Networks With Inter-Session Network Coding and Successive Interference Cancellation,"In this paper, we address the energy harvesting tradeoff for minimizing the average packet delay in wireless energy harvesting multi-hop networks with inter-session network coding (NC) and successive interference cancellation. Unlike the previous works, conventionally making a tradeoff between the transmission delay and the energy consumption in a wireless network, here by minimizing the ratio of the scheduling length to the harvesting energy remained, we present a cross-layer formulation for a joint routing, network coding, and scheduling problem in a wireless energy transfer network to make the length-energy tradeoff while satisfying the traffic demands from the upper layer. With the realistic signal-to-interference-plus-noise ratio model, the formulation is also to address a conflict-free scheduling problem on the NC components, and to specify an energy harvesting and consuming model for these components in detail. Then, for the combinatorial nonlinear problem resulted, we develop a Lyapunov optimization-based scheme conducting a dynamic scheduling policy that can approach the optimal length-energy tradeoff while keeping the network stable. Specifically, the mixed integer nonlinear programming model, including, especially, the fractional objective is first transformed and decomposed into a master subproblem and a pricing subproblem with a column generation (CG) method to avoid enumerating all the possible configures, and then resolved iteratively through the Lyapunov optimization algorithm. To further reduce the complexity, the CG method on finding feasible configures is operated within a limited number of iteration and stopped when no significant improvements can be obtained. Finally, with the numerical results, we show that the proposed algorithm can effectively reduce the scheduling length, while reserving the time long enough to harvest the energy for the wireless networks with and without NC, and verify the tradeoff on the performance metrics as [O(V), O(1/V)] , which provides engineering insights for a practical system design.","Energy harvesting,
Wireless networks,
Lyapunov methods,
Optimization,
Scheduling,
Network coding,
Spread spectrum management,
Energy transfer,
Performance evaluation,
Energy consumption,
Telecommunication traffic"
Closed-Loop Autonomous Pilot and Compressive CSIT Feedback Resource Adaptation in Multi-User FDD Massive MIMO Systems,"Acquisition of accurate channel state information (CSI) at the transmitter (CSIT) is a major challenge of deploying frequency-division duplexing massive MIMO systems. Although compressive sensing (CS)-based CSIT estimation approaches have been proposed to reduce the pilot training overhead for massive MIMO systems, the existing schemes cannot properly dimension the minimum required pilot symbols to estimate the CSIT of all users at the required CSIT quality, because of the loose bounds on the required number of measurements for successful CS recovery and the unknown sparsity levels of user channels. In this paper, we propose a robust closed-loop pilot and CSIT feedback resource adaptation framework which not only exploits the joint sparsity of the multiuser massive MIMO channels to improve the CSIT estimation performance, but also has the built-in learning capability to adapt to the minimum pilot and feedback resources needed for successful CSIT recovery under unknown and time-varying channel sparsity levels. We establish the convergence of the proposed closed-loop adaptation algorithm under certain conditions. Simulations show that the proposed framework has substantial performance gain over conventional schemes with a fixed number of pilots and is very robust to dynamic sparsity as well as model mismatch.","MIMO,
Estimation,
Training,
Signal processing algorithms,
Channel estimation,
Robustness,
Convergence"
The End of Moore's Law: A New Beginning for Information Technology,"The insights contained in Gordon Moore's now famous 1965 and 1975 papers have broadly guided the development of semiconductor electronics for over 50 years. However, the field-effect transistor is approaching some physical limits to further miniaturization, and the associated rising costs and reduced return on investment appear to be slowing the pace of development. Far from signaling an end to progress, this gradual ""end of Moore's law"" will open a new era in information technology as the focus of research and development shifts from miniaturization of long-established technologies to the coordinated introduction of new devices, new integration technologies, and new architectures for computing.","Algorithm design and analysis,
Field effect transistors,
Switching circuits,
Computer architecture,
Random access memory,
Moore's Law,
Scientific computing,
Memory management"
Support Vector Machine Informed Explicit Nonlinear Model Predictive Control Using Low-Discrepancy Sequences,"In this paper, an explicit nonlinear model predictive controller (ENMPC) for the stabilization of nonlinear systems is investigated. The proposed ENMPC is constructed using tensored polynomial basis functions and samples drawn from low-discrepancy sequences. Solutions of a finite-horizon optimal control problem at the sampled nodes are used (1) to learn an inner and outer approximation of the feasible region of the ENMPC using support vector machines, and (2) to construct the ENMPC control surface on the computed feasible region using regression or sparse-grid interpolation, depending on the shape of the feasible region. The attractiveness of the proposed control scheme lies in its tractability to higher-dimensional systems with feasibility and stability guarantees, significantly small online computation times, and ease of implementation.","Support vector machines,
Optimal control,
Nonlinear systems,
Stability analysis,
Predictive control,
Aerospace electronics,
Supervised learning"
Secrecy Rate Beamforming for Multicell Networks With Information and Energy Harvesting,"Considering a multicell network for the secure wireless information and power transfer, this paper studies the joint design of transmit beamformers at the base stations (BSs) and receive signal splitting ratios at the end users' equipment (UE). The primary concern in this work is the network internal security, where there may be a single multiantenna eavesdropper or there is a risk that any near user may accidentally eavesdrop on the received signal of any far user. The objective is to maximize the minimum secrecy user rate under BS transmit power and UE minimum harvested energy constraints. New path-following algorithms are proposed for computational solutions of these difficult nonconvex optimization problems. Each iteration involves one simple convex quadratic program. Numerical results confirm that the proposed algorithms converge quickly after few iterations having a low computational complexity.","Array signal processing,
Interference,
Receivers,
Energy harvesting,
Communication system security,
Wireless communication,
Ad hoc networks"
Batch Identification Game Model for Invalid Signatures in Wireless Mobile Networks,"Secure access is one of the fundamental problems in wireless mobile networks. Digital signature is a widely used technique to protect messages' authenticity and nodes' identities. From the practical perspective, to ensure the quality of services in wireless mobile networks, ideally the process of signature verification should introduce minimum delay. Batch cryptography technique is a powerful tool to reduce verification time. However, most of the existing works focus on designing batch verification algorithms for wireless mobile networks without sufficiently considering the impact of invalid signatures, which can lead to verification failures and performance degradation. In this paper, we propose a Batch Identification Game Model (BIGM) in wireless mobile networks, enabling nodes to find invalid signatures with reasonable delay no matter whether the game scenario is complete information or incomplete information. Specifically, we analyze and prove the existence of Nash Equilibriums (NEs) in both scenarios, to select the dominant algorithm for identifying invalid signatures. To optimize the identification algorithm selection, we propose a self-adaptive auto-match protocol which estimates the strategies and states of attackers based on historical information. Comprehensive simulation results in terms of NE reasonability, algorithm selection accuracy, and identification delay are provided to demonstrate that BIGM can identify invalid signatures more efficiently than existing algorithms.","Mobile computing,
Games,
Mobile communication,
Delays,
Wireless communication,
Algorithm design and analysis,
Communication system security"
Predictive Modeling of PV Energy Production: How to Set Up the Learning Task for a Better Prediction?,"In this paper, we tackle the problem of power prediction of several photovoltaic (PV) plants spread over an extended geographic area and connected to a power grid. The paper is intended to be a comprehensive study of one-day ahead forecast of PV energy production along several dimensions of analysis: 1) The consideration of the spatio-temporal autocorrelation, which characterizes geophysical phenomena, to obtain more accurate predictions. 2) The learning setting to be considered, i.e., using simple output prediction for each hour or structured output prediction for each day. 3) The learning algorithms: We compare artificial neural networks, most often used for PV prediction forecast, and regression trees for learning adaptive models. The results obtained on two PV power plant datasets show that: taking into account spatio/temporal autocorrelation is beneficial; the structured output prediction setting significantly outperforms the nonstructured output prediction setting; and regression trees provide better models than artificial neural networks.","Predictive models,
Correlation,
Production,
Data models,
Adaptation models,
Forecasting,
Meteorology"
BNB Method for No-Reference Image Quality Assessment,"It is challenging to quantitatively assess image quality in real time without a reference image while achieving human-level perception performance. In this paper, we present a no-reference (NR) image quality assessment (IQA) method called BNB (an acronym for blurriness, noisiness, and blockiness). Our BNB method quantifies the blurriness, noisiness, and blockiness of a given image, which are considered as three critical factors affecting users' quality of experience. This method is rooted in the observation that for any image, the difference between any two adjacent pixel values follows a generalized Laplace distribution with zero mean. This Laplace distribution changes differently when the image experiences various types of artifacts, i.e., blurriness, noisiness, and blockiness. To construct a metric for each BNB artifact, we first extract features for each type of artifacting from the changing Laplace distribution and then identify the quantitative relationship between the feature value and the variation of the artifact. Given human perception scores of a popular image database, we use the k-nearest neighbor algorithm to map our three BNB metrics of an image to a human perception score. Experimental results reveal that the image quality score obtained from our BNB method has higher correlation with human perceptual scores in addition to requiring notably less computation compared with existing NR IQA methods.","Image quality,
Measurement,
Feature extraction,
Nonlinear distortion,
Support vector machines,
Media"
Cognitive Diffusion Model: Facilitating EFL Learning in an Authentic Environment,"For this study, we designed learning activities in which students applied newly acquired knowledge to solve meaningful daily life problems in their local community - a real, familiar, and relevant environment for students. For example, students learned about signs and rules in class and then applied this new knowledge to create their own rules for a location in their community (e.g., playground rules that tell visitors what is or is not allowed to do in a local playground) to make it more environmentally friendly. To facilitate this, we developed a mobile learning system equipped with a dictionary as well as textual annotation, recording, and sharing functions. This mobile learning system enables students to take pictures of objects, describe them verbally or in writing, and share their work with peers. Our goal was to study the effectiveness of learning activities supported by a mobile learning system on the cognitive learning process by examining the changes in students' cognitive processes and the distribution of students who reach a certain level of cognition before and after learning. Fifty-seven junior high school students participated in the research, and their views of the mobile learning system and interest in continuing use were also explored. Students were divided into one control (n = 26) group and one experimental (n = 31) group. The control group completed learning activities using a traditional approach while the experimental group used a learning system installed in tablet PCs. The effectiveness of the mobile PC system on students' cognitive processes was tested by comparing the control and experimental groups' pre-test and post-test outcomes. Changes in students' cognitive processes were measured by calculating the differences in student scores among three tasks. The distribution of students who reached a certain level of cognition was derived based on their learning performance. Students' perceptions were evaluated using a questionnaire survey. The mobile learning system kept records of how students used it. Our results show that the experimental students significantly outperformed the control students on test items related to high cognitive levels. Students made clear cognitive progress from the second topic to the third one. Most students rated the learning system highly and want to use it in the future. Finally, the results show that creating text annotations is the best indicator of learning. Based on these results, we recommend applying appropriate learning activities supported by a mobile learning system to facilitate students' cognitive processes when they are studying English as a foreign language in an authentic environment.",
Observer-Based Event-Triggering Consensus Control for Multiagent Systems With Lossy Sensors and Cyber-Attacks,"In this paper, the observer-based event-triggering consensus control problem is investigated for a class of discrete-time multiagent systems with lossy sensors and cyber-attacks. A novel distributed observer is proposed to estimate the relative full states and the estimated states are then used in the feedback protocol in order to achieve the overall consensus. An event-triggered mechanism with state-independent threshold is adopted to update the control input signals so as to reduce unnecessary data communications. The success ratio of the launched attacks is taken into account to reflect the probabilistic failures of the attacks passing through the protection devices subject to limited resources and network fluctuations. The purpose of the address problem is to design an observer-based distributed controller such that the closed-loop multiagent system achieves the prescribed consensus in spite of the lossy sensors and cyber-attacks. By making use of eigenvalues and eigenvectors of the Laplacian matrix, the closed-loop system is transformed into an easy-to-analyze setting and then a sufficient condition is derived to guarantee the desired consensus. Furthermore, the controller gain is obtained in terms of the solution to certain matrix inequality which is independent of the number of agents. An algorithm is provided to optimize the consensus bound. Finally, a simulation example is utilized to illustrate the usefulness of the proposed controller design scheme.","Multi-agent systems,
Loss measurement,
Linear matrix inequalities,
Sensor systems,
Protocols,
Security"
Network Partition Based Zonal Voltage Control for Distribution Networks with Distributed PV Systems,"As the penetration level of distributed photovoltaic (PV) systems keeps increasing in distribution networks, overvoltage due to reverse power flow is an urgent issue to be addressed. This paper proposes a voltage regulation method by utilizing the voltage control capability of PV inverters. A novel network partition approach based on a community detection algorithm is presented to realize zonal voltage control in a shorter control response time using the minimum amount of reactive power compensation and active power curtailment. An improved modularity index that considers local reactive power balance is introduced to partition a distribution network into several clusters/communities with PVs based on the node voltage sensitivity analysis. An optimal reactive and active power control strategy is proposed for voltage control in each cluster. The voltage management of the overall system can be achieved by controlling each cluster separately. The proposed approach is applied to the voltage control of a practical 10kV, 37-node feeder. Case studies on the real distribution network and a modified IEEE 123-node system are carried out to verify the feasibility and effectiveness of the proposed method.","Voltage control,
Reactive power,
Indexes,
Inverters,
Sensitivity,
Detection algorithms,
Microgrids"
Uncovering Droop Control Laws Embedded Within the Nonlinear Dynamics of Van der Pol Oscillators,"This paper examines the dynamics of power-electronic inverters in islanded microgrids that are controlled to emulate the dynamics of Van der Pol oscillators. The general strategy of controlling inverters to emulate the behavior of nonlinear oscillators presents a compelling time-domain alternative to ubiquitous droop control methods which presume the existence of a quasistationary sinusoidal steady state and operate on phasor quantities. We present two main results in this paper. First, by leveraging the method of periodic averaging, we demonstrate that droop laws are intrinsically embedded within a slower time scale in the nonlinear dynamics of Van der Pol oscillators. Second, we establish the global convergence of amplitude and phase dynamics in a resistive network interconnecting inverters controlled as Van der Pol oscillators. Furthermore, under a set of nonrestrictive decoupling approximations, we derive sufficient conditions for local exponential stability of desirable equilibria of the linearized amplitude and phase dynamics.","Oscillators,
Inverters,
Steady-state,
Synchronization,
Voltage control,
Power system dynamics,
Control systems"
Compressive Sampling Using Annihilating Filter-Based Low-Rank Interpolation,"While the recent theory of compressed sensing provides an opportunity to overcome the Nyquist limit in recovering sparse signals, a solution approach usually takes the form of an inverse problem of an unknown signal, which is crucially dependent on specific signal representation. In this paper, we propose a drastically different two-step Fourier compressive sampling framework in a continuous domain that can be implemented via measurement domain interpolation, after which signal reconstruction can be done using classical analytic reconstruction methods. The main idea originates from the fundamental duality between the sparsity in the primary space and the low-rankness of a structured matrix in the spectral domain, showing that a low-rank interpolator in the spectral domain can enjoy all of the benefits of sparse recovery with performance guarantees. Most notably, the proposed low-rank interpolation approach can be regarded as a generalization of recent spectral compressed sensing to recover large classes of finite rate of innovations (FRI) signals at a near-optimal sampling rate. Moreover, for the case of cardinal representation, we can show that the proposed low-rank interpolation scheme will benefit from inherent regularization and an optimal incoherence parameter. Using a powerful dual certificate and the golfing scheme, we show that the new framework still achieves a near-optimal sampling rate for a general class of FRI signal recovery, while the sampling rate can be further reduced for a class of cardinal splines. Numerical results using various types of FRI signals confirm that the proposed low-rank interpolation approach offers significantly better phase transitions than conventional compressive sampling approaches.","Interpolation,
Compressed sensing,
Biomedical measurement,
Magnetic resonance imaging,
Technological innovation,
Splines (mathematics),
X-ray imaging"
An Effective Computational Method Incorporating Multiple Secondary Structure Predictions in Topology Determination for Cryo-EM Images,"A key idea in de novo modeling of a medium-resolution density image obtained from cryo-electron microscopy is to compute the optimal mapping between the secondary structure traces observed in the density image and those predicted on the protein sequence. When secondary structures are not determined precisely, either from the image or from the amino acid sequence of the protein, the computational problem becomes more complex. We present an efficient method that addresses the secondary structure placement problem in presence of multiple secondary structure predictions and computes the optimal mapping. We tested the method using 12 simulated images from α-proteins and two Cryo-EM images of α-β proteins. We observed that the rank of the true topologies is consistently improved by using multiple secondary structure predictions instead of a single prediction. The results show that the algorithm is robust and works well even when errors/misses in the predicted secondary structures are present in the image or the sequence. The results also show that the algorithm is efficient and is able to handle proteins with as many as 33 helices.","Topology,
Protein sequence,
Amino acids,
Heuristic algorithms,
Three-dimensional displays,
Computer science"
Risk Assessment in a Sensor Cloud Framework Using Attack Graphs,"A sensor cloud consists of various heterogeneous wireless sensor networks (WSNs). These WSNs may have different owners and run a wide variety of user applications on demand in a wireless communication medium. Hence, they are susceptible to various security attacks. Thus, a need exists to formulate effective and efficient security measures that safeguard these applications impacted from attack in the sensor cloud. However, analyzing the impact of different attacks and their cause-consequence relationship is a prerequisite before security measures can be either developed or deployed. In this paper, we propose a risk assessment framework for WSNs in a sensor cloud that utilizes attack graphs. We use Bayesian networks to not only assess but also to analyze attacks on WSNs. The risk assessment framework will first review the impact of attacks on a WSN and estimate reasonable time frames that predict the degradation of WSN security parameters like confidentiality, integrity and availability. Using our proposed risk assessment framework allows the security administrator to better understand the threats present and take necessary actions against them. The framework is validated by comparing the assessment results with that of the results obtained from different simulated attack scenarios.","Wireless sensor networks,
Computer security,
Risk management,
Cloud computing,
Bayes methods,
Estimation"
FinFET With Encased Air-Gap Spacers for High-Performance and Low-Energy Circuits,"We experimentally demonstrate n-channel bulk FinFET with encased air-gap spacers. Encased air gap in the spacer region is formed by depositing carbon sidewalls, encasing them with silicon nitride (SiN) film and finally removing carbon using mild oxygen plasma. We show that the drive current of air-spacer FinFET is improved by about 40% compared with the baseline bulk FinFET with SiN spacers likely due to enhanced tensile stress in the channel. The parasitic capacitance and ring oscillator delay of FinFET with air-spacers is about 25% and 40% lower compared with that with SiN spacers.","Silicon compounds,
FinFETs,
Logic gates,
Air gaps,
Carbon,
Parasitic capacitance"
"Social Authentication Applications, Attacks, Defense Strategies and Future Research Directions: A Systematic Review","The ever-increasing volumes of social knowledge shared in online social networks, the establishment of trustworthy social relationships over these platforms, and the emergence of technologies that allow friendship networks to be inferred from data exchanged in communication networks have motivated researchers to build socially aware authentication schemes. We conduct the first study that surveys the literature related to social authentication. In this paper, we not only created a taxonomy for classifying all social authentication schemes deployed in online or physical social contexts and extensively analyzed their authentication features, but also built a novel framework for evaluating the effectiveness of all social authentication schemes, identified all the practical and theoretical attacks that may be mounted against such schemes, addressed possible defense strategies, and identified challenges, open questions, and future research opportunities. To measure their accuracy, strengths, weaknesses, and limitations, as well as to identify the potential of knowledge-based and trust-based social authentication schemes, a comprehensive comparative assessment of the security, usability, and deployability was conducted. We hope, by providing a solid foundation for gaining sufficient understanding of the manners in which users' social interactions have been utilized in user authentication schemes and their corresponding security implications, we will guide future research in this domain.",
Design Automation for Interwell Connectivity Estimation in Petroleum Cyber-Physical Systems,"In a petroleum cyber-physical system (CPS), interwell connectivity estimation is critical for improving petroleum production. An accurately estimated connectivity topology facilitates reduction in the production cost and improvement in the waterflood management. This paper presents the first study focused on computer-aided design for a petroleum CPS. A new CPS framework is developed to estimate the petroleum well connectivities. Such a framework explores an innovative water/oil index integrated with the advanced cross-entropy optimization. It is applied to a real industrial petroleum field with massive petroleum CPS data. The experimental results demonstrate that our automated estimations well match the expensive tracer-based true observations. This demonstrates that our framework is highly promising.","Petroleum,
Production,
Cyber-physical systems,
Entropy,
Optimization,
Mathematical model,
Indexes"
A Survey on Successors of LEACH Protocol,"Even after 16 years of existence, low energy adaptive clustering hierarchy (LEACH) protocol is still gaining the attention of the research community working in the area of wireless sensor network (WSN). This itself shows the importance of this protocol. Researchers have come up with various and diverse modifications of the LEACH protocol. Successors of LEACH protocol are now available from single hop to multi-hop scenarios. Extensive work has already been done related to LEACH and it is a good idea for a new research in the field of WSN to go through LEACH and its variants over the years. This paper surveys the variants of LEACH routing protocols proposed so far and discusses the enhancement and working of them. This survey classifies all the protocols in two sections, namely, single hop communication and multi-hop communication based on data transmission from the cluster head to the base station. A comparitive analysis using nine different parameters, such as energy efficiency, overhead, scalability complexity, and so on, has been provided in a chronological fashion. The article also discusses the strong and the weak points of each and every variants of LEACH. Finally the paper concludes with suggestions on future research domains in the area of WSN.","Wireless sensor networks,
Routing protocols,
Routing,
Time division multiple access,
Schedules,
Scalability"
Objective Quality Assessment of Screen Content Images by Uncertainty Weighting,"In this paper, we propose a novel full-reference objective quality assessment metric for screen content images (SCIs) by structure features and uncertainty weighting (SFUW). The input SCI is first divided into textual and pictorial regions. The visual quality of textual regions is estimated based on perceptual structural similarity, where the gradient information is adopted as the structural feature. To predict the visual quality of pictorial regions in SCIs, we extract the structural features and luminance features for similarity computation between the reference and distorted pictorial patches. To obtain the final visual quality of SCI, we design an uncertainty weighting method by perceptual theories to fuse the visual quality of textual and pictorial regions effectively. Experimental results show that the proposed SFUW can obtain better performance of visual quality prediction for SCIs than other existing ones.","Measurement,
Visualization,
Feature extraction,
Distortion,
Uncertainty,
Quality assessment,
Image segmentation"
Soft-Boosted Self-Constructing Neural Fuzzy Inference Network,"This correspondence paper proposes an improved version of the self-constructing neural fuzzy inference network (SONFIN), called soft-boosted SONFIN (SB-SONFIN). The design softly boosts the learning process of the SONFIN in order to decrease the error rate and enhance the learning speed. The SB-SONFIN boosts the learning power of the SONFIN by taking into account the numbers of fuzzy rules and initial weights which are two important parameters of the SONFIN, SB-SONFIN advances the learning process by: 1) initializing the weights with the width of the fuzzy sets rather than just with random values and 2) improving the parameter learning rates with the number of learned fuzzy rules. The effectiveness of the proposed soft boosting scheme is validated on several real world and benchmark datasets. The experimental results show that the SB-SONFIN possesses the capability to outperform other known methods on various datasets.","Benchmark testing,
Training,
Cybernetics,
Fuzzy sets,
Time series analysis,
Boosting"
Photonics-Based Broadband Microwave Measurement,"Microwave measurement refers to the acquisition of parameters of a microwave signal or the identification of properties of an object via microwave-based approaches. Thanks to the broad bandwidth and high speed provided by modern photonics, microwave measurement in the optical domain can provide better performance in terms of bandwidth and speed which may not be achievable using traditional, even state-of-the-art electronics. In this tutorial, techniques for photonics-based broadband and high-speed microwave measurement are discussed with an emphasis on the system architectures for microwave signal parameter measurement and object property identification. Emerging technologies in this area and possible future research directions are also discussed.","Microwave measurement,
Electric variables measurement,
Electrooptical waveguides,
Frequency measurement,
Optical variables measurement,
Microwave photonics"
Superconducting NbTin Thin Films With Highly Uniform Properties Over a {\varnothing} 100 mm Wafer,"Uniformity in thickness and electronic properties of superconducting niobium titanium nitride (NbTiN) thin films is a critical issue for upscaling superconducting electronics, such as microwave kinetic inductance detectors for submillimeter wave astronomy. In this article we make an experimental comparison between the uniformity of NbTiN thin films produced by two DC magnetron sputtering systems with vastly different target sizes: the Nordiko 2000 equipped with a circular Ø 100 mm target, and the Evatec LLS801 with a rectangular target of 127 mm × 444.5 mm. In addition to the films deposited staticly in both systems, we have also deposited films in the LLS801 while shuttling the substrate in front of the target, with the aim of further enhancing the uniformity. Among these three setups, the LLS801 system with substrate shuttling has yielded the highest uniformity in film thickness (±2%), effective resistivity (decreasing by 5% from center to edge), and superconducting critical temperature (Tc = 15.0 K-15.3 K) over a Ø 100 mm wafer. However, the shuttling appears to increase the resistivity by almost a factor of 2 compared to static deposition. Surface SEM inspections suggest that the shuttling could have induced a different mode of microstructural film growth.","Conductivity,
Sputtering,
Resonant frequency,
Superconducting microwave devices,
Superconducting transmission lines,
Microwave circuits,
Niobium"
A Novel Endmember Extraction Method for Hyperspectral Imagery Based on Quantum-Behaved Particle Swarm Optimization,"Endmember extraction is one of the most important issues in hyperspectral image analysis. Under the linear mixing model and pure pixel assumption, a number of convex-geometry-based methods have been developed in the past decades. However, these traditional methods generally produce unsatisfactory results since they require the hyperspectral image to have a convex structure and this is not exactly the case with the real image scene. The particle swarm optimization (PSO) algorithm has recently been employed to address the endmember extraction problem, but its performance is limited by the premature convergence and lower precision of the standard PSO, and much effort is required to enhance the optimization result. To address these problems, in this study, a novel quantum-behaved particle swarm optimization (QPSO) algorithm is proposed for hyperspectral endmember extraction. The notable advantages of the proposed method include: 1) a row-column coding approach for the particles is designed to accelerate the optimization process; 2) a cooperative approach is employed to update the particles' individual and global best positions, in order to help the particles' optimization behavior in the multidimensional search space; and 3) two kinds of objective functions, namely, maximizing the simplex volume formed by the endmember combination, and minimizing the root-mean-square error between the original image and its remixed image, are incorporated in a sequential optimization approach for the endmember extraction problem, which makes the algorithm robust to outliers at an acceptable time cost. The extensive experimental results prove that QPSO is able to find the optimal endmember combination.","Hyperspectral imaging,
Optimization,
Particle swarm optimization,
Earth,
Convergence"
Temporal Restricted Visual Tracking Via Reverse-Low-Rank Sparse Learning,"An effective representation model, which aims to mine the most meaningful information in the data, plays an important role in visual tracking. Some recent particle-filter-based trackers achieve promising results by introducing the low-rank assumption into the representation model. However, their assumed low-rank structure of candidates limits the robustness when facing severe challenges such as abrupt motion. To avoid the above limitation, we propose a temporal restricted reverse-low-rank learning algorithm for visual tracking with the following advantages: 1) the reverse-low-rank model jointly represents target and background templates via candidates, which exploits the low-rank structure among consecutive target observations and enforces the temporal consistency of target in a global level; 2) the appearance consistency may be broken when target suffers from sudden changes. To overcome this issue, we propose a local constraint via 11,2 mixed-norm, which can not only ensures the local consistency of target appearance, but also tolerates the sudden changes between two adjacent frames; and 3) to alleviate the inference of unreasonable representation values due to outlier candidates, an adaptive weighted scheme is designed to improve the robustness of the tracker. By evaluating on 26 challenge video sequences, the experiments show the effectiveness and favorable performance of the proposed algorithm against 12 state-of-the-art visual trackers.","Target tracking,
Visualization,
Robustness,
Bayes methods,
Computational modeling,
Inference algorithms"
Beyond Frame-level CNN: Saliency-Aware 3-D CNN With LSTM for Video Action Recognition,"Human activity recognition in videos with convolutional neural network (CNN) features has received increasing attention in multimedia understanding. Taking videos as a sequence of frames, a new record was recently set on several benchmark datasets by feeding frame-level CNN sequence features to long short-term memory (LSTM) model for video activity recognition. This recurrent model-based visual recognition pipeline is a natural choice for perceptual problems with time-varying visual input or sequential outputs. However, the above-mentioned pipeline takes frame-level CNN sequence features as input for LSTM, which may fail to capture the rich motion information from adjacent frames or maybe multiple clips. Furthermore, an activity is conducted by a subject or multiple subjects. It is important to consider attention that allows for salient features, instead of mapping an entire frame into a static representation. To tackle these issues, we propose a novel pipeline, saliency-aware three-dimensional (3-D) CNN with LSTM, for video action recognition by integrating LSTM with salient-aware deep 3-D CNN features on videos shots. Specifically, we first apply saliency-aware methods to generate saliency-aware videos. Then, we design an end-to-end pipeline by integrating 3-D CNN with LSTM, followed by a time series pooling layer and a softmax layer to predict the activities. Noticeably, we set a new record on two benchmark datasets, i.e., UCF101 with 13 320 videos and HMDB-51 with 6766 videos. Our method outperforms the state-of-the-art end-to-end methods of action recognition by 3.8% and 3.2%, respectively on above two datasets.","Three-dimensional displays,
Pipelines,
Visualization,
Time series analysis,
Image recognition,
Microprocessors,
Computer architecture"
Emulation of Physician Tasks in Eye-Tracked Virtual Reality for Remote Diagnosis of Neurodegenerative Disease,"For neurodegenerative conditions like Parkinson's disease, early and accurate diagnosis is still a difficult task. Evaluations can be time consuming, patients must often travel to metropolitan areas or different cities to see experts, and misdiagnosis can result in improper treatment. To date, only a handful of assistive or remote methods exist to help physicians evaluate patients with suspected neurological disease in a convenient and consistent way. In this paper, we present a low-cost VR interface designed to support evaluation and diagnosis of neurodegenerative disease and test its use in a clinical setting. Using a commercially available VR display with an infrared camera integrated into the lens, we have constructed a 3D virtual environment designed to emulate common tasks used to evaluate patients, such as fixating on a point, conducting smooth pursuit of an object, or executing saccades. These virtual tasks are designed to elicit eye movements commonly associated with neurodegenerative disease, such as abnormal saccades, square wave jerks, and ocular tremor. Next, we conducted experiments with 9 patients with a diagnosis of Parkinson's disease and 7 healthy controls to test the system's potential to emulate tasks for clinical diagnosis. We then applied eye tracking algorithms and image enhancement to the eye recordings taken during the experiment and conducted a short follow-up study with two physicians for evaluation. Results showed that our VR interface was able to elicit five common types of movements usable for evaluation, physicians were able to confirm three out of four abnormalities, and visualizations were rated as potentially useful for diagnosis.","Diseases,
Gaze tracking,
Cameras,
Visualization,
Three-dimensional displays,
Lenses"
Distributed Power and Channel Allocation for Cognitive Femtocell Network Using a Coalitional Game in Partition-Form Approach,"The cognitive femtocell network (CFN) integrated with cognitive-radio-enabled technology has emerged as one of the promising solutions to improve wireless broadband coverage in indoor environments for next-generation mobile networks. In this paper, we study a distributed resource allocation that consists of subchannel- and power-level allocation in the uplink of the two-tier CFN comprised of a conventional macrocell and multiple femtocells using underlay spectrum access. The distributed resource allocation problem is addressed via an optimization problem, in which we maximize the uplink sum rate under constraints of intratier and intertier interference while maintaining the average delay requirement for cognitive femtocell users. Specifically, the aggregated interference from cognitive femtocell users to the macrocell base station (MBS) is also kept under an acceptable level. We show that this optimization problem is NP-hard and propose an autonomous framework, in which the cognitive femtocell users self-organize into disjoint groups (DJGs). Then, instead of maximizing the sum rate in all cognitive femtocells, we only maximize the sum rate of each DJG. After that, we formulate the optimization problem as a coalitional game in partition form, which obtains suboptimal solutions. Moreover, distributed algorithms are also proposed for allocating resources to the CFN. Finally, the proposed framework is tested based on the simulation results and shown to perform efficient resource allocation.","Interference,
Resource management,
Optimization,
Games,
Uplink,
Macrocell networks,
Femtocell networks"
A Sparse and Low-Rank Near-Isometric Linear Embedding Method for Feature Extraction in Hyperspectral Imagery Classification,"A sparse and low-rank near-isometric linear embedding (SLRNILE) method has been proposed to make dimensionality reduction and extract proper features for hyperspectral imagery (HSI) classification. The SLRNILE stands on the theory of the John-Lindenstrauss lemma, and tries to estimate a sparse and low-rank projection matrix that satisfies the restricted isometric property (RIP) condition on all secants of the HSI data. The RIP condition guarantees that the desired linear mapping near-isometrically preserves nearest neighbor points of all HSI pixels. Seeking the desired mapping is then modeled into minimizing a Lagrange multipliers formulation. The alternating direction method of multipliers framework is utilized to solve the above convex program, and column generation techniques are adopted to alleviate the computation memory burden during the optimization procedure. Five experiments on three widely used HSI data sets are designed to completely test the performance of SLRNILE, and experimental results are compared against those of six state-of-the-art feature extraction methods, including principal component analysis, Laplacian eigenmaps, locality preserving projections, neighborhood preserving embedding, sparse nonnegative matrix underapproximation, and random projections. The results show that SLRNILE performs best among all the seven methods, and its computational time is longest of all but still bearable for regular users. Therefore, the SLRNILE can be a good choice for feature extraction in HSI classification.","Feature extraction,
Manifolds,
Principal component analysis,
Sparse matrices,
Learning systems,
Hyperspectral imaging"
Security and Privacy Preservation Scheme of Face Identification and Resolution Framework Using Fog Computing in Internet of Things,"Face identification and resolution technology is crucial to ensure the identity consistency of humans in physical space and cyber space. In the current Internet of Things (IoT) and big data situation, the increase of applications based on face identification and resolution raises the demands of computation, communication, and storage capabilities. Therefore, we have proposed the fog computing-based face identification and resolution framework to improve processing capacity and save the bandwidth. However, there are some security and privacy issues brought by the properties of fog computing-based framework. In this paper, we propose a security and privacy preservation scheme to solve the above issues. We give an outline of the fog computing-based face identification and resolution framework, and summarize the security and privacy issues. Then the authentication and session key agreement scheme, data encryption scheme, and data integrity checking scheme are proposed to solve the issues of confidentiality, integrity, and availability in the processes of face identification and face resolution. Finally, we implement a prototype system to evaluate the influence of security scheme on system performance. Meanwhile, we also evaluate and analyze the security properties of proposed scheme from the viewpoint of logical formal proof and the confidentiality, integrity, and availability (CIA) properties of information security. The results indicate that the proposed scheme can effectively meet the requirements for security and privacy preservation.","Big Data,
cloud computing,
cryptography,
data integrity,
data privacy,
face recognition,
Internet of Things,
security of data,
telecommunication security"
CoRE: Cooperative End-to-End Traffic Redundancy Elimination for Reducing Cloud Bandwidth Cost,"The pay-as-you-go service model impels cloud customers to reduce the usage cost of bandwidth. Traffic Redundancy Elimination (TRE) has been shown to be an effective solution for reducing bandwidth costs, and thus has recently captured significant attention in the cloud environment. By studying the TRE techniques in a trace driven approach, we found that both short-term (time span of seconds) and long-term (time span of hours or days) data redundancy can concurrently appear in the traffic, and solely using either sender-based TRE or receiver-based TRE cannot simultaneously capture both types of traffic redundancy. Also, the efficiency of existing receiver-based TRE solution is susceptible to the data changes compared to the historical data in the cache. In this paper, we propose a Cooperative end-to-end TRE solution (CoRE) that can detect and remove both short-term and long-term redundancy through a two-layer TRE design with cooperative operations between layers. An adaptive prediction algorithm is further proposed to improve TRE efficiency through dynamically adjusting the prediction window size based on the hit ratio of historical predictions. Besides, we enhance CoRE to adapt to different traffic redundancy characteristics of cloud applications to improve its operation cost. Extensive evaluation with several real traces show that CoRE is capable of effectively identifying both short-term and long-term redundancy with low additional cost while ensuring TRE efficiency from data changes.","Redundancy,
Cloud computing,
Bandwidth,
Servers,
Receivers,
Elasticity,
Electronic mail"
Decomposition-Based-Sorting and Angle-Based-Selection for Evolutionary Multiobjective and Many-Objective Optimization,"Multiobjective evolutionary algorithm based on decomposition (MOEA/D) decomposes a multiobjective optimization problem (MOP) into a number of scalar optimization subproblems and then solves them in parallel. In many MOEA/D variants, each subproblem is associated with one and only one solution. An underlying assumption is that each subproblem has a different Pareto-optimal solution, which may not be held, for irregular Pareto fronts (PFs), e.g., disconnected and degenerate ones. In this paper, we propose a new variant of MOEA/D with sorting-and-selection (MOEA/D-SAS). Different from other selection schemes, the balance between convergence and diversity is achieved by two distinctive components, decomposition-based-sorting (DBS) and angle-based-selection (ABS). DBS only sorts L closest solutions to each subproblem to control the convergence and reduce the computational cost. The parameter L has been made adaptive based on the evolutionary process. ABS takes use of angle information between solutions in the objective space to maintain a more fine-grained diversity. In MOEA/D-SAS, different solutions can be associated with the same subproblems; and some subproblems are allowed to have no associated solution, more flexible to MOPs or many-objective optimization problems (MaOPs) with different shapes of PFs. Comprehensive experimental studies have shown that MOEA/D-SAS outperforms other approaches; and is especially effective on MOPs or MaOPs with irregular PFs. Moreover, the computational efficiency of DBS and the effects of ABS in MOEA/D-SAS are also investigated and discussed in detail.","Optimization,
Satellite broadcasting,
Convergence,
Synthetic aperture sonar,
Sociology,
Statistics,
Computational efficiency"
Filtering Out Infrequent Behavior from Business Process Event Logs,"In the era of “big data”, one of the key challenges is to analyze large amounts of data collected in meaningful and scalable ways. The field of process mining is concerned with the analysis of data that is of a particular nature, namely data that results from the execution of business processes. The analysis of such data can be negatively influenced by the presence of outliers, which reflect infrequent behavior or “noise”. In process discovery, where the objective is to automatically extract a process model from the data, this may result in rarely travelled pathways that clutter the process model. This paper presents an automated technique to the removal of infrequent behavior from event logs. The proposed technique is evaluated in detail and it is shown that its application in conjunction with certain existing process discovery algorithms significantly improves the quality of the discovered process models and that it scales well to large datasets.","Big data,
Data mining,
Data models,
Business,
Information analysis,
Behavioral science,
Filtering,
Data analysis"
Early Detection of Sudden Pedestrian Crossing for Safe Driving During Summer Nights,"Sudden pedestrian crossing (SPC) is the major reason for pedestrian-vehicle crashes. In this paper, we focus on detecting SPCs at night for supporting an advanced driver assistance system using a far-infrared (FIR) camera mounted on the front roof of a vehicle. Although the thermal temperature of the road is similar to or higher than that of the pedestrians during summer nights, many previous researches have focused on pedestrian detection during the winter, spring, or autumn seasons. However, our research concentrates on SPC during the hot summer season because the number of collisions between pedestrians and vehicles in Korea is higher at that time than during the other seasons. For real-time processing, we first decide the optimal levels of image scaling and search area. We then use our proposed method for detecting virtual reference lines that are associated with road segmentation without using color information and change these lines according to the turning direction of the vehicle. Pedestrian detection is conducted using a cascade random forest with low-dimensional Haar-like features and oriented center-symmetric local binary patterns. The SPC is predicted based on the likelihood and the spatiotemporal features of the pedestrians, such as their overlapping ratio with virtual reference lines, as well as the direction and magnitude of each pedestrian's movement. The proposed algorithm was successfully applied to various pedestrian data sets captured by an FIR camera, and the results show that its SPC detection performance is better than those of other methods.","Cameras,
Finite impulse response filters,
Vehicles,
Feature extraction,
Roads,
Image color analysis,
Support vector machines"
A Secure and Efficient ID-Based Aggregate Signature Scheme for Wireless Sensor Networks,"Affording secure and efficient big data aggregation methods is very attractive in the field of wireless sensor networks (WSNs) research. In real settings, the WSNs have been broadly applied, such as target tracking and environment remote monitoring. However, data can be easily compromised by a vast of attacks, such as data interception and data tampering, etc. In this paper, we mainly focus on data integrity protection, give an identity-based aggregate signature (IBAS) scheme with a designated verifier for WSNs. According to the advantage of aggregate signatures, our scheme not only can keep data integrity, but also can reduce bandwidth and storage cost for WSNs. Furthermore, the security of our IBAS scheme is rigorously presented based on the computational Diffie-Hellman assumption in random oracle model.","Aggregates,
Wireless sensor networks,
Public key,
Internet of things,
Big data"
Model-Based Self-Aware Performance and Resource Management Using the Descartes Modeling Language,"Modern IT systems have increasingly distributed and dynamic architectures providing flexibility to adapt to changes in the environment and thus enabling higher resource efficiency. However, these benefits come at the cost of higher system complexity and dynamics. Thus, engineering systems that manage their end-to-end application performance and resource efficiency in an autonomic manner is a challenge. In this article, we present a holistic model-based approach for self-aware performance and resource management leveraging the Descartes Modeling Language (DML), an architecture-level modeling language for online performance and resource management. We propose a novel online performance prediction process that dynamically tailors the model solving depending on the requirements regarding accuracy and overhead. Using these prediction capabilities, we implement a generic model-based control loop for proactive system adaptation. We evaluate our model-based approach in the context of two representative case studies showing that with the proposed methods, significant resource efficiency gains can be achieved while maintaining performance requirements. These results represent the first end-to-end validation of our approach, demonstrating its potential for self-aware performance and resource management in the context of modern IT systems and infrastructures.","Adaptation models,
Resource management,
Computer architecture,
Predictive models,
Unified modeling language,
Software,
Dynamic scheduling"
A Novel Fusion Approach Based on the Global Consistency Criterion to Fusing Multiple Segmentations,"In this paper, we introduce a new fusion model whose objective is to fuse multiple region-based segmentation maps to get a final better segmentation result. The suggested new fusion model is based on an energy function originated from the global consistency error (GCE), a perceptual measure which takes into account the inherent multiscale nature of an image segmentation by measuring the level of refinement existing between two spatial partitions. Combined with a region merging/splitting prior, this new energy-based fusion model of label fields allows to define an interesting penalized likelihood estimation procedure based on the GCE criterion with which the fusion of basic, rapidly-computed segmentation results appears as a relevant alternative compared with other (possibly complex) segmentation techniques proposed in the image segmentation field. The performance of our fusion model was evaluated on the Berkeley dataset including various segmentations given by humans (manual ground truth segmentations). The obtained results clearly demonstrate the efficiency of this fusion model.","Image segmentation,
Measurement uncertainty,
Energy measurement,
Estimation,
Indexes,
Cybernetics"
Direct Sparse Odometry,"Direct Sparse Odometry (DSO) is a visual odometry method based on a novel, highly accurate sparse and direct structure and motion formulation. It combines a fully direct probabilistic model (minimizing a photometric error) with consistent, joint optimization of all model parameters, including geometry – represented as inverse depth in a reference frame – and camera motion. This is achieved in real time by omitting the smoothness prior used in other direct methods and instead sampling pixels evenly throughout the images. Since our method does not depend on keypoint detectors or descriptors, it can naturally sample pixels from across all image regions that have intensity gradient, including edges or smooth intensity variations on essentially featureless walls. The proposed model integrates a full photometric calibration, accounting for exposure time, lens vignetting, and non-linear response functions. We thoroughly evaluate our method on three different datasets comprising several hours of video. The experiments show that the presented approach significantly outperforms state-of-the-art direct and indirect methods in a variety of real-world settings, both in terms of tracking accuracy and robustness.","Cameras,
Geometry,
Three-dimensional displays,
Optimization,
Robustness,
Computational modeling,
Visualization"
Distributed User Association in Energy Harvesting Small Cell Networks: A Probabilistic Bandit Model,"We investigate a distributed downlink user association problem in a dynamic small cell network, where every small base station (SBS) obtains its required energy through ambient energy harvesting. On the one hand, energy harvesting is inherently opportunistic, so that the amount of available energy is a random variable. On the other hand, users arrive at random and require different wireless services, rendering the energy consumption a random variable. In this paper, we develop a probabilistic framework to mathematically model and analyze the random behavior of energy harvesting and energy consumption. We further analyze the probability of QoS satisfaction (success probability), for each user with respect to every SBS. The proposed user association scheme is distributed in the sense that every user independently selects its corresponding SBS with the success probability serving as the performance metric. The success probability however depends on a variety of random factors such as energy harvesting, channel quality, and network traffic, whose distribution or statistical characteristics might not be known at users. Since acquiring the knowledge of these random variables (even statistical) is very costly in a dense network, we develop a bandit-theoretical formulation for distributed SBS selection when no prior information is available at users. The performance is analyzed both theoretically and numerically.","Energy harvesting,
Wireless communication,
Random variables,
Quality of service,
Downlink,
Probabilistic logic,
Analytical models"
Occlusion-Aware Real-Time Object Tracking,"The online learning methods are popular for visual tracking because of their robust performance for most video sequences. However, the drifting problem caused by noisy updates is still a challenge for most highly adaptive online classifiers. In visual tracking, target object appearance variation, such as deformation and long-term occlusion, easily causes noisy updates. To overcome this problem, a new real-time occlusion-aware visual tracking algorithm is introduced. First, we learn a novel two-stage classifier with circulant structure with kernel, named integrated circulant structure kernels (ICSK). The first stage is applied for transition estimation and the second is used for scale estimation. The circulant structure makes our algorithm realize fast learning and detection. Then, the ICSK is used to detect the target without occlusion and build a classifier pool to save these classifiers with noisy updates. When the target is in heavy occlusion or after long-term occlusion, we redetect it using an optimal classifier selected from the classifier-pool according to an entropy minimization criterion. Extensive experimental results on the full benchmark demonstrate our real-time algorithm achieves better performance than state-of-the-art methods.","Target tracking,
Robustness,
Visualization,
Feature extraction,
Kernel,
Noise measurement,
Support vector machines"
RGB-D Salient Object Detection via Minimum Barrier Distance Transform and Saliency Fusion,"Automatic detection of salient objects in images has gained its popularity in computer vision field for its usage in numerous vision tasks in recent years. Depth information plays an important role in the human vision system while it is underutilized in most existing two-dimensional (2-D) saliency detection methods. In this letter, a multistage salient object detection framework via minimum barrier distance transform and saliency fusion based on multilayer cellular automata (MCA) is proposed. First, we independently generate the 3-D spatial prior, depth bias, and RGB-produced and depth-induced saliency maps. Next, the two saliency maps are weighted by depth bias to obtain two initial maps. Then, we adopt a saliency optimization step to generate more precise depth-induced saliency map. Moreover, the initial RGB-produced and the optimized depth-induced maps are further fused with 3-D spatial prior. Finally, we utilize MCA to fuse all saliency maps generated previously and obtain the final saliency result with complete salient object. The proposed method is evaluated on the publicly available benchmark dataset, RGBD1000. Compared to several state-of-the-art 2-D and depth-aware approaches, the experimental results demonstrate the effectiveness and superiority of our method, which can accurately detect the salient objects from RGB-D images, and has the most satisfactory overall performance.","Object detection,
Two dimensional displays,
Three-dimensional displays,
Optimization,
Transforms,
Signal processing algorithms,
Image color analysis"
Visualizing Social Media Content with SentenTree,"We introduce SentenTree, a novel technique for visualizing the content of unstructured social media text. SentenTree displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. SentenTree displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. SentenTree can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser.","Visualization,
Tag clouds,
Media,
Context,
Twitter,
Games,
Layout"
TSRA: An Adaptive Mechanism for Switching between Communication Modes in Full-Duplex Opportunistic Spectrum Access Systems,"Full-duplex (FD) communications and self-interference suppression (SIS) techniques can be exploited in opportunistic spectrum access (OSA) systems for simultaneous transmission-sensing (TS) or simultaneous transmission-reception (TR). Motivated by the competing goals of primary user (PU) protection (in the TS mode) and secondary user (SU) performance (in the TR mode), we present an optimal adaptive switching strategy and an associated communication protocol for FD OSA systems. Specifically, we optimize the spectrum-awareness/efficiency tradeoff by allowing the SU link to adaptively switch between various modes, depending on the forecasted PU dynamics. The proposed three-stage adaptive mode-selection strategy maximizes an SU utility function subject to a constraint on the PU collision probability. We also propose a protocol that executes the switching mechanism in a distributed fashion. In practice, SIS is imperfect, resulting in residual self-interference that degrades the sensing performance in the TS mode. Accordingly, we study different spectrum sensing techniques in the TS mode, while illustrating their accuracy-complexity tradeoff. We evaluate the performance of the proposed switching scheme against the listen-before-talk (LBT) scheme using numerical results, simulations, and hardware USRP experiments.","Sensors,
Silicon,
Switches,
Protocols,
Interference,
Adaptation models,
Mobile computing"
Total-Ionizing-Dose Effects in Piezoresistive Micromachined Cantilevers,"We evaluate the response of T-shaped, asymmetric, piezoresistive, micromachined cantilevers fabricated on p-type Si to 10-keV X-ray irradiation. The resonant frequency decreases by 25 ppm at 2.1 Mrad(SiO2), and partially recovers during post-irradiation annealing. An explanation of the results is proposed that is based on radiation-induced acceptor depassivation. This occurs because radiation-generated holes release hydrogen from previously passivated acceptors, causing the carrier concentration to increase, especially near the surface. Increased carrier concentration decreases Young's modulus, resulting in a decrease in the cantilever resonant frequency. Finite element simulations show that the effect of a decreasing Young's modulus in the surface region is consistent with the measured decrease in resonant frequency in the irradiated devices.","Resonant frequency,
Piezoresistance,
Silicon,
Radiation effects,
Micromechanical devices,
Young's modulus"
Electric Vehicle Charging Station Placement for Urban Public Bus Systems,"Due to the low pollution and sustainable properties, using electric buses for public transportation systems has attracted considerable attention, whereas how to recharge the electric buses with long continuous service hours remains an open problem. In this paper, we consider the problem of placing electric vehicle (EV) charging stations at selected bus stops, to minimize the total installation cost of charging stations. Specifically, we study two EV charging station placement cases, with and without considering the limited battery size, which are called ECSP_LB and ECSP problems, respectively. The solution of the ECSP problem achieves the lower bound compared with the solution of the ECSP_LB problem, and the larger the battery size of the EV, the lower the overall cost of the charging station installation. For both cases, we prove that the placement problems under consideration are NP-hard and formulate them into integer linear programming. Specifically, for the ECSP problem we design a linear programming relaxation algorithm to get a suboptimal solution and derive an approximation ratio of the algorithm. Moreover, we derive the condition of the battery size when the ECSP problem can be applied. For the ECSP_LB problem, we show that, for a single bus route, the problem can be optimally solved with a backtracking algorithm, whereas for multiple bus routes we propose two heuristic algorithms, namely, multiple backtracking and greedy algorithms. Finally, simulation results show the effectiveness of the proposed schemes.","Charging stations,
Batteries,
Algorithm design and analysis,
Approximation algorithms,
Public transportation,
Heuristic algorithms,
Fossil fuels"
Measurement of the Mass Flow and Velocity Distributions of Pulverized Fuel in Primary Air Pipes Using Electrostatic Sensing Techniques,"Online measurement of pulverized fuel (PF) distribution between primary air pipes on a coal-fired power plant is of great importance to achieve balanced fuel supply to the boiler for increased combustion efficiency and reduced pollutant emissions. An instrumentation system using multiple electrostatic sensing heads is developed and installed on 510-mm bore primary air pipes on the same mill of a 600-MW coal-fired boiler unit for the measurement of PF mass flow and velocity distributions. An array of electrostatic electrodes with different axial widths is housed in a sensing head. An electrode with a greater axial width and three narrower electrodes are used to derive the electrostatic signals for the determination of PF mass flow rate and velocity, respectively. The PF velocity is determined by multiple cross correlation of the electrostatic signals from the narrow electrodes. The measured PF velocity is applied on the root-mean-square magnitude of the measured electrostatic signal from the wide electrode for the calibration of PF mass flow rate. On-plant comparison trials of the developed system were conducted under five typical operating conditions after a system calibration test. Isokinetic sampling equipment is used to obtain reference data to evaluate the performance of the developed system. Experimental data demonstrate that the developed system is effective and reliable for the online continuous measurement of the mass flow and velocity distributions between the primary air pipes of the same mill.","Velocity measurement,
Electrostatics,
Electrodes,
Fuels,
Electrostatic measurements,
Sensors,
Atmospheric measurements"
CSR: Classified Source Routing in DHT-Based Networks,"In recent years cloud computing provides a new way to address the constraints of limited energy, capabilities, and resources. Distributed hash table (DHT) based networks have become increasingly important for efficient communication in large-scale cloud systems. Previous studies mainly focus on improving the performance such as latency, scalability and robustness, but seldom consider the security demands on the routing paths, for example, bypassing untrusted intermediate nodes. Inspired by Internet source routing, in which the source nodes specify the routing paths taken by their packets, this paper presents CSR, a tag-based, Classified Source Routing scheme in DHT-based cloud networks to satisfy the security demands on the routing paths. Different from Internet source routing which requires some map of the overall network, CSR operates in a distributed manner where nodes with certain security level are tagged with a label and routing messages requiring that level of security are forwarded only to the qualified next-hops. We show how this can be achieved efficiently, by simple extensions of the traditional routing structures, and safely, so that the routing is uniformly convergent. The effectiveness of our proposals is demonstrated through theoretical analysis and extensive simulations.","Servers,
Routing,
Cloud computing,
Security,
Topology,
Robustness"
A Multiphase Switched Capacitor Power Amplifier,"This paper presents an all-digital multiphase switched capacitor power amplifier (MP-SCPA) implemented in a 130-nm CMOS. Quadrature architectures suffer reduced output power and efficiency owing to the combination of out-ofphase signals. The MP architecture reduces the phase difference between the basis vectors that are combined, and hence the output power and efficiency are greatly improved. Sixteen clocks with identical adjacent phase separations are produced by a phase generator with each phase's relative amplitude weighted on the top plate of a capacitor array and combined on a common bottom plate, resulting in linear amplification. The MP-SCPA delivers a peak output power Pout of 26 dBm with a peak system efficiency (SE) of 24.9%. When amplifying a long-term evolution signal at 1.85 GHz, the average Pout and the SE are 20.9 dBm and 15.2%, respectively, with an Adjacent Channel Leakage Ratio (ACLR) <; -30 dBc and error vector magnitude of 3.5% rms using a 2-D digital predistortion.","Capacitors,
Switching circuits,
Power generation,
Switches,
Phase modulation,
Bandwidth,
Computer architecture"
Towards Unsupervised Gene Selection: A Matrix Factorization Framework,"The recent development of microarray gene expression techniques have made it possible to offer phenotype classification of many diseases. However, in gene expression data analysis, each sample is represented by quite a large number of genes, and many of them are redundant or insignificant to clarify the disease problem. Therefore, how to efficiently select the most useful genes has been becoming one of the most hot research topics in the gene expression data analysis. In this paper, a novel unsupervised two-stage coarse-fine gene selection method is proposed. In the first stage, we apply the kmeans algorithm to over-cluster the genes and discard some redundant genes. In the second stage, we select the most representative genes from the remaining ones based on matrix factorization. Finally the experimental results on several data sets are presented to show the effectiveness of our method.","Gene expression,
Optimization,
Standards,
Symmetric matrices,
Data analysis,
Linear programming,
Diseases"
"Learning to Generate Chairs, Tables and Cars with Convolutional Networks","We train generative `up-convolutional' neural networks which are able to generate images of objects given object style, viewpoint, and color. We train the networks on rendered 3D models of chairs, tables, and cars. Our experiments show that the networks do not merely learn all images by heart, but rather find a meaningful representation of 3D models allowing them to assess the similarity of different models, interpolate between given views to generate the missing ones, extrapolate views, and invent new objects not present in the training set by recombining training instances, or even two different object classes. Moreover, we show that such generative networks can be used to find correspondences between different objects from the dataset, outperforming existing approaches on this task.","Training,
Neural networks,
Image segmentation,
Solid modeling,
Three-dimensional displays,
Automobiles,
Image color analysis"
Discrete Nonnegative Spectral Clustering,"Spectral clustering has been playing a vital role in various research areas. Most traditional spectral clustering algorithms comprise two independent stages (e.g., first learning continuous labels and then rounding the learned labels into discrete ones), which may cause unpredictable deviation of resultant cluster labels from genuine ones, thereby leading to severe information loss and performance degradation. In this work, we study how to achieve discrete clustering as well as reliably generalize to unseen data. We propose a novel spectral clustering scheme which deeply explores cluster label properties, including discreteness, nonnegativity, and discrimination, as well as learns robust out-of-sample prediction functions. Specifically, we explicitly enforce a discrete transformation on the intermediate continuous labels, which leads to a tractable optimization problem with a discrete solution. Besides, we preserve the natural nonnegative characteristic of the clustering labels to enhance the interpretability of the results. Moreover, to further compensate the unreliability of the learned clustering labels, we integrate an adaptive robust module with ℓ2p loss to learn prediction function for grouping unseen data. We also show that the out-of-sample component can inject discriminative knowledge into the learning of cluster labels under certain conditions. Extensive experiments conducted on various data sets have demonstrated the superiority of our proposal as compared to several existing clustering approaches.","Clustering algorithms,
Predictive models,
Robustness,
Optimization,
Matrix decomposition,
Biological system modeling,
Laplace equations"
Hyperspectral Image Classification by Exploring Low-Rank Property in Spectral or/and Spatial Domain,"Within-class spectral variation, which is caused by varied imaging conditions, such as changes in illumination, environmental, atmospheric, and temporal conditions, significantly degrades the performance of hyperspectral image classification. Recent studies have shown that such spectral variation can be alleviated by exploring the low-rank property in the spectral domain, especially based on the low-rank subspace assumption. In this paper, the low-rank subspace assumption is approached by exploring the low-rank property in the local spectral domain. In addition, the low-rank property in the spatial domain is also explored to alleviate spectral variation. As a result, two novel spectral-spatial low-rank (SSLR) strategies are designed to alleviate spectral variation by exploring the low-rank property in both spectral and spatial domains. Experimental results on two benchmark hyperspectral datasets demonstrate that exploring the low-rank property in local spectral space can help to alleviate spectral variation and improve the performance of classification obviously for all tested data, while exploring the low-rank property in spatial space is more effective for images presenting large homogeneous areas.","Hyperspectral imaging,
Spectral analysis,
Libraries,
Training,
Support vector machines,
Collaboration"
LIME: Low-Light Image Enhancement via Illumination Map Estimation,"When one captures images in low-light conditions, the images often suffer from low visibility. Besides degrading the visual aesthetics of images, this poor quality may also significantly degenerate the performance of many computer vision and multimedia algorithms that are primarily designed for high-quality inputs. In this paper, we propose a simple yet effective low-light image enhancement (LIME) method. More concretely, the illumination of each pixel is first estimated individually by finding the maximum value in R, G, and B channels. Furthermore, we refine the initial illumination map by imposing a structure prior on it, as the final illumination map. Having the well-constructed illumination map, the enhancement can be achieved accordingly. Experiments on a number of challenging low-light images are present to reveal the efficacy of our LIME and show its superiority over several state-of-the-arts in terms of enhancement quality and efficiency.","Lighting,
Estimation,
Image enhancement,
Visualization,
Atmospheric modeling,
Histograms,
Image color analysis"
A New Circuit for Emulating Memristors Using Inductive Coupling,"In order to explore the coupling inter-relationship between two closely placed memristors (MRs), a new circuit for emulating MRs is proposed. The coupling behavior between closely placed MRs is achieved by making use of the inductive coupling properties of two inductors. The most attractive advantages of this emulator are the unique capability that it offers for wireless coupling and high-frequency operation up to dozens of kilohertz. The theoretical discussion for the dynamic operation performance of this coupled MRs emulator is presented and then validated by simulation and experimental results considering different parameter configurations. The value of memductance for one MR can be altered by the MR on the other side. Meanwhile, no energy could be transferred between two MRs. Good agreement between theoretical and experimental analysis confirms that the proposed emulator could be utilized for discovering potential applications of coupled MRs.","Couplings,
Inductors,
Mathematical model,
Wireless communication,
Nanoscale devices,
Analytical models,
Memristors"
Recent trends in the Internet of Things,"The Internet of Things (IoT) has become a hot topic in the present tech-driven world. A strong framework of cloud computing, backed up by a seamless blending of sensors and actuators with the environment around us, is making this “network of networks of autonomous objects” a reality. From smart wearables to smart cities, from domestic life to industries, the IoT is expanding itself to different areas. According to Gartner Inc., the IoT will include 26 billion units installed by 2020. Smart security solutions, smart home automation, smart health care, smart wearables etc. are in-trend applications of IoT, and by the near future we expect to see its application to a city's transportation system or smart power grids. This paper presents a brief overview on different trends of the IoT and also discusses about the effects of the IoT on our day-to-day life. It also discusses the importance of cloud computing, autonomous control, artificial intelligence in the context of the IoT. Lastly, it's concluded with the need of synchronization of the Internet, wireless sensors and actuators and distributed computing for successfully enabling technologies for the IoT.","synchronisation,
artificial intelligence,
cloud computing,
Internet of Things"
A Visual Analytics Approach for Understanding Reasons behind Snowballing and Comeback in MOBA Games,"To design a successful Multiplayer Online Battle Arena (MOBA) game, the ratio of snowballing and comeback occurrences to all matches played must be maintained at a certain level to ensure its fairness and engagement. Although it is easy to identify these two types of occurrences, game developers often find it difficult to determine their causes and triggers with so many game design choices and game parameters involved. In addition, the huge amounts of MOBA game data are often heterogeneous, multi-dimensional and highly dynamic in terms of space and time, which poses special challenges for analysts. In this paper, we present a visual analytics system to help game designers find key events and game parameters resulting in snowballing or comeback occurrences in MOBA game data. We follow a user-centered design process developing the system with game analysts and testing with real data of a trial version MOBA game from NetEase Inc. We apply novel visualization techniques in conjunction with well-established ones to depict the evolution of players' positions, status and the occurrences of events. Our system can reveal players' strategies and performance throughout a single match and suggest patterns, e.g., specific player' actions and game events, that have led to the final occurrences. We further demonstrate a workflow of leveraging human analyzed patterns to improve the scalability and generality of match data analysis. Finally, we validate the usability of our system by proving the identified patterns are representative in snowballing or comeback matches in a one-month-long MOBA tournament dataset.","Games,
Visual analytics,
Data visualization,
Gold,
Market research,
Pattern matching"
Game-Theoretic Multi-Agent Control and Network Cost Allocation Under Communication Constraints,"Multi-agent networked linear dynamic systems have attracted the attention of researchers in power systems, intelligent transportation, and industrial automation. The agents might cooperatively optimize a global performance objective, resulting in social optimization, or try to satisfy their own selfish objectives using a noncooperative differential game. However, in these solutions, large volumes of data must be sent from system states to possibly distant control inputs, thus resulting in high cost of the underlying communication network. To enable economically viable communication, a game-theoretic framework is proposed under the communication cost, or sparsity, constraint, given by the number of communicating state/control input pairs. As this constraint tightens, the system transitions from dense to sparse communication, providing the tradeoff between dynamic system performance and information exchange. Moreover, using the proposed sparsity-constrained distributed social optimization and noncooperative game algorithms, we develop a method to allocate the costs of the communication infrastructure fairly and according to the agents' diverse needs for feedback and cooperation. Numerical results illustrate utilization of the proposed algorithms to enable and ensure economic fairness of wide-area control among power companies.","Optimization,
Games,
Resource management,
Power system dynamics,
State feedback,
Multi-agent systems"
Extending XCS with Cyclic Graphs for Scalability on Complex Boolean Problems,"A main research direction in the field of evolutionary machine learning is to develop a scalable classifier system to solve high-dimensional problems. Recently work has begun on autonomously reusing learned building blocks of knowledge to scale from low-dimensional problems to high-dimensional ones. An XCS-based classifier system, known as XCSCFC, has been shown to be scalable, through the addition of expression tree–like code fragments, to a limit beyond standard learning classifier systems. XCSCFC is especially beneficial if the target problem can be divided into a hierarchy of subproblems and each of them is solvable in a bottom-up fashion. However, if the hierarchy of subproblems is too deep, then XCSCFC becomes impractical because of the needed computational time and thus eventually hits a limit in problem size. A limitation in this technique is the lack of a cyclic representation, which is inherent in finite state machines (FSMs). However, the evolution of FSMs is a hard task owing to the combinatorially large number of possible states, connections, and interaction. Usually this requires supervised learning to minimize inappropriate FSMs, which for high-dimensional problems necessitates subsampling or incremental testing. To avoid these constraints, this work introduces a state-machine-based encoding scheme into XCS for the first time, termed XCSSMA. The proposed system has been tested on six complex Boolean problem domains: multiplexer, majority-on, carry, even-parity, count ones, and digital design verification problems. The proposed approach outperforms XCSCFA (an XCS that computes actions) and XCSF (an XCS that computes predictions) in three of the six problem domains, while the performance in others is similar. In addition, XCSSMA evolved, for the first time, compact and human readable general classifiers (i.e., solving any n-bit problems) for the even-parity and carry problem domains, demonstrating its ability to produce scalable solutions using a cyclic representation.","Learning classifier systems,
XCS,
state machines,
scalability,
pattern recognition."
FPGA-based accelerator for long short-term memory recurrent neural networks,"Long Short-Term Memory Recurrent neural networks (LSTM-RNNs) have been widely used for speech recognition, machine translation, scene analysis, etc. Unfortunately, general-purpose processors like CPUs and GPGPUs can not implement LSTM-RNNs efficiently due to the recurrent nature of LSTM-RNNs. FPGA-based accelerators have attracted attention of researchers because of good performance, high energy-efficiency and great flexibility. In this work, we present an FPGA-based accelerator for LSTM-RNNs that optimizes both computation performance and communication requirements. The peak performance of our accelerator achieves 7.26 GFLOP/S, which significantly outperforms previous approaches.","Computer architecture,
Logic gates,
Recurrent neural networks,
Standards,
Microprocessors,
Speech recognition,
Computational modeling"
A Low-Profile Aperture-Coupled Microstrip Antenna With Enhanced Bandwidth Under Dual Resonance,"A low-profile aperture-coupled microstrip patch antenna (MPA) using the TM10 and TM30 resonant modes to enhance the impedance bandwidth is proposed in this paper. Based on the cavity model for a square MPA, the TM10 and TM30 modes as well as both higher odd-order and even-order modes between them can be characterized. In order to combine the dual radiative resonant modes for a wide impedance bandwidth, a rectangular radiating patch with an aperture-coupled feeder is employed and theoretically investigated at first, aiming to demonstrate that all of the undesired modes between them can be removed effectively. After that, by loading the shorting pins properly underneath the patch, the resonant frequency of TM10 mode is shown to progressively turn up with slight effect on that of TM30 mode. As a result, these two radiative modes can be allocated in proximity to each other, resulting in a wide impedance bandwidth with a stable radiation pattern and the same far-field polarization. Moreover, the principal parameters of the MPA have been extensively studied in order to investigate the sensitivity in input impedance of the aperture-fed patch antenna. Finally, the proposed antenna is fabricated and measured. Simulated and measured results are found in good agreement with each other and illustrate that the antenna achieves a wide impedance bandwidth of about 15.2% in fraction or 2.32-2.70 GHz under |S11| <; -10 dB, while keeping a low profile property with the height of 0.032 free-space wavelength. Besides, a stable gain varied from 3 to 6.8 dBi within the whole operating band is also obtained.","Bandwidth,
Resonant frequency,
Impedance,
Pins,
Microstrip antennas,
Microstrip"
A Mixed Reality Telepresence System for Collaborative Space Operation,"This paper presents a mixed reality (MR) system that results from the integration of a telepresence system and an application to improve collaborative space exploration. The system combines free viewpoint video with immersive projection technology to support nonverbal communication (NVC), including eye gaze, interpersonal distance, and facial expression. Importantly, these features can be interpreted together as people move around the simulation, maintaining a natural social distance. The application is a simulation of Mars, within which the collaborators must come to agreement over; for example, where the Rover should land and go. The first contribution is the creation of an MR system supporting contextualization of NVC. Two technological contributions are prototyping a technique to subtract a person from a background that may contain physical objects and/or moving images and a lightweight texturing method for multiview rendering, which provides balance in terms of visual and temporal quality. A practical contribution is the demonstration of pragmatic approaches to sharing space between display systems of distinct levels of immersion. A research tool contribution is a system that allows comparison of conventional authored and video-based reconstructed avatars, within an environment that encourages exploration and social interaction. Aspects of system quality, including the communication of facial expression and end-to-end latency are reported.","Three-dimensional displays,
Virtual reality,
Space exploration,
Rendering (computer graphics),
Space research,
Collaborative work"
Efficiency Improvement of Nonuniformly Aged PV Arrays,"The utilization of solar energy by photovoltaic (PV) systems has received much research and development attention across the globe. In the past decades, a large number of PV array have been installed. Since the installed PV arrays often operate in harsh environments, nonuniform aging can occur and impact adversely on the performance of PV systems, especially in the middle and late periods of their service life. Due to the high cost of replacing aged PV modules by new modules, it is appealing to improve energy efficiency of aged PV systems. For this purpose, this paper presents a PV module reconfiguration strategy to achieve the maximum power generation from nonuniformly aged PV arrays without significant investment. The proposed reconfiguration strategy is based on the cell-unit structure of PV modules, the operating voltage limit of grid-connected converter, and the resulted bucket effect of the maximum short-circuit current. The objectives are to analyze all the potential reorganization options of the PV modules, find the maximum power point, and express it in a proposition. This proposition is further developed into a novel implementable algorithm to calculate the maximum power generation and the corresponding reconfiguration of the PV modules. The immediate benefits from this reconfiguration are the increased total power output and maximum power point voltage information for global maximum power point tracking. A PV array simulation model is used to illustrate the proposed method under three different cases. Furthermore, an experimental rig is built to verify the effectiveness of the proposed method. The proposed method will open an effective approach for condition-based maintenance of emerging aging PV arrays.","Aging,
Power generation,
Short-circuit currents,
Electrical engineering,
Consumer electronics,
Silicon,
Temperature measurement"
"Smart city: The state of the art, datasets, and evaluation platforms","While smart city concept holds great promise of boosting living standards through effective management and utilization of scarce resources in cities, the unavailability of realworld datasets and test environments to evaluate designed models and techniques have slowed research progress. In this paper, we review existing research endeavors and develop a tool for extracting real-time smart city related data. We also conduct some simulations and evaluations in smart energy, which will be an important application in smart cities.","Smart cities,
Tools,
Data collection,
Data mining,
Standards,
Sensors"
Dynamic Radio Cooperation for User-Centric Cloud-RAN With Computing Resource Sharing,"A novel dynamic radio-cooperation strategy is proposed for a Cloud Radio Access Network (Cloud-RAN) consisting of multiple Remote Radio Heads connected to a central Virtual Base Station (VBS) pool. In particular, the key capabilities of Cloud-RAN in computing-resource sharing and real-time communication among the VBSs are leveraged to design a joint dynamic radio clustering and cooperative beamforming scheme that maximizes the downlink Weighted Sum-Rate System Utility (WSRSU). Due to the combinatorial nature of the radio clustering process and to the non-convexity of the cooperative beamforming design, the underlying optimization problem is NP-hard, and is extremely difficult to solve for a large network. The proposed approach aims for a suboptimal solution by transforming the original problem into a Mixed-Integer Second-Order Cone Program (MI-SOCP) and applying Sequential Convex Approximation (SCA) to derive a novel iterative algorithm. Numerical simulation results show that our low-complexity algorithm provides near-optimal performance in terms of WSRSU while significantly outperforming conventional radio clustering and beamforming schemes. Additionally, the results also demonstrate the significant improvement in computing-resource utilization of Cloud-RAN over a traditional RAN with distributed computing resources.",
Social-Aware Rate Based Content Sharing Mode Selection for D2D Content Sharing Scenarios,"Device-to-device (D2D) content sharing has become a promising solution to support the growing popularity of multimedia contents for local services. Considering the randomness of content location, the limited storage and transmission capability of devices, and the coexistence of altruistic and selfish user behaviors, how to optimally match the demanders to the providers of contents and how to stimulate an efficient cooperation are of importance for achieving the full benefits of D2D content sharing. Especially when the base-station-to-device (B2D), D2D, and novel multi-D2D sharing modes coexist, the issue of content sharing mode selection plays the predominant role in such matching. In this paper, we introduce a notion of social-aware rate, which combines the social selfishness from the social knowledge with the link rate to ensure the physical link quality and the effective cooperation together. Then, the social-aware rate-based content sharing mode selection problem is modeled as a maximum weighted mixed matching problem, which can be computationally reduced to a submodular welfare problem subject to a matroid constraint. Subsequently, we develop a best-effort distributed algorithm framework, which displays alternatives of various computation complexities and approximation ratios to satisfy the diverse practical needs.","Device-to-device communication,
Distributed algorithms,
Complexity theory,
Computational modeling,
Electronic mail,
Social network services,
Approximation algorithms"
Incentive Scheme for Cyber Physical Social Systems Based on User Behaviors,"Cyber-physical social system (CPSS) has emerged as a new paradigm to help social users share and exchange data by the close association with the cyberspace and physical world. To further improve the performance of CPSS, the incentive computing scheme to provide efficient crowd sourcing in the CPPS becomes a challenge. Therefore, in this paper we propose a novel incentive scheme for CPSS based on the reputation of social users. Firstly, we present a framework to provide crowd sourcing service in CPSS by dividing social users into three types, which are malicious users, speculative users and honest users, respectively. Secondly, based on the reputation of social users, an incentive scheme is proposed to encourage users to contribute sourcing data. Next, an auction game model is developed to help CPSS select the optimal social user to obtain the needed data. Finally, simulation results show that the proposal can obtain a lower cost and higher data accuracy than other conventional methods.","Mobile communication,
Sensors,
Incentive schemes,
Games,
Mobile handsets,
Data models,
Computational modeling"
Verifiable and Exculpable Outsourced Attribute-Based Encryption for Access Control in Cloud Computing,"We propose two ciphertext-policy attribute-based key encapsulation mechanism (CP-AB-KEM) schemes that for the first time achieve both outsourced encryption and outsourced decryption in two system storage models and give corresponding security analysis. In our schemes, heavy computations are outsourced to Encryption Service Providers (ESPs) or Decryption Service Providers (DSPs), leaving only one modular exponentiation computation for the sender or the receiver. Moreover, we propose a general verification mechanism for a wide class of ciphertext-policy (cf. key-policy) AB-KEM schemes, which can check the correctness of the outsourced encryption and decryption efficiently. Concretely, we introduce a stronger version of verifiability (cf. [1] ) and a new security notion for outsourced decryption called exculpability, which guarantees that a user cannot accuse DSP of returning incorrect results while it is not the case. With all these mechanisms, any dispute between a user and an outsource computation service provider can be easily resolved, furthermore, a service provider will be less motivated to give out wrong results. Finally, we implement our schemes in Charm  [2] , and the results indicate that the proposed schemes/mechanisms are efficient and practical.","Servers,
Encryption,
Digital signal processing,
Cloud computing,
Decision support systems"
Improved Synchronverters with Bounded Frequency and Voltage for Smart Grid Integration,"Synchronverters are grid-friendly inverters that mimic conventional synchronous generators and play an important role in integrating different types of renewable energy sources, electric vehicles, energy storage systems, etc., to the smart grid. In this paper, an improved synchronverter is proposed to make sure that its frequency and voltage always stay within given ranges, while maintaining the function of the original synchronverter. Furthermore, the stability region characterised by the system parameters is analytically obtained, which guarantees that the improved synchronverter is always stable and converges to a unique equilibrium as long as the power exchanged at the terminal is kept within this area. Extensive OPAL-RT real-time simulation results are presented for the improved and the original self-synchronised synchronverters connected to a stiff grid and for the case when two improved synchronverters are connected to the same bus with one operating as a weak grid, to verify the theoretical development.","Frequency synchronization,
Power system stability,
Stability analysis,
Inverters,
Synchronous generators,
Time-frequency analysis,
Power system dynamics"
Improving Activity Recognition Accuracy in Ambient-Assisted Living Systems by Automated Feature Engineering,"Ambient-assisted living (AAL) is promising to become a supplement of the current care models, providing enhanced living experience to people within context-aware homes and smart environments. Activity recognition based on sensory data in AAL systems is an important task because 1) it can be used for estimation of levels of physical activity, 2) it can lead to detecting changes of daily patterns that may indicate an emerging medical condition, or 3) it can be used for detection of accidents and emergencies. To be accepted, AAL systems must be affordable while providing reliable performance. These two factors hugely depend on optimizing the number of utilized sensors and extracting robust features from them. This paper proposes a generic feature engineering method for selecting robust features from a variety of sensors, which can be used for generating reliable classification models. From the originally recorded time series and some newly generated time series [i.e., magnitudes, first derivatives, delta series, and fast Fourier transformation (FFT)-based series], a variety of time and frequency domain features are extracted. Then, using two-phase feature selection, the number of generated features is greatly reduced. Finally, different classification models are trained and evaluated on an independent test set. The proposed method was evaluated on five publicly available data sets, and on all of them, it yielded better accuracy than when using hand-tailored features. The benefits of the proposed systematic feature engineering method are quickly discovering good feature sets for any given task than manually finding ones suitable for a particular task, selecting a small feature set that outperforms manually determined features in both execution time and accuracy, and identification of relevant sensor types and body locations automatically. Ultimately, the proposed method could reduce the cost of AAL systems by facilitating execution of algorithms on devices with limited resources and by using as few sensors as possible.","Feature extraction,
Windows,
Activity recognition,
Sensor phenomena and characterization,
Robustness,
Ambient assisted living"
Stochastic Analysis of the Signed LMS Algorithms for Cyclostationary White Gaussian Inputs,"This paper studies the stochastic behavior of the signed variants of the LMS algorithm for a system identification framework when the input signal is a cyclostationary white Gaussian process. Three algorithms are studied: the signed regressor, the signed error, and the sign-sign algorithms. The input cyclostationary signal is modeled by a white Gaussian random process with periodically time-varying power. The system parameters vary according to a random-walk. Mathematical models are derived for the mean and mean-square-deviation behavior of the adaptive weights with the input cyclostationarity. These models are used to derive new results concerning the performance of the algorithms. Some of these results are surprising. Monte Carlo simulations of the three algorithms provide strong support for the theory.","Algorithm design and analysis,
Signal processing algorithms,
Adaptation models,
Mathematical model,
Adaptive filters,
Analytical models,
Stochastic processes"
Network Flow Integer Programming to Track Elliptical Cells in Time-Lapse Sequences,"We propose a novel approach to automatically tracking elliptical cell populations in time-lapse image sequences. Given an initial segmentation, we account for partial occlusions and overlaps by generating an over-complete set of competing detection hypotheses. To this end, we fit ellipses to portions of the initial regions and build a hierarchy of ellipses, which are then treated as cell candidates. We then select temporally consistent ones by solving to optimality an integer program with only one type of flow variables. This eliminates the need for heuristics to handle missed detections due to partial occlusions and complex morphology. We demonstrate the effectiveness of our approach on a range of challenging sequences consisting of clumped cells and show that it outperforms state-of-the-art techniques.","Image segmentation,
Trajectory,
Linear programming,
Target tracking,
Statistics,
Sociology,
Image sequences"
Optimal Camera Placement for Motion Capture Systems,"Optical motion capture is based on estimating the three-dimensional positions of markers by triangulation from multiple cameras. Successful performance depends on points being visible from at least two cameras and on the accuracy of the triangulation. Triangulation accuracy is strongly related to the positions and orientations of the cameras. Thus, the configuration of the camera network has a critical impact on performance. A poor camera configuration may result in a low quality three-dimensional (3D) estimation and consequently low quality of tracking. This paper introduces and compares two methods for camera placement. The first method is based on a metric that computes target point visibility in the presence of dynamic occlusion from cameras with “good” views. The second method is based on the distribution of views of target points. Efficient algorithms, based on simulated annealing, are introduced for estimating the optimal configuration of cameras for the two metrics and a given distribution of target points. The accuracy and robustness of the algorithms are evaluated through both simulation and empirical measurement. Implementations of the two methods are available for download as tools for the community.",
Technological Impacts in Socio-Technical Communities: Values and Pathologies,"Communities and societies are known to achieve key benefits, such as trade growth, risk mitigation and resource sustainability [1], by following and observing conventionally-agreed and mutable rules (e.g., norms and laws). We focus on ""democratic"" societies-where citizens can contribute to changes in these governing regulations (directly or indirectly), which then apply equally to all [2], [3]. However, the unrestricted self-interested, or power-seeking behavior of some members may progressively deform such society; for example the iron law of oligarchy [4]. Consequently, scholars of socio-political sciences have identified ""defense mechanisms"" that help protect societies against such phenomena [3], [5]. These include comprehensible<sup>1</sup> transparency, responsible engagement, and the perceptible impact of pro-social contributions.","Communities,
Economics,
Sociotechnical systems,
Cognition,
Object recognition,
Complexity theory,
Risk management"
A Game-Theoretic Approach to Fake-Acknowledgment Attack on Cyber-Physical Systems,"A class of malicious attacks against remote state estimation in cyber-physical systems is considered. A sensor adopts an acknowledgement (ACK)-based online power schedule to improve the remote state estimation performance under limited resources. To launch malicious attacks, the attacker can modify the ACKs from the remote estimator and convey fake information to the sensor, thereby misleading the sensor with subsequent performance degradation. One feasible attack pattern is proposed and the corresponding effect on the estimation performance is derived analytically. Due to the ACKs being unreliable, the sensor needs to decide at each instant, whether to trust the ACK information or not and adapt the transmission schedule accordingly. In the meanwhile, there is also a tradeoff for the attacker between attacking and not attacking when the modification of ACKs is costly. To investigate the optimal strategies for both the sensor and the attacker, a game-theoretic framework is built and the equilibrium for both sides is studied.","Cyber-physical systems,
State estimation,
Game theory,
Communication system security,
Wireless communication"
A Wideband Absorber With a Multiresonant Gridded-Square FSS for Antenna RCS Reduction,"This letter proposes a wideband absorber using a multiresonant gridded-square frequency-selected surface structure. Equivalent circuit models of parallel LC resonant circuits in series are given to clarify the multiresonant working principle. Using this method, a quad-resonant absorbing ground plane is designed. Surface current distributions are shown to explicate the multiresonant modes. By using the proposed absorbing ground, a wideband dipole's radar cross section (RCS) can be reduced effectively. Measured results show that 50% absorption bandwidth of the proposed absorbing ground plane is from 2 to 2.7 GHz, and maximum RCS reduction of the antenna with absorbing ground is 5 dB. The peak gain of the antenna still maintains above 6.8 dBi in the frequency range from 1.66 to 2.76 GHz. The proposed absorbing ground has advantages such as multiresonant mechanism, wideband absorbing bandwidth, and polarization independence. Thus, it can be used to reduce antenna's RCS with maintained radiation performance.","Frequency selective surfaces,
Integrated circuit modeling,
Equivalent circuits,
Absorption,
Dipole antennas,
Analytical models,
Reflection coefficient"
Robustness-Driven Resilience Evaluation of Self-Adaptive Software Systems,"An increasingly important requirement for certain classes of software-intensive systems is the ability to self-adapt their structure and behavior at run-time when reacting to changes that may occur to the system, its environment, or its goals. A major challenge related to self-adaptive software systems is the ability to provide assurances of their resilience when facing changes. Since in these systems, the components that act as controllers of a target system incorporate highly complex software, there is the need to analyze the impact that controller failures might have on the services delivered by the system. In this paper, we present a novel approach for evaluating the resilience of self-adaptive software systems by applying robustness testing techniques to the controller to uncover failures that can affect system resilience. The approach for evaluating resilience, which is based on probabilistic model checking, quantifies the probability of satisfaction of system properties when the target system is subject to controller failures. The feasibility of the proposed approach is evaluated in the context of an industrial middleware system used to monitor and manage highly populated networks of devices, which was implemented using the Rainbow framework for architecture-based self-adaptation.","Resilience,
Robustness,
Testing,
Probes,
Context,
Software systems,
Monitoring"
"Quantifying User Reputation Scores, Data Trustworthiness, and User Incentives in Mobile Crowd-Sensing","Ubiquity of mobile devices with rich sensory capabilities has given rise to the mobile crowd-sensing (MCS) concept, in which a central authority (the platform) and its participants (mobile users) work collaboratively to acquire sensory data over a wide geographic area. Recent research in MCS highlights the following facts: 1) a utility metric can be defined for both the platform and the users, quantifying the value received by either side; 2) incentivizing the users to participate is a non-trivial challenge; 3) correctness and truthfulness of the acquired data must be verified, because the users might provide incorrect or inaccurate data, whether due to malicious intent or malfunctioning devices; and 4) an intricate relationship exists among platform utility, user utility, user reputation, and data trustworthiness, suggesting a co-quantification of these inter-related metrics. In this paper, we study two existing approaches that quantify crowd-sensed data trustworthiness, based on statistical and vote-based user reputation scores. We introduce a new metric - collaborative reputation scores - to expand this definition. Our simulation results show that collaborative reputation scores can provide an effective alternative to the previously proposed metrics and are able to extend crowd sensing to applications that are driven by a centralized as well as decentralized control.","Mobile communication,
Measurement,
Sensors,
Mobile handsets,
Collaboration,
Social network services,
Computers"
A Multi-Functional Fully Distributed Control Framework for AC Microgrids,"This paper proposes a fully distributed control methodology for secondary control of AC microgrids. The control framework includes three modules: voltage regulator, reactive power regulator, and active power/frequency regulator. The voltage regulator module maintains the average voltage of the microgrid distribution line at the rated value. The reactive power regulator compares the local normalized reactive power of an inverter with its neighbors’ powers on a communication graph and, accordingly, fine-tunes Q-V droop coefficients to mitigate any reactive power mismatch. Collectively, these two modules account for the effect of the distribution line impedance on the reactive power flow. The third module regulates all inverter frequencies at the nominal value while sharing the active power demand among them. Unlike most conventional methods, this controller does not utilize any explicit frequency measurement. The proposed controller is fully distributed; i.e., each controller requires information exchange with only its neighbors linked directly on the communication graph. Steady-state performance analysis assures the global voltage regulation, frequency synchronization, and proportional active/reactive power sharing. An AC microgrid is prototyped to experimentally validate the proposed control methodology against the load change, plug-and-play operation, and communication constraints such as delay, packet loss, and limited bandwidth.",
A Generic Framework for Constraint-Driven Data Selection in Mobile Crowd Photographing,"Mobile crowd photographing (MCP) is an emerging area of interest for researchers as the built-in cameras of mobile devices are becoming one of the commonly used visual logging approaches in our daily lives. In order to meet diverse MCP application requirements and constraints of sensing targets, a multifacet task model should be defined for a generic MCP data collection framework. Furthermore, MCP collects pictures in a distributed way in which a large number of contributors upload pictures whenever and wherever it is suitable. This inevitably leads to evolving picture streams. This paper investigates the multiconstraint-driven data selection problem in MCP picture aggregation and proposes a pyramid-tree (PTree) model which can efficiently select an optimal subset from the evolving picture streams based on varied coverage needs of MCP tasks. By utilizing the PTree model in a generic MCP data collection framework, which is called CrowdPic, we test and evaluate the effectiveness, efficiency, and flexibility of the proposed framework through crowdsourcing-based and simulation-based experiments. Both the theoretical analysis and simulation results indicate that the PTree-based framework can effectively select a subset with high utility coverage and low redundancy ratio from the streaming data. The overall framework is also proved flexible and applicable to a wide range of MCP task scenarios.","Sensors,
Data collection,
Visualization,
Data models,
Redundancy,
Mobile communication,
Monitoring"
Convolutional recurrent neural networks for music classification,"We introduce a convolutional recurrent neural network (CRNN) for music tagging. CRNNs take advantage of convolutional neural networks (CNNs) for local feature extraction and recurrent neural networks for temporal summarisation of the extracted features. We compare CRNN with three CNN structures that have been used for music tagging while controlling the number of parameters with respect to their performance and training time per sample. Overall, we found that CRNNs show a strong performance with respect to the number of parameter and training time, indicating the effectiveness of its hybrid structure in music feature extraction and feature summarisation.","Convolution,
Feature extraction,
Kernel,
Tagging,
Training,
Two dimensional displays,
Recurrent neural networks"
Stochastic Multiview Hashing for Large-Scale Near-Duplicate Video Retrieval,"Near-duplicate video retrieval (NDVR) has been a significant research task in multimedia given its high impact in applications, such as video search, recommendation, and copyright protection. In addition to accurate retrieval performance, the exponential growth of online videos has imposed heavy demands on the efficiency and scalability of the existing systems. Aiming at improving both the retrieval accuracy and speed, we propose a novel stochastic multiview hashing algorithm to facilitate the construction of a large-scale NDVR system. Reliable mapping functions, which convert multiple types of keyframe features, enhanced by auxiliary information such as video-keyframe association and ground truth relevance to binary hash code strings, are learned by maximizing a mixture of the generalized retrieval precision and recall scores. A composite Kullback-Leibler divergence measure is used to approximate the retrieval scores, which aligns stochastically the neighborhood structures between the original feature and the relaxed hash code spaces. The efficiency and effectiveness of the proposed method are examined using two public near-duplicate video collections and are compared against various classical and state-of-the-art NDVR systems.","Feature extraction,
Multimedia communication,
Streaming media,
Histograms,
Copyright protection,
Scalability,
Electronic mail"
Automatically Evolving Rotation-Invariant Texture Image Descriptors by Genetic Programming,"In computer vision, training a model that performs classification effectively is highly dependent on the extracted features, and the number of training instances. Conventionally, feature detection and extraction are performed by a domain expert who, in many cases, is expensive to employ and hard to find. Therefore, image descriptors have emerged to automate these tasks. However, designing an image descriptor still requires domain-expert intervention. Moreover, the majority of machine learning algorithms require a large number of training examples to perform well. However, labeled data is not always available or easy to acquire, and dealing with a large dataset can dramatically slow down the training process. In this paper, we propose a novel genetic programming-based method that automatically synthesises a descriptor using only two training instances per class. The proposed method combines arithmetic operators to evolve a model that takes an image and generates a feature vector. The performance of the proposed method is assessed using six datasets for texture classification with different degrees of rotation and is compared with seven domain-expert designed descriptors. The results show that the proposed method is robust to rotation and has significantly outperformed, or achieved a comparable performance to, the baseline methods.","Feature extraction,
Training,
Computer vision,
Robustness,
Pattern recognition,
Image segmentation,
Genetic programming"
Parallel and Distributed Computation for Dynamical Economic Dispatch,"This letter introduces a parallel and distributed computation method for dynamical economic dispatch over a cyber-physical system. To achieve a faster economic dispatch operation, accelerated consensus approach is proposed. The simulation illustrates the better performance of accelerated consensus algorithm.","Economics,
Acceleration,
Generators,
Heuristic algorithms,
Algorithm design and analysis,
Power generation,
Australia"
A Coupled-Line Balanced-to-Single-Ended Out-of-Phase Power Divider With Enhanced Bandwidth,"In this paper, a coupled-line balanced-to-single-ended out-of-phase power divider is proposed. Configured by three quarter-wavelength coupled lines, the proposed power divider is compact and able to enhance the bandwidth of differential-mode power dividing, isolation, common-mode suppression, and phase difference between the output ports. Furthermore, enhancing the bandwidth for common-mode suppression using additional quarter-wavelength open stubs is discussed. Analytical solution of the parameters for specified bandwidth can be achieved using oddand even-mode analysis. Analytical and practical bandwidth limitation has been analyzed, and it is shown that the bandwidths can be controlled by the oddand even-mode impedance of the coupled lines. For demonstration, a prototype of size 15 mm x 95 mm (0.15 λg x0.95 λg) achieves an operating bandwidth (|SddAA| <; -20 dB) of 30% with the minimum insertion loss of 0.1 dB.","Bandwidth,
Power dividers,
Equivalent circuits,
Integrated circuit modeling,
Ports (Computers),
Microstrip,
Impedance"
Hybrid Passive-Overcurrent Relay for Detection of Faults in Low-Voltage DC Grids,"Detection of high-resistance faults on meshed low-voltage dc grids poses a challenge, as such faults have very low fault current magnitudes. This paper proposes a hybrid passive-overcurrent relay to overcome this problem. The proposed relay consists of one current and one voltage transducer, as well as two passive elements: 1) an inductor; and 2) a capacitor. For bolted and relatively low-resistance faults, the relay uses a simple overcurrent function to detect the resultant high fault current magnitudes within 2 ms. On the other hand, for relatively high-resistance faults, a real-time discrete wavelet transform is used to detect the voltage transients generated by the relay passive elements in less than 5 ms. Furthermore, the proposed relay is inherently capable of identifying the type of fault. The proposed approach relies on local-bus measurements to detect and classify various types of faults with resistance up to 200 ohms. Analytical modeling proves that the proposed approach is system independent. Testing the hybrid passive-overcurrent relay on a ±750 V meshed TN-S dc grid reveals that the proposed relay is fast, sensitive, and selective under various conditions.","Relays,
Circuit faults,
Capacitors,
Fault currents,
Resistance,
RLC circuits,
Discharges (electric)"
Evolving boxes for fast vehicle detection,"We perform fast vehicle detection from traffic surveillance cameras. A novel deep learning framework, namely Evolving Boxes, is developed that proposes and refines the object boxes under different feature representations. Specifically, our framework is embedded with a light-weight proposal network to generate initial anchor boxes as well as to early discard unlikely regions; a fine-turning network produces detailed features for these candidate boxes. We show intriguingly that by applying different feature fusion techniques, the initial boxes can be refined for both localization and recognition. We evaluate our network on the recent DETRAC benchmark and obtain a significant improvement over the state-of-the-art Faster RCNN by 9.5% mAP. Further, our network achieves 9-13 FPS detection speed on a moderate commercial GPU.","Proposals,
Vehicle detection,
Machine learning,
Training,
Detectors,
Object detection,
Surveillance"
Secure Signature-Based Authenticated Key Establishment Scheme for Future IoT Applications,"Internet of Things (IoT) is a network of all devices that can be accessed through the Internet. These devices can be remotely accessed and controlled using existing network infrastructure, thus allowing a direct integration of computing systems with the physical world. This also reduces human involvement along with improving accuracy and efficiency, resulting in economic benefit. The devices in IoT facilitate the day-to-day life of people. However, the IoT has an enormous threat to security and privacy due to its heterogeneous and dynamic nature. Authentication is one of the most challenging security requirements in the IoT environment, where a user (external party) can directly access information from the devices, provided the mutual authentication between user and devices happens. In this paper, we present a new signature-based authenticated key establishment scheme for the IoT environment. The proposed scheme is tested for security with the help of the widely used Burrows-Abadi-Needham logic, informal security analysis, and also the formal security verification using the broadly accepted automated validation of Internet security protocols and applications tool. The proposed scheme is also implemented using the widely accepted NS2 simulator, and the simulation results demonstrate the practicability of the scheme. Finally, the proposed scheme provides more functionality features, and its computational and communication costs are also comparable with other existing approaches.",
Heating Dispersal for Self-Healing NAND Flash Memory,"Substantially reduced lifetimes are becoming a critical issue in NAND flash memory with the advent of multi-level cell and triple-level cell flash memory. Researchers discovered that heating can cause worn-out NAND flash cells to become reusable and greatly extend the lifetime of flash memory cells. However, the heating process consumes a substantial amount of power, and some fundamental changes are required for existing NAND flash management techniques. In particular, all existing wear-leveling techniques are based on the principle of evenly distributing writes and erases. For self-healing NAND flash, this may cause NAND flash cells to be worn out in a short period of time. Moreover, frequently healing these cells may drain the energy quickly in battery-driven mobile devices, which is defined as the concentrated heating problem. In this paper, we propose a novel wear-leveling scheme called DHeating (Dispersed Heating) to address the problem. In DHeating, rather than evenly distributing writes and erases over a time period, write and erase operations are scheduled on a small number of flash memory cells at a time, so that these cells can be worn out and healed much earlier than other cells. In this way, we can avoid quick energy depletion caused by concentrated heating. In addition, the heating process takes several seconds and has become the new performance bottleneck. In order to address this issue, we propose a lazy heating repair scheme. The lazy heating repair scheme can ease the long time delays caused by the heating via delaying the heating operation and using the system idle time to repair. Furthermore, the flash memory's reliability becomes worse with the flash memory cells reaching the excepted worn-out time. We propose an early heating strategy to solve the reliability problem. With the extended lifetime provided by self-healing, we can trade some lifetimes for reliability. The idea is to start the healing process earlier than the expected worn-out time. We evaluate our scheme based on an embedded platform. The experimental results show that the proposed scheme can effectively prolong the consecutive heating time interval, alleviate the long time delays caused by the heating, and enhance the reliability for self-healing flash memory.","Heating,
Maintenance engineering,
Reliability,
Logic gates,
Delay effects,
Silicon,
Substrates"
A High-Order Possibilistic C-Means Algorithm for Clustering Incomplete Multimedia Data,"Clustering is a commonly used technique for multimedia organization, analysis, and retrieval. However, most multimedia clustering methods are difficult to capture the high-order nonlinear correlations over multimodal features, resulting in the low clustering accuracy. Furthermore, they cannot extract features from multimedia data with missing values, leading to failure in clustering incomplete multimedia data that are widespread in practical applications. In this paper, we propose a high-order possibilistic C-means algorithm (HOPCM) for clustering incomplete multimedia data. HOPCM improves the basic autoencoder model for learning features of multimedia data with missing values. Furthermore, HOPCM uses the tensor distance rather than the Euclidean distance as the distance metric to capture as much as possible the unknown high-dimensional distribution of multimedia data. Extensive experiments are carried out on three representative multimedia data sets: NUS-WIDE, CUAVE, and SNAE. The results demonstrate that HOPCM achieves significantly better clustering performance than many existing algorithms. More importantly, HOPCM is able to cluster both high-quality multimedia data and incomplete multimedia data effectively, while other existing methods can only cluster the high-quality multimedia data.","Multimedia communication,
Clustering algorithms,
Tensile stress,
Phase change materials,
Feature extraction"
On data integrity attacks against optimal power flow in power grid systems,"In this paper, we investigate the data integrity attack against Optimal Power Flow (OPF) with the least effort from the adversary's perspective. The investigated attack can first select the minimum number of target nodes to compromise by analyzing the difference between the capacity of transmission line and the real transmission power, and then search for a critical attack vector (with a goal to minimize the amount of information to manipulate) as an optimal attack strategy. To defend against such an attack, we develop the defensive scheme by protecting the critical nodes. Based on various IEEE standard systems, we show the effectiveness of our investigated attack scheme and the corresponding defense schemes.",
Energy-Distortion Exponents in Lossy Transmission of Gaussian Sources Over Gaussian Channels,"Lossy transmission of Gaussian sources over energy-limited Gaussian point-to-point and broadcast channels is studied under the infinite bandwidth regime, i.e., when the number of channel uses is unlimited. Using previously known asymptotic achievability and converse results, the energy-distortion exponent, defined as the rate of decay of the square-error distortion as the available energy-to-noise ratio increases without bound, is completely characterized for both the point-to-point and broadcast channel cases. Turning then to the scenario of zero-delay transmission, where outage events with arbitrarily small probability are allowed, it is shown that the same energy-distortion exponent as in the infinite-delay case can be achieved in all the studied scenarios.",
Fourier Accelerated Multistatic Imaging: A Fast Reconstruction Algorithm for Multiple-Input-Multiple-Output Radar Imaging,"Multiple-input-multiple-output (MIMO) radar image processing presents problems difficult to address by modifying conventional monostatic radar methods as Fourier range migration. When the distance between the transmitter and receiver is comparable to the target size, the single phase center approximation is not accurate. Furthermore, if the antenna radiation pattern significantly deviates from a spherical wave, the symmetries assumed in most range migration techniques are violated. We present a rapid Fourier-based MIMO reconstruction called Fourier accelerated multistatic imaging (FAMI) suitable for massively parallel computation that accounts for frequency-dependent radiation patterns, does not require the single phase center approximation, and is able to dynamically adapt to different target support volume shapes. FAMI is especially suitable for frequency-diversity antenna systems that use spectrally modulated coded spatial radiation patterns.","Antenna radiation patterns,
Radar imaging,
Radar antennas,
Antenna arrays,
Imaging,
Receivers"
Microexpression Identification and Categorization Using a Facial Dynamics Map,"Unlike conventional facial expressions, microexpressions are instantaneous and involuntary reflections of human emotion. Because microexpressions are fleeting, lasting only a few frames within a video sequence, they are difficult to perceive and interpret correctly, and they are highly challenging to identify and categorize automatically. Existing recognition methods are often ineffective at handling subtle face displacements, which can be prevalent in typical microexpression applications due to the constant movements of the individuals being observed. To address this problem, a novel method called the Facial Dynamics Map is proposed to characterize the movements of a microexpression in different granularity. Specifically, an algorithm based on optical flow estimation is used to perform pixel-level alignment for microexpression sequences. Each expression sequence is then divided into spatiotemporal cuboids in the chosen granularity. We also present an iterative optimal strategy to calculate the principal optical flow direction of each cuboid for better representation of the local facial dynamics. With these principal directions, the resulting Facial Dynamics Map can characterize a microexpression sequence. Finally, a classifier is developed to identify the presence of microexpressions and to categorize different types. Experimental results on four benchmark datasets demonstrate higher recognition performance and improved interpretability.",
A Collective Neurodynamic Approach to Constrained Global Optimization,"Global optimization is a long-lasting research topic in the field of optimization, posting many challenging theoretic and computational issues. This paper presents a novel collective neurodynamic method for solving constrained global optimization problems. At first, a one-layer recurrent neural network (RNN) is presented for searching the Karush-Kuhn-Tucker points of the optimization problem under study. Next, a collective neuroydnamic optimization approach is developed by emulating the paradigm of brainstorming. Multiple RNNs are exploited cooperatively to search for the global optimal solutions in a framework of particle swarm optimization. Each RNN carries out a precise local search and converges to a candidate solution according to its own neurodynamics. The neuronal state of each neural network is repetitively reset by exchanging historical information of each individual network and the entire group. Wavelet mutation is performed to avoid prematurity, add diversity, and promote global convergence. It is proved in the framework of stochastic optimization that the proposed collective neurodynamic approach is capable of computing the global optimal solutions with probability one provided that a sufficiently large number of neural networks are utilized. The essence of the collective neurodynamic optimization approach lies in its potential to solve constrained global optimization problems in real time. The effectiveness and characteristics of the proposed approach are illustrated by using benchmark optimization problems.",
Reducing Image Compression Artifacts by Structural Sparse Representation and Quantization Constraint Prior,"The block discrete cosine transform (BDCT) has been widely used in current image and video coding standards, owing to its good energy compaction and decorrelation properties. However, because of independent quantization of DCT coefficients in each block, BDCT usually gives rise to visually annoying blocking compression artifacts, especially at low bit rates. In this paper, to reduce blocking artifacts and obtain high-quality images, image deblocking is cast as an optimization problem within maximum a posteriori framework, and a novel algorithm for image deblocking by using structural sparse representation (SSR) prior and quantization constraint (QC) prior is proposed. The SSR prior is utilized to simultaneously enforce the intrinsic local sparsity and the nonlocal self-similarity of natural images, while QC is explicitly incorporated to ensure a more reliable and robust estimation. A new split Bregman iteration-based method with an adaptively adjusted regularization parameter is developed to solve the proposed optimization problem, which makes the entire algorithm more practical. Experiments demonstrate that the proposed image-deblocking algorithm combining SSR and QC outperforms the current state-of-the-art methods in both peak signal-to-noise ratio and visual perception.",
Hierarchical Representation Learning for Kinship Verification,"Kinship verification has a number of applications such as organizing large collections of images and recognizing resemblances among humans. In this paper, first, a human study is conducted to understand the capabilities of human mind and to identify the discriminatory areas of a face that facilitate kinshipcues. The visual stimuli presented to the participants determine their ability to recognize kin relationship using the whole face as well as specific facial regions. The effect of participant gender and age and kin-relation pair of the stimulus is analyzed using quantitative measures such as accuracy, discriminability index d', and perceptual information entropy. Utilizing the information obtained from the human study, a hierarchical kinship verification via representation learning (KVRL) framework is utilized to learn the representation of different face regions in an unsupervised manner. We propose a novel approach for feature representation termed as filtered contractive deep belief networks (fcDBN). The proposed feature representation encodes relational information present in images using filters and contractive regularization penalty. A compact representation of facial images of kin is extracted as an output from the learned model and a multi-layer neural network is utilized to verify the kin accurately. A new WVU kinship database is created, which consists of multiple images per subject to facilitate kinship verification. The results show that the proposed deep learning framework (KVRL-fcDBN) yields the state-of-the-art kinship verification accuracy on the WVU kinship database and on four existing benchmark data sets. Furthermore, kinship information is used as a soft biometric modality to boost the performance of face verification via product of likelihood ratio and support vector machine based approaches. Using the proposed KVRL-fcDBN framework, an improvement of over 20% is observed in the performance of face verification.","Face,
Face recognition,
Entropy,
Indexes,
Machine learning,
Training"
Distributed Home Energy Management System With Storage in Smart Grid Using Game Theory,"In this paper, the problem of distributed home energy management system with storage (HoMeS) in a coalition, which consists of multiple microgrids and multiple customers, is studied using the multiple-leader-multiple-follower Stackelberg game theoretic model-a multistage and multilevel game. The microgrids, which act as the leaders, need to decide on the minimum amount of energy to be generated with the help of a central energy management unit and the optimum price per unit energy to maximize their profit. On the other hand, the customers, which act as the followers, need to decide on the optimum amount of energy to be consumed, including the energy to be requested for storage. Using the proposed distributed scheme, i.e., HoMeS, the earned profit of the grid improves up to 55%, and the customers consume almost 30.79% higher amount of energy, which, in turn, increases the utilization of the generated energy by the microgrids.",
An Emotion Recognition System for Mobile Applications,"Emotion-aware mobile applications have been increasing due to their smart features and user acceptability. To realize such an application, an emotion recognition system should be in real time and highly accurate. As a mobile device has limited processing power, the algorithm in the emotion recognition system should be implemented using less computation. In this paper, we propose an emotion recognition with high performance for mobile applications. In the proposed system, facial video is captured by an embedded camera of a smart phone. Some representative frames are extracted from the video, and a face detection module is applied to extract the face regions in the frames. The Bandlet transform is realized on the face regions, and the resultant subband is divided into non-overlapping blocks. Local binary patterns' histograms are calculated for each block, and then are concatenated over all the blocks. The Kruskal-Wallis feature selection is applied to select the most dominant bins of the concatenated histograms. The dominant bins are then fed into a Gaussian mixture model-based classifier to classify the emotion. Experimental results show that the proposed system achieves high recognition accuracy in a reasonable time.","Emotion recognition,
Mobile applications,
Face,
Transforms,
Histograms,
Smart phones,
Speech recognition"
Silicon Demonstration of Hardware Trojan Design and Detection in Wireless Cryptographic ICs,"Using silicon measurements from 40 chips fabricated in Taiwan Semiconductor Manufacturing Company's (TSMC's) 0.35-μm technology, we demonstrate the operation of two hardware Trojans, which leak the secret key of a wireless cryptographic integrated circuit (IC) consisting of an Advanced Encryption Standard (AES) core and an ultrawideband (UWB) transmitter (TX). With their impact carefully hidden in the transmission specification margins allowed for process variations, these hardware Trojans cannot be detected by production testing methods of either the digital or the analog part of the IC and do not violate the transmission protocol or any system-level specifications. Nevertheless, the informed adversary, who knows what to look for in the transmission power waveform, is capable of retrieving the 128-bit AES key, which is leaked with every 128-bit ciphertext block sent by the UWB TX. Moreover, through physical measurements and MATLAB simulations, we show that the attack facilitated by these hardware Trojans is robust to test equipment and communication channel noise. Finally, we experimentally evaluate the effectiveness of a popular hardware Trojan detection method, namely, statistical side-channel fingerprinting via trained one-class classifiers, in detecting the hardware Trojans introduced in our fabricated IC population.","Hardware,
Trojan horses,
Integrated circuits,
Wireless communication,
Silicon,
Encryption"
On the Limits of Coexisting Coverage and Capacity in Multi-RAT Heterogeneous Networks,"This paper devises a general modeling and analyzing framework for a heterogeneous wireless network (HetNet) in which several wireless subnetworks coexist and use multiple radio access technologies (multi-RATs). The coexisting coverage and network capacity in such a multi-RAT HetNet are hardly investigated in prior works. To characterize the coexisting interactions in a multi-RAT HetNet, in this paper, we consider a HetNet consisting of K tiers of access points (APs) and two different RATs, RAT-I and RAT-U, are adopted in the HetNet. RAT-I is adopted by the APs in the first K-1 tiers and APs in the Kth tier only use RAT-U. Both noncrossing-RAT and crossingRAT user association scenarios are considered. In each scenario, the void probability and the channel access probability of the APs in each tier are first found and then the tight lower bounds and their lowest limits on the proposed coexisting coverage and network capacity are derived. We show that multi-RAT networks in general can achieve higher link coverage and capacity by using opportunistic carrier sense multiple access with collision avoidance that avoids/alleviates severe interfering between all coexisting APs. Also, crossing-RAT user association is shown to achieve much higher coexisting coverage and network capacity than noncrossing-RAT user association. Finally, numerical simulations for the LTE-U and WiFi networks coexisting in the HetNet validate our findings.","Rats,
Wireless fidelity,
Wireless networks,
Access protocols,
Long Term Evolution,
Analytical models"
Hybrid Method for Minimizing Service Delay in Edge Cloud Computing Through VM Migration and Transmission Power Control,"Due to physical limitations, mobile devices are restricted in memory, battery, processing, among other characteristics. This results in many applications that cannot be run in such devices. This problem is fixed by Edge Cloud Computing, where the users offload tasks they cannot run to cloudlet servers in the edge of the network. The main requirement of such a system is having a low Service Delay, which would correspond to a high Quality of Service. This paper presents a method for minimizing Service Delay in a scenario with two cloudlet servers. The method has a dual focus on computation and communication elements, controlling Processing Delay through virtual machine migration and improving Transmission Delay with Transmission Power Control. The foundation of the proposal is a mathematical model of the scenario, whose analysis is used on a comparison between the proposed approach and two other conventional methods; these methods have single focus and only make an effort to improve either Transmission Delay or Processing Delay, but not both. As expected, the proposal presents the lowest Service Delay in all study cases, corroborating our conclusion that a dual focus approach is the best way to tackle the Service Delay problem in Edge Cloud Computing.","Delays,
Servers,
Cloud computing,
Mobile handsets,
Proposals,
Power control,
Process control"
"Control Under Stochastic Multiplicative Uncertainties: Part I, Fundamental Conditions of Stabilizability","In this two-part paper we study stabilization and optimal control of linear time-invariant systems with stochastic multiplicative uncertainties. We consider structured multiplicative perturbations, which, unlike in robust control theory, consist of static, zero-mean stochastic processes, and we assess the stability and performance of such systems using mean-square measures. While Part 2 of this paper tackles and solves optimal control problems under the mean-square criterion, Part 1 is devoted to the stabilizability problem. We develop fundamental conditions of mean-square stabilizability which ensure that an open-loop unstable system can be stabilized by output feedback in the mean-square sense. For single-input single-output systems, a general, explicit stabilizability condition is obtained. This condition, both necessary and sufficient, provides a fundamental limit imposed by the system's unstable poles, nonminimum phase zeros and time delay. For multi-input multi-output systems, we provide a complete, computationally efficient solution for minimum phase systems possibly containing time delays, in the form of a generalized eigenvalue problem readily solvable by means of linear matrix inequality optimization. Limiting cases and nonminimum phase plants are analyzed in depth for conceptual insights, revealing, among other things, how the directions of unstable poles and nonminimum phase zeros may affect mean-square stabilizability in MIMO systems. Other than their independent interest, stochastic multiplicative uncertainties have found utilities in modeling networked control systems pertaining to, e.g., packet drops, network delays, and fading. Our results herein lend solutions applicable to networked control problems addressing these issues.","Uncertainty,
Stochastic processes,
Stability criteria,
Optimal control,
Poles and zeros,
MIMO"
Sparseness Analysis in the Pretraining of Deep Neural Networks,"A major progress in deep multilayer neural networks (DNNs) is the invention of various unsupervised pretraining methods to initialize network parameters which lead to good prediction accuracy. This paper presents the sparseness analysis on the hidden unit in the pretraining process. In particular, we use the L1-norm to measure sparseness and provide some sufficient conditions for that pretraining leads to sparseness with respect to the popular pretraining models- such as denoising autoencoders (DAEs) and restricted Boltzmann machines (RBMs). Our experimental results demonstrate that when the sufficient conditions are satisfied, the pretraining models lead to sparseness. Our experiments also reveal that when using the sigmoid activation functions, pretraining plays an important sparseness role in DNNs with sigmoid (Dsigm), and when using the rectifier linear unit (ReLU) activation functions, pretraining becomes less effective for DNNs with ReLU (Drelu). Luckily, Drelu can reach a higher recognition accuracy than DNNs with pretraining (DAEs and RBMs), as it can capture the main benefit (such as sparseness-encouraging) of pretraining in Dsigm. However, ReLU is not adapted to the different firing rates in biological neurons, because the firing rate actually changes along with the varying membrane resistances. To address this problem, we further propose a family of rectifier piecewise linear units (RePLUs) to fit the different firing rates. The experimental results show that the performance of RePLU is better than ReLU, and is comparable with those with some pretraining techniques, such as RBMs and DAEs.","Biological neural networks,
Neurons,
Training,
Biomembranes,
Learning systems,
Signal processing algorithms"
Coded OFDM-IM With Transmit Diversity,"In this paper, we propose a simple transmit diversity scheme for orthogonal frequency division multiplexing (OFDM) with index modulation (IM) in order to achieve a diversity gain for index detection, which can significantly improve the performance of OFDM-IM at the cost of the spectral efficiency. An optimal approach for active index detection is derived, which has a complexity, growing linearly with the size of OFDM symbol. A salient feature of the proposed transmit diversity scheme is that it can be easily employed in conjunction with a conventional coding scheme for data symbols. Consequently, we can implement coded OFDM-IM together with the proposed transmit diversity scheme in a straightforward manner, which can provide a good performance under a frequency-fading environment.","OFDM,
Indexes,
Modulation,
Diversity methods,
Channel coding,
Complexity theory"
A Hybrid Data Compression Scheme for Power Reduction in Wireless Sensors for IoT,"This paper presents a novel data compression and transmission scheme for power reduction in Internet-of-Things (IoT) enabled wireless sensors. In the proposed scheme, data is compressed with both lossy and lossless techniques, so as to enable hybrid transmission mode, support adaptive data rate selection and save power in wireless transmission. Applying the method to electrocardiogram (ECG), the data is first compressed using a lossy compression technique with a high compression ratio (CR). The residual error between the original data and the decompressed lossy data is preserved using entropy coding, enabling a lossless restoration of the original data when required. Average CR of 2.1× and 7.8× were achieved for lossless and lossy compression respectively with MIT/BIH database. The power reduction is demonstrated using a Bluetooth transceiver and is found to be reduced to 18% for lossy and 53% for lossless transmission respectively. Options for hybrid transmission mode, adaptive rate selection and system level power reduction make the proposed scheme attractive for IoT wireless sensors in healthcare applications.","Sensors,
Wireless sensor networks,
Wireless communication,
Electrocardiography,
Propagation losses,
Hybrid power systems,
Data compression"
Multi-Resolution Climate Ensemble Parameter Analysis with Nested Parallel Coordinates Plots,"Due to the uncertain nature of weather prediction, climate simulations are usually performed multiple times with different spatial resolutions. The outputs of simulations are multi-resolution spatial temporal ensembles. Each simulation run uses a unique set of values for multiple convective parameters. Distinct parameter settings from different simulation runs in different resolutions constitute a multi-resolution high-dimensional parameter space. Understanding the correlation between the different convective parameters, and establishing a connection between the parameter settings and the ensemble outputs are crucial to domain scientists. The multi-resolution high-dimensional parameter space, however, presents a unique challenge to the existing correlation visualization techniques. We present Nested Parallel Coordinates Plot (NPCP), a new type of parallel coordinates plots that enables visualization of intra-resolution and inter-resolution parameter correlations. With flexible user control, NPCP integrates superimposition, juxtaposition and explicit encodings in a single view for comparative data visualization and analysis. We develop an integrated visual analytics system to help domain scientists understand the connection between multi-resolution convective parameters and the large spatial temporal ensembles. Our system presents intricate climate ensembles with a comprehensive overview and on-demand geographic details. We demonstrate NPCP, along with the climate ensemble visualization system, based on real-world use-cases from our collaborators in computational and predictive science.","Meteorology,
Data visualization,
Computational modeling,
Correlation,
Atmospheric modeling,
Visualization,
Spatial resolution"
Energy Management Problems Under Uncertainties for Grid-Connected Microgrids: A Chance Constrained Programming Approach,"This paper studies two energy management problems under uncertainties for a grid-connected microgrid. The problems are motivated by practical microgrid applications such as peak power shaving and frequency regulation. These applications require constraints on the microgrid energy output, which is uncertain due to the integration with renewable resources and random loads. Both problems are formulated as chance constrained programming problems to systematically incorporate uncertainties. We also show that the resulting chance constrained programming problems can both be solved using linear programming. The proposed formulation and solution are verified by two case studies originated from real world applications.","Microgrids,
Batteries,
Uncertainty,
Programming,
Probability distribution,
Energy management,
Automotive engineering"
A Local-Optimization Emergency Scheduling Scheme With Self-Recovery for a Smart Grid,"With the widespread applications of Internet of Things (IoT), the emergency response performance for large-scale network packets is facing serious challenge, especially for renewable distributed energy resources monitoring in a smart grid. Therefore, how to improve the real-time performance of the emergency data packets has been a critical issue. Traditional packet scheduling schemes and topology optimization strategies are not suitable for a large-scale IoT-based smart grid. To address this problem, this paper proposes a new packet scheduling scheme named LOES, which first combines the priority-based packet scheduling scheme with local optimization. We exchange local geographic information to reduce the hop counts and distance between distributed source nodes and sink nodes. Each destination node determines the packet scheduling sequence according to the received emergency information. Finally, we compare LOES with first come first serve, multilevel scheme, and dynamic multilevel priority packet scheduling scheme using packet loss rate, packet waiting time, and average packet end-to-end delay as metrics. The simulation results show that LOES outperforms these previous scheduling schemes.",
Comprehensive Feature-Based Robust Video Fingerprinting Using Tensor Model,"Content-based near-duplicate video detection (NDVD) is essential for effective search and retrieval, and robust video fingerprinting is a good solution for NDVD. Most existing video fingerprinting methods use a single feature or concatenate different features to generate video fingerprints, and show good performance under single-mode modifications such as noise addition and blurring. However, when they suffer combined modifications, the performance is degraded to a certain extent because such features cannot characterize the video content completely. By contrast, the assistance and consensus among different features can improve the performance of video fingerprinting. Therefore, in the present study, we mine the assistance and consensus among different features based on a tensor model, and we present a new comprehensive feature to fully use them in the proposed video fingerprinting framework. We also analyze what the comprehensive feature really is for representing the original video. In this framework, the video is initially set as a high-order tensor that consists of different features, and the video tensor is decomposed via the Tucker model with a solution that determines the number of components. Subsequently, the comprehensive feature is generated by the low-order tensor obtained from tensor decomposition. Finally, the video fingerprint is computed using this feature. A matching strategy used for narrowing the search is also proposed based on the core tensor. The robust video fingerprinting framework is resistant not only to single-mode modifications but also to their combination.","Tensile stress,
Robustness,
Feature extraction,
Media,
Sun,
Fingerprint recognition,
Computational modeling"
Intensity and Compactness Enabled Saliency Estimation for Leakage Detection in Diabetic and Malarial Retinopathy,"Leakage in retinal angiography currently is a key feature for confirming the activities of lesions in the management of a wide range of retinal diseases, such as diabetic maculopathy and paediatric malarial retinopathy. This paper proposes a new saliency-based method for the detection of leakage in fluorescein angiography. A superpixel approach is firstly employed to divide the image into meaningful patches (or superpixels) at different levels. Two saliency cues, intensity and compactness, are then proposed for the estimation of the saliency map of each individual superpixel at each level. The saliency maps at different levels over the same cues are fused using an averaging operator. The two saliency maps over different cues are fused using a pixel-wise multiplication operator. Leaking regions are finally detected by thresholding the saliency map followed by a graph-cut segmentation. The proposed method has been validated using the only two publicly available datasets: one for malarial retinopathy and the other for diabetic retinopathy. The experimental results show that it outperforms one of the latest competitors and performs as well as a human expert for leakage detection and outperforms several state-of-the-art methods for saliency detection.","Retina,
Diseases,
Retinopathy,
Diabetes,
Image color analysis,
Lesions,
Image segmentation"
Iterative Re-Constrained Group Sparse Face Recognition With Adaptive Weights Learning,"In this paper, we consider the robust face recognition problem via iterative re-constrained group sparse classifier (IRGSC) with adaptive weights learning. Specifically, we propose a group sparse representation classification (GSRC) approach in which weighted features and groups are collaboratively adopted to encode more structure information and discriminative information than other regression based methods. In addition, we derive an efficient algorithm to optimize the proposed objective function, and theoretically prove the convergence. There are several appealing aspects associated with IRGSC. First, adaptively learned weights can be seamlessly incorporated into the GSRC framework. This integrates the locality structure of the data and validity information of the features into l2,p-norm regularization to form a unified formulation. Second, IRGSC is very flexible to different size of training set as well as feature dimension thanks to the l2,p-norm regularization. Third, the derived solution is proved to be a stationary point (globally optimal if p ≥ 1). Comprehensive experiments on representative data sets demonstrate that IRGSC is a robust discriminative classifier which significantly improves the performance and efficiency compared with the state-of-the-art methods in dealing with face occlusion, corruption, and illumination changes, and so on.","Robustness,
Training,
Dictionaries,
Face recognition,
Face,
Lighting,
Databases"
CMX: The Effects of an Educational MMORPG on Learning and Teaching Computer Programming,"Computer programming has for decades posed several difficulties for students of all educational levels. A number of teaching approaches have been proposed over the years but none seems to fulfil the needs of students nowadays. Students use computers mainly for playing games and the Internet and as quite a few researchers state this aspect of computers should be taken into account in the way we educate them. Towards this direction, this paper aims to examine the effects of using an educational Massive Multiplayer Online Role Playing Game (MMORPG) on teaching and learning computer programming. The educational features of an MMORPG called CMX are presented along with a design framework that was devised taking into account previous work in designing educational games. The effects of CMX on teaching and learning computer programming are assessed through a study with first-year undergraduate students. Seventy six students used CMX over a period of five weeks for learning various procedural programming concepts. Students evaluated various aspects of CMX byfilling in a questionnaire that was based on an evaluation framework, which was devised in accordance with the design framework of CMX. Moreover, the results of a midterm exam that took place priorto using CMX and students' accomplishments in the context of CMX were recorded and analyzed. The results show that the majority of the students was entertained by playing the game while learning, and felt motivated to continue based on the game's scenario due to the variety of activities included. In regards to the students' performance, a pre-test and a post-test were carried out in the experimental group, i.e., the participants of this study, and the control group, i.e., students of the course that continued to get taught the same concepts and performed the same assignments as the experimental group, but traditionally. The pre-test and post-test analysis of the performance results for both groups showed that the majority of the students in the experimental group increased their performance in computer programming. Furthermore, students stated they had a positive attitude in regards to re-using CMX in the future in order to learn additional programming concepts. The positive results of this study pave the way for CMX being used in the classroom and expanding the game's functionalities that will further increase students' performance and support teachers in delivering the required knowledge. Moreover, the work reported in this paper offers game designers and teachers methodological and empirical results for game-based learning in such a difficult domain as is computer programming. What is more, the design and evaluation frameworks presented are general enough that they can be easily adjusted and/or extended for designing and assessing educational games in other domains as well.","Games,
Programming profession,
Computers,
Education,
Robots"
Measure-Transformed Quasi-Maximum Likelihood Estimation,"In this paper, the Gaussian quasi-maximum likelihood estimator (GQMLE) is generalized by applying a transform to the probability distribution of the data. The proposed estimator, called measure-transformed GQMLE (MT-GQMLE), minimizes the empirical Kullback-Leibler divergence between a transformed probability distribution of the data and a hypothesized Gaussian probability measure. By judicious choice of the transform we show that, unlike the GQMLE, the proposed estimator can gain sensitivity to higher order statistical moments and resilience to outliers leading to significant mitigation of the model mismatch effect on the estimates. Under some mild regularity conditions, we show that the MT-GQMLE is consistent, asymptotically normal and unbiased. Furthermore, we derive a necessary and sufficient condition for asymptotic efficiency. A data driven procedure for optimal selection of the measure transformation parameters is developed that minimizes the trace of an empirical estimate of the asymptotic mean-squared-error matrix. The MT-GQMLE is applied to linear regression and source localization and numerical comparisons illustrate its robustness and resilience to outliers.","Maximum likelihood estimation,
Probability distribution,
Covariance matrices,
Transforms,
Resilience"
Nonlinear Direct Control for Three-Level NPC Back-to-Back Converter PMSG Wind Turbine Systems: Experimental Assessment With FPGA,"Finite control set model predictive control techniques have been emerged as good alternatives in particularly for multilevel and multiphase power converters, for which switching vectors with multiple magnitudes/directions are available but the modulator or switching table design becomes complex. In this paper, a finite-control-set model predictive direct torque and power control (FCS-DTC-DPC) for grid-tied three-level neutral-point clamped back-to-back power converters in permanent-magnet synchronous generator wind turbine systems is presented and experimentally compared with its counterpart: switching table-based direct torque and power control (ST-DTC-DPC). Both methods have been implemented and verified at a lab-constructed setup with a fully FPGA-based real-time controller. Experimental results confirm that both achieve (equivalently) good control dynamics, whereas FCS-DTC-DPC outperforms ST-DTC-DPC in terms of steady-state control performances at similar switching frequencies but has a higher computational demanding and is more sensitive to system parameter variations.","Wind turbines,
Switches,
Field programmable gate arrays,
Modulation,
Generators,
Torque"
Investigation and Demonstration of High Speed Full-Optical Hybrid FSO/Fiber Communication System Under Light Sand Storm Condition,"Traditional free space optic (FSO) communication systems has limited bandwidth because of the electrical/optical conversion. Full-optical FSO system eliminates this issue so it highly improves the system bandwidth. Such system can overcomes the backhaul problem in 4G/5G networks. This would be of great interest for researchers and network planners in the design and planning of wireless networks. Also it would be interesting for point-to-point data communication, to-ship communication, etc.","Optical transmitters,
Modulation,
Optical fiber networks,
Optical fiber amplifiers"
Secure Communications in Millimeter Wave Ad Hoc Networks,"Wireless networks with directional antennas, like millimeter wave (mmWave) networks, have enhanced security. For a large-scale mmWave ad hoc network in which eavesdroppers are randomly located, however, eavesdroppers can still intercept the confidential messages, since they may reside in the signal beam. This paper explores the potential of physical layer security in mmWave ad hoc networks. Specifically, we characterize the impact of mmWave channel characteristics, random blockages, and antenna gains on the secrecy performance. For the special case of uniform linear array (ULA), a tractable approach is proposed to evaluate the average achievable secrecy rate. We also characterize the impact of artificial noise in such networks. Our results reveal that in the low transmit power regime, the use of low mmWave frequency achieves better secrecy performance, and when increasing transmit power, a transition from low mmWave frequency to high mmWave frequency is demanded for obtaining a higher secrecy rate. More antennas at the transmitting nodes are needed to decrease the antenna gain obtained by the eavesdroppers when using ULA. Eavesdroppers can intercept more information by using a wide beam pattern. Furthermore, the use of artificial noise may be ineffective for enhancing the secrecy rate.","Ad hoc networks,
Interference,
Network security,
Physical layer,
Receivers,
Transmitting antennas,
Array signal processing"
Numerical simulation and experiments on mono-polar negative corona discharge applied in nanocomposites,"The corona discharge techniques, which are employed to orient dipoles and built up charges inside functional polymers, can develop important commercial applications of electroactive polymers (EAPs) and electrets for energy storage devices, air filters, electroacoustic and electromechanical transducers. We propose hereby an elective hybrid approach to the point-plane corona modeling in order to obtain more accurate electron flow in unipolar corona discharge system. A coupled system of partial differential equations (PDEs) w.r.t. Navier-stokes equations and hydrodynamic drift diffusion equations described the nature of photo-ionization, where the secondary avalanche in the discharge process was demonstrated. The simulation was verified by comparison with Surface Potential (SP) measurement of the nano-composites after corona polarization. Consequently, the spacial electric potential distribution and initial surface potential could be obtained by the means of finite elements method (FEM), which provided a good numerical approach for the experimental data of electrostatic surface potential. In addition, the influence of nano particle on the charge retain ability of the insulating polymers was also investigated, which could be a guideline for designing an effective poling method on the functional polymers applied in electrical energy storage devices sensors, actuators and transducer etc.","Partial discharges,
Finite element analysis,
Corona,
Discharges (electric),
Nanocomposites,
Energy storage,
Polymers"
Superpixel-Based Multitask Learning Framework for Hyperspectral Image Classification,"Due to the high spectral dimensionality of hyperspectral images as well as the difficult and time-consuming process of collecting sufficient labeled samples in practice, the small sample size scenario is one crucial problem and a challenging issue for hyperspectral image classification. Fortunately, the structure information of materials, reflecting region of homogeneity in the spatial domain, offers an invaluable complement to the spectral information. Assuming some spatial regularity and locality of surface materials, it is reasonable to segment the image into different homogeneous parts in advance, called superpixel, which can be used to improve the classification performance. In this paper, a superpixel-based multitask learning framework has been proposed for hyperspectral image classification. Specifically, a set of 2-D Gabor filters are first applied to hyperspectral images to extract discriminative features. Meanwhile, a superpixel map is generated from the hyperspectral images. Second, a superpixel-based spatial-spectral Schroedinger eigenmaps (S4E) method is adopted to effectively reduce the dimensions of each extracted Gabor cube. Finally, the classification is carried out by a support vector machine (SVM)-based multitask learning framework. The proposed approach is thus termed Gabor S4E and SVM-based multitask learning (GS4E-MTLSVM). A series of experiments is conducted on three real hyperspectral image data sets to demonstrate the effectiveness of the proposed GS4E-MTLSVM approach. The experimental results show that the performance of the proposed GS4E-MTLSVM is better than those of several state-of-the-art methods, while the computational complexity has been greatly reduced, compared with the pixel-based spatial-spectral Schroedinger eigenmaps method.","Hyperspectral imaging,
Feature extraction,
Support vector machines,
Data mining,
Computational complexity,
Training"
Perceptual Reduced-Reference Visual Quality Assessment for Contrast Alteration,"In image/video systems, contrast adjustment which manages to enhance visual quality is nowadays an important research topic. Yet very limited struggles have been made to the exploration of visual quality assessment for contrast adjustment. To tackle the issue, this paper proposes a novel reduced-reference (RR) quality metric with the integration of bottom-up and top-down strategies. The former one stems from the recently revealed free energy principle that tells that the human visual system seeks to comprehend an input image via uncertainty removal, while the latter one is toward using the symmetric Kullback-Leibler divergence to compare the histogram of the contrast-altered image with that of the pristine image. The bottom-up and top-down strategies are lastly incorporated to derive the RR contrast-altered image quality measure. A comparison using numerous existing IQA models is carried out on five contrast related databases/subsets in CID2013, CCID2014, CSIQ, TID2008, and TID2013, and experimental results validate the superiority of the proposed technique.","Visualization,
Databases,
Measurement,
Brain modeling,
Distortion,
Image quality,
Histograms"
Investigation of Mo/Ti/AlN/HfO2 High-k Metal Gate Stack for Low Power Consumption InGaAs NMOS Device Application,"Use of the Mo/Ti/AlN/HfO2 metal/dielectric stack to increase the permittivity of HfO2 for low power consumption InGaAs-based MOSFET is investigated in this letter. The dielectric constant of HfO2 was found to increase by 47%, from 17 to 25, after Ti doping without affecting the interface trap density around the mid-gap of the MOSCAPs. A strong inversion behavior with low leakage current for the MOSCAP was also observed. The gate voltage needed to tune the Fermi level of InGaAs channel was found to be smaller for the Ti-doped HfO2 sample as compared with the sample with un-doped HfO2. The increase of the dielectric constant of HfO2 after Ti doping combined with the use of Ti gate metal, which has the work function level near the conduction band edge of InGaAs, makes the proposed Mo/Ti/HfO2 (Ti) stack ideal for future lowpower consumption InGaAs-based NMOS applications.","Hafnium compounds,
Annealing,
Indium gallium arsenide,
Logic gates,
III-V semiconductor materials,
Passivation"
Fabrication of Side-Polished Single Mode-Multimode-Single Mode Fiber and Its Characteristics of Refractive Index Sensing,"This paper presents a low-cost, flexible, and highly efficient wheel polishing techniques for the fabrication of sidepolished single mode-multimode-single mode fiber (SP-SMSF). The evolution of transmission spectrum of SP-SMSF is measured, simulated, and discussed. The good linear relationship between polished depth (PD) and polish-induced loss has relatively high linear correlation at 95%, allowing us to monitor and control the critical parameter PD in line and in real time. Several desirable SPSMSF with PD = 9.6 , 15, 20.6 μm were fabricated successfully. Their characteristics of refractive index (RI) sensing are investigated experimentally. The results show that SP-SMS sensitivity increases as RI increases, approaching its maximum when the latter gets close to its core. The maximum sensitivity of the SP-SMSF with PD = 20.6 μm is 1190 nm/RIU, comparable to that of chemically etched SMSF. The dependence of the sensitivity on the PD of SP-SMSF is also measured and discussed, showing that an increase in PD can improve the sensitivity of SP-SMSF. In addition, such novel structure of SP-SMSF will provide a flat platform to implement various fiber devices.","Optical fibers,
Optical fiber sensors,
Optical fiber communication,
Sensitivity,
Fabrication"
Pallas: Self-Bootstrapping Fine-Grained Passive Indoor Localization Using WiFi Monitors,"Passive indoor localization for smartphones requires no explicit cooperation of the smartphone and enables a new spectrum of applications such as passive user tracking, mobility monitoring, social pattern analysis, etc. However, existing passive localization methods either achieve coarse-grained localization accuracy or require expensive infrastructure support. In this paper, we present Pallas, a self-bootstrapping system for fine-grained passive indoor localization using non-intrusive WiFi monitors. Pallas uses off-the-shelf access point hardware to opportunistically capture WiFi packets to infer the location of smartphones in the indoor environment. The key novelty of Pallas lies in that the passive fingerprint database for localization is automatically constructed and updated without any active participation of WiFi devices or manual calibration. To achieve this, Pallas first identifies passive landmarks that are present in WiFi RSS traces. Given the knowledge of the indoor floor plan and the location of WiFi monitors, Pallas statistically maps the collected RSS traces to specific indoor pathways. With sufficient mapping opportunistically detected, Pallas is able to bootstrap a fine-grained passive fingerprint database and build Gaussian processes for localization automatically without requiring any additional calibration effort.","IEEE 802.11 Standard,
Smart phones,
Monitoring,
Radar tracking,
Electronic mail,
Indoor environments,
Databases"
1.4 Quantum computing - the next challenge in circuit and system design,"Quantum computers have the potential to tackle problems in materials science, chemistry, and mathematics that are well beyond the reach of supercomputers. Their power derives from the use of quantum bits, which can exist in both 0 and 1 simultaneously, a so-called quantum superposition state. This leads to a computing power that doubles with every additional quantum bit. This paper will introduce the basic concepts behind quantum computing, summarize the state-of-the-art of solid-state implementations, and present the major open challenges in the realization of large-scale quantum circuits, including the design of dedicated classical control circuits and systems.","Quantum computing,
Quantum dots,
Logic gates,
Microwave circuits,
Josephson junctions,
Computers,
Couplings"
Droplet Size-Aware High-Level Synthesis for Micro-Electrode-Dot-Array Digital Microfluidic Biochips,"A digital microfluidic biochip (DMFB) is an attractive technology platform for automating laboratory procedures in biochemistry. In recent years, DMFBs based on a microelectrode-dot-array (MEDA) architecture have been demonstrated. However, due to the inherent differences between today's DMFBs and MEDA, existing synthesis solutions for biochemistry mapping cannot be utilized for MEDA biochips. We present the first synthesis approach that can be used for MEDA biochips. We first present a general analytical model for droplet velocity and validate it experimentally using a fabricated MEDA biochip. We then present the proposed synthesis method targeting reservoir placement, operation scheduling, module placement, routing of droplets of various sizes, and diagonal movement of droplets in a two-dimensional array. Simulation results using benchmarks and experimental results using a fabricated MEDA biochip demonstrate the effectiveness of the proposed synthesis technique.",
The Reorganization of Human Brain Networks Modulated by Driving Mental Fatigue,"The organization of the brain functional network is associated with mental fatigue, but little is known about the brain network topology that is modulated by the mental fatigue. In this study, we used the graph theory approach to investigate reconfiguration changes in functional networks of different electroen-cephalography (EEG) bands from 16 subjects performing a simulated driving task. Behavior and brain functional networks were compared between the normal and driving mental fatigue states. The scores of subjective self-reports indicated that 90 min of simulated driving-induced mental fatigue. We observed that coherence was significantly increased in the frontal, central, and temporal brain regions. Furthermore, in the brain network topology metric, significant increases were observed in the clustering coefficient (Cp) for beta, alpha, and delta bands and the character path length (Lp) for all EEG bands. The normalized measures γ showed significant increases in beta, alpha, and delta bands, and λ showed similar patterns in beta and theta bands. These results indicate that functional network topology can shift the network topology structure toward a more economic but less efficient configuration, which suggests low wiring costs in functional networks and disruption of the effective interactions between and across cortical regions during mental fatigue states. Graph theory analysis might be a useful tool for further understanding the neural mechanisms of driving mental fatigue.","Fatigue,
Electroencephalography,
Physiology,
Electrodes,
Network topology,
Informatics"
Statistical error analysis for low power approximate adders,"Low-power approximate adders provide basic building blocks for approximate computing hardware that have shown remarkable energy efficiency for error-resilient applications (like image/video processing, computer vision, etc.), especially for battery-driven portable systems. In this paper, we present a novel scalable, fast yet accurate analytical method to evaluate the output error probability of multi-bit low power adders for a predetermined probability of input bits. Our method recursively computes the error probability by considering the accurate cases only, which are considerably smaller than the erroneous ones. Our method can handle the error analysis of a wider-range of adders with negligible computational overhead. To ensure its rapid adoption in industry and academia, we have open-sourced our LabVIEW and MATLAB libraries.","Adders,
Error probability,
Gears,
Error analysis,
Approximate computing,
Complexity theory,
Mathematical model"
"Cost Effective, Reliable and Secure Workflow Deployment over Federated Clouds","The significant growth in cloud computing has led to increasing number of cloud providers, each offering their service under different conditions – one might be more secure whilst another might be less expensive or more reliable. At the same time user applications have become more and more complex. Often, they consist of a diverse collection of software components, and need to handle variable workloads, which poses different requirements on the infrastructure. Therefore, many organisations are considering using a combination of different clouds to satisfy these needs. It raises, however, a non-trivial issue of how to select the best combination of clouds to meet the application requirements. This paper presents a novel algorithm to deploy workflow applications on federated clouds. First, we introduce an entropy-based method to quantify the most reliable workflow deployments. Second, we apply an extension of the Bell-LaPadula Multi-Level security model to address application security requirements. Finally, we optimise deployment in terms of its entropy and also its monetary cost, taking into account the cost of computing power, data storage and inter-cloud communication. We implemented our new approach and compared it against two existing scheduling algorithms: Extended Dynamic Constraint Algorithm (EDCA) and Extended Biobjective dynamic level scheduling (EBDLS). We show that our algorithm can find deployments that are of equivalent reliability but are less expensive and meet security requirements. We have validated our solution through a set of realistic scientific workflows, using well-known cloud simulation tools (WorkflowSim and DynamicCloudSim) and a realistic cloud based data analysis system (e-Science Central).","Cloud computing,
Reliability,
Computer security,
Computational modeling,
Entropy,
Heuristic algorithms,
Data models,
Scheduling"
Blockwise Human Brain Network Visual Comparison Using NodeTrix Representation,"Visually comparing human brain networks from multiple population groups serves as an important task in the field of brain connectomics. The commonly used brain network representation, consisting of nodes and edges, may not be able to reveal the most compelling network differences when the reconstructed networks are dense and homogeneous. In this paper, we leveraged the block information on the Region Of Interest (ROI) based brain networks and studied the problem of blockwise brain network visual comparison. An integrated visual analytics framework was proposed. In the first stage, a two-level ROI block hierarchy was detected by optimizing the anatomical structure and the predictive comparison performance simultaneously. In the second stage, the NodeTrix representation was adopted and customized to visualize the brain network with block information. We conducted controlled user experiments and case studies to evaluate our proposed solution. Results indicated that our visual analytics method outperformed the commonly used node-link graph and adjacency matrix design in the blockwise network comparison tasks. We have shown compelling findings from two real-world brain network data sets, which are consistent with the prior connectomics studies.","Diffusion tensor imaging,
Data visualization,
Visual analytics,
Diseases,
Sociology"
"Uncertainty Marginal Price, Transmission Reserve, and Day-Ahead Market Clearing With Robust Unit Commitment","The increasing penetration of renewable energy in recent years has led to more uncertainties in power systems. These uncertainties have to be accommodated by flexible resources (i.e., upward and downward generation reserves). In this paper, a novel concept, Uncertainty Marginal Price (UMP), is proposed to price both the uncertainty and generation reserve. At the same time, the energy is priced at Locational Marginal Price (LMP). A novel market clearing mechanism is proposed to credit the generation and reserve and to charge the load and uncertainty within the robust unit commitment in the day-ahead market. We derive the UMPs and LMPs in the robust optimization framework. UMP helps allocate the cost of generation reserves to uncertainty sources. We prove that the proposed market clearing mechanism leads to partial market equilibrium. We find that transmission reserves must be kept explicitly in addition to generation reserves for uncertainty accommodation. We prove that transmission reserves for ramping delivery may lead to Financial Transmission Right (FTR) underfunding in existing markets. The FTR underfunding can be covered by congestion fund collected from uncertainty payment in the proposed market clearing mechanism. Simulations on a six-bus system and the IEEE 118-bus system are performed to illustrate the new concepts and the market clearing mechanism.","Uncertainty,
Robustness,
Optimization,
Pricing,
Indexes,
Generators,
Renewable energy sources"
The Impact of Scent Type on Olfaction-Enhanced Multimedia Quality of Experience,"In the quest to increase user perceived quality of experience (QoE), the classic audio-visual content paradigm can be extended to include media components that stimulate other human senses. Among these, olfaction-enhanced multimedia has attracted significant attention, as it is both attractive from user point of view and challenging from research perspective. This paper presents the results of two subjective studies which analyzed user QoE of olfaction-enhanced multimedia. Diverse scent types and video content were considered. In particular, QoE levels were studied when one and two olfaction stimuli enhanced audiovisual media. The results presented show that scent type influences user QoE. Statistically significant differences between pleasant and unpleasant scent types existed. Also, in certain cases, users were prepared to forgive the presence of unpleasant scent types with respect to QoE. Finally, users reported a clear preference for olfaction presented after the video sequence with which the olfaction effect should be synchronized, as opposed to before the video sequence.","Olfactory,
Media,
Synchronization,
Multimedia communication,
Streaming media,
Testing,
Quality of service"
A Femto-Aided Location Tracking Algorithm in LTE-A Heterogeneous Networks,"In dense urban or indoor environments under a weak global positioning system (GPS) signal, the Long-Term Evolution Advanced (LTE-A) system can provide range measurements for location estimation of mobile stations (MSs). Based on the reference signals transmitted from macro base stations (mBSs), femto BS (fBSs), and neighbor MSs in LTE-A heterogeneous networks (HetNets), the femto-aided cooperative location tracking (FACLT) algorithm is proposed to estimate an MS's position. Since fBSs are user-deployed in the residential or business buildings, the locations of fBSs are usually not known exactly. Moreover, an MS can communicate with its neighbor MSs with the support of device-to-device (D2D) communications. To deal with the uncertain neighbor MSs' positions and the imprecise fBSs' positions, we utilize a Bayesian framework to investigate a distributed cooperative location tracking problem and a particle filter (PF) to develop the FACLT algorithm. Different femto-aided strategies are adopted to deal with the uncertainty of fBS position. The utilization of the PF not only allows the fusion of time difference of arrival (TDOA) and two-way time of arrival (TW-TOA) measurements but enables the line-of-sight (LOS)/non-LOS (NLOS) condition as well, based on the information of the Markov model or indoor map. Performance evaluation is conducted based on the system-level simulation of LTE-A HetNet environments, where the proposed FACLT algorithm using the assistive fBSs and cooperative MSs provides better location tracking of MSs.","Estimation,
Uncertainty,
Synchronization,
Position measurement,
Global Positioning System,
Computer architecture"
Dual-Electrical-Port Control of Cascaded Doubly-Fed Induction Machine for EV/HEV Applications,"This paper presents a dual-electrical-port control scheme for four-quadrant operation of cascaded doubly-fed induction machine (CDFIM), which has conventionally been used as a variable-speed drive or variable-speed constant-frequency generator for limited-speed-range applications. The proposed control method enables the synchronous control of both power winding (PW) and control winding (CW) currents, and as a consequence, not only the control complexity but also the rotor slip frequency and related core losses are significantly reduced in comparison with the previously proposed single-electrical-port control scheme. It is for the first time revealed that the CDFIM drive that indirectly couples PW and CW through induction behavior can be readily controlled like a conventional induction motor to achieve the highest torque density. The torque density-speed region of the CDFIM falls within that of the power machine in singly-fed operation mode, and only a half of that of the power machine in doubly-fed operation mode, which shows the urgent need for torque density enhancement of brushless doubly-fed machines for electric vehicle/hybrid electric vehicle applications. Computer simulations and experiments are implemented to verify the dynamic performance of the proposed control method.","Rotors,
Torque,
Stator windings,
Frequency control,
Windings,
Induction machines"
Resilient IoT Architectures Over Dynamic Sensor Networks With Adaptive Components,"As competing industries delve into the Internet of Things (IoT), a growing challenge of interoperability and redundant deployments is magnified. Specifically, as we augment more “things” in the IoT fabric, how will these components interact across their heterogeneity, let alone collaborate. In this paper, we address the core issue of component interaction and operation under the IoT umbrella. We present our contribution in the framework of wireless sensor networks (WSNs), as a founding block in the IoT. More importantly, we present a novel paradigm in the design of WSNs, to build a resilient architecture that decouples operational mandates from the nodes. We abstract IoT things as wirelessly interfaced components, which introduce functionality physically decoupled from their devices; boosting resilience, dynamicity, and resource utilization. This approach dissects the study of any IoT nodal capacity to its “connected” components, and empowers dynamic associativity between things to serve varying functional requirements and levels. It also enables reintroducing only the components required to suffice for network operation, or only those needed to meet a new requirement. More importantly, critical resources in the network will be shared within their neighborhoods. Thus network lifetime will relate to functional cliques of dynamic IoT nodes, rather than individual networks. We evaluate the cost effectiveness and resilience of our paradigm via simulations.","Internet of Things,
open systems,
wireless sensor networks"
Frame Structure Design and Analysis for Millimeter Wave Cellular Systems,"The millimeter-wave (mmWave) frequencies have attracted considerable attention for fifth generation (5G) cellular communication as they offer orders of magnitude greater bandwidth than current systems. However, the medium access control (MAC) layer may need to be significantly redesigned to support the highly directional transmissions, and the demand for ultra-low latencies and high peak rates expected in mmWave communication. To address these challenges, we present a novel mmWave MAC layer frame structure with a number of enhancements, including flexible, highly granular transmission times, dynamic control signal locations, extended messaging, and the ability to efficiently multiplex directional control signals. Analytic formulas are derived for the utilization and control overhead as a function of control periodicity, number of users, traffic statistics, signal-to-noise ratio, and antenna gains. Importantly, the analysis can incorporate various front-end MIMO capability assumptions-a critical feature of mmWave. Under realistic system and traffic assumptions, the analysis reveals that the proposed flexible frame structure design offers significant benefits over designs with fixed frame structures similar to current 4G long-term evolution. It is also shown that the fully digital beamforming architectures offer significantly lower overhead compared with analog and hybrid beamforming under equivalent power budgets.","Array signal processing,
Analog-digital conversion,
Long Term Evolution,
Computer architecture,
Wireless communication,
Antennas,
MIMO"
Physical Layer Security Jamming: Theoretical Limits and Practical Designs in Wireless Networks,"Physical layer security has been recently recognized as a promising new design paradigm to provide security in wireless networks. In addition to the existing conventional cryptographic methods, physical layer security exploits the dynamics of fading channels to enhance secured wireless links. In this approach, jamming plays a key role by generating noise signals to confuse the potential eavesdroppers, and significantly improves quality and reliability of secure communications between legitimate terminals. This article presents theoretical limits and practical designs of jamming approaches for physical layer security. In particular, the theoretical limits explore the achievable secrecy rates of user cooperation-based jamming whilst the centralized and game theoretic-based precoding techniques are reviewed for practical implementations. In addition, the emerging wireless energy harvesting techniques are exploited to harvest the required energy to transmit jamming signals. Future directions of these approaches and the associated research challenges are also briefly outlined.","Jamming,
Noise measurement,
Interference,
Wireless communication,
Receivers,
Encoding,
Physical layer"
Scientific Workflow Clustering and Recommendation Leveraging Layer Hierarchical Analysis,"This article proposes an approach for identifying and recommending scientific workflows for reuse and repurposing. Specifically, a scientific workflow is represented as a layer hierarchy, which specifies hierarchical relations between this workflow, its subworkflows, and activities. Semantic similarity is calculated between layer hierarchies of workflows. A graphskeleton based clustering technique is adopted for grouping layer hierarchies into clusters. Barycenters in each cluster are identified, which refer to core workflows in this cluster, for facilitating cluster identification and workflow ranking and recommendation. Experimental evaluation shows that our technique is efficient and accurate on ranking and recommending appropriate clusters and scientific workflows with respect to specific requirements of scientific experiments.",
Capacity of Gaussian Many-Access Channels,"Classical multiuser information theory studies the fundamental limits of models with a fixed (often small) number of users as the coding blocklength goes to infinity. This paper proposes a new paradigm, referred to as many-user information theory, where the number of users is allowed to grow with the blocklength. This paradigm is motivated by emerging systems with a massive number of users in an area, such as the Internet of Things. The focus of this paper is the many-access channel model, which consists of a single receiver and many transmitters, whose number increases unboundedly with the blocklength. Moreover, an unknown subset of transmitters may transmit in a given block and need to be identified as well as decoded by the receiver. A new notion of capacity is introduced and characterized for the Gaussian many-access channel with random user activities. The capacity can be achieved by first detecting the set of active users and then decoding their messages. The minimum cost of identifying the active users is also quantified.",
Bilevel Feature Extraction-Based Text Mining for Fault Diagnosis of Railway Systems,"A vast amount of text data is recorded in the forms of repair verbatim in railway maintenance sectors. Efficient text mining of such maintenance data plays an important role in detecting anomalies and improving fault diagnosis efficiency. However, unstructured verbatim, high-dimensional data, and imbalanced fault class distribution pose challenges for feature selections and fault diagnosis. We propose a bilevel feature extraction-based text mining that integrates features extracted at both syntax and semantic levels with the aim to improve the fault classification performance. We first perform an improved X2 statistics-based feature selection at the syntax level to overcome the learning difficulty caused by an imbalanced data set. Then, we perform a prior latent Dirichlet allocation-based feature selection at the semantic level to reduce the data set into a low-dimensional topic space. Finally, we fuse fault features derived from both syntax and semantic levels via serial fusion. The proposed method uses fault features at different levels and enhances the precision of fault diagnosis for all fault classes, particularly minority ones. Its performance has been validated by using a railway maintenance data set collected from 2008 to 2014 by a railway corporation. It outperforms traditional approaches.","Feature extraction,
Maintenance engineering,
Rail transportation,
Syntactics,
Fault diagnosis,
Semantics,
Text mining"
My Privacy My Decision: Control of Photo Sharing on Online Social Networks,"Photo sharing is an attractive feature which popularizes online social networks (OSNs). Unfortunately, it may leak users' privacy if they are allowed to post, comment, and tag a photo freely. In this paper, we attempt to address this issue and study the scenario when a user shares a photo containing individuals other than himself/herself (termed co-photo for short). To prevent possible privacy leakage of a photo, we design a mechanism to enable each individual in a photo be aware of the posting activity and participate in the decision making on the photo posting. For this purpose, we need an efficient facial recognition (FR) system that can recognize everyone in the photo. However, more demanding privacy setting may limit the number of the photos publicly available to train the FR system. To deal with this dilemma, our mechanism attempts to utilize users' private photos to design a personalized FR system specifically trained to differentiate possible photo co-owners without leaking their privacy. We also develop a distributed consensus-based method to reduce the computational complexity and protect the private training set. We show that our system is superior to other possible approaches in terms of recognition ratio and efficiency. Our mechanism is implemented as a proof of concept Android application on Facebook's platform.",
The Recognition and Control of Nonideal Soft-Switching Frequency for Wireless Power Transfer System Based on Waveform Identification,"Nonideal frequency problems can occur in a wireless power transfer system due to multiple soft-switching frequencies and frequency bifurcation. To make the system work at an ideal frequency with high-power transfer capability and efficiency, a method based on waveform identification is proposed. First, the space state model of a SP type WPT system is built, and the waveforms at ideal and nonideal working frequencies are obtained based on the stroboscopic mapping theory. Second, according to the characteristics of these waveforms, the swing door algorithm is improved by waveform distortion rate and fast Fourier transformation, which is used to recognize nonideal waveforms. Then, a control strategy based on “online self-determined optimization” is proposed to deal with the problem. Finally, the results of simulation and experiments show that the method proposed in this paper can identify the waveforms at nonideal frequency and find an ideal working frequency for the WPT system.","Resonant frequency,
Soft switching,
Capacitors,
Electromagnetic interference,
Inverters,
Inductance"
Robust Matrix Discriminative Analysis for Feature Extraction From Hyperspectral Images,"Linear discriminative analysis (LDA) is an effective feature extraction method for hyperspectral image (HSI) classification. Most of the existing LDA-related methods are based on spectral features, ignoring spatial information. Recently, a matrix discriminative analysis (MDA) model has been proposed to incorporate the spatial information into the LDA. However, due to sensor interferers, calibration errors, and other issues, HSIs can be noisy. These corrupted data easily degrade the performance of the MDA. In this paper, a robust MDA (RMDA) model is proposed to address this important issue. Specifically, based on the prior knowledge that the pixels in a small spatial neighborhood of the HSI lie in a low-rank subspace, a denoising model is first employed to recover the intrinsic components from the noisy HSI. Then, the MDA model is used to extract discriminative spatial-spectral features from the recovered components. Besides, different HSIs exhibit different spatial contextual structures, and even a single HSI may contain both large and small homogeneous regions simultaneously. To sufficiently describe these multiscale spatial structures, a multiscale RMDA model is further proposed. Experiments have been conducted using three widely used HSIs, and the obtained results show that the proposed method allows for a significant improvement in the classification performance when compared to other LDA-based methods.","Feature extraction,
Robustness,
Hyperspectral imaging,
Matrix decomposition,
Noise measurement,
Iron"
A Visual Analytics Approach for Categorical Joint Distribution Reconstruction from Marginal Projections,"Oftentimes multivariate data are not available as sets of equally multivariate tuples, but only as sets of projections into subspaces spanned by subsets of these attributes. For example, one may find data with five attributes stored in six tables of two attributes each, instead of a single table of five attributes. This prohibits the visualization of these data with standard high-dimensional methods, such as parallel coordinates or MDS, and there is hence the need to reconstruct the full multivariate (joint) distribution from these marginal ones. Most of the existing methods designed for this purpose use an iterative procedure to estimate the joint distribution. With insufficient marginal distributions and domain knowledge, they lead to results whose joint errors can be large. Moreover, enforcing smoothness for regularizations in the joint space is not applicable if the attributes are not numerical but categorical. We propose a visual analytics approach that integrates both anecdotal data and human experts to iteratively narrow down a large set of plausible solutions. The solution space is populated using a Monte Carlo procedure which uniformly samples the solution space. A level-of-detail high dimensional visualization system helps the user understand the patterns and the uncertainties. Constraints that narrow the solution space can then be added by the user interactively during the iterative exploration, and eventually a subset of solutions with narrow uncertainty intervals emerges.","Uncertainty,
Image reconstruction,
Diseases,
Visual analytics,
Iterative methods,
Two dimensional displays"
A High-Accuracy Wind Power Forecasting Model,"In this letter, a forecasting model consisting of the Gaussian process with a novel composite covariance function for high-accuracy wind power forecasting is presented. The proposed composite covariance function is based on the exploration of joint effects between numerical weather prediction features. The performance of the proposed forecasting model is evaluated using the 2012 global energy forecasting competition wind power forecasting data, and the proposed model outperforms all of the competitors.","Forecasting,
Predictive models,
Wind power generation,
Wind farms,
Wind speed,
Numerical models,
Training"
Current Status and Opportunities of Organic Thin-Film Transistor Technologies,"Attributed to its advantages of super mechanical flexibility, very low-temperature processing, and compatibility with low cost and high throughput manufacturing, organic thin-film transistor (OTFT) technology is able to bring electrical, mechanical, and industrial benefits to a wide range of new applications by activating nonflat surfaces with flexible displays, sensors, and other electronic functions. Despite both strong application demand and these significant technological advances, there is still a gap to be filled for OTFT technology to be widely commercially adopted. This paper provides a comprehensive review of the current status of OTFT technologies ranging from material, device, process, and integration, to design and system applications, and clarifies the real challenges behind to be addressed.","Organic thin film transistors,
Dielectrics,
Polymers,
Manufacturing,
Logic gates,
Sensors"
Sampling and Exact Reconstruction of Pulses with Variable Width,"Recent sampling results enable the reconstruction of signals composed of streams of fixed-shaped pulses. These results have found applications in topics as varied as channel estimation, biomedical imaging and radio astronomy. However, in many real signals, the pulse shapes vary throughout the signal. In this paper, we show how to sample and perfectly reconstruct Lorentzian pulses with variable width. In the noiseless case, perfect recovery is guaranteed by a set of theorems. In addition, we verify that our algorithm is robust to model mismatch and noise. This allows us to apply the technique to two practical applications: electrocardiogram (ECG) compression and bidirectional reflectance distribution function (BRDF) sampling. ECG signals are one dimensional, but the BRDF is a higher dimensional signal, which is more naturally expressed in a spherical coordinate system; this motivated us to extend the theory to the 2D and spherical cases. Experiments on real data demonstrate the viability of the proposed model for ECG acquisition and compression, as well as the efficient representation and low-rate sampling of specular BRDFs.","Electrocardiography,
Technological innovation,
Fourier series,
Shape,
Image reconstruction,
Kernel,
Streaming media"
Game Theoretic Study on Channel-Based Authentication in MIMO Systems,"In this paper, we investigate the authentication based on radio channel information in multiple-input multiple-output (MIMO) systems and formulate the interactions between a receiver with multiple antennas and a spoofing node as a zero-sum physical (PHY)-layer authentication game. In this game, the receiver chooses the test threshold of the hypothesis test to maximize its Bayesian risk-based utility in the spoofing detection, while the adversary chooses its attack rate, i.e., how often a spoofing signal is sent. We derive the Nash equilibrium (NE) of the static PHY-layer authentication game and present the condition that the NE exists, showing that both the spoofing detection error rates and the spoofing rate decrease with the number of transmit and receive antennas. We propose a PHY-layer spoofing detection algorithm for MIMO systems based on Q-learning, in which the receiver applies the reinforcement learning technique to achieve the optimal test threshold via trials in a dynamic game without knowing the system parameters, such as the channel time variation and spoofing cost. We also use Dyna architecture and prioritized sweeping (Dyna-PS) to improve the spoofing detection in time-variant radio environments. The proposed authentication algorithms are implemented over universal software radio peripherals and evaluated via experiments in an indoor environment. Experimental results show that the Dyna-PS-based spoofing detection algorithm further reduces the spoofing detection error rates and increases the utility of the receiver compared with the Q-learning-based algorithm, and both performances improve with more number of transmit or receive antennas.","Games,
Authentication,
MIMO,
Receiving antennas,
Game theory,
Channel estimation"
Coupling-Inductor-Based Hybrid mm-Wave CMOS SPST Switch,"This brief presents a hybrid CMOS millimeter-wave single-pole single-throw (SPST) switch. This newly invented hybrid structure demonstrates better tradeoffs between insertion loss and isolation compared to conventional distributed structures. The performance benefits are analyzed in detail and validated by both simulation and measurement results. Additionally, the chip area is conserved by using lump elements, the coupled inductor. Moreover, a specific bias scheme is used to further decrease insertion loss by about 0.5 dB. This SPST switch achieves higher than 35-dB isolation over an ultrawide frequency range, from 54 to 84 GHz, a minimum 1.7-dB insertion loss, and <;-10-dB reflection coefficient with 0.012-mm2 chip area in 65-nm CMOS. The design achieves more than 10-dB enhancement of isolation in comparison with the state-of-the-arts while maintaining similar insertion loss.","Switching circuits,
Transistors,
Insertion loss,
Inductors,
Switches,
Couplings,
Shunts (electrical)"
Enabling Focus Cues in Head-Mounted Displays,"Developing head-mounted displays (HMDs) that offer uncompromised optical pathways to both digital and physical worlds without encumbrance and discomfort confronts many grand challenges, both from technological perspectives and human factors. Among the many challenges, minimizing visual discomfort is one of the key obstacles. One of the key contributing factors to visual discomfort is the lack of the ability to render proper focus cues in HMDs to stimulate natural eye accommodation responses, which leads to the wellknown problem of vergence-accommodation conflict. This paper provides a comprehensive summary of various technical approaches toward enabling focus cues in HMDs for both virtual reality (VR) and augmented reality (AR) applications.","Visualization,
Stereo image processing,
Retina,
Optical imaging,
Convergence,
Three-dimensional displays,
Adaptive optics,
Augmented reality,
Virtual reality"
Exploring Connected Dominating Sets in Energy Harvest Networks,"Duty-cycle scheduling is an effective way to balance energy consumptions and prolong network lifetime of wireless sensor networks (WSNs), which usually requires a connected dominating set (CDS) to guarantee network connectivity and coverage. Therefore, the problem of finding the largest number of CDSs is important for WSNs. The previous works always assume all the nodes are non-rechargeable. However, WSNs are now taking advantages of rechargeable nodes to become energy harvest networks (EHNs). To find the largest number of CDSs then becomes completely different. This is the first work to investigate, how to identify the largest number of CDSs in EHNs to prolong network lifetime. The investigated novel problems are proved to be NP-Complete and we propose four approximate algorithms, accordingly. Both the solid theoretical analysis and the extensive simulations are performed to evaluate our algorithms.","Wireless sensor networks,
Approximation algorithms,
Energy harvesting,
Distributed algorithms,
Energy consumption,
Algorithm design and analysis,
IEEE transactions"
A Cloud-Based Trust Management Framework for Vehicular Social Networks,"The mobile industry's evolution from 4G to 5G will lead to a deep progress on mobile applications that are widely used in some new environments, such as vehicular social networks (VSNs). In VSNs, which are considered the first automobile social networks, vehicular communication can facilitate large-scale data sharing between drivers and their neighbours. However, malicious users of VSNs can also disseminate false information over the network. Traditional public key infrastructure (PKI) cannot recognize these malicious users, as they all have authorized identities. Thus, a trust management mechanism is introduced to secure vehicular social data. This paper demonstrates a high-level trust management model and its deployment scheme based on a vehicular cloud system. We propose a layered trust management mechanism that benefits from efficient use of physical resources (e.g., computing, storage, communication cost) and explore its deployment in a VSN scenario based on a three-layer cloud computing architecture. Moreover, performance modeling of the proposed trust management scheme is conducted through a novel formal compositional approach - Performance Evaluation Process Algebra (PEPA). PEPA has superior features in compositionality and parsimony, which means that it can efficiently model systems with layered architectures and complex behaviours. PEPA also supports various numerical analyses through calculating its underlying continuous time Markov chains (CTMCs) directly or solving a set of approximated ordinary differential equations (ODEs). According to analysis outcomes, we analyzed several key performance properties of the scheme and related capacity issues in deployment. The findings also reveal an efficient investigation approach for evaluating the performances of trust models.","Cloud computing,
Computer architecture,
Social network services,
Computational modeling,
Vehicles,
Vehicular ad hoc networks,
Roads"
Distributed Continuous-Time Algorithm for Constrained Convex Optimizations via Nonsmooth Analysis Approach,"This technical note studies the distributed optimization problem of a sum of nonsmooth convex cost functions with local constraints. At first, we propose a novel distributed continuous-time projected algorithm, in which each agent knows its local cost function and local constraint set, for the constrained optimization problem. Then we prove that all the agents of the algorithm can find the same optimal solution, and meanwhile, keep the states bounded while seeking the optimal solutions. We conduct a complete convergence analysis by employing nonsmooth Lyapunov functions for the stability analysis of differential inclusions. Finally, we provide a numerical example for illustration.","Algorithm design and analysis,
Cost function,
Convergence,
Stability analysis,
Heuristic algorithms,
Laplace equations"
Relation Between Combinations of Personal Characteristic Types and Educational Effectiveness for a Controlled Project-Based Learning Course,"To improve practical IT education, many Japanese universities are implementing project-based learning (PBL). Although a previous study examined the relationship between educational effectiveness and the scatter of personal characteristics, the relationship between educational effectiveness and the combination of personal characteristics in a team, which is important to optimize the team composition for PBL, has yet to be examined. Herein, we use the five factor and stress theory to measure personal characteristics and classify students enrolled in a PBL class at Waseda University into four types-leadership, management, tugboat, and anchor. Then, knowledge and skills questionnaires are used to measure educational effectiveness. The results show that educational effectiveness is highest when a team consists of management and anchor types without leadership types. The results are preliminary, because the practical usefulness of our results is limited as the experiment of the paper targeted only one PBL course of one university. For that reason, we need to collect data from other PBL course at the same or other university.","Business,
Teamwork,
Education,
Stress,
Software,
Engineering profession,
Planning"
A Probabilistic Distance-Based Modeling and Analysis for Cellular Networks With Underlaying Device-to-Device Communications,"Device-to-device (D2D) communications in cellular networks are promising technologies for improving network performance. However, they may cause severe intra/inter-cell interference that can considerably degrade the performance of cellular users, and vice versa. Therefore, interference analysis has been one of the most important research topics in such a system. Focusing on an uplink resource reusing scenario, this paper presents a framework based on a probabilistic distance and path-loss model to obtain the distributions of signal, interference, and further Signal-to-Interference-plus-Noise Ratio (SINR), based on which, the performance metrics that are functions of SINR can be analyzed, such as outage probability and capacity. Different from the previous work, this proposed framework: 1) obtains interference and SINR distributions for both cellular and D2D communications, through which insights into their performance metrics and mutual influence are provided and 2) has no limitations on cell shapes, except that they are approximated by polygons or circles. The framework can also be applied to a downlink reusing scenario. Our results indicate that the developed framework is helpful for network planners to effectively tune the network parameters, and thus to achieve the optimum system performance for both cellular and D2D communications.","Device-to-device communication,
Interference,
Uplink,
Cellular networks,
Signal to noise ratio,
Analytical models,
Downlink"
Deeply Learned View-Invariant Features for Cross-View Action Recognition,"Classifying human actions from varied views is challenging due to huge data variations in different views. The key to this problem is to learn discriminative view-invariant features robust to view variations. In this paper, we address this problem by learning view-specific and view-shared features using novel deep models. View-specific features capture unique dynamics of each view while view-shared features encode common patterns across views. A novel sample-affinity matrix is introduced in learning shared features, which accurately balances information transfer within the samples from multiple views and limits the transfer across samples. This allows us to learn more discriminative shared features robust to view variations. In addition, the incoherence between the two types of features is encouraged to reduce information redundancy and exploit discriminative information in them separately. The discriminative power of the learned features is further improved by encouraging features in the same categories to be geometrically closer. Robust view-invariant features are finally learned by stacking several layers of features. Experimental results on three multi-view data sets show that our approaches outperform the state-of-the-art approaches.","Cameras,
Sensor phenomena and characterization,
Robustness,
Magnetic sensors,
Feature extraction,
Magnetometers"
Multi-objective Reliability-Redundancy Allocation Problem with Interval Type-2 Fuzzy Uncertainty,"The Multi-objective reliability-redundancy allocation problem (MORRAP) aims to ensure high system reliability in the presence of optimally redundant components. This is one of the most important design considerations for system designers. Due to the associated uncertainty in component parameters, precise computations of overall system reliability, cost, and weight, etc. are difficult during design time. Hence, these parameters are befitting to be modeled as fuzzy quantities. As type-1 fuzzy numbers have limitations in representing higher order uncertainties, so this paper models the component parameters viz. reliability, cost, and weight with interval type-2 fuzzy numbers (IT2 FNs). Thus, we propose a novel formulation of MORRAP, termed as interval type-2 fuzzy multi-objective optimization problem (IT2FMORRAP). A popular multi-objective evolutionary algorithm, viz. non-dominated sorting genetic algorithm-II, is used to solve the proposed IT2FMORRAP, for which we have developed two novel algorithms in this paper. Numerical examples are included to demonstrate the solution approach. On comparing the outcomes with earlier results, we have found that the proposed IT2FMORRAP outperforms classical as well as other type-1 fuzzy number based approaches.","Reliability,
Uncertainty,
Fuzzy sets,
Frequency selective surfaces,
Fuzzy logic,
Resource management,
Analytical models"
Transient Analysis of Dispersive Power-Ground Plate Pairs With Arbitrarily Shaped Antipads by the DGTD Method With Wave Port Excitation,"A discontinuous Galerkin time-domain (DGTD) method analyzing signal/power integrity on multilayered power-ground parallel plate pairs is proposed. The excitation is realized by introducing wave ports on the antipads where electric/magnetic current sources are represented in terms of the eigenmodes of the antipads. Since closed-forms solutions do not exist for the eigenmodes of the arbitrarily shaped antipads, they have to be calculated using numerical schemes. Spatial orthogonality of the eigenmodes permits determination of each mode's temporal expansion coefficient by integrating the product of the electric field and the mode over the wave port. The temporal mode coefficients are then Fourier transformed to accurately calculate the S-parameters corresponding to different modes. Additionally, to generalize the DGTD to manipulate dispersive media, the auxiliary differential equation method is employed. This is done by introducing a time-dependent polarization volume current as an auxiliary unknown and the constitutive relation between this current and the electric field as an auxiliary equation. Consequently, computationally expensive temporal convolution is avoided. Various numerical examples, which demonstrate the applicability, robustness, and accuracy of the proposed method, are presented.",
"Effects of Grip-Force, Contact, and Acceleration Feedback on a Teleoperated Pick-and-Place Task","The multifaceted human sense of touch is fundamental to direct manipulation, but technical challenges prevent most teleoperation systems from providing even a single modality of haptic feedback, such as force feedback. This paper postulates that ungrounded grip-force, fingertip-contact-and-pressure, and high-frequency acceleration haptic feedback will improve human performance of a teleoperated pick-and-place task. Thirty subjects used a teleoperation system consisting of a haptic device worn on the subject's right hand, a remote PR2 humanoid robot, and a Vicon motion capture system to move an object to a target location. Each subject completed the pick-and-place task 10 times under each of the eight haptic conditions obtained by turning on and off grip-force feedback, contact feedback, and acceleration feedback. To understand how object stiffness affects the utility of the feedback, half of the subjects completed the task with a flexible plastic cup, and the others used a rigid plastic block. The results indicate that the addition of grip-force feedback with gain switching enables subjects to hold both the flexible and rigid objects more stably, and it also allowed subjects who manipulated the rigid block to hold the object more delicately and to better control the motion of the remote robot's hand. Contact feedback improved the ability of subjects who manipulated the flexible cup to move the robot's arm in space, but it deteriorated this ability for subjects who manipulated the rigid block. Contact feedback also caused subjects to hold the flexible cup less stably, but the rigid block more securely. Finally, adding acceleration feedback slightly improved the subject's performance when setting the object down, as originally hypothesized; interestingly, it also allowed subjects to feel vibrations produced by the robot's motion, causing them to be more careful when completing the task. This study supports the utility of grip-force and high-frequency acceleration feedback in teleoperation systems and motivates further improvements to fingertip-contact-and-pressure feedback.","Robot sensing systems,
Force,
Acceleration,
Force feedback,
Grippers"
Robust Transfer Metric Learning for Image Classification,"Metric learning has attracted increasing attention due to its critical role in image analysis and classification. Conventional metric learning always assumes that the training and test data are sampled from the same or similar distribution. However, to build an effective distance metric, we need abundant supervised knowledge (i.e., side/label information), which is generally inaccessible in practice, because of the expensive labeling cost. In this paper, we develop a robust transfer metric learning (RTML) framework to effectively assist the unlabeled target learning by transferring the knowledge from the well-labeled source domain. Specifically, RTML exploits knowledge transfer to mitigate the domain shift in two directions, i.e., sample space and feature space. In the sample space, domain-wise and class-wise adaption schemes are adopted to bridge the gap of marginal and conditional distribution disparities across two domains. In the feature space, our metric is built in a marginalized denoising fashion and low-rank constraint, which make it more robust to tackle noisy data in reality. Furthermore, we design an explicit rank constraint regularizer to replace the rank minimization NP-hard problem to guide the low-rank metric learning. Experimental results on several standard benchmarks demonstrate the effectiveness of our proposed RTML by comparing it with the state-of-the-art transfer learning and metric learning algorithms.",
Understanding Mobile Traffic Patterns of Large Scale Cellular Towers in Urban Environment,"Understanding mobile traffic patterns of large scale cellular towers in urban environment is extremely valuable for Internet service providers, mobile users, and government managers of modern metropolis. This paper aims at extracting and modeling the traffic patterns of large scale towers deployed in a metropolitan city. To achieve this goal, we need to address several challenges, including lack of appropriate tools for processing large scale traffic measurement data, unknown traffic patterns, as well as handling complicated factors of urban ecology and human behaviors that affect traffic patterns. Our core contribution is a powerful model which combines three dimensional information (time, locations of towers, and traffic frequency spectrum) to extract and model the traffic patterns of thousands of cellular towers. Our empirical analysis reveals the following important observations. First, only five basic time-domain traffic patterns exist among the 9600 cellular towers. Second, each of the extracted traffic pattern maps to one type of geographical locations related to urban ecology, including residential area, business district, transport, entertainment, and comprehensive area. Third, our frequency-domain traffic spectrum analysis suggests that the traffic of any tower among 9600 can be constructed using a linear combination of four primary components corresponding to human activity behaviors. We believe that the proposed traffic patterns extraction and modeling methodology, combined with the empirical analysis on the mobile traffic, pave the way toward a deep understanding of the traffic patterns of large scale cellular towers in modern metropolis.","Poles and towers,
Mobile communication,
Urban areas,
Base stations,
Ecology,
Biological system modeling,
Data visualization"
Energy-Efficient Scheduling for mmWave Backhauling of Small Cells in Heterogeneous Cellular Networks,"Heterogeneous cellular networks (HCNs) are emerging as a promising candidate for the fifth-generation (5G) mobile network. With base stations (BSs) of small cells densely deployed, the cost-effective, flexible, and green backhaul solution has become one of the most urgent and critical challenges. With vast amounts of spectrum available, wireless backhaul in the millimeter-wave (mmWave) band is able to provide transmission rates of several gigabits per second. The mmWave backhaul utilizes beamforming to achieve directional transmission, and concurrent transmissions under low interlink interference can be enabled to improve network capacity. To achieve an energy-efficient solution for mmWave backhauling, we first formulate the problem of minimizing the energy consumption via concurrent transmission scheduling and power control into a mixed integer nonlinear program (MINLP). Then, we develop an energy-efficient and practical mmWave backhauling scheme, which consists of the maximum independent set (MIS)-based scheduling algorithm and the power control algorithm. We also theoretically analyze the conditions that our scheme reduces energy consumption, as well as the choice of the interference threshold. Through extensive simulations under various traffic patterns and system parameters, we demonstrate the superior performance of our scheme in terms of energy efficiency and analyze the choice of the interference threshold under different traffic loads, BS distributions, and the maximum transmission power.","Energy consumption,
Wireless communication,
Throughput,
5G mobile communication,
Interference,
Power control"
Global Finite-Time Adaptive Stabilization of Nonlinearly Parametrized Systems With Multiple Unknown Control Directions,"In this paper, the problem of the global finite-time adaptive stabilization for nonlinearly parametrized systems with multiple unknown control directions is addressed. Different from the previous results, the control directions of the considered systems are completely unknown. Adopting the adding a power integrator design technique, we develop an adaptive switching controller with a tuning parameter. Due to control directions unknown, a novel logic switching regulation is established based on Lyapunov function method to overcome this main obstacle. According to this switching rule, the design parameter is tuned online in a switching way. With the help of the obtained adaptive switching controller, the global finite-time stability of the closed-loop systems is shown. To verify the effectiveness of the control algorithm, a simulation example is presented.","Switches,
Adaptive control,
Stability analysis,
Tuning,
Asymptotic stability"
Calcium Ion Fluctuations Alter Channel Gating in a Stochastic Luminal Calcium Release Site Model,"Stochasticity and small system size effects in complex biochemical reaction networks can greatly alter transient and steady-state system properties. A common approach to modeling reaction networks, which accounts for system size, is the chemical master equation that governs the dynamics of the joint probability distribution for molecular copy number. However, calculation of the stationary distribution is often prohibitive, due to the large state-space associated with most biochemical reaction networks. Here, we analyze a network representing a luminal calcium release site model and investigate to what extent small system size effects and calcium fluctuations, driven by ion channel gating, influx and diffusion, alter steady-state ion channel properties including open probability. For a physiological ion channel gating model and number of channels, the state-space may be between approximately 10^6-10^8
elements, and a novel modified block power method is used to solve the associated dominant eigenvector problem required to calculate the stationary distribution. We demonstrate that both small local cytosolic domain volume and a small number of ion channels drive calcium fluctuations that result in deviation from the corresponding model that neglects small system size effects.","Mathematical model,
Biological system modeling,
Calcium,
Steady-state,
IEEE transactions,
Computational biology,
Bioinformatics"
Multisource Transfer Learning With Convolutional Neural Networks for Lung Pattern Analysis,"Early diagnosis of interstitial lung diseases is crucial for their treatment, but even experienced physicians find it difficult, as their clinical manifestations are similar. In order to assist with the diagnosis, computer-aided diagnosis systems have been developed. These commonly rely on a fixed scale classifier that scans CT images, recognizes textural lung patterns, and generates a map of pathologies. In a previous study, we proposed a method for classifying lung tissue patterns using a deep convolutional neural network (CNN), with an architecture designed for the specific problem. In this study, we present an improved method for training the proposed network by transferring knowledge from the similar domain of general texture classification. Six publicly available texture databases are used to pretrain networks with the proposed architecture, which are then fine-tuned on the lung tissue data. The resulting CNNs are combined in an ensemble and their fused knowledge is compressed back to a network with the original architecture. The proposed approach resulted in an absolute increase of about 2% in the performance of the proposed CNN. The results demonstrate the potential of transfer learning in the field of medical image analysis, indicate the textural nature of the problem and show that the method used for training a network can be as important as designing its architecture.","Lungs,
Biomedical imaging,
Training,
Databases,
Computed tomography,
Knowledge engineering,
Machine learning"
Information-Centric Networks With Correlated Mobility,"The information-centric networking (ICN), which is an important research direction of future internet architecture, has gained lots of attention from the research community. This paper investigates the impact of a correlated mobility on the throughput and delay performance of mobile ad hoc networks (MANETs) under information-centric environments, where the main concern of nodes is to retrieve contents stored by other nodes. Based on the degree of correlation among nodes, we consider two network regimes, i.e., the cluster-dense regime and cluster-sparse regime. In each regime, we study two mobility time scales: 1) fast mobility, where node mobility is at the same time scale as packet transmissions, and 2) slow mobility, where node mobility is at a much slower time scale than the packet transmissions. In each regime, we characterize the network performance under fast mobility and slow mobility, respectively. Our results indicate that 1) under fast mobility, correlated mobility improves delay performance at the cost of throughput performance; 2) under slow mobility, correlated mobility has a negative impact on both throughput and delay performance when the length of each time slot T = Ω(1/rn), where rn denotes the transmission range. However, when T = o(1/rn), correlated mobility improves delay performance but degrades throughput performance; 3) under slow mobility, the mobility of nodes has a negative impact on both throughput and delay performance. The results help us to have a deep understanding on the fundamental performance scaling laws and to shed light on the design of better performance information-centric MANETs with correlated mobility.",
Tensor-Based Dictionary Learning for Spectral CT Reconstruction,"Spectral computed tomography (CT) produces an energy-discriminative attenuation map of an object, extending a conventional image volume with a spectral dimension. In spectral CT, an image can be sparsely represented in each of multiple energy channels, and are highly correlated among energy channels. According to this characteristics, we propose a tensor-based dictionary learning method for spectral CT reconstruction. In our method, tensor patches are extracted from an image tensor, which is reconstructed using the filtered backprojection (FBP), to form a training dataset. With the Candecomp/Parafac decomposition, a tensor-based dictionary is trained, in which each atom is a rank-one tensor. Then, the trained dictionary is used to sparsely represent image tensor patches during an iterative reconstruction process, and the alternating minimization scheme is adapted for optimization. The effectiveness of our proposed method is validated with both numerically simulated and real preclinical mouse datasets. The results demonstrate that the proposed tensor-based method generally produces superior image quality, and leads to more accurate material decomposition than the currently popular popular methods.","Tensile stress,
Computed tomography,
Dictionaries,
Image reconstruction,
Photonics,
Reconstruction algorithms,
Learning systems"
A Balanced Energy-Consuming and Hole-Alleviating Algorithm for Wireless Sensor Networks,"In wireless sensor networks, energy balancing and energy efficiency are the key requirements to prolong the network lifetime. In this paper, we investigate the problem of energy hole, in which sensor nodes located near the sink or in some other parts of the network die early due to unbalanced load distribution. Moreover, there is a dire need to utilize the energy resource efficiently. For this purpose, balanced energy consumption and hole alleviation, and energy-aware balanced energy-consuming and hole-alleviating algorithms are proposed. These algorithms balance the distribution of load along with efficient energy consumption. An optimal distance and energy-based transmission strategy with least expected error rate is adopted to forward the data packets of different sizes. Furthermore, the data distribution between high-energy consuming nodes and low-energy consuming nodes in each corona is analyzed. This distribution enables the proposed algorithms to outperform their counterparts in term of network lifetime, balanced energy consumption, and throughput on the cost of increased end-to-end delay.","Wireless sensor networks,
Throughput,
Energy consumption,
Corona,
Maintenance engineering,
Energy resources,
Delays"
"Multilevel Diversity Coding Systems: Rate Regions, Codes, Computation, & Forbidden Minors","The rate regions of multilevel diversity coding systems (MDCSs), a sub-class of the broader family of multi-source multi-sink networks with special structure, are investigated in a systematic way. We enumerate all non-isomorphic MDCS instances with at most three sources and four encoders. Then, the exact rate region of every one of these more than 7000 instances is proven via computations showing that the Shannon outer bound matches with a custom constructed linear code-based inner bound. Results gained from these computations are summarized in key statistics involving aspects, such as the sufficiency of scalar binary codes, the necessary size of vector binary codes, and so on. Also, it is shown how to construct the codes for an achievability proof. Based on this large repository of rate regions, a series of results about general MDCS cases of arbitrary size that they inspired is introduced and proved. In particular, a series of embedding operations that preserve the property of sufficiency of scalar or vector codes is presented. The utility of these operations is demonstrated by boiling the thousands of MDCS instances for which scalar binary (superposition) codes are insufficient down to 12 (26) forbidden the smallest embedded MDCS instances.instances.","Decoding,
Network coding,
Linear codes,
Computers,
Binary codes"
Cloud-Assisted Context-Aware Vehicular Cyber-Physical System for PHEVs in Smart Grid,"Plug-in Hybrid Electric Vehicles (PHEVs) can be one of the cost-effective options of modern intelligent transportation systems in smart grid (SG) which can balance the demand and supply by temporarily storing the electrical energy in their batteries. In this paper, we propose a new context-aware layered architecture for demand side management using vehicular cyber-physical system (VCPS) with cloud support. We have used the concept of Bayesian coalition game and learning automata for an intelligent context-aware data collection and processing using a new payoff function for the players in the coalition game. In the proposed scheme, vehicles are assumed as the players which sense the SG environment during their mobility and collect information from it. The players in the game perform actions such as alert generation, and information dissemination. For each action, players receive a feedback from the environment according to which they update their action probability vector. The performance of the proposed scheme shows that there is a reduction in energy shortage by 30%, and information processing delay of 10%-15%. In addition, there is an increase of 15% in energy sold back to the grid using the proposed scheme. The results obtained demonstrate the effectiveness of the proposed scheme.","Vehicles,
Games,
Sensors,
Batteries,
Multimedia communication,
Cloud computing"
Fractional Differential Systems: A Fuzzy Solution Based on Operational Matrix of Shifted Chebyshev Polynomials and Its Applications,"In this paper, a new formula of fuzzy Caputo fractional-order derivatives (0 <; v ≤ 1) in terms of shifted Chebyshev polynomials is derived. The proposed approach introduces a shifted Chebyshev operational matrix in combination with a shifted Chebyshev tau technique for the numerical solution of linear fuzzy fractional-order differential equations. The main advantage of the proposed approach is that it simplifies the problem alike in solving a system of fuzzy algebraic linear equations. An approximated error bound between the exact solution and the proposed fuzzy solution with respect to the number of fuzzy rules and solution errors is derived. Furthermore, we also discuss the convergence of the proposed method from the fuzzy perspective. Experimentally, we show the strength of the proposed method in solving a variety of fractional differential equation models under uncertainty encountered in engineering and physical phenomena (i.e., viscoelasticity, oscillations, and resistor-capacitor (RC) circuits). Comparisons are also made with solutions obtained by the Laguerre polynomials and the fractional Euler method.","Chebyshev approximation,
Jacobian matrices,
Differential equations,
Fractional calculus,
Concrete,
Uncertainty"
"Development, Demonstration, and Control of a Testbed for Multiterminal HVDC System","This paper presents the development of a scaled four-terminal high-voltage direct current (HVDC) testbed, including hardware structure, communication architecture, and different control schemes. The developed testbed is capable of emulating typical operation scenarios including system start-up, power variation, line contingency, and converter station failure. Some unique scenarios are also developed and demonstrated, such as online control mode transition and station re-commission. In particular, a dc line current control is proposed, through the regulation of a converter station at one terminal. By controlling a dc line current to zero, the transmission line can be opened by using relatively low-cost HVDC disconnects with low current interrupting capability, instead of the more expensive dc circuit breaker. Utilizing the dc line current control, an automatic line current limiting scheme is developed. When a dc line is overloaded, the line current control will be automatically activated to regulate current within the allowable maximum value.","Power conversion,
Voltage control,
HVDC transmission,
Circuit breakers,
Topology"
A Hybrid Miniaturized-Element Frequency Selective Surface With a Third-Order Bandpass Response,"A new architecture for a miniaturized-element frequency selective surface (MEFSS) capable of providing a third-order bandpass response is presented and experimentally verified. The proposed MEFSS consists of three metal layers separated from one another by two dielectric substrates. The exterior metal layers are nonresonant inductive wire grids, while the center layer is a hybrid resonator composed of an inductive wire and an I-shaped resonator. The exterior metal layers and the dielectric substrates act as two inductively coupled series resonators sandwiching the hybrid resonator layer in the middle. This results in a filter with a third-order bandpass response that can also provide an out-of-band transmission null at a frequency higher than that of the main passband. An equivalent-circuit-based synthesis procedure for this MEFSS is also presented in this letter that allows for designing the FSS from its desired system-level performance indicators (e.g., center frequency of operation, bandwidth, etc.). The validity of this design procedure is verified by presenting a design example and conducting full-wave electromagnetic simulations. Finally, an experimental proof-of-concept demonstration is performed by characterizing the unit cell of this MEFSS designed to operate in a WR-112 waveguide environment.","Frequency selective surfaces,
Integrated circuit modeling,
Wires,
Computer architecture,
Dielectric substrates,
Equivalent circuits,
Metals"
Cloudde: A Heterogeneous Differential Evolution Algorithm and Its Distributed Cloud Version,"Existing differential evolution (DE) algorithms often face two challenges. The first is that the optimization performance is significantly affected by the ad hoc configurations of operators and parameters for different problems. The second is the long runtime for real-world problems whose fitness evaluations are often expensive. Aiming at solving these two problems, this paper develops a novel double-layered heterogeneous DE algorithm and realizes it in cloud computing distributed environment. In the first layer, different populations with various parameters and/or operators run concurrently and adaptively migrate to deliver robust solutions by making the best use of performance differences among multiple populations. In the second layer, a set of cloud virtual machines run in parallel to evaluate fitness of corresponding populations, reducing computational costs as offered by cloud. Experimental results on a set of benchmark problems with different search requirements and a case study with expensive design evaluations have shown that the proposed algorithm offers generally improved performance and reduced computational time, compared with not only conventional and a number of state-of-the-art DE variants, but also a number of other distributed DE and high-performing evolutionary algorithms. The speedup is significant especially on expensive problems, offering high potential in a broad range of real-world applications.",
A Novel Automatic Composition System Using Evolutionary Algorithm and Phrase Imitation,"Music is a significant achievement of human activities and culture. Composing music is a complex and challenging task in that many factors, such as scale, key, chord, rhythm, and pitch, and their interactions need to be considered. With the advance of computer technology and artificial intelligence, automatic composition systems emerge and present some promising results. In particular, composing music through evolutionary algorithms has received increasing attention. Although evolutionary approaches are capable of generating compositions that follow music theory, these compositions are easily recognized as machine-made products due to their unpredictability in melodic progression, which is an important factor affecting a human's impression and feeling on a song. This paper aims for an automatic composition system that emulates human intelligence in music composition. Specifically, we propose the phrase imitation-based evolutionary composition (PIEC) to generate compositions by an evolutionary algorithm based on music theory and imitation of the characteristics and melodic progression of human-composed music. The PIEC conducts intraphrase and interphrase rearrangement to imitate the ascending/descending motion of phrases. Furthermore, we design four fitness functions for the PIEC to evolve compositions considering note distribution, interval variance, and music theory. The experimental results show that the proposed PIEC can effectively generate satisfactory compositions with the characteristics of the sample melody. The results also validate the effects of phrase imitation and the four fitness functions on evolutionary composition.","Rhythm,
Evolutionary computation,
Genetic algorithms,
Biological cells,
Artificial intelligence,
Neural networks,
Sociology"
Ant Colony Optimization With Local Search for Dynamic Traveling Salesman Problems,"For a dynamic traveling salesman problem (DTSP), the weights (or traveling times) between two cities (or nodes) may be subject to changes. Ant colony optimization (ACO) algorithms have proved to be powerful methods to tackle such problems due to their adaptation capabilities. It has been shown that the integration of local search operators can significantly improve the performance of ACO. In this paper, a memetic ACO algorithm, where a local search operator (called unstring and string) is integrated into ACO, is proposed to address DTSPs. The best solution from ACO is passed to the local search operator, which removes and inserts cities in such a way that improves the solution quality. The proposed memetic ACO algorithm is designed to address both symmetric and asymmetric DTSPs. The experimental results show the efficiency of the proposed memetic algorithm for addressing DTSPs in comparison with other state-of-the-art algorithms.","Urban areas,
Heuristic algorithms,
Benchmark testing,
Memetics,
Generators,
Algorithm design and analysis,
Traveling salesman problems"
SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations,"The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efficient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including finding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efficiently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data.","Trajectory,
Data visualization,
Public transportation,
Advertising,
Visual analytics,
Data mining"
Robust Operation of Distribution Networks Coupled With Urban Transportation Infrastructures,"We study the energy dispatch of power distribution networks (PDNs) coupled with urban transportation networks. The electricity demand at each charging/swapping facility is influenced by the arrival rates and charging requests of electric vehicles, which further depends on the spatial distribution of traffic flows over the entire transportation system. We consider the impact of the road congestion on route choices of vehicles from a system-level perspective. The traffic flow pattern in steady state is characterized by the Wardrop user equilibrium. We consider the PDN load perturbation caused by the traffic demand uncertainty, and propose a robust dispatch method that maintains the feasibility of an alternating current power flow constraints. By applying the convex relaxation to nonlinear branch power flow equations, the proposed model yields a two-stage robust convex optimization problem with an implicit uncertainty set. Moreover, a decomposition framework is proposed, in which the first phase determines the uncertainty set of electricity demand by solving two traffic assignment problems associated with the extreme scenarios, and the second phase solves a two-stage robust second-order cone program following a delayed constraint generation framework. Several issues regarding the scalability and conservatism are elaborated. Case studies corroborate the applicability and efficiency of the proposed method.",
Zero-Attracting Recursive Least Squares Algorithms,"The l1-norm sparsity constraint is a widely used technique for constructing sparse models. In this paper, two zeroattracting recursive least squares algorithms, which are referred to as ZA-RLS-I and ZA-RLS-II, are derived by employing the l1-norm of the parameter vector constraint to facilitate model sparsity. To achieve a closed-form solution, the l1-norm of the parameter vector is approximated by an adaptively weighted l2-norm in which the weighting factors are set as the inversion of the associated l1-norm of parameter estimates that are readily available in the adaptive learning environment. ZA-RLS-II is computationally more efficient than ZA-RLS-I by exploiting the known results from linear algebra and the sparsity of the system. The proposed algorithms are proven to converge, and adaptive sparse channel estimation is used to demonstrate the effectiveness of the proposed approach.",
Efficient Hierarchical Identity-Based Signature With Batch Verification for Automatic Dependent Surveillance-Broadcast System,"The automatic-dependent surveillance-broad-cast (ADS-B) is generally regarded as the most important module in air traffic surveillance technology. To obtain better airline security, ADS-B system will be deployed in most airspace by 2020, where aircraft will be equipped with an ADS-B device that periodically broadcasts messages to other aircraft and ground station controllers. Due to the open communication environment, the ADS-B system is subject to a broad range of attacks. To simultaneously implement both integrity and authenticity of messages transmitted in the ADS-B system, Yang et al. proposed a new authentication frame based on the three-level hierarchical identity-based signature (TLHIBS) scheme with batch verification, as well as constructing two schemes for the ADS-B system. However, neither TLHIBS schemes are sufficiently lightweight for practical deployment due to the need for complex hash-to-point operation or expensive certification management. In this paper, we construct an efficient TLHIBS scheme with batch verification for the ADS-B system. Our scheme does not require hash-to-point operation or (expensive) certification management. We then prove the TLHIBS scheme secure in the random oracle model. We also demonstrate the practicality of the scheme using experiments, whose findings indicate that the TLHIBS scheme supports attributes required by the ADS-B system without the computation cost in Chow et al.'s scheme and Yang et al.'s TLHIBS schemes.",
Experimental Evaluation of Impulsive Ultrasonic Intra-Body Communications for Implantable Biomedical Devices,"Biomedical systems of miniaturized implantable sensors and actuators interconnected in an intra-body area network could enable revolutionary clinical applications. Given the well-understood limitations of radio frequency (RF) propagation in the human body, in our previous work we investigated the use of ultrasonic waves as an alternative physical carrier of information, and proposed Ultrasonic WideBand (UsWB), an ultrasonic multipath-resilient integrated physical and medium access control (MAC) layer protocol. In this paper, we discuss the design and implementation of a software-defined testbed architecture for ultrasonic intra-body area networks, and propose the first experimental demonstration of the feasibility of ultrasonic communications in tissue mimicking materials. We first discuss in detail our FPGA-based prototype implementation of UsWB. We then demonstrate how the prototype can flexibly trade performance off for power consumption, and achieve, for bit error rates (BER) no higher than 10-6, either (i) high-data rate transmissions up to 700 kbit/s at a transmit power of -14 dBm (≈ 40 μW), or (ii) low-data rate and lower-power transmissions down to -21 dBm (≈ 8 μW) at 70 kbit/s. We demonstrate that the UsWB MAC protocol allows multiple transmitter-receiver pairs to coexist and dynamically adapt the transmission rate according to channel and interference conditions to maximize throughput while satisfying predefined reliability constraints. We also show how UsWB can be used to enable a video monitoring medical application for implantable devices. Finally, we propose (and validate through experiments) a statistical model of small-scale fading for the ultrasonic intra-body channel.","Acoustics,
Radio frequency,
Media Access Protocol,
Attenuation,
Monitoring,
Implants,
Wireless communication"
Stereoscopic Thumbnail Creation via Efficient Stereo Saliency Detection,"In this paper, we propose a framework for automatically producing thumbnails from stereo image pairs. It has two components focusing respectively on stereo saliency detection and stereo thumbnail generation. The first component analyzes stereo saliency through various saliency stimuli, stereoscopic perception and the relevance between two stereo views. The second component uses stereo saliency to guide stereo thumbnail generation. We develop two types of thumbnail generation methods, both changing image size automatically. The first method is called content-persistent cropping (CPC), which aims at cropping stereo images for display devices with different aspect ratios while preserving as much content as possible. The second method is an object-aware cropping method (OAC) for generating the smallest possible thumbnail pair that retains the most important content only and facilitates quick visual exploration of a stereo image database. Quantitative and qualitative experimental evaluations demonstrate promising performance of our thumbnail generation methods in comparison to state-of-the-art algorithms.","Stereo image processing,
Detection algorithms,
Image edge detection,
Estimation,
Visualization,
Distortion,
Computer science"
Auction-Based Frameworks for Secure Communications in Static and Dynamic Cognitive Radio Networks,"This paper investigates the secure communication issue for both static and dynamic cognitive radio networks (CRNs), where multiple nonaltruistic primary users (PUs), secondary users (SUs), and eavesdroppers exist. The design objective is to provide secure communications for PUs and, meanwhile, to ease the starvation of transmission opportunities for SUs. To achieve this goal, we propose a barter-like trading model to incentivize the cooperation among nonaltruistic users. Specifically, PUs leverage the assistance of SUs in the form of cooperative relaying or friendly jamming and, in return, yield certain licensed spectrum accessing time to the aided SUs. We propose a truthful nonmonetary double auction framework (FONDA) toward secure communications for static CRN where PUs and SUs interact in a single round. Then, we extend our framework to d-FONDA for dynamic CRN, where SUs who have patience (tolerant of traffic delay) arrive and leave the network dynamically. We prove that both FONDA and d-FONDA preserve nice economic properties, including truthfulness, individual rationality, and budget balance. Simulation results reveal that the proposed frameworks provide substantial performance gains compared with the baseline scheme and suffer acceptable performance degradation over ideal schemes.",
Person Re-identification by Multi-hypergraph Fusion,"Matching people across nonoverlapping cameras, also known as person re-identification, is an important and challenging research topic. Despite its great demand in many crucial applications such as surveillance, person re-identification is still far from being solved. Due to drastic view changes, even the same person may look quite dissimilar in different cameras. Illumination and pose variations further aggravate this discrepancy. To this end, various feature descriptors have been designed for improving the matching accuracy. Since different features encode information from different aspects, in this paper, we propose to effectively leverage multiple off-the-shelf features via multi-hypergraph fusion. A hypergraph captures not only pairwise but also high-order relationships among the subjects being matched. In addition, different from conventional approaches in which the matching is achieved by computing the pairwise distance or similarity between a probe and a gallery subject, the similarities between the probe and all gallery subjects are learned jointly via hypergraph optimization. Experiments on popular data sets demonstrate the effectiveness of the proposed method, and a superior performance is achieved as compared with the most recent state-of-the-arts.",
Shape Sensing Techniques for Continuum Robots in Minimally Invasive Surgery: A Survey,"Continuum robots provide inherent structural compliance with high dexterity to access the surgical target sites along tortuous anatomical paths under constrained environments and enable to perform complex and delicate operations through small incisions in minimally invasive surgery. These advantages enable their broad applications with minimal trauma and make challenging clinical procedures possible with miniaturized instrumentation and high curvilinear access capabilities. However, their inherent deformable designs make it difficult to realize 3-D intraoperative real-time shape sensing to accurately model their shape. Solutions to this limitation can lead themselves to further develop closely associated techniques of closed-loop control, path planning, human-robot interaction, and surgical manipulation safety concerns in minimally invasive surgery. Although extensive model-based research that relies on kinematics and mechanics has been performed, accurate shape sensing of continuum robots remains challenging, particularly in cases of unknown and dynamic payloads. This survey investigates the recent advances in alternative emerging techniques for 3-D shape sensing in this field and focuses on the following categories: fiber-optic-sensor-based, electromagnetic-tracking-based, and intraoperative imaging modality-based shape-reconstruction methods. The limitations of existing technologies and prospects of new technologies are also discussed.","Robot sensing systems,
Shape,
Optical fiber sensors,
Needles,
Image reconstruction"
Mobility-Aware Service Composition in Mobile Communities,"The advances in mobile technologies enable mobile devices to perform tasks that are traditionally run by personal computers as well as provide services to the others. Mobile users can form a service sharing community within an area by using their mobile devices. This paper highlights several challenges involved in building such service compositions in mobile communities when both service requesters and providers are mobile. To deal with them, we first propose a mobile service provisioning architecture named a mobile service sharing community and then propose a service composition approach by utilizing the Krill-Herd algorithm. To evaluate the effectiveness and efficiency of our approach, we build a simulation tool. The experimental results demonstrate that our approach can obtain superior solutions as compared with current standard composition methods in mobile environments. It can yield near-optimal solutions and has a nearly linear complexity with respect to a problem size.","Mobile communication,
Mobile handsets,
Web services,
Mobile computing,
Sensors,
Protocols,
Libraries"
RoBA Multiplier: A Rounding-Based Approximate Multiplier for High-Speed yet Energy-Efficient Digital Signal Processing,"In this paper, we propose an approximate multiplier that is high speed yet energy efficient. The approach is to round the operands to the nearest exponent of two. This way the computational intensive part of the multiplication is omitted improving speed and energy consumption at the price of a small error. The proposed approach is applicable to both signed and unsigned multiplications. We propose three hardware implementations of the approximate multiplier that includes one for the unsigned and two for the signed operations. The efficiency of the proposed multiplier is evaluated by comparing its performance with those of some approximate and accurate multipliers using different design parameters. In addition, the efficacy of the proposed approximate multiplier is studied in two image processing applications, i.e., image sharpening and smoothing.",
Characterizing Guidance in Visual Analytics,"Visual analytics (VA) is typically applied in scenarios where complex data has to be analyzed. Unfortunately, there is a natural correlation between the complexity of the data and the complexity of the tools to study them. An adverse effect of complicated tools is that analytical goals are more difficult to reach. Therefore, it makes sense to consider methods that guide or assist users in the visual analysis process. Several such methods already exist in the literature, yet we are lacking a general model that facilitates in-depth reasoning about guidance. We establish such a model by extending van Wijk's model of visualization with the fundamental components of guidance. Guidance is defined as a process that gradually narrows the gap that hinders effective continuation of the data analysis. We describe diverse inputs based on which guidance can be generated and discuss different degrees of guidance and means to incorporate guidance into VA tools. We use existing guidance approaches from the literature to illustrate the various aspects of our model. As a conclusion, we identify research challenges and suggest directions for future studies. With our work we take a necessary step to pave the way to a systematic development of guidance techniques that effectively support users in the context of VA.",
Improving Performance of Heterogeneous MapReduce Clusters with Adaptive Task Tuning,"Datacenter-scale clusters are evolving toward heterogeneous hardware architectures due to continuous server replacement. Meanwhile, datacenters are commonly shared by many users for quite different uses. It often exhibits significant performance heterogeneity due to multi-tenant interferences. The deployment of MapReduce on such heterogeneous clusters presents significant challenges in achieving good application performance compared to in-house dedicated clusters. As most MapReduce implementations are originally designed for homogeneous environments, heterogeneity can cause significant performance deterioration in job execution despite existing optimizations on task scheduling and load balancing. In this paper, we observe that the homogeneous configuration of tasks on heterogeneous nodes can be an important source of load imbalance and thus cause poor performance. Tasks should be customized with different configurations to match the capabilities of heterogeneous nodes. To this end, we propose a self-adaptive task tuning approach, Ant, that automatically searches the optimal configurations for individual tasks running on different nodes. In a heterogeneous cluster, Ant first divides nodes into a number of homogeneous subclusters based on their hardware configurations. It then treats each subcluster as a homogeneous cluster and independently applies the self-tuning algorithm to them. Ant finally configures tasks with randomly selected configurations and gradually improves tasks configurations by reproducing the configurations from best performing tasks and discarding poor performing configurations. To accelerate task tuning and avoid trapping in local optimum, Ant uses genetic algorithm during adaptive task configuration. Experimental results on a heterogeneous physical cluster with varying hardware capabilities show that Ant improves the average job completion time by 31, 20, and 14 percent compared to stock Hadoop (Stock), customized Hadoop with industry recommendations (Heuristic), and a profilingbased configuration approach (Starfish), respectively. Furthermore, we extend Ant to virtual MapReduce clusters in a multi-tenant private cloud. Specifically, Ant characterizes a virtual node based on two measured performance statistics: I/O rate and CPU steal time. It uses k-means clustering algorithm to classify virtual nodes into configuration groups based on the measured dynamic interference. Experimental results on virtual clusters with varying interferences show that Ant improves the average job completion time by 20, 15, and 11 percent compared to Stock, Heuristic and Starfish, respectively.","Tuning,
Hardware,
Cloud computing,
Interference,
Optimization,
Clustering algorithms,
Industries"
Large scale assessment of Ka/Q band atmospheric channel across Europe with ALPHASAT TDP5: The augmented network,"The upcoming migration of satellite services to higher bands, namely the Ka- and Q-bands offers many advantages in terms of bandwidth, data rates and system capacity. However, it poses challenges as propagation effects introduced by the various atmospheric phenomena are particularly pronounced in these bands and can become a serious constraint in terms of system reliability and performance. This paper outlines the goals, organization and some first results of an ongoing large propagation campaign consortium formed across Europe under the supervision of the European Space Agency; the campaign, shall ultimately assist in the validation and development of channel models targeting these-bands. Finally, the consideration of diverse climatic conditions and elevation angles along with the evaluation of the frequency and spatio-temporal effects, shall support the development of Fading and Mitigation Techniques and their assessment using real data.","Europe,
Atmospheric measurements,
Satellites,
Atmospheric modeling,
Satellite broadcasting,
Antennas,
Q measurement"
Autonomous Energy Management Strategy for Solid-State Transformer to Integrate PV-Assisted EV Charging Station Participating in Ancillary Service,"Photovoltaic-assisted charging station (PVCS) is expected to be one of the important charging facilities for serving electric vehicles (EVs). In this paper, a type of solid-state transformer (SST) is introduced to the PVCS design and an autonomous energy management strategy (EMS) for SST is proposed. This study aims to develop an effective real-time EMS for PVCS participating in ancillary service of smart grid, and the rule-based decision-making method is utilized. Considering the dynamic classification of EVs, an energy-bound calculation (EBC) model is proposed to find the upper and lower bounds of flexible resources. Moreover, considering the EBC results and power command from the aggregator, a charging power allocation algorithm is designed for power distribution of flexible EVs. By case study and experiment analysis, the proposed EMS is effective in real-time energy management and suitable for practical applications.","Energy management,
Bidirectional control,
State of charge,
Batteries,
Charging stations,
Real-time systems,
Smart grids"
Multilayered Echo State Machine: A Novel Architecture and Algorithm,"In this paper, we present a novel architecture and learning algorithm for a multilayered echo state machine (ML-ESM). Traditional echo state networks (ESNs) refer to a particular type of reservoir computing (RC) architecture. They constitute an effective approach to recurrent neural network (RNN) training, with the (RNN-based) reservoir generated randomly, and only the readout trained using a simple computationally efficient algorithm. ESNs have greatly facilitated the real-time application of RNN, and have been shown to outperform classical approaches in a number of benchmark tasks. In this paper, we introduce a novel criteria for integrating multiple layers of reservoirs within the ML-ESM. The addition of multiple layers of reservoirs are shown to provide a more robust alternative to conventional RC networks. We demonstrate the comparative merits of this approach in a number of applications, considering both benchmark datasets and real world applications.",
An Adaptive Multipopulation Differential Evolution With Dynamic Population Reduction,"Developing efficient evolutionary algorithms attracts many researchers due to the existence of optimization problems in numerous real-world applications. A new differential evolution algorithm, sTDE-dR, is proposed to improve the search quality, avoid premature convergence, and stagnation. The population is clustered in multiple tribes and utilizes an ensemble of different mutation and crossover strategies. In this algorithm, a competitive success-based scheme is introduced to determine the life cycle of each tribe and its participation ratio for the next generation. In each tribe, a different adaptive scheme is used to control the scaling factor and crossover rate. The mean success of each subgroup is used to calculate the ratio of its participation for the next generation. This guarantees that successful tribes with the best adaptive schemes are only the ones that guide the search toward the optimal solution. The population size is dynamically reduced using a dynamic reduction method. Comprehensive comparison of the proposed heuristic over a challenging set of benchmarks from the CEC2014 real parameter single objective competition against several state-of-the-art algorithms is performed. The results affirm robustness of the proposed approach compared to other state-of-the-art algorithms.",
On the Sampling Strategy for Evaluation of Spectral-Spatial Methods in Hyperspectral Image Classification,"Spectral-spatial processing has been increasingly explored in remote sensing hyperspectral image classification. While extensive studies have focused on developing methods to improve the classification accuracy, experimental setting and design for method evaluation have drawn little attention. In the scope of supervised classification, we find that traditional experimental designs for spectral processing are often improperly used in the spectral-spatial processing context, leading to unfair or biased performance evaluation. This is especially the case when training and testing samples are randomly drawn from the same image - a practice that has been commonly adopted in the experiments. Under such setting, the dependence caused by overlap between the training and testing samples may be artificially enhanced by some spatial information processing methods, such as spatial filtering and morphological operation. Such enhancement of dependence in return amplifies the classification accuracy, leading to an improper evaluation of spectral-spatial classification techniques. Therefore, the widely adopted pixel-based random sampling strategy is not always suitable to evaluate spectral-spatial classification algorithms, because it is difficult to determine whether the improvement of classification accuracy is caused by incorporating spatial information into classifier or by increasing the overlap between training and testing samples. To tackle this problem, we propose a novel controlled random sampling strategy for spectral-spatial methods. It can greatly reduce the overlap between training and testing samples and provides more objective and accurate evaluation.",
Nonlocal Gradient Sparsity Regularization for Image Restoration,"Total variation (TV) regularization is widely used in image restoration to exploit the local smoothness of image content. Essentially, the TV model assumes a zero-mean Laplacian distribution for the gradient at all pixels. However, real-world images are nonstationary in general, and the zero-mean assumption of pixel gradient might be invalid, especially for regions with strong edges or rich textures. This paper introduces a nonlocal (NL) extension of TV regularization, which models the sparsity of the image gradient with pixelwise content-adaptive distributions, reflecting the nonstationary nature of image statistics. Taking advantage of the NL similarity of natural images, the proposed approach estimates the image gradient statistics at a particular pixel from a group of nonlocally searched patches, which are similar to the patch located at the current pixel. The gradient data in these NL similar patches are regarded as the samples of the gradient distribution to be learned. In this way, more accurate estimation of gradient is achieved. Experimental results demonstrate that the proposed method outperforms the conventional TV and several other anchors remarkably and produces better objective and subjective image qualities.","TV,
Adaptation models,
Image edge detection,
Image restoration,
Estimation,
Transforms,
Predictive models"
Flexible and Fine-Grained Attribute-Based Data Storage in Cloud Computing,"With the development of cloud computing, outsourcing data to cloud server attracts lots of attentions. To guarantee the security and achieve flexibly fine-grained file access control, attribute based encryption (ABE) was proposed and used in cloud storage system. However, user revocation is the primary issue in ABE schemes. In this article, we provide a ciphertext-policy attribute based encryption (CP-ABE) scheme with efficient user revocation for cloud storage system. The issue of user revocation can be solved efficiently by introducing the concept of user group. When any user leaves, the group manager will update users' private keys except for those who have been revoked. Additionally, CP-ABE scheme has heavy computation cost, as it grows linearly with the complexity for the access structure. To reduce the computation cost, we outsource high computation load to cloud service providers without leaking file content and secret keys. Notably, our scheme can withstand collusion attack performed by revoked users cooperating with existing users. We prove the security of our scheme under the divisible computation Diffie-Hellman assumption. The result of our experiment shows computation cost for local devices is relatively low and can be constant. Our scheme is suitable for resource constrained devices.","Cloud computing,
Encryption,
Outsourcing,
Access control,
Performance evaluation"
Catch You if You Misbehave: Ranked Keyword Search Results Verification in Cloud Computing,"With the advent of cloud computing, more and more people tend to outsource their data to the cloud. As a fundamental data utilization, secure keyword search over encrypted cloud data has attracted the interest of many researchers recently. However, most of existing researches are based on an ideal assumption that the cloud server is ?curious but honest?, where the search results are not verified. In this paper, we consider a more challenging model, where the cloud server would probably behave dishonestly. Based on this model, we explore the problem of result verification for the secure ranked keyword search. Different from previous data verification schemes, we propose a novel deterrent-based scheme. With our carefully devised verification data, the cloud server cannot know which data owners, or how many data owners exchange anchor data which will be used for verifying the cloud server?s misbehavior. With our systematically designed verification construction, the cloud server cannot know which data owners? data are embedded in the verification data buffer, or how many data owners? verification data are actually used for verification. All the cloud server knows is that, once he behaves dishonestly, he would be discovered with a high probability, and punished seriously once discovered. Furthermore, we propose to optimize the value of parameters used in the construction of the secret verification data buffer. Finally, with thorough analysis and extensive experiments, we confirm the efficacy and efficiency of our proposed schemes.","Servers,
Keyword search,
Cloud computing,
Encryption,
Indexes,
Data models"
A Kernel-Power-Density-Based Algorithm for Channel Multipath Components Clustering,"Cluster-based channel modeling has been an important trend in the development of channel model, as it maintains accuracy while reducing complexity. Whereas a large number of channel measurements have shown that multipath components (MPCs) are distributed as groups, i.e., clusters, existing clustering algorithms have various drawbacks with respect to complexity, threshold choices, and/or assumptions about prior knowledge. In this paper, a kernel-power-density (KPD)-based algorithm is proposed for MPC clustering. It uses the kernel density of MPCs to incorporate the modeled behavior of MPCs and takes into account the power of the MPCs. Furthermore, the KPD algorithm only considers the K nearest MPCs in the density estimation to better identify the local density variations of MPCs. A heuristic approach of cluster merging is used to improve the performance. Both simulation and channel measurements validate the KPD algorithm, and almost no performance degradation is found even with a large number of clusters and large cluster angular spread, which outperforming other algorithms. The KPD algorithm enables applications in multipleinput-multiple-output channels with no prior knowledge about the clusters, such as number and initial locations. It also has a fairly low computational complexity and can be used for clusterbased channel modeling.","Clustering algorithms,
Delays,
Channel models,
MIMO,
Algorithm design and analysis,
Wireless communication,
Data models"
Automated Disease Identification With 3-D Optical Imaging: A Medical Diagnostic Tool,"Digital holographic microscopy is an ideal tool for 3-D cell imaging and characterization. It provides a host of cell parameters based on cell morphology and its temporal dynamics or time variation. These parameters can be used to study and quantify cell growth and cell physiology. When coupled with classification algorithms, this technique can also be used to identify and classify cells such as blood cells for automated disease identification. A compact, portable version of this 3-D optical imaging system has the potential to become a device for compact field portable biological data collection, analysis, and cell identification leading to disease diagnosis with mobile devices, low cost instruments for deployment in remote areas with limited access to healthcare to combat disease. In this paper, we present an overview of our reported work on the development of digital holographic microscopes and their applications in 3-D cell imaging, cell parameter extraction and cell classification for potential automated disease identification.","Microscopy,
Diseases,
Optical imaging,
Holography,
Biomedical imaging,
Image reconstruction,
Cellular biophysics,
Image classification"
Including Smart Loads for Optimal Demand Response in Integrated Energy Management Systems for Isolated Microgrids,"This paper presents a mathematical model of smart loads in demand response (DR) schemes, which is integrated into centralized unit commitment (UC) with optimal power flow coupled energy management systems for isolated microgrids for optimal generation and peak load dispatch. The smart loads are modeled with a neural network (NN) load estimator as a function of the ambient temperature, time of day, time of use price, and the peak demand imposed by the microgrid operator. To develop the NN-based smart load estimator, realistic data from an actual energy hub management system is used for supervised training. Based on these, a novel microgrid energy management system (MEMS) framework based on a model predictive control approach is proposed, which yields optimal dispatch decisions of dispatchable generators, energy storage system, and peak demand for controllable loads, considering power flow and UC constraints simultaneously. To study the impact of DR on the microgrid operation with the proposed MEMS framework, a CIGRE benchmark system is used that includes distributed energy resources and renewables based generation. The results show the feasibility and benefits of the proposed models and approach.",
Procedure Graph Model for Automatic RFID Data Processing Service Management,"Process management is practical in the state-of-the-art of Internet of things research. However, this has become a bottleneck in recent years since an extreme amount of heterogeneous items have to be recorded and traced with radio frequency identification (RFID) tags. In a typical application of process synthesis management, each item will be involved with multiple processes but when those processes are interconnected, an extremely complex network emerges and has to be managed. Existing works on processing management systems, however, are always case-based and only focus on specific application domains. Thus, the general applied processing management model is rather limited. In this paper, we summarize the characteristics of the RFID application domains, and by abstraction, we propose an innovation of the RFID processing model. In this model, each RFID data were deemed as an operation record and all their processing services are logically interconnected and organized as a procedure graph. In addition, we abstract and summarize the basic RFID data processes into a few types. The advantage of this design is that the basic RFID data processing logic can be preprogrammed and in a real domain, the system can be dynamically programmed by automatically constructing the procedure graph nodes with those basic processes and mapping the interconnection logic according to the topology of the graph. As the last part of this paper, we designed a prototype system for medical instruments infection control to demonstrate our approach.","Data models,
Data processing,
RFID tags,
Instruments,
Internet of Things,
Logic gates"
Impulsive Effects and Stability Analysis on Memristive Neural Networks With Variable Delays,"In this brief, hybrid impulsive and adaptive feedback controllers are simultaneously exerted on a general delayed memristive neural network (MNN) model to formulate a novel impulsive controlled MNN (IMNN) model with variable delays. By means of Lyapunov-Razumikhin technique and other analytical ways, several new stability criteria of the proposed IMNN model are obtained. In addition, by choosing appropriate impulses and external inputs, the convergence speed of IMNN can be increased, which implies that its dynamic behaviors will be optimized. Finally, the effectiveness of the obtained results is illustrated by one numerical example.","Delays,
Artificial neural networks,
Multi-layer neural network,
Adaptation models,
Stability criteria,
Asymptotic stability"
Hankel Matrix Nuclear Norm Regularized Tensor Completion for N-dimensional Exponential Signals,"Signals are generally modeled as a superposition of exponential functions in spectroscopy of chemistry, biology, and medical imaging. For fast data acquisition or other inevitable reasons, however, only a small amount of samples may be acquired, and thus, how to recover the full signal becomes an active research topic, but existing approaches cannot efficiently recover N-dimensional exponential signals with N ≥ 3. In this paper, we study the problem of recovering N-dimensional (particularly N ≥ 3) exponential signals from partial observations, and formulate this problem as a low-rank tensor completion problem with exponential factor vectors. The full signal is reconstructed by simultaneously exploiting the CANDECOMP/PARAFAC tensor structure and the exponential structure of the associated factor vectors. The latter is promoted by minimizing an objective function involving the nuclear norm of Hankel matrices. Experimental results on simulated and real magnetic resonance spectroscopy data show that the proposed approach can successfully recover full signals from very limited samples and is robust to the estimated tensor rank.","Tensile stress,
Spectroscopy,
Nuclear magnetic resonance,
Image reconstruction,
Frequency-domain analysis,
Compressed sensing,
Minimization"
Content-Adaptive Region-Based Color Texture Descriptors for Medical Images,"The design of computer-assisted decision (CAD) systems for different biomedical imaging scenarios is a challenging task in computer vision. Sometimes, this challenge can be attributed to the image acquisition mechanisms since the lack of control on the cameras can create different visualizations of the same imaging site under different rotation, scaling, and illumination parameters, with a requirement to get a consistent diagnosis by the CAD systems. Moreover, the images acquired from different sites have specific colors, making the use of standard color spaces highly redundant. In this paper, we propose to tackle these issues by introducing novel region-based texture, and color descriptors. The proposed texture features are based on the usage of analytic Gabor filters (for compensation of illumination variations) followed by the calculation of first- and second-order statistics of the filter responses and making them invariant using some trivial mathematical operators. The proposed color features are obtained by compensating for the illumination variations in the images using homomorphic filtering followed by a bag-of-words approach to obtain the most typical colors in the images. The proposed features are used for the identification of cancer in images from two distinct imaging modalities, i.e., gastroenterology and dermoscopy. Experiments demonstrate that the proposed descriptors compares favorably to several other state-of-the-art methods, elucidating on the effectiveness of adapted features for image characterization.","Image color analysis,
Feature extraction,
Lighting,
Biomedical imaging,
Visualization,
Histograms"
iShuffle: Improving Hadoop Performance with Shuffle-on-Write,"Hadoop is a popular implementation of the MapReduce framework for running data-intensive jobs on clusters of commodity servers. Shuffle, the all-to-all input data fetching phase between the map and reduce phase can significantly affect job performance. However, the shuffle phase and reduce phase are coupled together in Hadoop and the shuffle can only be performed by running the reduce tasks. This leaves the potential parallelism between multiple waves of map and reduce unexploited and resource wastage in multi-tenant Hadoop clusters, which significantly delays the completion of jobs in a multi-tenant Hadoop cluster. More importantly, Hadoop lacks the ability to schedule task efficiently and mitigate the data distribution skew among reduce tasks, which leads to further degradation of job performance. In this work, we propose to decouple shuffle from reduce tasks and convert it into a platform service provided by Hadoop. We present iShuffle, a user-transparent shuffle service that pro-actively pushes map output data to nodes via a novel shuffle-on-write operation and flexibly schedules reduce tasks considering workload balance. Experimental results with representative workloads and Facebook workload trace show that iShuffle reduces job completion time by as much as 29.6 and 34 percent in single-user and multi-user clusters, respectively.","Delays,
Couplings,
Data models,
Scheduling,
Parallel processing,
Schedules,
Facebook"
A Scheme on Indoor Tracking of Ship Dynamic Positioning Based on Distributed Multi-Sensor Data Fusion,"Investigating the model ship dynamic positioning system by simulating the actual sea conditions in the laboratory can not only avoid the risks caused by the directly experiments on a true ship, but also reduce the costs. With the purpose of realizing the high accuracy control of the dynamic positioning, besides a high accuracy mathematical model of the ship, an important condition is that the position information provided by the position detection system must be accurate, reliable, and continuous. The global positioning system (GPS) signal is restricted when the model ship dynamic positioning system is set indoors. This paper describes a novel scheme for ship target tracking based on the multi-sensor data fusion techniques. To improve the accuracy of indoor positioning and ship target tracking, the characteristics of many sensors are systematically analyzed, such as radar, difference GPS, and ultrasonic sensors. Other important factors, including the indoor temperature, position, and environment, are also taken into account to further optimize the performance. Combining the Kalman filter method, the time alignment method, the coordinate transformation method, and the optimal fusion criterion method, the core algorithm of our framework employs the track correlation as the performance index of the optimal fusion. The experimental results indicate that our method outperforms the methods based on a single ultrasonic sensor. The maximum error between the estimated location and the real location is only 1.32 cm, which meets the standard for engineering applications.","Marine vehicles,
Integrated circuit modeling,
Data integration,
Target tracking,
Data models,
Sensor systems"
Practical Encoder and Decoder for Power Constrained QC LDPC-Lattice Codes,"Low density parity check (LDPC) lattices were the first family of lattices equipped with iterative decoding algorithms. We introduce quasi-cyclic LDPC (QC LDPC) lattices as a special case of LDPC lattices with one binary QC-LDPC code as their underlying code. These lattices are obtained from the Construction A of lattices providing us to encode them efficiently using shift registers. To benefit from an encoder with linear complexity in the lattice dimension, we obtain the generator matrix of these lattices in quasi-cyclic form. We generalize the proposed quasi-cyclic form of the generator matrix for other Construction A lattices, namely the LDA lattices, with a non-binary QC-LDPC code as their underlying code. We provide a low-complexity decoding algorithm of QC LDPC-lattices based on the sum product algorithm. To design lattice codes, QC LDPC-lattices are combined with the nested lattice shaping that uses the Voronoi region of a sublattice for shaping. The shaping gain and the shaping loss of our lattice codes with dimensions 40, 50, and 60 using an optimal quantizer, are presented. The guidelines for applying efficient shaping methods, like hypercube shaping, for QC LDPC-lattices are also given. Consequently, we establish a family of lattice codes that perform practically close to the sphere bound.","Lattices,
Parity check codes,
Encoding,
Decoding,
Generators,
Complexity theory,
AWGN channels"
Distributed Multicast Tree Construction in Wireless Sensor Networks,"Multicast tree is a key structure for data dissemination from one source to multiple receivers in wireless networks. Minimum length multica modeled as the Steiner tree problem, and is proven to be NP-hard. In this paper, we explore how to efficiently generate minimum length multi wireless sensor networks (WSNs), where only limited knowledge of network topology is available at each node. We design and analyze a simple algorithm, which we call toward source tree (TST), to build multicast trees in WSNs. We show three metrics of TST algorithm, i.e., running and energy efficiency. We prove that its running time is O(√(n log n)), the best among all existing solutions to our best knowledge. We prove that TST tree length is in the same order as Steiner tree, which give a theoretical upper bound and use simulations to show the ratio be only 1.114 when nodes are uniformly distributed. We evaluate energy efficiency in terms of message complexity and the number of forwarding prove that they are both order-optimal. We give an efficient way to construct multicast tree in support of transmission of voluminous data.","Wireless sensor networks,
Receivers,
Routing,
Steiner trees,
Algorithm design and analysis,
Wireless networks,
Measurement"
Pull-Based Distributed Event-Triggered Consensus for Multiagent Systems With Directed Topologies,"This paper mainly investigates consensus problem with a pull-based event-triggered feedback control. For each agent, the diffusion coupling feedbacks are based on the states of its in-neighbors at its latest triggering time, and the next triggering time of this agent is determined by its in-neighbors' information. The general directed topologies, including irreducible and reducible cases, are investigated. The scenario of distributed continuous communication is considered first. It is proved that if the network topology has a spanning tree, then the event-triggered coupling algorithm can realize the consensus for the multiagent system. Then, the results are extended to discontinuous communication, i.e., self-triggered control, where each agent computes its next triggering time in advance without having to observe the system's states continuously. The effectiveness of the theoretical results is illustrated by a numerical example finally.","Multi-agent systems,
Topology,
Network topology,
Eigenvalues and eigenfunctions,
Couplings,
Symmetric matrices,
Learning systems"
Phone Synchronous Speech Recognition With CTC Lattices,"Connectionist temporal classification (CTC) has recently shown improved performance and efficiency in automatic speech recognition. One popular decoding implementation is to use a CTC model to predict the phone posteriors at each frame and then perform Viterbi beam search on a modified WFST network. This is still within the traditional frame synchronous decoding framework. In this paper, the peaky posterior property of CTC is carefully investigated and it is found that ignoring blank frames will not introduce additional search errors. Based on this phenomenon, a novel phone synchronous decoding framework is proposed by removing tremendous search redundancy due to blank frames, which results in significant search speed up. The framework naturally leads to an extremely compact phone-level acoustic space representation: CTC lattice. With CTC lattice, efficient and effective modular speech recognition approaches, second pass rescoring for large vocabulary continuous speech recognition (LVCSR), and phone-based keyword spotting (KWS), are also proposed in this paper. Experiments showed that phone synchronous decoding can achieve 3-4 times search speed up without performance degradation compared to frame synchronous decoding. Modular LVCSR with CTC lattice can achieve further WER improvement. KWS with CTC lattice not only achieved significant equal error rate improvement, but also greatly reduced the KWS model size and increased the search speed.","Hidden Markov models,
Decoding,
Acoustics,
Lattices,
Pragmatics,
Speech recognition,
Acoustic beams"
Privacy-preserving Double-projection Deep Computation Model with Crowdsourcing on Cloud for Big Data Feature Learning,"Recent years have witness a considerable advance of Internet of Things with the tremendous progress of communication theories and sensing technologies. A large number of data, usually referring to big data, have been generated from Internet of Things. In this paper, we present a double-projection deep computation model (DPDCM) for big data feature learning, which projects the raw input into two separate subspaces in the hidden layers to learn interacted features of big data by replacing the hidden layers of the conventional deep computation model (DCM) with double-projection layers. Furthermore, we devise a learning algorithm to train the double-projection deep computation model. Cloud computing is used to improve the training efficiency of the learning algorithm by crowdsourcing the data on cloud. To protect the private data, a privacy-preserving double-projection deep computation model (PPDPDCM) is proposed based on the BGV encryption scheme. Finally, experiments are carried on Animal-20 and NUS-WIDE-14 to estimate the performance of DPDCM and PPDPDCM by comparing with DCM. Results demonstrate that DPDCM achieves a higher classification accuracy than DCM. More importantly, PPDPDCM can effectively improve the efficiency for training parameters, proving its potential for big data feature learning.","Computational modeling,
Tensile stress,
Data models,
Internet of Things,
Big Data,
Training,
Cloud computing"
Distributed Software Emulator for Cyber-Physical Analysis in Smart Grid,"A smart grid is a highly complex cyber-physical electrical power system that uses two-way digital communication and intelligent embedded devices to achieve sensing, control, computation, and communication within power network. To validate the functionality, security, and reliability of such a system requires the modeling and emulation of both communication network and power network, as well as the interactions between them. In this paper, we present smart-grid common open research emulator (SCORE), a distributed software emulator for cyber-physical analysis in smart grid. SCORE integrates the emulations of both power network and communication network, and it is highlighted by the following features. First, SCORE is the first software emulation platform for smart grid, which means that the same application program running in SCORE can be directly ported to embedded devices with little or no migration issues. Second, for one smart grid instance, SCORE supports distributed emulation when the instance is in very large scale. Third, for multiple smart grid emulation instances running on different networked computers, SCORE allows them to dynamically connect or disconnect with each other in run time, such that each instance can capture its own interior system dynamics even without a prior knowledge of the entire smart grid topology.","Smart grids,
Emulation,
Hardware,
Software,
Computational modeling,
Analytical models,
Graphical user interfaces"
Proportional Fairness-Based Resource Allocation for LTE-U Coexisting With Wi-Fi,"To further boost the performance of LTE to meet the ever-increasing mobile traffic demand in a cost-effective way, applying LTE in unlicensed spectrum, known as LTE-U technology, is considered as a promising complementary solution for achieving the ultra-capacity foreseen in 5G and beyond. In the unlicensed spectrum, LTE-U will share the channel with other unlicensed networks, e.g., Wi-Fi. However, the centralized control architecture of LTE networks is inherently different from the distributed channel access of Wi-Fi network, which poses great challenges to achieve fair coexistence of the two networks. To this end, in this paper, we propose a cross-layer proportional fairness (PF)-based framework to jointly optimize the protocol parameters of the medium access control layer and physical layer of an LTE-U network. Specifically, to achieve throughput-oriented PF between the two heterogeneous networks, the cross-layer optimization framework can be decoupled into a device number weighted time occupation ratio-oriented PF optimization problem and a channel-power allocation-based instantaneous transmission rate-oriented PF optimization problem. Given that LTE-U base stations adopt a listen-before-talk-based channel access scheme, the interactions between the LTE-U and the Wi-Fi networks are modeled by two interactive Markov chains. The effectiveness and the superior performance of the proposed cross-layer PF-based optimization framework are demonstrated and verified by simulations.","IEEE 802.11 Standard,
Resource management,
Optimization,
Long Term Evolution,
Time-frequency analysis,
Protocols,
Physical layer"
MPC-based Delay-Aware Fountain Codes for Real-Time Video Communication,"With the prevalence of smart mobile devices and surveillance cameras, the traffic load within the Internet of Things (IoT) has shifted away from non-multimedia data to multimedia traffics, particularly, the video content. However, the explosive demand for real-time video communication over wireless networks in IoT is constantly challenging both video coding and communication research communities. The state-ofthe- art answer to this challenge is sliding-window-based Delay- Aware Fountain (DAF) codes, which combine the channeladaptive feature in rateless coding and the delay-aware feature in video coding. However, the high computational cost and large delay make it impractical for real-time streaming. To address this issue, we integrate the Model Predictive Control (MPC) technique into DAF codes, so the complexity is lowered to an affordable level so that real-time video encoding is supported. Two schemes are developed in this paper: (i) DAF-S, the small-horizon DAF codes, and (ii) DAF-O, the MPC-based DAF using video bit rate prediction. The advantages of both designs are validated through theoretical analysis and comprehensive experiments. The results of simulation experiments show that the decoding ratio of DAF-S is close to the global optimum in DAF codes, and higher than the other existing schemes; DAF-O outperforms the state-of-the-art real-time video communication algorithms.",
Fabrication of Vacuum-Sealed Capacitive Micromachined Ultrasonic Transducers With Through-Glass-Via Interconnects Using Anodic Bonding,"This paper presents a novel fabrication method for vacuum-sealed capacitive micromachined ultrasonic transducer (CMUT) arrays that are amenable to 3D integration. This paper demonstrates that MEMS structures can be directly built on a glass substrate with preformed through-glass-via (TGV) interconnects. The key feature of this new approach is the combination of copper through-glass interconnects with a vibrating silicon-plate structure suspended over a vacuum-sealed cavity by using anodic bonding. This method simplifies the overall fabrication process for CMUTs with through-wafer interconnects by eliminating the need for an insulating lining for vias or isolation trenches that are often employed for implementing through-wafer interconnects in silicon. Anodic bonding is a low-temperature bonding technique that tolerates high surface roughness. Fabrication of CMUTs on a glass substrate and use of copper-filled vias as interconnects reduce the parasitic interconnect capacitance and resistance, and improve device performance and reliability. A 16×16-element 2D CMUT array has been successfully fabricated. The fabricated device performs as the finite-element and equivalent circuit models predict. A TGV interconnect shows a 2-Ω parasitic resistance and a 20-fF shunt parasitic capacitance for 250-μm via pitch. A critical achievement presented in this paper is the sealing of the CMUT cavities in vacuum using a PECVD silicon nitride layer. By mechanically isolating the via structure from the active cells, vacuum sealing can be ensured even when hermetic sealing of the via is compromised. Vacuum sealing is confirmed by measuring the deflection of the edge-clamped thin plate of a CMUT cell under atmospheric pressure. The resonance frequency of an 8-cell 2D array element with 78-μm diameter circular cells and a 1.5-μm plate thickness is measured as 3.32 MHz at 15-V dc voltage (80% Vpull-in). [2016-0200].",
MSP-IMPROV: An Acted Corpus of Dyadic Interactions to Study Emotion Perception,"We present the MSP-IMPROV corpus, a multimodal emotional database, where the goal is to have control over lexical content and emotion while also promoting naturalness in the recordings. Studies on emotion perception often require stimuli with fixed lexical content, but that convey different emotions. These stimuli can also serve as an instrument to understand how emotion modulates speech at the phoneme level, in a manner that controls for coarticulation. Such audiovisual data are not easily available from natural recordings. A common solution is to record actors reading sentences that portray different emotions, which may not produce natural behaviors. We propose an alternative approach in which we define hypothetical scenarios for each sentence that are carefully designed to elicit a particular emotion. Two actors improvise these emotion-specific situations, leading them to utter contextualized, non-read renditions of sentences that have fixed lexical content and convey different emotions. We describe the context in which this corpus was recorded, the key features of the corpus, the areas in which this corpus can be useful, and the emotional content of the recordings. The paper also provides the performance for speech and facial emotion classifiers. The analysis brings novel classification evaluations where we study the performance in terms of inter-evaluator agreement and naturalness perception, leveraging the large size of the audiovisual database.","Databases,
Speech,
Affective computing,
Context,
Videos,
Emotion recognition,
Computer science"
Data-Based Tuning of Reduced-Order Inverse Model in Both Disturbance Observer and Feedforward With Application to Tray Indexing,"Performance of traditional model-based control relies upon accurate modeling. In motion control of flexible systems, it is desirable to use the reduced-order model for ease of trajectory planning and pole placement, but its performance is constrained by modeling inaccuracies due to the existence of friction and multiple flexible modes. To improve the tracking performance, we have developed a data-based method for iterative tuning of the parameters in the reduced-order inverse model within a three-degree-of-freedom composite control structure. The proposed method solely makes use of the input-output data obtained during closed-loop experiments to fine-tune the inverse system model, and accurate system modeling is not required. Unbiasedness of the cost function gradient estimation is proven under reasonable assumptions of stochastic properties of the perturbations. Simulation and experiments are conducted to further illustrate the proposed method and show its practical appeals in industrial applications.",
Secure Full-Duplex Spectrum-Sharing Wiretap Networks With Different Antenna Reception Schemes,"In this paper, we investigate the secrecy performance of full-duplex multi-antenna spectrum-sharing wiretap networks in which a jamming signal is simultaneously transmitted by the full-duplex secondary receiver (Bob) based on the zero forcing beamforming (ZFB) algorithm. For the security enhancement, we propose the two antenna reception schemes: 1) random selection combining (RSC) where Bob selects LB antennas at random to combine the received signals and 2) generalized selection combining (GSC) where Bob selects LB strongest antennas to combine the received signals. We derive the exact closed-form expressions for the secrecy outage probability of full-duplex multi-antenna spectrum-sharing wiretap networks with ZFB algorithm. In order to explore a new design of the proposed schemes, we provide tractable asymptotic approximations for the secrecy outage probability in high signal-to-noise ratio regime under two distinct scenarios. From the analysis, we demonstrate that: 1) when the main channel is much better than the eavesdropper's channel, GSC/ZFB scheme achieves full diversity NB, while RSC/ZFB scheme only achieves partial diversity LB and 2) GSC/ZFB scheme achieves better secrecy performance than RSC/ZFB with different antenna numbers at Bob.","Jamming,
Niobium,
Cognitive radio,
Receiving antennas,
Security"
Reliable and Energy-Efficient Data Forwarding in Industrial Wireless Sensor Networks,"Reliable and energy-efficient data forwarding is significant for industrial Internet of Things (IoT) applications. A routing protocol called Network Coding and Power Control based Routing (NCPCR) is presented for unreliable wireless networks to save energy. The proposed NCPCR incorporates network coding mechanism and considers dynamic transmit power and the number of packet transmissions. In addition to the optimal transmit power, we derive the probability of successful decoding an encoded packet to achieve the network coding gain. The proposed NCPCR adopts the derived network coding gain in making intelligent decisions on whether to apply network coding or not such that energy consumption is significantly reduced. Simulation results show that the proposed NCPCR outperforms existing routing protocols in terms of lower energy consumption.","Network coding,
Decoding,
Wireless sensor networks,
Energy consumption,
Nickel,
Routing,
Encoding"
Robust Non-Rigid Point Set Registration Using Spatially Constrained Gaussian Fields,"Estimating transformations from degraded point sets is necessary for many computer vision and pattern recognition applications. In this paper, we propose a robust non-rigid point set registration method based on spatially constrained context-aware Gaussian fields. We first construct a context-aware representation (e.g., shape context) for assignment initialization. Then, we use a graph Laplacian regularized Gaussian fields to estimate the underlying transformation from the likely correspondences. On the one hand, the intrinsic manifold is considered and used to preserve the geometrical structure, and a priori knowledge of the point set is extracted. On the other hand, by using the deterministic annealing, the presented method is extended to a projected high-dimensional feature space, i.e., reproducing kernel Hilbert space through a kernel trick to solve the transformation, in which the local structure is propagated by the coarse-to-fine scaling strategy. In this way, the proposed method gradually recovers much more correct correspondences, and then estimates the transformation parameters accurately and robustly when facing degradations. Experimental results on 2D and 3D synthetic and real data (point sets) demonstrate that the proposed method reaches better performance than the state-of-the-art algorithms.","Robustness,
Kernel,
Shape,
Context,
Degradation,
Laplace equations,
Estimation"
"A Survey of Stealth Malware Attacks, Mitigation Measures, and Steps Toward Autonomous Open World Solutions","As our professional, social, and financial existences become increasingly digitized and as our government, healthcare, and military infrastructures rely more on computer technologies, they present larger and more lucrative targets for malware. Stealth malware in particular poses an increased threat because it is specifically designed to evade detection mechanisms, spreading dormant, in the wild for extended periods of time, gathering sensitive information or positioning itself for a high-impact zero-day attack. Policing the growing attack surface requires the development of efficient anti-malware solutions with improved generalization to detect novel types of malware and resolve these occurrences with as little burden on human experts as possible. In this paper, we survey malicious stealth technologies as well as existing solutions for detecting and categorizing these countermeasures autonomously. While machine learning offers promising potential for increasingly autonomous solutions with improved generalization to new malware types, both at the network level and at the host level, our findings suggest that several flawed assumptions inherent to most recognition algorithms prevent a direct mapping between the stealth malware recognition problem and a machine learning solution. The most notable of these flawed assumptions is the closed world assumption: that no sample belonging to a class outside of a static training set will appear at query time. We present a formalized adaptive open world framework for stealth malware recognition and relate it mathematically to research from other machine learning domains.","Malware,
Tutorials,
Intrusion detection,
Operating systems,
Command and control systems,
Machine learning algorithms"
Incentivizing Sharing in Realtime D2D Streaming Networks: A Mean Field Game Perspective,"We consider the problem of streaming live content to a cluster of co-located wireless devices that have both an expensive unicast base-station-to-device (B2D) interface, as well as an inexpensive broadcast device-to-device (D2D) interface, which can be used simultaneously. Our setting is a streaming system that uses a block-by-block random linear coding approach to achieve a target percentage of on-time deliveries with minimal B2D usage. Our goal is to design an incentive framework that would promote such cooperation across devices, while ensuring good quality of service. Based on the ideas drawn from truth-telling auctions, we design a mechanism that achieves this goal via appropriate transfers (monetary payments or rebates) in a setting with a large number of devices, and with peer arrivals and departures. Here, we show that a mean field game can be used to accurately approximate our system. Furthermore, the complexity of calculating the best responses under this regime is low. We implement the proposed system on an Android testbed, and illustrate its efficient performance using real world experiments.",
New Distance-Adaptive Modulation Scheme for Elastic Optical Networks,"Elastic optical networks enter as a promising technology for the future of high-capacity networks. Its features provide flexibility and superior scalability in spectrum allocation following the growing demands of Internet traffic. In this letter, we propose a novel approach to address the routing, modulation level, and spectrum allocation (RMLSA) problem through the use of a distance-adaptive modulation scheme that enables the routing of traffic through multiple hops in virtual topology, enabling smoothing out the spectrum continuity and transmission distance constraints. The results showed that the use of the proposed scheme provide a gain of up to 82% in the bandwidth blocking rate using 7% less spectral resources in the network compared with the literature. This proposal opens a new avenue for future research, allowing new solutions for RMLSA problem.",
Cyclist Social Force Model at Unsignalized Intersections With Heterogeneous Traffic,"Cycling is a typical green traffic mode, and takes a growing part of urban traffic volume. Yet limited cyclist behavior models shed light on cases at unsignalized intersections with heterogeneous traffic, where bicycle behavior is characterized by frequent confrontations with other road users (vehicles, bicycles, and pedestrians). This study developed a microscopic simulation model for cyclist behavior analysis at unsignalized intersection with heterogeneous traffic. The cyclist crossing model applied fuzzy logic and social force theory for this purpose. The parameters are either estimated directly based on empirical data or derived indirectly through maximum likelihood estimation. Finally model performance was confirmed through comparisons between estimations and observations on individual trajectory, minimum distances, and average riding speeds of collision avoidance behaviors with different conflicting road users. Simulation results indicated that the model can represent cyclist crossing behavior at unsignalized intersection with heterogeneous traffic as in the real world.",
Prediction of Rising Stars in the Game of Cricket,"Online social databases are rich sources to retrieve appropriate information that is subsequently analyzed for forthcoming trends prediction. In this paper, we identify rising stars in cricket domain by employing machine learning techniques. More precisely, we predict rising stars from batting as well as from bowling realms. For this intent, the concepts of co-players, team, and opposite teams are incorporated and distinct features along with their mathematical formulations are presented. For classification purpose, generative and discriminative machine learning algorithms are employed, and two models from each category are evaluated. As a proof of applicability, the proposed approach is validated experimentally while analyzing the impact of individual features. Besides, model and categorywise assessment is also performed. Employing cross validation, we demonstrate high accuracy for rising star prediction that is both robust and statistically significant. Finally, ranking lists of top ten rising cricketers based on weighted average, performance evolution, and rising star scores are compared with the international cricket council rankings.",
DGLB: Distributed Stochastic Geographical Load Balancing over Cloud Networks,"Contemporary cloud networks are being challenged by the rapid increase of user demands and growing concerns about global warming, due to their substantial energy consumption. This requires future data centers to be both energy efficient and sustainable, which calls for leveraging cutting-edge features and the flexibility provided by the modern smart grids. To fulfill those goals, this paper puts forward a systematic approach to designing energy-aware traffic-efficient geographical load balancing schemes for data-center networks that are not only optimal, but also computationally efficient and amenable to distributed implementation. Under this comprehensive approach, workload and power balancing schemes are designed jointly across the network, both delay-tolerant and interactive workloads are accommodated, novel smart-grid features such as energy storage units are incorporated to cope with renewables, and incentive pricing mechanisms are adopted in the design. To further account for the spatio-temporal variation of demands, energy prices and renewables, the task is formulated as a two-timescale stochastic optimization. Leveraging dual stochastic approximation and the fast iterative shrinkage-thresholding algorithm (FISTA), the proposed optimization is decomposed across time slots (first-stage) and data centers (second-stage). While the resultant online algorithm is strictly feasible and provably optimal under a Markovian assumption for the underlying random processes, extensive numerical tests further demonstrate that it also works well in real-data scenarios, where the underlying randomness is highly correlated across time.","Manganese,
Optimization,
Resource management,
Load management,
Servers,
Cooling,
Routing"
UM Paging: Unified M2M Paging with Optimal DRX Cycle,"In Machine-to-Machine (M2M) communications, devices can automatically communicate with each other without any intervention by humans. However, LTE-A is primarily designed and optimized for Human-to-Human (H2H) communications. Even though LTE-A has defined Machine-Type Communications (MTC), several parts are still undefined or follow the existing H2H standards. Specifically, the existing paging mechanism in LTE-A will substantially increase the computational load and signaling overhead of the system when there are many M2M devices. Therefore, we propose an effective solution to mitigate this problem. Compared with the traditional paging mechanism defined in LTE-A, the proposed solution can save more energy for M2M devices, reduce signaling overhead and alleviate the network's load significantly.",
Magnifying Smartphone Screen Using Google Glass for Low-Vision Users,"Magnification is a key accessibility feature used by low-vision smartphone users. However, small screen size can lead to loss of context and make interaction with magnified displays challenging. We hypothesize that controlling the viewport with head motion can be natural and help in gaining access to magnified displays. We implement this idea using a Google Glass that displays the magnified smartphone screenshots received in real time via Bluetooth. Instead of navigating with touch gestures on the magnified smartphone display, the users can view different screen locations by rotating their head, and remotely interacting with the smartphone. It is equivalent to looking at a large virtual image through a head contingent viewing port, in this case, the Glass display with ~ 15° field of view. The system can transfer seven screenshots per second at 8 × magnification, sufficient for tasks where the display content does not change rapidly. A pilot evaluation of this approach was conducted with eight normally sighted and four visually impaired subjects performing assigned tasks using calculator and music player apps. Results showed that performance in the calculation task was faster with the Glass than with the phone's built-in screen zoom. We conclude that head contingent scanning control can be beneficial in navigating magnified small smartphone displays, at least for tasks involving familiar content layout.","Glass,
Google,
Head,
Windows,
Navigation,
Visualization,
Bluetooth"
Spectral Quantification for High-Resolution MR Spectroscopic Imaging With Spatiospectral Constraints,"Objective: To obtain reliable spectral estimation from magnetic resonance spectroscopic imaging (MRSI) data. Methods: The proposed method takes advantage of prior knowledge: 1) along the spectral dimension in the form of spectral bases, and 2) along the spatial dimensions in the form of spatial regularizations (e.g., smoothness or transform sparsity) and jointly estimates parameters from all the voxels. Results: Simulation and in vivo studies have been performed to demonstrate the performance of the proposed method. A Cramér-Rao-bound-based analysis is also provided. Conclusion: Incorporation of both spatial and spectral constraints can significantly improve spectral quantification of MRSI data. Significance: The proposed method is expected to be useful for various quantitative MRSI studies.","Estimation,
Transforms,
Imaging,
TV,
Signal to noise ratio,
Electronic mail,
In vivo"
Low-Rank Covariance-Assisted Downlink Training and Channel Estimation for FDD Massive MIMO Systems,"We consider the problem of downlink training and channel estimation in frequency division duplex (FDD) massive MIMO systems, where the base station (BS) equipped with a large number of antennas serves a number of single-antenna users simultaneously. To obtain the channel state information (CSI) at the BS in FDD systems, the downlink channel has to be estimated by users via downlink training and then fed back to the BS. For FDD large-scale MIMO systems, the overhead for downlink training and CSI uplink feedback could be prohibitively high, which presents a significant challenge. In this paper, we study the behavior of the minimum mean-squared error (MMSE) estimator when the channel covariance matrix has a low rank or an approximate low-rank structure. Our theoretical analysis reveals that the amount of training overhead can be substantially reduced by exploiting the low-rank property of the channel covariance matrix. In particular, we show that the MMSE estimator is able to achieve exact channel recovery in the asymptotic low-noise regime, provided that the number of pilot symbols in time is no less than the rank of the channel covariance matrix. We also present an optimal pilot design for the single-user case, and an asymptotic optimal pilot design for the multi-user scenario. Last, we develop a simple model-based scheme to estimate the channel covariance matrix, based on which the MMSE estimator can be employed to estimate the channel. The proposed scheme does not need any additional training overhead. Simulation results are provided to verify our theoretical results and illustrate the effectiveness of the proposed estimated covariance-assisted MMSE estimator.","Downlink,
Channel estimation,
MIMO,
Training,
Covariance matrices,
Uplink,
Wireless communication"
A Cyber-Physical Control Framework for Transient Stability in Smart Grids,"Denial of service attacks and communication latency pose challenges for the operation of control systems within power systems. Specifically, excessive delay between sensors and controllers can substantially worsen the performance of distributed control schemes. In this article, we propose a framework for delay-resilient cyber-physical control of smart grid systems for transient stability applications. The proposed control scheme adapts its structure depending on the value of the latency. As an example, we consider a parametric feedback linearization (PFL) control paradigm and make it “cyber-aware.” A delay-adaptive design that capitalizes on the features of PFL control is presented to enhance the time-delay tolerance of the power system. Depending on the information latency present in the smart grid, the parameters and the structure of the PFL controller are adapted accordingly to optimize performance. The improved resilience is demonstrated by applying the PFL controller to the New England 39-bus and WECC 9-bus test power systems following the occurrence of physical and cyber disturbances. Numerical results show that the proposed cyber-physical controller can tolerate substantial delays without noticeable performance degradation.","Power system stability,
Smart grids,
Transient analysis,
Resilience,
Stability analysis"
A Tube-and-Droplet-Based Approach for Representing and Analyzing Motion Trajectories,"Trajectory analysis is essential in many applications. In this paper, we address the problem of representing motion trajectories in a highly informative way, and consequently utilize it for analyzing trajectories. Our approach first leverages the complete information from given trajectories to construct a thermal transfer field which provides a context-rich way to describe the global motion pattern in a scene. Then, a 3D tube is derived which depicts an input trajectory by integrating its surrounding motion patterns contained in the thermal transfer field. The 3D tube effectively: 1) maintains the movement information of a trajectory, 2) embeds the complete contextual motion pattern around a trajectory, 3) visualizes information about a trajectory in a clear and unified way. We further introduce a droplet-based process. It derives a droplet vector from a 3D tube, so as to characterize the high-dimensional 3D tube information in a simple but effective way. Finally, we apply our tube-and-droplet representation to trajectory analysis applications including trajectory clustering, trajectory classification & abnormality detection, and 3D action recognition. Experimental comparisons with state-of-the-art algorithms demonstrate the effectiveness of our approach.","Trajectory,
Three-dimensional displays,
Electron tubes,
Hidden Markov models,
Context modeling,
Electronic mail,
Shape"
Biosignal-Based Spoken Communication: A Survey,"Speech is a complex process involving a wide range of biosignals, including but not limited to acoustics. These biosignals-stemming from the articulators, the articulator muscle activities, the neural pathways, and the brain itself-can be used to circumvent limitations of conventional speech processing in particular, and to gain insights into the process of speech production in general. Research on biosignal-based speech processing is a wide and very active field at the intersection of various disciplines, ranging from engineering, computer science, electronics and machine learning to medicine, neuroscience, physiology, and psychology. Consequently, a variety of methods and approaches have been used to investigate the common goal of creating biosignal-based speech processing devices for communication applications in everyday situations and for speech rehabilitation, as well as gaining a deeper understanding of spoken communication. This paper gives an overview of the various modalities, research approaches, and objectives for biosignal-based spoken communication.","Biology,
Speech recognition,
Speech synthesis,
Electromyography,
Electroencephalography,
Biomedical measurement,
Infrared spectra,
Spectroscopy,
Ultrasonic imaging,
Biomedical signal processing"
Single-Carrier Frequency-Domain Equalization With Index Modulation,"Motivated by the recent index modulation (IM) concept in the spatial, frequency, and space-time domains, we propose a novel broadband single-carrier (SC)-based IM (SC-IM) scheme as well as its low-complexity frequency-domain equalization (FDE) algorithm. The proposed FDE-aided SC-IM scheme outperforms the conventional FDE-aided SC scheme, while achieving a comparable low level of detection complexity. In addition, in order to reduce the inter-channel correlation arising from the activated symbol indices, we propose a symbol mapping algorithm, which further improves the achievable error-rate performance of the SC-IM scheme. Our simulation results demonstrate the performance advantage of the proposed FDE-aided SC-IM scheme over the conventional FDE-aided SC scheme.","OFDM,
Frequency-domain analysis,
Modulation,
Correlation,
Indexes,
Broadband communication,
Time-domain analysis"
Zero-Forcing Precoding Performance in Multiuser MIMO Systems With Heterogeneous Ricean Fading,"An accurate approximation is developed for the distribution of the instantaneous per-terminal signal-to-noise-ratio (SNR) of a downlink multiuser multiple-input multiple-output system with zero-forcing (ZF) precoding. Our analysis assumes a Ricean fading environment, where we show that the SNR at a given terminal is well approximated by the gamma distribution and we derive its parameters. The analysis relies on densities of an arbitrary eigenvalue and a pair of arbitrary eigenvalues of the uncorrelated complex non-standard, noncentral Wishart matrices. Unlike previous studies, we consider microwave and millimeter-wave channel parameters with a unique Rice factor for each terminal. We demonstrate that stronger line-of-sight adversely impacts the ZF SNR, while increasing the Rice factor variability results in higher peak ZF SNR. Our approximations are insensitive to changes in the system dimension and operating SNRs.","Signal to noise ratio,
Precoding,
Reactive power,
Eigenvalues and eigenfunctions,
Rayleigh channels,
Downlink"
Negative Iris Recognition,"Elements of a person's biometrics are typically stable over the duration of a lifetime, and thus, it is highly important to protect biometric data while supporting recognition (it is also called secure biometric recognition). However, the biometric data that are derived from a person usually vary slightly due to a variety of reasons, such as distortion during picture capture, and it is difficult to use traditional techniques, such as classical encryption algorithms, in secure biometric recognition. The negative database (NDB) is a new technique for privacy preservation. Reversing the NDB has been demonstrated to be an NP-hard problem, and several algorithms for generating hard-to-reverse NDBs have been proposed. In this paper, first, we propose negative iris recognition, which is a novel secure iris recognition scheme that is based on the NDB. We show that negative iris recognition supports several important strategies in iris recognition, e.g., shifting and masking. Next, we analyze the security and efficiency of negative iris recognition. Experimental results show that negative iris recognition is an effective and secure iris recognition scheme. Specifically, negative iris recognition can achieve a highly promising recognition performance (i.e., GAR=98.94% at FAR=0.01%, EER=0.60%) on the typical database CASIA-IrisV3-Interval.","Iris recognition,
Bioinformatics,
Feature extraction,
Databases,
Cryptography"
An Artificial Robot Nervous System To Teach Robots How To Feel Pain And Reflexively React To Potentially Damaging Contacts,"In this letter, we introduce the concept of an artificial Robot Nervous System (aRNS) as a novel way of unifying multimodal physical stimuli sensation with robot pain-reflex movements. We focus on the formalization of robot pain, based on insights from human pain research, as an interpretation of tactile sensation. Specifically, pain signals are used to adapt the equilibrium position, stiffness, and feedforward torque of a pain-based impedance controller. The schemes are experimentally validated with the KUKA LWR4+ for simulated and real physical collisions using the BioTac sensor.",
Social Force Model-Based MCMC-OCSVM Particle PHD Filter for Multiple Human Tracking,"Video-based multiple human tracking often involves several challenges, including target number variation, object occlusions, and noise corruption in sensor measurements. In this paper, we propose a novel method to address these challenges based on probability hypothesis density (PHD) filtering with a Markov chain Monte Carlo (MCMC) implementation. More specifically, a novel social force model (SFM) for describing the interaction between the targets is used to calculate the likelihood within the MCMC resampling step in the prediction step of the PHD filter, and a one class support vector machine (OCSVM) is then used in the update step to mitigate the noise in the measurements, where the SVM is trained with features from both color and oriented gradient histograms. The proposed method is evaluated and compared with state-of-the-art techniques using sequences from the CAVIAR, TUD, and PETS2009 datasets based on the mean Euclidean tracking error on each frame, the optimal subpattern assignment metric, and the multiple object tracking precision metric. The results show improved performance of the proposed method over the baseline algorithms, including the traditional particle PHD filtering method, the traditional SFM-based particle filtering method, multi-Bernoulli filtering, and an online-learning-based tracking method.","Target tracking,
Predictive models,
Mathematical model,
Force,
Noise measurement,
Atmospheric measurements,
Particle measurements"
Exploiting Voltage Regulators to Enhance Various Power Attack Countermeasures,"The security implications of on-chip voltage regulation on the effectiveness of various voltage/frequency scaling-based countermeasures such as random dynamic voltage and frequency scaling (RDVFS), random dynamic voltage scaling (RDVS), and aggressive voltage and frequency scaling (AVFS) are investigated. The side-channel leakage mechanisms of different on-chip voltage regulator topologies are mathematically analyzed and verified with circuit level simulations. Correlation coefficient between the input data and monitored power consumption of a cryptographic circuit is used as the security metric to compare the impact of different on-chip voltage regulators when implemented with the aforementioned countermeasures. As compared to a cryptographic circuit without countermeasure, the RDVFS technique implemented with an on-chip switched-capacitor voltage converter reduces the correlation coefficient over 80% and over 92% against differential and leakage power analysis attacks, respectively, through masking the leakage of the clock frequency and supply voltage information in the monitored power profile.","Voltage control,
Regulators,
Cryptography,
Power demand,
System-on-chip,
Monitoring"
Design of a Thyristor Controlled LC Compensator for Dynamic Reactive Power Compensation in Smart Grid,"This paper presents a thyristor controlled LC (TCLC) compensator for dynamic reactive power compensation in a smart grid system. Compared with the traditional static var compensators like a fixed capacitor-thyristor controlled reactor (FC-TCR) which generates low order harmonic currents, the proposed TCLC can significantly mitigate the injection of harmonic currents. In this paper, the design of the TCLC parameters is investigated with the considerations of its reactive power compensation range and harmonic currents rejection. And a control method based on the generalized instantaneous reactive power theory is proposed. Moreover, representative simulation and experimental results of the proposed three-phase three-wire TCLC are presented to show its effectiveness in dynamic reactive power compensation in comparison with the traditional FC-TCR and parallel combination of FC-TCR and passive power filter.","Reactive power,
Harmonic analysis,
Power harmonic filters,
Thyristors,
Inductors,
Wind farms"
Sum-Rate Analysis for Massive MIMO Downlink With Joint Statistical Beamforming and User Scheduling,"Statistical beamforming is an important technique for multi-user massive MIMO downlink, since it depends on the downlink channel covariance only. In this paper, we first derive an explicit analytical sum-rate expression for generic channel covariance-based beamforming scheme. Then, a low-complexity joint statistical beamforming and user scheduling algorithm via greedy search is proposed, where the beamforming is based on the signal-to-leakage-and-noise-ratio (SLNR) for closed-form design and tractable analysis, while the user scheduling is based on the derived sum-rate expression. Further, with the help of large-scale asymptotic simplifications and the introduction of the interference user number parameter, a simple analytical sum-rate expression of the joint algorithm is derived for channels with flat power beam spectrum. The expression explicitly exhibits the sum-rate behavior with respect to different network parameters and captures the effect of sum-rate-based user scheduling. Finally, simulation results are provided to verify our analytical results and to show the advantage of the proposed joint design compared with existing schemes.","MIMO,
Downlink,
Antennas,
Array signal processing,
Interference,
Signal to noise ratio,
Channel estimation"
"Routing, Spectrum, and core and/or mode assignment on space-division multiplexing optical networks [invited]","Elastic optical networks (EONs) are considered to be one of the promising future networks for spectrum flexibility. In conventional wavelength-division multiplexing networks, routing and wavelength assignment is one of the key issues, whereas the routing and spectrum assignment (RSA) problem considerably affects the network performance in EONs. In addition, the data-center traffic and mobile back-haul traffic keeps increasing. To deal with such increasing capacity of applications, spacedivision multiplexing (SDM) technologies such as multicore fiber (MCF) and multi-mode fiber (MMF) have been intensively researched. From the network perspective, this paper focuses on the routing, spectrum, and core and/or mode assignment (RSCMA) problem for future SDMEONs. Introducing MCF or MMF further complicates the RSA problem because the fiber core or mode dimension is newly expanded. In addition, physical impairment caused by MCF or MMF must be considered. In this paper, the target RSCMA problem is first divided into routing and SCMA problems, and a pre-computation method based on the K-shortest path is introduced as the routing solution. Next, we propose SCMA methods with efficiency and flexibility awareness, exploiting prioritized area concept and crosstalk awareness depending on whether MCF or MMF supports intercore/intermode crosstalk. Finally, the paper evaluates and compares the effectiveness of the proposed algorithms with that of representative algorithms.","Optical fiber networks,
Routing,
Optical switches,
Optical fibers,
Modulation,
Multiplexing"
On the SPN Estimation in Image Forensics: A Systematic Empirical Evaluation,"Extracting a fingerprint of a digital camera has fertile applications in image forensics, such as source camera identification and image authentication. In the last decade, photo response nonuniformity (PRNU) has been well established as a reliable unique fingerprint of digital imaging devices. The PRNU noise appears in every image as a very weak signal, and its reliable estimation is crucial for the success rate of the forensic application. In this paper, we present a novel methodical evaluation of 21 state-of-the-art PRNU estimation/enhancement techniques that have been proposed in the literature in various frameworks. The techniques are classified and systematically compared based on their role/stage in the PRNU estimation procedure, manifesting their intrinsic impacts. The performance of each technique is extensively demonstrated over a large-scale experiment to conclude this case-sensitive study. The experiments have been conducted on our created database and a public image database, the “Dresden image database.”","Cameras,
Estimation,
Fingerprint recognition,
Forgery,
Image forensics,
Reliability"
On the Design and Implementation of an Integrated Security Architecture for Cloud with Improved Resilience,"In this paper, we propose an integrated security architecture which combines policy based access control with intrusion detection techniques and trusted computing technologies for securing distributed applications running on virtualised systems. Our security architecture incorporates access control security policies for secure interactions between applications and virtual machines in different physical virtualized servers. It provides intrusion detection and trusted attestation techniques to detect and counteract dynamic attacks in an efficient manner. We demonstrate how this integrated security architecture is used to secure the life cycle of virtual machines including dynamic hosting and allocation of resources as well as migration of virtual machines across different physical servers. We discuss the implementation of the developed architecture and show how the architecture can counteract attack scenarios involving malicious users exploiting vulnerabilities to achieve privilege escalation and then using the compromised machines to generate further attacks. The feedback between the various security components of our security architecture plays a critical role in detecting sophisticated, dynamically changing attacks, thereby increasing the resilience of the overall secure system.","Virtual machining,
Cloud computing,
Computer architecture,
Servers,
Access control,
Intrusion detection"
Generalized Rao Test for Decentralized Detection of an Uncooperative Target,"We tackle distributed detection of a noncooperative target with a wireless sensor network. When the target is present, sensors observe an (unknown) deterministic signal with attenuation depending on the distance between the sensor and the (unknown) target positions, embedded in symmetric and unimodal noise. The fusion center receives quantized sensor observations through error-prone binary symmetric channels and is in charge of performing a more-accurate global decision. The resulting problem is a two-sided parameter testing with nuisance parameters (i.e., the target position) present only under the alternative hypothesis. After introducing the generalized likelihood ratio test for the problem, we develop a novel fusion rule corresponding to a generalized Rao test, based on Davies' framework, to reduce the computational complexity. Also, a rationale for threshold-optimization is proposed and confirmed by simulations. Finally, the aforementioned rules are compared in terms of performance and computational complexity.",
Ubii: Physical World Interaction Through Augmented Reality,"We describe a new set of interaction techniques that allow users to interact with physical objects through augmented reality (AR). Previously, to operate a smart device, physical touch is generally needed and a graphical interface is normally involved. These become limitations and prevent the user from operating a device out of reach or operating multiple devices at once. Ubii (Ubiquitous interface and interaction) is an integrated interface system that connects a network of smart devices together, and allows users to interact with the physical objects using hand gestures. The user wears a smart glass which displays the user interface in an augmented reality view. Hand gestures are captured by the smart glass, and upon recognizing the right gesture input, Ubii will communicate with the connected smart devices to complete the designated operations. Ubii supports common inter-device operations such as file transfer, printing, projecting, as well as device pairing. To improve the overall performance of the system, we implement computation offloading to perform the image processing computation. Our user test shows that Ubii is easy to use and more intuitive than traditional user interfaces. Ubii shortens the operation time on various tasks involving operating physical devices. The novel interaction paradigm attains a seamless interaction between the physical and digital worlds.",
The Use of a Multilabel Classification Framework for the Detection of Broken Bars and Mixed Eccentricity Faults Based on the Start-Up Transient,"In this paper, a data-driven approach for the classification of simultaneously occurring faults in an induction motor is presented. The problem is treated as a multilabel classification problem, with each label corresponding to one specific fault. The faulty conditions examined include the existence of a broken bar fault and the presence of mixed eccentricity with various degrees of static and dynamic eccentricity, while three “problem transformation” methods are tested and compared. For the feature extraction stage, the start-up current is exploited using two well-known time-frequency (scale) transformations. This is the first time that a multilabel framework is used for the diagnosis of co-occurring fault conditions using information coming from the start-up current of induction motors. The efficiency of the proposed approach is validated using simulation data with promising results irrespective of the selected time-frequency transformation.","Time-frequency analysis,
Bars,
Transient analysis,
Induction motors,
Continuous wavelet transforms,
Fault detection,
Informatics"
Multi-Frequency Measurement of Volatile Organic Compounds With a Radio-Frequency Interferometer,"We present a radio-frequency (RF) sensor and its measurement results of three volatile organic compounds (VOCs) at multiple frequency points from ~ 2 to ~ 11 GHz, which is a convenient range in our examination. The sensor is based on a simple RF interferometer and uses two coplanar waveguides (CPWs), A and B of 5 and 25 mm length, respectively, as VOC sensing electrodes. Approximately 70-nm-thick poly copolymer films are coated on CPW surfaces for VOC adsorption and concentration. It is shown that ethanol, acetone, and isopropyl (IPA) induce frequency-dependent RF responses, which are also VOC-dependent. Thus, the frequency-dependent properties provide a possible new approach for better VOC sensing selectivity. With CPW A, the limit-of-detections (LODs) are ~ 600 ppm for ethanol, ~ 270 ppm for acetone, and ~ 330 ppm for IPA at 9.29 GHz. With CPW B, the LODs are roughly four times better. These LODs are also better than most of other RF VOC sensor results. In the future work, it is promising to further improve RF sensitivity and selectivity significantly.","Frequency measurement,
Radio frequency,
Coplanar waveguides,
Polymers,
Sensitivity,
Sensor arrays"
Protocol Design and Game Theoretic Solutions for Device-to-Device Radio Resource Allocation,"Device-to-device (D2D) communication has been proposed to improve the resource efficiency and lighten the heavy load of the base station (BS) in Long-Term Evolution (LTE)-Advanced systems. In a D2D-enabled LTE-A system, the resource efficiency is primarily determined by D2D/cellular mode selection and resource allocation. However, the D2D channel quality, which is the key factor for the BS to allocate resources, cannot be learned directly by the BS, owing to the peculiarity of D2D communication. Rational user equipment (UE) will take advantage of the peculiarity to report their experienced D2D quality untruthfully for their selfish interests and, consequently, degrade system efficiency. This so-called unknown channel quality (UCQ) problem imposes a fatal impact on the resource efficiency and will limit the practicality of D2D communication. To overcome the UCQ problem, we propose to use game theory to analyze the peculiarity of D2D communication. In this paper, two practical D2D resource allocating protocols were investigated, and the system efficiencies were analyzed to show the potential performance degradation when the UCQ problem is not addressed. To circumvent the performance degradation caused by the UCQ problem, a contract-based mechanism and the corresponding algorithms were proposed to eliminate the UE's incentive of reporting untruthfully. Numerical and simulation results validated the feasibility and the effectiveness of our approach.","Resource management,
Protocols,
Interference,
Games,
Long Term Evolution,
Game theory,
Contracts"
State Estimation for the Individual and the Population in Mean Field Control With Application to Demand Dispatch,"This paper concerns state estimation problems in a mean field control setting. In a finite population model, the goal is to estimate the joint distribution of the population state and the state of a typical individual. The observation equations are a noisy measurement of the population. The general results are applied to demand dispatch for regulation of the power grid, based on randomized local control algorithms. In prior work by the authors it is shown that local control can be designed so that the aggregate of loads behaves as a controllable resource, with accuracy matching or exceeding traditional sources of frequency regulation. The operational cost is nearly zero in many cases. The information exchange between grid and load is minimal, but it is assumed in the overall control architecture that the aggregate power consumption of loads is available to the grid operator. It is shown that the Kalman filter can be constructed to reduce these communication requirements, and to provide the grid operator with accurate estimates of the mean and variance of quality of service (QoS) for an individual load.","Mathematical model,
Kalman filters,
Load modeling,
Sociology,
Statistics,
Noise measurement,
Aggregates"
Automatic Detection and Classification of Colorectal Polyps by Transferring Low-Level CNN Features From Nonmedical Domain,"Colorectal cancer (CRC) is a leading cause of cancer deaths worldwide. Although polypectomy at early stage reduces CRC incidence, 90% of the polyps are small and diminutive, where removal of them poses risks to patients that may outweigh the benefits. Correctly detecting and predicting polyp type during colonoscopy allows endoscopists to resect and discard the tissue without submitting it for histology, saving time, and costs. Nevertheless, human visual observation of early stage polyps varies. Therefore, this paper aims at developing a fully automatic algorithm to detect and classify hyperplastic and adenomatous colorectal polyps. Adenomatous polyps should be removed, whereas distal diminutive hyperplastic polyps are considered clinically insignificant and may be left in situ . A novel transfer learning application is proposed utilizing features learned from big nonmedical datasets with 1.4-2.5 million images using deep convolutional neural network. The endoscopic images we collected for experiment were taken under random lighting conditions, zooming and optical magnification, including 1104 endoscopic nonpolyp images taken under both white-light and narrowband imaging (NBI) endoscopy and 826 NBI endoscopic polyp images, of which 263 images were hyperplasia and 563 were adenoma as confirmed by histology. The proposed method identified polyp images from nonpolyp images in the beginning followed by predicting the polyp histology. When compared with visual inspection by endoscopists, the results of this study show that the proposed method has similar precision (87.3% versus 86.4%) but a higher recall rate (87.6% versus 77.0%) and a higher accuracy (85.9% versus 74.3%). In conclusion, automatic algorithms can assist endoscopists in identifying polyps that are adenomatous but have been incorrectly judged as hyperplasia and, therefore, enable timely resection of these polyps at an early stage before they develop into invasive cancer.",
Magnetic Induction-Based Simultaneous Wireless Information and Power Transfer for Single Information and Multiple Power Receivers,"Magnetic induction (MI)-based communication systems have gained increased attention in recent years. Typical applications for these systems lie in the area of wireless power transfer, near-field communication (NFC), and wireless sensor networks in challenging environments. In this paper, a system for simultaneous wireless information and power transfer (SWIPT) using MI-based signal transmission is designed for supporting one data stream and multiple parallel power streams. One of the possible applications for this scheme is an NFC-based access point. The overall system is optimized to guarantee a certain quality-of-service for the data stream as well as a maximum sum receive power for all power receivers (max-sum problem) or a maximum receive power for the worst power receiver (max-min problem), respectively. Both optimization problems turn out to be non-convex, such that the optimum solution cannot be found with limited computational complexity. Hence, we provide efficient suboptimal solutions. In this context, a convex approximation of the transmit power constraint in MI-based multiple-input multiple-output systems turns out to be very useful. A very high achievable power efficiency renders the proposed MI-based SWIPT system very promising.","Receivers,
Coils,
Array signal processing,
Couplings,
Resonant frequency,
Wireless sensor networks,
Radio transmitters"
Sensorless Low-Current Start-Up Strategy of 100-kW BLDC Motor With Small Inductance,"This paper focuses on the start-up strategy of a high-speed 100-kW brushless dc motor with small inductance using a voltage comparator. This paper includes three key technique contributions: 1) determining zero-speed positioning, 2) removing high-frequency disturbances, and 3) optimizing the controller parameters. The sensorless low-current start-up strategy is based on an amplification circuit: a low-pass filter circuit and a signal modulate circuit. The amplification circuit is used to amplify the amplitude of back electromotive force for detecting the rotor position at low speed, the low-pass filter circuit is used to remove high-frequency disturbances, and the signal modulate circuit is used to obtain the rotor position signal. A hysteresis control strategy is proposed against the load disturbance in the start-up stage. Experimental results show that the proposed sensorless start-up strategy can realize a low-current start-up.","Rotors,
Hysteresis motors,
Brushless DC motors,
Reluctance motors"
Data-Driven Adaptive Optimal Control of Connected Vehicles,"In this paper, a data-driven non-model-based approach is proposed for the adaptive optimal control of a class of connected vehicles that is composed of n human-driven vehicles only transmitting motional data and an autonomous vehicle in the tail receiving the broadcasted data from preceding vehicles by wireless vehicle-to-vehicle (V2V) communication devices. Considering the cases of range-limited V2V communication and input saturation, several optimal control problems are formulated to minimize the errors of distance and velocity and to optimize the fuel usage. By employing an adaptive dynamic programming technique, the optimal controllers are obtained without relying on the knowledge of system dynamics. The effectiveness of the proposed approaches is demonstrated via the online learning control of the connected vehicles in Paramics' traffic microsimulation.","Vehicles,
Connected vehicles,
Optimal control,
Vehicular ad hoc networks,
Vehicle dynamics,
Adaptive systems,
Fuels"
Mixed mmWave RF/FSO Relaying Systems Over Generalized Fading Channels With Pointing Errors,"This paper, for the first time, studies the performance of the mixed millimeter-wave radio frequency and free space optics in the context of the fifth-generation (5G) mobile backhaul networks. The considered system is expected to provide a high capacity and cost-effective backhaul networks to forward the massive traffic from a large number of small cells (e.g., picocells and femtocells) into the core network.","Radio frequency,
Rician channels,
Fading channels,
Computer architecture,
Signal to noise ratio,
Microprocessors,
Atmospheric modeling"
Dual-Band and Dual-Circularly Polarized Single-Layer Microstrip Array Based on Multiresonant Modes,"A planar dual-band array with orthogonal circular polarizations (CPs) in the two frequency bands is proposed in this communication. The array is implemented on a single-layer substrate and easy to be extended to the design of a larger array. A new antenna element for such an array is exploited by symmetrically loading stubs on the edges of a square patch. In this communication, two pairs of orthogonal modes of the patch, namely, TM10/TM01 and TM30/TM03, are excited simultaneously and used to realize different senses of CP radiation in the two bands. An equivalent transmission-line model of this patch is then developed to describe its working principle and design procedure. To validate its effectiveness, a 2 × 2-element array prototype operating at 2.53 and 3.59 GHz is designed and fabricated. Both the left- and right-hand CPs are obtained simultaneously in the dual bands, and the measured results are found to be in good agreement with the simulated ones. The measured radiation gains in the lower and higher bands are 10.8 and 12.5 dBic, respectively.","Dual band,
Resonant frequency,
Microstrip antenna arrays,
Microstrip,
Feeds"
Embedding Spatio-Temporal Information into Maps by Route-Zooming,"Analysis and exploration of spatio-temporal data such as traffic flow and vehicle trajectories have become important in urban planning and management. In this paper, we present a novel visualization technique called route-zooming that can embed spatio-temporal information into a map seamlessly for occlusion-free visualization of both spatial and temporal data. The proposed technique can broaden a selected route in a map by deforming the overall road network. We formulate the problem of route-zooming as a nonlinear least squares optimization problem by defining an energy function that ensures the route is broadened successfully on demand while the distortion caused to the road network is minimized. The spatio-temporal information can then be embedded into the route to reveal both spatial and temporal patterns without occluding the spatial context information. The route-zooming technique is applied in two instantiations including an interactive metro map for city tourism and illustrative maps to highlight information on the broadened roads to prove its applicability. We demonstrate the usability of our spatio-temporal visualization approach with case studies on real traffic flow data. We also study various design choices in our method, including the encoding of the time direction and choices of temporal display, and conduct a comprehensive user study to validate our embedded visualization design.","Roads,
Data visualization,
Context,
Trajectory,
Optimization,
Spatial databases,
Nonlinear distortion"
Sensor Pattern Noise Estimation Based on Improved Locally Adaptive DCT Filtering and Weighted Averaging for Source Camera Identification and Verification,"Photo response non-uniformity (PRNU) noise is a sensor pattern noise characterizing the imaging device. It has been broadly used in the literature for source camera identification and image authentication. The abundant information that the sensor pattern noise carries in terms of the frequency content makes it unique, and hence suitable for identifying the source camera and detecting image forgeries. However, the PRNU extraction process is inevitably faced with the presence of image-dependent information as well as other non-unique noise components. To reduce such undesirable effects, researchers have developed a number of techniques in different stages of the process, i.e., the filtering stage, the estimation stage, and the post-estimation stage. In this paper, we present a new PRNU-based source camera identification and verification system and propose enhancements in different stages. First, an improved version of the locally adaptive discrete cosine transform filter is proposed in the filtering stage. In the estimation stage, a new weighted averaging technique is presented. The post-estimation stage consists of concatenating the PRNUs estimated from color planes in order to exploit the presence of physical PRNU components in different channels. Experimental results on two image data sets acquired by various camera devices have shown a significant gain obtained with the proposed enhancements in each stage as well as the superiority of the overall system over related state-of-the-art systems.",
Discovery of Shared Semantic Spaces for Multiscene Video Query and Summarization,"The growing rate of public space closed-circuit television (CCTV) installations has generated a need for automated methods for exploiting video surveillance data, including scene understanding, query, behavior annotation, and summarization. For this reason, extensive research has been performed on surveillance scene understanding and analysis. However, most studies have considered single scenes or groups of adjacent scenes. The semantic similarity between different but related scenes (e.g., many different traffic scenes of a similar layout) is not generally exploited to improve any automated surveillance tasks and reduce manual effort. Exploiting commonality and sharing any supervised annotations between different scenes is, however, challenging due to the following reason: some scenes are totally unrelated and thus any information sharing between them would be detrimental, whereas others may share only a subset of common activities and thus information sharing is only useful if it is selective. Moreover, semantically similar activities that should be modeled together and shared across scenes may have quite different pixel-level appearances in each scene. To address these issues, we develop a new framework for distributed multiple-scene global understanding that clusters surveillance scenes by their ability to explain each other's behaviors and further discovers which subset of activities are shared versus scene specific within each cluster. We show how to use this structured representation of multiple scenes to improve common surveillance tasks, including scene activity understanding, cross-scene query-by-example, behavior classification with reduced supervised labeling requirements, and video summarization. In each case, we demonstrate how our multiscene model improves on a collection of standard single-scene models and a flat model of all scenes.","Surveillance,
Semantics,
Cameras,
Hidden Markov models,
Redundancy,
Computational modeling,
Layout"
Beamforming for Simultaneous Wireless Information and Power Transfer in Two-Way Relay Channels,"This paper studies the beamforming designs for simultaneous wireless information and power transfer systems in two-way relaying (TWR) channels. The system consists of two energy-constrained source nodes which employ the power splitting (PS) to receive the information and the energy simultaneously from the power-supply relay. To maximize the weighted sum energy subject to the constraints of the quality of service and the transmit powers, three well-known relaying protocols, i.e., amplify-and-forward, bit level XOR-based decode-and-forward (DF), and symbol level superposition coding-based DF, are considered. For each relaying protocol, we formulate the joint relay beamforming, the source transmit power, and the PS ratios optimization as a nonconvex quadratically constrained problem. To solve the complex nonconvex problem, we decouple the objective problem into two subproblems in which one is to optimize the beamforming vectors while another is to optimize the remaining parameters. We show that the optimal solution of each subproblem can be obtained in the closed-form expressions. The solution is finally obtained with the proposed convergent iterative algorithm. Extensive numerical results demonstrate the advantage of adapting the different relaying strategies and weighted factors to harvest energy in TWR channels.","Relays,
Protocols,
Array signal processing,
Wireless communication,
Optimization,
Energy harvesting,
MIMO"
Bayesian Networks in Fault Diagnosis,"Fault diagnosis is useful in helping technicians detect, isolate, and identify faults, and troubleshoot. Bayesian network (BN) is a probabilistic graphical model that effectively deals with various uncertainty problems. This model is increasingly utilized in fault diagnosis. This paper presents bibliographical review on use of BNs in fault diagnosis in the last decades with focus on engineering systems. This work also presents general procedure of fault diagnosis modeling with BNs; processes include BN structure modeling, BN parameter modeling, BN inference, fault identification, validation, and verification. The paper provides series of classification schemes for BNs for fault diagnosis, BNs combined with other techniques, and domain of fault diagnosis with BN. This study finally explores current gaps and challenges and several directions for future research.","Fault diagnosis,
Analytical models,
Probability,
Mathematical model,
Learning systems,
Inference algorithms"
A Deep Learning Scheme for Motor Imagery Classification based on Restricted Boltzmann Machines,"Motor imagery classification is an important topic in brain-computer interface (BCI) research that enables the recognition of a subject's intension to, e.g., implement prosthesis control. The brain dynamics of motor imagery are usually measured by electroencephalography (EEG) as nonstationary time series of low signal-to-noise ratio. Although a variety of methods have been previously developed to learn EEG signal features, the deep learning idea has rarely been explored to generate new representation of EEG features and achieve further performance improvement for motor imagery classification. In this study, a novel deep learning scheme based on restricted Boltzmann machine (RBM) is proposed. Specifically, frequency domain representations of EEG signals obtained via fast Fourier transform (FFT) and wavelet package decomposition (WPD) are obtained to train three RBMs. These RBMs are then stacked up with an extra output layer to form a four-layer neural network, which is named the frequential deep belief network (FDBN). The output layer employs the softmax regression to accomplish the classification task. Also, the conjugate gradient method and backpropagation are used to fine tune the FDBN. Extensive and systematic experiments have been performed on public benchmark datasets, and the results show that the performance improvement of FDBN over other selected state-of-the-art methods is statistically significant. Also, several findings that may be of significant interest to the BCI community are presented in this article.","Machine learning,
Electroencephalography,
Biological neural networks,
Frequency-domain analysis,
Feature extraction,
Training,
Benchmark testing"
Far-Field Pattern Tolerance Analysis of the Antenna-Radome System With the Material Thickness Error: An Interval Arithmetic Approach,"As the geometry thickness error of composite radome impacts the electromagnetic (EM) performance of the antenna-radome system, a novel interval arithmetic analytic approach to the analysis of the effect on average power pattern of antenna-radome system with the thickness error in the composite radome-based is proposed. The thickness error of radome's composite material is modeled as interval-valued errors. The link between the interval of thickness error and the interval power pattern along with some main EM characteristics (sidelobe level, peak power, and half-power beamwidth) expressed as intervals are efficiently constructed. Some comparisons with measured and simulated results reported in the state-of-the-art literature, experiment data and Monte Carlo (MC) method result serve as a way to validate the interval analysis (IA)-based method. Some numerical examples are reported to reveal the effect of the main geometric properties (i.e., location, size, width, and midpoint of the error interval) of the thickness error interval on power pattern. The obtained results show that the proposed IA-based approach offers tangible advantages and exhibits effectiveness versus some traditional statistical techniques (e.g., MC method).","Antenna radiation patterns,
Monte Carlo methods,
Degradation,
Aperture antennas,
Material properties"
Mobile Service Selection for Composition: An Energy Consumption Perspective,"Due to the limits of battery capacity of mobile devices, how to select cloud services to invoke in order to reduce energy consumption in mobile environments is becoming a critical issue. This paper addresses the problem of mobile service selection for composition in terms of energy consumption. It formally models this problem and constructs energy consumption computation models. Energy consumption aggregation rules for composite services with different structures are presented. It adopts the genetic algorithm to resolve it. A replanning mechanism is also proposed to deal with the changeable conditions and user behavior. A series of experiments are conducted to evaluate the performance of our method. The results show that our service selection method significantly outperforms traditional methods. Even if the conditions or user behavior is changeable, this method is still effective to recommend services. Moreover, the service selection method performs good scalability as the experimental scale increases.","Energy consumption,
Mobile communication,
Quality of service,
Mobile handsets,
Web services,
Computational modeling,
Data communication"
Fundamentals of Modeling Finite Wireless Networks Using Binomial Point Process,"Modeling the locations of nodes as a uniform binomial point process, we present a generic mathematical framework to characterize the performance of an arbitrarily located reference receiver in a finite wireless network. Different from most of the prior works where the serving transmitter (TX) is located at the fixed distance from the reference receiver, we consider two general TX-selection policies: 1) uniform TX-selection: the serving node is chosen uniformly at random from amongst all transmitting nodes and 2) k-closest TX-selection: the serving node is the kth closest node (out of all transmitting nodes) to the reference receiver. The key intermediate step in our analysis is the derivation of a new set of distance distributions that lead not only to the tractable analysis of coverage probability but also enable the analysis of wide range of classical and currently trending problems in wireless networks. Using this new set of distance distributions, we further investigate the diversity loss due to SIR correlation in a finite network. We then obtain the optimal number of links that can be simultaneously activated to maximize network spectral efficiency. Finally, we evaluate optimal caching probability to maximize the total hit probability in cache-enabled finite networks.",
End-to-End Comparative Attention Networks for Person Re-Identification,"Person re-identification across disjoint camera views has been widely applied in video surveillance yet it is still a challenging problem. One of the major challenges lies in the lack of spatial and temporal cues, which makes it difficult to deal with large variations of lighting conditions, viewing angles, body poses, and occlusions. Recently, several deep-learning-based person re-identification approaches have been proposed and achieved remarkable performance. However, most of those approaches extract discriminative features from the whole frame at one glimpse without differentiating various parts of the persons to identify. It is essentially important to examine multiple highly discriminative local regions of the person images in details through multiple glimpses for dealing with the large appearance variance. In this paper, we propose a new soft attention-based model, i.e., the end-to-end comparative attention network (CAN), specifically tailored for the task of person re-identification. The end-to-end CAN learns to selectively focus on parts of pairs of person images after taking a few glimpses of them and adaptively comparing their appearance. The CAN model is able to learn which parts of images are relevant for discerning persons and automatically integrates information from different parts to determine whether a pair of images belongs to the same person. In other words, our proposed CAN model simulates the human perception process to verify whether two images are from the same person. Extensive experiments on four benchmark person re-identification data sets, including CUHK01, CHUHK03, Market-1501, and VIPeR, clearly demonstrate that our proposed end-to-end CAN for person re-identification outperforms well established baselines significantly and offer the new state-of-the-art performance.",
Electronic Sleep Stage Classifiers: A Survey and VLSI Design Methodology,"First, existing sleep stage classifier sensors and algorithms are reviewed and compared in terms of classification accuracy, level of automation, implementation complexity, invasiveness, and targeted application. Next, the implementation of a miniature microsystem for low-latency automatic sleep stage classification in rodents is presented. The classification algorithm uses one EMG (electromyogram) and two EEG (electroencephalogram) signals as inputs in order to detect REM (rapid eye movement) sleep, and is optimized for low complexity and low power consumption. It is implemented in an on-board low-power FPGA connected to a multi-channel neural recording IC, to achieve low-latency (order of 1 ms or less) classification. Off-line experimental results using pre-recorded signals from nine mice show REM detection sensitivity and specificity of 81.69% and 93.86%, respectively, with the maximum latency of 39 μs. The device is designed to be used in a non-disruptive closed-loop REM sleep suppression microsystem, for future studies of the effects of REM sleep deprivation on memory consolidation.",
Unidirectional Dual-Band Stacked Patch Antenna With Independent Frequency Reconfiguration,"A novel dual-band frequency-reconfigurable stacked patch antenna is presented. The antenna comprises two stacked square patches. Each patch is divided into two rectangular portions by a gap, and a pair of varactor diodes is introduced to bridge the gap. By changing the reverse bias voltages across the two pairs of varactor diodes, the antenna can operate at dual frequency bands with independent frequency tuning. A fully functional prototype is fabricated and characterized. It exhibits a continuously dual frequency-tunable characteristic, from 1.68 to 1.93 GHz for the low band and from 2.11 to 2.51 GHz for the high band. Well-controlled unidirectional radiation patterns are achieved at all operating frequencies. To the best knowledge of the authors, this is the first dual-band reconfigurable patch antenna with an independent frequency tuning ability. The dual-band frequency selective feature makes the antenna potentially suitable for future wireless communication systems, such as cognitive radio.","Varactors,
Antenna measurements,
Dual band,
Antenna radiation patterns,
Gain measurement,
Gain"
Effect of RF Interference on the Security-Reliability Tradeoff Analysis of Multiuser Mixed RF/FSO Relay Networks With Power Allocation,"In this paper, the impact of radio frequency (RF) cochannel interference (CCI) on the performance of multiuser mixed RF/free-space optical (FSO) relay network with opportunistic user scheduling under eavesdropping attack is studied. The considered system includes multiple users, one decode-and forward relay, one destination, and an eavesdropper. In the analysis, the RF/FSO channels follow Nakagami-m/Gamma-Gamma fading models, respectively, with pointing errors on the FSO link. Exact closed-form expression for the system outage probability is derived. Then, an asymptotic expression for the outage probability is obtained at the high signal-to-interference-plus-noise ratio regime to get more insights on the system performance. Moreover, the obtained results are used to find the optimal transmission power in different turbulence conditions. The secrecy performance is studied in the presence of CCI at both the authorized relay and eavesdropper, where closed-form expressions are derived for the intercept probability. The physical layer security performance is enhanced using cooperative jamming models, where new closed-form expressions are derived for the intercept probability. Another power allocation optimization problem is formulated to find the optimal transmission and jamming powers. The derived analytical formulas are supported by numerical results to clarify the main contributions of this paper.","Radio frequency,
Closed-form solutions,
Security,
Resource management,
Jamming,
Relay networks (telecommunications)"
Robust Relay Selection for Large-Scale Energy-Harvesting IoT Networks,"We consider the relay selection problem in large-scale energy harvesting (EH) networks. It is known that if channel state information (CSI) is available at EH relays, a diversity order equal to the number of relays can be obtained, however, at the penalty of a feedback overhead (necessary to obtain accurate CSI) which is not suitable for energy-limited devices intended, e.g., for Internet-of-Things applications. In this paper, we therefore propose a new EH relay selection scheme which is based on the residual energy at each relay's battery, and on information on the distribution of the channels between relays and the destination. The method thus minimizes both the outage probability and the feedback cost. Where previous work relay selection based on channel distribution information consider only small-scale fading distribution, we employ a stochastic geometry approach to consider jointly the geometrical distribution (i.e., large-scale fading) and small-scale fading yielding a simple relay selection criterion that furthermore utilizes only rough information on the relay's location, i.e., an ordinal number from the destination. The outage probability of the proposed relay selection scheme is analytically derived, and the achievable diversity order of the proposed approach is investigated. Computer simulations confirm our theoretical analyses and show that our approach is robust against errors in the estimation of the distances between nodes.",
DaSCE: Data Security for Cloud Environment with Semi-Trusted Third Party,"Off-site data storage is an application of cloud that relieves the customers from focusing on data storage system. However, outsourcing data to a third-party administrative control entails serious security concerns. Data leakage may occur due to attacks by other users and machines in the cloud. Wholesale of data by cloud service provider is yet another problem that is faced in the cloud environment. Consequently, high-level of security measures is required. In this paper, we propose data security for cloud environment with semi-trusted third party (DaSCE), a data security system that provides (a) key management (b) access control, and (c) file assured deletion. The DaSCE utilizes Shamir's (k, n) threshold scheme to manage the keys, where k out of n shares are required to generate the key. We use multiple key managers, each hosting one share of key. Multiple key managers avoid single point of failure for the cryptographic keys. We (a) implement a working prototype of DaSCE and evaluate its performance based on the time consumed during various operations, (b) formally model and analyze the working of DaSCE using high level petri nets (HLPN), and (c) verify the working of DaSCE using satisfiability modulo theories library (SMT-Lib) and Z3 solver. The results reveal that DaSCE can be effectively used for security of outsourced data by employing key management, access control, and file assured deletion.",
Variability-Aware Analysis of Hybrid MTJ/CMOS Circuits by a Micromagnetic-Based Simulation Framework,"Magnetic tunnel junctions (MTJs) are attracting an increasing interest due to their potentiality for high-density nonvolatile memories. However, some issues need to be opportunely considered in the design and optimization of hybrid MTJ/CMOS circuits, such as the stochastic nature of the MTJ switching, the high write energy consumption and the susceptibility to process variations. In this paper, we evaluate the impact of both MTJ and CMOS variability on the performance of basic hybrid MTJ/CMOS circuits in state-of-the-art nanoscale technologies. To this purpose, we exploit a simulation framework combining micromagnetic and electrical simulations. Full micromagnetic simulations are used to predict the MTJ behavior in terms of magnetoresistance-current hysteresis loop and statistical distribution of the switching delay as a function of the applied current. Those data are used to set up a look-up-table-based MTJ Verilog-A model to be used in commercial electrical simulators. Considering an MTJ with a diameter of 30 nm and a 28-nm fully-depleted silicon-on-insulator CMOS technology, we have exploited the above simulation framework to perform a variability-aware analysis on the write operation of a 1-MTJ writing circuit for nonvolatile flip-flops and a 256 × 256 STT-MRAM array. Our results show that the voltage scaling can be a promising approach for energy minimization in hybrid MTJ/CMOS circuits at the expense of larger area.","Magnetic tunneling,
Integrated circuit modeling,
Micromagnetics,
Semiconductor device modeling,
Switches,
Hardware design languages,
Computational modeling"
Submillimolar Detection of Adenosine Monophosphate Using Graphene-Based Electrochemical Aptasensor,"In this paper, we present a successful demonstration of a graphene-based field-effect-transistor-like electrochemical nanobiosensor to accurately detect ultralow concentrations of adenosine monophosphate (AMP). Graphene being a two-dimensional material is a suitable option as a sensing element due to its biocompatibility and large surface area. It has also demonstrated surface binding chemistries as well as its ability to serve as a conducting channel. A short 20-base deoxyribonucleic acid (DNA) aptamer is used as the sensing element to ensure that the interaction between the analyte and the aptamer occurs within the Debye length of the electrolyte. The sensor is found to be nonlinear in nature and sensitive in the picomolar (pM) and nanomolar (nM) concentrations of AMP. The linear region of operation is found to be 1 nM-100 μM and percentage change in drain current in this concentration region is calculated as 1.56%/decade. A minimum concentration of 10 pM of AMP has been detected using this type of sensor.",
Facial Expression Recognition Utilizing Local Direction-Based Robust Features and Deep Belief Network,"Emotional health plays very vital role to improve people's quality of lives, especially for the elderly. Negative emotional states can lead to social or mental health problems. To cope with emotional health problems caused by negative emotions in daily life, we propose efficient facial expression recognition system to contribute in emotional healthcare system. Thus, facial expressions play a key role in our daily communications, and recent years have witnessed a great amount of research works for reliable facial expressions recognition (FER) systems. Therefore, facial expression evaluation or analysis from video information is very challenging and its accuracy depends on the extraction of robust features. In this paper, a unique feature extraction method is presented to extract distinguished features from the human face. For person independent expression recognition, depth video data is used as input to the system where in each frame, pixel intensities are distributed based on the distances to the camera. A novel robust feature extraction process is applied in this work which is named as local directional position pattern (LDPP). In LDPP, after extracting local directional strengths for each pixel such as applied in typical local directional pattern (LDP), top directional strength positions are considered in binary along with their strength sign bits. Considering top directional strength positions with strength signs in LDPP can differentiate edge pixels with bright as well as dark regions on their opposite sides by generating different patterns whereas typical LDP only considers directions representing the top strengths irrespective of their signs as well as position orders (i.e., directions with top strengths represent 1 and rest of them 0), which can generate the same patterns in this regard sometimes. Hence, LDP fails to distinguish edge pixels with opposite bright and dark regions in some cases which can be overcome by LDPP. Moreover, the LDPP capabilities are extended through principal component analysis (PCA) and generalized discriminant analysis (GDA) for better face characteristic illustration in expression. The proposed features are finally applied with deep belief network (DBN) for expression training and recognition.","Face,
Feature extraction,
Cameras,
Face recognition,
Principal component analysis,
Robustness,
Training"
Intelligent Critic Control With Disturbance Attenuation for Affine Dynamics Including an Application to a Microgrid System,"In this paper, a computationally efficient framework for intelligent critic control design and application of continuous-time input-affine systems is established with the purpose of disturbance attenuation. The described problem is formulated as a two-player zero-sum differential game and the adaptive critic mechanism with intelligent component is employed to solve the minimax optimization problem. First, a neural identifier is developed to reconstruct the unknown dynamical information incorporating stability analysis. Next, the optimal control law and the worst-case disturbance law are designed by introducing and tuning a critic neural network. Moreover, the closed-loop system is proved to possess the uniform ultimate boundedness. At last, the present method is applied to a smart microgrid and then is further adopted to control a general nonlinear system via simulation, thereby substantiating the performance of disturbance attenuation.","Attenuation,
Optimal control,
Neural networks,
Cost function,
Game theory,
Games,
Dynamic programming"
Predictive Control of Cascaded H-Bridge Converters Under Unbalanced Power Generation,This paper presents a predictive control strategy for grid-connected cascaded H-bridge (CHB) converters under unbalanced power generation among each converter phase. The proposed controller belongs to the finite-control-set model predictive control (FCS-MPC) family and is designed to extract unbalanced power from each CHB converter phase while providing balanced power to the grid. The key novelty of this strategy lies in the way the unbalanced power generation among the phases is explicitly considered into the optimal control problem. Power balance is achieved by enforcing the CHB converter to work with a suitable zero-sequence voltage component. The proposed predictive controller is directly formulated in the original abc-framework to account for the common-mode voltage. Simulation and experimental results are provided to verify the effectiveness of the proposed FCS-MPC strategy.,"Predictive control,
Power generation,
Voltage control,
Cost function,
Standards,
Optimal control"
Trust Adaptation Leads to Lower Control Effort in Shared Control of Crane Automation,"We present a shared-control framework predicated on a measure of trust in the operator, that is calculated automatically based on the quality of the interactions between a human and autonomous system. This measure of trust is built upon a control-theoretic foundation that rewards stable operation of the system to give more trusted users additional control authority. The level of control authority is used to modify the human input, and as a result, we observe a minimization of the required effort of the controller. We validate this work within a planar crane environment with a receding horizon controller to assist with the regulation of the system dynamics. The human defines the reference trajectory for the controller. In an experimental study users navigate a suspended payload through a set of maze configurations. We find that adaptation of the trust metric over time provides the benefit of substantially ( p <; 0.01
) improving the automated system's ability to modulate the user's input, resulting in stable reference trajectories that require less effort to track. In effect, the human and automation spend less time fighting each other during task execution, suggesting that the automated system and user each have a better understanding of the other's ability.","Trajectory,
Optimization,
Measurement,
Aerodynamics,
Robots,
Vehicle dynamics"
Trapdoor computational fuzzy extractors and stateless cryptographically-secure physical unclonable functions,"We present a fuzzy extractor whose security can be reduced to the hardness of Learning Parity with Noise (LPN) and can efficiently correct a constant fraction of errors in a biometric source with a “noise-avoiding trapdoor.” Using this computational fuzzy extractor, we present a stateless construction of a cryptographically-secure Physical Unclonable Function. Our construct requires no non-volatile (permanent) storage, secure or otherwise, and its computational security can be reduced to the hardness of an LPN variant under the random oracle model. The construction is “stateless,” because there is no information stored between subsequent queries, which mitigates attacks against the PUF via tampering. Moreover, our stateless construction corresponds to a PUF whose outputs are free of noise because of internal error-correcting capability, which enables a host of applications beyond authentication. We describe the construction, provide a proof of computational security, analysis of the security parameter for system parameter choices, and present experimental evidence that the construction is practical and reliable under a wide environmental range.","Protocols,
Ring oscillators,
Authentication,
Silicon,
Manufacturing,
Error correction"
PWM and PFM Hybrid Control Method for LLC Resonant Converters in High Switching Frequency Operation,"High switching frequency is an effective method to improve power density for LLC resonant converters. However, conventional digital controllers, such as general-purpose digital signal processors and microprocessors, have limited frequency resolution, which induces high primary- and secondary-side current variation and leads to poor output voltage regulation. In this paper, a hybrid control method combining pulse frequency modulation (PFM) and pulse width modulation is proposed to overcome the limited frequency resolution issue. The proposed hybrid control method focuses on steady-state operation, and its operating principles are introduced and analyzed. In addition, the proper magnetizing inductance and dead time duration are derived to ensure that the power mosfets achieve zero voltage switching with the proposed control method. The improved voltage regulation performance is compared with the conventional PFM control and verified through simulation and experimental results using a 240 W prototype converter operating at a switching frequency of 1 MHz.","Switching frequency,
Voltage control,
Resonant frequency,
Digital signal processing,
Pulse width modulation,
Control systems,
Frequency control"
Dynamic Privacy Pricing: A Multi-Armed Bandit Approach With Time-Variant Rewards,"Recently, the conflict between exploiting the value of personal data and protecting individuals' privacy has attracted much attention. Personal data market provides a promising solution to this conflict, while determining the price of privacy is a tough issue. In this paper, we study the pricing problem in a setting where a data collector sequentially buys data from multiple data owners whose valuations of privacy are randomly drawn from an unknown distribution. To maximize the total payoff, the collector needs to dynamically adjust the prices offered to owners. We model the sequential decision-making problem of the collector as a multi-armed bandit problem with each arm representing a candidate price. Specifically, the privacy protection technique adopted by the collector is taken into account. Protecting privacy generally causes a negative effect on the value of data, and this effect is embodied by the time-variant distributions of the rewards associated with arms. Based on the classic upper confidence bound policy, we propose two learning policies for the bandit problem. The first policy estimates the expected reward of a price by counting how many times the price has been accepted by data owners. The second policy treats the time-variant data value as a context and uses ridge regression to estimate the rewards in different contexts. Simulation results on real-world data demonstrate that by applying the proposed policies, the collector can get a payoff which is close to that he can get by setting a fixed price, which is the best in hindsight, for all data owners.",
On the Security of a Privacy-Aware Authentication Scheme for Distributed Mobile Cloud Computing Services,"Recently, Tsai and Lo proposed a privacy aware authentication scheme for distributed mobile cloud computing services. It is claimed that the scheme achieves mutual authentication and withstands all major security threats. However, we first identify that their scheme fails to achieve mutual authentication, because it is vulnerable to the service provider impersonation attack. Beside this major defect, it also suffers from some minor design flaws, including the problem of biometrics misuse, wrong password, and fingerprint login, no user revocation facility when the smart card is lost/stolen. Some suggestions are provided to avoid these design flaws in the future design of authentication schemes.","Authentication,
Mobile communication,
Biometrics (access control),
Cloud computing,
Smart cards,
Silicon"
Illumination Variation-Resistant Video-Based Heart Rate Measurement Using Joint Blind Source Separation and Ensemble Empirical Mode Decomposition,"Recent studies have demonstrated that heart rate (HR) could be estimated using video data [e.g., exploring human facial regions of interest (ROIs)] under wellcontrolled conditions. However, in practice, the pulse signals may be contaminated by motions and illumination variations. In this paper, tackling the illumination variation challenge, we propose an illumination-robust framework using joint blind source separation (JBSS) and ensemble empirical mode decomposition (EEMD) to effectively evaluate HR from webcam videos. The framework takes the hypotheses that both facial ROI and background ROI have similar illumination variations. The background ROI is then considered as a noise reference sensor to denoise the facial signals by using the JBSS technique to extract the underlying illumination variation sources. Further, the reconstructed illumination-resisted green channel of the facial ROI is detrended and decomposed into a number of intrinsic mode functions using EEMD to estimate the HR. Experimental results demonstrated that the proposed framework could estimate HR more accurately than the state-of-the-art methods. The Bland-Altman plots showed that it led to better agreement with HR ground truth with the mean bias 1.15 beats/min (bpm), with 95% limits from -15.43 to 17.73 bpm, and the correlation coefficient 0.53. This study provides a promising solution for realistic noncontact and robust HR measurement applications.","Lighting,
Heart rate,
Biomedical measurement,
Pollution measurement,
Skin,
Robustness,
Face"
Proprioceptive Actuator Design in the MIT Cheetah: Impact Mitigation and High-Bandwidth Physical Interaction for Dynamic Legged Robots,"Designing an actuator system for highly dynamic legged robots has been one of the grand challenges in robotics research. Conventional actuators for manufacturing applications have difficulty satisfying design requirements for high-speed locomotion, such as the need for high torque density and the ability to manage dynamic physical interactions. To address this challenge, this paper suggests a proprioceptive actuation paradigm that enables highly dynamic performance in legged machines. Proprioceptive actuation uses collocated force control at the joints to effectively control contact interactions at the feet under dynamic conditions. Modal analysis of a reduced leg model and dimensional analysis of DC motors address the main principles for implementation of this paradigm. In the realm of legged machines, this paradigm provides a unique combination of high torque density, high-bandwidth force control, and the ability to mitigate impacts through backdrivability. We introduce a new metric named the “impact mitigation factor” (IMF) to quantify backdrivability at impact, which enables design comparison across a wide class of robots. The MIT Cheetah leg is presented, and is shown to have an IMF that is comparable to other quadrupeds with series springs to handle impact. The design enables the Cheetah to control contact forces during dynamic bounding, with contact times down to 85 ms and peak forces over 450 N. The unique capabilities of the MIT Cheetah, achieving impact-robust force-controlled operation in high-speed three-dimensional running and jumping, suggest wider implementation of this holistic actuation approach.",
Color Scheme Adaptation to Enhance User Experience on Smartphone Displays Leveraging Ambient Light,"With the rapid development of information technology, mobile devices have exhibited increasing popularity in recent years. To support the anytime-anywhere service model of mobile devices, one important problem related to the screen display arises when using these devices (e.g., smartphone and tablet) under various lighting conditions. On one hand, it is hard for users to see the display clearly under strong lighting conditions (e.g., sunlight). On the other hand, the screen appears dazzling under weak lighting conditions. This problem related to the mobile device display can significantly degrade user experience and undermine the successful deployment of the anytime-anywhere mobile service model. Existing solutions mainly focus on the automatic adjustment of brightness level under different light conditions. We show that merely utilizing brightness level to solve the display problem is not enough to maintain the user experience under both strong and weak lighting scenarios through experimenting with over 200 volunteers. In this work, we take a different approach by investigating automatic color scheme adjustment to improve user experience. We find that Readability, Comfort level, and Similarityare major factors that contribute to user experience. In recognizing these problems, we propose a system, ColorVert, which utilizes the DKL color space to adaptively transform color schemes by sensing ambient light to improve user experience under various lighting scenarios. Our experimental evaluation with over 200 precipitants and various mobile devices demonstrates that ColorVert is more effective in both maintaining as well as improving user experience compared with the existing automatic brightness adjustment system.",
Simulation Study of Large-Scale Charge Sharing Mitigation Using Seamless Guard Band,"In this paper, a novel seamless guard band (SGB) technique for charge sharing mitigation is studied using 3-D TCAD numerical simulations. The simulations results in 65-nm twin-well bulk CMOS technology indicate that the SGB technique can not only mitigate the single-event transient pulsewidth greatly but also mitigate the charge sharing between logical nodes or logical cells significantly. The simulation results also indicate that the SGB technique is superior to the conventional guard band (GB) technique, for it is more beneficial for parasitic bipolar effect mitigation. Using SGB technique, the single-event doubletransient (SEDT) generation is mitigated completely under low LET particle (LET ≤ 40 MeV· cm2/mg) radiation, and the SEDT pulsewidth is mitigated > 50% even with the LET of 80 MeV · cm2/mg, which is > 25% from GB technique. Finally, the SGB technique can be applied to the construction of a radiation-hardened standard cell library conveniently, and its area penalty is 1-1.67 ×, which is the same with that of the GB technique.",
Many-Objective Evolutionary Algorithms Based on Coordinated Selection Strategy,"Selection strategy, including mating selection and environmental selection, is a key ingredient in the design of evolutionary multiobjective optimization algorithms. Existing approaches, which have shown competitive performance in low-dimensional multiobjective optimization problems with two or three objectives, often encounter considerable challenges in many-objective optimization, where the number of objectives exceeds 3. This paper first provides a comprehensive analysis on the selection strategies in the current evolutionary many-objective optimization algorithms. Afterward, we propose a coordinated selection strategy to improve the performance of evolutionary algorithms in many-objective optimization. This selection strategy considers three crucial factors: 1) the new mating selection criterion considers both the quality of each selected parent and the effectiveness of the combination of selected parents; 2) the new environmental selection criterion directly focuses on the performance of the whole population rather than single individual alone; and 3) both selection steps are complement to each other and the coordination between them in the evolutionary process can achieve a better performance than each of them used individually. Furthermore, in order to handle the curse of dimensionality in many-objective optimization problems, a new convergence measure by distance and a new diversity measure by angle are developed in both selection steps. Experimental results on both DTLZ and WFG benchmark functions demonstrate the superiority of the proposed algorithm in comparison with six state-of-the-art designs in terms of both solution quality and computational efficiency.","Optimization,
Convergence,
Evolutionary computation,
Sociology,
Statistics,
Algorithm design and analysis,
Estimation"
Backstepping-Based Lyapunov Function Construction Using Approximate Dynamic Programming and Sum of Square Techniques,"In this paper, backstepping for a class of block strict-feedback nonlinear systems is considered. Since the input function could be zero for each backstepping step, the backstepping technique cannot be applied directly. Based on the assumption that nonlinear systems are polynomials, for each backstepping step, Lypunov function can be constructed in a polynomial form by sum of square (SOS) technique. The virtual control can be obtained by the Sontag feedback formula, which is equivalent to an optimal control-the solution of a Hamilton-Jacobi-Bellman equation. Thus, approximate dynamic programming (ADP) could be used to estimate value functions (Lyapunov functions) instead of SOS. Through backstepping technique, the control Lyapunov function (CLF) of the full system is constructed finally making use of the strict-feedback structure and a stabilizable controller can be obtained through the constructed CLF. The contributions of the proposed method are twofold. On one hand, introducing ADP into backstepping can broaden the application of the backstepping technique. A class of block strict-feedback systems can be dealt by the proposed method and the requirement of nonzero input function for each backstepping step can be relaxed. On the other hand, backstepping with surface dynamic control actually reduces the computation complexity of ADP through constructing one part of the CLF by solving semidefinite programming using SOS. Simulation results verify contributions of the proposed method.","Backstepping,
Artificial neural networks,
Optimal control,
Lyapunov methods,
Dynamic programming,
Nonlinear systems,
Programming"
Annotation Graphs: A Graph-Based Visualization for Meta-Analysis of Data Based on User-Authored Annotations,"User-authored annotations of data can support analysts in the activity of hypothesis generation and sensemaking, where it is not only critical to document key observations, but also to communicate insights between analysts. We present annotation graphs, a dynamic graph visualization that enables meta-analysis of data based on user-authored annotations. The annotation graph topology encodes annotation semantics, which describe the content of and relations between data selections, comments, and tags. We present a mixed-initiative approach to graph layout that integrates an analyst's manual manipulations with an automatic method based on similarity inferred from the annotation semantics. Various visual graph layout styles reveal different perspectives on the annotation semantics. Annotation graphs are implemented within C8, a system that supports authoring annotations during exploratory analysis of a dataset. We apply principles of Exploratory Sequential Data Analysis (ESDA) in designing C8, and further link these to an existing task typology in the visualization literature. We develop and evaluate the system through an iterative user-centered design process with three experts, situated in the domain of analyzing HCI experiment data. The results suggest that annotation graphs are effective as a method of visually extending user-authored annotations to data meta-analysis for discovery and organization of ideas.","Data visualization,
Semantics,
Layout,
Visualization,
Human computer interaction,
Data analysis,
Manuals"
GreenCoMP: Energy-Aware Cooperation for Green Cellular Networks,"Switching off base stations (BSs) is an effective and efficient energy-saving solution for green cellular networks. The previous works focus mainly on when to switch off BSs without sacrificing the traffic demands of current active users, and then enlarge the coverage of the stay-on cells to cover as many users as possible. Based on this objective, both constant power and transmission power of each BS become the major energy consumption sources. However, the transmission powers of enlarged cells, which have not been taken into account in previous research, are not negligible as compared to other energy consumption sources. To tackle this problem, we observe that the transmission power of one specific BS could be reduced via cooperation among two or more BSs, which is typically used to improve the throughput or enhance the spectrum efficiency in wireless systems. The challenges come mainly from how to jointly consider which BSs to switch off and how to cooperate among active-mode BSs. In this paper, we design energy-aware cooperation strategies that ensure that our system is energy-saving while satisfying user demands. To cope with sleep-mode BSs and perform cooperation among active BSs, we formulate this problem as a binary integer programming problem, and prove it is NP-hard. Based on our formulation, we derive a performance lower bound for this problem via Lagrangian Relaxation with search enumeration. Furthermore, we propose two heuristic algorithms accounting for the properties of energy savings and the constraints of bandwidth resources. The simulation results show that our algorithms outperform pure power control mechanisms that do not consider the transmission power and pure cooperation without power control in terms of the total consumed energy. We also observe that larger cooperative size does not imply a better strategy under different scenarios. Compared to the total consumed energy given that all BSs are turned on, our algorithms can save up to 60 percent of energy. This demonstrates that our methods are indeed efficient energy-saving cooperation strategies for green cellular networks.",
Multiagent-Based Resource Allocation for Energy Minimization in Cloud Computing Systems,"Cloud computing has emerged as a very flexible service paradigm by allowing users to require virtual machine (VM) resources on-demand and allowing cloud service providers (CSPs) to provide VM resources via a pay-as-you-go model. This paper addresses the CSP's problem of efficiently allocating VM resources to physical machines (PMs) with the aim of minimizing the energy consumption. Traditional energy-aware VM allocations either allocate VMs to PMs in a centralized manner or implement VM migrations for energy reduction without considering the migration cost in cloud computing systems. We address these two issues by introducing a decentralized multiagent (MA)-based VM allocation approach. The proposed MA works by first dispatching a cooperative agent to each PM to assist the PM in managing VM resources. Then, an auction-based VM allocation mechanism is designed for these agents to decide the allocations of VMs to PMs. Moreover, to tackle system dynamics and avoid incurring prohibitive VM migration overhead, a local negotiation-based VM consolidation mechanism is devised for the agents to exchange their assigned VMs for energy cost saving. We evaluate the efficiency of the MA approach by using both static and dynamic simulations. The static experimental results demonstrate that the MA can incur acceptable computation time to reduce system energy cost compared with traditional bin packing and genetic algorithm-based centralized approaches. In the dynamic setting, the energy cost of the MA is similar to that of benchmark global-based VM consolidation approaches, but the MA largely reduces the migration cost.","Resource management,
Cloud computing,
Computational modeling,
Quality of service,
Minimization,
Dynamic scheduling,
Biological cells"
Quadratic Model Predictive Control Including Input Cardinality Constraints,"This note addresses the problem of feedback control with a constrained number of active inputs. This problem is known as sparse control. Specifically, we describe a novel quadratic model predictive control strategy that guarantees sparsity by bounding directly the ℓ0-norm of the control input vector at each control horizon instant. Besides this sparsity constraint, bounded constraints are also imposed on both control input and system state. Under this scenario, we provide sufficient conditions for guaranteeing practical stability of the closed-loop. We transform the combinatorial optimization problem into an equivalent optimization problem that does not consider relaxation in the cardinality constraints. The equivalent optimization problem can be solved utilizing standard nonlinear programming toolboxes that provides the input control sequence corresponding to the global optimum.",
Sleep Apnea Detection Based on Thoracic and Abdominal Movement Signals of Wearable Piezoelectric Bands,"Physiologically, the thoracic (THO) and abdominal (ABD) movement signals, captured using wearable piezoelectric bands, provide information about various types of apnea, including central sleep apnea (CSA) and obstructive sleep apnea (OSA). However, the use of piezoelectric wearables in detecting sleep apnea events has been seldom explored in the literature. This study explored the possibility of identifying sleep apnea events, including OSA and CSA, by solely analyzing one or both the THO and ABD signals. An adaptive nonharmonic model was introduced to model the THO and ABD signals, which allows us to design features for sleep apnea events. To confirm the suitability of the extracted features, a support vector machine was applied to classify three categories - normal and hypopnea, OSA, and CSA. According to a database of 34 subjects, the overall classification accuracies were on average 75.9% ± 11.7% and 73.8% ± 4.4%, respectively, based on the cross validation. When the features determined from the THO and ABD signals were combined, the overall classification accuracy became 81.8% ± 9.4%. These features were applied for designing a state machine for online apnea event detection. Two event-by-event accuracy indexes, S and I, were proposed for evaluating the performance of the state machine. For the same database, the S index was 84.01% ± 9.06% and the I index was 77.21% ± 19.01%. The results indicate the considerable potential of applying the proposed algorithm to clinical examinations for both screening and homecare purposes.",
Linear Processing for Intercarrier Interference in OFDM Index Modulation Based on Capacity Maximization,"In this letter, we study the linear processing method to alleviate the intercarrier interference (ICI) for the orthogonal frequency division multiplexing (OFDM) index modulation (IM) in the rapidly time-varying (RTV) channel. Concretely, the proposed linear processing scheme is implemented by the joint design of the transmit precoding and receive postprocessing matrices. First, a lower bound of the capacity of OFDM-IM in the RTV channel is derived. Then, the precoding and postprocessing matrices are designed to maximize this capacity lower bound through utilizing the particle swarm optimization algorithm. Computer simulations show that the proposed scheme can alleviate the ICI effectively and has better performance than the conventional ICI self-cancellation scheme.","OFDM,
Modulation,
Indexes,
Optimization,
Interference,
Doppler effect,
Particle swarm optimization"
A Modularization Method for Battery Equalizers Using Multiwinding Transformers,"This paper proposes a modularized global architecture using multi-winding transformers for battery cell balancing. The global balancing for a series-connected battery string is achieved based on forward conversion in each battery module and based on flyback conversion among modules. The demagnetization of the multiwinding transformers is also simultaneously achieved by the flyback conversion among modules without the need of additional demagnetizing circuits. Moreover, all MOSFET switches are driven by two complementary pulse width modulation signals without the requirement of cell voltage sensors, and energy can be automatically and simultaneously delivered from any high voltage cells to any low voltage cells. Compared with existing equalizers requiring additional balancing circuits for battery modules, the proposed modularized equalizer shares one circuit for the balancing among cells and modules. The balancing performance of the proposed equalizer is perfectly verified through experimental results, and the maximum balancing efficiency is up to 91.3%. In summary, the proposed modularized equalizer has the advantages of easier modularization, simpler control, higher efficiency, smaller size, and lower cost, ensuring the battery system higher reliability and easier implementation.",
Cross-Layer Energy Minimization for Underwater ALOHA Networks,"Underwater networks suffer from energy efficiency challenges due to difficulties in recharging underwater nodes. In addition, underwater acoustic networks show unique transmission characteristics such as frequency-dependent attenuation, which causes the transmission power to significantly depend on the bandwidth and the distance. We here investigate the cross-layer energy minimization problem in underwater ALOHA networks considering the unique transmission properties of the underwater medium. We first analyze the separate optimization of the physical (PHY) and multiple access control (MAC) layers to minimize energy consumption. We analytically obtain the energy-optimum channel access rate for the ALOHA MAC layer, which minimizes the energy consumption per successfully transmitted bit. We then formulate a cross-layer optimization problem, which jointly optimizes PHY and MAC layers to minimize energy consumption. We show that such cross-layer optimization reduces the energy consumption per bit as much as 66% in comparison with separate optimization of both layers. Cross-layer optimization achieves this energy efficiency by assigning higher MAC-layer resources to the nodes that have a longer distance to the base station, i.e., which experience a less efficient PHY layer. Moreover, cross-layer optimization significantly increases the amount data transferred until first node failure since it results in a more homogeneous energy consumption distribution among the nodes.",
A Bio-Inspired Approach to Task Assignment of Swarm Robots in 3-D Dynamic Environments,"Intending to mimic the operating mechanism of biological neural systems, a self organizing map-based approach to task assignment of a swarm of robots in 3-D dynamic environments is proposed in this paper. This approach integrates the advantages and characteristics of biological neural systems. It is capable of dynamically planning the paths of a swarm of robots in 3-D environments under uncertain situations, such as when some robots are presented in or broken down or when more than one robot is needed for some special task locations. A Bezier path optimizing algorithm and a parameter adjusting algorithm are integrated in this paper. It is capable of reducing the complexity of the robot navigation control and limiting the number of convergence iterations. The simulation results with different environments demonstrate the effectiveness of the proposed approach.",
An Efficient Public Auditing Protocol With Novel Dynamic Structure for Cloud Data,"With the rapid development of cloud computing, cloud storage has been accepted by an increasing number of organizations and individuals, therein serving as a convenient and on-demand outsourcing application. However, upon losing local control of data, it becomes an urgent need for users to verify whether cloud service providers have stored their data securely. Hence, many researchers have devoted themselves to the design of auditing protocols directed at outsourced data. In this paper, we propose an efficient public auditing protocol with global and sampling blockless verification as well as batch auditing, where data dynamics are substantially more efficiently supported than is the case with the state of the art. Note that, the novel dynamic structure in our protocol consists of a doubly linked info table and a location array. Moreover, with such a structure, computational and communication overheads can be reduced substantially. Security analysis indicates that our protocol can achieve the desired properties. Moreover, numerical analysis and real-world experimental results demonstrate that the proposed protocol achieves a given efficiency in practice.","Protocols,
Cloud computing,
Indexes,
Security,
Switches,
Outsourcing,
Arrays"
PPHOPCM: Privacy-preserving High-order Possibilistic c-Means Algorithm for Big Data Clustering with Cloud Computing,"As one important technique of fuzzy clustering in data mining and pattern recognition, the possibilistic c-means algorithm (PCM) has been widely used in image analysis and knowledge discovery. However, it is difficult for PCM to produce a good result for clustering big data, especially for heterogenous data, since it is initially designed for only small structured dataset. To tackle this problem, the paper proposes a high-order PCM algorithm (HOPCM) for big data clustering by optimizing the objective function in the tensor space. Further, we design a distributed HOPCM method based on MapReduce for very large amounts of heterogeneous data. Finally, we devise a privacy-preserving HOPCM algorithm (PPHOPCM) to protect the private data on cloud by applying the BGV encryption scheme to HOPCM, In PPHOPCM, the functions for updating the membership matrix and clustering centers are approximated as polynomial functions to support the secure computing of the BGV scheme. Experimental results indicate that PPHOPCM can effectively cluster a large number of heterogeneous data using cloud computing without disclosure of private data.","Clustering algorithms,
Big data,
Phase change materials,
Algorithm design and analysis,
Tensile stress,
Correlation,
Data models"
Online Human Interaction Detection and Recognition With Multiple Cameras,"We address the problem of detecting and recognizing online the occurrence of human interactions as seen by a network of multiple cameras. We represent interactions by forming temporal trajectories, coupling together the body motion of each individual and their proximity relationships with others, and also sound whenever available. Such trajectories are modeled with kernel state-space (KSS) models. Their advantage is being suitable for the online interaction detection, recognition, and also for fusing information from multiple cameras, while enabling a fast implementation based on online recursive updates. For recognition, in order to compare interaction trajectories in the space of KSS models, we design so-called pairwise kernels with a special symmetry. For detection, we exploit the geometry of linear operators in Hilbert space, and extend to KSS models the concept of parity space, originally defined for linear models. For fusion, we combine KSS models with kernel construction and multiview learning techniques. We extensively evaluate the approach on four single view publicly available data sets, and we also introduce, and will make public, a new challenging human interactions data set that we have collected using a network of three cameras. The results show that the approach holds promise to become an effective building block for the analysis of real-time human behavior from multiple cameras.","Kernel,
Trajectory,
Cameras,
Tracking,
Histograms,
Hilbert space,
Geometry"
A Resilient 2-D Waveguide Communication Fabric for Hybrid Wired-Wireless NoC Design,"Hybrid wired-wireless Network-on-Chip (WiNoC) has emerged as an alternative solution to the poor scalability and performance issues of conventional wireline NoC design for future System-on-Chip (SoC). Existing feasible wireless solution for WiNoCs in the form of millimeter wave (mm-Wave) relies on free space signal radiation which has high power dissipation with high degradation rate in the signal strength per transmission distance. Moreover, over the lossy wireless medium, combining wireless and wireline channels drastically reduces the total reliability of the communication fabric. Surface wave has been proposed as an alternative wireless technology for low power on-chip communication. With the right design considerations, the reliability and performance benefits of the surface wave channel could be extended. In this paper, we propose a surface wave communication fabric for emerging WiNoCs that is able to match the reliability of traditional wireline NoCs. First, we propose a realistic channel model which demonstrates that existing mm-Wave WiNoCs suffers from not only free-space spreading loss (FSSL) but also molecular absorption attenuation (MAA), especially at high frequency band, which reduces the reliability of the system. Consequently, we employ a carefully designed transducer and commercially available thin metal conductor coated with a low cost dielectric material to generate surface wave signals with improved transmission gain. Our experimental results demonstrate that the proposed communication fabric can achieve a 5 dB operational bandwidth of about 60 GHz around the center frequency (60 GHz). By improving the transmission reliability of wireless layer, the proposed communication fabric can improve maximum sustainable load of NoCs by an average of 20:9 and 133:3 percent compared to existing WiNoCs and wireline NoCs, respectively.","Wireless communication,
Fabrics,
Reliability,
Surface waves,
System-on-chip,
Channel models,
Optical surface waves"
Contextual Exemplar Classifier-Based Image Representation for Classification,"The use of local features for image representation has become popular in recent years. Local features are often used in the bag-of-visual-words scheme. Although proven effective, this method still has two drawbacks. First, local regions from which local features are extracted are not discriminative enough for visual tasks. Hence, the combination of local features is necessary. Second, the semantic gap between visual features and human perception also hinders the performance. To address these two problems, in this paper, we propose a novel contextual exemplar classifier-based method for image representation and apply it for classification tasks. Each exemplar classifier is trained to separate one training image from the other images of different classes. We partition each image into a number of regions and use the responses of these exemplar classifiers as the image region's representation. The contextual relationship is then modeled using mixture Dirichlet distributions. A bilayer model is used to predict image classes with L2 constraints. Experimental results on the Natural Scene, Caltech-101/256, Flower-17/102, and SUN-397 data sets show that the proposed method is able to outperform the state-of-the-art local feature-based methods for image classification.",
Low-Profile and Wide-Beamwidth Dual-Polarized Distributed Microstrip Antenna,"A low-profile and wide-beamwidth dual-polarized distributed microstrip antenna is presented in this paper. Four isolated micro patches are proposed as the radiation components and are excited by a compact differential-fed network. The micro patches in two diagonals determine the operating frequency bands of the two polarizations, respectively. By increasing the distances between the micro patches, the beamwidth in E plane can be broadened. Shorting poles between the patches and the ground plane are used to achieve good impedance matching. Compact dual-polarized differential-fed networks are also studied and compared with achieve the best antenna performance. To validate the proposed method, a wide-beamwith dual-polarized distributed microstrip antenna, whose dual polarizations operate at 2 and 2.2 GHz, respectively, is manufactured and measured. The external dimensions of the antenna is 70mmx10 mm (0.49λ x 0.07λ). The experimental results agree well with the simulated ones. The 3dB beamwidths in E planes reach 116° and 115°, and the gains are 5.15 and 5.5 dB for two polarizations, respectively. Meanwhile, the cross polarizations are less than -26.2 and -27.8 dB. In addition, the impedance bandwidths of 9.2% and 9.9% for VSWR≤2 are achieved, and the port isolation is greater than 25.4 dB in the bands.","Microstrip antennas,
Ports (Computers),
Microstrip,
Impedance,
Resonant frequency,
Cavity resonators"
Procrustean Normal Distribution for Non-Rigid Structure from Motion,"A well-defined deformation model can be vital for non-rigid structure from motion (NRSfM). Most existing methods restrict the deformation space by assuming a fixed rank or smooth deformation, which are not exactly true in the real world, and they require the degree of deformation to be predetermined, which is impractical. Meanwhile, the errors in rotation estimation can have severe effects on the performance, i.e., these errors can make a rigid motion be misinterpreted as a deformation. In this paper, we propose an alternative to resolve these issues, motivated by an observation that non-rigid deformations, excluding rigid changes, can be concisely represented in a linear subspace without imposing any strong constraints, such as smoothness or low-rank. This observation is embedded in our new prior distribution, the Procrustean normal distribution (PND), which is a shape distribution exclusively for non-rigid deformations. Because of this unique characteristic of the PND, rigid and non-rigid changes can be strictly separated, which leads to better performance. The proposed algorithm, EM-PND, fits a PND to given 2D observations to solve NRSfM without any user-determined parameters. The experimental results show that EM-PND gives the state-of-the-art performance for the benchmark data sets, confirming the adequacy of the new deformation model.",
Remaining Useful Lifetime Estimation for Power MOSFETs Under Thermal Stress With RANSAC Outlier Removal,"Reliability of power converters is crucial for mission critical systems. Among the components that are susceptible to failure, power semiconductor devices are one of the major causes of the power converter failures. This paper focuses on the remaining useful lifetime (RUL) estimation of degraded power MOSFETs, which are stressed by thermal cycling. The relative change in on-state resistance is identified as the fault signature. A data-driven RUL estimation algorithm based on a linear approximation model is proposed. The empirical coefficients are estimated by the classical least squares, where the outliers are removed by random sample consensus (RANSAC) algorithm. A sliding window approach is used to track the nonlinearities. The window size, threshold value, and number of samples used by RANSAC are optimized with the genetic algorithm. The accuracy of the proposed RUL estimation tool is verified on a number of thermally aged discrete power MOSFET data.",
Improved 64-bit Radix-16 Booth Multiplier Based on Partial Product Array Height Reduction,"In this paper, we describe an optimization for binary radix-16 (modified) Booth recoded multipliers to reduce the maximum height of the partial product columns to [n/4] for n = 64-bit unsigned operands. This is in contrast to the conventional maximum height of [(n + 1)/4]. Therefore, a reduction of one unit in the maximum height is achieved. This reduction may add flexibility during the design of the pipelined multiplier to meet the design goals, it may allow further optimizations of the partial product array reduction stage in terms of area/delay/power and/or may allow additional addends to be included in the partial product array without increasing the delay. The method can be extended to Booth recoded radix-8 multipliers, signed multipliers, combined signed/unsigned multipliers, and other values of n.","Optimization,
Adders,
Delays,
Microprocessors,
Pipeline processing,
Vegetation,
Multiplexing"
Performance Evaluation of Underwater Wireless Optical Communications Links in the Presence of Different Air Bubble Populations,Air bubbles significantly affect the performance of underwater wireless optical communication (UWOC) systems and understanding on how they interact with the propagating optical beam in water is crucial. We experimentally evaluate the performance of UWOC links in the presence of air bubbles of different sizes. We also propose and show that beam expansion improves performance degradation caused by air bubbles in the channel. Our findings could help design better UOWC systems.,"Sea measurements,
Optical pumping,
Optical refraction,
Oceans,
Sociology,
Statistics,
Optical scattering"
Optimal Distributed Control for Platooning via Sparse Coprime Factorizations,"We introduce a novel distributed control architecture for heterogeneous platoons of linear time-invariant autonomous vehicles. Our approach is based on a generalization of the concept of leader-follower controllers for which we provide a Youla-like parameterization, while the sparsity constraints are imposed on the controller's left coprime factors, outlining a new concept of structural constraints in distributed control. The proposed scheme is amenable to optimal controller design via norm based costs, it guarantees string stability and eliminates the accordion effect from the behavior of the platoon. We also introduce a synchronization mechanism for the exact compensation of the time delays induced by the wireless communications.","Vehicles,
Stability analysis,
Decentralized control,
Delay effects,
Wireless communication,
Standards,
Transfer functions"
A Unified Framework for Vehicle Rerouting and Traffic Light Control to Reduce Traffic Congestion,"As the number of vehicles grows rapidly each year, more and more traffic congestion occurs, becoming a big issue for civil engineers in almost all metropolitan cities. In this paper, we propose a novel pheromone-based traffic management framework for reducing traffic congestion, which unifies the strategies of both dynamic vehicle rerouting and traffic light control. Specifically, each vehicle, represented as an agent, deposits digital pheromones over its route, while roadside infrastructure agents collect the pheromones and fuse them to evaluate real-time traffic conditions as well as to predict expected road congestion levels in near future. Once road congestion is predicted, a proactive vehicle rerouting strategy based on global distance and local pheromone is employed to assign alternative routes to selected vehicles before they enter congested roads. In the meanwhile, traffic light control agents take online strategies to further alleviate traffic congestion levels. We propose and evaluate two traffic light control strategies, depending on whether or not to consider downstream traffic conditions. The unified pheromone-based traffic management framework is compared with seven other approaches in simulation environments. Experimental results show that the proposed framework outperforms other approaches in terms of traffic congestion levels and several other transportation metrics, such as air pollution and fuel consumption. Moreover, experiments over various compliance and penetration rates show the robustness of the proposed framework.","Vehicles,
Roads,
Fuels,
Delays,
Vehicle dynamics"
A Finger Vein Image-Based Personal Identification System With Self-Adaptive Illuminance Control,"As a biometric trait, finger vein pattern-based technology is highly effective for personal identification with high security. In this paper, we presented the design of a personal identification system based on near infrared (NIR) finger vein image. In this paper, we introduced an observation model of finger vein imaging, upon which a self-adaptive illuminance control algorithm is proposed and integrated into image acquisition hardware. According to the distribution of pixel intensity of the acquired image, the proposed algorithm could automatically adjust the illuminance distribution of lighting: increase the illuminance of lighting, under which the thicker part of finger body is presented and decrease the illuminance of lighting, under which the thinner part of finger body is presented. With this adaptation, the whole finger body could be illuminated appropriately according to its thickness distribution, and the overexposure and underexposure are avoided effectively. An NIR finger vein image database containing 2040 images is established and published in this paper. In the image preprocessing stage, Gabor filters are used to enhance captured raw finger vein images. In our experiment, the identification performance of our system is evaluated using the recognition rate and the margin distribution. A sparse representation-based algorithm is used to calculate the recognition rate and provide data for margin analysis. The results prove the effectiveness of the proposed illuminance control algorithm and the whole system in finger vein-based personal identification.","Veins,
Light emitting diodes,
Lighting,
Optical sensors,
Fingers,
Cameras"
Optimal k-leader selection for coherence and convergence rate in one-dimensional networks,"We study the problem of optimal leader selection in consensus networks under two performance measures: 1) formation coherence when subject to additive perturbations, as quantified by the steady-state variance of the deviation from the desired trajectory, and 2) convergence rate to a consensus value. The objective is to identify the set of k leaders that optimizes the chosen performance measure. In both cases, an optimal leader set can be found by an exhaustive search over all possible leader sets; however, this approach is not scalable to large networks. In recent years, several works have proposed approximation algorithms to the k-leader selection problem, yet the question of whether there exists an efficient, noncombinatorial method to identify the optimal leader set remains open. This work takes a first step toward answering this question. We show that, in 1-D weighted graphs, namely, path graphs and ring graphs, the k-leader selection problem can be solved in polynomial time (ink and the network size n). We give an O(n3) solution for optimal k-leader selection in path graphs and an O(kn3) solution for optimal k-leader selection in ring graphs.","Coherence,
Convergence,
Noise measurement,
Trajectory,
Network topology,
Steady-state"
Resource Provisioning and Profit Maximization for Transcoding in Clouds: A Two-Timescale Approach,"Transcoding is widely adopted for content adaptation; however, it may incur excessive resource consumption and processing delays. Taking advantage of cloud infrastructure, cloud-based transcoding can elastically allocate resources under time-varying workloads and perform multiple transcodings in parallel to reduce delays. To provide transcoding as a cloud service, cloud transcoding systems require some intelligent mechanisms to provision resources and schedule tasks to satisfy user requirements while maximizing financial profit. To this end, we propose a two-timescale stochastic optimization framework for maximizing service profit while achieving performance requirements by jointly provisioning resources and scheduling tasks under a hierarchical control architecture. Our method analytically integrates service revenue, processing delay, and resource consumption in one optimization framework. We derive the offline exact solution and design some approximate online solutions for task scheduling and resource provisioning. We implement an open source cloud transcoding system, called Morph, and evaluate the performance of our method in a real environment. Empirical studies verify that our method can reduce resource consumption and achieve a higher profit compared with baseline schemes.",
Nonlinear Process Fault Diagnosis Based on Serial Principal Component Analysis,"Many industrial processes contain both linear and nonlinear parts, and kernel principal component analysis (KPCA), widely used in nonlinear process monitoring, may not offer the most effective means for dealing with these nonlinear processes. This paper proposes a new hybrid linear-nonlinear statistical modeling approach for nonlinear process monitoring by closely integrating linear principal component analysis (PCA) and nonlinear KPCA using a serial model structure, which we refer to as serial PCA (SPCA). Specifically, PCA is first applied to extract PCs as linear features, and to decompose the data into the PC subspace and residual subspace (RS). Then, KPCA is performed in the RS to extract the nonlinear PCs as nonlinear features. Two monitoring statistics are constructed for fault detection, based on both the linear and nonlinear features extracted by the proposed SPCA. To effectively perform fault identification after a fault is detected, an SPCA similarity factor method is built for fault recognition, which fuses both the linear and nonlinear features. Unlike PCA and KPCA, the proposed method takes into account both linear and nonlinear PCs simultaneously, and therefore, it can better exploit the underlying process's structure to enhance fault diagnosis performance. Two case studies involving a simulated nonlinear process and the benchmark Tennessee Eastman process demonstrate that the proposed SPCA approach is more effective than the existing state-of-the-art approach based on KPCA alone, in terms of nonlinear process fault detection and identification.",
Epidemic Protection Over Heterogeneous Networks Using Evolutionary Poisson Games,"Malware is increasingly sophisticated and affects the wellbeing of a large population of heterogeneous and highly connected devices. The users of these devices can make strategic and dynamic decisions to choose whether or not to adopt the antivirus software, not only to secure their individual devices but also to protect the network they are part of. Motivated by the strategic behaviors of the antivirus adoption, we establish an evolutionary Poisson game framework to capture the random, dynamic, and heterogeneous interactions of agents in a holistic fashion, and design mechanisms to control their behaviors to achieve a system-wide objective. We first prove the existence and uniqueness of a mixed Nash equilibrium of the large population game and show that the equilibrium is an evolutionary stable strategy. Finally, we develop online algorithms using the techniques of stochastic approximation coupled with the population dynamics, and they are shown to converge to the optimal solution of the controller problem. Numerical examples are used to illustrate and corroborate our results.","Sociology,
Statistics,
Games,
Nash equilibrium,
Heuristic algorithms,
Robustness"
Pole-Converging Intrastage Bandwidth Extension Technique for Wideband Amplifiers,"To overcome limitations on bandwidth extension in conventional design techniques, a novel pole-converging technique with transformer feedback for intrastage bandwidth extension is proposed and analyzed in this paper. For verification, a three-stage cascode low-noise amplifier (LNA) based on the pole converging and negative drain-source transformer feedback is designed and implemented in a 65-nm CMOS technology. Consuming 27 mW dc power from a 1.8 V supply, the fabricated prototype exhibits peak power gain of 18.5 dB, minimum noise figure of 5.5 dB, 3-dB bandwidth of 30 GHz, and fractional bandwidth of 38.7%. The bandwidth of the three-stage cascode LNA is significantly extended without increasing power consumption and die size.",
Passivity of Directed and Undirected Complex Dynamical Networks With Adaptive Coupling Weights,"A complex dynamical network consisting of N identical neural networks with reaction-diffusion terms is considered in this paper. First, several passivity definitions for the systems with different dimensions of input and output are given. By utilizing some inequality techniques, several criteria are presented, ensuring the passivity of the complex dynamical network under the designed adaptive law. Then, we discuss the relationship between the synchronization and output strict passivity of the proposed network model. Furthermore, these results are extended to the case when the topological structure of the network is undirected. Finally, two examples with numerical simulations are provided to illustrate the correctness and effectiveness of the proposed results.",
Improved Sliding Mode Design for Load Frequency Control of Power System Integrated an Adaptive Learning Strategy,"Randomness from the power load demand and renewable generations causes frequency oscillations among interconnected power systems. Due to the requirement of synchronism of the whole grid, load frequency control (LFC) has become one of the essential challenges for power system stability and security. In this paper, by modeling the disturbances and parameter uncertainties into the LFC model, we propose an adaptive supplementary control scheme for the power system frequency regulation. An improved sliding mode control (SMC) is employed as the basic controller, where a new sliding mode variable is specifically proposed for the LFC problem. The adaptive dynamic programming strategy is used to provide the supplementary control signal, which is beneficial to the frequency regulation by adapting to the real-time disturbances and uncertainties. The stability analysis is also provided to guarantee the reliability of the proposed control strategy. For comparison, a particle swarm optimization-based SMC scheme is developed as the optimal parameter controller for the frequency regulation problem. Simulation studies are performed on single-area and multiarea benchmark systems, and comparative results illustrate the favorable performance of the proposed adaptive approach for the frequency regulation under load disturbances and parameter uncertainties.","Frequency control,
Power system stability,
Load modeling,
Uncertain systems,
Adaptation models,
Uncertainty"
Resource Exchange in Smart Grid Connected Cooperative Cognitive Radio Networks,"Wireless telecommunications is experiencing a massive penetration of wireless devices and an exponential growth in wireless applications. To accommodate the expected service requirements with the available radio resources, we present a new radio resource exchange scheme for a smart grid connected cognitive radio system, in which independently harvested energy can be stored in the smart grid in the form of on-grid credit. The secondary system will gain spectrum usage by either forwarding primary data or transferring energy credit directly to the primary system. In particular, to maximize the overall energy saving while meeting the throughput requirement, the utilities of both systems are optimized by jointly designing the subchannel assignment scheme with power control. First, for any given subchannel assignment, we have derived the optimal power allocated by both primary and secondary systems to each subchannel. Then, the characteristics of the subchannel assignment scheme are analyzed, and the complexity of finding the optimal assignment is reduced. Finally, a novel joint subchannel assignment and power control scheme is proposed to decide whether and how to cooperate by comparing the utilities of both systems with and without cooperation. Simulations results are presented to verify the optimality of the derived scheme.",
On Energy-Efficient Offloading in Mobile Cloud for Real-Time Video Applications,"Batteries of modern mobile devices remain severely limited in capacity, which makes energy consumption a key concern for mobile applications, particularly for the computation-intensive video applications. Mobile devices can save energy by offloading computation tasks to the cloud, yet the energy gain must exceed the additional communication cost for cloud migration to be beneficial. The situation is further complicated by real-time video applications that have stringent delay and bandwidth constraints. In this paper, we closely examine the performance and energy efficiency of representative mobile cloud applications under dynamic wireless network channels and state-of-the-art mobile platforms. We identify the unique challenges of and opportunities for offloading real-time video applications and develop a generic model for energy-efficient computation offloading accordingly in this context. We propose a scheduling algorithm that makes adaptive offloading decisions in fine granularity in dynamic wireless network conditions and verify its effectiveness through trace-driven simulations. We further present case studies with advanced mobile platforms and practical applications to demonstrate the superiority of our solution and the substantial gain of our approach over baseline approaches.","Mobile communication,
Streaming media,
Cloud computing,
Delays,
Games,
Mobile handsets,
Energy consumption"
Low-complexity and high-accuracy DOA estimation for coprime arrays using Toeplitz matrices,"Pal et al. proposed a method to extend a coprime array to a larger virtual uniform linear array (ULA), thus subspace-based direction of arrival (DOA) estimation algorithms can be used to detect more sources than the number of array elements. However, since the full information of the observation vector obtained by vectorizing the signal covariance matrix is not used, then applying the spatial smoothing technique, the performance of DOA estimation may be limited in some scenarios. By exploiting the full information of the observation vector, and using a Toeplitz matrix to form the covariance matrix of the virtual ULA, we propose a reduced-complexity DOA estimation method. Computer simulations reveal that the proposed method has better estimation accuracy and lower computational complexity than Pal et al.'s method.","Covariance matrices,
Estimation,
Direction-of-arrival estimation,
Sensor arrays,
Manifolds,
Smoothing methods"
A Heterogeneous Multi-Core System-on-Chip for Energy Efficient Brain Inspired Computing,"Convolutional Neural Networks (CNNs) have revolutionized computer vision, speech recognition and other fields requiring strong classification capabilities. These strenghts make CNNs appealing in edge node internet-of-things (IoT) applications requiring near-sensors processing. Specialized CNN accelerators deliver significant performance per watt and satisfy the tight constraints of deeply embedded devices, but they cannot be used to implement arbitrary CNN topologies or non-conventional sensory algorithms where CNNs are only a part of the processing stack. A higher level of flexibility is desirable for next generation IoT nodes. Here we present Mia Wallace, a 65nm Systemon- Chip integrating a near-threshold parallel processor cluster tightly coupled with a CNN accelerator: it achieves peak energy efficiency of 108 GMAC/s/W @ 0.72V and peak performance of 14 GMAC/s @ 1.2V, leaving 1.2 GMAC/s available for generalpurpose parallel processing.",
Terahertz Broadband-Tunable Minigyrotron With a Pulse Magnet,"A minigyrotron scheme controlled by a compact pulse magnet to excite broadband terahertz (THz) radiation is presented here. In comparison to an open-cavity circuit, the adopted prebunched backward-wave interaction circuit can expand tuning bandwidth tenfold under the control of time-varying magnetic field strength, which also significantly extends the available duration time of the pulse magnet for gyrotron operation. A quasi-optical mode convertor and a Brewster window constitute the output system to transfer the broadband radiation from the circuit into free space. A systematic gyrotron design is also presented. Driven by a low-voltage electron beam, the minigyrotron is predicted to generate radiation with 10-GHz tuning bandwidth around 0.33 THz and a maximum peak power of 2.1 kW with 6-ms pulse duration, using a TE6,2 mode interaction. Such a THz gyrotron with broad tunable bandwidth, kilowatt level power, and with the unique advantage of a compact configuration is the key to high-power THz scientific and industrial applications.","Gyrotrons,
Magnetic circuits,
Broadband communication,
Superconducting magnets,
Tuning,
Electron beams,
Q-factor"
Mobile Sensors Deployment Subject to Location Estimation Error,"Voronoi-based mobile sensor deployment algorithms require the knowledge of sensors' locations to guarantee a simple reliable coverage detection, and they miss the mark if the location is inaccurate. However, in practice, it is often too expensive to include a Global Positioning System (GPS) receiver in each node, and location information is inaccurate as sensors estimate locations from the messages they receive. We study sensor deployment algorithms in the presence of location estimation error for sensors with nonidentical sensing ranges. We propose a set of Voronoi-based diagrams, which are called guaranteed Voronoi diagrams (VDs), that guarantee single-cell-based coverage hole detection algorithms, provided that upper bounds on localization errors are assumed. Although inaccuracy of location information would appear to deteriorate the total coverage, our simulation results demonstrate that the proposed algorithms can exploit this inaccuracy to improve network coverage. Hence, even if the location information is exactly known at each node, assuming some error margins improves the network coverage if guaranteed Voronoi diagrams are used.","Sensor phenomena and characterization,
Wireless sensor networks,
Mobile communication,
Estimation error,
Mobile computing,
Network topology"
Power control and relay selection in Full-Duplex Cognitive Relay Networks: Coherent versus non-coherent scenarios,"This paper investigates power control and relay selection in Full Duplex Cognitive Relay Networks (FDCRNs), where the secondary-user (SU) relays can simultaneously receive and forward the signal from the SU source. We study both non-coherent and coherent scenarios. In the non-coherent case, the SU relay forwards the signal from the SU source without regulating the phase; while in the coherent scenario, the SU relay regulates the phase when forwarding the signal to minimize the interference at the primary-user (PU) receiver. We consider the problem of maximizing the transmission rate from the SU source to the SU destination subject to the interference constraint at the PU receiver and power constraints at both the SU source and SU relay. We develop low-complexity and high-performance joint power control and relay selection algorithms. The superior performance of the proposed algorithms are confirmed using extensive numerical evaluation. In particular, we demonstrate the significant gain of phase regulation at the SU relay (i.e., the gain of the coherent mechanism over the noncoherent mechanism).","Interference,
Power control,
Receivers,
Relay networks (telecommunications),
Optimization,
Cognitive radio"
Cluster Synchronization for Linearly Coupled Nonidentical Systems With Delays via Aperiodically Intermittent Pinning Control,"This paper investigates the cluster synchronization problem of linearly coupled complex networks via aperiodically intermittent control (AIC). The dynamical behaviors of nodes in different clusters are assumed to be governed by different dynamical functions, while the dynamical behaviors of nodes in the same cluster are the same. Moreover, the original functions of nodes are defined by continuous-time ordinary differential equations with time-varying delays. As for the coupling matrix, we assume it is a Metzler matrix with zero row sums. The main contribution is that we pin some simple AIC to realize the cluster synchronization. Furthermore, as for the pinning control gains, both static and adaptive control cases are considered and some criteria are obtained. We also present some numerical simulations to verify the theoretical results.","Synchronization,
Couplings,
Complex networks,
Symmetric matrices,
Delays,
Indexes,
Adaptive systems"
Dimensionality Reduction of Hyperspectral Imagery Using Sparse Graph Learning,"Combining with sparse representation, the sparse graph can adaptively capture the intrinsic structural information of the specified data. In this paper, an unsupervised sparse-graph-learning-based dimensionality reduction (SGL-DR) method is proposed for hyperspectral image. In SGL-DR, the sparse graph construction and projection learning are combined together in a unified framework and influence each other. During sparse graph learning, projected features are utilized to enhance the discriminant information in sparse graph. Likewise, in projection learning, the enhanced sparse graph could make projected features have high discriminant capacity. Besides, the spatial-spectral information in the original space combined with the structure information in the projected space is also exploited to learn the imprecise discriminant information. With the imprecise discriminant information, the projected space that is spanned by the projection matrix of the constructed sparse graph would contain abundant discriminant information, which is beneficial for hyperspectral image classification. Experimental results over two hyperspectral image datasets demonstrate that the proposed approach outperforms the other state-of-the-art unsupervised approaches with a 10% improvement of the classification accuracy. Furthermore, it also outperforms those graph-based supervised methods with acceptable computational cost.","Hyperspectral imaging,
Sparse matrices,
Computational efficiency,
Dictionaries,
Symmetric matrices"
Statistical Learning for Anomaly Detection in Cloud Server Systems: A Multi-Order Markov Chain Framework,"As a major strategy to ensure the safety of IT infrastructure, anomaly detection plays a more important role in cloud computing platform which hosts the entire applications and data. On top of the classic Markov chain model, we proposed in this paper a feasible multi-order Markov chain based framework for anomaly detection. In this approach, both the high-order Markov chain and multivariate time series are adopted to compose a scheme described in algorithms along with the training procedure in the form of statistical learning framework. To curb time and space complexity, the algorithms are designed and implemented with non-zero value table and logarithm values in initial and transition matrices. For validation, the series of system calls and the corresponding return values are extracted from classic Defense Advanced Research Projects Agency (DARPA) intrusion detection evaluation data set to form a two-dimensional test input set. The testing results show that the multi-order approach is able to produce more effective indicators: in addition to the absolute values given by an individual single-order model, the changes in ranking positions of outputs from different-order ones also correlate closely with abnormal behaviours.","Markov processes,
Training,
Cloud computing,
Algorithm design and analysis,
Mathematical model,
Equations,
Servers"
Spatial Random Sampling: A Structure-Preserving Data Sketching Tool,"Random column sampling is not guaranteed to yield data sketches that preserve the underlying structures of the data and may not sample sufficiently from less-populated data clusters. Also, adaptive sampling can often provide accurate low rank approximations, yet may fall short of producing descriptive data sketches, especially when the cluster centers are linearly dependent. Motivated by that, this letter introduces a novel randomized column sampling tool dubbed spatial random sampling (SRS), in which data points are sampled based on their proximity to randomly sampled points on the unit sphere. The most compelling feature of SRS is that the corresponding probability of sampling from a given data cluster is proportional to the surface area the cluster occupies on the unit sphere, independently of the size of the cluster population. Although it is fully randomized, SRS is shown to provide descriptive and balanced data representations. The proposed idea addresses a pressing need in data science and holds potential to inspire many novel approaches for analysis of big data.",
"Needs, Pains, and Motivations in Autonomous Agents","This paper presents the development of a motivated learning (ML) agent with symbolic I/O. Our earlier work on the ML agent was enhanced, giving it autonomy for interaction with other agents. Specifically, we equipped the agent with drives and pains that establish its motivations to learn how to respond to desired and undesired events and create related abstract goals. The purpose of this paper is to explore the autonomous development of motivations and memory in agents within a simulated environment. The ML agent has been implemented in a virtual environment created within the NeoAxis game engine. Additionally, to illustrate the benefits of an ML-based agent, we compared the performance of our algorithm against various reinforcement learning (RL) algorithms in a dynamic test scenario, and demonstrated that our ML agent learns better than any of the tested RL agents.","Pain,
Computer architecture,
Cognition,
Learning systems,
Heuristic algorithms,
Robots,
Computer science"
The Value of Cooperation: Minimizing User Costs in Multi-Broker Mobile Cloud Computing Networks,"We study the problem of user cost minimization in mobile cloud computing (MCC) networks. We consider a MCC model where multiple brokers assign cloud resources to mobile users. The model is characterized by an heterogeneous cloud architecture (which includes a public cloud and a cloudlet) and by the heterogeneous pricing strategies of cloud service providers. In this setting, we investigate two classes of cloud reservation strategies, i.e., a competitive strategy, and a compete-then-cooperate strategy as a performance bound. We first study a purely competitive scenario where brokers compete to reserve computing resources from remote public clouds (which are affected by long delays) and from local cloudlets (which have limited computational resources but short delays). We provide theoretical results demonstrating the existence of disagreement points (i.e., the equilibrium reservation strategy that no broker has incentive to deviate unilaterally from) and convergence of the best-response strategies of the brokers to disagreement points. We then consider the scenario in which brokers agree to cooperate in exchange for a lower average cost of resources. We formulate a cooperative problem where the objective is to minimize the total average price of all brokers, under the constraint that no broker should pay a price higher than the disagreement price (i.e., the competitive price). We design new globally optimal solution algorithm to solve the resulting non-convex cooperative problem, based on a combination of the branch and bound framework and of advanced convex relaxation techniques. The resulting optimal solution provides a lower bound on the achievable user cost without complete collusion among brokers. Compared with pure competition, we found that (i) noticeable cooperative gains can be achieved over pure competition in markets with a few brokers only, and (ii) the cooperative gain is only marginal in crowded markets, i.e., with a high number of brokers, hence there is no clear incentive for brokers to cooperate.",
CRIL: An Efficient Online Adaptive Indoor Localization System,"Indoor localization or indoor positioning systems find their use in many important applications such as augmented reality, guided tours, tracking and monitoring, and situational awareness and have recently attracted intense research interests. Previous localization systems are usually received signal strength indication (RSSI)-based, inertial navigation system (INS)-based, or an integration of these two. However, few of them can account for dynamic communication environments, where channel states constantly change. To the best of our knowledge, this paper is the first to propose an efficient and adaptive indoor localization system called coupled RSSI and INS localization (CRIL), which can adapt to dynamic communication environments quickly and effectively. Moreover, CRIL can account for the uncertainties in RSSI measurements such as varying covariances and outliers as well. Extensive simulation results demonstrate that our proposed CRIL system is able to track both slow changes and sudden changes of the channel states in dynamic environments. Noticeably, the proposed CRIL can perform accurate localization with estimation errors up to 1 m, while previous schemes' localization errors are up to several meters or even tens of meters. Moreover, we test CRIL in real experiments, and its localization error is up to 3 m in dynamic environments.","Vehicle dynamics,
Channel models,
Estimation,
Fuses,
Received signal strength indicator,
Indoor environments,
Mobile handsets"
Pay or Perish: The Economics of Premium Peering,"As the Internet continues to evolve, traditional peering agreements cannot accommodate the changing market conditions. Premium peering has emerged where access providers (APs) charge content providers (CPs) for premium services beyond best-effort connectivity. Although prioritized peering raises concerns about net neutrality, the U.S. FCC exempted peering agreements from its recent ruling, as it falls short of background in the Internet peering context. In this paper, we consider the premium peering options provided by APs and study whether CPs will choose to peer. Based on a novel choice model of complementary services, we characterize the market shares and utilities of the providers under various peering decisions and identify the value of premium peering for the CPs that fundamentally determine CPs' peering decisions. We find that high-value CPs have peer pressure when low-value CPs peer; however, low-value CPs behave oppositely. The peering decisions of the high-value and low-value CPs are substantially influenced by their baseline market shares and user stickiness, respectively, but not vice versa.",
Co-Bootstrapping Saliency,"In this paper, we propose a visual saliency detection algorithm to explore the fusion of various saliency models in a manner of bootstrap learning. First, an original bootstrapping model, which combines both weak and strong saliency models, is constructed. In this model, image priors are exploited to generate an original weak saliency model, which provides training samples for a strong model. Then, a strong classifier is learned based on the samples extracted from the weak model. We use this classifier to classify all the salient and non-salient superpixels in an input image. To further improve the detection performance, multi-scale saliency maps of weak and strong model are integrated, respectively. The final result is the combination of the weak and strong saliency maps. The original model indicates that the overall performance of the proposed algorithm is largely affected by the quality of weak saliency model. Therefore, we propose a co-bootstrapping mechanism, which integrates the advantages of different saliency methods to construct the weak saliency model thus addresses the problem and achieves a better performance. Extensive experiments on benchmark data sets demonstrate that the proposed algorithm outperforms the state-of-the-art methods.","Feature extraction,
Training,
Computational modeling,
Support vector machines,
Object detection,
Kernel,
Visualization"
Error Analysis of Customer Baseline Load (CBL) Calculation Methods for Residential Customers,"Federal Energy Regulatory Commission (FERC) 745 order has created an environment that allows demand response owners to sell their load reduction in the wholesale market. One of the main challenges that independent system operators and utilities face is developing customer baseline load (CBL) calculation methods that work satisfactorily in this new environment. Consequently, it is critical that these methods need to be evaluated from the error performance's perspective. In this paper, error analysis of CBL calculation methods for residential customers is carried out theoretically and empirically. To perform theoretical analysis, the utility function of customers is analyzed to determine the existence of the economic incentives for gaming and inefficient consumption as well as studying the impact of inaccuracy on the social welfare loss. Furthermore, to perform the empirical analysis, well-established CBL calculation methods, HighXofY (New York ISO, well known as NYISO), LowXofY, MidXofY, exponential moving average (New England ISO, well known as ISONE), and regression are first introduced and, then, utilized to calculate the CBL. A dataset consisting of 262 residential customers is used for this analysis. In addition, the error analysis is performed using accuracy and bias metrics. To reach a valid conclusion about the overall performance of CBL methods, an economic analysis of a hypothetical peak time rebate (PTR) program is carried out. According to the results of the case study, the utility pays at least half of its revenue as a rebate solely due to inaccuracy of CBL methods. In addition, it is demonstrated that PTR creates inefficiencies in the residential sector because of the failure of CBL calculation methods to accurately predict the customers' load profile on the event day.",
Defending against Flow Table Overloading Attack in Software-Defined Networks,"The Software-Defined Network (SDN) is a new and promising network architecture. At the same time, SDN will surely become a new target of cyber attackers. In this paper, we point out one critical vulnerability in SDNs, the size of flow table, which is most likely to be attacked. Due to the expensive and power-hungry features of Ternary Content Addressable Memory (TCAM), a flow table usually has a limited size, which can be easily disabled by a flow table overloading attack (a transformed DDoS attack). To provide a security service in SDN, we proposed a QoS-aware mitigation strategy, namely, peer support strategy, which integrates the available idle flow table resource of the whole SDN system to mitigate such an attack on a single switch of the system. We established a practical mathematical model to represent the studied system, and conducted a thorough analysis for the system in various circumstances. Based on our analysis, we found that the proposed strategy can effectively defeat the flow table overloading attacks. Extensive simulations and testbed-based experiments solidly support our claims. Moreover, our work also shed light on the implementation of SDN networks against possible brute-force attacks.","Switches,
Computer crime,
Quality of service,
Mathematical model,
Servers"
Blind Recovery of Sparse Signals From Subsampled Convolution,"Subsampled blind deconvolution is the recovery of two unknown signals from samples of their convolution. To overcome the ill-posedness of this problem, solutions based on priors tailored to specific practical application have been developed. In particular, sparsity models have provided promising priors. However, in spite of the empirical success of these methods in many applications, existing analyses are rather limited in two main ways: by disparity between the theoretical assumptions on the signal and/or measurement model versus practical setups; or by failure to provide a performance guarantee for parameter values within the optimal regime defined by the information theoretic limits. In particular, it has been shown that a naive sparsity model is not a strong enough prior for identifiability in the blind deconvolution problem. Instead, in addition to sparsity, we adopt a conic constraint, which enforces spectral flatness of the signals. Under this prior together with random dictionary models, we show that the unknown sparse signals can be recovered from samples of their convolution at a rate scaling near optimally with the problem parameters. We also propose an iterative algorithm that is guaranteed to provide robust recovery at the same near optimal sample complexity provided that certain projection steps in the algorithm are successful. In our analysis, we have not verified the success of these projection steps, but these steps are inactive with high probability. Numerical results show the empirical performance of the iterative algorithm agrees with the performance guarantee.","Deconvolution,
Convolution,
Complexity theory,
Iterative methods,
Analytical models,
Minimization"
Autonomous Data Collection Using a Self-Organizing Map,"The self-organizing map (SOM) is an unsupervised learning technique providing a transformation of a high-dimensional input space into a lower dimensional output space. In this paper, we utilize the SOM for the traveling salesman problem (TSP) to develop a solution to autonomous data collection. Autonomous data collection requires gathering data from predeployed sensors by moving within a limited communication radius. We propose a new growing SOM that adapts the number of neurons during learning, which also allows our approach to apply in cases where some sensors can be ignored due to a lower priority. Based on a comparison with available combinatorial heuristic algorithms for relevant variants of the TSP, the proposed approach demonstrates improved results, while also being less computationally demanding. Moreover, the proposed learning procedure can be extended to cases where particular sensors have varying communication radii, and it can also be extended to multivehicle planning.","Data collection,
Urban areas,
Neurons,
Planning,
Robot sensing systems"
A Broadband Differentially Fed Dual-Polarized Planar Antenna,"A novel broadband differentially fed dual-polarized planar antenna is proposed in this communication. The antenna is composed of two dual-dipole elements, each of which is differentially fed by two coaxial cables through a short stub. Four pairs of parasitic elements are introduced to enhance the bandwidth. Both the dual-dipole elements and the parasitic elements are etched on the same substrate, making the antenna feature a planar configuration. The antenna achieves a 15-dB differential impedance bandwidth of 45% (|Sdd11| <; -15 dB), a high isolation of 45 dB, an antenna gain of ~9 dBi, and a half-power beamwidth of 65° ± 8°.","Dipole antennas,
Bandwidth,
Broadband antennas,
Ports (Computers),
Impedance,
Antenna measurements"
Design and Optimization Strategy of Sensor Array Layout for Magnetic Localization System,"Magnetic tracking technology is emerging to provide an occlusion-free tracking scheme for the estimation of full pose of various instruments. This brings substantial benefits for intra-corporeal applications, such as tracking of flexible robots or wireless endoscopic devices, and thus is helpful for further computer-assisted diagnosis, interventions, and surgeries. Towards efficient magnetic tracking, we propose a magnetic localization and orientation system in this paper. By modeling the cylindrical magnet, the magnetic models have been compared and analyzed. Moreover, we present a sensor layout strategy based on grid method and its optimization method for better performance. Based on the magnetic model and the layout optimization results, we have built a sensor array for magnetic positioning. Extensive simulations and experiments have shown the feasibility of the proposed system with the average positional and orientational errors of 1.4mm and 3.4°, respectively.","Magnetic sensors,
Sensor arrays,
Target tracking,
Mathematical model,
Layout,
Permanent magnets"
Stealthy Attacks in Dynamical Systems: Tradeoffs Between Utility and Detectability With Application in Anonymous Systems,"Cyber physical systems which integrate physical system dynamics with digital cyber infrastructure are envisioned to transform our core infrastructural frameworks, such as the smart electricity grid, transportation networks, and advanced manufacturing. This integration, however, exposes the physical system functioning to the security vulnerabilities of cyber communication. Both scientific studies and real-world examples have demonstrated the impact of data injection attacks on complex systems, including the Internet, the smart electricity grid, and air traffic systems. In this paper, an abstract theoretical framework is proposed to study data injection/modification attacks on Markov modeled dynamical systems from the perspective of an adversary. Typical data injection attacks focus on one shot attacks by adversary and the non-detectability of such attacks under static assumptions. In this paper, we study dynamic data injection attacks where the adversary is capable of modifying a temporal sequence of data and the physical controller is equipped with prior statistical knowledge about the data arrival process to detect the presence of an adversary. The goal of the adversary is to modify the arrivals to minimize a utility function of the controller while minimizing the detectability of his presence as measured by the K-L divergence between the prior and posterior distribution of the arriving data. The tradeoff between these two metrics-controller utility and the detectability cost-is studied analytically for different underlying dynamics. The proposed framework is then applied to a practical problem in data networks where a router tries to hide the path of traffic flow from timing analysis by an active adversary who can modify the timing of an incoming packet stream. This problem is studied from the adversary perspective wherein the goal is to balance two costs-the adversary's detectability cost measured by the K-L divergence and the network privacy cost measured by the maximum length of the packet stream whose paths can be hidden by a memory limited router.","Data models,
Power system dynamics,
System dynamics,
Security,
Markov processes,
Privacy,
Control systems"
Modeling Urban Behavior by Mining Geotagged Social Data,"Data generated on location-based social networks provide rich information on the whereabouts of urban dwellers. Specifically, such data reveal who spends time where, when, and on what type of activity (e.g., shopping at a mall, or dining at a restaurant). That information can, in turn, be used to describe city regions in terms of activity that takes place therein. For example, the data might reveal that citizens visit one region mainly for shopping in the morning, while another for dining in the evening. Furthermore, once such a description is available, one can ask more elaborate questions. For example, one might ask what features distinguish one region from another - some regions might be different in terms of the type of venues they host and others in terms of the visitors they attract. As another example, one might ask which regions are similar across cities. In this paper, we present a method to answer such questions using publicly shared Foursquare data. Our analysis makes use of a probabilistic model, the features of which include the exact location of activity, the users who participate in the activity, as well as the time of the day and day of week the activity takes place. Compared to previous approaches to similar tasks, our probabilistic modeling approach allows us to make minimal assumptions about the data - which relieves us from having to set arbitrary parameters in our analysis (e.g., regarding the granularity of discovered regions or the importance of different features). We demonstrate how the model learned with our method can be used to identify the most likely and distinctive features of a geographical area, quantify the importance features used in the model, and discover similar regions across different cities. Finally, we perform an empirical comparison with previous work and discuss insights obtained through our findings.",
Epidemic Processes over Time-Varying Networks,"The spread of viruses in biological networks, computer networks, and human contact networks can have devastating effects; developing and analyzing mathematical models of these systems can provide insights that lead to long-term societal benefits. Prior research has focused mainly on network models with static graph structures, however the systems being modeled typically have dynamic graph structures. In this paper, we consider virus spread models over networks with dynamic graph structures, and we investigate the behavior of these systems. We perform a stability analysis of epidemic processes over time– varying networks, providing sufficient conditions for convergence to the disease free equilibrium (the origin, or healthy state), in both the deterministic and stochastic cases.We present simulation results and discuss quarantine control via simulation.",
Face recognition in real-world images,"Face recognition systems are designed to handle well-aligned images captured under controlled situations. However real-world images present varying orientations, expressions, and illumination conditions. Traditional face recognition algorithms perform poorly on such images. In this paper we present a method for face recognition adapted to real-world conditions that can be trained using very few training examples and is computationally efficient. Our method consists of performing a novel alignment process followed by classification using sparse representation techniques. We present our recognition rates on a difficult dataset that represents real-world faces where we significantly outperform state-of-the-art methods.","Face,
Face recognition,
Training,
Robustness,
Image recognition,
Encoding,
Dictionaries"
Sensor-Based Gait Parameter Extraction With Deep Convolutional Neural Networks,"Measurement of stride-related, biomechanical parameters is the common rationale for objective gait impairment scoring. State-of-the-art double-integration approaches to extract these parameters from inertial sensor data are, however, limited in their clinical applicability due to the underlying assumptions. To overcome this, we present a method to translate the abstract information provided by wearable sensors to context-related expert features based on deep convolutional neural networks. Regarding mobile gait analysis, this enables integration-free and data-driven extraction of a set of eight spatio-temporal stride parameters. To this end, two modeling approaches are compared: a combined network estimating all parameters of interest and an ensemble approach that spawns less complex networks for each parameter individually. The ensemble approach is outperforming the combined modeling in the current application. On a clinically relevant and publicly available benchmark dataset, we estimate stride length, width and medio-lateral change in foot angle up to -0.15 ± 6.09 cm, -0.09 ± 4.22 cm and 0.13 ± 3.78° respectively. Stride, swing and stance time as well as heel and toe contact times are estimated up to ±0.07, ±0.05, ±0.07, ±0.07 and ±0.12 s respectively. This is comparable to and in parts outperforming or defining state of the art. Our results further indicate that the proposed change in the methodology could substitute assumption-driven double-integration methods and enable mobile assessment of spatio-temporal stride parameters in clinically critical situations as, e.g., in the case of spastic gait impairments.","Mobile communication,
Neural networks,
Feature extraction,
Foot,
Biomedical measurement,
Biomechanics,
Wearable sensors"
On the VLSI Energy Complexity of LDPC Decoder Circuits,"Sequences of randomly generated bipartite configurations are analyzed; under mild conditions almost surely such configurations have minimum bisection width proportional to the number of vertices. This implies an almost sure Ω(n2/dmax2) scaling rule for the energy of directlyimplemented low-density parity-check (LDPC) decoder circuits for codes of block length n and maximum node degree dmax. It also implies an Ω(n3/2/dmax) lower bound for serialized LDPC decoders. It is also shown that all (as opposed to almost all) capacity-approaching, directly-implemented non-split-node LDPC decoding circuits, have energy, per iteration, that scales as Ω(χ2 ln3 χ), where χ = (1 - R/C)-1 is the reciprocal gap to capacity, R is code rate, and C is channel capacity.","Parity check codes,
Decoding,
Wires,
Integrated circuit modeling,
Complexity theory,
Computational modeling,
Very large scale integration"
Temporal Summary Images: An Approach to Narrative Visualization via Interactive Annotation Generation and Placement,"Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest (POls). We present Temporal Summary Images (TSIs) as an approach for both exploring this data and creating stories from it. As a visualization, a TSI is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for TSIs to conduct two case studies with large-scale, scientific simulation datasets.","Data visualization,
Visualization,
Strips,
Layout,
Context,
Data analysis,
Additives"
Bilevel Model-Based Discriminative Dictionary Learning for Recognition,"Most supervised dictionary learning methods optimize the combinations of reconstruction error, sparsity prior, and discriminative terms. Thus, the learnt dictionaries may not be optimal for recognition tasks. Also, the sparse codes learning models in the training and the testing phases are inconsistent. Besides, without utilizing the intrinsic data structure, many dictionary learning methods only employ the l0 or I1 norm to encode each datum independently, limiting the performance of the learnt dictionaries. We present a novel bilevel model-based discriminative dictionary learning method for recognition tasks. The upper level directly minimizes the classification error, while the lower level uses the sparsity term and the Laplacian term to characterize the intrinsic data structure. The lower level is subordinate to the upper level. Therefore, our model achieves an overall optimality for recognition in that the learnt dictionary is directly tailored for recognition. Moreover, the sparse codes learning models in the training and the testing phases can be the same. We further propose a novel method to solve our bilevel optimization problem. It first replaces the lower level with its Karush-Kuhn-Tucker conditions and then applies the alternating direction method of multipliers to solve the equivalent problem. Extensive experiments demonstrate the effectiveness and robustness of our method.","Dictionaries,
Learning systems,
Data structures,
Computational modeling,
Testing,
Laplace equations,
Training"
Decision-Based System Identification and Adaptive Resource Allocation,"System identification extracts information from a system's operational data to derive a representative model for the system so that a decision can be made with desired accuracy and reliability. When resources are limited, especially for networked systems sharing data and communication power and bandwidth, identification must consider complexity as a critical limitation. Focusing on optimal resource allocation under a given reliability requirement, this paper studies identification complexity and its relations to decision making. Dynamic resource assignments are investigated. Algorithms are developed and their convergence properties are established, including strong convergence, almost sure convergence rate, and asymptotic normality. By a suitable design of resource updating step sizes, the algorithms are shown to achieve the CR lower bound asymptotically, and hence are asymptotically efficient. Illustrative examples demonstrate significant advantages of our real-time and individualized resource allocation methodologies over population-based worst-case strategies.",
A New PV System Configuration Based on Submodule Integrated Converters,"The power loss due to mismatch effect among interconnected photovoltaic (PV) modules can be significantly reduced by applying the maximum power point tracking to fine granularity level. In this paper, a novel configuration is proposed to utilize a submodule integrated converter (subMIC) for effective solar energy harvesting. Gallium Nitride (GaN) field-effect transistors (FETs) are used to construct the power circuits for high conversion efficiency and high power density. The detailed mathematical analysis is presented to provide insight into the architecture. Simulation is carried out to demonstrate the system behavior in response to real-world atmospheric conditions. The hardware prototype consisting of three subMICs is developed utilizing GaN FET as the power switches, which are based on industrial standard and are compact to fit into the junction box of commercial PV modules. The advantages in terms of conversion efficiency, system cost, and dynamic performance are experimentally proved by the comparison with a benchmark system.","Maximum power point trackers,
Gallium nitride,
Computer architecture,
Field effect transistors,
Power systems,
DC-DC power converters,
Temperature"
An Event-Related Potential-Based Adaptive Model for Telepresence Control of Humanoid Robot Motion in an Environment Cluttered With Obstacles,"This paper develops an event-related potential (ERP)-based adaptive model for the control of humanoid robot movements in an environment cluttered with obstacles based on live video feedback. This model adaptively determines the repetition number according to an individual's mental state to speed up the robot control cycle. N200 and P300 potential features increase in the frontal and occipital areas when using robot images as visual stimuli, so it is able to effectively recognize target visual stimuli by processing Fisher's linear discriminant analysis (FLDA) and to identify a subject's intention by using support vector machine (SVM), in parallel. The offline evaluations show that, compared with a nonadaptive model, the adaptive model increases the accuracy rate from 88.8% to 92.9%, a change of 4.1%, and the information transfer rate (ITR) from 41.3 to 46.3 bits/min, a change of 5.0 bits/min. Eight subjects participated in telepresence controlling a NAO humanoid robot to move in an office environment cluttered with obstacles. The successful maneuvers demonstrate that the brain-controlled humanoid robot can be applied for surveillance and exploration in unknown environments based on live video feedback, which are evaluated by using new metrics for the performance of the brain-robot interaction (BRI) system.",
Occlusion-Model Guided Antiocclusion Depth Estimation in Light Field,"Occlusion is one of the most challenging problems in depth estimation. Previous work has modeled the single-occluder occlusion in light field and achieves good performances, however it is still difficult to obtain accurate depth for multioccluder occlusion. In this paper, we explore the complete occlusion model in light field and derive the occluder-consistency between the spatial and angular spaces, which is used as a guidance to select unoccluded views for each candidate occlusion point. Then, an antiocclusion energy function is built to regularize the depth map. Experimental results on both synthetic and real light-field datasets have demonstrated the advantages of the proposed algorithm compared with state-of-the-art algorithms of light-field depth estimation, especially in multioccluder cases.",
Adaptive Social Learning Based on Crowdsourcing,"Many techniques have been developed to enhance learning experience with computer technology. A particularly great influence of technology on learning came with the emergence of the web and adaptive educational hypermedia systems. While the web enables users to interact and collaborate with each other to create, organize, and share knowledge via user-generated content, majority of e-learning systems do not utilize the power of their users to create high quality educational content and provide data for adaptive algorithms. In this paper, we introduce a novel social learning framework that allows anybody to author educational content in a form of mini-lessons, learn lessons by following adaptive learning pathways as well as interact with their peers as in any social network. The proposed approach combines concepts of crowd-sourcing, online social networks, and complex adaptive systems to engage users in efficient learning through teaching process. We first describe the main idea behind the framework and how users interact with it, and then we describe SALT system that implements the framework. We also performed evaluation of the SALT system via several classroom studies. Our results show that collective learning experiences can be efficiently utilized in adaptive social learning. We found that students tend to form stable clusters that survive very high similarity threshold. Meanwhile, our learning pathway analysis showed that almost all students have their own unique best pathway. Experiments with various recommendation algorithms showed that most algorithms obtain very small penalty in all classes.",
Robust Data-Driven State Estimation for Smart Grid,"A grand challenge for state estimation in newly built smart grid lies in how to deal with the increasing uncertainties. To solve the problem, we propose a data-driven state estimation approach based on recent targeted investment on sensors, data storage, and computing devices. An architecture is proposed to use power system physics and pattern to systematically clean historical data and conduct supervised learning, where historical similar measurements and their states are used to learn the relationship between the current measurement and the state. In order to deal with nonlinearity, kernel trick is used to produce linear mapping in a carefully selected higher dimensional space. To speed up the data-driven approach for online services, we analyze power system data set and discover its clustering property due to the periodic pattern of power systems. This leads to significant dimension reduction and the idea of preorganizing data points in a tree structure for inquiry, leading to 1000 times speedup. Numerical results show that the proposed data-driven approach works well in a smart grid setting with increasing uncertainties and it produces an online state estimate excelling current industrial approach.","State estimation,
Current measurement,
Topology,
Robustness,
Smart grids"
Integration of DC Microgrids as Virtual Synchronous Machines Into the AC Grid,"A smart and autonomous integration concept for dc microgrids into the legacy ac grid is proposed based on the virtual synchronous machine (VSM) concept. It utilizes a dc-ac converter as a universal VSM-based interface (VSMBI) between the ac grid and various distributed energy resources (DER) connected on the dc side. The control strategy of it includes: 1) a frequency regulation improved from previous VSM works, which is suitable for the microgrid integration; 2) an improved dual droop control between the ac frequency and the dc side energy storages; 3) a power system stabilizer to enhance the system stability. Under this concept, the VSMBI integrates the DERs, loads and energy storages in the dc microgrid into a VSM. The VSMBI and the dc microgrid together will respond to short-term and long-term requirements of the grid frequency regulation, and achieve autonomous power management for the ac grid and the dc microgrid. It is therefore an important step forward in supporting high DER penetration. The concept, its design and small-signal analysis are presented in this paper. Its effectiveness and functions are verified by simulation and experimental results.","Microgrids,
Frequency control,
Voltage control,
Power system stability,
DC-AC power converters,
Mathematical model,
Energy storage"
Transmission Capacity Analysis of Relay-Assisted Device-to-Device Overlay/Underlay Communication,"Device-to-device (D2D) communication can effectively meet the demanding high data rate by providing direct links among mobile users in cellular networks. In this paper, we analyze the transmission capacity of relay-assisted D2D communication coexisting with cellular networks in both overlay and underlay modes. D2D users can use the delicate spectrum resources in the overlay mode, while reuse the cellular resources in the underlay mode. Based on stochastic geometry, cellular users, D2D transmitters, and relay nodes (RNs) in the networks are all modeled as Poisson point process. Then, we calculate the RN existence probability and the expectation of relay link distance to obtain the successful transmission probabilities for D2D communication. According to two relay mechanisms for enhancing D2D transmission distance, we further obtain the transmission capacities of D2D communication with the assistance of RNs in both two modes, which reflect the influence from D2D density and power. In addition, the D2D transmission capacities with variable D2D link distance are also analyzed in two modes. Simulation results verify that D2D transmission capacity can be enhanced by relay transmission and influenced by a multitude of factors, including the user density, power, the D2D link distance, and the way of using RNs.","Device-to-device communication,
Relays,
Receivers,
Transmitters,
Interference,
Stochastic processes,
Geometry"
An Analytical Model for False Turn-On Evaluation of High-Voltage Enhancement-Mode GaN Transistor in Bridge-Leg Configuration,"Compared with the state-of-the-art Si-based power devices, enhancement-mode Gallium Nitride (E-mode GaN) transistors have better figures of merit and exhibit great potential in enabling higher switching frequency, higher efficiency, and higher power density for power converters. The bridge-leg configuration circuit, consisting of a controlling switch and a synchronous switch, is a critical component in many power converters. However, owing to the low threshold voltage and fast switching speed, E-mode GaN devices are more prone to false turn-on phenomenon in bridge-leg configuration, leading to undesirable results, such as higher switching loss, circuit oscillation, and shoot through. In order to expand gate terminal's safe operating margin without increasing reverse conduction loss during deadtime, negative gate voltage bias for turn-off and antiparallel diode could be applied to E-mode GaN device. In this paper, with consideration of strong nonlinearities in C-V and I-V characteristics of high-voltage (650 V) E-mode GaN transistors, analytical device models are first developed. Then, we develop an analytical circuit model that combines the circuit parameters with intrinsic characteristics of the high-voltage GaN transistor and antiparallel diode. Thus, key transient waveforms with regard to the false turn-on problem can be acquired, including displacement current and false triggering voltage pulse on gate terminal. The simulated waveforms are then verified on a testing board with GaN-based bridge-leg circuit. In contrast to piecewise switching process models and PSpice simulation, the proposed model exhibits outstanding performances. To provide design guidelines for mitigating false turn-on of GaN transistor, the impacts of different circuit parameters, along with the optimum negative gate voltage bias, are investigated based on the proposed model.","Logic gates,
Gallium nitride,
Transistors,
Integrated circuit modeling,
Inductance,
Switches,
Analytical models"
A Higher Order Hybrid SIE/FEM/SEM Method for the Flexible Electromagnetic Simulation in Layered Medium,"A novel hybrid method is developed for the flexible and accurate electromagnetic simulation of penetrable objects in a layered medium (LM). In this method, the original complex simulation domain is first divided into several subdomains, following the spirit of divide-and-conquer. Each subdomain is then meshed and solved independently, where nonconformal mesh is inevitable. The Riemann type transmission condition is utilized at the interfaces of each subdomain to correctly exchange information so that the solutions of all subdomains converge rapidly to the real solution of the original problem. More specifically, in our method, the surface integral equation (SIE) combined with the LM Green's functions (LMGFs) is adopted for the boundary subdomain, while the finite-element method (FEM) and the spectral element method (SEM) are employed for all the other interior dielectric subdomains. The SIE with LMGFs truncates the simulation domain tightly within the object itself, which drastically decreases the number of unknowns. The interior subdomains are modeled by either FEM or SEM, depending on the geometry and material property of each subdomain. To further enhance the simulation capability, higher order approaches are adopted for all the subdomain solvers in this hybrid method. Several numerical examples are demonstrated, where a high convergence and accuracy of this method is observed. This paper will serve as an efficient and flexible simulation tool for the applications of geophysical exploration.","Finite element analysis,
Mathematical model,
Numerical models,
Integral equations,
Electromagnetics,
Convergence"
A Novel Fall Prediction System on Smartphones,"The elderly person's life is almost full of hazards. Especially, the fall risk is one of the problems caused by the elderly and the people using prostheses. This paper aims to develop a fall prediction system on smartphones. The proposed App system can record users' gait data sets with which their gait statuses regarding stability and symmetry are analyzed. A high-level fuzzy Petri net model is used to identify the human's actions, including normal action, sport, and fall risk. The experimental results indicate that there are high successful predictions obtained by the proposed App system. Thus, it can easily increase the fall risk prevention.","Senior citizens,
Support vector machines,
Petri nets,
Accelerometers,
Smart phones,
Legged locomotion,
Sensors"
Dynamic Load Altering Attacks Against Power System Stability: Attack Models and Protection Schemes,"Dynamic Load Altering Attacks (D-LAA) are introduced as a new class of cyber-physical attacks against smart grid demand response programs. The fundamental characteristics of D-LAAs are explained. Accordingly, D-LAAs are classified in terms of open-loop versus closed-loop attacks, single-point versus multi-point attacks, the type of feedback, and the type of attack controller. A specific closed-loop D-LAA against power system stability is formulated and analyzed, where the attacker controls the changes in the victim load based on a feedback from the power system frequency. A protection system is designed against D-LAAs by formulating and solving a non-convex pole-placement optimization problem. Uncertainty with respect to attack sensor location is addressed. Case studies are presented to assess system vulnerabilities, impacts of single-point and multi-point attacks, and optimal load protection in an IEEE 39 bus test system.","Power system stability,
Power system dynamics,
Generators,
Power grids,
Monitoring,
Frequency measurement,
Frequency control"
Distributed Spatial Multiplexing Systems With Hardware Impairments and Imperfect Channel Estimation Under Rank-1 Rician Fading Channels,"The performance of a multiuser communication system with single-antenna transmitting terminals and a multiantenna base-station receiver is analytically investigated. The system operates under independent and nonidentically distributed rank-1 Rician fading channels with imperfect channel estimation and residual hardware impairments (compensation algorithms are assumed, which mitigate the main impairments) at the transceiver. The spatial multiplexing mode of operation is considered where all the users are simultaneously transmitting their streams to the receiver. Zero forcing is applied along with successive interference cancellation as a means for efficient detection of the received streams. New analytical closed-form expressions are derived for some important performance metrics, namely, the outage probability and ergodic capacity of the entire system. Both the analytical expressions and simulation results show the impact of imperfect channel estimation and hardware impairments to the overall system performance in the usage scenarios of massive multiple-input-multiple-output and millimeter-wave communication systems.","Channel estimation,
Hardware,
Receivers,
Rician channels,
Transceivers,
Multiplexing"
Area-constrained technology mapping for in-memory computing using ReRAM devices,"In-memory computing platforms, such as Resistive RAM (ReRAM), offer natural advantage to data-intensive applications. The benefits of data locality and capability to perform native Boolean operations is exploited for significant performance advantage in multiple contexts ranging across neuromorphic computing, associative memory-based computing, arithmetic benchmarks and general-purpose programmable logic-in-memory computing. Despite these advances, design automation tools supporting in-memory computing are still in a nascent phase. In this work, we investigate for the first time, the problem of minimizing delay under arbitrary area constraint of ReRAM devices. We formulate the problem of area-constrained delay minimization as an Integer Linear Programming (ILP) formulation and further propose heuristics that offers scalability as well as solution close to optimal performance. Area-constrained mapping technology mappings enables unlocking significantly large design space trade-offs.","Delays,
Schedules,
Performance evaluation,
Clocks,
Boolean functions,
Optimal scheduling,
Resistive RAM"
"Silicon Millimeter-Wave, Terahertz, and High-Speed Fiber-Optic Device and Benchmark Circuit Scaling Through the 2030 ITRS Horizon","This paper reviews the technology requirements of future 100-300-GHz millimeter-wave (mm-wave) systems-on-chip (SOI) for high data rate wireless and sensor applications, as well as for 100-300-GBaud fiber-optic communication systems. Measurements of state-of-the-art silicon metal-oxide-semiconductor field-effect transistors (MOSFETs), SiGe heterojunction bipolar transistors (HBTs), and of a variety of HBT-HBT and MOS-HBT cascodes are presented from dc to 325 GHz. The challenges facing mm-wave MOSFET and SiGe HBT device and benchmark circuit scaling toward 2-3-nm gate length and beyond 2-THz transistor Fmax are discussed for the first time based on technology computer-aided design (TCAD) and atomistic simulations. Finally, simulations of the scaling of the SiGe HBT analog and mixed-signal mm-wave benchmark circuit performance across future technology nodes predict that PAs with 45% power added efficiency (PAE) at 220 GHz, track and hold amplifiers (THAs) with over 140-GHz bandwidth, and transimpedance amplifiers (TIAs) with 250-GHz bandwidth and less than 5-dB noise figure will become feasible by 2030. Comparison of simulations and measurements for representative benchmark circuits such as TIAs, THAs, linear modulator drivers, digital-to-analog converters (DACs), and power amplifiers (PAs), fabricated in advanced SiGe BiCMOS and nanoscale SOI complementary metal-oxide-semiconductor (CMOS) technologies, and operating at 120 Gb/s and above 100 GHz, respectively, are presented to support the credibility of the benchmark circuit scaling exercise.",
Deep-Cascade: Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localization in Crowded Scenes,"This paper proposes a fast and reliable method for anomaly detection and localization in video data showing crowded scenes. Time-efficient anomaly localization is an ongoing challenge and subject of this paper. We propose a cubic-patch-based method, characterised by a cascade of classifiers, which makes use of an advanced feature-learning approach. Our cascade of classifiers has two main stages. First, a light but deep 3D auto-encoder is used for early identification of “many” normal cubic patches. This deep network operates on small cubic patches as being the first stage, before carefully resizing the remaining candidates of interest, and evaluating those at the second stage using a more complex and deeper 3D convolutional neural network (CNN). We divide the deep auto-encoder and the CNN into multiple sub-stages, which operate as cascaded classifiers. Shallow layers of the cascaded deep networks (designed as Gaussian classifiers, acting as weak single-class classifiers) detect “simple” normal patches, such as background patches and more complex normal patches, are detected at deeper layers. It is shown that the proposed novel technique (a cascade of two cascaded classifiers) performs comparable to current top-performing detection and localization methods on standard benchmarks, but outperforms those in general with respect to required computation time.","Feature extraction,
Hidden Markov models,
Neural networks,
Training,
Context,
Complexity theory,
Detectors"
Exact routing for micro-electrode-dot-array digital microfluidic biochips,"Digital microfluidics is an emerging technology that provide fluidic-handling capabilities on a chip. One of the most important issues to be considered when conducting experiments on the corresponding biochips is the routing of droplets. A recent variant of biochips uses a micro-electrode-dot-array (MEDA) which yields a finer controllability of the droplets. Although this new technology allows for more advanced routing possibilities, it also poses new challenges to corresponding CAD methods. In contrast to conventional microfluidic biochips, droplets on MEDA biochips may move diagonally on the grid and are not bound to have the same shape during the entire experiment. In this work, we present an exact routing method that copes with these challenges while, at the same time, guarantees to find the minimal solution with respect to completion time. For the first time, this allows for evaluating the benefits of MEDA biochips compared to their conventional counterparts as well as a quality assessment of previously proposed routing methods in this domain.","Routing,
Microelectrodes,
Force,
Sensors,
Very large scale integration,
Shape"
Laser Phase Noise Effects and Joint Carrier Phase Recovery in Coherent Optical Transmissions With Digital Subcarrier Multiplexing,"Digital subcarrier multiplexing (SCM) was proposed for fiber nonlinearity mitigation in long-haul optical transmission but such system has different tolerance to phase noise compared with conventional single carrier system. In this work, a thorough study of phase noise effects in SCM systems is provided. In addition, a novel joint CPR scheme is presented and demonstrated for cycle slip correction in SCM systems, which leads to neither additional pilot overhead nor OSNR penalty.","Laser noise,
Phase noise,
Digital signal processing,
Algorithm design and analysis,
Phase estimation,
Distributed feedback devices,
Optical transmitters"
A Nonconvex Splitting Method for Symmetric Nonnegative Matrix Factorization: Convergence Analysis and Optimality,"Symmetric nonnegative matrix factorization (SymNMF) has important applications in data analytics problems such as document clustering, community detection, and image segmentation. In this paper, we propose a novel nonconvex variable splitting method for solving SymNMF. The proposed algorithm is guaranteed to converge to the set of Karush-Kuhn-Tucker (KKT) points of the nonconvex SymNMF problem. Furthermore, it achieves a global sublinear convergence rate. We also show that the algorithm can be efficiently implemented in parallel. Further, sufficient conditions are provided that guarantee the global and local optimality of the obtained solutions. Extensive numerical results performed on both synthetic and real datasets suggest that the proposed algorithm converges quickly to a local minimum solution.","Signal processing algorithms,
Convergence,
Symmetric matrices,
Algorithm design and analysis,
Matrix decomposition,
Linear programming,
Clustering algorithms"
Robust and Discriminative Labeling for Multi-Label Active Learning Based on Maximum Correntropy Criterion,"Multi-label learning draws great interests in many real world applications. It is a highly costly task to assign many labels by the oracle for one instance. Meanwhile, it is also hard to build a good model without diagnosing discriminative labels. Can we reduce the label costs and improve the ability to train a good model for multi-label learning simultaneously? Active learning addresses the less training samples problem by querying the most valuable samples to achieve a better performance with little costs. In multi-label active learning, some researches have been done for querying the relevant labels with less training samples or querying all labels without diagnosing the discriminative information. They all cannot effectively handle the outlier labels for the measurement of uncertainty. Since maximum correntropy criterion (MCC) provides a robust analysis for outliers in many machine learning and data mining algorithms, in this paper, we derive a robust multi-label active learning algorithm based on an MCC by merging uncertainty and representativeness, and propose an efficient alternating optimization method to solve it. With MCC, our method can eliminate the influence of outlier labels that are not discriminative to measure the uncertainty. To make further improvement on the ability of information measurement, we merge uncertainty and representativeness with the prediction labels of unknown data. It cannot only enhance the uncertainty but also improve the similarity measurement of multi-label data with labels information. Experiments on benchmark multi-label data sets have shown a superior performance than the state-of-the-art methods.",
Robust Coordinated Optimization of Active and Reactive Power in Active Distribution Systems,"Active power dispatch and reactive power optimization problems are usually handled separately in active distribution systems, aiming at minimizing the total generation cost or transmission losses. However, the separate optimization cannot achieve a global optimum scheme in distribution system operations. Moreover, the significant relationship between the active power and reactive power may pose great challenges to distribution system operations due to the uncertain nature of load demands and intermittent renewable energy resources. In this paper, using the branch flow model based relaxed optimal power flow (BFM-ROPF), we formulate a robust coordinated optimization problem for active and reactive powers as a mixed integer second order cone (SOC) programming problem. Furthermore, in order to address the uncertainties, a two-stage robust optimization model is proposed to coordinate the on load tap changer ratios, reactive power compensators, and chargedischarge power of energy storage system (ESS) to find a robust optimal solution. Then the column-and-constraint generation algorithm is applied to solve the proposed robust two-stage optimization model. In the ROPF, a stricter cut is added to speed up the computation process of the SOC relaxation in order to guarantee the exactness for representative cases, such as those with high penetration of distributed energy resources (DERs). Numerical results based on the 33-bus and 69-bus systems verify the effectiveness of the proposed method.","Optimization,
Reactive power,
Robustness,
Load modeling,
Load flow,
Programming,
Uncertainty"
Compact Pattern-Reconfigurable Monopole Antenna Using Parasitic Strips,"A monopole antenna array with pairs of switchable parasitic strips is proposed to realize eight beams for azimuth omnidirectional coverage. The proposed antenna consists of one active monopole and four pairs of parasitic elements. Each pair of parasitic elements is formed by two switchable parasitic strips. By switching p-i-n diodes, a pair of parasitic strips can be used as a director or a reflector. By introducing a shorter parasitic strip between the monopole and the longer strip, the radiation impedance of the monopole is increased when the monopole and the reflector/director are closely positioned. As a result, the diameter of the whole antenna array is only 0.1λ0, where λ0 is the operating wavelength in free space. For demonstration, the antenna is designed to realize eight beams in the azimuth plane with a 45°-angle interval at 1.575 GHz for global positioning service with the peak gain of all the beams larger than 7 dBi at the elevation angle of 60°.","Antenna radiation patterns,
Reflector antennas,
Switches,
Impedance,
Resistance,
Antenna measurements,
Antenna feeds"
"The Deep Learning Vision for Heterogeneous Network Traffic Control: Proposal, Challenges, and Future Perspective","Recently, deep learning, an emerging machine learning technique, is garnering a lot of research attention in several computer science areas. However, to the best of our knowledge, its application to improve heterogeneous network traffic control (which is an important and challenging area by its own merit) has yet to appear because of the difficult challenge in characterizing the appropriate input and output patterns for a deep learning system to correctly reflect the highly dynamic nature of large-scale heterogeneous networks. In this vein, in this article, we propose appropriate input and output characterizations of heterogeneous network traffic and propose a supervised deep neural network system. We describe how our proposed system works and how it differs from traditional neural networks. Also, preliminary results are reported that demonstrate the encouraging performance of our proposed deep learning system compared to a benchmark routing strategy (Open Shortest Path First (OSPF)) in terms of significantly better signaling overhead, throughput, and delay.","Machine learning,
Neural networks,
Heterogeneous networks,
Routing,
Google,
Telecommunication traffic,
Speech recognition"
Analytical Modeling of Interturn Short Circuit for Multiphase Fault-Tolerant PM Machines With Fractional Slot Concentrated Windings,"Interturn short-circuit faults that occur inside stator coils are difficult to cope with compared with terminal short-circuit faults. A general analytical model for interturn short-circuit faults is developed that employs a novel T-type equivalent circuit. When this model is used to investigate the impact of interturn short-circuit faults in permanent-magnet (PM) machines with fractional slot concentrated windings (FSCW), the model delivers fault response predictions that agree very well with results from the finite element analysis. The model is used to show that the 24-slot/14-pole FSCW PM machine is vulnerable to very high interturn fault currents, even when the remaining turns are shorted, offsetting its advantage of low magnetic coupling between phases. FSCW-PM machines that employ aligned coils in phase windings can effectively suppress their interturn fault currents. Experimental verifications are provided for the 24-slot/22-pole FSCW PM prototype machine (with two aligned coils per phase) under the single-turn short-circuit fault.","Windings,
Circuit faults,
Power capacitors,
Integrated circuit modeling,
Coils,
Magnetic flux,
Analytical models"
In Situ and Ex Situ Investigations of KF Postdeposition Treatment Effects on CIGS Solar Cells,"In situ and ex situ characterization were performed to assess the effects of potassium fluoride postdeposition treatment (KF PDT) on Cu(In,Ga)Se2 (CIGS) films and solar cells. Real-time spectroscopic ellipsometry enabled the in situ observation of the modification of the CIGS dielectric function and surface roughness thickness during KF PDT. In addition, deep-level transient spectroscopies (DLTS) and deep-level optical spectroscopies and scanning-DLTS enabled the identification of the nature and location of trap levels. Two main traps were present in both films near Ev + 0.56/0.61 eV and Ev + 0.99 eV, but with clearly lower concentrations for the latter in the KF PDT film. Finally, devices were fabricated, and higher efficiencies were found for the KF PDT devices. SCAPS modeling indicates that the traps identified by deep-level spectroscopies are in part responsible for these changes.","Dielectrics,
Photovoltaic cells,
Spectroscopy,
Ellipsometry,
Substrates,
Real-time systems,
Rough surfaces"
Segmentation-Based Fine Registration of Very High Resolution Multitemporal Images,"In this paper, a segmentation-based approach to fine registration of multispectral and multitemporal very high resolution (VHR) images is proposed. The proposed approach aims at estimating and correcting the residual local misalignment [also referred to as registration noise (RN)] that often affects multitemporal VHR images even after standard registration. The method extracts automatically a set of object representative points associated with regions with homogeneous spectral properties (i.e., objects in the scene). Such points result to be distributed all over the considered scene and account for the high spatial correlation of pixels in VHR images. Then, it estimates the amount and direction of residual local misalignment for each object representative point by exploiting residual local misalignment properties in a multiple displacement analysis framework. To this end, a multiscale differential analysis of the multispectral difference image is employed for modeling the statistical distribution of pixels affected by residual misalignment (i.e., RN pixels) and detect them. The RN is used to perform a segmentation-based fine registration based on both temporal and spatial correlation. Accordingly, the method is particularly suitable to be used for images with a large number of border regions like VHR images of urban scenes. Experimental results obtained on both simulated and real multitemporal VHR images confirm the effectiveness of the proposed method.","Image segmentation,
Feature extraction,
Correlation,
Standards,
Image color analysis,
Image resolution,
Geometry"
Millimeter-Wave Transmission for Small-Cell Backhaul in Dense Urban Environment: a Solution Based on MIMO-OFDM and Space-Time Shift Keying (STSK),"Next generation wireless standards will exploit the wide bandwidth available at the millimeterwave (mm-Wave) frequencies, in particular the E-band (71-76 and 81-86 GHz). This large available bandwidth may be converted into multi-gigabit capacity, when efficient and computationally affordable transceivers are designed to cope with the constrained power budget, the clustered fading, and the high level of phase noise, which actually characterize mm-wave connections. In this paper, we propose a viable multiple-input multiple-output (MIMO) solution for high bit-rate transmission in the E-band with application to small-cell backhaul based on space-time shift keying (STSK) and orthogonal frequency division multiplexing. STSK provides an efficient tradeoff between diversity and multiplexing without interchannel interference and without the need for large antenna arrays. These features make STSK theoretically preferable over other throughput-oriented space-time coding techniques, namely, spatial multiplexing and spatial modulation, which were recently considered in the literature for mm-wave MIMO applications. In this paper, we consider the most significant channel impairments related to small-cell backhaul in dense urban environment, namely, the correlated fading with and without the presence the line-of-sight, the phase noise, the rain attenuation, and shadowing. In addition, we consider small-size MIMO systems (2 × 2 and 4 × 4), and low-cost base station equipments in the perspective of easily deployable small-cell network components. Comparative results, obtained by intensive simulations targeted at assessing link performance and coverage, have clearly shown the superior performance of STSK against counterpart techniques, although obtained at the cost of a somewhat reduced spectral efficiency.","MIMO,
OFDM,
Wireless communication,
5G mobile communication,
Antenna arrays,
Receivers"
"Cascade of Two
W
-Band Helical-Waveguide Gyro-TWTs With High Gain and Output Power: Concept and Modeling","In order to realize a high-power (100 s of kilowatts at the W-band) wideband microwave amplifier, we suggest to use a cascade of two gyrotron traveling-wave tubes (gyro-TWTs), one of which possesses a relatively high gain (40-50 dB) while the other provides a high output power at a moderate (15-20 dB) gain. Both gyro-TWTs are assumed to use helically corrugated waveguides and operate at the second cyclotron harmonic. A principal scheme of such an amplifier chain is discussed, including issues on the microwave input, output, and transmission between the tubes. Computer modeling of the beam-wave interaction using CST Particle Studio PIC Solver shows the possibility of achieving of 200-370-kW output power with 8-10-GHz bandwidth when driving by a 50-mW input source at the W-band.",
A Novel Recurrent Neural Network for Manipulator Control With Improved Noise Tolerance,"In this paper, we propose a novel recurrent neural network to resolve the redundancy of manipulators for efficient kinematic control in the presence of noises in a polynomial type. Leveraging the high-order derivative properties of polynomial noises, a deliberately devised neural network is proposed to eliminate the impact of noises and recover the accurate tracking of desired trajectories in workspace. Rigorous analysis shows that the proposed neural law stabilizes the system dynamics and the position tracking error converges to zero in the presence of noises. Extensive simulations verify the theoretical results. Numerical comparisons show that existing dual neural solutions lose stability when exposed to large constant noises or time-varying noises. In contrast, the proposed approach works well and has a low tracking error comparable to noise-free situations.","Manipulators,
Redundancy,
Kinematics,
Recurrent neural networks,
Mathematical model,
Optimization"
Power System Economic Dispatch Considering Steady-State Secure Region for Wind Power,"In this paper, an economic dispatch model considering a flexible generation redispatch is proposed for managing the wind power variability in electric power systems. The model considers the base-case operation cost as well as the steady-state secure region for the variable wind energy. The generation schedule in the secure region provides grid operators with the boundary for absorbing wind power. The proposed model is formulated as a generalized semi-infinite programming problem and the corresponding solution is presented. The impact of flexible thermal resources and transmission capacity on the calculation of the wind power secure region is also discussed. The proposed solution method is analyzed using the modified IEEE-RTS 1979.","Wind power generation,
Wind farms,
Steady-state,
Generators,
Economics,
Power systems,
Schedules"
Robust Resource Allocation to Enhance Physical Layer Security in Systems With Full-Duplex Receivers: Active Adversary,"We propose a robust resource allocation framework to improve the physical layer security in the presence of an active eavesdropper. In the considered system, we assume that both legitimate receiver and eavesdropper are full-duplex (FD) while most works in the literature concentrate on passive eavesdroppers and half-duplex (HD) legitimate receivers. In this paper, the adversary intends to optimize its transmit and jamming signal parameters so as to minimize the secrecy data rate of the legitimate transmission. In the literature, assuming that the receiver operates in HD mode, secrecy data rate maximization problems subject to the power transmission constraint have been considered in which cooperating nodes act as jammers to confound the eavesdropper. This paper investigates an alternative solution in which we take advantage of FD capability of the receiver to send jamming signals against the eavesdroppers. The proposed self-protection scheme eliminates the need for external helpers. Moreover, we consider the channel state information uncertainty on the links between the active eavesdropper and other legitimate nodes of the network. Optimal power allocation is then obtained based on the worst-case secrecy data rate maximization, under a legitimate transmitter power constraint in the presence of the active eavesdropper. Numerical results confirm the advantage of the proposed secrecy design and in certain conditions, demonstrate substantial performance gain over the conventional approaches.","Receivers,
Jamming,
High definition video,
Relays,
Transmitters,
Resource management,
Physical layer"
Energy-Aware Adaptive Restore Schemes for MLC STT-RAM Cache,"For the sake of higher cell density while achieving near-zero standby power, recent research progress in Magnetic Tunneling Junction (MTJ) devices has leveraged Multi-Level Cell (MLC) configurations of Spin-Transfer Torque Random Access Memory (STT-RAM). However, in orderto mitigate the write disturbance in an MLC strategy, data stored in the soft bit must be restored back immediately after the hard bit switching is completed. Furthermore, as the result of MTJ feature size scaling, the soft bit can be expected to become disturbed by the read sensing current, thus requiring an immediate restore operation to ensure the data reliability. In this paper, we design and analyze a novel Adaptive Restore Scheme for Write Disturbance (ARS-WD) and Read Disturbance (ARS-RD), respectively. ARS-WD alleviates restoration overhead by intentionally overwriting soft bit lines which are less likely to be read. ARS-RD, on the other hand, aggregates the potential writes and restore the soft bit line at the time of its eviction from higher level cache. Both of these two schemes are based on a lightweight forecasting approach for the future read behavior of the cache block. Our experimental results show substantial reduction in soft bit line restore operations, delivering 17.9 percent decrease in overall energy consumption and 9.4 percent increase in IPC, while incurring negligible capacity overhead. Moreover, ARS promotes advantages of MLC to provide a preferable L2 design alternative in terms of energy, area and latency product compared to SLC STT-RAM alternatives.","Magnetic tunneling,
Switches,
Random access memory,
Resistance,
Sensors,
Magnetization,
Reliability"
Lateral Vehicle Trajectory Optimization Using Constrained Linear Time-Varying MPC,"In this paper, a trajectory optimization algorithm is proposed, which formulates the lateral vehicle guidance task along a reference curve as a constrained optimal control problem. The optimization problem is solved by means of a linear time-varying model predictive control scheme that generates trajectories for path following under consideration of various time-varying system constraints in a receding horizon fashion. Formulating the system dynamics linearly in combination with a quadratic cost function has two great advantages. First, the system constraints can be set up not only to achieve collision avoidance with both static and dynamic obstacles, but also aspects of human driving behavior can be considered. Second, the optimization problem can be solved very efficiently, such that the algorithm can be run with little computational effort. In addition, due to an elaborate problem formulation, reference curves with discontinuous, high curvatures will be effortlessly smoothed out by the algorithm. This makes the proposed algorithm applicable to different traffic scenarios, such as parking or highway driving. Experimental results are presented for different real-world scenarios to demonstrate the algorithm's abilities.",
Perceptually Guided Photo Retargeting,"We propose perceptually guided photo retargeting, which shrinks a photo by simulating a human's process of sequentially perceiving visually/semantically important regions in a photo. In particular, we first project the local features (graphlets in this paper) onto a semantic space, wherein visual cues such as global spatial layout and rough geometric context are exploited. Thereafter, a sparsity-constrained learning algorithm is derived to select semantically representative graphlets of a photo, and the selecting process can be interpreted by a path which simulates how a human actively perceives semantics in a photo. Furthermore, we learn the prior distribution of such active graphlet paths (AGPs) from training photos that are marked as esthetically pleasing by multiple users. The learned priors enforce the corresponding AGP of a retargeted photo to be maximally similar to those from the training photos. On top of the retargeting model, we further design an online learning scheme to incrementally update the model with new photos that are esthetically pleasing. The online update module makes the algorithm less dependent on the number and contents of the initial training data. Experimental results show that: 1) the proposed AGP is over 90% consistent with human gaze shifting path, as verified by the eye-tracking data, and 2) the retargeting algorithm outperforms its competitors significantly, as AGP is more indicative of photo esthetics than conventional saliency maps.","Semantics,
Training,
Algorithm design and analysis,
Computer science,
Manifolds,
Visualization,
Probabilistic logic"
Dynamic Projection Mapping onto Deforming Non-Rigid Surface Using Deformable Dot Cluster Marker,"Dynamic projection mapping for moving objects has attracted much attention in recent years. However, conventional approaches have faced some issues, such as the target objects being limited to rigid objects, and the limited moving speed of the targets. In this paper, we focus on dynamic projection mapping onto rapidly deforming non-rigid surfaces with a speed sufficiently high that a human does not perceive any misalignment between the target object and the projected images. In order to achieve such projection mapping, we need a high-speed technique for tracking non-rigid surfaces, which is still a challenging problem in the field of computer vision. We propose the Deformable Dot Cluster Marker (DDCM), a novel fiducial marker for high-speed tracking of non-rigid surfaces using a high-frame-rate camera. The DDCM has three performance advantages. First, it can be detected even when it is strongly deformed. Second, it realizes robust tracking even in the presence of external and self occlusions. Third, it allows millisecond-order computational speed. Using DDCM and a high-speed projector, we realized dynamic projection mapping onto a deformed sheet of paper and a T-shirt with a speed sufficiently high that the projected images appeared to be printed on the objects.",
Robust Multi-Exposure Image Fusion: A Structural Patch Decomposition Approach,"We propose a simple yet effective structural patch decomposition approach for multi-exposure image fusion (MEF) that is robust to ghosting effect. We decompose an image patch into three conceptually independent components: signal strength, signal structure, and mean intensity. Upon fusing these three components separately, we reconstruct a desired patch and place it back into the fused image. This novel patch decomposition approach benefits MEF in many aspects. First, as opposed to most pixel-wise MEF methods, the proposed algorithm does not require post-processing steps to improve visual quality or to reduce spatial artifacts. Second, it handles RGB color channels jointly, and thus produces fused images with more vivid color appearance. Third and most importantly, the direction of the signal structure component in the patch vector space provides ideal information for ghost removal. It allows us to reliably and efficiently reject inconsistent object motions with respect to a chosen reference image without performing computationally expensive motion estimation. We compare the proposed algorithm with 12 MEF methods on 21 static scenes and 12 deghosting schemes on 19 dynamic scenes (with camera and object motion). Extensive experimental results demonstrate that the proposed algorithm not only outperforms previous MEF algorithms on static scenes but also consistently produces high quality fused images with little ghosting artifacts for dynamic scenes. Moreover, it maintains a lower computational cost compared with the state-of-the-art deghosting schemes.","Heuristic algorithms,
Image color analysis,
Cameras,
Dynamics,
Robustness,
Motion estimation,
Dynamic range"
Efficient Multijunction Solar Cell Design for Maximum Annual Energy Yield by Representative Spectrum Selection,"We describe a systematic approach to multijunction solar cell (MJSC) design that unambiguously identifies the spectrum to be used in cell optimization such that local annual energy yield is maximized. A set of candidate spectra is generated from air mass (AM) values ranging from AM1d to AM5d. Each candidate spectrum is used to find the bandgap combination that maximizes cell efficiency and its energy yield is then calculated using an efficient data reduction approach. The bandgap combination that maximizes annual energy yield identifies the representative spectrum. We do this for cells with up to eight junctions across all clear-sky latitudes and compare our results to other cell optimization approaches. Our representative spectrum selection (RSS) approach is robust and highly tolerant of variations in latitude, particularly when compared to the standard AM1.5d approach which, at midlatitudes, cannot be used without suffering an increasingly severe yield penalty. Comparison against the 50% cumulative energy AM (50% AM) design approach is enabled by using the same design conditions (sea level and ASTM standard atmosphere) in order to unambiguously associate each 50% AM value with a cell design spectrum. We find that our RSS approach always produces cells with slightly higher annual energy yields than are achieved by the corresponding 50% AM designs. While both approaches show similar yields for devices with few junctions, we find yield enhancements approaching 1% for cell designs with many junctions, emphasizing the need to consider the spectral variability of the local solar resource. This consideration is systematically enabled by our RSS approach, addressing a deficiency in the previous design approaches.","Photonic band gap,
Junctions,
Optimization,
Photovoltaic cells,
Color,
Standards,
Absorption"
Evolutionary Behavior Tree Approaches for Navigating Platform Games,"Computer games are highly dynamic environments, where players are faced with a multitude of potentially unseen scenarios. In this paper, AI controllers are applied to the Mario AI benchmark platform, by using the grammatical evolution system to evolve behavior tree structures. These controllers are either evolved to both deal with navigation and reactiveness to elements of the game or used in conjunction with a dynamic A* approach. The results obtained highlight the applicability of behavior trees as representations for evolutionary computation and their flexibility for incorporation of diverse algorithms to deal with specific aspects of bot control in game environments.","Games,
Artificial intelligence,
Navigation,
Benchmark testing,
Hazards,
Heuristic algorithms,
Real-time systems"
Energy Efficient Clustering Algorithm for Multi-Hop Wireless Sensor Network Using Type-2 Fuzzy Logic,"Lifetime enhancement has always been a crucial issue as most of the wireless sensor networks (WSNs) operate in unattended environment where human access and monitoring are practically infeasible. Clustering is one of the most powerful techniques that can arrange the system operation in associated manner to attend the network scalability, minimize energy consumption, and achieve prolonged network lifetime. To conquer this issue, current researchers have triggered the proposition of many numerous clustering algorithms. However, most of the proposed algorithms overburden the cluster head (CH) during cluster formation. To overcome this problem, many researchers have come up with the idea of fuzzy logic (FL), which is applied in WSN for decision making. These algorithms focus on the efficiency of CH, which could be adoptive, flexible, and intelligent enough to distribute the load among the sensor nodes that can enhance the network lifetime. But unfortunately, most of the algorithms use type-1 FL (T1FL) model. In this paper, we propose a clustering algorithm on the basis of interval type-2 FL model, expecting to handle uncertain level decision better than T1FL model.","Sensors,
Clustering algorithms,
Fuzzy logic,
Wireless sensor networks,
Protocols,
Mathematical model,
Base stations"
Factored Evolutionary Algorithms,"Factored evolutionary algorithms (FEAs) are a new class of evolutionary search-based optimization algorithms that have successfully been applied to various problems, such as training neural networks and performing abductive inference in graphical models. An FEA is unique in that it factors the objective function by creating overlapping subpopulations that optimize over a subset of variables of the function. In this paper, we give a formal definition of FEA algorithms and present empirical results related to their performance. One consideration in using an FEA is determining the appropriate factor architecture, which determines the set of variables each factor will optimize. For this reason, we present the results of experiments comparing the performance of different factor architectures on several standard applications for evolutionary algorithms. Additionally, we show that FEA's performance is not restricted by the underlying optimization algorithm by creating FEA versions of hill climbing, particle swarm optimization, genetic algorithm, and differential evolution and comparing their performance to their single-population and cooperative coevolutionary counterparts.","Optimization,
Inference algorithms,
Open systems,
Genetic algorithms,
Neural networks,
Evolutionary computation,
Computer architecture"
Adaptive Scheduling of Task Graphs with Dynamic Resilience,"This paper studies a scheduling problem of task graphs on a nondedicated networked computing platform. The networked platform is characterized by a set of fully connected processors such as a multiprocessor system that can be shared by multiple tasks. Therefore, the computation and communication capacities of the computing platform dynamically fluctuate. To deal with this fluctuations for high performance task graph computing, we propose an online dynamic resilience scheduling algorithm called Adaptive Scheduling Algorithm (ASA) that bears certain distinct features compared to existing algorithms. First, the proposed algorithm deliberately assigns tasks to idle processors in multiple rounds to prevent any unfavorable decisions and also to avoid inefficient assignments of certain key tasks to slow processors. Second, the algorithm adopts task duplication as an attempt to minimize serious increase of schedule length due to unexpected processor slowdown. Finally, a look-ahead message transmission policy is applied to save communication time and further improve the overall performance. Performance evaluation results are presented to demonstrate the effectiveness and competitiveness of our approaches when compared with the existing algorithms.","Program processors,
Heuristic algorithms,
Processor scheduling,
Dynamic scheduling,
Computers,
Clustering algorithms"
Bayesian Random Vector Functional-Link Networks for Robust Data Modeling,"Random vector functional-link (RVFL) networks are randomized multilayer perceptrons with a single hidden layer and a linear output layer, which can be trained by solving a linear modeling problem. In particular, they are generally trained using a closed-form solution of the (regularized) least-squares approach. This paper introduces several alternative strategies for performing full Bayesian inference (BI) of RVFL networks. Distinct from standard or classical approaches, our proposed Bayesian training algorithms allow to derive an entire probability distribution over the optimal output weights of the network, instead of a single pointwise estimate according to some given criterion (e.g., least-squares). This provides several known advantages, including the possibility of introducing additional prior knowledge in the training process, the availability of an uncertainty measure during the test phase, and the capability of automatically inferring hyper-parameters from given data. In this paper, two BI algorithms for regression are first proposed that, under some practical assumptions, can be implemented by a simple iterative process with closed-form computations. Simulation results show that one of the proposed algorithms, Bayesian RVFL, is able to outperform standard training algorithms for RVFL networks with a proper regularization factor selected carefully via a line search procedure. A general strategy based on variational inference is also presented, with an application to data modeling problems with noisy outputs or outliers. As we discuss in this paper, using recent advances in automatic differentiation this strategy can be applied to a wide range of additional situations in an immediate fashion.","Training,
Standards,
Bayes methods,
Data models,
Robustness,
Inference algorithms,
Computational modeling"
PLAN: Joint Policy- and Network-Aware VM Management for Cloud Data Centers,"Policies play an important role in network configuration and therefore in offering secure and high performance services especially over multi-tenant Cloud Data Center (DC) environments. At the same time, elastic resource provisioning through virtualization often disregards policy requirements, assuming that the policy implementation is handled by the underlying network infrastructure. This can result in policy violations, performance degradation and security vulnerabilities. In this paper, we define PLAN, a PoLicy-Aware and Network-aware VM management scheme to jointly consider DC communication cost reduction through Virtual Machine (VM) migration while meeting network policy requirements. We show that the problem is NP-hard and derive an efficient approximate algorithm to reduce communication cost while adhering to policy constraints. Through extensive evaluation, we show that PLAN can reduce topology-wide communication cost by 38 percent over diverse aggregate traffic and configuration policies.","Middleboxes,
Web servers,
Cloud computing,
Electronic mail,
Network topology"
Efficient and exact query of large process model repositories in cloud workflow systems,"As cloud computing platforms are widely accepted by more and more enterprises and individuals, the underlying cloud workflow systems accumulate large numbers of business process models. Retrieving and recommending the most similar process models according to the tenant?s requirements become extremely important, for it is not only beneficial to promote the reuse of the existing model assets, but also helpful to reduce the error rate of the modeling process. Since the scales of cloud workflow repositories become bigger and bigger, developing efficient and exact query approaches is urgent. To this end, an improved two-stage exact query approach based on graph structure is proposed. In the filtering stage, the composite task index, which consists of the label, join-attribute and split-attribute of a task, is adopted to acquire candidate models, which can greatly reduce the number of process models needed to be tested by a time-consuming verification algorithm. In the verification stage, a novel subgraph isomorphism test based on task code is proposed to refine the candidate model set. Experiments are conducted on 6 synthetic model sets and 2 real model sets. The results demonstrate that the presented approach can significantly improve the query efficiency and reduce the query response time.","Filtering,
Computational modeling,
Business,
Algorithm design and analysis,
Indexing,
Semantics"
Customer-Satisfaction-Aware Optimal Multiserver Configuration for Profit Maximization in Cloud Computing,"Along with the development of cloud computing, an increasing number of enterprises start to adopt cloud service, which promotes the emergence of many cloud service providers. For cloud service providers, how to configure their cloud service platforms to obtain the maximum profit becomes increasingly the focus that they pay attention to. In this paper, we take customer satisfaction into consideration to address this problem. Customer satisfaction affects the profit of cloud service providers in two ways. On one hand, the cloud configuration affects the quality of service which is an important factor affecting customer satisfaction. On the other hand, the customer satisfaction affects the request arrival rate of a cloud service provider. However, few existing works take customer satisfaction into consideration in solving profit maximization problem, or the existing works considering customer satisfaction do not give a proper formalized definition for it. Hence, we first refer to the definition of customer satisfaction in economics and develop a formula for measuring customer satisfaction in cloud computing. And then, an analysis is given in detail on how the customer satisfaction affects the profit. Lastly, taking into consideration customer satisfaction, service-level agreement, renting price, energy consumption, and so forth, a profit maximization problem is formulated and solved to get the optimal configuration such that the profit is maximized.","Cloud computing,
Customer satisfaction,
Quality of service,
Computational modeling,
Optimization,
Economics,
Companies"
Moving Object Detection With a Freely Moving Camera via Background Motion Subtraction,"Detection of moving objects in a video captured by a freely moving camera is a challenging problem in computer vision. Most existing methods often assume that the background (BG) can be approximated by dominant single plane/multiple planes or impose significant geometric constraints on BG, or utilize a complex BG/foreground probabilistic model. Instead, we propose a computationally efficient algorithm that is able to detect moving objects accurately and robustly in a general 3D scene. This problem is formulated as a coarse-to-fine thresholding scheme on the particle trajectories in the video sequence. First, a coarse foreground (CFG) region is extracted by performing reduced singular value decomposition on multiple matrices that are built from bundles of particle trajectories. Next, the BG motion of pixels in the CFG region is reconstructed by a fast inpainting method. After subtracting the BG motion, the fine foreground is segmented out by an adaptive thresholding method that is capable of solving multiple-moving-objects scenarios. Finally, the detected foreground is further refined by the mean-shift segmentation method. Extensive simulations and a comparison with the state-of-the-art methods verify the effectiveness of the proposed method.","Cameras,
Trajectory,
Three-dimensional displays,
Matrix decomposition,
Object detection,
Probabilistic logic,
Motion segmentation"
An Adaptive Bayesian System for Context-Aware Data Fusion in Smart Environments,"The adoption of multi-sensor data fusion techniques is essential to effectively merge and analyze heterogeneous data collected by multiple sensors, pervasively deployed in a smart environment. Existing literature leverages contextual information in the fusion process, to increase the accuracy of inference and hence decision making in a dynamically changing environment. In this paper, we propose a context-aware, self-optimizing, adaptive system for sensor data fusion, based on a three-tier architecture. Heterogeneous data collected by sensors at the lowest tier are combined by a dynamic Bayesian network at the intermediate tier, which also integrates contextual information to refine the inference process. At the highest tier, a self-optimization process dynamically reconfigures the sensory infrastructure, by sampling a subset of sensors in order to minimize energy consumption and maximize inference accuracy. A Bayesian approach allows to deal with the imprecision of sensory measurements, due to environmental noise and possible hardware malfunctions. The effectiveness of our approach is demonstrated with the application scenario of the user activity recognition in an Ambient Intelligence system managing a smart home environment. Experimental results show that the proposed solution outperforms static approaches for context-aware multi-sensor fusion, achieving substantial energy savings whilst maintaining a high degree of inference accuracy.",
Designing a Vibrotactile Head-Mounted Display for Spatial Awareness in 3D Spaces,"Due to the perceptual characteristics of the head, vibrotactile Head-mounted Displays are built with low actuator density. Therefore, vibrotactile guidance is mostly assessed by pointing towards objects in the azimuthal plane. When it comes to multisensory interaction in 3D environments, it is also important to convey information about objects in the elevation plane. In this paper, we design and assess a haptic guidance technique for 3D environments. First, we explore the modulation of vibration frequency to indicate the position of objects in the elevation plane. Then, we assessed a vibrotactile HMD made to render the position of objects in a 3D space around the subject by varying both stimulus loci and vibration frequency. Results have shown that frequencies modulated with a quadratic growth function allowed a more accurate, precise, and faster target localization in an active head pointing task. The technique presented high usability and a strong learning effect for a haptic search across different scenarios in an immersive VR setup.","Three-dimensional displays,
Frequency modulation,
Vibrations,
Azimuthal plane,
Haptic interfaces,
Visualization,
Skin"
Semidefinite Relaxation-Based Optimization of Multiple-Input Wireless Power Transfer Systems,"An optimization procedure for multitransmitter multiple-input single-output (MISO) wireless power transfer (WPT) systems based on tight semidefinite relaxation (SDR) is presented. This method ensures physical realizability of MISO WPT systems designed via convex optimization-a robust, semianalytical, and intuitive route to optimizing such systems. To that end, the nonconvex constraints requiring that power is fed into rather than drawn from the system via all transmitter ports are incorporated in a convex SDR, which is efficiently and reliably solvable by dedicated algorithms. A test of the solution then confirms that this modified problem is equivalent (tight relaxation) to the original (nonconvex) one and that the true global optimum has been found. This is a clear advantage over global optimization methods (e.g., genetic algorithms), where convergence to the true global optimum cannot be ensured or tested. Discussions of numerical results yielded by both the closed-form expressions and the refined technique illustrate the importance and practicability of the new method. It is shown that this technique offers a rigorous optimization framework for a broad range of current and emerging WPT applications.","Receivers,
Optimization,
Transmitters,
MISO,
Impedance,
Resistance,
Load modeling"
Exploring Locally Adaptive Dimensionality Reduction for Hyperspectral Image Classification: A Maximum Margin Metric Learning Aspect,"The high-dimensional data space generated by hyperspectral sensors introduces challenges for the conventional data analysis techniques. Popular dimensionality reduction techniques usually assume a Gaussian distribution, which may not be in accordance with real life. Metric learning methods, which explore the global data structure of the labeled training samples, have proved to be very efficient in hyperspectral fields. However, we can go further by utilizing locally adaptive decision constraints for the labeled training samples per class to obtain an even better performance. In this paper, we present the locally adaptive dimensionality reduction metric learning (LADRml) method for hyperspectral image classification. The aims of the presented method are: 1) first, to utilize the limited training samples to reduce the dimensionality of data without a certain distribution hypothesis; and 2) second, to better handle data with complex distributions by the use of locally adaptive decision constraints, which can assess the similarity between a pair of samples based on the distance changes before and after metric learning. The experimental results obtained with a number of challenging hyperspectral image datasets demonstrate that the proposed LADRml algorithm outperforms the state-of-the-art dimensionality reduction and metric learning methods.","Measurement,
Hyperspectral imaging,
Learning systems,
Training,
Earth"
Automatic Design of High-Sensitivity Color Filter Arrays With Panchromatic Pixels,"In most of existing digital cameras, color images have to be reconstructed from raw images, which only have one color sensed at each pixel, as their imaging sensors are covered by color filter arrays (CFAs). At each pixel, a CFA usually allows only a portion of the light spectrum to pass through, and thereby reduces the light sensitivity of pixels. To address this issue, previous works have explored adding panchromatic pixels into CFAs. However, almost all existing methods assign panchromatic pixels empirically, making the designed CFAs prone to aliasing artifacts. In this paper, based on a mathematical model, we propose a fully automatic approach to designing high-sensitivity CFAs using panchromatic pixels. By the frequency structure representation of CFAs, we formulate high-sensitivity CFA design as a continuous multi-objective optimization problem, where robustness to aliasing artifacts and percentage of panchromatic pixels are simultaneously maximized. We analyze the characteristics of our new formulation. According to the analysis, we develop a new method to propose frequency structure candidates, which can produce CFAs that reach a desired percentage of panchromatic pixels. Then for each candidate, we optimize parameters to obtain the final CFA, which is an appropriately balanced solution to the multi-objective optimization problem. We formulate the two design procedures as constrained optimization problems and solve them using the alternating direction method. Extensive experiments confirm the advantage of the proposed method in both low-light and normal-light conditions.","Image color analysis,
Color,
Sensor arrays,
Sensitivity,
Optimization,
Image reconstruction,
Robustness"
Distributed Robust Bilinear State Estimation for Power Systems with Nonlinear Measurements,"This paper proposes a fully distributed robust bilinear state-estimation (D-RBSE) method that is applicable to multi-area power systems with nonlinear measurements. We extend the recently introduced bilinear formulation of state estimation problems to a robust model. A distributed bilinear state-estimation procedure is developed. In both linear stages, the state estimation problem in each area is solved locally, with minimal data exchange with its neighbors. The intermediate nonlinear transformation can be performed by all areas in parallel without any need of inter-regional communication. This algorithm does not require a central coordinator and can compress bad measurements by introducing a robust state estimation model. Numerical tests on IEEE 14-bus, 118-bus benchmark systems, and a 1062-bus system demonstrate the validity of the method.","State estimation,
Robustness,
Pollution measurement,
Power systems,
Distributed algorithms,
Convergence,
Numerical models"
How Social and Communication Channels Shape and Challenge a Participatory Culture in Software Development,"Software developers use many different communication tools and channels in their work. The diversity of these tools has dramatically increased over the past decade and developers now have access to a wide range of socially enabled communication channels and social media to support their activities. The availability of such social tools is leading to a participatory culture of software development, where developers want to engage with, learn from, and co-create software with other developers. However, the interplay of these social channels, as well as the opportunities and challenges they may create when used together within this participatory development culture are not yet well understood. In this paper, we report on a large-scale survey conducted with 1,449 GitHub users. We discuss the channels these developers find essential to their work and gain an understanding of the challenges they face using them. Our findings lay the empirical foundation for providing recommendations to developers and tool designers on how to use and improve tools for software developers.","Software,
Communication channels,
Media,
Collaboration,
Electronic mail,
Face,
Knowledge engineering"
Distributed Charge Scheduling of Plug-In Electric Vehicles Using Inter-Aggregator Collaboration,"Plug-in electric vehicles (PEVs) are emerging as an eco-friendly and cost-effective alternative to conventional vehicles driven by internal combustion engines. However, uncoordinated charging of a large number of PEVs may cause grid failure. Therefore, charge scheduling of PEVs is an important problem. However, the charge scheduling by a single aggregator does not scale well as the PEV population grows. We propose a distributed framework for efficient PEV charging with multiple aggregators in a city where a PEV raises its charging request to a specific aggregator, and each aggregator has partial information about others. The aggregators collaborate among themselves for scheduling PEVs for charging in different charging stations owned by it or others. In this paper, we formulate a bi-objective charge scheduling optimization problem that attempts to maximize the total profit of the aggregators while maximizing the total number of PEVs charged. We first prove that the problem is NP-complete. We then propose distributed offline and online algorithms to solve the problem, and present simulation results for some realistic traffic scenarios.","Charging stations,
Collaboration,
Schedules,
Silicon,
Cities and towns,
Electric vehicles"
Passivity and Output Synchronization of Complex Dynamical Networks With Fixed and Adaptive Coupling Strength,"This paper considers a complex dynamical network model, in which the input and output vectors have different dimensions. We, respectively, investigate the passivity and the relationship between output strict passivity and output synchronization of the complex dynamical network with fixed and adaptive coupling strength. First, two new passivity definitions are proposed, which generalize some existing concepts of passivity. By constructing appropriate Lyapunov functional, some sufficient conditions ensuring the passivity, input strict passivity and output strict passivity are derived for the complex dynamical network with fixed coupling strength. In addition, we also reveal the relationship between output strict passivity and output synchronization of the complex dynamical network with fixed coupling strength. By employing the relationship between output strict passivity and output synchronization, a sufficient condition for output synchronization of the complex dynamical network with fixed coupling strength is established. Then, we extend these results to the case when the coupling strength is adaptively adjusted. Finally, two examples with numerical simulations are provided to demonstrate the effectiveness of the proposed criteria.",
"Two-Step Narrow Ridge Cascade Diode Lasers Emitting Near 2~\mu
m",Nearly diffraction limited GaSb-based type-I quantum well cascade diode lasers emitting in the spectral region 1.95-2 μm were designed and fabricated. Two-step 5.5-μm-wide shallow and 14-μm-wide deep etched ridge waveguide design yielded devices generating stable single lobe beams with 250 mW of continuous wave output power at 20 °C. Quantum well radiative recombination current contributes about 13% to laser threshold as estimated from true spontaneous emission and modal gain analysis. Recombination at etched sidewalls of the 14-μmwide deep ridges controls about 30% of the threshold.,"Waveguide lasers,
Quantum cascade lasers,
Optical waveguides,
Laser modes,
Measurement by laser beam,
Current density"
Particle Swarm Optimization for high-DOF inverse kinematics,"The inverse kinematics (IK) problem is a fundamental problem in robotic manipulation. Traditional, Jacobian-based solutions to this problem are known to scale poorly with the number of degrees of freedom (DOF) in the manipulator, necessitating novel IK solutions for high-DOF manipulators. Metaheuristic optimization algorithms such as Particle Swarm Optimization (PSO) are a promising alternative approach to traditional IK techniques due to their strong performance on difficult and high-DOF problems in many diverse domains. Previous applications of PSO to the IK problem have focused on specific classes (e.g., planar) or models of manipulators or specific IK subproblems (e.g., position only IK). Furthermore, the experimental validation of these techniques has considered only manipulators with seven or fewer degrees of freedom and taken place almost exclusively in simulation. In this paper, we (1) generalize previous work to derive a fitness function that can be minimized to solve the full position and orientation IK problem for any serial manipulator while respecting joint limits and avoiding self-collisions, (2) present the first statistical analysis of PSO as a high-DOF IK solver on simulated manipulators with up to 180 DOF using this fitness function, and (3) present an important validation of PSO-based IK using this fitness function on real-world hardware on a difficult precision manipulation task.",
RAAC: Robust and Auditable Access Control With Multiple Attribute Authorities for Public Cloud Storage,"Data access control is a challenging issue in public cloud storage systems. Ciphertext-policy attribute-based encryption (CP-ABE) has been adopted as a promising technique to provide flexible, fine-grained, and secure data access control for cloud storage with honest-but-curious cloud servers. However, in the existing CP-ABE schemes, the single attribute authority must execute the time-consuming user legitimacy verification and secret key distribution, and hence, it results in a single-point performance bottleneck when a CP-ABE scheme is adopted in a large-scale cloud storage system. Users may be stuck in the waiting queue for a long period to obtain their secret keys, thereby resulting in low efficiency of the system. Although multi-authority access control schemes have been proposed, these schemes still cannot overcome the drawbacks of single-point bottleneck and low efficiency, due to the fact that each of the authorities still independently manages a disjoint attribute set. In this paper, we propose a novel heterogeneous framework to remove the problem of single-point performance bottleneck and provide a more efficient access control scheme with an auditing mechanism. Our framework employs multiple attribute authorities to share the load of user legitimacy verification. Meanwhile, in our scheme, a central authority is introduced to generate secret keys for legitimacy verified users. Unlike other multi-authority access control schemes, each of the authorities in our scheme manages the whole attribute set individually. To enhance security, we also propose an auditing mechanism to detect which attribute authority has incorrectly or maliciously performed the legitimacy verification procedure. Analysis shows that our system not only guarantees the security requirements but also makes great performance improvement on key generation.","Access control,
Cloud computing,
Robustness,
Electronic mail,
Encryption"
A Triple-mode Wideband Bandpass Filter Using Single Rectangular Waveguide Cavity,"A triple-mode wideband bandpass filter (BPF) is proposed. It consists of a single rectangular waveguide cavity with two small metal rods to be inserted into the cavity from input/output feeding ports. As such, one TM110 mode, one TM210 mode, and one TM130 mode can be simultaneously excited in this cavity to form up a wide frequency passband. The fractional bandwidth is 58% at center frequency of 5.5 GHz with low insertion loss (<;0.5 dB). Furthermore, this design approach is good for miniaturization compared with traditional single-mode filter. For validation, a proposed filter is fabricated using silver-plated aluminum metal cavity. Both theoretical and measured results are presented with good agreement.","Cavity resonators,
Wideband,
Couplings,
Band-pass filters,
Wireless communication,
Rectangular waveguides"
Plug-In Electric Vehicle to Home (V2H) Operation Under a Grid Outage,"This paper investigates vehicle-to-home (V2H) operation that provides backup power under outage of the external electric grid. First, we introduce a novel optimization model that aims at maximizing backup duration. Motivated by the optimization problem, a new algorithm for V2H system is proposed. Subsequently, we extend the model to vehicles-to-homes (Vs2Hs) composed of multiple homes, electric vehicles, and photovoltaic generation. An algorithm for Vs2Hs considering scheduling of its energy resources is suggested. Numerical simulations show that the proposed algorithms provide sufficient backup duration while maintaining relative simplicity. The effectiveness of Vs2Hs is also investigated using simulations.","Batteries,
Optimization,
Petroleum,
Generators,
Microgrids"
Cloud-Based Utility Service Framework for Trust Negotiations Using Federated Identity Management,"Utility based cloud services can efficiently provide various supportive services to different service providers. Trust negotiations with federated identity management are vital for preserving privacy in open systems such as distributed collaborative systems. However, due to the large amounts of server based communications involved in trust negotiations scalability issues prove to be less cumbersome when offloaded on to the cloud as a utility service. In this view, we propose trust based federated identity management as a cloud based utility service. The main component of this model is the trust establishment between the cloud service provider and the identity providers. We propose novel trust metrics based on the potential vulnerability to be attacked, the available security enforcements and a novel cost metric based on policy dependencies to rank the cooperativeness of identity providers. Practical use of these trust metrics is demonstrated by analyses using simulated data sets, attack history data: published by MIT Lincoln laboratory, real-life attacks and vulnerabilities extracted from Common Vulnerabilities and Exposures (CVE) repository and fuzzy rule based evaluations. The results of the evaluations imply the significance of the proposed trust model to support cloud based utility services to ensure reliable trust negotiations using federated identity management.","Reliability,
Cloud computing,
Collaboration,
Computational modeling,
Measurement,
Authorization,
Interoperability"
An HSS Matrix-Inspired Butterfly-Based Direct Solver for Analyzing Scattering From Two-Dimensional Objects,"A butterfly-based fast direct integral equation solver for analyzing high-frequency scattering from two-dimensional objects is presented. The solver leverages a randomized butterfly scheme to compress blocks corresponding to near- and far-field interactions in the discretized forward and inverse electric field integral operators. The observed memory requirements and computational cost of the proposed solver scale as O(N log2N and O(N1.5log N) , respectively. The solver is applied to the analysis of scattering from electrically large objects spanning over 10 000 wavelengths and modeled in terms of five million unknowns.","Scattering,
Sparse matrices,
Impedance,
Memory management,
Matrix decomposition,
Integral equations,
Electric fields"
Fast signature spotting in continuous air writing,"Development of depth sensors paves way for implementation of touch-less biometric authentication systems using 3D gestures or signatures. No keys or passwords are required in such systems to prove identities. Moreover, the systems do not suffer from various security risks such as stolen passwords or loss of passwords. In this paper, we propose such a security system that is robust in nature by allowing a user to perform random gestures before and after a signature during authentication. Since the signature can appear within any position of a gesture pattern, correct spotting of the actual signature is extremely important. In this paper, we propose a signature spotting mechanism that has been accomplished using a window-based analysis on feature sequence. An efficient searching strategy has been proposed using 3D convex hull points. Dynamic Time Warping (DTW) has been used to perform the verification of the spotted signatures. Our proposed method achieves 80% accuracy for signature spotting with less computational overhead. The method can be used, on applications requiring robust authentication in a huge dataset.","Three-dimensional displays,
Writing,
Authentication,
Training,
Sensors"
Distributed Real-Time Optimal Power Flow Control in Smart Grid,"Conventionally, power system has a hierarchical control structure including primary, secondary, and tertiary controls. The drawbacks of this hierarchical scheme are manifest: 1) it lacks flexibility and scalability, which is against the trend toward an open-access power system; 2) load forecast as the basis of tertiary control could be inaccurate and infeasible, especially in microgrid for example; 3) as the penetration of renewable energy increases, the relatively long time-scales of secondary and tertiary controls cannot accommodate to more severe power fluctuation within the system. To avoid these drawbacks, a distributed real-time optimal power flow control strategy is introduced in this paper. With the aid of up-to-date smart grid technologies such as two-way communication and distributed sensor, the proposed approach can avoid the need of load forecast and achieve the same objective as hierarchical control with a feedback mechanism in real time, that is to recover the nominal system frequency and maintain the active power of the generators close to the optimal operational condition in the presence of any disturbance. Convergence of the proposed approach is analytically proved. Simulation results in a 34-bus islanded microgrid and the IEEE 118-bus bulk power grid validate the effectiveness and efficiency of the proposed approach.","Frequency control,
Generators,
Real-time systems,
Smart grids,
Power system stability,
Load forecasting"
Protection Coordination Index Enhancement Considering Multiple DG Locations Using FCL,"Increasing the penetration level of distributed generation (DG) may lead to improper protection coordination. Previous work introduced a protection coordination index (PCI) that can quantify the impact of installing a DG at individual locations. This paper extends on previous work and proposes a generalized approach for calculating PCI considering multiple DG locations simultaneously. Furthermore, this paper proposes a solution for enhancing the PCI using fault current limiters (FCL). The problem is formulated as a mixed-integer nonlinear programming problem to determine the optimal FCL size and location as well as enhanced PCI.","Relays,
Fault currents,
Indexes,
Performance evaluation,
Optimization,
Distributed power generation,
Genetic algorithms"
Sequence Learning with Passive RFID Sensors for Real-Time Bed-Egress Recognition in Older People,"Getting out of bed and ambulating without supervision is identified as one of the major causes of patient falls in hospitals and nursing homes. Therefore, increased supervision is proposed as a key strategy toward falls prevention. An emerging generation of batteryless, lightweight, and wearable sensors are creating new possibilities for ambulatory monitoring, where the unobtrusive nature of such sensors makes them particularly adapted for monitoring older people. In this study, we investigate the use of a batteryless radio-frequency identification (RFID) tag response to analyze bed-egress movements. We propose a bed-egress movement detection framework that includes a novel sequence learning classifier with a set of features derived from bed-egress motion analysis. We analyzed data from 14 healthy older people (66-86 years old) who wore a wearable embodiment of a batteryless accelerometer integrated RFID sensor platform loosely attached over their clothes at sternum level, and undertook a series of activities including bed-egress in two clinical room settings. The promising results indicate the efficacy of our batteryless bed-egress monitoring framework.","Radiofrequency identification,
Antennas,
Hospitals,
Monitoring,
Accelerometers,
Sensor phenomena and characterization"
Adaptive State of Charge Estimation of Lithium-Ion Batteries With Parameter and Thermal Uncertainties,"In this brief, an adaptive state of charge (SOC) estimation strategy is proposed for lithium-ion batteries. The proposed methodology makes use of adaptive control theory to track online parameter variation. The convergence and stability of the proposed estimator are guaranteed by Lyapunov's direct method as opposed to many existing procedures. Since temperature variations introduce a drift in the battery's parameters, a compensation methodology is also proposed to cope with this effect. Therefore, robustness to both parameter and temperature variations is obtained, which yields precise SOC estimation. The proposed estimation scheme is validated through a set of experiments under different currents and temperatures. The experimental results reveal high performance in determining the SOC with high accuracy.","State of charge,
Batteries,
Estimation,
Temperature measurement,
Uncertainty,
Thermal stability,
Integrated circuit modeling"
Design of a Real-Time ECG Filter for Portable Mobile Medical Systems,"Electrocardiogram (ECG) signal is a direct and effective way to find cardiovascular disease timely, which can intuitively reflect changes of the heart beat and activities of different parts. Due to the noise interference from surroundings, acquisition of real-time and high-quality ECG signal is a big challenge for portable mobile medical systems. Integer coefficients infinite impulse response (IIR) digital filter is suitable for portable mobile platform, but it will be a little bit of distortion. So, an improved integer IIR filter for portable ECG monitors is presented in this paper. The proposed IIR filter can instantaneously and effectively eliminate baseline drift of main interference frequency band and 50-Hz power frequency interference in ECG signal. The method is verified by a specific example and MIT/BIH Arrhythmia Database. The improved integer coefficients IIR filter was applied in a portable mobile medical system. It can meet the requirements of ECG filtering in real-time and filtering performance.","Electrocardiography,
Interference (signal),
Mobile communication,
IIR filters,
Real-time systems,
Cardiovascular diseases,
Medical devices,
Portable computers"
EEG-Based Strategies to Detect Motor Imagery for Control and Rehabilitation,"Advances in brain-computer interface (BCI) technology have facilitated the detection of Motor Imagery (MI) from electroencephalography (EEG). First, we present three strategies of using BCI to detect MI from EEG: operant conditioning that employed a fixed model, machine learning that employed a subject-specific model computed from calibration, and adaptive strategy that continuously compute the subject-specific model. Second, we review prevailing works that employed the operant conditioning and machine learning strategies. Third, we present our past work on six stroke patients who underwent a BCI rehabilitation clinical trial with averaged accuracies of 79.8% during calibration and 69.5% across 18 online feedback sessions. Finally, we perform an offline study in this paper on our work employing the adaptive strategy. The results yielded significant improvements of 12% (p <; 0.001) and 9% (p <; 0.001) using all the data and using limited preceding data respectively in the feedback accuracies. The results showed an increase in the amount of training data yielded improvements. Nevertheless, results of using limited preceding data showed a larger part of the improvement was due to the adaptive strategy and changing subject-specific models did not deteriorate the accuracies. Hence the adaptive strategy is effective in addressing the non-stationarity between calibration and feedback sessions.",
Video-based face recognition using ensemble of haar-like deep convolutional neural networks,"Growing number of surveillance and biometric applications seek to recognize the face of individuals appearing in the viewpoint of video cameras. Systems for video-based FR can be subjected to challenging operational environments, where the appearance of faces captured with video cameras varies significantly due to changes in pose, illumination, scale, blur, expression, occlusion, etc. In particular, with still-to-video FR, a limited number of high-quality facial images are typically captured for enrollment of an individual to the system, whereas an abundance facial trajectories can be captured using video cameras during operations, under different viewpoints and uncontrolled conditions. This paper presents a deep learning architecture that can learn a robust facial representation for each target individual during enrollment, and then accurately compare the facial regions of interest (ROIs) extracted from a still reference image (of the target individual) with ROIs extracted from live or archived videos. An ensemble of deep convolutional neural networks (DCNNs) named HaarNet is proposed, where a trunk network first extracts features from the global appearance of the facial ROIs (holistic representation). Then, three branch networks effectively embed asymmetrical and complex facial features (local representations) based on Haar-like features. In order to increase the discriminativness of face representations, a novel regularized triplet-loss function is proposed that reduces the intra-class variations, while increasing the inter-class variations. Given the single reference still per target individual, the robustness of the proposed DCNN is further improved by fine-tuning the HaarNet with synthetically-generated facial still ROIs that emulate capture conditions found in operational environments. The proposed system is evaluated on stills and videos from the challenging COX Face and Chokepoint datasets according to accuracy and complexity. Experimental results indicate that the proposed method can significantly improve performance with respect to state-of-the-art systems for video-based FR.","Face,
Feature extraction,
Computer architecture,
Cameras,
Robustness,
Training,
Face recognition"
Reinforcement Learning for Constrained Energy Trading Games With Incomplete Information,"This paper considers the problem of designing adaptive learning algorithms to seek the Nash equilibrium (NE) of the constrained energy trading game among individually strategic players with incomplete information. In this game, each player uses the learning automaton scheme to generate the action probability distribution based on his/her private information for maximizing his own averaged utility. It is shown that if one of admissible mixed-strategies converges to the NE with probability one, then the averaged utility and trading quantity almost surely converge to their expected ones, respectively. For the given discontinuous pricing function, the utility function has already been proved to be upper semicontinuous and payoff secure which guarantee the existence of the mixed-strategy NE. By the strict diagonal concavity of the regularized Lagrange function, the uniqueness of NE is also guaranteed. Finally, an adaptive learning algorithm is provided to generate the strategy probability distribution for seeking the mixed-strategy NE.","Games,
Smart grids,
Pricing,
Load modeling,
Cybernetics,
Learning (artificial intelligence),
Algorithm design and analysis"
Enhancing Heart-Beat-Based Security for mHealth Applications,"In heart-beat-based security, a security key is derived from the time difference between consecutive heart beats (the inter-pulse interval, IPI), which may, subsequently, be used to enable secure communication. While heart-beat-based security holds promise in mobile health (mHealth) applications, there currently exists no work that provides a detailed characterization of the delivered security in a real system. In this paper, we evaluate the strength of IPI-based security keys in the context of entity authentication. We investigate several aspects that should be considered in practice, including subjects with reduced heart-rate variability (HRV), different sensor-sampling frequencies, intersensor variability (i.e., how accurate each entity may measure heart beats) as well as average and worst-case-authentication time. Contrary to the current state of the art, our evaluation demonstrates that authentication using multiple, less-entropic keys may actually increase the key strength by reducing the effects of intersensor variability. Moreover, we find that the maximal key strength of a 60-bit key varies between 29.2 bits and only 5.7 bits, depending on the subject's HRV. To improve security, we introduce the inter-multi-pulse interval (ImPI), a novel method of extracting entropy from the heart by considering the time difference between nonconsecutive heart beats. Given the same authentication time, using the ImPI for key generation increases key strength by up to 3.4× (+19.2 bits) for subjects with limited HRV, at the cost of an extended key-generation time of 4.8× (+45 s).",
Authorship Attribution for Social Media Forensics,"The veil of anonymity provided by smartphones with pre-paid SIM cards, public Wi-Fi hotspots, and distributed networks like Tor has drastically complicated the task of identifying users of social media during forensic investigations. In some cases, the text of a single posted message will be the only clue to an author's identity. How can we accurately predict who that author might be when the message may never exceed 140 characters on a service like Twitter? For the past 50 years, linguists, computer scientists, and scholars of the humanities have been jointly developing automated methods to identify authors based on the style of their writing. All authors possess peculiarities of habit that influence the form and content of their written works. These characteristics can often be quantified and measured using machine learning algorithms. In this paper, we provide a comprehensive review of the methods of authorship attribution that can be applied to the problem of social media forensics. Furthermore, we examine emerging supervised learning-based methods that are effective for small sample sizes, and provide step-by-step explanations for several scalable approaches as instructional case studies for newcomers to the field. We argue that there is a significant need in forensics for new authorship attribution algorithms that can exploit context, can process multi-modal data, and are tolerant to incomplete knowledge of the space of all possible authors at training time.","Media,
Forensics,
Internet,
Writing,
Feature extraction,
Context,
Speech"
TTSA: An Effective Scheduling Approach for Delay Bounded Tasks in Hybrid Clouds,"The economy of scale provided by cloud attracts a growing number of organizations and industrial companies to deploy their applications in cloud data centers (CDCs) and to provide services to users around the world. The uncertainty of arriving tasks makes it a big challenge for private CDC to cost-effectively schedule delay bounded tasks without exceeding their delay bounds. Unlike previous studies, this paper takes into account the cost minimization problem for private CDC in hybrid clouds, where the energy price of private CDC and execution price of public clouds both show the temporal diversity. Then, this paper proposes a temporal task scheduling algorithm (TTSA) to effectively dispatch all arriving tasks to private CDC and public clouds. In each iteration of TTSA, the cost minimization problem is modeled as a mixed integer linear program and solved by a hybrid simulated-annealing particle-swarm-optimization. The experimental results demonstrate that compared with the existing methods, the optimal or suboptimal scheduling strategy produced by TTSA can efficiently increase the throughput and reduce the cost of private CDC while meeting the delay bounds of all the tasks.","Cloud computing,
Delays,
Minimization,
Time factors,
Job shop scheduling,
Scheduling algorithms"
Linear Precoding for Fading Cognitive Multiple-Access Wiretap Channel With Finite-Alphabet Inputs,"We investigate the fading cognitive multiple-access wiretap channel (CMAC-WT), in which two secondary-user transmitters (STs) send secure messages to a secondary-user receiver (SR) in the presence of an eavesdropper and subject to interference threshold constraints at multiple primary-user receivers (PRs). We design linear precoders to maximize the average secrecy sum rate for a multiple-input-multiple-output (MIMO) fading CMAC-WT under finite-alphabet inputs and statistical channel state information at STs. For this nondeterministic polynomial-time NP-hard problem, we utilize an accurate approximation of the average secrecy sum rate to reduce the computational complexity and then present a two-layer algorithm by embedding the convex-concave procedure into an outer-approximation framework. The idea behind this algorithm is to reformulate the approximated average secrecy sum rate as a difference of convex functions and then generate a sequence of simpler relaxed sets to approach the nonconvex feasible set. Subsequently, we maximize the approximated average secrecy sum rate over the sequence of relaxed sets by using the convex-concave procedure. Numerical results indicate that our proposed precoding algorithm is superior to the conventional Gaussian precoding method in the medium and high signal-to-noise ratio (SNR) regimes.","Precoding,
Receivers,
Fading channels,
Approximation algorithms,
Security,
Optimization,
Interference"
Attention-Weighted Texture and Depth Bit-Allocation in General-Geometry Free-Viewpoint Television,"In a free-viewpoint television network, each viewer chooses its point of view from which to watch a scene. We use the concept of total observed distortion, wherein we aim to minimize the distortion of the view observed by the viewers as opposed to the distortion of each camera, to develop an optimized bit-rate allocation for each camera. Our attention-weighted approach effectively gives more bits to the cameras that are more watched. The more concentrated the viewer distribution, the larger the bit-rate savings, for a given total observed distortion, compared with the uniform rate allocation. We analyze and model the distortion of a synthesized view as a function of the distortions (both in texture and/or depth) of the nearby cameras. Based on such models, we develop optimal rate-allocation methods for texture images, considering a uniform bit allocation for depth, and for both texture and depth simultaneously. Simulation results are shown, demonstrating not only the correctness of the optimized solution, but also measuring its improvement against uniform rate allocation for a few viewer distributions.","Cameras,
Distortion,
Resource management,
Bit rate,
TV,
Encoding,
Context"
Accurate Real-time Map Matching for Challenging Environments,"We present the SnapNet system, which provides accurate real-time map matching for cellular-based trajectory traces. Such traces are characterized by input locations that are far from the actual road segment, errors on the order of kilometers, back-and-forth transitions, and highly sparse input data. SnapNet applies a series of filters to handle the noisy locations and an interpolation stage to address the data sparseness. At the core of SnapNet is a novel incremental HMM algorithm that combines digital map hints in the estimation process and a number of heuristics to reduce the noise and provide real-time estimations. Evaluation of SnapNet using actual traces from different cities covering more than 400 km shows that it can achieve a precision and recall of more than 90% under noisy coarse-grained input location estimates. This maps to over 97% and 34% enhancement in precision and recall, respectively, when compared to the traditional HMM map-matching algorithms. Moreover, SnapNet has a latency of 0.58 ms per location estimate.",
Secure Multiantenna Cognitive Wiretap Networks,"In this paper, we investigate the secrecy performance of a multiantenna cognitive wiretap network, where the secondary transmitter (Alice) communicates with the secondary receiver (Bob) in the presence of an eavesdropper (Eve). Specifically, we consider both half-duplex (HD) and full-duplex (FD) operations. For the HD, maximal-ratio combining (MRC) is adopted at Bob, while for the FD, we propose two jamming schemes to deteriorate the quality of the eavesdropper's channel, i.e., selection combining/selection jammer (SC/SJ) and SC/zero forcing beamforming (SC/ZFB). Assuming Rayleigh fading, exact closed-form expressions for the secrecy outage probability of the cognitive wiretap network are derived. In addition, we also provide simple asymptotic approximations for the secrecy outage probability under two distinct scenarios, depending on the quality of the main and wiretap channels. From the analytical results and numerical simulations, it is concluded that all the proposed schemes outperform the SC scheme; all the proposed schemes achieve full diversity when the main channel is much better than the eavesdropper's channel; MRC outperforms SC/SJ and SC/ZBF in the low interference threshold regime, while the opposite holds in the high interference one; and SC/ZFB always achieves better performance than SC/SJ, albeit with higher complexity.","Antennas,
Interference,
Receivers,
Jamming,
Cognitive radio,
High definition video,
Niobium"
Weighted Low-Rank Decomposition for Robust Grayscale-Thermal Foreground Detection,"This paper investigates how to fuse grayscale and thermal video data for detecting foreground objects in challenging scenarios. To this end, we propose an intuitive yet effective method called weighted low-rank decomposition (WELD), which adaptively pursues the cross-modality low-rank representation. Specifically, we form two data matrices by accumulating sequential frames from the grayscale and the thermal videos, respectively. Within these two observing matrices, WELD detects moving foreground pixels as sparse outliers against the low-rank structure background and incorporates the weight variables to make the models of two modalities complementary to each other. The smoothness constraints of object motion are also introduced in WELD to further improve the robustness to noises. For optimization, we propose an iterative algorithm to efficiently solve the low-rank models with three subproblems. Moreover, we utilize an edge-preserving filtering-based method to substantially speed up WELD while preserving its accuracy. To provide a comprehensive evaluation benchmark of grayscale-thermal foreground detection, we create a new data set including 25 aligned grayscale-thermal video pairs with high diversity. Our extensive experiments on both the newly created data set and the public data set OSU3 suggest that WELD achieves superior performance and comparable efficiency against other state-of-the-art approaches.",
DTD: A Novel Double-Track Approach to Clone Detection for RFID-Enabled Supply Chains,"Toward improving the traditional clone detection technique whose performance may be affected by dynamic changes of supply chains and misread, we present a novel and effective clone detection approach, termed double-track detection, for radio frequency identification-enabled supply chains. As part of a tag's attributes, verification information is written into tags so that the set of all verification information in the collected tag events forms a time series sequence. Genuine tags can be differentiated from clone tags due to the discrepancy in their verification sequences which are constructed as products flow along the supply chain. The verification sequence together with the sequence formed by business actions performed during the supply chains yield two tracks which can be assessed to detect the presence of clone tags. Theoretical analysis and experimental results show that our proposed mechanism is effective, reasonable, and has a relatively high clone detection rate when compared with a leading method in this area.","Cloning,
Supply chains,
Radiofrequency identification,
Distributed databases,
Educational institutions,
Electronic mail"
Secure and Efficient Cloud Data Deduplication With Randomized Tag,"Cross-client data deduplication has been widely used to eliminate redundant storage overhead in cloud storage system. Recently, Abadi et al. introduced the primitive of MLE2 with nice security properties for secure and efficient data deduplication. However, besides the computationally expensive noninteractive zero-knowledge proofs, their fully randomized scheme (R-MLE2) requires the inefficient equality-testing algorithm to identify all duplicate ciphertexts. Thus, an interesting challenging problem is how to reduce the overhead of R-MLE2 and propose an efficient construction for R-MLE2. In this paper, we introduce a new primitive called μR-MLE2, which gives a partial positive answer for this challenging problem. We propose two schemes: static scheme and dynamic scheme, where the latter one allows tree adjustment by increasing some computation cost. Our main trick is to use the interactive protocol based on static or dynamic decision trees. The advantage gained from it is, by interacting with clients, the server will reduce the time complexity of deduplication equality test from linear time to efficient logarithmic time over the whole data items in the database. The security analysis and the performance evaluation show that our schemes are Path-PRV-CDA2 secure and achieve several orders of magnitude higher performance for data equality test than R-MLE2 scheme when the number of data items is relatively large.","Cloud computing,
Encryption,
Decision trees,
Servers,
Maximum likelihood estimation"
1/f-Noise in AlGaN/GaN Nanowire Omega-FinFETs,"The low-frequency noise (LFN) characteristics of AlGaN/GaN FinFETs with omega-gate and combined two-dimensional electron gas (2DEG) and MOS conduction are investigated. It is found that LFN is dominated by carrier number fluctuations whatever the width of the fin. Charge trapping in narrow devices is one order of magnitude lower than in wide fin device. In narrow devices, the sidewall conduction prevails and the noise mainly stems from the carrier trapping in the sidewall Al2O3 gate dielectric. Instead, in wide fin devices, the top gate AlGaN/GaN HEMT structure dominates and the LFN is mostly governed by the carrier trapping in the GaN layer close to 2DEG channel.","Aluminum gallium nitride,
Wide band gap semiconductors,
HEMTs,
Logic gates,
MODFETs,
Gallium nitride,
Fluctuations"
Entropy of Primitive: From Sparse Representation to Visual Information Evaluation,"In this paper, we propose a novel concept in evaluating the visual information when perceiving natural images-the entropy of primitive (EoP). Sparse representation has been successfully applied in a wide variety of signal processing and analysis applications due to its high efficiency in dealing with rich varied and directional information contained in natural scenes. Inspired by this observation, in this paper, the visual signal can be decomposed into structural and nonstructural layers according to the visual importance of sparse primitives. Accordingly, the EoP is developed in measuring the visual information. It has been found that the EoP changing tendency in image sparse representation is highly relevant with the hierarchical perceptual cognitive process of human eyes. Extensive mathematical explanations as well as experimental verifications have been presented in order to support the hypothesis. The robustness of the EoP is evaluated in terms of varied block sizes. The dictionary universality is also studied by employing both universal and adaptive dictionaries. With the convergence characteristics of the EoP, a novel top-down just-noticeable difference (JND) profile is proposed. The simulation results have shown that the EoP-based JND outperforms the state-of-the-art JND models according to the subjective evaluation.","Visualization,
Dictionaries,
Feature extraction,
Matching pursuit algorithms,
Entropy,
Discrete cosine transforms,
Visual perception"
Power System Reliability Evaluation Considering Load Redistribution Attacks,"The increased complexity of power system makes the power dispatch heavily rely on the condition monitoring and state estimation functions. However, with the massive deployment of cyber technologies, the power grid is becoming more vulnerable to malicious cyber attacks, including various kinds of false data injection attacks. This paper quantifies the influence of load redistribution (LR) attack on the long-term power supply reliability. The intrusion process for manipulating the measurements is modeled by the semi-Markov models. Considering the practical cross-check for suspicious measurements, the regional LR attack model is proposed. A holistic framework incorporating the physical failures and the LR attack is proposed for cyber-physical power system reliability evaluation. The simulation is carried out on the IEEE RTS79 system. The influences of critical factors and strategies are analyzed. It is concluded that the LR attacks have a non-negligible impact on the power system reliability.","Power system reliability,
State estimation,
Substations,
Power measurement,
Power grids,
Gain measurement,
Transmission line measurements"
Energy Harvesting-Based D2D-Assisted Machine-Type Communications,"Supporting massive numbers of machine-type communication (MTC) devices poses several challenges for future 5G networks, including network control, scheduling, and powering these devices. A potential solution is to offload MTC traffic onto device-to-device (D2D) communication links to better manage radio resources and reduce MTC devices' energy consumption. However, this approach requires D2D users to use their own limited energy to relay MTC traffic, which may be undesirable. This motivates us to exploit recent advancements in RF energy harvesting for powering D2D relay transmissions. In this paper, we consider a D2D communication as an underlay to the cellular network, where D2D users access a fraction of the spectrum occupied by cellular users. This underlay model presents a fundamental trade-off: to protect cellular users, the spectrum available to D2D users needs to be reduced, which limits the number of D2D transmissions, but increases the amount of time that D2D users can spend harvesting energy to support MTC traffic. We study this trade-off by characterizing the spectral efficiency of MTC, D2D, and cellular users using stochastic geometry. The optimal spectrum partition factor is characterized to achieve fairness and balance in the network, while increasing the average MTC spectral efficiency.","Device-to-device communication,
Radio frequency,
Energy harvesting,
Relays,
Cellular networks,
Interference,
Stochastic processes"
Artificial Neural Network model design and topology analysis for FPGA implementation of Lorenz chaotic generator,"This paper presents an Artificial Neural Network (ANN) design for a chaotic generator, and the training performances for a three layer ANN architecture with different number of hidden neurons. Chaotic systems can be synchronized and used for secure communication. Chaotic systems such as Lorenz attractor, Rossler attractor and Chen's system are generally implemented directly based on their definitions represented by a unique group of ordinary differential equations (ODEs). An feed forward ANN can be trained using the output values of a chaotic system. The training process is carried out on a computer and the weights are generated for all neurons in an ANN architecture. These weights are then used for a trained ANN architecture model to generate the expected output for the target chaotic system. The complexity of the ANN architecture defines the implementation cost and speed. Therefore it is beneficial to use less number of hidden neurons to achieve the target training performance. Lorenz attractor has its significance in studying chaotic systems and is used as the design subject in this paper. The 3-layer ANN has one input, one hidden and one output layer. The ANN architecture with 1 to 16 hidden neurons is designed and trained respectively using MATLAB Neural Network Toolbox with three training algorithms: Levenberg-Marquardt, Scaled Conjugate Gradient algorithm and Bayesian Regulation. The optimized ANN architecture can be used to improve the efficiency of the fixed-point implementation on an Field Programmable Gates Array (FPGA) device.","Training,
Neurons,
Field programmable gate arrays,
Chaotic communication,
Nonlinear dynamical systems,
Generators,
Mathematical model"
Differentially Private Location Protection for Worker Datasets in Spatial Crowdsourcing,"Spatial Crowdsourcing (SC) is a transformative platform that engages individuals in collecting and analyzing environmental, social, and other spatio-temporal information. SC outsources spatio-temporal tasks to a set of workers, i.e., individuals with mobile devices that perform the tasks by physically traveling to specified locations. However, current solutions require the workers to disclose their locations to untrusted parties. In this paper, we introduce a framework for protecting location privacy of workers participating in SC tasks. We propose a mechanism based on differential privacy and geocasting that achieves effective SC services while offering privacy guarantees to workers. We address scenarios with both static and dynamic (i.e., moving) datasets of workers. Experimental results on real-world data show that the proposed technique protects location privacy without incurring significant performance overhead.","Privacy,
Data privacy,
Crowdsourcing,
Noise measurement,
Mobile computing,
Indexes"
Two-Pass Rate Control for Improved Quality of Experience in UHDTV Delivery,"Rate control plays an important role in any video coding application and it was extensively studied in the context of previous video coding standards. However, the current state-of the-art high efficiency video coding (HEVC) standard introduces many flexible tools making previous rate-distortion models used in rate control insufficiently accurate. Recently, a few rate control methods have been developed for HEVC that introduce many useful features, such as a robust correspondence between the rate and Lagrange multiplier λ. Nonetheless, previous rate control algorithms for HEVC do not address typical content in television applications that consists of frequent scene changes. Furthermore, the new ultra high definition television (UHDTV) format, which is expected to become widespread in the future, demands for even higher compression efficiency. To overcome these issues, a two-pass rate control method is proposed in this paper, targeting the encoding of UHDTV content. In the first pass, a fast encoder with limited set of coding tools is used during pre-encoding step to obtain the data used for rate allocation and model parameter initialization, which will then be used during the second pass. To avoid multiple encoding steps when deriving this information, a variable quantization parameter framework is proposed. Experimental results show that the proposed rate control method outperforms the well-known HEVC rate control method. When compared with variable bit-rate encoding mode, the proposed two-pass rate control method achieves on average 2.9% BD-rate losses. That is significantly better than the state-of-the-art HEVC rate control method, which achieves an average 8.8% BD-rate loss. The proposed method also provides a more consistent quality fluctuation with time, measured with standard deviation of frame PSNR values, required for high Quality of Experience.","Encoding,
Standards,
Quantization (signal),
Adaptation models,
HDTV"
Area-Time Efficient Architecture of FFT-Based Montgomery Multiplication,"The modular multiplication operation is the most time-consuming operation for number-theoretic cryptographic algorithms involving large integers, such as RSA and Diffie-Hellman. Implementations reveal that more than 75 percent of the time is spent in the modular multiplication function within the RSA for more than 1,024-bit moduli. There are fast multiplier architectures to minimize the delay and increase the throughput using parallelism and pipelining. However such designs are large in terms of area and low in efficiency. In this paper, we integrate the fast Fourier transform (FFT) method into the McLaughlin's framework, and present an improved FFT-based Montgomery modular multiplication (MMM) algorithm achieving high area-time efficiency. Compared to the previous FFT-based designs, we inhibit the zero-padding operation by computing the modular multiplication steps directly using cyclic and nega-cyclic convolutions. Thus, we reduce the convolution length by half. Furthermore, supported by the number-theoretic weighted transform, the FFT algorithm is used to provide fast convolution computation. We also introduce a general method for efficient parameter selection for the proposed algorithm. Architectures with single and double butterfly structures are designed obtaining low area-latency solutions, which we implemented on Xilinx Virtex-6 FPGAs. The results show that our work offers a better area-latency efficiency compared to the state-of-the-art FFT-based MMM architectures from and above 1,024-bit operand sizes. We have obtained area-latency efficiency improvements up to 50.9 percent for 1,024-bit, 41.9 percent for 2,048-bit, 37.8 percent for 4,096-bit and 103.2 percent for 7,680-bit operands. Furthermore, the operating latency is also outperformed with high clock frequency for length-64 transform and above.",
VisAdapt: A Visualization Tool to Support Climate Change Adaptation,"The Web-based visualization VisAdapt tool was developed to help laypeople in the Nordic countries assess how anticipated climate change will impact their homes. The tool guides users through a three-step visual process that helps them explore risks and identify adaptive actions specifically modified to their location and house type. This article walks through the tool's multistep, user-centered design process. Although VisAdapt's target end users are Nordic homeowners, the insights gained from the development process and the lessons learned from the project are applicable to a wide range of domains.",
An Android-Based Mechanism for Energy Efficient Localization Depending on Indoor/Outdoor Context,"Today, there is widespread use of mobile applications that take advantage of a user's location. Popular usages of location information include geotagging on social media websites, driver assistance and navigation, and querying nearby locations of interest. However, the average user may not realize the high energy costs of using location services (namely the GPS) or may not make smart decisions regarding when to enable or disable location services-for example, when indoors. As a result, a mechanism that can make these decisions on the user's behalf can significantly improve a smartphone's battery life. In this paper, we present an energy consumption analysis of the localization methods available on modern Android smartphones and propose the addition of an indoor localization mechanism that can be triggered depending on whether a user is detected to be indoors or outdoors. Based on our energy analysis and implementation of our proposed system, we provide experimental results-monitoring battery life over time-and show that an indoor localization method triggered by indoor or outdoor context can improve smartphone battery life and, potentially, location accuracy.","Global Positioning System,
Androids,
Humanoid robots,
Smart phones,
Operating systems,
Context,
Sensors"
KSF-OABE: Outsourced Attribute-Based Encryption with Keyword Search Function for Cloud Storage,"Cloud computing becomes increasingly popular for data owners to outsource their data to public cloud servers while allowing intended data users to retrieve these data stored in cloud. This kind of computing model brings challenges to the security and privacy of data stored in cloud. Attribute-based encryption (ABE) technology has been used to design fine-grained access control system, which provides one good method to solve the security issues in cloud setting. However, the computation cost and ciphertext size in most ABE schemes grow with the complexity of the access policy. Outsourced ABE (OABE) with fine-grained access control system can largely reduce the computation cost for users who want to access encrypted data stored in cloud by outsourcing the heavy computation to cloud service provider (CSP). However, as the amount of encrypted files stored in cloud is becoming very huge, which will hinder efficient query processing. To deal with above problem, we present a new cryptographic primitive called attribute-based encryption scheme with outsourcing key-issuing and outsourcing decryption, which can implement keyword search function (KSF-OABE). The proposed KSF-OABE scheme is proved secure against chosen-plaintext attack (CPA). CSP performs partial decryption task delegated by data user without knowing anything about the plaintext. Moreover, the CSP can perform encrypted keyword search without knowing anything about the keywords embedded in trapdoor.","Cloud computing,
Outsourcing,
Encryption,
Keyword search,
Servers"
Thrust Control for Multirotor Aerial Vehicles,"This paper presents a novel control algorithm to regulate the aerodynamic thrust produced by fixed-pitch rotors commonly used on small-scale electrically powered multirotor aerial vehicles. The proposed controller significantly improves the disturbance rejection and gust tolerance of rotor thrust control compared to state-of-the-art RPM (revolutions per minute) rotor control schemes. The thrust modeling approach taken is based on a model of aerodynamic power generated by a fixed-pitch rotor and computed in real time on the embedded electronic speed controllers using measurements of electrical power and rotor angular velocity. Static and dynamic flight tests were carried out in downdrafts and updrafts of varying strengths to quantify the resulting improvement in maintaining a desired thrust setpoint. The performance of the proposed approach in flight conditions is demonstrated by a path tracking experiment, where a quadrotor was flown through an artificial wind gust and the trajectory tracking error was measured. The proposed approach for thrust control demonstrably reduced the tracking error compared to classical RPM rotor control.",
Accurate Angular Velocity Estimation With an Event Camera,"We present an algorithm to estimate the rotational motion of an event camera. In contrast to traditional cameras, which produce images at a fixed rate, event cameras have independent pixels that respond asynchronously to brightness changes, with microsecond resolution. Our method leverages the type of information conveyed by these novel sensors (i.e., edges) to directly estimate the angular velocity of the camera, without requiring optical flow or image intensity estimation. The core of the method is a contrast maximization design. The method performs favorably against ground truth data and gyroscopic measurements from an Inertial Measurement Unit, even in the presence of very high-speed motions (close to 1000 deg/s).","Cameras,
Trajectory,
Image edge detection,
Angular velocity,
Optical imaging,
Estimation,
Robot vision systems"
"L
0
Regularized Stationary-Time Estimation for Crowd Analysis","In this paper, we tackle the problem of stationary crowd analysis which is as important as modeling mobile groups in crowd scenes and finds many important applications in crowd surveillance. Our key contribution is to propose a robust algorithm for estimating how long a foreground pixel becomes stationary. It is much more challenging than only subtracting background because failure at a single frame due to local movement of objects, lighting variation, and occlusion could lead to large errors on stationary-time estimation. To achieve robust and accurate estimation, sparse constraints along spatial and temporal dimensions are jointly added by mixed partials (which are second-order gradients) to shape a 3D stationary-time map. It is formulated as an L0 optimization problem. Besides background subtraction, it distinguishes among different foreground objects, which are close or overlapped in the spatio-temporal space by using a locally shared foreground codebook. The proposed technologies are further demonstrated through three applications. 1) Based on the results of stationary-time estimation, 12 descriptors are proposed to detect four types of stationary crowd activities. 2) The averaged stationary-time map is estimated to analyze crowd scene structures. 3) The result of stationary-time estimation is also used to study the influence of stationary crowd groups to traffic patterns.",
Reverse Query-Aware Locality-Sensitive Hashing for High-Dimensional Furthest Neighbor Search,"The c-Approximate Furthest Neighbor (c-AFN) search is a fundamental problem in many applications. However, existing hashing schemes are designed for internal memory. The old techniques for external memory, such as furthest point Voronoi diagram and the tree-based methods, are only suitable for the low-dimensional case. In this paper, we introduce a novel concept of Reverse Locality-Sensitive Hashing (RLSH) family which is directly designed for c-AFN search. Accordingly, we propose two novel hashing schemes RQALSH and RQALSH for highdimensional c-AFN search over external memory. Experimental results validate the efficiency and effectiveness of RQALSH and RQALSH.","Search problems,
Euclidean distance,
Computer science,
Sun,
Probability density function,
Buildings,
Distortion"
Studies on Robust Social Influence Mechanisms: Incentives for Efficient Network Routing in Uncertain Settings,"Many of today's engineered systems are tightly interconnected with their users, and in many cases, system performance depends greatly on user behavior [1]. As a result, the traditional lines between engineering and the social sciences are becoming increasingly blurred, and analytical tools such as game theory are finding new applications in engineering [2], [3]. It is often insufficient to judge an engineered system on its technical merits alone since strategic user behavior can lead to unpredictable and/or undesirable results [4]. Of particular importance to this article are socially integrated engineering problems in which users' strategic behavior has a significant impact on overall system performance. These types of systems appear in a variety of contexts in theory and practice; transportation networks [5], ride-sharing applications [6], [7], supply-chain management [8], cloud computing [9], and electric power grids [10] are immediate examples. A common problem in these settings is that individual user incentives may not be aligned with the objectives of the central planner. Thus, in addition to the technical challenges of a socially integrated engineering problem, an engineer may need to consider methods of influencing individual user behavior to effect positive change on aggregate system performance [11]. These behavior-influencing mechanisms often take the form of offering users a tradeoff between quality of service and monetary incentive.",
AT-MAC: Adaptive MAC-Frame Payload Tuning for Reliable Communication in Wireless Body Area Networks,"In wireless sensor networks, adaptive tuning of Medium Access Control (MAC) parameters is necessary in order to assure the QoS requirements. In this paper, we propose an adaptive MAC-frame payload tuning mechanism for wireless body area networks (WBANs) to maximize the probability of successful packet delivery or reliability of the associated sensor nodes based on real-time situation. The enabling algorithm, Adaptively Tuned MAC (AT-MAC), has been proposed to tune the MAC-frame payload of a WBAN sensor node, which is compliant with the IEEE 802.15.4 protocol. AT-MAC prioritizes sensor nodes based on the seriousness of the health parameters that are being measured by the respective sensor nodes. Further, we consider a Markov chain-based analytical approach that acknowledges the slotted CSMA/CA backoff mechanism with retry limits, as described in the IEEE 802.15.4 protocol. We derive expressions for reliability, power consumption, and throughput, which are the key metrics to evaluate the network performance of the proposed protocol, and analyze the impact of MAC parameters on them. Finally, results indicate that the low rate and low power IEEE 802.15.4 can be used effectively in case of WBANs if the payload is tuned properly through the proposed algorithm. The proposed AT-MAC algorithm yields around 70 percent increase in reliability of a critical node in a WBAN.","Reliability,
Payloads,
Biomedical monitoring,
IEEE 802.15 Standard,
Tuning,
Wireless communication,
Body area networks"
Improving Convergence and Simulation Time of Quantum Hydrodynamic Simulation: Application to Extraction of Best 10-nm FinFET Parameter Values,"As electronic devices enter the deep nanometer regime, accurate and efficient device simulations become necessary to account for the emerging quantum effects. The traditional drift-diffusion and hydrodynamic (HD) device simulation models are not accurate in this regime. It is important to use the quantum HD (QHD) simulation model. However, this model suffers from poor convergence and high CPU times. To overcome these obstacles, in this paper, we propose a novel method to replace part of the QHD simulation that exhibits poor convergence behavior and high CPU time with HD simulation. In order to implement this, we capture the device states from the classical HD model and then apply the results as the initial guess to the QHD simulation, which is then solved by the Newton-Raphson method. This leads to significant improvements. The nonconvergence rate and the simulation time are reduced by 86.0% and 30.2%, respectively. As an application of the proposed methodology, we extract the best parameter values of both bulk and silicon-on-insulator FinFETs at the 10-nm technology node from their vast device design space.",
Just-Noticeable Difference-Based Perceptual Optimization for JPEG Compression,"The Quantization table in JPEG, which specifies the quantization scale for each discrete cosine transform (DCT) coefficient, plays an important role in image codec optimization. However, the generic quantization table design that is based on the characteristics of human visual system (HVS) cannot adapt to the variations of image content. In this letter, we propose a just-noticeable difference (JND) based quantization table derivation method for JPEG by optimizing the rate-distortion costs for all the frequency bands. To achieve better perceptual quality, the DCT domain JND-based distortion metric is utilized to model the stair distortion perceived by HVS. The rate-distortion cost for each band is derived by estimating the rate with the first-order entropy of quantized coefficients. Subsequently, the optimal quantization table is obtained by minimizing the total rate-distortion costs of all the bands. Extensive experimental results show that the quantization table generated by the proposed method achieves significant bit-rate savings compared with JPEG recommended quantization table and specifically developed quantization tables in terms of both objective and subjective evaluations.","Quantization (signal),
Distortion,
Discrete cosine transforms,
Transform coding,
Rate-distortion,
Image coding,
Optimization"
Power Quality Enhancement for a Grid Connected Wind Turbine Energy System,"A comprehensive control of a wind turbine system connected to an industrial plant is discussed in this paper, where an algorithm has been developed allowing a control structure that utilizes a four-leg inverter connected to the grid side to inject the available energy, as well as to work as an active power filter mitigating load current disturbances and enhancing power quality. A four-wire system is considered with three-phase and single-phase linear and nonlinear loads. During the connection of the wind turbine, the utility-side controller is designed to compensate the disturbances caused in presence of reactive, nonlinear, and/or unbalanced single- and intra-phase loads, in addition to providing active and reactive power as required. When there is no wind power available, the controller is intended to improve the power quality using the dc-link capacitor with the power converter attached to the grid. The main difference of the proposed methodology with respect to others in the literature is that the proposed control structure is based on the conservative power theory decompositions. This choice provides decoupled power and current references for the inverter control, offering very flexible, selective, and powerful functionalities. Real-time software benchmarking has been conducted in order to evaluate the performance of the proposed control algorithm for full real-time implementation. The control methodology is implemented and validated in hardware-in-the-loop based on the real time simulator “Opal-RT” and a TMSF28335 DSP microcontroller. The results corroborated our power quality enhancement control and allowed to exclude passive filters, contributing to a more compact, flexible, and reliable electronic implementation of a smart-grid based control.",
Truncated Predictor Control of Lipschitz Nonlinear Systems With Time-Varying Input Delay,"This note deals with control design for Lipschitz nonlinear systems with time-varying input delay. Based on a truncated prediction of the system state over the delay period, both a state and an output feedback control law are constructed. Within the framework of Lyapunov-Krasovskii functionals, a set of conditions are identified under which the closed-loop system under either the state feedback or the output feedback law is globally asymptotically stable at the origin. A numerical example is included to demonstrate the effectiveness of the proposed designs.",
Turning Diffusion-Based Image Colorization Into Efficient Color Compression,"The work of Levin et al. (2004) popularized stroke-based methods that add color to gray value images according to a small amount of user-specified color samples. Even though such reconstructions from sparse data suggest a possible use in compression, only few attempts were made so far in this direction. Diffusion-based compression methods pursue a similar idea: they store only few image pixels and inpaint the missing regions. Despite this close relation and a lack of diffusion-based color codecs, colorization ideas were so far only integrated into transform-based approaches such as JPEG. We address this missing link with two contributions. First, we show the relation between the discrete colorization of Levin et al. and continuous diffusion-based inpainting in the YCbCr color space. It decomposes the image into a luma (brightness) channel and two chroma (color) channels. Our luma-guided diffusion framework steers the diffusion inpainting in the chroma channels according to the structure in the luma channel. We show that making the luma-guided colorization anisotropic outperforms the method of Levin et al. significantly. Second, we propose a new luma preference codec that invests a large fraction of the bit budget into an accurate representation of the luma channel. This allows a high-quality reconstruction of color data with our colorization technique. Simultaneously, we exploit the fact that the human visual system is more sensitive to structural than to color information. Our experiments demonstrate that our new codec outperforms the state of the art in diffusion-based image compression and is competitive to transform-based codecs.",
A Differential-Fed Microstrip Patch Antenna With Bandwidth Enhancement Under Operation of TM10 and TM30 Modes,"A differential-fed microstrip patch antenna (MPA) with bandwidth enhancement is proposed under the operation of TM10 and TM30 resonant modes in a single patch resonator. Initially, a rectangular differential-fed MPA is theoretically investigated so as to demonstrate that all of the undesired modes between the TM10 and TM30 modes are suppressed or removed out effectively. Then, by symmetrically introducing two pairs of shorting pins, the resonant frequency of TM10 mode is progressively turned up. After that, with the help of two long slots, the resonant frequency of TM30 mode is decreased with slight effect on that of TM10 mode. Furthermore, a short slot is inserted at the center of the patch to cancel the parasitic inductances of the shorting pins and probe feeds. With this arrangement, these two radiative resonant modes are moved in proximity to each other for wideband antenna. Finally, the proposed differential-fed MPA is fabricated and measured. Experimental results illustrate that the impedance bandwidth (|Sdd11| <; -10 dB) of the antenna has gained a tremendous increment up to about 13% (1.88-2.14 GHz), while keeping a low profile property with the height of 0.029 free-space wavelength. Additionally, the antenna has achieved a stable gain varied from 5.8 to 7 dBi over the operating band.",
Multi-Set Space-Time Shift Keying and Space- Frequency Space-Time Shift Keying for Millimeter-Wave Communications,"In this paper, we introduce a novel OFDM-aided multifunctional multiple-input multiple-output scheme based on multi-set space-time shift keying (MS-STSK), where the information transmitted over each subcarrier is divided into two parts: STSK codeword and the implicit antenna combination (AC) index. In MS-STSK, a unique combination of antennas can be activated at each subcarrier to convey extra information over the AC index while additionally transmitting the STSK codeword. Furthermore, inspired by the MS-STSK concept, this scheme is extended also to the frequency domain in the novel context of our multi-space-frequency STSK (MSF-STSK), where the total number of subcarriers is partitioned into blocks to implicitly carry the block's frequency index. The proposed MSF-STSK scheme benefits from the huge bandwidths available at mmWaves for partitioning the total number of OFDM subcarriers into blocks to convey more information over the frequency domain. Both proposed systems use STSK codewords as the basic transmission block, and they can achieve higher data throughput and better BER performance than STSK. Moreover, given that the system is meant to operate at mmWaves, antenna arrays relying on several antenna elements are employed at both the transmitter and receiver for analogue beamforming with the aid of phase shifters and power amplifiers to overcome the effect of high path loss.","OFDM,
MIMO,
Indexes,
Transmitting antennas,
Receiving antennas,
Array signal processing,
Antenna arrays"
Optimal Power Control in Ultra-Dense Small Cell Networks: A Game-Theoretic Approach,"In this paper, we study the power control problem for interference management in the ultra-dense small cell networks, which is formulated to maximize the sum-rate of all the small cells while keeping tolerable interference to the macrocell users. We investigate the problem by proposing a novel game with dynamic pricing. Theoretically, we prove that the Nash equilibrium (NE) of the formulated game coincides with the stationary point of the original sum-rate maximization problem, which could be locally or globally optimal. Furthermore, we propose a distributed iterative power control algorithm to converge to the NE of the game with guaranteed convergence. To reduce the information exchange and computational complexity, we propose an approximation model for the original optimization problem by constructing the interfering domains, and accordingly design a local information-based iterative algorithm for updating each small cell's power strategy. Theoretic analysis shows that the local information-based power control algorithm can converge to the NE of the game, which corresponds to the stationary point of the original sum-rate maximization problem. Finally, simulation results demonstrate that the proposed approach yields a significant transmission rate gain, compared with the existing benchmark algorithms.",
The hint protocol: Using a broadcast method to enable ID-free data transmission for dense IoT devices,"IoT (Internet of Things) has attracted a lot of attention recently. IoT devices need to report their data or status to base stations at various frequencies. The IoT communications observed by a base station normally exhibit the following characteristics: (1) massively connected, (2) lightly loaded per packet, and (3) periodical or at least mostly predictable. The current design principals of communication networks, when applied to IoT scenarios, however, do not fit well to these requirements. For example, an IPv6 address is 128 bits, which is much longer than a 16-bit temperature report. Also, contending to send a small packet is not cost-effective. In this work, we propose a novel framework, which is slot-based, schedule-oriented, and identity-free for uploading IoT devices' data. We show that it fits very well for IoT applications. We propose two schemes, from an ideal one to a more practical one. The main idea is to bundle time slots with certain hashing functions of device IDs, thus significantly reducing transmission overheads, including device IDs and contention overheads.",
An Analysis of Wind Curtailment and Constraint at a Nodal Level,"Many countries have set challenging wind power targets to achieve by 2020. This paper implements a realistic analysis of curtailment and constraint of wind energy at a nodal level using a unit commitment and economic dispatch model of the Irish Single Electricity Market in 2020. The key findings show that significant reduction in curtailment can be achieved when the system nonsynchronous penetration limit increases from 65% to 75%. For the period analyzed, this results in a decreased total generation cost and a reduction in the dispatch-down of wind. However, some nodes experience significant dispatch-down of wind, which can be in the order of 40%. This work illustrates the importance of implementing analysis at the nodal level for the purpose of power system planning.","Nickel,
Generators,
Integrated circuit interconnections,
Economics,
Wind forecasting,
Wind power generation,
Power systems"
An Optimal Fuzzy System for Edge Detection in Color Images Using Bacterial Foraging Algorithm,"This paper presents a fuzzy system for edge detection, using smallest univalue segment assimilating nucleus (USAN) principle and bacterial foraging algorithm (BFA). The proposed algorithm fuzzifies the USAN area obtained from the original image, using a USAN area histogram-based Gaussian membership function. A parametric fuzzy intensification operator (FINT) is proposed to enhance the weak edge information, which results in another fuzzy set. The fuzzy measures, i.e., fuzzy edge quality factor and sharpness factor, are defined on fuzzy sets. The BFA is used to optimize the parameters involved in the fuzzy membership function and the FINT. The fuzzy edge map is obtained using optimized parameters. The adaptive thresholding is used to defuzzify the fuzzy edge map to obtain a binary edge map. The experimental results are analyzed qualitatively and quantitatively. The quantitative measures, i.e., Pratt's figure of merit, Cohen' Kappa, Shannon's entropy, and edge strength similarity-based edge quality metric, are used. The quantitative results are statistically analyzed using t-test. The proposed algorithm outperforms many of the traditional and state-of-the-art edge detectors.","Image edge detection,
Detectors,
Microorganisms,
Image segmentation,
Entropy,
Histograms,
Convolution"
Distribution-Based Cluster Structure Selection,"The objective of cluster structure ensemble is to find a unified cluster structure from multiple cluster structures obtained from different datasets. Unfortunately, not all the cluster structures contribute to the unified cluster structure. This paper investigates the problem of how to select the suitable cluster structures in the ensemble which will be summarized to a more representative cluster structure. Specifically, the cluster structure is first represented by a mixture of Gaussian distributions, the parameters of which are estimated using the expectation-maximization algorithm. Then, several distribution-based distance functions are designed to evaluate the similarity between two cluster structures. Based on the similarity comparison results, we propose a new approach, which is referred to as the distribution-based cluster structure ensemble (DCSE) framework, to find the most representative unified cluster structure. We then design a new technique, the distribution-based cluster structure selection strategy (DCSSS), to select a subset of cluster structures. Finally, we propose using a distribution-based normalized hypergraph cut algorithm to generate the final result. In our experiments, a nonparametric test is adopted to evaluate the difference between DCSE and its competitors. We adopt 20 real-world datasets obtained from the University of California, Irvine and knowledge extraction based on evolutionary learning repositories, and a number of cancer gene expression profiles to evaluate the performance of the proposed methods. The experimental results show that: 1) DCSE works well on the real-world datasets and 2) DCSE based on DCSSS can further improve the performance of the algorithm.",
Optimization-Based Wearable Tactile Rendering,"Novel wearable tactile interfaces offer the possibility to simulate tactile interactions with virtual environments directly on our skin. But, unlike kinesthetic interfaces, for which haptic rendering is a well explored problem, they pose new questions about the formulation of the rendering problem. In this work, we propose a formulation of tactile rendering as an optimization problem, which is general for a large family of tactile interfaces. Based on an accurate simulation of contact between a finger model and the virtual environment, we pose tactile rendering as the optimization of the device configuration, such that the contact surface between the device and the actual finger matches as close as possible the contact surface in the virtual environment. We describe the optimization formulation in general terms, and we also demonstrate its implementation on a thimble-like wearable device. We validate the tactile rendering formulation by analyzing its force error, and we show that it outperforms other approaches.","Rendering (computer graphics),
Skin,
Computational modeling,
Optimization,
Virtual environments,
Haptic interfaces,
Force"
Regularized Non-negative Matrix Factorization for Identifying Differential Genes and Clustering Samples: a Survey,"Non-negative Matrix Factorization (NMF), a classical method for dimensionality reduction, has been applied in many fields. It is based on the idea that negative numbers are physically meaningless in various data-processing tasks. Apart from its contribution to conventional data analysis, the recent overwhelming interest in NMF is due to its newly discovered ability to solve challenging data mining and machine learning problems, especially in relation to gene expression data. This survey paper mainly focuses on research examining the application of NMF to identify differentially expressed genes and to cluster samples, and the main NMF models, properties, principles, and algorithms with its various generalizations, extensions, and modifications are summarized. The experimental results demonstrate the performance of the various NMF algorithms in identifying differentially expressed genes and clustering samples.","Gene expression,
Clustering algorithms,
Data analysis,
Data mining,
Principal component analysis,
Algorithm design and analysis,
Bioinformatics"
Grayscale-Thermal Object Tracking via Multitask Laplacian Sparse Representation,"This paper studies the problem of object tracking in challenging scenarios by leveraging multimodal visual data. We propose a grayscale-thermal object tracking method in Bayesian filtering framework based on multitask Laplacian sparse representation. Given one bounding box, we extract a set of overlapping local patches within it, and pursue the multitask joint sparse representation for grayscale and thermal modalities. Then, the representation coefficients of the two modalities are concatenated into a vector to represent the feature of the bounding box. Moreover, the similarity between each patch pair is deployed to refine their representation coefficients in the sparse representation, which can be formulated as the Laplacian sparse representation. We also incorporate the modal reliability into the Laplacian sparse representation to achieve an adaptive fusion of different source data. Experiments on two grayscale-thermal datasets suggest that the proposed approach outperforms both grayscale and grayscale-thermal tracking approaches.","Laplace equations,
Target tracking,
Dictionaries,
Object tracking,
Visualization,
Gray-scale,
Computational modeling"
Batch Process Monitoring Based on Multiway Global Preserving Kernel Slow Feature Analysis,"As an effective nonlinear dynamic data analysis tool, kernel slow feature analysis (KSFA) has achieved great success in continuous process monitoring field during recent years. However, its application to batch process monitoring is unexploited, which is a more challenging task because of the complicated characteristics of batch process data. In this paper, we propose a novel batch process monitoring method based on the modified KSFA method, referred to as multiway global preserving kernel slow feature analysis (MGKSFA), to capture high nonlinearity and inherently time-varying dynamics of process data. In the proposed method, a two-step multiway data unfolding strategy is first utilized to convert the three-way batch process training data set into a two-way matrix. Then, the global structure preserving-based kernel slow feature analysis (GKSFA) is used to build the nonlinear statistical monitoring model, which not only explores the local dynamic data relationships but also considers the mining of global data structure information. Furthermore, a rule based on the cumulative slowness contribution is designed to determine the number of the retained slow features. Last, two monitoring statistics T2 and SPE are built to detect the process faults. Two case studies, including one simple numerical nonlinear system and the benchmark fed-batch penicillin fermentation process, are used to demonstrate that the proposed MGKSFA method has the superior fault detection performance over the traditional batch process monitoring methods.","Batch production systems,
Monitoring,
Kernel,
Feature extraction,
Data mining,
Data analysis,
Principal component analysis"
Locally Supervised Deep Hybrid Model for Scene Recognition,"Convolutional neural networks (CNNs) have recently achieved remarkable successes in various image classification and understanding tasks. The deep features obtained at the top fully connected layer of the CNN (FC-features) exhibit rich global semantic information and are extremely effective in image classification. On the other hand, the convolutional features in the middle layers of the CNN also contain meaningful local information, but are not fully explored for image representation. In this paper, we propose a novel locally supervised deep hybrid model (LS-DHM) that effectively enhances and explores the convolutional features for scene recognition. First, we notice that the convolutional features capture local objects and fine structures of scene images, which yield important cues for discriminating ambiguous scenes, whereas these features are significantly eliminated in the highly compressed FC representation. Second, we propose a new local convolutional supervision layer to enhance the local structure of the image by directly propagating the label information to the convolutional layers. Third, we propose an efficient Fisher convolutional vector (FCV) that successfully rescues the orderless mid-level semantic information (e.g., objects and textures) of scene image. The FCV encodes the large-sized convolutional maps into a fixed-length mid-level representation, and is demonstrated to be strongly complementary to the high-level FC-features. Finally, both the FCV and FC-features are collaboratively employed in the LS-DHM representation, which achieves outstanding performance in our experiments. It obtains 83.75% and 67.56% accuracies, respectively, on the heavily benchmarked MIT Indoor67 and SUN397 data sets, advancing the state-of-the-art substantially.","Convolutional codes,
Semantics,
Image recognition,
Computer vision,
Image coding,
Feature extraction,
Electronic mail"
A Concurrent Multiple Negotiation Protocol Based on Colored Petri Nets,"Concurrent multiple negotiation (CMN) provides a mechanism for an agent to simultaneously conduct more than one negotiation. There may exist different interdependency relationships among these negotiations and these interdependency relationships can impact the outcomes of these negotiations. The outcomes of these concurrent negotiations contribute together for the agent to achieve an overall negotiation goal. Handling a CMN while considering interdependency relationships among multiple negotiations is a challenging research problem. This paper: 1) comprehensively highlights research problems of negotiations at concurrent negotiation level; 2) provides a graph-based CMN model with consideration of the interdependency relationships; and 3) proposes a colored Petri net-based negotiation protocol for conducting CMNs. With the proposed protocol, a CMN can be efficiently and concurrently processed and negotiation agreements can be efficiently achieved. Experimental results indicate the effectiveness and efficiency of the proposed protocol in terms of the negotiation success rate, the negotiation time and the negotiation outcome.","Protocols,
Petri nets,
Concurrent computing,
Cloud computing,
Australia,
Cybernetics,
Servers"
Sub-Channel and Power Allocation for Non-Orthogonal Multiple Access Relay Networks With Amplify-and-Forward Protocol,"In this paper, we study the resource allocation problem for a single-cell non-orthogonal multiple access (NOMA) relay network where an OFDM amplify-and-forward relay allocates the spectrum and power resources to the source-destination (SD) pairs. We aim to optimize the resource allocation to maximize the average sum-rate. The optimal approach requires an exhaustive search, leading to an NP-hard problem. To solve this problem, we propose two efficient many-to-many two-sided SD pair-subchannel matching algorithms, in which the SD pairs and sub-channels are considered as two sets of players chasing their own interests. The proposed algorithms can provide a sub-optimal solution to this resource allocation problem in affordable time. Both the static matching algorithm and the dynamic matching algorithm converge to a pair-wise stable matching after a limited number of iterations. Simulation results show that the capacity of both proposed algorithms in the NOMA scheme significantly outperforms the conventional orthogonal multiple access scheme. The proposed matching algorithms in NOMA scheme also achieve a better user-fairness performance than the conventional orthogonal multiple access.","NOMA,
Resource management,
Relay networks (telecommunications),
Fading channels,
Heuristic algorithms,
Wireless communication"
Radial Uniform Circular Antenna Array for Dual-Mode OAM Communication,"A radial uniform circular array (UCA) is proposed for orbital angular momentum (OAM) generation and dual-mode communication based on a multilayer design. Theoretical derivation is presented for the demonstration of the OAM generation from radial UCAs. The UCA of single mode is realized by cascading an eight-dividing feeding network with equal magnitude and specific phases for each of two neighbor ports and eight microstrip antenna elements. Both the full-wave simulations and measurements of a final fabricated antenna array are carried out. From 5.72 to 5.95 GHz, the proposed antenna possesses good -15-dB bandwidths at the ±1 modes, and a very weak cross coupling (less than -24 dB) exists in this frequency band. The helical phase wavefronts are obtained, and the radiation patterns are presented. Moreover, the dual-mode multiplexing is achieved with isolations of different channels more than 19 dB in measurements.","Antenna measurements,
Microstrip antenna arrays,
Phased arrays,
Ports (Computers),
Antenna radiation patterns,
Microstrip"
Miniature Resonant Ambulatory Robot,"This article describes the design, manufacture, and performance of a prototype miniature resonant ambulatory robot that uses piezoelectric actuators to achieve locomotion. Each leg is comprised of two piezoelectric bimorph benders, joined at the tip by a flexure and end effector. Combinations of amplitude and phase can be used to produce a wide range of motions including swinging and lifting. A lumped mass model previously developed is described as a design tool to tune the resonance modes of the end effector. The completed robot was driven with frequencies up to 500 Hz resulting in a maximum forward velocity of approximately 520 mm/s at 350 Hz. A frequency analysis was also performed to determine the effects of ground contact on the performance of the robot. This analysis showed a significant reduction in the resonance gain and frequency.","Legged locomotion,
Piezoelectric actuators,
Prototypes,
Resonant frequency,
Robot sensing systems"
Modeling and Analysis of AC Output Power Factor for Wireless Chargers in Electric Vehicles,"This paper presents a general mathematical expression and characteristic analysis of the output power factor before rectification on the receiver side for wireless chargers in electric vehicles. This power factor is usually regarded as unity (i.e., the ac output voltage is in phase with the current), based on fundamental harmonic approximation. However, the default unity power factor assumption is not accurate for output power derivation even at resonance frequency. This study explores not only output power factor characteristics for different frequencies or power levels, but also the phase relationships of the input and output ac voltages. The continuous conduction mode and discontinuous conduction mode are both analyzed. An integrated LCC compensation topology is selected as the research object, and its analysis process can be readily extended to other common topologies. Furthermore, this study is beneficial for the implementation of some control strategies requiring precise power computation/estimation, e.g., feedforward control or model prediction control. Finally, a comparison of numerical and experimental results with various misalignment cases validates correctness of the proposed theoretical derivation and analysis methodology.","Topology,
Coils,
Receivers,
Power generation,
Transmitters,
Resonant frequency,
Network topology"
A Set of Methods to Support Object-Based Distributed Analysis of Large Volumes of Earth Observation Data,"The rapid increase in the number of aerial and orbital Earth observation systems is generating a huge amount of remote sensing data that need to be readily transformed into useful information for policy and decision makers. This exposes an urgent demand for image interpretation tools that can deal efficiently with very large volumes of data. In this work, we introduce a set of methods that support distributed processing of georeferenced raster and vector data in a computer cluster, which may be a virtual cluster provided by cloud computing infrastructure services. The set of methods comprise a particular technique for indexing distributed georeferenced datasets, as well as strategies for distributing efficiently the processing of spatial context-aware operations. They provide the means for the development of scalable applications, capable of processing large volumes of geospatial data. We evaluated the proposed methods in a remote sensing image interpretation application, built on the MapReduce framework, and executed in a cloud computing infrastructure. The experimental results corroborate the capacity of the methods to support efficient handling of very large earth observation datasets.","Cloud computing,
Distributed databases,
Indexing,
Geospatial analysis,
Earth,
Remote sensing,
Spatial databases"
An Investigation of Deep-Learning Frameworks for Speaker Verification Antispoofing,"In this study, we explore the use of deep-learning approaches for spoofing detection in speaker verification. Most spoofing detection systems that have achieved recent success employ hand-craft features with specific spoofing prior knowledge, which may limit the feasibility to unseen spoofing attacks. We aim to investigate the genuine-spoofing discriminative ability from the back-end stage, utilizing recent advancements in deep-learning research. In this paper, alternative network architectures are exploited to target spoofed speech. Based on this analysis, a novel spoofing detection system, which simultaneously employs convolutional neural networks (CNNs) and recurrent neural networks (RNNs) is proposed. In this framework, CNN is treated as a convolutional feature extractor applied on the speech input. On top of the CNN processed output, recurrent networks are employed to capture long-term dependencies across the time domain. Novel features including Teager energy operator critical band autocorrelation envelope, perceptual minimum variance distortionless response, and a more general spectrogram are also investigated as inputs to our proposed deep-learning frameworks. Experiments using the ASVspoof 2015 Corpus show that the integrated CNN-RNN framework achieves state-of-the-art single-system performance. The addition of score-level fusion further improves system robustness. A detailed analysis shows that our proposed approach can potentially compensate for the issue due to short duration test utterances, which is also an issue in the evaluation corpus.","Speech,
Feature extraction,
Machine learning,
Recurrent neural networks,
Context,
Spectrogram,
Robustness"
Probabilistic Keys,"Probabilistic databases address well the requirements of an increasing number of modern applications that produce large volumes of uncertain data from a variety of sources. Probabilistic keys enforce the integrity of entities in order to facilitate data processing in probabilistic database systems. For this purpose, we establish algorithms for an agile schema-and data-driven elicitation of the marginal probability by which keys should hold in a given application domain, and for reasoning about these keys. The efficiency of our elicitation framework is demonstrated theoretically and experimentally.",
Active Synchronous Detection of Deception Attacks in Microgrid Control Systems,"An active synchronous detection method (ASDM) is presented to detect deception attacks on inverter controllers in microgrids without impeding system operations. First, microgrid control center generates specified small probing signals and inject them into controllers. The output signals are then obtained and compared with pre-determined values to locate infracted controller components. Test results show that ASDM can quickly and precisely detect various deception attacks in microgrids.","Microgrids,
Inverters,
Detectors,
Control systems,
Systems operation,
Computer security,
Fault tolerance"
Stationary Graph Processes and Spectral Estimation,"Stationarity is a cornerstone property that facilitates the analysis and processing of random signals in the time domain. Although time-varying signals are abundant in nature, in many practical scenarios, the information of interest resides in more irregular graph domains. This lack of regularity hampers the generalization of the classical notion of stationarity to graph signals. This paper proposes a definition of weak stationarity for random graph signals that takes into account the structure of the graph where the random process takes place, while inheriting many of the meaningful properties of the classical time domain definition. Provided that the topology of the graph can be described by a normal matrix, stationary graph processes can be modeled as the output of a linear graph filter applied to a white input. This is shown equivalent to requiring the correlation matrix to be diagonalized by the graph Fourier transform; a fact that is leveraged to define a notion of power spectral density (PSD). Properties of the graph PSD are analyzed and a number of methods for its estimation are proposed. This includes generalizations of nonparametric approaches such as periodograms, window-based average periodograms, and filter banks, as well as parametric approaches, using moving-average, autoregressive, and ARMA processes. Graph stationarity and graph PSD estimation are investigated numerically for synthetic and real-world graph signals.",
A Novel Solar and Electromagnetic Energy Harvesting System With a 3-D Printed Package for Energy Efficient Internet-of-Things Wireless Sensors,"This paper discusses the design of a novel dual (solar + electromagnetic) energy harvesting powered communication system, which operates at 2.4 GHz ISM band, enabling the autonomous operation of a low power consumption power management circuit for a wireless sensor, while featuring a very good “cold start” capability. The proposed harvester consists of a dual port rectangular slot antenna, a 3-D printed package, a solar cell, an RF-dc converter, a power management unit (PMU), a microcontroller unit, and an RF transceiver. Each designed component was characterized through simulation and measurements. As a result, the antenna exhibited a performance satisfying the design goals in the frequency range of 2.4-2.5 GHz. Similarly, the designed miniaturized RF-dc conversion circuit generated a sufficient voltage and power to support the autonomous operation of the bq25504 PMU for RF input power levels as low as -12.6 and -15.6 dBm at the “cold start” and “hot start” condition, respectively. The experimental testing of the PMU utilizing the proposed hybrid energy harvester confirmed the reduction of the capacitor charging time by 40% and the reduction of the minimum required RF input power level by 50% compared with the one required for the individual RF and solar harvester under the room light irradiation condition of 334 lx.","Radio frequency,
Energy harvesting,
Ports (Computers),
Three-dimensional printing,
Sensor systems,
Slot antennas"
Double-Sided Bidding Mechanism for Resource Sharing in Mobile Cloud,"Recently, a new architecture regarding a crowd of mobile devices as mobile cloud has been proposed, where the neighboring mobile devices are pooled together for resource sharing. Most existing works focus on mobile cloud framework design and assume that the nearby users are willing to share their resources. Since each user is rational and self-interested, a proper market mechanism is needed to incentivize users to participate and allocate resources among multiple users. In this paper, we consider a broker-based mobile cloud, where multiple supplying users have idle resources to share, and multiple demanding users suffer from resource limitations. We propose and analyze a double-sided bidding mechanism where each demanding user submits a bid to choose a demand resource-price function, and each supplying user submits a bid to choose a supply resource-price function. We consider the cases with price-taking users and price-anticipating users who would anticipate the influence of their own bids on the price, respectively. For the case with price-taking users, we first show that the proposed mechanism admits a unique competitive equilibrium that maximizes the social welfare of the mobile cloud and then develop an optimal distributed algorithm to achieve the desired equilibrium point. For the case with price-anticipating users, we first formulate the interaction among multiple users as a strategic game and prove the existence and uniqueness of the Nash equilibrium and then develop a distributed algorithm to compute the Nash equilibrium. Numerical results validate the efficacy of our proposed algorithms and illustrate that the social welfare achieved at the Nash equilibrium is very close to the optimal social welfare.","Mobile communication,
Cloud computing,
Mobile handsets,
Resource management,
Nash equilibrium,
Computational modeling,
Heuristic algorithms"
Smart driving in smart city,"Smart cities have been drawing attention of researchers as seen in recent intensive studies. In associated with this fact, this situation is expected to continue in future works. In other side, smart vehicles are an indispensable part of smart cities. Scientists have been researching vehicles and transportation in order to reach safe and comfortable mobility. Among these vehicles, cars are the first ones that affect human life. In this study, smart cars and their drivers are elaborated in behavioral aspect. Existing works have been discussed to figure out futuristic driving behavior in smart city environment. In order to understand human thought system, additional studies have been given and recommendations have been provided. As seen in the researches conducted in recent years, researchers have been tried to interpret behavior of drivers by examining data taken by smart phones and vehicle OBD output. Evaluations are conducted by result of the specified methods. In recent decade, it has been observed that these behaviors are not only estimations; but also systems mounted on vehicles learn overall driving behavior. Hence, developed systems should work online while drivers on steering wheel. Consequently, this study will enlighten existing trends for different types of learning schemes. Future studies are expected to combine car, driver's biologic, psychological, and environmental data. Thus, in the near future, systems that understand the human thought will be developed.",
Preserving Synchronization Accuracy From the Plug-in of NonSynchronized Nodes in a Wireless Sensor Network,"The synchronization accuracy of the nodes of a wireless sensor network (WSN) can be perturbed by the plug-in of nonsynchronized nodes (NSNs). In the case of peer-to-peer synchronization algorithms, the reference time of the WSN is established on the basis of the clock time of all nodes. Therefore, each NSN changes the reference time to synchronize all nodes with the new reference time interval needs. In this time interval, the synchronization accuracy can degrade, i.e., the delay among node clocks overcomes the admissible range. In the case of only one or many NSNs, it was assessed in previous papers that by filtering the message of each NSN, the synchronization accuracy of the already synchronized nodes (ASNs) is preserved. However, the spatial distribution of the NSNs can fool the ASNs, foiling the effect of the message filtering. This paper presents a procedure that overcomes this inconvenience. The new fully distributed and consensus-based procedure iteratively filters the messages of communicating NSNs that would increase the time delay over the admissible range. As a consequence, the synchronization accuracy is preserved whatever the spatial distribution of ASNs and NSNs. Numerical and experimental tests are performed to validate the proposed procedure.","Synchronization,
Wireless sensor networks,
Peer-to-peer computing,
Clocks,
Standards,
Delays,
Hardware"
Data Fusion and IoT for Smart Ubiquitous Environments: A Survey,"The Internet of Things (IoT) is set to become one of the key technological developments of our times provided we are able to realize its full potential. The number of objects connected to IoT is expected to reach 50 billion by 2020 due to the massive influx of diverse objects emerging progressively. IoT, hence, is expected to be a major producer of big data. Sharing and collaboration of data and other resources would be the key for enabling sustainable ubiquitous environments, such as smart cities and societies. A timely fusion and analysis of big data, acquired from IoT and other sources, to enable highly efficient, reliable, and accurate decision making and management of ubiquitous environments would be a grand future challenge. Computational intelligence would play a key role in this challenge. A number of surveys exist on data fusion. However, these are mainly focused on specific application areas or classifications. The aim of this paper is to review literature on data fusion for IoT with a particular focus on mathematical methods (including probabilistic methods, artificial intelligence, and theory of belief) and specific IoT environments (distributed, heterogeneous, nonlinear, and object tracking environments). The opportunities and challenges for each of the mathematical methods and environments are given. Future developments, including emerging areas that would intrinsically benefit from data fusion and IoT, autonomous vehicles, deep learning for data fusion, and smart cities, are discussed.","Data integration,
Smart cities,
Internet of Things,
Big Data,
Decision making,
Computer science,
Information technology"
Cuckoo search coupled artificial neural network in detection of chronic kidney disease,"In the present work a Cuckoo Search (CS) trained Neural Network (NN) or NN-CS based model has been proposed to detect Chronic Kidney Disease (CKD) which has become one of the newest threats to the developing and undeveloped countries. Studies and surveys in different parts of India have suggested that CKD is becoming a major concern day by day. The financial burden of the treatment and future consequences of CKD could be unaffordable to many if not detected at an earlier stage. Motivated by this, the NN-CS model has been proposed which significantly overcomes the problem of using local search based learning algorithms to train NNs. The input weight vector of the NN is gradually optimized by using CS to train the NN. The model has been compared with well-known classifiers like Multilayer Perceptron Feedforward Network (MLP-FFN) (trained with scaled conjugate gradient descent) and also with NN supported by Genetic Algorithm (NN-GA). The performance of the classifiers has been measured in terms of accuracy, precision, recall and F-Measure. The experimental results suggest that NN-CS based model is capable of detecting CKD more efficiently than any other existing model.","Artificial neural networks,
Diseases,
Kidney,
Training,
Optimization,
Computational modeling"
Maximizing Spectral Efficiency for Energy Harvesting-Aware WBAN,"In this paper, we investigate the spectral efficiency of a communication link in a wireless body area network (WBAN) capable of harvesting energy from the environment. We consider two scenarios for the transmission which are single- and dual-hop and achieve the power management policy for each scenario. In the first scenario, the aim is to maximize the link's spectral efficiency over N time slots subject to the battery capacity, energy harvesting constraint, and WBAN limitations including power and outage probability. In the second scenario, a decode-and-forward relay node is considered, and a spectral efficiency optimization problem with constraints similar to the first scenario is evaluated. In addition, since the channel distribution information is available at the transmitters, the lower and upper bounds of the average spectral efficiency are also derived in both scenarios. Finally, numerical results corroborate the analytical results.",
Robust Wireless Power Transmission to mm-Sized Free-Floating Distributed Implants,"This paper presents an inductive link for wireless power transmission (WPT) to mm-sized free-floating implants (FFIs) distributed in a large three-dimensional space in the neural tissue that is insensitive to the exact location of the receiver (Rx). The proposed structure utilizes a high-Q resonator on the target wirelessly powered plane that encompasses randomly positioned multiple FFIs, all powered by a large external transmitter (Tx). Based on resonant WPT fundamentals, we have devised a detailed method for optimization of the FFIs and explored design strategies and safety concerns, such as coil segmentation and specific absorption rate limits using realistic finite element simulation models in HFSS including head tissue layers, respectively. We have built several FFI prototypes to conduct accurate measurements and to characterize the performance of the proposed WPT method. Measurement results on 1-mm receivers operating at 60 MHz show power transfer efficiency and power delivered to the load at 2.4% and 1.3 mW, respectively, within 14–18 mm of Tx–Rx separation and 7 cm2 of brain surface.","Implants,
Robustness,
Wireless power transmission,
Optimization,
Magnetic heads,
Optical resonators,
Brain"
A 73.9%-Efficiency CMOS Rectifier Using a Lower DC Feeding (LDCF) Self-Body-Biasing Technique for Far-Field RF Energy-Harvesting Systems,"A self-body-biasing technique is proposed for differential-drive cross-coupled (DDCC) rectifier, with its profound application in far-field RF energy-harvesting systems. The conventional source-to-body, and the proposed technique known as Lower DC Feeding (LDCF), were fabricated in the 130-nm CMOS and compared at the operation frequency of 500 MHz, 953 MHz and 2 GHz along with a corresponding load of 2 kQ, 10 kQ and 50 kQ. The technique allows the PMOS transistors to operate with a dynamic threshold voltage (Vth) which improves the power conversion efficiency (PCE) when the rectifier is operating at a smaller received power. A 9.5% of improvement is achieved at the peak PCE when the rectifier is operating at 953 MHz, and driving a 10 kQ load. A maximum PCE of 73.9% is measured at 2 GHz when driving a 2-kQ load. The LDCF technique also offers a self-limiting capability for its output voltage, by reducing the PCE at larger received power. A limit-voltage level of 3.5 V is measured irrespective to the operating frequency and load. This capability aids the protection of the subsequent circuits in a wireless sensor from being overpowered.",
Morphus: Supporting Online Reconfigurations in Sharded NoSQL Systems,"While sharded NoSQL stores offer high availability, reconfiguration operations present a major pain point in deployments today. For instance, in order to change a configuration setting, such as the shard (or primary) key of a database table, the prevalent solutions entail shutting down the database, exporting and re-importing the table, and restarting the database. This goes against the NoSQL philosophy of high availability of data. Our system, called Morphus, provides support toward reconfigurations for NoSQL stores in an online manner. Morphus allows read and write operations to continue concurrently with the data transfer among servers. Morphus works for NoSQL stores that feature master-slave replication, range partitioning, and flexible data placement. This paper presents: 1) a systems architecture for online reconfigurations, incorporated into MongoDB and 2) optimal algorithms for online reconfigurations. Our evaluation using realistic workloads shows that Morphus completes reconfiguration efficiently, offers high availability, and incurs low overhead for reads and writes.",
Effectively Interpreting Discrete Wavelet Transformed Signals [Lecture Notes],"Following two decades of research focusing on the discrete wavelet transform (DWT) and driven by students' high level of questioning, I decided to write this essay on one of the most significant tools for time-frequency signal analysis. As it is widely applicable in a variety of fields, I invite readers to follow this lecture note, which is specially dedicated to show a practical strategy for the interpretation of DWT-based transformed signals while extracting useful information from them. The particular focus resides on the procedure used to find the time support of frequencies and how it is influenced by the wavelet family and the support size of corresponding filters.","Discrete wavelet transforms,
Time-frequency analysis,
Low-pass filters,
Finite impulse response filters,
Fluctuations,
Discrete Fourier transforms"
Social Attribute Aware Incentive Mechanism for Device-to-Device Video Distribution,"To offload and alleviate the heavy base station (BS) traffic load caused by the rapidly growing video services, device-to-device (D2D) communication, as one of the most indispensable technologies of the future cellular networks, can be potentially exploited by mobile users to distribute videos for a BS. In this paper, an effective pricing-based multicast video distribution system and a grid-based clustering method are proposed to support the distribution. Moreover, with the consideration of users' mobility and social characteristics, we classify them into multicast and core types by studying the user stay probability and familiarity. In particular, core users can cooperate with the BS to distribute videos to the multicast users through intracluster D2D multicast. However, core users cannot selflessly help the BS to distribute videos; instead, they will evaluate their personal benefits before distributing the videos to the multicast users. Further, a Stackelberg game-based pricing mechanism is proposed to inspire the core users to distribute videos. Simulation results demonstrate that the proposed mechanism can not only effectively alleviate the BS traffic load, but also significantly improve the effectiveness and reliability of video transmission.","Streaming media,
Device-to-device communication,
Mobile computing,
Data communication,
Collaboration,
Cellular networks"
Fuzzy Rule-Based Approach for Software Fault Prediction,"Knowing faulty modules prior to testing makes testing more effective and helps to obtain reliable software. Here, we develop a framework for automatic extraction of human understandable fuzzy rules for software fault detection/classification. This is an integrated framework to simultaneously identify useful determinants (attributes) of faults and fuzzy rules using those attributes. At the beginning of the training, the system assumes every attribute (feature) as a useless feature and then uses a concept of feature attenuating gate to select useful features. The learning process opens the gates or closes them more tightly based on utility of the features. Our system can discard derogatory and indifferent attributes and select the useful ones. It can also exploit subtle nonlinear interaction between attributes. In order to demonstrate the effectiveness of the framework, we have used several publicly available software fault data sets and compared the performance of our method with that of some existing methods. The results using tenfold cross-validation setup show that our system can find useful fuzzy rules for fault prediction.","Software,
Feature extraction,
Software metrics,
Software reliability,
Logic gates"
Use of Adaptive Thermal Storage System as Smart Load for Voltage Control and Demand Response,"This paper describes how a large-scale ice-thermal storage can be turned into a smart load for fast voltage control and demand-side management in power systems with intermittent renewable power, while maintaining its existing function of load shaving. The possibility of modifying a conventional thermal load has been practically demonstrated in a refrigerator using power electronics technology. With the help of an electric spring, the modified thermal load can reduce power imbalance in buildings while providing active and reactive power compensation for the power grid. Based on practical data, a building energy model incorporating a large-scale ice-thermal storage system has been successfully used to demonstrate the advantageous demand-response features using computer simulation of both grid connected and isolated power systems. The results indicate the potential of using ice-thermal storage in tall buildings in reducing voltage and frequency fluctuations in weak power grids.",
Self-Tuning Variable Frequency Controller for Inductive Electric Vehicle Charging With Multiple Power Levels,"A self-tuning controller for contactless electric vehicle (EV) charging systems based on inductive power transfer (IPT) with multiple power levels is proposed. The multiple charging levels (consisting of ten charging levels) are achieved by controlling the energy injection frequency of the transmitter coil of the IPT system. The proposed controller is capable of self-tuning the switching operations to the natural resonance frequency of the IPT system, and it benefits from soft-switching operations (zero-current switching), which ensures the maximum performance of the IPT system. The proposed controller has such a simple design, which can be implemented based on a simplified control circuit. The simulation of the proposed controller for an inductive charging system at different charging levels is carried out in MATLAB/Simulink. Also the proposed controller with an ac/dc/ac converter is implemented experimentally on an IPT charging system to verify the effectiveness of the controller at different charging levels. The experimental test results conform with the simulation results and verify that the proposed controller effectively enables self-tuning capability and soft-switching operations at different charging levels for IPT-based contactless EV charging systems.",
NameClarifier: A Visual Analytics System for Author Name Disambiguation,"In this paper, we present a novel visual analytics system called NameClarifier to interactively disambiguate author names in publications by keeping humans in the loop. Specifically, NameClarifier quantifies and visualizes the similarities between ambiguous names and those that have been confirmed in digital libraries. The similarities are calculated using three key factors, namely, co-authorships, publication venues, and temporal information. Our system estimates all possible allocations, and then provides visual cues to users to help them validate every ambiguous case. By looping users in the disambiguation process, our system can achieve more reliable results than general data mining models for highly ambiguous cases. In addition, once an ambiguous case is resolved, the result is instantly added back to our system and serves as additional cues for all the remaining unidentified names. In this way, we open up the black box in traditional disambiguation processes, and help intuitively and comprehensively explain why the corresponding classifications should hold. We conducted two use cases and an expert review to demonstrate the effectiveness of NameClarifier.","Libraries,
Metadata,
Algorithm design and analysis,
Uncertainty,
Visual analytics"
Chiral-Selective Plasmonic Metasurface Absorbers Operating at Visible Frequencies,"We demonstrate theoretically and experimentally a chiral-selective plasmonic absorber by utilizing n-shaped-resonators in the visible frequencies. Our metasurface design enables chiral-selective absorption bands, in which absorption peaks for left-handed circularly polarized and right-handed circularly polarized occur at different resonance wavelengths resulting in significant circular dichroism (CD). Both simulated and measured absorption spectra exhibit maximum absorptions exceeding 80% associated with a CD value of ~0.5. Such a chiral plasmonic metasurface absorber with high performance could find applications in optical filters, non-linear optics, thermal emitters, and hot-electron collection devices.","circular dichroism,
optical design techniques,
optical metamaterials,
optical resonators,
plasmonics,
visible spectra"
Impact of Short-Wavelength and Long-Wavelength Line-Edge Roughness on the Variability of Ultrascaled FinFETs,"We examine the impact of line-edge roughness (LER) on the variability in the on-current and saturation threshold voltage of ultrascaled FinFET devices via quantum-mechanical transport simulation. We obtain a realistic model of LER by decomposing the LER into short-λ and long-λ fluctuations, and we consider their separate influences on device performance. We show that the long-λ fluctuations lead to greater device variability than the short-λ fluctuations, and we explain the difference between the two cases via the influence of fluctuating quantum confinement arising from the LER. Finally, we consider devices in which the long-λ fluctuations of the two fin edges are correlated and demonstrate that this correlation significantly improves the variability. Thus, we show the continued need for fabrication technology either to reduce the amplitude of the long-λ fluctuations or to ensure the long-λ fluctuations between the sidewalls of ultrascaled FinFET devices are correlated.",
A Power Management System for Multianode Benthic Microbial Fuel Cells,"Benthic microbial fuel cells (BMFCs) are important energy-harvesting devices for underwater sensors and electronic devices. However, it is a challenging problem to ensure the robustness of BMFCs in harsh ocean environment. In particular, the anode buried in sediment is subject to burrowing organisms tunneling, which breaks the anaerobic condition, and the electrons generated by the anode will be consumed locally. This eliminates the difference in electric potential between the anode and the cathode. The system then becomes short-circuited and ceases to function. This is a serious problem in the underwater environment due to the likelihood of bioturbation. Using a multianode BMFC can effectively address this problem due to the distributed structure of multiple anodes. This, however, requires a new power management system (PMS) to automatically detect and remove the effect of impaired anodes. This paper presents a new PMS for multianode BMFCs. The proposed PMS automatically disconnects the impaired anodes from the rest of the system for bioturbation resilience and better efficiency. The proposed PMS is self-starting, i.e., no need of extra power sources other than the BMFC. The PMS has been tested through a prototype BFMC. Experimental results demonstrate the effectiveness of this design for multianode BMFCs.","Anodes,
Capacitors,
Charge pumps,
Cathodes,
Sediments,
Switching circuits,
Electric potential"
LESS: Big data sketching and Encryption on low power platform,"Ever-growing IoT demands big data processing and cognitive computing on mobile and battery operated devices. However, big data processing on low power embedded cores is challenging due to their limited communication bandwidth and on-chip storage. Additionally, IoT and cloud-based computing demand low overhead security kernel to avoid data breaches. In this paper, we propose a Light-weight Encryption using Scalable Sketching (LESS) framework for big data sketching and encryption using One-Time Random Linear Projections (OTRLP). OTRLP encoded matrix makes the Known Plaintext Attacks (KPA) ineffective, and attackers cannot gain significant information from plaintext-ciphertext pair. LESS framework can reduce data up to 67% with 3.81 dB signal-to-reconstruction error rate (SRER). This framework has two important kernels “sketching” and “sketch-reconstruction”, the latter is computationally intensive and costly. We propose to accelerate the sketch reconstruction using Orthogonal Matching Pursuit (OMP) on a domain specific many-core hardware named Power Efficient Nano Cluster (PENC) designed by authors of this paper. To demonstrate efficiency of LESS framework, we integrate it with Hadoop MapReduce platform for objects and scenes identification application. The full hardware integration consists of tiny ARM cores which perform task scheduling and objects identification application, while PENC acts as an accelerator for sketch reconstruction. The full hardware integration results show that the LESS framework achieves 46% reduction in data transfers with very low execution overhead of 0.11% and negligible energy overhead of 0.001% when tested for 2.6 GB streaming input data. The heterogeneous LESS framework requires 2× less transfer time and achieves 2.25× higher throughput per watt compared to MapReduce platform.",
MRapid: An Efficient Short Job Optimizer on Hadoop,"Data have been generated and collected at an accelerating pace. Hadoop has made analyzing large scale data much simpler to developers/analysts using commodity hardware. Interestingly, it has been shown that most Hadoop jobs have small input size and do not run for long time. For example, higher level query languages, such as Hive and Pig, would handle a complex query by breaking it into smaller adhoc ones. Although Hadoop is designed for handling complex queries with large data sets, we found that it is highly inefficient to operate at small scale data, despite a new Uber mode was introduced specifically to handle jobs with small input size. In this paper, we propose an optimized Hadoop extension called MRapid, which significantly speeds up the execution of short jobs. It is completely backward compatible to Hadoop, and imposes negligible overhead. Our experiments on Microsoft Azure public cloud show that MRapid can improve performance by up to 88% compared to the original Hadoop.","Containers,
Heart beat,
Resource management,
Distributed databases,
Yarn,
Computer science,
Parallel processing"
Joint Optimization of Bandwidth for Provider and Delay for User in Software Defined Data Centers,"In large-scale Internet applications running on geographically distributed datacenters, such as video streaming, it is important to efficiently allocate requests among datacenters. To the best of our knowledge, existing approaches, however, either solely focus on minimizing total cost for provider, or guaranteeing QoS for end-users. In this paper, we apply the software defined network (SDN) controller to enable the central control of the entire network, and propose a joint optimization model to consider high bandwidth utilization for provider and low delay for users. We present the Nash bargaining solution (NBS) based method to model both requirements of provider's high bandwidth utilization and end-users' low delay. Specifically, we formulate the design of request allocation under those requirements as an optimization problem, which is NP-hard. To solve such hard optimization problem, we develop an efficient algorithm blending the advantages of Logarithmic Smoothing technique and the auxiliary variable method. According to the theoretical analysis, we verify the existence and uniqueness of our solution and the convergence of our algorithm. We conduct a large amount of experiments based on real-world workload traces and demonstrate the efficiency of our algorithm compared to both greedy and locality algorithms.","Delays,
Bandwidth,
Resource management,
Optimization,
Time factors,
Games,
Joints"
Cloud Service Reliability Enhancement via Virtual Machine Placement Optimization,"With rapid adoption of the cloud computing model, many enterprises have begun deploying cloud-based services. Failures of virtual machines (VMs) in clouds have caused serious quality assurance issues for those services. VM replication is a commonly used technique for enhancing the reliability of cloud services. However, when determining the VM redundancy strategy for a specific service, many state-of-the-art methods ignore the huge network resource consumption issue that could be experienced when the service is in failure recovery mode. This paper proposes a redundant VM placement optimization approach to enhancing the reliability of cloud services. The approach employs three algorithms. The first algorithm selects an appropriate set of VM-hosting servers from a potentially large set of candidate host servers based upon the network topology. The second algorithm determines an optimal strategy to place the primary and backup VMs on the selected host servers with k-fault-tolerance assurance. Lastly, a heuristic is used to address the task-to-VM reassignment optimization problem, which is formulated as finding a maximum weight matching in bipartite graphs. The evaluation results show that the proposed approach outperforms four other representative methods in network resource consumption in the service recovery stage.",
Supermodular Game-Based Distributed Joint Uplink Power and Rate Allocation in Two-Tier Femtocell Networks,"This paper tackles the problem of joint users' uplink transmission power and data rate allocation in multi-service two-tier femtocell networks. Each user-either macrocell (MUE) or femtocell user equipment (FUE)-is associated with a two-variable utility function that represents his perceived satisfaction with respect to his allocated resources (i.e., power and rate). User's utility function is differentiated based both on the tier that the user belongs to and the service he requests. The joint resource allocation problem is directly confronted as a two-variable optimization problem and formulated as a non-cooperative game. The theory of supermodular games is utilized towards treating the two-variable optimization problem and the inherent multidimensional competition that arises among the users. The existence of proposed game's Nash Equilibrium (NE) point is analytically shown, while game's convergence to its NE point is proven. A distributed and iterative algorithm for computing the desired NE is introduced, where the optimal values of each user's uplink transmission power and data rate are simultaneously updated at the same step. The performance of the proposed approach is evaluated via modeling and simulation and its superiority compared to other state of the art approaches is illustrated.",
Deletion Codes in the High-Noise and High-Rate Regimes,"The noise model of deletions poses significant challenges in coding theory, with basic questions like the capacity of the binary deletion channel still being open. In this paper, we study the harder model of worst case deletions, with a focus on constructing efficiently decodable codes for the two extreme regimes of high-noise and high-rate. Specifically, we construct polynomial-time decodable codes with the following tradeoffs (for any ε > 0): 1) codes that can correct a fraction 1 - ε of deletions with rate poly(ε) over an alphabet of size poly(1/ε); 2) binary codes of rate 1-Õ(√ε) that can correct a fraction ε of deletions; and 3) Binary codes that can be list-decoded from a fraction (1/2-ε) of deletions with rate poly(ε). This paper gives the first efficient constructions which meet the qualitative goals of correcting a deletion fraction approaching 1 over bounded alphabets, and correcting a constant fraction of bit deletions with rate approaching 1 over a fixed alphabet. The abovementioned results bring our understanding of deletion code constructions in these regimes to a similar level as worst case errors.","Binary codes,
Decoding,
Encoding,
Upper bound,
Electronic mail,
Reed-Solomon codes"
CATrust: Context-Aware Trust Management for Service-Oriented Ad Hoc Networks,"We propose a context-aware trust management model called CATrust for service-oriented ad hoc networks such as peer-to-peer and Internet of Things networks wherein a node can be a service requester or a service provider. The novelty of our design lies in the use of logistic regression to dynamically estimate trustworthiness of a service provider based on its service behavior patterns in response to context environment changes. We develop a recommendation filtering mechanism to effectively screen out dishonest recommendations even in extremely hostile environments in which the majority recommenders are dishonest. We demonstrate desirable convergence, accuracy, and resiliency properties of CATrust. We also demonstrate that CATrust outperforms contemporary peer-to-peer and Internet of Things trust models in terms of service trust prediction accuracy against collusion recommendation attacks.",
On Log-Normality of RSSI in Narrowband Receivers Under Static Conditions,"A growing set of environmental sensing applications use received signal strength measurements of a static wireless network for unobtrusive monitoring purposes. The success of these systems, which typically process low-amplitude signals, depend strongly on the distribution of the measurements when there are no changes in the channel. In this letter, a statistical model for signal strength measurements acquired when the environment is static is studied. As previously empirically verified, it is shown that the measurements have log-normal distribution even in idealistic environments, which cannot be explained using log-normal shadow fading arguments. Quantization and round-off errors induced by different measurement system components are also considered, and their impact are analyzed. As a result, it is shown that the logarithmic received signal strength measurements under static channel conditions are samples from stationary Gaussian process independent of the environment.","Random variables,
Quantization (signal),
Signal to noise ratio,
Fading channels,
Received signal strength indicator,
Sensors,
Gaussian distribution"
Improving Evolutionary Algorithms in a Continuous Domain by Monitoring the Population Midpoint,"It is advocated that monitoring the population midpoint allows for improving the efficiency of population-based evolutionary algorithms (EAs) in ℝd. The theoretical motivation supporting this hypothesis is provided in this letter, and this phenomenon is empirically confirmed for selected typical EAs by a series of tests for fitness functions contained in the CEC2005 and CEC2013 benchmark sets.",
A Global Approach to Fast Video Stabilization,"This paper presents a novel formulation of video stabilization by directly solving for optimal image warps toward stabilized sequence. With the estimated shaky motion via long or short feature trajectories, our approach encodes another two steps, motion compensation and image warping, into a single global optimization process, rather than operating as two individual steps. This process is done only with positions of embedded mesh vertices as common variables. Spatial and temporal coherence is therein reformulated with similarity-invariant representation of motion trajectories and intra- (and inter-) frame consistency of similar transformations with respect to mesh vertices. Such a one-shot formulation converts video stabilization into a quadratic energy minimization problem defined for image warps, and thus can be efficiently resolved by using a robust solver for sparse linear systems. Experimental results demonstrate the flexibility and efficiency of our approach in producing visually plausible stabilization effects on a variety of videos.","Trajectory,
Motion compensation,
Cameras,
Optimization,
Optical imaging,
Distortion,
Visualization"
Power System Risk Assessment in Cyber Attacks Considering the Role of Protection Systems,"This paper presents a risk assessment method for evaluating the cyber security of power systems considering the role of protection systems. This paper considers the impact of bus and transmission line protection systems located in substations on the cyber-physical performance of power systems. The proposed method simulates the physical response of power systems to malicious attacks on protection system settings and parameters. The relationship among settings of protection devices, protection logics, and circuit breaker logics is analyzed. The expected load curtailment (ELC) index is used in this paper to quantify potential system losses due to cyber attacks. The Monte Carlo simulation is applied to calculate ELC for assessing attackers' capabilities as bus arrangements are altered. The effectiveness of the proposed risk assessment method is demonstrated using a 9-bus system and the IEEE 68-bus system.","Substations,
Relays,
Computer security,
Risk management,
Power system protection,
Power grids"
Efficient Algorithms for Mining Erasable Closed Patterns From Product Datasets,"Finding knowledge from large data sets to use in intelligent systems becomes more and more important in the Internet era. Pattern mining, classification, text mining, and opinion mining are the topical issues. Among them, pattern mining is an important issue. The problem of mining erasable patterns (EPs) has been proposed as a variant of frequent pattern mining for optimizing the production plans of factories. Several algorithms have been proposed for effectively mining EPs. However, for large threshold values, many EPs are obtained, leading to large memory usage. Therefore, it is necessary to mine a condensed representation of EPs. This paper first defines erasable closed patterns (ECPs), which can represent the set of EPs without information loss. Then, a theorem for fast determining ECPs based on dPidset structure is proposed and proven. Next, two efficient algorithms [erasable closed pattern mining (ECPat) and dNC_Set based algorithm for erasable closed pattern mining (dNC-ECPM)] for mining ECPs based on this theorem are proposed. Experimental results show that ECPat is the best method for sparse data sets, while dNC-ECPM algorithm outperforms ECPat algorithm and a modified mining erasable itemsets algorithm in terms of the mining time and memory usage for all remaining data sets.","Algorithm design and analysis,
Data mining,
Intelligent systems,
Production facilities,
Urban areas,
Itemsets,
Magneto electrical resistivity imaging technique"
A 1.2V-to-0.4V 3.2GHz-to-14.3MHz Power-Efficient 3-Port Register File in 65-nm CMOS,"This paper presents a 44.2-mW 3.2-GHz 3-port register file (RF) that demonstrates measured operation from 1.2 V down to 0.4 V. The 32-entry× 32-bit/word 2-read/1-write RF is fabricated in TSMC 65-nm low-power low threshold voltage (low-Vt) CMOS process. A four-transistor read port is presented that permits the design of low-capacitance dynamic local bitlines (LBLs). Switching power in the LBLs and the LBL precharge buffer is thereby reduced. Based on extensive simulation results, the proposed read port is recommended for use in wide-worded RFs, which employ a wide dynamic-OR structure at the LBL stage. The proposed RF outperforms the conventional design in terms of power consumption for frequencies exceeding 3-GHz. The read port exploits intrinsic capacitive coupling to achieve robust operation over a wide voltage range. The architecture of the read port simultaneously enhances robustness of the dynamic bitline by 58.8% as compared to the conventional low-Vt bitline.","Radio frequency,
Logic gates,
Robustness,
Ports (Computers),
Clocks,
MOS devices,
Registers"
Colorgorical: Creating discriminable and preferable color palettes for information visualization,"We present an evaluation of Colorgorical, a web-based tool for creating discriminable and aesthetically preferable categorical color palettes. Colorgorical uses iterative semi-random sampling to pick colors from CIELAB space based on user-defined discriminability and preference importances. Colors are selected by assigning each a weighted sum score that applies the user-defined importances to Perceptual Distance, Name Difference, Name Uniqueness, and Pair Preference scoring functions, which compare a potential sample to already-picked palette colors. After, a color is added to the palette by randomly sampling from the highest scoring palettes. Users can also specify hue ranges or build off their own starting palettes. This procedure differs from previous approaches that do not allow customization (e.g., pre-made ColorBrewer palettes) or do not consider visualization design constraints (e.g., Adobe Color and ACE). In a Palette Score Evaluation, we verified that each scoring function measured different color information. Experiment 1 demonstrated that slider manipulation generates palettes that are consistent with the expected balance of discriminability and aesthetic preference for 3-, 5-, and 8-color palettes, and also shows that the number of colors may change the effectiveness of pair-based discriminability and preference scores. For instance, if the Pair Preference slider were upweighted, users would judge the palettes as more preferable on average. Experiment 2 compared Colorgorical palettes to benchmark palettes (ColorBrewer, Microsoft, Tableau, Random). Colorgorical palettes are as discriminable and are at least as preferable or more preferable than the alternative palette sets. In sum, Colorgorical allows users to make customized color palettes that are, on average, as effective as current industry standards by balancing the importance of discriminability and aesthetic preference.","Color,
Image color analysis,
Visualization,
Harmonic analysis,
Benchmark testing,
Industries,
Standards"
Gait Rhythm Fluctuation Analysis for Neurodegenerative Diseases by Empirical Mode Decomposition,"Previous studies have indicated that gait rhythm fluctuations are useful for characterizing certain pathologies of neurodegenerative diseases such as Huntington's disease (HD), amyotrophic lateral sclerosis (ALS), and Parkinson's disease (PD). However, no previous study has investigated the properties of frequency range distributions of gait rhythms. Therefore, in our study, empirical mode decomposition was implemented for decomposing the time series of gait rhythms into intrinsic mode functions from the high-frequency component to the low-frequency component sequentially. Then, Kendall's coefficient of concordance and the ratio for energy change for different IMFs were calculated, which were denoted as Wand RE, respectively. Results revealed that the frequency distributions of gait rhythms in patients with neurodegenerative diseases are less homogeneous than healthy subjects, and the gait rhythms of the patients contain much more high-frequency components. In addition, parameters of W and RE can significantly differentiate among the four groups of subjects (HD, ALS, PD, and healthy subjects) (with the minimum p-value of 0.0000493). Finally, five representative classifiers were utilized in order to evaluate the possible capabilities of W and RE to distinguish the patients with neurodegenerative diseases from the healthy subjects. This achieved maximum area under the curve values of 0.949, 0.900, and 0.934 for PD, HD, and ALS detection, respectively. In sum, our study suggests that gait rhythm features extracted in the frequency domain should be given consideration seriously in the future neurodegenerative disease characterization and intervention.","Diseases,
Rhythm,
High definition video,
Fluctuations,
Time series analysis,
Foot,
Empirical mode decomposition"
Mitigating Water Absorption in Waveguides Made From Unannealed PECVD SiO2,"Water absorption was studied in two types of waveguides made from unannealed plasma enhanced chemical vapor deposition (PECVD) SiO2. Standard rib anti-resonant reflecting optical waveguides (ARROWs) were fabricated with thin films of different intrinsic stress and indices of refraction. Buried ARROWs (bARROWs) with low and high refractive index differences between the core and cladding regions were also fabricated from the same types of PECVD films. All waveguides were subjected to a heated, high humidity environment and their optical throughput was tested over time. Due to water absorption in the SiO2 films, the optical throughput of all of the ARROWs decreased with time spent in the wet environment. The ARROWs with the lowest stress SiO2 had the slowest rate of throughput change. High index difference bARROWs showed no decrease in optical throughput after 40 days in the wet environment and are presented as a solution for environmentally stable waveguides made from unannealed PECVD SiO2.","Optical waveguides,
Optical films,
Optical refraction,
Optical device fabrication,
Optical variables control,
Stress"
Knowledge-Enhanced Mobile Video Broadcasting Framework With Cloud Support,"The convergence of mobile communications and cloud computing facilitates the cross-layer network design and content-assisted communication. Mobile video broadcasting can benefit from this trend by utilizing joint source-channel coding and strong information correlation in clouds. In this paper, a knowledge-enhanced mobile video broadcasting (KMV-Cast) is proposed. The KMV-Cast is built on a linear video transmission instead of a traditional digital video system, and exploits the hierarchical Bayesian model to integrate the correlated information into the video reconstruction at the receiver. The correlated information is distilled to obtain its intrinsic features, and the Bayesian estimation algorithm is used to maximize the video quality. The KMV-Cast system consists of both likelihood broadcasting and prior knowledge broadcasting. The simulation results show that the proposed KMV-Cast scheme outperforms the typical linear video transmission scheme called Softcast, and achieves 8 dB more of the peak signal-to-noise ratio (PSNR) gain at low-SNR channels (i.e., -10 dB), and 5 dB more of PSNR gain at high-SNR channels (i.e., 25 dB). Compared with the traditional digital video system, the proposed scheme has 7 dB more of PSNR gain than the JPEG2000 + 802.11a scheme at a 10-dB channel SNR.","Mobile communication,
Cloud computing,
Image reconstruction,
Discrete cosine transforms,
Mobile computing,
Bayes methods,
Multimedia communication"
Modeling and Analysis of the Thermal Properties Exhibited by Cyberphysical Data Centers,"Data centers (DCs) contribute toward the prevalent application and adoption of the cloud by providing architectural and operational foundation. To perform sustainable computation and storage, a DC is equipped with tens of thousands of servers, if not more. It is worth noting that the operational cost of a DC is being dominated by the cost spent on energy consumption. In this paper, we model a DC as a cyberphysical system (CPS) to capture the thermal properties exhibited by the DC. All software aspects, such as scheduling, load balancing, and all the computations performed by the devices, are considered the “cyber” component. The supported infrastructure, such as servers and switches, are modeled as the “physical” component of the CPS. We perform detailed modeling of the thermal characteristics displayed by the major components of the CPS. Moreover, we propose a thermal-aware control strategy that uses a high-level centralized controller and a low-level centralized controller to manage and control the thermal status of the cyber components at different levels. Our proposed strategy is testified and demonstrated by executing on a real DC workload and comparing it with three existing strategies, i.e., one classical and two thermal-aware strategies. Furthermore, we also perform formal modeling, analysis, and verification of the strategies using high-level Petri nets, the Z language, the Satisfiability Modulo Theories Library (SMT-Lib), and the Z3 solver.","Servers,
Computational modeling,
Analytical models,
Thermal analysis,
Thermal management,
Heating,
Temperature"
Sequential Estimation and Diffusion of Information Over Networks: A Bayesian Approach With Exponential Family of Distributions,"Diffusion networks where nodes collaboratively estimate the parameters of stochastic models from shared observations and other estimates have become an established research topic. In this paper the problem of sequential estimation where information in the network diffuses with time is formulated abstractly and independently from any particular model. The objective is to reach a generic solution that is applicable to a wide class of popular models and based on the exponential family of distributions. The adopted Bayesian and information-theoretic paradigms provide probabilistically consistent means for incorporation of shared observations in the implemented estimation of the unknowns by the nodes as well as for effective combination of the “knowledge” of the nodes over the network. It is shown and illustrated on four examples that under certain conditions, the resulting algorithms are analytically tractable, either directly or after simple approximations. The examples include linear regression, Kalman filtering, logistic regression, and inference of an inhomogeneous Poisson process. The first two examples have their more or less direct counterparts in the state-of-the-art diffusion literature whereas the latter two are new.",
Citywide Traffic Volume Estimation Using Trajectory Data,"Traffic volume estimation at the city scale is an important problem useful to many transportation operations and urban applications. This paper proposes a hybrid framework that integrates both state-of-art machine learning techniques and well-established traffic flow theory to estimate citywide traffic volume. In addition to typical urban context features extracted from multiple sources, we extract a special set of features from GPS trajectories based on the implications of traffic flow theory, which provide extra information on the speed-flow relationship. Using the network-wide speed information estimated from a travel speed estimation model, a volume related high level feature is first learned using an unsupervised graphical model. A volume re-interpretation model is then introduced to map the volume related high level feature to the predicted volume using a small amount of ground truth data for training. The framework is evaluated using a GPS trajectory dataset from 33,000 Beijing taxis and volume ground truth data obtained from 4,980 video clips. The results demonstrate effectiveness and potential of the proposed framework in citywide traffic volume estimation.","Roads,
Volume measurement,
Feature extraction,
Trajectory,
Global Positioning System,
Vehicles,
Solid modeling"
Fault Detection for Photovoltaic Systems Based on Multi-Resolution Signal Decomposition and Fuzzy Inference Systems,"This paper presents a detection scheme for DC side short-circuit faults of photovoltaic (PV) arrays that consist of multiple PV panels connected in a series/parallel configuration. Such faults are nearly undetectable under low irradiance conditions, particularly, when a maximum power point tracking algorithm is in-service. If remain undetected, these faults can considerably lower the output energy of solar systems, damage the panels, and potentially cause fire hazards. The proposed fault detection scheme is based on a pattern recognition approach that employs a multiresolution signal decomposition technique to extract the necessary features, based on which a fuzzy inference system determines if a fault has occurred. The presented case studies (both simulation and experimental) demonstrate the effective and reliable performance of the proposed method in detecting PV array faults.","Circuit faults,
Maximum power point trackers,
Fuses,
Fault detection,
Biographies,
Fuzzy logic"
Detecting Cardiovascular Disease from Mammograms With Deep Learning,"Coronary artery disease is a major cause of death in women. Breast arterial calcifications (BACs), detected in mammograms, can be useful risk markers associated with the disease. We investigate the feasibility of automated and accurate detection of BACs in mammograms for risk assessment of coronary artery disease. We develop a 12-layer convolutional neural network to discriminate BAC from non-BAC and apply a pixelwise, patch-based procedure for BAC detection. To assess the performance of the system, we conduct a reader study to provide ground-truth information using the consensus of human expert radiologists. We evaluate the performance using a set of 840 full-field digital mammograms from 210 cases, using both free-response receiver operating characteristic (FROC) analysis and calcium mass quantification analysis. The FROC analysis shows that the deep learning approach achieves a level of detection similar to the human experts. The calcium mass quantification analysis shows that the inferred calcium mass is close to the ground truth, with a linear regression between them yielding a coefficient of determination of 96.24%. Taken together, these results suggest that deep learning can be used effectively to develop an automated system for BAC detection in mammograms to help identify and assess patients with cardiovascular risks.","Mammography,
Diseases,
Arteries,
Machine learning,
Neural networks,
Calcium,
Breast"
A Robust and Efficient Approach to License Plate Detection,"This paper presents a robust and efficient method for license plate detection with the purpose of accurately localizing vehicle license plates from complex scenes in real time. A simple yet effective image downscaling method is first proposed to substantially accelerate license plate localization without sacrificing detection performance compared with that achieved using the original image. Furthermore, a novel line density filter approach is proposed to extract candidate regions, thereby significantly reducing the area to be analyzed for license plate localization. Moreover, a cascaded license plate classifier based on linear support vector machines using color saliency features is introduced to identify the true license plate from among the candidate regions. For performance evaluation, a data set consisting of 3977 images captured from diverse scenes under different conditions is also presented. Extensive experiments on the widely used Caltech license plate data set and our newly introduced data set demonstrate that the proposed approach substantially outperforms state-of-the-art methods in terms of both detection accuracy and run-time efficiency, increasing the detection ratio from 91.09% to 96.62% while decreasing the run time from 672 to 42 ms for processing an image with a resolution of 1082×728. The executable code and our collected data set are publicly available.","Licenses,
Image edge detection,
Image color analysis,
Vehicles,
Feature extraction,
Character recognition,
Robustness"
Stochastic Optimal Regulation of Nonlinear Networked Control Systems by Using Event-Driven Adaptive Dynamic Programming,"In this paper, an event-driven stochastic adaptive dynamic programming (ADP)-based technique is introduced for nonlinear systems with a communication network within its feedback loop. A near optimal control policy is designed using an actor-critic framework and ADP with event sampled state vector. First, the system dynamics are approximated by using a novel neural network (NN) identifier with event sampled state vector. The optimal control policy is generated via an actor NN by using the NN identifier and value function approximated by a critic NN through ADP. The stochastic NN identifier, actor, and critic NN weights are tuned at the event sampled instants leading to aperiodic weight tuning laws. Above all, an adaptive event sampling condition based on estimated NN weights is designed by using the Lyapunov technique to ensure ultimate boundedness of all the closed-loop signals along with the approximation accuracy. The net result is event-driven stochastic ADP technique that can significantly reduce the computation and network transmissions. Finally, the analytical design is substantiated with simulation results.","Artificial neural networks,
Delays,
Packet loss,
Optimal control,
Communication networks"
A novel approach for embedding communication symbols into physical radar waveforms,"Due to constantly increasing demand from commercial communications, defense applications are losing spectrum while still striving to maintain legacy capabilities, not to mention the need for enhanced performance. Consequently, ongoing research is focused on developing multi-function methods to share spectrum between radar and military communication. One approach is to incorporate information-bearing communication symbols into the emitted radar waveforms. However, varying the radar waveform during a coherent processing interval (CPI) causes range sidelobe modulation (RSM) that results in increased residual clutter in the range-Doppler response, thus leading to reduced target visibility. Here a novel approach is proposed to embed information into radar emissions while preserving constant envelope waveforms with good spectral containment. Information sequences are implemented using continuous phase modulation (CPM) and phase-attached to a polyphase-coded frequency-modulated (PCFM) radar waveform, the implementation of which is also derived from CPM. The resulting communication-embedded radar waveforms therefore maintain high power and spectral efficiency. More importantly, the adjustable parameterization of the proposed approach enables direct control of the degree of RSM by trading off bit error rate (BER) and/or data throughput.","Communication symbols,
Radar applications,
Frequency modulation,
Bit error rate,
Throughput"
Mode Selection and Resource Allocation in Device-to-Device Communications: A Matching Game Approach,"Device to device (D2D) communication is considered as an effective technology for enhancing the spectral efficiency and network throughput of existing cellular networks. However, enabling it in an underlay fashion poses a significant challenge pertaining to interference management. In this paper, mode selection and resource allocation for an underlay D2D network is studied while simultaneously providing interference management. The problem is formulated as a combinatorial optimization problem whose objective is to maximize the utility of all D2D pairs. To solve this problem, a learning framework is proposed based on a problem-specific Markov chain. From the local balance equation of the designed Markov chain, the transition probabilities are derived for distributed implementation. Then, a novel two phase algorithm is developed to perform mode selection and resource allocation in the respective phases. This algorithm is then shown to converge to a near optimal solution. Moreover, to reduce the computation in the learning framework, two resource allocation algorithms based on matching theory are proposed to output a specific and deterministic solution. The first algorithm employs the one-to-one matching game approach whereas in the second algorithm, the one-to many matching game with externalities and dynamic quota is employed. Simulation results show that the proposed framework converges to a near optimal solution under all scenarios with probability one. Moreover, our results show that the proposed matching game with externalities achieves a performance gain of up to 35 percent in terms of the average utility compared to a classical matching scheme with no externalities.","Device-to-device communication,
Resource management,
Interference,
Games,
Markov processes,
Cellular networks,
Throughput"
Continuous Dynamic Constrained Optimization With Ensemble of Locating and Tracking Feasible Regions Strategies,"Dynamic constrained optimization problems (DCOPs) are difficult to solve because both objective function and constraints can vary with time. Although DCOPs have drawn attention in recent years, little work has been performed to solve DCOPs with multiple dynamic feasible regions from the perspective of locating and tracking multiple feasible regions in parallel. Moreover, few benchmarks have been proposed to simulate the dynamics of multiple disconnected feasible regions. In this paper, first, the idea of tracking multiple feasible regions, originally proposed by Nguyen and Yao, is enhanced by specifically adopting multiple subpopulations. To this end, the dynamic species-based particle swam optimization (DSPSO), a representative multipopulation algorithm, is adopted. Second, an ensemble of locating and tracking feasible regions strategies is proposed to handle different types of dynamics in constraints. Third, two benchmarks are designed to simulate the DCOPs with dynamic constraints. The first benchmark, including two variants of G24 (called G24v and G24w), could control the size of feasible regions. The second benchmark, named moving feasible regions benchmark (MFRB), is highly configurable. The global optimum of MFRB is calculated mathematically for experimental comparisons. Experimental results on G24, G24v, G24w, and MFRB show that the DSPSO with the ensemble of strategies performs significantly better than the original DSPSO and other typical algorithms.",
Improving Flash Resource Utilization at Minimal Management Cost in Virtualized Flash-Based Storage Systems,"Effectively leveraging Flash resources has emerged as a highly important problem in enterprise storage systems. One of the popular techniques today is to use Flash as a secondary-level host-side cache in the virtual machine environment. Although this approach delivers IO acceleration for VMs’ IO workloads, it might not be able to fully exploit the outstanding performance of Flash and justify the high cost-per-GB of Flash resources. In this paper, we design new VMware Flash Resource Managers (vFRM and glb-vFRM) under the consideration of both performance and the incurred cost for managing Flash resources. Specifically, vFRM and glb-vFRM aim to maximize the utilization of Flash resources with minimal CPU, memory and IO cost in managing and operating Flash for a dedicated enterprise workload and multiple heterogeneous enterprise workloads, respectively. Our new Flash resource managers adopt the ideas of thermodynamic heating and cooling to identify data blocks that can benefit the most from being put on Flash and migrate data blocks between Flash and magnetic disks in a lazy and asynchronous mode. Experimental evaluation of the prototype shows that both vFRM and glb-vFRM achieve better cost-effectiveness than traditional caching solutions, i.e., obtaining IO hit ratios even slightly better than some of the conventional algorithms as Flash size increases yet costing orders of magnitude less IO bandwidth.","Resource management,
Servers,
Cloud computing,
Virtual machining,
Bandwidth,
Heuristic algorithms,
Measurement"
Necessary and Sufficient Conditions for Consensus of Second-Order Multiagent Systems Under Directed Topologies Without Global Gain Dependency,"The consensus problem for second-order multiagent systems with absolute velocity damping under directed topologies is investigated. In contrast to the existing results, which rely on a sufficiently large common absolute velocity damping gain above a lower bound dependent on global information, this paper focuses on novel algorithms to overcome this limitation. A novel consensus algorithm, where different agents use different absolute velocity damping gains, is first proposed. In the absence of delays, based on a system transformation method, the consensus problem for second-order multiagent systems is converted into that for first-order multiagent systems with the agent number doubled. Necessary and sufficient conditions are then derived under directed topologies by relating the topologies associated with the doubled number of agents and the original team of agents. In the presence of multiple constant delays, based on a further system transformation method, the consensus problem for second-order multiagent systems is converted into the stability problem for corresponding systems. Necessary and sufficient conditions are presented to guarantee consensus under a directed fixed topology. For systems with a uniform constant delay, more concrete necessary and sufficient conditions on how large the delay can be to guarantee consensus is given. Numerical simulations are provided to illustrate the effectiveness of the obtained theoretical results.",
Time-Encoded Values for Highly Efficient Stochastic Circuits,"Stochastic computing (SC) is a promising technique for applications that require low area overhead and fault tolerance, but can tolerate relatively high latency. In the SC paradigm, logical computation is performed on randomized bit streams. In prior work, streams were generated with linear feedback shift registers; these contributed heavily to the hardware cost and consumed a significant amount of power. This paper introduces a new approach for encoding signal values: computation is performed on analog periodic pulse signals. Exploiting pulse width modulation, time-encoded signals corresponding to specific values are generated by adjusting the frequency and duty cycles of pulse width modulated (PWM) signals. With this approach, the latency, area, and energy consumption are all greatly reduced. Experimental results on image processing applications show up to 99% performance speedup, 98% saving in energy dissipation, and 40% area reduction compared to prior stochastic approaches. Circuits synthesized with the proposed approach can work as fast and energy-efficiently as a conventional binary design while retaining the fault-tolerance and low-cost advantages of conventional stochastic designs.","Pulse width modulation,
Generators,
Logic gates,
Clocks,
Hardware,
Stochastic processes,
Image processing"
Scheduling and Control of Startup Process for Single-Arm Cluster Tools With Residency Time Constraints,"Due to the trends of larger wafer diameters and smaller lot sizes, cluster tools need to switch from processing one lot of wafers to another frequently. This leads to more transient periods in wafer fabrication, which includes startup and close-down processes. Their efficient scheduling and control problems become more and more important. They become very difficult to solve especially when wafer residency time constraints must be considered. Most previous studies focused on the steady periodic schedule for cluster tools. Little research was on the transient processes of cluster tools despite their increasing importance. In order to optimize a startup transient process, this work develops a Petri net model to describe its behavior for a single-arm cluster tool. Then, based on the model, for the case that the workloads among the steps can be properly balanced, this work proposes a scheduling algorithm to find an optimal and feasible schedule for the startup process. For the other cases schedulable at the steady state, a linear programming model is developed to find an optimal and feasible schedule for the startup process. Finally, illustrative examples are given to show the applications of the proposed method.",
Fully- and Quasi-Vertical GaN-on-Si p-i-n Diodes: High Performance and Comprehensive Comparison,"We report growth and fabrication of fully- and quasi-vertical GaN-on-Si p-i-n diodes. A record high Baliga figure of merit of 304 and 152 MW/cm2 is reported for fully-and quasi-vertical GaN-on-Si p-i-n diodes, respectively. A comprehensive comparison has been made between the two kinds of diodes in regard ON-resistance, breakdown voltage, and switching performance. An ultralow differential ON-resistance of 0.5 and 1.0 mQ · cm2 has been demonstrated for quasi- and fully-vertical diodes with a diameter of 60 μm at 3 kA/cm2. Current crowding effect in the n-GaN was a dominant factor of RON, especially for large size quasi-vertical diodes at high current density. A high Vbr of 390 V has been demonstrated for the two types of device structures, regardless of device diameters. The same breakdown voltage and low off-state leakage indicated the reliability of fully-vertical device fabrication that reflects intrinsic properties of the grown epilayers. The two kinds of diodes share similar switching performance, which is much superior to a commercial fast-recovery Si diode as a reference. The device characteristics show promising potential of both fully-and quasi-vertical diodes for low-cost high-power applications.",
Ring: Real-Time Emerging Anomaly Monitoring System over Text Streams,"Microblog platforms have been extremely popular in the big data era due to its real-time diffusion of information. It’s important to know what anomalous events are trending on the social network and be able to monitor their evolution and find related anomalies. In this paper we demonstrate RING, a real-time emerging anomaly monitoring system over microblog text streams. RING integrates our efforts on both emerging anomaly monitoring research and system research. From the anomaly monitoring perspective, RING proposes a graph analytic approach such that (1) RING is able to detect emerging anomalies at an earlier stage compared to the existing methods, (2) RING is among the first to discover emerging anomalies correlations in a streaming fashion, (3) RING is able to monitor anomaly evolutions in real-time at different time scales from minutes to months. From the system research perspective, RING (1) optimizes time-ranged keyword query performance of a full-text search engine to improve the efficiency of monitoring anomaly evolution, (2) improves the dynamic graph processing performance of Spark and implements our graph stream model on it, As a result, RING is able to process big data to the entire Weibo or Twitter text stream with linear horizontal scalability. The system clearly presents its advantages over existing systems and methods from both the event monitoring perspective and the system perspective for the emerging event monitoring task.","Monitoring,
Real-time systems,
Big data,
Correlation,
Image edge detection,
Scalability,
Optimization"
Event Recognition for Contactless Activity Monitoring Using Phase-Modulated Continuous Wave Radar,"Objectives: The use of remote sensing technologies such as radar is gaining popularity as a technique for contactless detection of physiological signals and analysis of human motion. This paper presents a methodology for classifying different events in a collection of phase modulated continuous wave radar returns. The primary application of interest is to monitor inmates where the presence of human vital signs amidst different, interferences needs to be identified. Methods: A comprehensive set of features is derived through time and frequency domain analyses of the radar returns. The Bhattacharyya distance is used to preselect the features with highest class separability as the possible candidate features for use in the classification process. The uncorrelated linear discriminant analysis is performed to decorrelate, denoise, and reduce the dimension of the candidate feature set. Linear and quadratic Bayesian classifiers are designed to distinguish breathing, different human motions, and nonhuman motions. The performance of these classifiers is evaluated on a pilot dataset of radar returns that contained different events including breathing, stopped breathing, simple human motions, and movement of fan and water. Results: Our proposed pattern classification system achieved accuracies of up to 93% in stationary subject detection, 90% in stop-breathing detection, and 86% in interference detection. Conclusion: Our proposed radar pattern recognition system was able to accurately distinguish the predefined events amidst interferences. Significance: Besides inmate monitoring and suicide attempt detection, this paper can be extended to other radar applications such as home-based monitoring of elderly people, apnea detection, and home occupancy detection.","Monitoring,
Feature extraction,
Biomedical monitoring,
Radar detection,
Radar antennas,
Heart"
Rate-Energy Region of SWIPT for MIMO Broadcasting Under Nonlinear Energy Harvesting Model,"This paper explores the rate-energy (R-E) region of simultaneous wireless information and power transfer for MIMO broadcasting channel under the nonlinear radio frequency energy harvesting (EH) model. The goal is to characterize the tradeoff between the maximal energy transfer versus information rate. The separated EH and information decoding (ID) receivers and the co-located EH and ID receivers scenarios are considered. For the co-located receivers scenario, both time switching (TS) and power splitting (PS) receiver architectures are investigated. Optimization problems are formulated to derive the boundaries of the R-E region s for the considered systems. As the problems are nonconvex, we first transform them into equivalent ones and derive some semi-closed-form solutions, and then design efficient algorithms to solve them. Numerical results are provided to show the R-E region s of the systems, which provide some interesting insights. It is shown that all practical circuit specifications greatly affect the system R-E region. Compared with the systems under traditional linear EH model, the ones under the nonlinear EH model achieve smaller R-E region s due to the limitations of practical circuit features and also show very different R-E tradeoff behaviors.","Receivers,
Transmitters,
MIMO,
Integrated circuit modeling,
Wireless communication,
Broadcasting,
RF signals"
Enhanced Deployment Algorithms for Heterogeneous Directional Mobile Sensors in a Bounded Monitoring Area,"Good deployment of sensors empowers the network with effective monitoring ability. Different from omnidirectional sensors, the coverage region of a directional sensor is determined by not only the sensing radius (distance), but also its sensing orientation and spread angle. Heterogeneous sensing distances and spread angles are likely to exist among directional sensors, to which we refer as heterogeneous directional sensors. In this paper, we target on a bounded monitoring area and deal with heterogeneous directional sensors equipped with locomotion and rotation facilities to enable the sensors self-deployment. Two Enhanced Deployment Algorithms, EDA-I and EDA-II, are proposed to achieve high sensing coverage ratio in the monitored field. EDA-I leverages the concept of virtual forces (for sensors movements) and virtual boundary torques (for sensors rotations), whereas EDA-II combines Voronoi diagram directed movements and boundary torques guided rotations. EDA-I computations can be centralized or distributed that differ in required energy and execution time, whereas EDA-II only allows centralized calculations. Our EDA-II outperforms EDA-I in centralized operations, while EDA-I can be adapted into a distributed deployment algorithm without requiring global information and still achieves comparably good coverage performance to its centralized version. To the best of our knowledge, this is perhaps the first work to employ movements followed by rotations for sensors self-deployment. Performance results demonstrate that our enhanced deployment mechanisms are capable of providing desirable surveillance level, while consuming moderate moving and rotating energy under reasonable execution time.","Surveillance,
Cameras,
Visualization,
Mobile communication,
Temperature sensors"
Synteny Explorer: An Interactive Visualization Application for Teaching Genome Evolution,"Rapid advances in biology demand new tools for more active research dissemination and engaged teaching. This paper presents Synteny Explorer, an interactive visualization application designed to let college students explore genome evolution of mammalian species. The tool visualizes synteny blocks: segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct, ancestral species. We take a karyogram-based approach to create an interactive synteny visualization, leading to a more appealing and engaging design for undergraduate-level genome evolution education. For validation, we conduct three user studies: two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context. While existing views communicate the same information, study participants found the interactive, karyogram-based views much easier and likable to use. We additionally discuss feedback from biology and genomics faculty, who judge Synteny Explorer's fitness for use in classrooms.","Genomics,
Bioinformatics,
Biological cells,
Visualization,
Animals,
Vegetation,
Education"
A Novel Cache-Utilization-Based Dynamic Voltage-Frequency Scaling Mechanism for Reliability Enhancements,"We propose a cache architecture using a 7T/14T SRAM (Fujiwara et al., 2009) and a control mechanism for reliability enhancements. Our control mechanism differs from conventional dynamic voltage-frequency scaling (DVFS) methods in that it considers not only the cycles per instruction behaviors but also the cache utilization. To measure cache utilization, a novel metric is proposed. The experimental results show that our proposed method achieves 1000 times less bit-error occurrences compared with conventional DVFS methods under the ultralow-voltage operation. Moreover, the results indicate that our proposed method surprisingly not only incurs no performance and energy overheads but also achieves on average a 2.10% performance improvement and a 6.66% energy reduction compared with conventional DVFS methods.","Reliability,
SRAM cells,
Voltage control,
Computer architecture,
Switches,
Error correction codes"
Adaptive service management for cloud applications using overlay networks,"This paper presents an adaptive service management mechanism that maintains service level agreement through use of overlay networks that are deployed over the cloud provider network. The application autonomic manager strives to maintain the SLA without provisioning new resources for as long as possible. Through continuous monitoring and analysis, autonomic manager uses software defined networking (SDN) to dynamically apply policies to the flows of requests that travel through the application components. We implement and evaluate the proposed method on a hybrid cloud environment. Through extensive experiments, we show that the management mechanism can successfully maintain the SLA of services while it avoids provisioning extra resources which is the common approach in cloud.",
A Two-Time-Scale Neurodynamic Approach to Constrained Minimax Optimization,"This paper presents a two-time-scale neurodynamic approach to constrained minimax optimization using two coupled neural networks. One of the recurrent neural networks is used for minimizing the objective function and another is used for maximization. It is shown that the coupled neurodynamic systems operating in two different time scales work well for minimax optimization. The effectiveness and characteristics of the proposed approach are illustrated using several examples. Furthermore, the proposed approach is applied for H∞ model predictive control.","Optimization,
Neurodynamics,
Linear programming,
Mathematical model,
Recurrent neural networks,
Observers,
Learning systems"
HELOS: Heterogeneous Load Scheduling for Electric Vehicle-Integrated Microgrids,"With increasing concerns about worldwide environmental conditions and rapid development of renewable energy technologies, microgrids have been regarded as a promising solution to reduce the burden of infrastructure-based power systems. However, due to the intrinsically intermittent features of existing renewable energy, along with random residential behavior patterns, unpredictable plugged-in or unplugged actions of electric vehicles (EVs) and the time-varying price of electricity, it is challenging for microgrid operators to efficiently perform load scheduling and energy management. In this paper, we propose an online algorithm to conduct cost-aware scheduling of EV loads and energy supplies for microgrids. We formulate this problem into a stochastic optimization problem with the objective of minimizing the time-average cost of a microgrid, including the purchase cost of electricity from the main grid, the cost of charging and discharging batteries, renewable harvesting costs, and life-cycle greenhouse-gas emission costs. To solve this problem, the key idea is to exploit the dynamics of the price of electricity to conduct battery charging and discharging operations, renewable energy harvesting, and schedule EV loads properly. Our method is based on the Lyapunov optimization technique, which has low computational complexity and only requires limited prediction of price information. The theoretical analysis of our algorithm confirms that the proposed strategy can achieve optimality with explicit bound. By conducting extensive real-data driven simulations, we demonstrate that our proposed algorithm can achieve much lower cost and be more eco-friendly than other alternative solutions.",
Locating the Few: Sparsity-Aware Waveform Design for Active Radar,"Owing to the inherent sparsity of the target scene, compressed sensing (CS) has been successfully employed in radar applications. It is known that the performance of target scene recovery in CS scenarios depends highly on the coherence of the sensing matrix, which is determined by the radar transmit waveform. In this paper, we propose efficient transmit waveform optimization approaches for two different structures of the radar waveform, namely, the single-pulse and the more general pulse-train scenarios. By determining the identical coherence values associated with the sensing matrices of CS-based radars, the suggested methods provide a considerable reduction in the number of optimization variables. We show that, in the single-pulse scenario, fast Fourier transform operations can be used to improve the computation speed, whereas efficient power method-like iterations may be employed in the pulse-train scenarios. The effectiveness of the proposed algorithms is illustrated through several numerical examples.","Coherence,
Sensors,
Optimization,
Radar cross-sections,
Signal processing algorithms,
Algorithm design and analysis"
"Efficient and Privacy-Preserving Min and
k
th Min Computations in Mobile Sensing Systems","Protecting the privacy of mobile phone user participants is extremely important for mobile phone sensing applications. In this paper, we study how an aggregator can expeditiously compute the minimum value or the kth minimum value of all users' data without knowing them. We construct two secure protocols using probabilistic coding schemes and a cipher system that allows homomorphic bitwise XOR computations for our problems. Following the standard cryptographic security definition in the semi-honest model, we formally prove our protocols' security. The protocols proposed by us can support time-series data and need not to assume the aggregator is trusted. Moreover, different from existing protocols that are based on secure arithmetic sum computations, our protocols are based on secure bitwise XOR computations, thus are more efficient.","Protocols,
Sensors,
Ciphers,
Mobile communication,
Mobile handsets"
Embracing approximate computing for energy-efficient motion estimation in high efficiency video coding,"Approximate Computing is an emerging paradigm for developing highly energy-efficient computing systems. It leverages the inherent resilience of applications to trade output quality with energy efficiency. In this paper, we present a novel approximate architecture for energy-efficient motion estimation (ME) in high efficiency video coding (HEVC). We synthesized our designs for both ASIC and FPGA design flows. ModelSim gate-level simulations are used for functional and timing verification. We comprehensively analyze the impact of heterogeneous approximation modes on the power/energy-quality tradeoffs for various video sequences. To facilitate reproducible results for comparisons and further research and development, the RTL and behavioral models of approximate SAD architectures and constituting approximate modules are made available at https://sourceforge.net/projects/lpaclib/.","Approximate computing,
Adders,
Motion estimation,
Resilience,
Energy efficiency,
Computer architecture,
High efficiency video coding"
The Achievable Rate of Interweave Cognitive Radio in the Face of Sensing Errors,"Cognitive radio (CR) systems are potentially capable of mitigating the spectrum shortage of contemporary wireless systems. In this paper, we provide a brief overview of CR systems and the important research milestones of their evolution, along with their standardization activities, as a result of their research. This is followed by the detailed analysis of the interweave policy-based CR network (CRN) and by a detailed comparison with the family of underlay-based CRNs. In the interweave-based CRN, sensing of the primary user's (PU) spectrum by the secondary user's (SU) has remained a challenge, because the sensing errors prevent us from fulfilling the significant throughput gains that the concept of CR promises. Since missed detection and false alarm errors in real-time spectrum sensing cannot be avoided, based on a new approach, we quantify the achievable rates of the interweave CR by explicitly incorporating the effect of sensing errors. The link between the PU transmitter and the SU transmitter is assumed to be fast fading. Explicitly, the achievable rate degradation imposed by the sensing errors is analyzed for two spectrum sensing techniques, namely, for energy detection and for magnitude squared coherence-based detection. It is demonstrated that when the channel is sparsely occupied by the PU, the reusing techniques that are capable of simultaneously providing low missed detection and false alarm probabilities cause only a minor degradation to the achievable rates. Furthermore, based on the achievable rates derived for underlay CRNs, we compare the interweave CR and the underlay CR paradigms from the perspective of their resilience against spectrum sensing errors. Interestingly, in many practical regimes, the interweave CR paradigm outperforms the underlay CR paradigm in the presence of sensing errors, especially when the SNR at the SU is below 10 dB and when the SNR at the PU is in the range of 10-40 dB. Furthermore, we also provide rules of thumb that identify regimes, where the interweave CR outperforms the underlay CR.","Sensors,
Cognitive radio,
Radio transmitters,
Degradation,
Signal to noise ratio,
Noise measurement,
Wireless networks"
RWiN: New Methodology for the Development of Reconfigurable WSN,"This paper presents new challenges for the development of reconfigurable wireless sensor networks (RWSNs) that adapt dynamically their behaviors to their environment under different properties. An RWSN is a set of networked nodes that execute reconfigurable software tasks for the control of local sensors. We propose a new design methodology named RWiN of an RWSN using unified modeling language (UML) to analyze, construct, develop, and verify easily RWSN architectures. For that, we formulate a metamodel of RWSN based on UML to describe a zone-based architecture that uses a communication protocol for the optimization of distributed reconfigurations. To control the design complexity, we model each agent of this architecture by nested state machines. To verify the temporal constraints by communicating agents, each one is modeled by a timed automaton. The paper's contribution is applied to a case study, which is simulated with TRMSim-WSN and UPPAAL environment to expose the originality of this new architecture.","Wireless sensor networks,
Unified modeling language,
Sensors,
Software,
Computer architecture,
Hardware,
Protocols"
Toward a Wearable RFID System for Real-Time Activity Recognition Using Radio Patterns,"Elderly care is one of the many applications supported by real-time activity recognition systems. Traditional approaches use cameras, body sensor networks, or radio patterns from various sources for activity recognition. However, these approaches are limited due to ease-of-use, coverage, or privacy preserving issues. In this paper, we present a novel wearable Radio Frequency Identification (RFID) system aims at providing an easy-to-use solution with high detection coverage. Our system uses passive tags which are maintenance-free and can be embedded into the clothes to reduce the wearing and maintenance efforts. A small RFID reader is also worn on the user's body to extend the detection coverage as the user moves. We exploit RFID radio patterns and extract both spatial and temporal features to characterize various activities. We also address the issues of false negative of tag readings and tag/antenna calibration, and design a fast online recognition system. Antenna and tag selection is done automatically to explore the minimum number of devices required to achieve target accuracy. We develop a prototype system which consists of a wearable RFID system and a smartphone to demonstrate the working principles, and conduct experimental studies with four subjects over two weeks. The results show that our system achieves a high recognition accuracy of 93.6 percent with a latency of 5 seconds. Additionally, we show that the system only requires two antennas and four tagged body parts to achieve a high recognition accuracy of 85 percent.","Radiofrequency identification,
Senior citizens,
Real-time systems,
Maintenance engineering,
Feature extraction,
Antennas,
Monitoring"
A Wideband Dual Circularly Polarized Full-Corporate Waveguide Array Antenna Fed by Triple-Resonant Cavities,"A dual circularly polarized (CP) waveguide array antenna is presented for Ka-band wireless communication. A novel triple-resonant cavity is proposed to implement mode conversion and impedance matching in the 2 × 2-element subarray. A ridge waveguide polarizer is integrated to form the left-hand circular polarization (LHCP) and the right-hand circular polarization (RHCP). A flyover-shaped full-corporate feeding network is designed to accommodate the dual polarizations and keep the wideband characteristic for a large-scale array. Subarray spacing is used to optimize the port-to-port isolation and decrease the sidelobe level at some definite angles. Computer numerically controlled machining technology is applied to fabricating a 16×16-element prototype. Measured results demonstrate a bandwidth of 16% from 27.6 to 32.4 GHz for the dual polarizations, in terms of good reflection coefficient and axial ratio. A maximum gain of 32.8 dBic is achieved at 28.8 GHz. A total efficiency over 60% is obtained throughout the above band for both LHCP and RHCP ports.",
A Cooperative Quality-aware Service Access System for Social Internet of Vehicles,"Due to the enormous potential to guarantee road safety and improve driving experience, Social Internet of Vehicle (SIoV) is becoming a hot research topic in both academic and industrial circles. As the ever-increasing variety, quantity and intelligence of on-board equipment, along with the ever-growing demand for service quality of automobiles, the way to provide users with a range of security-related and user-oriented vehicular applications has become significant. This paper concentrates on the design of a service access system in SIoVs, which focuses on a reliability assurance strategy and quality optimization method. First, due to the instability of vehicular devices, a dynamic access service evaluation scheme is investigated, which explores the potential relevance of vehicles by constructing their social relationships. Next, this work studies a trajectory-based interaction time prediction algorithm to cope with an unstable network topology and high rate of disconnection in SIoVs. At last, a cooperative quality-aware system model is proposed for service access in SIoVs. Simulation results demonstrate the effectiveness of the proposed scheme.","Routing,
Roads,
Security,
Network topology,
Routing protocols,
Vehicle dynamics,
Bandwidth"
Highly Efficient Implementation for Parameter Error Identification Method Exploiting Sparsity,"Accuracy of the network parameters has a strong influence on the results of power system state estimation. It has been shown earlier that normalized Lagrange multipliers can be used as a systematic way for identifying errors in network parameters. However, this approach carries a rather heavy computational burden limiting its practical utilization to small-size systems. In this paper, a computationally efficient algorithm is proposed to address this limitation. The idea is to derive and compute only the necessary subset of the gain matrix and covariance matrix, thus avoiding the computation and storage of large dense matrices. The proposed efficient procedure can be applied either to the single-scan or multiple-scan schemes with equal ease. Test results confirm that the improvements in computational speed and memory requirements brought by the proposed algorithm are quite remarkable. The proposed implementation of the normalized Lagrange multipliers method is tested using a large utility power system. The effectiveness and limitations of the single-scan scheme, and the improvements brought by incorporating multiple measurement scans, are discussed in detail.",
Decentralised system architecture for autonomous and cooperative M2M application service provision,"This publication presents a novel concept for autonomous and decentralised M2M application service provision. The functional architecture of the approach is introduced as well as a detailed description of the system structure and process for application creation. Furthermore, this publication describes details about the proposed process for decentralised M2M application service management and formal description of M2M application services.","Machine-to-machine communications,
Unified modeling language,
Computer architecture,
Overlay networks,
Software,
Protocols,
Business"
SLoT: A supervised learning model to predict dynamic timing errors of functional units,"Dynamic timing errors (DTEs), that are caused by the timing violations of sensitized critical timing paths, have emerged as an important threat to the reliability of digital circuits. Existing approaches model the DTEs without considering the impact of input operands on dynamic path sensitization, resulting in loss of accuracy. The diversity of input operands leads to complex path sensitization behaviors, making it hard to represent in DTE modeling. In this paper, we propose SLoT, a supervised learning model to predict the output of functional units (FUs) to be one of two timing classes: {timing correct, timing erroneous} as a function of input operands and clock period. We apply random forest classification (RFC) method to construct SLoT, by using input operands, computation history and circuit toggling as input features and outputs' timing classes as labels. The outputs' timing classes are measured using gate-level simulation (GLS) of a post place-and-route design in TSMC 45nm process. For evaluation, we apply SLoT to several FUs and on average 95% predictions are consistent with GLS, which is 6.3X higher compared to the existing instruction-level model. SLoT-based reliability analysis of FUs under different datasets can achieve 0.7-4.8% average difference compared with GLS-based analysis, and execute more than 20X faster than GLS.",
Two-Stage Multiple Access for Many Devices of Unique Identifications Over Frequency-Selective Fading Channels,"In this paper, we consider sparse index multiple access for uplink random access in a wireless system of a number of devices when a fraction of them are active. This multiple access scheme is suitable for the case that an access point (AP) needs not only to receive data symbols, but also to identify active devices when there are a number of devices with unique identification sequences (the number of devices can be easily more than a million) with low signaling/control overhead. We propose a two-stage transmission scheme for random access and derive computationally efficient methods to estimate the channel state information (CSI) of active devices over frequency-selective fading channels in the first stage and to perform joint active device identification and data detection in the second stage using a well-known sparse signal estimation method in compressive sensing. Simulation results demonstrate that the proposed approach can successfully estimate the CSI of active devices under reasonable conditions and identify the unique identification sequences or vectors of active devices with a high probability. For example, when 6 out of 64 devices become active, the AP can identify all six devices (using estimated CSI) with a probability higher than 1 - 10-2 over frequency-selective fading channels.",
A Survey of Enabling Technologies of Low Power and Long Range Machine-to-Machine Communications,"Low power and long range machine-to-machine (M2M) communication techniques are expected to provide ubiquitous connections for the wireless devices. In this paper, three major low power and long range M2M solutions are surveyed. The first type of solutions is referred to as the low power wide area (LPWA) network. The design of the LPWA techniques features low cost, low data rate, long communication range, and low power consumption. The second type of solutions is the IEEE 802.11ah which features higher data rates using a wider bandwidth than the LPWA-based solutions. The third type of solutions is operated under the cellular network infrastructure. Based on the analysis of the pros and cons of the enabling technologies of the surveyed M2M solutions, as well as the corresponding deployment strategies, the gaps in knowledge are identified. The paper also presents a summary of the research directions for improving the performance of the surveyed low power and long range M2M communication technologies.",
Demystifying the Clouds: Harnessing Resource Utilization Models for Cost Effective Infrastructure Alternatives,"Deployment of service oriented applications (SOAs) to public infrastructure-as-a-service (IaaS) clouds presents challenges to system analysts. Public clouds offer an increasing array of virtual machine types with qualitatively defined CPU, disk, and network I/O capabilities. Determining cost effective application deployments requires selecting both the quantity and type of virtual machine (VM) resources for hosting SOA workloads of interest. Hosting decisions must utilize sufficient infrastructure to meet service level objectives and cope with service demand. To support these decisions, analysts must: (1) understand how their SOA behaves in the cloud; (2) quantify representative workload(s) for execution; and (3) support service level objectives regardless of the performance limits of the hosting infrastructure. In this paper we introduce a workload cost prediction methodology which harnesses operating system time accounting principles to support equivalent SOA workload performance using alternate virtual machine types. We demonstrate how the use of resource utilization checkpointing supports capturing the total resource utilization profile for SOA workloads executed across a pool of VMs. Given these workload profiles, we develop and evaluate our cost prediction methodology using six SOAs. We demonstrate how our methodology can support finding alternate infrastructures that afford lower hosting costs while offering equal or better performance using any VM type on Amazon's public elastic compute cloud.",
Kira: Processing Astronomy Imagery Using Big Data Technology,"Scientific analyses commonly compose multiple single-process programs into a dataflow. An end-to-end dataflow of single-process programs is known as a many-task application. Typically, HPC tools are used to parallelize these analyses. In this work, we investigate an alternate approach that uses Apache Spark—a modern platform for data intensive computing—to parallelize many-task applications. We implement Kira, a flexible and distributed astronomy image processing toolkit, and its Source Extractor (Kira SE) application. Using Kira SE as a case study, we examine the programming flexibility, dataflow richness, scheduling capacity and performance of Apache Spark running on the Amazon EC2 cloud. By exploiting data locality, Kira SE achieves a 4.1 speedup over an equivalent C program when analyzing a 1TB dataset using 512 cores on the Amazon EC2 cloud. Furthermore, Kira SE on the Amazon EC2 cloud achieves a 1.8 speedup over the C program on the NERSC Edison supercomputer. A 128-core Amazon EC2 cloud deployment of Kira SE using Spark Streaming can achieve a second-scale latency with a sustained throughput of 800 MB/s. Our experience with Kira demonstrates that data intensive computing platforms like Apache Spark are a performant alternative for many-task scientific applications.",
Multimodal Imaging Based on Digital Holography,"Digital holography provides a method of the 3-D recording and numerical reconstruction by a simple optical system and a computer. Quantitative measurement and numerical refocusing are major characteristics. So far, many physical parameters such as amplitude, phase, polarization, fluorescence, and spectra can be obtained independently. Recently, multimodal imaging that can obtain simultaneously two or more physical parameters by combining digital holographic microscope and other optical microscopes such as a fluorescence optical microscope and a Raman scattering microscope has emerged. In this review, physical parametric imaging techniques based on digital holography are presented and then these techniques are enhanced to develop multimodal imaging based on digital holography.",
Learning to Predict High-Quality Edge Maps for Room Layout Estimation,"The goal of room layout estimation is to predict the three-dimensional box that represents the room spatial structure from a monocular image. In this paper, a deconvolution network is trained first to predict the edge map of a room image. Compared to the previous fully convolutional networks, the proposed deconvolution network has a multilayer deconvolution process that can refine the edge map estimate layer by layer. The deconvolution network also has fully connected layers to aggregate the information of every region throughout the entire image. During the layout generation process, an adaptive sampling strategy is introduced based on the obtained high-quality edge maps. Experimental results prove that the learned edge maps are highly reliable and can produce accurate layouts of room images.",
Estimating Renyi Entropy of Discrete Distributions,"It was shown recently that estimating the Shannon entropy H(p) of a discrete k-symbol distribution p requires Θ(k/log k) samples, a number that grows near-linearly in the support size. In many applications, H(p) can be replaced by the more general Rényi entropy of order α and Hα(p). We determine the number of samples needed to estimate Hα(p) for all α, showing that α <; 1 requires a super-linear, roughly k1/α samples, noninteger α > 1 requires a near-linear k samples, but, perhaps surprisingly, integer α > 1 requires only Θ(k1-1/α) samples. Furthermore, developing on a recently established connection between polynomial approximation and estimation of additive functions of the form Σx f (px), we reduce the sample complexity for noninteger values of α by a factor of log k compared with the empirical estimator. The estimators achieving these bounds are simple and run in time linear in the number of samples. Our lower bounds provide explicit constructions of distributions with different Rényi entropies that are hard to distinguish.","Entropy,
Complexity theory,
Additives,
Upper bound,
Estimation,
Electronic mail,
Genetics"
Cognitive Load Measurement in a Virtual Reality-Based Driving System for Autism Intervention,"Autism Spectrum Disorder (ASD) is a highly prevalent neurodevelopmental disorder with enormous individual and social cost. In this paper, a novel virtual reality (VR)-based driving system was introduced to teach driving skills to adolescents with ASD. This driving system is capable of gathering eye gaze, electroencephalography, and peripheral physiology data in addition to driving performance data. The objective of this paper is to fuse multimodal information to measure cognitive load during driving such that driving tasks can be individualized for optimal skill learning. Individualization of ASD intervention is an important criterion due to the spectrum nature of the disorder. Twenty adolescents with ASD participated in our study and the data collected were used for systematic feature extraction and classification of cognitive loads based on five well-known machine learning methods. Subsequently, three information fusion schemes-feature level fusion, decision level fusion and hybrid level fusion-were explored. Results indicate that multimodal information fusion can be used to measure cognitive load with high accuracy. Such a mechanism is essential since it will allow individualization of driving skill training based on cognitive load, which will facilitate acceptance of this driving system for clinical use and eventual commercialization.","Variable speed drives,
Physiology,
Electroencephalography,
Autism,
Training,
Vehicles,
Intelligent systems"
Energy-Efficient Web Server Load Balancing,"Rising energy costs and negative environmental impact resulting from the generation of electricity, particularly when relying on fossil fuels, increase the need for energy-efficient computing. In addition to the optimization of hardware devices, the use of sophisticated software solutions for reducing energy consumption is an important area of current research. Distributing the load among servers for performance optimization is a well-researched area. There is a large potential to reduce energy consumption with similar techniques. In this paper, we examine the application of energy-efficient load-balancing (or unbalancing) strategies for web server requests sent to a web server farm. Single requests usually lead to small fractions of performance need. They are quite suited for strategies relying on the assumption of a fully divisible load. We show that we are able to reduce the power consumption continuously for replays of Wikipedia access traces. Eventually, we are able to reduce the energy consumption in web server farms, significantly.",
Fingerprint Recognition of Young Children,"In 1899, Galton first captured ink-on-paper fingerprints of a single child from birth until the age of 4.5 years, manually compared the prints, and concluded that “the print of a child at the age of 2.5 years would serve to identify him ever after.” Since then, ink-on-paper fingerprinting and manual comparison methods have been superseded by digital capture and automatic fingerprint comparison techniques, but only a few feasibility studies on child fingerprint recognition have been conducted. Here, we present the first systematic and rigorous longitudinal study that addresses the following questions: (1) Do fingerprints of young children possess the salient features required to uniquely recognize a child? (2) If so, at what age can a child's fingerprints be captured with sufficient fidelity for recognition? (3) Can a child's fingerprints be used to reliably recognize the child as he ages? For this paper, we collected fingerprints of 309 children (0-5 years old) four different times over a one year period. We show, for the first time, that fingerprints acquired from a child as young as 6-h old exhibit distinguishing features necessary for recognition, and that state-of-the-art fingerprint technology achieves high recognition accuracy (98.9% true accept rate at 0.1% false accept rate) for children older than six months. In addition, we use mixed-effects statistical models to study the persistence of child fingerprint recognition accuracy and show that the recognition accuracy is not significantly affected over the one year time lapse in our data. Given rapidly growing requirements to recognize children for vaccination tracking, delivery of supplementary food, and national identification documents, this paper demonstrates that fingerprint recognition of young children (six months and older) is a viable solution based on available capture and recognition technology.",
Three-Dimensional End-to-End Modeling and Analysis for Graphene-Enabled Terahertz Band Communications,"Terahertz (0.1-10 THz) band communication is envisioned as a key technology to satisfy the increasing demand for ultra-high-speed wireless links. In this paper, a 3-D end-to-end model in the THz band is developed that includes the graphenebased reflectarray antenna response and the 3-D multipath propagation phenomena. In particular, the architecture of a graphenebased reflectarray antenna is investigated, and the 3-D radiation pattern is modeled. Moreover, a 3-D THz channel model based on ray tracing techniques is developed as a superposition of the line-of-sight (LoS), reflected, and scattered paths. By using the developed end-to-end model, an in-depth analysis on the 3-D channel characteristics is carried out. Specifically, the gain at the main beam of the graphene-based reflectarray antenna is 18 dB, and the 3-dB beamwidths in the elevation and the azimuth planes are 7° and 10°, respectively. The use of the reflectarray leads to a decrease of the delay spread from 1.23 to 0.099 ns, which suggests that the resulting coherence bandwidth reaches 2 GHz. Moreover, the root mean square (rms) angular spread in the elevation plane is less than 0.12°, which is one tenth of that without beamforming. Furthermore, the wideband channel capacity at THz frequencies is characterized, which can be enhanced with a larger transmit power, a lower operating frequency, a larger bandwidth, and a higher beamforming gain. Finally, the beamforming gain enabled by the reflectarray antenna is compromised at the cost of the strict beam alignment, and the deviation needs to be smaller than 11°. The provided analysis and the channel physical parameters lay out the foundation and are particularly useful for realizing reliable and efficient ultra-high-speed wireless communications in the THz band.","Antenna radiation patterns,
Solid modeling,
Wireless communication,
Graphene,
Channel models,
Conductivity"
Sparse Multigraph Embedding for Multimodal Feature Representation,"Data fusion is used to integrate features from heterogeneous data sources into a consistent and accurate representation for certain learning tasks. As an effective technique for data fusion, unsupervised multimodal feature representation aims to learn discriminative features, indicating the improvement of classification and clustering performance of learning algorithms. However, it is a challenging issue since varying modality favors different structural learning. In this paper, we propose an efficient feature learning method to represent multimodal images as a sparse multigraph structure embedding problem. First, an effective algorithm is proposed to learn a sparse multigraph construction from multimodal data, where each modality corresponds to one regularized graph structure. Second, incorporating the learned multigraph structure, the feature learning problem for multimodal images is formulated as a form of matrix factorization. An efficient corresponding algorithm is developed to optimize the problem and its convergence is also proved. Finally, the proposed method is compared with several state-of-the-art single-modal and multimodal feature learning techniques in eight publicly available face image datasets. Comprehensive experimental results demonstrate that the proposed method outperforms the existing ones in terms of clustering performance for all tested datasets.","Optimization,
Clustering algorithms,
Sparse matrices,
Data integration,
Correlation,
Feature extraction,
Learning systems"
Stability of Positive Switched Linear Systems: Weak Excitation and Robustness to Time-Varying Delay,"This article investigates the stability of positive switched linear systems. We start from motivating examples and focus on the case when each switched subsystem is marginally stable (in the sense that all the eigenvalues of the subsystem matrix are in the closed left-half plane with those on the imaginary axis simple) instead of asymptotically stable. A weak excitation condition is first proposed such that the considered positive switched linear system is exponentially stable. An extension to the case without dwell time assumption is also presented. Then, we study the influence of time-varying delay on the stability of the considered positive switched linear system. We show that the proposed weak excitation condition for the delay-free case is also sufficient for the asymptotic stability of the positive switched linear system under unbounded time-varying delay. In addition, it is shown that the convergence rate is exponential if there exists an upper bound for the delay, irrespective of the magnitude of this bound. The motivating examples are revisited to illustrate the theoretical results.","Switches,
Delays,
Linear systems,
Stability analysis,
Asymptotic stability,
Vehicles,
Time-varying systems"
Magnetic MIMO Signal Processing and Optimization for Wireless Power Transfer,"In magnetic resonant coupling (MRC) enabled multiple-input multiple-output (MIMO) wireless power transfer (WPT) systems, multiple transmitters (TXs) are used to enhance the efficiency of simultaneous power transfer to multiple receivers (RXs) by constructively combining their induced magnetic fields, a technique termed “magnetic beamforming”. In this paper, we study the optimal magnetic beamforming design in a multiuser MIMO MRC-WPT system. We introduce and characterize the multiuser power region, which constitutes all the achievable power tuples for all RXs, subject to the given total power constraint over all TXs as well as their individual peak voltage and current constraints. For the special case without TX peak voltage and current constraints, we derive the optimal TX current allocation for the single-RX setup in closed-form and that for the multi-RX setup by applying the techniques of semidefinite relaxation (SDR) and time-sharing. In general, the problem is a nonconvex quadratically constrained quadratic programming (QCQP), which is difficult to solve. For the case of one single RX, we show that the SDR of the problem is tight and thus solve the problem efficiently. For the general case with multiple RXs, based on SDR we obtain two approximate solutions by applying the techniques of time-sharing and randomization, respectively. Moreover, we propose a new method to estimate the magnetic MIMO channel between TXs and RXs for practical implementation of magnetic beamforming. Numerical results show that our proposed magnetic channel estimation and adaptive beamforming schemes are practically effective and can significantly improve the power transfer efficiency and multiuser performance tradeoff in MIMO MRC-WPT systems compared with the benchmark scheme of uncoordinated WPT with fixed identical TXs' current.","MIMO,
Magnetic resonance,
Array signal processing,
Channel estimation,
Wireless communication,
Optimization,
Resistance"
Effects of Total-Ionizing-Dose Irradiation on SEU- and SET-Induced Soft Errors in Bulk 40-nm Sequential Circuits,"Synergetic effects of total-ionizing-dose irradiation on the single event upset (SEU) and single event transient (SET) performance of 40-nm sequential circuits are studied at doses up to 2 Mrad(SiO2). The impacts of input pattern and supply voltage are evaluated. An initial increase of SEU- and SET-induced soft error cross-section versus total dose is observed, followed by a decreasing trend at higher doses. The maximum increase of SEU- and SET-induced soft error cross-section occurs when the total-ionizing-dose is approximately 1.5 Mrad(SiO2) in the studied sequential circuit. The SET-induced soft error cross-section versus total dose increases at a faster speed than the SEU-induced soft error cross-section.","Leakage currents,
Radiation effects,
Voltage measurement,
Current measurement,
Integrated circuits,
Single event upsets,
Logic gates"
Ranking Vectors by Means of the Dominance Degree Matrix,"In multi-/many-objective evolutionary algorithms (MOEAs), there are varieties of vector ranking schemes, including nondominated sorting, dominance counting, and so on. Usually, these vector ranking schemes in the classical MOEAs are of high computational complexity. Thus, in recent years, many researchers put emphasis on the further improvement of the computational complexity of the vector ranking schemes. In this paper, we propose the dominance degree matrix for a set of vectors and design a fast method to construct this new data structure, which requires O(mNlog N) comparisons on average. The dominance degree matrix is constructed based on the properties of Pareto domination, and it can convert the dominance comparison into counting the number of special element pairs. Based on the dominance degree matrix, we develop a new and efficient implementation of nondominated sorting called dominance degree approach for nondominated sorting (DDA-NS), which has an average time complexity of O(mN2) but only requires O(mNlog N) objective function value comparisons on average. Empirical results demonstrate that DDA-NS clearly outperforms six other representative approaches for nondominated sorting in most cases and DDA-NS performs well when dealing with large-size and many-objective populations. In addition, we also use the dominance degree matrix to form a new method for calculating the dominance strength for Strength Pareto Evolutionary Algorithm (SPEA)2, which greatly improves the efficiency of the naive calculation method in SPEA2. Experiments on benchmark problems show that the Nondominated Sorting Genetic Algorithm (NSGA)-II and NSGAIII framework embedding DDA-NS and the SPEA2 framework embedding the new method of calculating the dominance strength indeed achieve the improvement of the runtime.","Sorting,
Matrix converters,
Time complexity,
Sociology,
Statistics,
Linear programming"
A Unified Continuous and Discrete Model for Double-Gate MOSFETs With Spatially Varying or Pulsed Doping Profiles,"This paper presents a unified continuous and discrete model covering all device operating regions of double-gate MOSFETs for the first time. With a specific variable transformation method, the 1-D Poisson's equation in the Cartesian coordinate for double-gate MOSFETs is transformed into the corresponding form in the cylindrical coordinate. Such a transformed cylindrical Poisson's equation results in a simple algebraic equation, which correlates the (inversion-charge induced) surface potential to the field and allows the long-channel drain-current formula to be derived from the Pao-Sah integral. This model can be readily applied to predict the effects of both continuous and discrete doping variations. The short-channel-effect model is also developed by solving the 2-D Poisson's equation using the eigenfunction-expansion method. The accuracy of both long-channel and short-channel models is confirmed by the numerical calculations and TCAD simulations.","Mathematical model,
MOSFET,
Semiconductor device modeling,
Semiconductor process modeling,
Doping profiles"
Distributed Algorithms for Computation of Centrality Measures in Complex Networks,"This paper is concerned with distributed computation of several commonly used centrality measures in complex networks. In particular, we propose deterministic algorithms, which converge in finite time, for the distributed computation of the degree, closeness and betweenness centrality measures in directed graphs. Regarding eigenvector centrality, we consider the PageRank problem as its typical variant, and design distributed randomized algorithms to compute PageRank for both fixed and time-varying graphs. A key feature of the proposed algorithms is that they do not require to know the network size, which can be simultaneously estimated at every node, and that they are clock-free. To address the PageRank problem of time-varying graphs, we introduce the concept of persistent graph, which eliminates the effect of spamming nodes. Moreover, we prove that these algorithms converge almost surely and in the sense of L^p. Finally, the effectiveness of the proposed algorithms is illustrated via extensive simulations using a classical benchmark.","Algorithm design and analysis,
Convergence,
Distributed algorithms,
Complex networks,
Unsolicited electronic mail,
Internet,
Atmospheric measurements"
"Securing digital identities in the cloud by selecting an apposite Federated Identity Management from SAML, OAuth and OpenID Connect","Access to computer systems and the information held on them, be it commercially or personally sensitive, is naturally, strictly controlled by both legal and technical security measures. One such method is digital identity, which is used to authenticate and authorize users to provide access to IT infrastructure to perform official, financial or sensitive operations within organisations. However, transmitting and sharing this sensitive information with other organisations over insecure channels always poses a significant security and privacy risk. An example of an effective solution to this problem is the Federated Identity Management (FIdM) standard adopted in the cloud environment. The FIdM standard is used to authenticate and authorize users across multiple organisations to obtain access to their networks and resources without transmitting sensitive information to other organisations. Using the same authentication and authorization details among multiple organisations in one federated group, it protects the identities and credentials of users in the group. This protection is a balance, mitigating security risk whilst maintaining a positive experience for users. Three of the most popular FIdM standards are Security Assertion Markup Language (SAML), Open Authentication (OAuth), and OpenID Connect (OIDC). This paper presents an assessment of these standards considering their architectural design, working, security strength and security vulnerability, to cognise and ascertain effective usages to protect digital identities and credentials. Firstly, it explains the architectural design and working of these standards. Secondly, it proposes several assessment criteria and compares functionalities of these standards based on the proposed criteria. Finally, it presents a comprehensive analysis of their security vulnerabilities to aid in selecting an apposite FIdM. This analysis of security vulnerabilities is of great significance because their improper or erroneous deployment may be exploited for attacks.","Standards,
Authorization,
Authentication,
Servers,
Protocols,
Markup languages"
MIP Reformulation for Max-Min Problems in Two-Stage Robust SCUC,"With increasing renewable penetration in power systems, considerable research efforts have been focused on how to accommodate the uncertainties from renewables in the Security-Constraint Unit Commitment (SCUC) problem. One of the candidate approaches to handling uncertainties is the two-stage Robust SCUC (RSCUC), which enables system to survive in any scenario. The survivability is guaranteed by the solution optimality of the max-min problem in the second stage. However, as the non-convex max-min problem is NP-hard, it is difficult to get the exact optimal solution in acceptable time. In this paper, we propose a new efficient formulation which recasts the max-min problem to a Mixed Integer Programming (MIP) problem using Binary Expansion (BE). The upper bound of the gap between the new MIP problem and the original max-min problem is derived. The gap, which quantifies the solution optimality of the max-min problem, is controllable. Two effective acceleration techniques are proposed to improve the performance of the MIP problem by eliminating inactive flow constraints and decomposing time-coupled uncertainty budget constraints. Accordingly, the computation burden of solving the max-min problem is reduced tremendously. The simulation results for the IEEE 118-Bus system validate and demonstrate the effectiveness of the new BE-based solution approach to the two-stage RSCUC and the acceleration techniques.","Uncertainty,
Robustness,
Linear programming,
Acceleration,
Upper bound,
Optimization,
Power systems"
Energy-Efficient Reduce-and-Rank Using Input-Adaptive Approximations,"Approximate computing is an emerging design paradigm that exploits the intrinsic ability of applications to produce acceptable outputs even when their computations are executed approximately. In this paper, we explore approximate computing for a key computation pattern, reduce-andrank (RnR), which is prevalent in a wide range of workloads, including video processing, recognition, search, and data mining. An RnR kernel performs a reduction operation (e.g., distance computation, dot product, and L1-norm) between an input vector and each of a set of reference vectors, and ranks the reduction outputs to select the top reference vectors for the current input. We propose three complementary approximation strategies for the RnR computation pattern. The first is interleaved reductionand-ranking, wherein the vector reductions are decomposed into multiple partial reductions and interleaved with the rank computation. Leveraging this transformation, we propose the use of intermediate reduction results and ranks to identify future computations that are likely to have a low impact on the output, and can, hence, be approximated. The second strategy, inputsimilarity-based approximation, exploits the spatial or temporal correlation of inputs (e.g., pixels of an image or frames of a video) to identify computations that are amenable to approximation. The third strategy, reference vector reordering, rearranges the order in which the reference vectors are processed such that vectors that are relatively more critical in evaluating the correct output, are processed at the beginning of RnR operation. The number of these critical reference vectors is usually small, which renders a substantial portion of the total computation to be amenable to approximation. These strategies address a key challenge in approximate computing-identification of which computations to approximate-and may be used to drive any approximation mechanism, such as computation skipping or precision scaling to realize performance and energy improvements. A second key challenge in approximate computing is that the extent to which computations can be approximated varies significantly from application to application, and across inputs for even a single application. Hence, input-adaptive approximation, or the ability to automatically modulate the degree of approximation based on the nature of each individual input, is essential for obtaining optimal energy savings. In addition, to enable quality configurability in RnR kernels, we propose a kernel-level quality metric that correlates well to application-level quality, and identify key parameters that can be used to tune the proposed approximation strategies dynamically. We develop a runtime framework that modulates the identified parameters during the execution of RnR kernels to minimize their energy while meeting a given target quality. To evaluate the proposed concepts, we designed quality-configurable hardware implementations of six RnR-based applications from the recognition, mining, search, and video processing application domains in 45-nm technology. Our experiments demonstrate a 1.13×-3.18× reduction in energy consumption with virtually no loss in output quality (<;0.5%) at the application level. The energy benefits further improve up to 3.43× and 3.9× when the quality constraints are relaxed to 2.5% and 5%, respectively.",
Network-Assisted Outband D2D-Clustering in 5G Cellular Networks: Theory and Practice,"We introduce a channel-opportunistic architecture that enhances the user experience in terms of throughput, fairness, and energy efficiency. Our proposed architecture leverages D2D communication and it is built on top of the forthcoming D2D features of 5G networks. In particular, we focus on outband D2D where cellular users are allowed to exploit both cellular (i.e., LTE-A) and WLAN (i.e., WiFi Direct) technologies to establish a D2D connection. In this architecture, cellular users form clusters, in which only the user with the best channel condition communicates with the base station on behalf of the entire cluster. Within the cluster, the unlicensed spectrum is utilized to relay traffic. In this article, we provide analytical models for the proposed system and study the impact of several payoff distribution methods commonly adopted in the literature on coalitional game theory. We then introduce an operator-controlled relay protocol based on the D2D features of LTE-A and WiFi Direct, and demonstrate the feasibility and the advantages of D2D-assisted cellular communication with our SDR prototype.","Device-to-device communication,
Throughput,
Proposals,
Signal to noise ratio,
IEEE 802.11 Standard,
5G mobile communication,
Relays"
Lyapunov Estimator for High-Speed Demodulation in Dynamic Mode Atomic Force Microscopy,"In dynamic mode atomic force microscopy (AFM), the imaging bandwidth is governed by the slowest component in the open-loop chain consisting of the vertical actuator, cantilever, and demodulator. While the common demodulation method is to use a lock-in amplifier (LIA), its performance is ultimately bounded by the bandwidth of the postmixing low-pass filters. This brief proposes an amplitude and phase estimation method based on a strictly positive real Lyapunov design approach. The estimator is designed to be of low complexity while allowing for high bandwidth. In addition, suitable gains for high performance are suggested such that no tuning is necessary. The Lyapunov estimator is experimentally implemented for amplitude demodulation and shown to surpass the LIA in terms of tracking bandwidth and noise performance. High-speed AFM images are presented to corroborate the results.","Convergence,
Demodulation,
Bandwidth,
Kalman filters,
Transfer functions,
Dynamics,
Force"
Enhancing Security and Privacy for Identity-Based Batch Verification Scheme in VANETs,"Vehicular ad hoc networks (VANETs) can significantly improve traffic safety and efficiency. The basic idea is to allow vehicles to send traffic information to roadside units (RSUs) or other vehicles. Vehicles have to be prevented from some attacks on their privacy and misuse of their private data. For this reason, security and privacy preservation issues are important prerequisites for VANETs. The identity-based batch verification (IBV) scheme has been recently proposed to make VANETs more secure and efficient for practical use. In this paper, we point out that the current IBV scheme has some security risks. We introduce an improved scheme that can satisfy the security and privacy desired by vehicles. The proposed IBV scheme provides the provable security in the random oracle model. In addition, the batch verification of the proposed scheme needs only a small constant number of pairing and point multiplication computations, independent of the number of messages. We show the efficiency advantages of the proposed scheme through performance evaluations in terms of computation delay and transmission overhead. Moreover, the extensive simulation is conducted to verify the efficiency and applicability of the proposed scheme in the real-world road environment and vehicular traffic.","Vehicles,
Privacy,
Vehicular ad hoc networks,
Public key,
Mathematical model,
Delays"
R-TTWD: Robust Device-Free Through-The-Wall Detection of Moving Human With WiFi,"Due to rapid developments of smart devices and mobile applications, there is an urgent need for a new human-in-the-loop architecture with better system efficiency and user experience. Compared with conventional device-based human-computer interactive (HCI) methods, device-free technology with WiFi provides a new HCI method and is promising for providing better user-perceived quality-of-experience. Being essential for device-free applications, device-free human detection has gained increasing interest, of which through-the-wall (TTW) human detection is of great challenge. Existing TTW detection systems either rely on massive deployment of transceivers or require specialized WiFi monitors, making them inapplicable for real-world applications. Recently, more and more researchers have tapped into the physical layer for more robust and reliable human detection, ever since channel state information (CSI) can be exported with commodity devices. Despite great progress achieved, there have been few works studying TTW detection. In this paper, we propose a novel scheme for robust device-free TTW detection (R-TTWD) of a moving human with commodity devices. Different from the time dimension-based features exploited in the previous works, R-TTWD takes advantage of the correlated changes over different subcarriers and extracts the first-order difference of eigenvector of CSI across different subcarriers for TTW human detection. Instead of direct feature extraction, we first perform a PCA-based filtering on the preprocessed data, since a simple low-pass filtering is insufficient for noise removal. Furthermore, the detection results across different transmit-receive antenna pairs are fused with a majority-vote-based scheme for more robust and accurate detection. We prototype R-TTWD on commodity WiFi devices and evaluate its performance both in different environments and over long test period, validating the robustness of R-TTWD with both detection rates for moving human and human absence over 99% regardless of different wall materials, dynamic moving speeds, and so on.","Robustness,
Wireless fidelity,
Feature extraction,
Performance evaluation,
Wireless communication,
Wireless sensor networks,
Sensors"
WCE Abnormality Detection Based on Saliency and Adaptive Locality-Constrained Linear Coding,"Wireless capsule endoscopy (WCE) has become a widely used diagnostic technique for the digestive tract, at the price of a large volume of data that needs to be analyzed. To tackle this problem, a new computer-aided system using novel features is proposed in this paper to classify WCE images automatically. In the feature learning stage, to obtain the representative visual words, we first calculate the color scale invariant feature transform from the bleeding, polyp, ulcer, and normal WCE image samples separately and then apply K -means clustering on these features to obtain visual words. These four types of visual words are combined together to composite the representative visual words for classifying the WCE images. In the feature coding stage, we propose a novel saliency and adaptive locality-constrained linear coding (SALLC) algorithm to encode the images. The SALLC encodes patch features based on adaptive coding bases, which are calculated by the distance differences among the features and the visual words. Moreover, it imposes the patch saliency constraint on the feature coding process to emphasize the important information in the images. The experimental results exhibit a promising overall recognition accuracy of 88.61%, validating the effectiveness of the proposed method.","Encoding,
Feature extraction,
Visualization,
Image coding,
Image reconstruction,
Hemorrhaging,
Image color analysis"
STPP: Spatial-Temporal Phase Profiling-Based Method for Relative RFID Tag Localization,"Many object localization applications need the relative locations of a set of objects as oppose to their absolute locations. Although many schemes for object localization using radio frequency identification (RFID) tags have been proposed, they mostly focus on absolute object localization and are not suitable for relative object localization because of large error margins and the special hardware that they require. In this paper, we propose an approach called spatial-temporal phase profiling (STPP) to RFID-based relative object localization. The basic idea of STPP is that by moving a reader over a set of tags during which the reader continuously interrogating the tags, for each tag, the reader obtains a sequence of RF phase values, which we call a phase profile, from the tag's responses over time. By analyzing the spatial-temporal dynamics in the phase profiles, STPP can calculate the spatial ordering among the tags. In comparison with prior absolute object localization schemes, STPP requires neither dedicated infrastructure nor special hardware. We implemented STPP and evaluated its performance in two real-world applications: locating misplaced books in a library and determining the baggage order in an airport. The experimental results show that STPP achieves about 84% ordering accuracy for misplaced books and 95% ordering accuracy for baggage handling. We further leverage the controllable reader antenna and upgrade STPP to infer the spacing between each pair of tags. The result shows that STPP could achieve promising performance on distance ranging.",
A Subthreshold Voltage Reference With Scalable Output Voltage for Low-Power IoT Systems,"This paper presents a subthreshold voltage reference in which the output voltage is scalable depending on the number of stacked PMOS transistors. A key advantage is that its output voltage can be higher than that obtained with conventional low-power subthreshold voltage references. The proposed reference uses native NMOS transistors as a current source and develops a reference voltage by stacking one or more PMOS transistors. The temperature coefficient of the reference voltage is compensated by setting the size ratio of the native NMOS and stacked pMOS transistors to cancel temperature dependence of transistor threshold voltage and thermal voltage. Also, the transistor size is determined considering the trade-off between diode current between n-well and p-sub and process variation. Prototype chips are fabricated in a 0.18-μm CMOS process. Measurement results from three wafers show 3σ inaccuracy of ±1.0% from 0 °C to 100 °C after a single room-temperature trim. The proposed voltage reference achieves a line sensitivity of 0.31%/V and a power supply rejection of -41 dB while consuming 35 pW from 1.4 V at room temperature.","low-power electronics,
MOSFET"
Coordinated Distributed MPC for Load Frequency Control of Power System With Wind Farms,"Load frequency control (LFC) is crucial for the operation and design of modern electric power systems. This becomes quite challenging, as more wind power is included into the power system. This paper proposes a coordinated distributed model predictive control (DMPC) for the LFC of a power system that includes inherently variable wind-power generations. This DMPC communicates power system measurement and prediction data, and considers the information of other controllers for their local objective to realize effective coordination. The controllers solve the optimization problem while considering given constraints, e.g., generation rate constraints, wind speed, pitch angle, and load input constraints for each area. Since the wind-power output depends largely on the wind speed, different optimization modes for the DMPC were used. Both simulation and experimental tests of a four-area interconnected power system LFC, which consists of thermal plants, hydro units, and a wind farm, demonstrate the improved efficiency of the coordinated DMPC.",
Secure Beamforming in Downlink MISO Nonorthogonal Multiple Access Systems,"In this paper, we consider a cellular downlink multiple-input-single-output (MISO) nonorthogonal multiple access (NOMA) secure transmission system, where users are grouped as multiple clusters. Each cluster consists of a central user and a cell-edge user. The central user is an entrusted user, and the cell-edge user is a potential eavesdropper. We focus on the secure beamforming and power allocation design optimization problem which maximizes the sum achievable secrecy rate of central users subject to the transmit power constraint at the base station and transmission rate requirements at cell-edge users. The problem is nonconvex because of coupling optimization variables in the considered fractional quadratically constrained quadratic programming. We propose an alternating optimization-based solution and a constrained concave-convex procedure-based solution to the considered problem. Simulation results demonstrate that our proposed NOMA schemes outperform the conventional orthogonal multiple access scheme.","NOMA,
Optimization,
Array signal processing,
Base stations,
Downlink,
Signal to noise ratio,
MISO"
A Game Theoretic Approach to Parked Vehicle Assisted Content Delivery in Vehicular Ad Hoc Networks,"Recently, parked vehicles have been shown to be useful to deliver content in vehicular ad hoc networks, where the parked vehicles can form social communities to share and exchange content with other moving vehicles and road side units (RSUs). However, as it takes resource such as bandwidth and power for parked vehicles and RSUs to deliver content, the incentive scheme with the optimal pricing strategy needs to be studied. Furthermore, because multiple places including RSUs and parked vehicles can deliver content to moving vehicles, the optimal algorithm to determine where to obtain the requested content should also be discussed. Therefore, in this paper, we first propose a framework of content delivery with parked vehicles, where moving vehicles can obtain content from both the RSU and parked vehicles according to the competition and cooperation among them. Then, based on a Stackelberg game, we develop a pricing model where each of the three players, including moving vehicles, RSU, and parked vehicles, can obtain their maximum utilities. Next, a gradient based iteration algorithm is presented to obtain the Stackelberg equilibrium. Finally, the simulation results prove that the proposal can outperform other conventional methods and that each player in the game can obtain its optimal strategy during the content delivery.","Vehicles,
Games,
Vehicular ad hoc networks,
Relays,
Roads,
Pricing"
A Novel Semisupervised Active-Learning Algorithm for Hyperspectral Image Classification,"Less training samples are a challenging problem in hyperspectral image classification. Active learning and semisupervised learning are two promising techniques to address the problem. Active learning solves the problem by improving the quality of the training samples, while semisupervised learning solves the problem by increasing the quantity of the training samples. However, they pay too much attention to the discriminative information in the unlabeled data, leading to information bias to train supervised models, and much more effort to label samples. Therefore, a method to discover representativeness and discriminativeness by semisupervised active learning is proposed. It takes advantages of both active learning and semisupervised learning. The representativeness and discriminativeness are discovered with a labeling process based on a supervised clustering technique and classification results. Specifically, the supervised clustering results can discover important structural information in the unlabeled data, and the classification results are also highly confidential in the active-learning process. With these clustering results and classification results, we can assign pseudolabels to the unlabeled data. Meanwhile, the unlabeled samples that cannot be assigned with pseudolabels with high confidence at each iteration are regarded as candidates in active learning. The methodology is validated on four hyperspectral data sets. Significant improvements in classification accuracy are achieved by the proposed method with respect to the state-of-the-art methods.","Training,
Hyperspectral imaging,
Labeling,
Semisupervised learning,
Uncertainty"
Distributed User Association in Energy Harvesting Dense Small Cell Networks: A Mean-Field Multi-Armed Bandit Approach,"The emerging ultra-dense small cell networks (UD-SCNs) will need to combat a variety of challenges. On the one hand, massive number of devices sharing the limited wireless resources renders centralized control mechanisms infeasible due to the excessive cost of information acquisition and computation. On the other hand, to reduce the energy consumption from fixed power grid and/or battery, network entities (e.g., small cell base stations and user devices) may need to rely on the energy harvested from the ambient environment (e.g., from environmental sources). However, opportunistic energy harvesting introduces uncertainty in the network operation. In this paper, we study the distributed user association problem for energy harvesting UD-SCNs. After reviewing the state-of-the-art research, we outline the major challenges that arise in the presence of energy harvesting due to the uncertainty (e.g., limited knowledge on energy harvesting process or channel profile) as well as limited computational capacities. Finally, we propose an approach based on the mean-field multi-armed bandit games to solve the uplink user association problem for energy harvesting devices in a UD-SCN in the presence of uncertainty.","Energy harvesting,
Microprocessors,
Computer architecture,
Interference,
Uncertainty,
Uplink,
Performance evaluation"
Networked Control Under Random and Malicious Packet Losses,"We study cyber security issues in networked control of a linear dynamical system. Specifically, the dynamical system and the controller are assumed to be connected through a communication channel that face malicious attacks as well as random packet losses due to unreliability of transmissions. We provide a probabilistic characterization for the link failures which allows us to study combined effects of malicious and random packet losses. We first investigate almost sure stabilization under an event-triggered control law, where we utilize Lyapunov-like functions to characterize the triggering times at which the plant and the controller attempt to exchange state and control data over the network. We then provide a look at the networked control problem from the attacker's perspective and explore malicious attacks that cause instability. Finally, we demonstrate the efficacy of our results with numerical examples.",
Distributed Coordination of Dynamical Multi-Agent Systems Under Directed Graphs and Constrained Information Exchange,"The distributed coordination problem of multi-agent systems is addressed under the assumption of intermittent discrete-time information exchange with time-varying (possibly unbounded) delays. Specifically, we consider the containment control problem of second-order multi-agent systems with multiple dynamic leaders under a directed interconnection graph topology. First, we present distributed control algorithms for double integrator dynamics in the full and partial state feedback cases. Thereafter, we propose a method to extend our results to second-order systems with locally Lipschitz nonlinear dynamics. We show that, under the same information exchange constraints, our approach can be applied to solve similar coordination problems for other types of complex second-order multi-agent systems, such as harmonic oscillators. In all cases, our control objectives are achieved under some conditions that can be realized independently from the interconnection topology and from the characteristics of the communication process. The effectiveness of the proposed control schemes is illustrated through some examples and numerical simulations.","Delays,
Heuristic algorithms,
Multi-agent systems,
Information exchange,
Topology,
Vehicle dynamics,
Oscillators"
Mining User Attributes Using Large-Scale APP Lists of Smartphones,"Prevalence of smartphones is changing people's lifestyle. Mobile applications (abbr. APPs) on a smartphone serve as entries for users to access a wide range of services. What APPs installed on one's smartphone, i.e., APP list, convey lots of information regarding his/her personal attributes, such as gender, occupation, income, and preferences. This paper addresses the discovery of user attributes from an APP list. We develop an attribute-specific representation to describe user characteristics and then model the relationship between an attribute and an APP list. A large-scale real-world data set with APP lists of more than 100 000 smartphones is used for evaluation. Our approach achieves the average equal error rate of 16.4% for 12 predefined user attributes. To our best knowledge, this is the first work to explore mining of user attributes from installed APP lists.","Smart phones,
Data mining,
Global Positioning System,
Mobile communication,
Social network services,
Error analysis"
Improved Single-Phase Split-Source Inverter With Hybrid Quasi-Sinusoidal and Constant PWM,"A single-stage topology of a three-phase boost inverter known as split-source inverter (SSI) has recently been introduced in the literature. This topology suffers from high frequency current commutations across two diodes and complicated analysis since the inductor is charged with variable duty cycle. This paper presents a single-phase version of SSI with improvements in inverter topology as well as the pulse width modulation (PWM) technique. An inductor is connected to two MOSFETs operating at fundamental frequency to boost the voltage from input source to dc-link voltage. In the proposed hybrid quasi-sinusoidal and constant PWM, one of the full-bridge legs undergoes constant duty cycle switching while the other one undergoes sinusoidally varying duty cycle switching, with the former is accountable for charging and discharging of inductor while the latter is accountable for producing ac output. Therefore, the proposed topology with hybrid quasi-sinusoidal and constant PWM exhibits the merit of simplicity since the control of dc-link voltage and ac output is detached within the single-stage topology. It is not liable to the undesired high frequency current commutation. In addition, a wide range of ac output voltage is achievable in either buck or boost operation. Theoretical analysis is presented and verified through simulation and experimental results.",
Monet: A User-Oriented Behavior-Based Malware Variants Detection System for Android,"Android, the most popular mobile OS, has around 78% of the mobile market share. Due to its popularity, it attracts many malware attacks. In fact, people have discovered around 1 million new malware samples per quarter, and it was reported that over 98% of these new malware samples are in fact “derivatives” (or variants) from existing malware families. In this paper, we first show that runtime behaviors of malware's core functionalities are in fact similar within a malware family. Hence, we propose a framework to combine “runtime behavior” with “static structures” to detect malware variants. We present the design and implementation of Monet, which has a client and a backend server module. The client module is a lightweight, in-device app for behavior monitoring and signature generation, and we realize this using two novel interception techniques. The backend server is responsible for large scale malware detection. We collect 3723 malware samples and top 500 benign apps to carry out extensive experiments of detecting malware variants and defending against malware transformation. Our experiments show that Monet can achieve around 99% accuracy in detecting malware variants. Furthermore, it can defend against ten different obfuscation and transformation techniques, while only incurs around 7% performance overhead and about 3% battery overhead. More importantly, Monet will automatically alert users with intrusion details so to prevent further malicious behaviors.","Malware,
Runtime,
Androids,
Humanoid robots,
Servers,
Monitoring,
Batteries"
Energy Demand Model for Residential Sector: A First Principles Approach,"According to the U.S. Energy Information Administration (EIA), the residential sector accounts for one-third of the country's energy consumption. This number is steadily increasing, posing a challenge to energy regulators as well as suppliers. To manage the growing demand for energy, there is a need for energy system optimization, especially on the demand side. This paper uses a first principles approach to build a high-resolution energy demand model, which can be used as a test bed by academicians as well as policy makers for performing such optimizations. This framework generates activity-based, building-level, time-dependent demand profiles. The model associates appliance usage with each household activity and calculates energy consumption based on the appliance energy rating, the duration of the energy consuming activity, and the type of activity performed by each household member. It also accounts for shared activities among household members to avoid double counting. Additionally, passive energy consumptions such as space heating/cooling, lighting, etc., are measured. Finally, validation of the results obtained by this model against real-world data for Virginia is carried out. The results indicate that the modeling framework is robust and can be extended to other parts of the U.S. and beyond.","Energy consumption,
Home appliances,
Sociology,
Statistics,
Space heating,
Data models,
Schedules"
Compact and Accurate Digital Filters Based on Stochastic Computing,"Stochastic computing (SC), which is an approximate computation with probabilities, has attracted attention as an alternative to deterministic computing. In this paper, we discuss a design method for compact and accurate digital filters based on SC. Such filter designs are widely used for various purposes, such as image and signal processing and machine learning. Our design method involves two techniques. One is sharing random number sources with several stochastic number generators to reduce the areas required by these generators. Clarifying the influence of the correlation around multiplexers (MUXs) on computation accuracy and utilizing circular shifts of the output of random number sources, we can reduce the number of random number sources for a digital filter without losing accuracy. The other technique is to construct a MUX tree, which is the principal part of an SC-based filter. We formulate the correlation-induced errors produced by the MUX tree, and then propose an algorithm for constructing an optimum MUX tree to minimize the error. Experimental results show that the proposed design method can derive compact (approximately 70% area reduction) SC-based filters that retain high accuracy.","Correlation,
Design methodology,
Hardware,
Generators,
Multiplexing,
Logic gates,
Adders"
Blind Domain Adaptation With Augmented Extreme Learning Machine Features,"In practical applications, the test data often have different distribution from the training data leading to suboptimal visual classification performance. Domain adaptation (DA) addresses this problem by designing classifiers that are robust to mismatched distributions. Existing DA algorithms use the unlabeled test data from target domain during training time in addition to the source domain data. However, target domain data may not always be available for training. We propose a blind DA algorithm that does not require target domain samples for training. For this purpose, we learn a global nonlinear extreme learning machine (ELM) model from the source domain data in an unsupervised fashion. The global ELM model is then used to initialize and learn class specific ELM models from the source domain data. During testing, the target domain features are augmented with the reconstructed features from the global ELM model. The resulting enriched features are then classified using the class specific ELM models based on minimum reconstruction error. Extensive experiments on 16 standard datasets show that despite blind learning, our method outperforms six existing state-of-the-art methods in cross domain visual recognition.","Training,
Adaptation models,
Data models,
Training data,
Visualization,
Joining processes,
Cybernetics"
Growth of Oxygen Precipitates and Dislocations in Czochralski Silicon,"The impact of oxygen precipitates and dislocations on carrier recombination is investigated on thick silicon slabs cut vertically from a Czochralski-grown silicon ingot. Using a combination of photoluminescence imaging, photoluminescence spectroscopy, and Fourier transform infrared spectroscopy, we investigate the impact of pre-anneal on their recombination activity. We show that the vacancy concentration during precipitate growth affects the recombination activity of oxygen precipitates. Finally, we demonstrate the impact of nonequilibrium point defect concentrations on precipitate and dislocation growth.",
Multifunctional Control Strategy for Asymmetrical Cascaded H-Bridge Inverter in Microgrid Applications,"A multifunctional control strategy for a single-phase asymmetrical cascaded H-bridge multilevel inverter (ACHMI), suitable for microgrid systems with nonlinear loads, is presented. The primary advantage of ACHMI is to produce a staircase output voltage with low harmonic content utilizing unequal dc voltages on the individual H-bridge cells. In a grid-connected mode of operation, the control strategy of the ACHMI is based on the conservative power theory, providing selective disturbing current compensation besides injecting its available energy. In autonomous mode of operation, two different control methods along with a damping resistor in the filter circuit are developed for regulation of the ACHMI instantaneous output voltage in a variety of load conditions. The first method is a single-loop voltage control scheme without the need of any current measurement. The second one is a multiloop voltage control scheme with a load current feedforward compensation strategy and preservation of the grid-connected current control scheme. The steady-state response and stability of both voltage control schemes are analyzed, and based on the application requirement, the control schemes are implemented individually. The effectiveness of each control strategy is experimentally verified using a hardware-in-the-loop setup with the control algorithm implemented in the TMSF28335 DSP microcontroller.","Inverters,
Voltage control,
Power harmonic filters,
Harmonic analysis,
Switches,
Capacitors,
Modulation"
Light-Field Depth Estimation via Epipolar Plane Image Analysis and Locally Linear Embedding,"In this paper, we propose a novel method for 4D light-field (LF) depth estimation exploiting the special linear structure of an epipolar plane image (EPI) and locally linear embedding (LLE). Without high computational complexity, depth maps are locally estimated by locating the optimal slope of each line segmentation on the EPIs, which are projected by the corresponding scene points. For each pixel to be processed, we build and then minimize the matching cost that aggregates the intensity pixel value, gradient pixel value, spatial consistency, as well as reliability measure to select the optimal slope from a predefined set of directions. Next, a subangle estimation method is proposed to further refine the obtained optimal slope of each pixel. Furthermore, based on a local reliability measure, all the pixels are classified into reliable and unreliable pixels. For the unreliable pixels, LLE is employed to propagate the missing pixels by the reliable pixels based on the assumption of manifold preserving property maintained by natural images. We demonstrate the effectiveness of our approach on a number of synthetic LF examples and real-world LF data sets, and show that our experimental results can achieve higher performance than the typical and recent state-of-the-art LF stereo matching methods.","Estimation,
Cameras,
Reliability,
Three-dimensional displays,
Computational complexity,
Electronic mail,
Image reconstruction"
A Gradient-Based Coverage Optimization Strategy for Mobile Sensor Networks,"A Voronoi-based strategy is proposed to maximize the sensing coverage in a mobile sensor network. Each sensor is moved to a point inside its Voronoi cell using a coverage improvement scheme. To this end, a gradient-based nonlinear optimization approach is utilized to find a target point for each sensor such that the local coverage increases as much as possible, if the sensor moves to this point. The algorithm is implemented in a distributed fashion using local information exchange among sensors. Analytical results are first developed for the single sensor case, and are subsequently extended to a network of mobile sensors, where it is desirable to maximize network-wide coverage with fast convergence. It is shown that under some mild conditions, the positions of the sensors converge to a stationary point of the objective function, which is the overall weighted coverage of the sensors. Simulations demonstrate the effectiveness of the proposed strategy.","Sensors,
Optimization,
Mobile communication,
Mobile computing,
Linear programming,
Partitioning algorithms,
Control systems"
Efficient Markov Blanket Discovery and Its Application,"In a Bayesian network (BN), a target node is independent of all other nodes given its Markov blanket (MB), and finding the MB has many applications, including feature selection and BN structure learning. We propose a new MB discovery algorithm, simultaneous MB (STMB), to improve the efficiency of the existing topology-based MB discovery algorithms. The proposed method removes the necessity of enforcing the symmetry constraint that is prevalent in existing algorithms, by exploiting the coexisting property between spouses and descendants of the target node. Since STMB mainly reduces the number of independence tests needed to complete the MB set after finding the parents-and-children set, it is applicable to all previous topology-based methods. STMB is both sound and complete. Experiments show that STMB has a comparable accuracy but much better efficiency than state-of-the-art methods. An application on benchmark feature selection datasets further demonstrates the excellent performance of STMB.","Markov processes,
Random variables,
Topology,
Complexity theory,
Cybernetics,
Bayes methods,
Approximation algorithms"
Prius: Hybrid Edge Cloud and Client Adaptation for HTTP Adaptive Streaming in Cellular Networks,"In this paper, we present Prius, a hybrid edge cloud and client adaptation framework for HTTP adaptive streaming (HAS) by taking advantage of the new capabilities empowered by recent advances in edge cloud computing. In particular, emerging edge clouds are capable of accessing an application layer and radio access networks (RANs) information in real time. Coupled with powerful computation support, an edge cloud-assisted strategy is expected to significantly enrich mobile services. Meanwhile, although HAS has established itself as the dominant technology for video streaming, one key challenge for adapting HAS to mobile cellular networks is in overcoming the inaccurate bandwidth estimation and unfair bitrate adaptation under the highly dynamic cellular links. Edge cloud-assisted HAS presents a new opportunity to resolve these issues and achieve systematic enhancement of quality of experience (QoE) and QoE fairness in cellular networks. To explore this new opportunity, Prius overlays a layer of adaptation intelligence at the edge cloud to finalize the adaptation decisions while considering the initial bandwidth-irrelevant bitrate selection at the clients. Prius is able to exploit RAN channel status, client device characteristics, and application-layer information in order to jointly adapt the bitrate of multiple clients. Prius also adopts a QoE continuum model to track the cumulative viewing experience and an exponential smoothing estimation to accurately estimate a future channel under different moving patterns. Extensive trace-driven simulation results show that Prius with hybrid edge cloud and client adaptation is promising under both slow and fast-moving environments. Furthermore, the Prius adaptation algorithm achieves a near-optimal performance that outperforms the exiting strategies.","Bandwidth,
Bit rate,
Mobile communication,
Cloud computing,
Streaming media,
Adaptation models,
Throughput"
An Investigation on the Radar Signatures of Small Consumer Drones,"Radar signatures of several small consumer drones are investigated by laboratory measurement. The drones are rotated on a turntable, and backscattered data are collected at two different frequency bands. The data are post-processed into inverse synthetic aperture radar images. The effects of frequency, aspect, polarization, dynamic blade rotation, camera mount, and drone types are presented.","Drones,
Radar cross-sections,
Blades,
Cameras,
Scattering,
Azimuth"
Experimental demonstration of upstream transmission in digital filter multiple access pons with real-time reconfigurable optical network units,"Digital filter multiple access (DFMA) passive optical networks (PONs) exploit centralized software-defined networking (SDN) controller-managed and transceiver-embedded digital orthogonal filters in individual optical network units (ONUs) to enable end-users to adaptively and dynamically access and share a common fiber transmission medium. DFMA PONs have the potential of not only equipping NG-PONs with sufficient network operation flexibility, adaptability, elasticity, and reconfigurability, but also providing highly desirable backward compatibility with current PON standards. In this paper, for the first time to our knowledge, multipoint-to-point upstream signal transmission in intensity-modulation and direct-detection (IMDD)DFMAPONs is experimentally demonstrated using two real-time, reconfigurable, optical orthogonal frequency division multiplexing-modulated ONUs and an offline optical line terminal. The experimental demonstrations show that each ONU achieves a similar upstream bit error rate performance, excellent tolerance to inter-ONU sample timing offset, and a relatively large ONU launch power variation range.","Passive optical networks,
Optical network units,
Digital filters,
Optical fibers,
Optical fiber filters"
A Comprehensive Study of MapReduce Over Lustre for Intermediate Data Placement and Shuffle Strategies on HPC Clusters,"With high performance interconnects and parallel file systems, running MapReduce over modern High Performance Computing (HPC) clusters has attracted much attention due to its uniqueness of solving data analytics problems with a combination of Big Data and HPC technologies. Since the MapReduce architecture relies heavily on the availability of local storage media, the Lustrebased global storage in HPC clusters poses many new opportunities and challenges. In this paper, we perform a comprehensive study on different MapReduce over Lustre deployments and propose a novel high-performance design of YARN MapReduce on HPC clusters by utilizing Lustre as the additional storage provider for intermediate data. With a deployment architecture where both local disks and Lustre are utilized for intermediate data storage, we propose a novel priority directory selection scheme through which RDMAenhanced MapReduce can choose the best intermediate storage during runtime by on-line profiling. Our results indicate that, we can achieve 44 percent performance benefit for shuffle-intensive workloads in leadership-class HPC systems. Our priority directory selection scheme can improve the job execution time by 63 percent over default MapReduce while executing multiple concurrent jobs. To the best of our knowledge, this is the first such comprehensive study for YARN MapReduce with Lustre and RDMA.",
A Novel Heuristic Passive and Active Matching Circuit Design Method for Wireless Power Transfer to Moving Objects,"In this paper, a novel matching circuit design method utilizing a genetic algorithm (GA) and the measured S-parameters of randomly moved coil configurations is discussed. Through the detailed comparison of different matching circuit topologies, the superiority of active matching circuits is clearly demonstrated, and potentially there is 21.4% improvement in the wireless power transfer efficiency by using a four-cell active matching circuit, which can create 16 different impedance values. Also, the matching circuit design simulation can be further simplified by choosing a much smaller subset of representative impedance values for the utilized time-changing coil configuration through the employment of k-means clustering and use only these values for the derivation of the optimal matching circuit. This heuristic approach could drastically reduce the time for the matching circuit design simulation, especially for matching circuit topologies with a larger number of cells.",
In Vivo High-Efficiency Wireless Power Transfer With Multisine Excitation,"This paper presents a systematic design of a high-efficiency magnetic resonant wireless power transfer (MR-WPT) system for biomedical implants based on the unconventional multisine (MS) transmission waveform. The MS waveform featuring a high peak to average power ratio can boost the system efficiency with an elaborate design. Optimizations on flexible coil, system model, and rectifier design are all considered to strengthen its efficiency improvement as well as eliminate its drawbacks. With all the proposed optimizations implemented, the MS waveform has been applied for the first time in practical MR-WPT system for in vivo power delivery. A 6.78-MHz MR-WPT system with 18-mm implant depth is realized for wirelessly powering a spinal cord stimulator. It achieves an overall system efficiency (both coils and rectifier included) of 50.7% with a three-tone 230-kHz tone spacing MS waveform postimplantation in the rodent model. Low specific absorption rate and the tissue temperature rising from electromagnetic fields in the body are also verified to guarantee a safe and practical wireless power link for biomedical implants.",
On Secrecy Rate and Optimal Power Allocation of the Full-Duplex Amplify-and-Forward Relay Wire-Tap Channel,"We present the secrecy rate of a relay wire-tap channel in which a source node communicates securely to a destination node in the presence of an eavesdropper using an amplify-and-forward (AF) relay operating in full-duplex (FD) mode. We explicitly account for the residual self-interference due to FD transmission and compute the optimal power allocation (PA) that maximizes the secrecy rate under both individual and joint power constraints of the source and the relay nodes. For slowly varying fading channels, we show that the optimal PA problem is quasiconcave and, hence, determine the globally optimal solution. Applying the method of dominant balance to analyze the capacity and PA schemes in different high-power regimes, we demonstrate that full PA at the relay is only necessary when the power at the relay is sufficiently small compared to the power at the source. Our results show that FD relaying achieves a significantly higher secrecy rate than half-duplex (HD) relaying. We extend the results to ergodic fading channels where the channel gains are assumed to be available at the receivers but not the transmitters. To this end, we first calculate the expectation of linear functions of exponentially distributed random variables using the exponential integral function. This method allows us to obtain a closed-form expression for the ergodic secrecy rate. The bisection method can then be applied to find the optimal PA scheme. Numerical results also reveal the superiority of FD over HD relaying in channels with ergodic fading.","Relays,
Fading channels,
High definition video,
Wireless communication,
Resource management,
Communication system security,
Receivers"
Echo State Networks for Proactive Caching in Cloud-Based Radio Access Networks With Mobile Users,"In this paper, the problem of proactive caching is studied for cloud radio access networks (CRANs). In the studied model, the baseband units (BBUs) can predict the content request distribution and mobility pattern of each user and determine which content to cache at remote radio heads and the BBUs. This problem is formulated as an optimization problem, which jointly incorporates backhaul and fronthaul loads and content caching. To solve this problem, an algorithm that combines the machine learning framework of echo state networks (ESNs) with sublinear algorithms is proposed. Using ESNs, the BBUs can predict each user's content request distribution and mobility pattern while having only limited information on the network's and user's state. In order to predict each user's periodic mobility pattern with minimal complexity, the memory capacity of the corresponding ESN is derived for a periodic input. This memory capacity is shown to capture the maximum amount of user information needed for the proposed ESN model. Then, a sublinear algorithm is proposed to determine which content to cache while using limited content request distribution samples. Simulation results using real data from Youku and the Beijing University of Posts and Telecommunications show that the proposed approach yields significant gains, in terms of sum effective capacity, that reach up to 27.8% and 30.7%, respectively, compared with two baseline algorithms: random caching with clustering and random caching without clustering.","Wireless communication,
Prediction algorithms,
Algorithm design and analysis,
Cloud computing,
Context,
Radio access networks"
ViCoS2: Video Co-saliency Guided Co-segmentation,"We introduce the term video co-saliency to denote the task of extracting the common noticeable, or salient, regions from multiple relevant videos. The proposed video cosaliency approach accounts for both inter-video foreground correspondences and intra-video saliency stimuli to emphasize the salient foreground regions of video frames and, at the same time, disregard irrelevant visual information of the background. Compared to image co-saliency, it is more reliable due to the utilization of temporal information of video sequence. Benefiting from the discriminability of video co-saliency, we present a unified framework for segmenting out common salient regions of relevant videos, guided by video co-saliency prior. Unlike naive video co-segmentation approaches employing simple color differences and local motion features, the presented video cosaliency provides a more powerful indicator for the common salient regions, thus conducting video co-segmentation efficiently. Extensive experiments show that the proposed method successfully infers video co-saliency and extracts the common salient regions, outperforming the state-of-the-art methods.","Visualization,
Silicon,
Video sequences,
Estimation,
Motion segmentation,
Proposals,
Circuits and systems"
"The Log-Volume of Optimal Codes for Memoryless Channels, Asymptotically Within a Few Nats","Shannon's analysis of the fundamental capacity limits for memoryless communication channels has been refined over time. In this paper, the maximum volume M*avg(n, ∈) of length-n codes subject to an average decoding error probability ∈ is shown to satisfy the following tight asymptotic lower and upper bounds as n → ∞: A∈ + o(1) ≤ log M*avg(n, ∈) - [nC - √nV∈ Q-1(∈)+ (1/2)log n] ≤ A∈ + o(1), where C is the Shannon capacity, V∈ is the ∈-channel dispersion, or secondorder coding rate, Q is the tail probability of the normal distribution, and the constants AE and AE are explicitly identified. This expression holds under mild regularity assumptions on the channel, including nonsingularity. The gap A∈ - A∈ is one nat for weakly symmetric channels in the Cover-Thomas sense, and typically a few nats for other symmetric channels, for the binary symmetric channel, and for the Z channel. The derivation is based on strong large-deviations analysis and refined central limit asymptotics. A random coding scheme that achieves the lower bound is presented. The codewords are drawn from a capacityachieving input distribution modified by an O(1/√n) correction term.","Upper bound,
Error probability,
Monte Carlo methods,
Random variables,
Channel coding,
Dispersion"
Data Centers as Dispatchable Loads to Harness Stranded Power,"We analyze how traditional data center placement and optimal placement of dispatchable data centers affect power grid efficiency. We use detailed network models, stochastic optimization formulations, and diverse renewable generation scenarios to perform our analysis. Our results reveal that significant spillage and stranded power will persist in power grids as wind power levels are increased. A counter-intuitive finding is that collocating data centers with inflexible loads next to wind farms has limited impacts on renewable portfolio standard (RPS) goals because it provides limited system-level flexibility. Such an approach can, in fact, increase stranded power and fossil-fueled generation. In contrast, optimally placing data centers that are dispatchable provides system-wide flexibility, reduces stranded power, and improves efficiency. In short, optimally placed dispatchable computing loads can enable better scaling to high RPS. In our case study, we find that these dispatchable computing loads are powered to 60-80% of their requested capacity, indicating that there are significant economic incentives provided by stranded power.",
On the Feasibility of Creating Double-Identity Fingerprints,"A double-identity fingerprint is a fake fingerprint created by combining features from two different fingers, so that it has a high chance to be falsely matched with fingerprints from both fingers. This paper studies the feasibility of creating double-identity fingerprints by proposing two possible techniques and evaluating to what extent they may be used to fool the state-of-the-art fingerprint recognition systems. The results of systematic experiments suggest that existing algorithms are highly vulnerable to this specific attack (about 90% chance of success at FAR = 0.1%) and that the fingerprint patterns generated might be realistic enough to fool human examiners.","Fingerprint recognition,
Fingers,
Face,
Systematics,
Estimation,
Frequency estimation,
Europe"
6-DoF object pose from semantic keypoints,"This paper presents a novel approach to estimating the continuous six degree of freedom (6-DoF) pose (3D translation and rotation) of an object from a single RGB image. The approach combines semantic keypoints predicted by a convolutional network (convnet) with a deformable shape model. Unlike prior work, we are agnostic to whether the object is textured or textureless, as the convnet learns the optimal representation from the available training image data. Furthermore, the approach can be applied to instance- and class-based pose recovery. Empirically, we show that the proposed approach can accurately recover the 6-DoF object pose for both instance- and class-based scenarios with a cluttered background. For class-based object pose estimation, state-of-the-art accuracy is shown on the large-scale PASCAL3D+ dataset.","Shape,
Solid modeling,
Three-dimensional displays,
Heating systems,
Two dimensional displays,
Cameras,
Semantics"
Template Deformation-Based 3-D Reconstruction of Full Human Body Scans From Low-Cost Depth Cameras,"Full human body shape scans provide valuable data for a variety of applications including anthropometric surveying, clothing design, human-factors engineering, health, and entertainment. However, the high price, large volume, and difficulty of operating professional 3-D scanners preclude their use in home entertainment. Recently, portable low-cost red green blue-depth cameras such as the Kinect have become popular for computer vision tasks. However, the infrared mechanism of this type of camera leads to noisy and incomplete depth images. We construct a stereo full-body scanning environment composed of multiple depth cameras and propose a novel registration algorithm. Our algorithm determines a segment constrained correspondence for two neighboring views, integrating them using rigid transformation. Furthermore, it aligns all of the views based on uniform error distribution. The generated 3-D mesh model is typically sparse, noisy, and even with holes, which makes it lose surface details. To address this, we introduce a geometric and topological fitting prior in the form of a professionally designed high-resolution template model. We formulate a template deformation optimization problem to fit the high-resolution model to the low-quality scan. Its solution overcomes the obstacles posed by different poses, varying body details, and surface noise. The entire process is free of body and template markers, fully automatic, and achieves satisfactory reconstruction results.",
Training Signal Design for Correlated Massive MIMO Channel Estimation,"In this paper, we propose a new approach to the design of training sequences that can be used for an accurate estimation of multi-input multi-output channels. The proposed method is particularly instrumental in training sequence designs that deal with three key challenges: 1) arbitrary channel and noise statistics that do not follow specific models, 2) limitations on the properties of the transmit signals, including total power, per-antenna power, having a constant-modulus, discrete-phase, or low peak-to-average-power ratio, and 3) signal design for large-scale or massive antenna arrays. Several numerical examples are provided to examine the proposed method.",
What do Support Analysts Know About Their Customers? On the Study and Prediction of Support Ticket Escalations in Large Software Organizations,"Understanding and keeping the customer happy is a central tenet of requirements engineering. Strategies to gather, analyze, and negotiate requirements are complemented by efforts to manage customer input after products have been deployed. For the latter, support tickets are key in allowing customers to submit their issues, bug reports, and feature requests. Whenever insufficient attention is given to support issues, however, their escalation to management is time-consuming and expensive, especially for large organizations managing hundreds of customers and thousands of support tickets. Our work provides a step towards simplifying the job of support analysts and managers, particularly in predicting the risk of escalating support tickets. In a field study at our large industrial partner, IBM, we used a design science methodology to characterize the support process and data available to IBM analysts in managing escalations. Through iterative cycles of design and evaluation, we translated our understanding of support analysts' expert knowledge of their customers into features of a support ticket model to be implemented into a Machine Learning model to predict support ticket escalations. We trained and evaluated our Machine Learning model on over 2.5 million support tickets and 10,000 escalations, obtaining a recall of 79.9% and an 80.8% reduction in the workload for support analysts looking to identify support tickets at risk of escalation. Further on-site evaluations, through a prototype tool we developed to implement our Machine Learning techniques in practice, showed more efficient weekly support-ticket-management meetings. The features we developed in the Support Ticket Model are designed to serve as a starting place for organizations interested in implementing our model to predict support ticket escalations, and for future researchers to build on to advance research in escalation prediction.","Organizations,
Analytical models,
Software,
Predictive models,
Iron,
Customer relationship management,
Computer bugs"
Smart Sensors and Internet of Things: A Postgraduate Paper,"A course on the emerging topic “Smart Sensors and Internet of Things (IoT)” has been designed, developed, and delivered from 21st March 2016 to 31st March 2016 in the Department of Electrical Engineering, Jamia Millia Islamia (Central University), New Delhi-110025, India. This course was organized under a program initiated by the Government of India, entitled “Global Initiative of Academic Networks” for higher education. The basic objective is to bring the internationally and nationally acclaimed scientists on a single platform to motivate young minds of India so that India's scientific and technological capacity reach global excellence. The course was designed to develop the technical skills for the students, the researchers, the engineers, and the faculties, who desire to address some of the issues faced by the people around the world in the fields of smart sensors and IoTs with applications in smart homes, smart cities, smart grids, smart environment, smart transport, and so on. The assessment of the course by the participants shows extreme usefulness of it.","educational courses,
intelligent sensors,
Internet of Things"
Blind Interference Alignment for Multiuser MISO Indoor Visible Light Communications,"A filter-pair-based blind interference alignment scheme is proposed to improve the achievable degree of freedom (DoF) in multiuser multiple-input single-output indoor visible light communications. In the proposed scheme, the transmitter does not need to know channel state information. Different transmit sub-channels employ different pulse-shaping filters, and each user is equipped with multiple receive filters. The transmitter sends signals according to the predesigned strategy, and each user sets the receive mode by choosing the corresponding receive filter. Optical orthogonal frequency division multiplexing is employed in the proposed scheme to combat the intersymbol interference in high-speed transmissions, and the maximum achievable spectrum efficiency (SE) of the proposed scheme is analyzed. Simulation results validate that the proposed scheme can achieve higher SE and more DoF than the orthogonal multiple access schemes.","OFDM,
Optical transmitters,
Light emitting diodes,
Interference,
Optical receivers,
MIMO"
"Unified Modeling of Composite \kappa -\mu /Gamma, \eta -\mu/Gamma, and \alpha -\mu/Gamma Fading Channels Using a Mixture Gamma Distribution With Applications to Energy Detection","In this letter, the performance of an energy detection (ED) is analyzed over different composite generalized multipath/gamma fading channels, namely, κ - μ/gamma, η - μ/gamma, and α - μ/gamma. The mixture gamma distribution is employed to approximate with high accuracy the signal-to-noise ratio for all these channels. General, mathematically tractable, and unified analytic expressions for the performance metrics of ED, i.e., the average detection probability and the average area under the receiver operating characteristics curve, are derived. The validation of our analysis is verified by comparing the analytical results to the simulation results.",
Robust Registration of Multimodal Remote Sensing Images Based on Structural Similarity,"Automatic registration of multimodal remote sensing data [e.g., optical, light detection and ranging (LiDAR), and synthetic aperture radar (SAR)] is a challenging task due to the significant nonlinear radiometric differences between these data. To address this problem, this paper proposes a novel feature descriptor named the histogram of orientated phase congruency (HOPC), which is based on the structural properties of images. Furthermore, a similarity metric named HOPCncc is defined, which uses the normalized correlation coefficient (NCC) of the HOPC descriptors for multimodal registration. In the definition of the proposed similarity metric, we first extend the phase congruency model to generate its orientation representation and use the extended model to build HOPCncc. Then, a fast template matching scheme for this metric is designed to detect the control points between images. The proposed HOPCncc aims to capture the structural similarity between images and has been tested with a variety of optical, LiDAR, SAR, and map data. The results show that HOPCncc is robust against complex nonlinear radiometric differences and outperforms the state-of-the-art similarities metrics (i.e., NCC and mutual information) in matching performance. Moreover, a robust registration method is also proposed in this paper based on HOPCncc, which is evaluated using six pairs of multimodal remote sensing images. The experimental results demonstrate the effectiveness of the proposed method for multimodal image registration.","Remote sensing,
Radiometry,
Image registration,
Feature extraction,
Robustness,
Nonlinear optics"
A Quality-of-Content-Based Joint Source and Channel Coding for Human Detections in a Mobile Surveillance Cloud,"More than 70% of consumer mobile Internet traffic will be mobile video transmissions by 2019. The development of wireless video transmission technologies has been boosted by the rapidly increasing demand of video streaming applications. Although more and more videos are delivered for video analysis (e.g., object detection/tracking and action recognition), most existing wireless video transmission schemes are developed to optimize human perception quality and are suboptimal for video analysis. In mobile surveillance networks, a cloud server collects videos from multiple moving cameras and detects suspicious persons in all camera views. Camera mobility in smartphones or dash cameras implies that video is to be uploaded through bandwidth-limited and error-prone wireless networks, which may cause quality degradation of the decoded videos and jeopardize the performance of video analyses. In this paper, we propose an effective rate-allocation scheme for multiple moving cameras in order to improve human detection (content) performance. Therefore, the optimization criterion of the proposed rate-allocation scheme is driven by quality of content (QoC). Both video source coding and application layer forward error correction coding rates are jointly optimized. Moreover, the proposed rate-allocation problem is formulated as a convex optimization problem and can be efficiently solved by standard solvers. Many simulations using High Efficiency Video Coding standard compression of video sequences and the deformable part model object detector are carried, and results demonstrate the effectiveness and favorable performance of our proposed QoC-driven scheme under different pedestrian densities and wireless conditions.",
Collaborative Smartphone Sensing Using Overlapping Coalition Formation Games,"With the rapid growth of sensor technology, smartphone sensing has become an effective approach to improve the quality of smartphone applications. However, due to time-varying wireless channels and lack of incentives for the users to participate, the quality and quantity of the data uploaded by the smartphone users are not always satisfying. In this paper, we consider a smartphone sensing system in which a platform publicizes multiple tasks, and the smartphone users choose a set of tasks to participate in. In the traditional non-cooperative approach with incentives, each smartphone user gets rewards from the platform as an independent individual and the limit of the wireless channel resources is often omitted. To tackle this problem, we introduce a novel cooperative approach with an overlapping coalition formation game (OCF-game) model, in which the smartphone users can cooperate with each other to form the overlapping coalitions for different sensing tasks. We also utilize a centralized case to describe the upper bound of the system sensing performance. Simulation results show that the cooperative approach achieves a better performance than the non-cooperative one in various situations.",
GHz Optical Time-Stretch Microscopy by Compressive Sensing,"We demonstrate compressive sensing on the platform of optical time-stretch microscopy to overcome the trade-off between frame rate and temporal dispersion. Our results indicate that the spatial resolution and cell classification accuracy reach 780 nm and 95% at a line scan rate of 675 MHz and 6.75 GHz, respectively, which correspond to 5 times and 50 times higher frame rates than what conventional optical time-stretch microscopy can achieve.",
Self-Supervised Visual Descriptor Learning for Dense Correspondence,"Robust estimation of correspondences between image pixels is an important problem in robotics, with applications in tracking, mapping, and recognition of objects, environments, and other agents. Correspondence estimation has long been the domain of hand-engineered features, but more recently deep learning techniques have provided powerful tools for learning features from raw data. The drawback of the latter approach is that a vast amount of (labeled, typically) training data are required for learning. This paper advocates a new approach to learning visual descriptors for dense correspondence estimation in which we harness the power of a strong three-dimensional generative model to automatically label correspondences in RGB-D video data. A fully convolutional network is trained using a contrastive loss to produce viewpoint- and lighting-invariant descriptors. As a proof of concept, we collected two datasets: The first depicts the upper torso and head of the same person in widely varied settings, and the second depicts an office as seen on multiple days with objects rearranged within. Our datasets focus on revisitation of the same objects and environments, and we show that by training the CNN only from local tracking data, our learned visual descriptor generalizes toward identifying nonlabeled correspondences across videos. We furthermore show that our approach to descriptor learning can be used to achieve state-of-the-art single-frame localization results on the MSR 7-scenes dataset without using any labels identifying correspondences between separate videos of the same scenes at training time.","Visualization,
Training data,
Labeling,
Simultaneous localization and mapping,
Computational modeling,
Training"
Returnn: The RWTH extensible training framework for universal recurrent neural networks,In this work we release our extensible and easily configurable neural network training software. It provides a rich set of functional layers with a particular focus on efficient training of recurrent neural network topologies on multiple GPUs. The source of the software package is public and freely available for academic research purposes and can be used as a framework or as a standalone tool which supports a flexible configuration. The software allows to train state-of-the-art deep bidirectional long short-term memory (LSTM) models on both one dimensional data like speech or two dimensional data like handwritten text and was used to develop successful submission systems in several evaluation campaigns.,"Training,
Graphics processing units,
Recurrent neural networks,
Network topology,
Software packages"
3-D Markerless Tracking of Human Gait by Geometric Trilateration of Multiple Kinects,"In this paper, we develop an integrated markerless gait tracking system with three Kinect v2 sensors. A geometric principle-based trilateration method is proposed for optimizing the accuracy of the measured gait data. To tackle the data synchronization problem among the Kinect clients and the server, a synchronization mechanism based on network time protocol (NTP) is designed for synchronizing the server and Kinect clients’ clocks. Furthermore, a time schedule is designed for timing each Kinect client’s data transmission. In the experiment, participants are asked to perform a 60-s walk, while the proposed tracking system obtains the participant’s gait data. Six joints (including left hip, right hip, left knee, right knee, left ankle, and right ankle) of the participants are tracked where the obtained gait data are described as 6000 movements of joint positions (1000 movements for each joint). The results show that the trilateration tracking result by the three Kinect sensors has a much higher accuracy compared with the accuracy measured by a single Kinect sensor. Within a randomly sampled time period (67.726 s in the experiment), 98.37
%
of the frames generated by the gait tracking system have timing errors less than 1 ms, which is much better than the default NTP service embedded in the Windows 8.1 operating system. The accuracy of the proposed system is quantitatively evaluated and verified by a comparison with a commercial medical system (Delsys Trigno Smart Sensor System).",
Helical Stirring for Enhanced Low-Frequency Performance of Reverberation Chambers,"A novel class of volumetric mechanical mode stirring methods is introduced. One particular type, denoted as helical stirring, combines rotation and translation in a single motion. This technique is implemented, and its measured performance is compared to conventional circular stirring by the same paddle. It is observed that helical stirring can significantly increase the number of uncorrelated stir states at sufficiently low frequencies. Higher maximum- and lower minimum-to-average ratios of the magnitude and intensity of the received field are obtained that are traceable to a heavier tail of their probability density functions. While the helix pitch can be optimized per frequency, suboptimal values also yield considerable improvement. The use of a stir matrix facilitates the data analysis and estimation of ensemble statistics for arbitrary values of the helix pitch, beyond its experimentally realized discrete values.",
"FIM
2c
: Multicolor, Multipurpose Imaging System to Manipulate and Analyze Animal Behavior","In vivo whole-body imaging of small animals plays an important role for biomedical studies. In particular, animals like the fruit fly Drosophila melanogaster or the nematode Caenorhabditis elegans are popular model organisms for preclinical research since they offer sophisticated genetic tool-kits. Recording these translucent animals with high contrast in a large arena is however not trivial. Furthermore, fluorescent proteins are widely used to mark cells in vivo and report their functions. This paper introduces a novel optical imaging technique called FIM2c enabling simultaneous detection of the animals posture and movement as well as fluorescent markers like green fluorescent protein (GFP). FIM2c utilizes frustrated total internal reflection of two distinct wavelengths and captures both, reflected and emitted light. The resultant two-color high-contrast images are superb compared to other imaging systems for larvae or worms. This multipurpose method enables a large variety of different experimental approaches. For example, FIM2c can be used to image GFP positive cells/tissues/animals and supports the integration of fluorescent tracers into multitarget tracking paradigms. Moreover, optogenetic tools can be applied in large-scale behavioral analysis to manipulate and study neuronal functions. To demonstrate the benefit of our system, we use FIM2c to resolve colliding larvae in a high-throughput approach, which was impossible given the existing tools. Finally, we present a comprehensive database including images and locomotion features of more than 1300 resolved collisions available for the community. In conclusion, FIM2c is a versatile tool for advanced imaging and locomotion analysis for a variety of different model organisms.",
Low Delay Random Linear Coding and Scheduling Over Multiple Interfaces,"High-performance real-time applications, expected to be of importance in the upcoming 5G era, such as virtual and augmented reality or tele-presence, have stringent requirements on throughput and per-packet in-order delivery delay. Use of multipath transport is gaining momentum for supporting these applications. However, building an efficient, low latency multipath transfer mechanism remains highly challenging. The primary reason for this is that the delivery delay along each path is typically uncertain and time-varying. When the transmitter ignores the stochastic nature of the path delays, then packets sent along different paths frequently arrive out of order and need to be buffered at the receiver to allow in-order delivery to the application. In this paper, we propose Stochastic Earliest Delivery Path First (S-EDPF), a generalization of EDPF which takes into account uncertainty and time-variation in path delays yet has low-complexity suited to practical implementation. Moreover, we integrate a novel low-delay Forward Error Correction (FEC) scheme into S-EDPF in a principled manner by deriving the optimal schedule for coded packets across multiple paths. Finally, we demonstrate, both analytically and empirically, that S-EDPF is effective at mitigating the delay impact of reordering and loss in multipath transport protocols, offering substantial performance gains over the state of the art.",
Understanding autonomous drone maneuverability for Internet of Things applications,"Increasing sensing and communication capabilities combined with falling prices have made drones very attractive for Internet of Things applications. A key requirement of these applications is that the drones should be autonomously maneuvered by computer programs. It is therefore important to understand the practical limitations of autonomous drone maneuverability to ensure that target application performance is met. In this paper, we first analyze drone maneuverability using theory to shed light on the tradeoff between the flying speed and the turning agility of the drone. To investigate the practical maneuverability performance, we then emulate as well as fly a commercial drone under the control of an Android program. We reveal some practical maneuverability factors that must be considered for the applications that require frequent changes of direction for the drone.",
Buffer-Aided Non-Orthogonal Multiple Access Relaying Systems in Rayleigh Fading Channels,"Non-orthogonal multiple access (NOMA) is a promising technology in future communication systems. In this paper, we propose a buffer-aided NOMA relaying system, which consists of a source, a relay, and two destinations. In the relaying system, the relay helps the source transmit packets to two destinations simultaneously using NOMA scheme. We theoretically derive outage probabilities of source-to-relay link and relay-to-destinations links considering two scenarios that the relay does and does not know the channel state information (CSI) from itself to two destinations. When the relay knows CSI, the obtained outage probability of relay-to-destinations links involves integration operation. Thus, we derive an upper bound and two lower bounds. Simulation results demonstrate that two lower bounds approach exact outage probability at low and high signal-to-noise ratios, respectively. We also propose a relay decision scheme for the buffer-aided NOMA relaying system. Based on the obtained system outage probability, we theoretically derive the diversity order. It is found that no matter whether the relay knows CSI or not, the diversity order of 2 can be achieved when the buffer size is larger than or equal to 3.","Relays,
NOMA,
Delays,
Buffer storage,
Throughput,
Transmitters,
Receivers"
Electromagnetic Near-Field Inhomogeneity Reduction for Image Acquisition Optimization in High-Resolution Multi-Channel Magnetic Resonance Imaging (MRI) Systems,"This paper is a study of the inhomogeneity reduction for near-field acquisition in high-resolution magnetic resonance imaging (MRI) systems. The acquisition homogeneity in MRI imaging modality is an open issue concerning the optimal MRI image generation in terms of the RF signal acquisition. The acquisition inhomogeneity is related to the radiation patterns of the receiving antennas and its location in the MRI system, among other relevant aspects. The acquisition inhomogeneity is translated into two main effects: pattern ripples at the outer cylindrical rings and radial inhomogeneity when comparing the center value (maximum) with the rest of the pattern. To overcome these effects, two strategies are proposed. In the first one, it is proposed to progressively vary the antenna location in the azimuthal array distribution. In the second one, it is proposed to progressively vary the antenna amplitude and phase feeding in the array distribution. To compute a figure of merit of the pattern radial uniformity and the ripples, two metrics are defined in this paper. It is proved that both the progressive modification in the location at each array ring and the variation of the feeding phase of each array ring reduce the pattern ripples and radial inhomogeneity. Optimal values for either the angular rotation or the feeding phase values can be calculated, depending on the particular dimensions of the cylinder that conforms the region of interest.",
Fusion of Magnetic and Visual Sensors for Indoor Localization: Infrastructure-Free and More Effective,"Accurate and infrastructure-free indoor positioning can be very useful in a variety of applications. However, most existing approaches (e.g., WiFi and infrared-based methods) for indoor localization heavily rely on infrastructure, which is neither scalable nor pervasively available. In this paper, we propose a novel indoor localization and tracking approach, termed VMag, that does not require any infrastructure assistance. The user can be localized while simply holding a smartphone. To the best of our knowledge, the proposed method is the first exploration of fusing geomagnetic and visual sensing for indoor localization. More specifically, we conduct an in-depth study on both the advantageous properties and the challenges in leveraging the geomagnetic field and visual images for indoor localization. Based on these studies, we design a context-aware particle filtering framework to track the user with the goal of maximizing the positioning accuracy. We also introduce a neural-network-based method to extract deep features for the purpose of indoor positioning. We have conducted extensive experiments on four different indoor settings including a laboratory, a garage, a canteen, and an office building. Experimental results demonstrate the superior performance of VMag over the state of the art with these four indoor settings.","Visualization,
Magnetic resonance imaging,
Magnetometers,
Magnetic sensors,
Legged locomotion,
Buildings"
Continuous and unconstrained vital signs monitoring with ballistocardiogram sensors in headrest position,"Unobtrusive and long-term monitoring of human vital signs are essential requirements for early diagnosis and prophylaxis due to many reasons, one of the most important being improving the quality of life. Currently, vital signs are continuously monitored through sensors attached to the body, such as multiple electrodes for measuring electrical activity of the heart. Such methods may be undesirable, especially for elderly, infants and other groups of people. In this paper, we introduce an improved technique for measuring heart rate from noisy ballistocardiogram signals acquired from 50 human volunteers in a sitting position using a massage chair. The signals are unobtrusively collected from a microbend fiber optic sensor embedded within the headrest of the chair, and then transmitted to a computer through a Bluetooth connection. The heart rate is computed using the multiresolution analysis of the maximal overlap discrete wavelet transform. The error between the proposed method and the reference ECG is estimated in beats per minute using the mean absolute error, where the system achieved relatively good results (7.31 ± 1.60) despite the large amount of motion artifacts produced owing to the frequent body movements and/or vibrations of the massage chair during stress relief massage. Unlike the complete ensemble empirical mode decomposition algorithm, previously employed for heart rate estimation, the suggested system is much faster. Hence, it can be used in real-time applications.",
Rate of Convergence of the FOCUSS Algorithm,"Focal underdetermined system solver (FOCUSS) is a powerful method for basis selection and sparse representation, where it employs the ℓp-norm with p ∈ (0, 2) to measure the sparsity of solutions. In this paper, we give a systematical analysis on the rate of convergence of the FOCUSS algorithm with respect to p ∈ (0, 2). We prove that the FOCUSS algorithm converges superlinearly for 0 <; p <; 1 and linearly for 1 ≤ p <; 2 usually, but may superlinearly in some very special scenarios. In addition, we verify its rates of convergence with respect to p by numerical experiments.",
Six-Degree-of-Freedom Localization of an Untethered Magnetic Capsule Using a Single Rotating Magnetic Dipole,"This paper presents a method to estimate the six-degree-of-freedom pose of a magnetic capsule, with an embedded permanent magnet and Hall-effect sensors, using a rotating dipole field. The method's convergence properties as a function of the number of distinct rotation axes of the applied field and the number of complete rotations about each axis are characterized. Across our tested workspace, the localization error was 4.9 ± 2.7 mm and 3.3 ± 1.7 degrees (mean ± standard deviation). We experimentally demonstrate this is sufficient for propulsion of a screw-type magnetic capsule through a lumen using a single dipole to both propel and localize the capsule.","Magnetic sensors,
Propulsion,
Magnetic moments,
Robot sensing systems,
Mathematical model"
Segment-Based Predominant Learning Swarm Optimizer for Large-Scale Optimization,"Large-scale optimization has become a significant yet challenging area in evolutionary computation. To solve this problem, this paper proposes a novel segment-based predominant learning swarm optimizer (SPLSO) swarm optimizer through letting several predominant particles guide the learning of a particle. First, a segment-based learning strategy is proposed to randomly divide the whole dimensions into segments. During update, variables in different segments are evolved by learning from different exemplars while the ones in the same segment are evolved by the same exemplar. Second, to accelerate search speed and enhance search diversity, a predominant learning strategy is also proposed, which lets several predominant particles guide the update of a particle with each predominant particle responsible for one segment of dimensions. By combining these two learning strategies together, SPLSO evolves all dimensions simultaneously and possesses competitive exploration and exploitation abilities. Extensive experiments are conducted on two large-scale benchmark function sets to investigate the influence of each algorithmic component and comparisons with several state-of-the-art meta-heuristic algorithms dealing with large-scale problems demonstrate the competitive efficiency and effectiveness of the proposed optimizer. Further the scalability of the optimizer to solve problems with dimensionality up to 2000 is also verified.","Optimization,
Diversity reception,
Computer science,
Clustering algorithms,
Convergence,
Cybernetics,
Evolutionary computation"
Java Technologies for Cyber-Physical Systems,"Cyber-physical systems (CPS) provide a strong integration and coordination between computing science, network communications, and the physical world. These systems are usually real-time and embedded applications with stringent requirements, including highly precise timing characteristics, small memory footprints, flexible sensor and actuator interfaces, and robust safety characteristics. This paper outlines opportunities and challenges in the development of CPS by using distributed real-time and embedded Java technologies.","Java,
Real-time systems,
Memory management,
Programming,
Clocks,
Timing,
Instruction sets"
Innovative Robust Modulation Classification Using Graph-Based Cyclic-Spectrum Analysis,"A novel automatic modulation classification method based on the graph presentation of the cyclic spectrum is proposed. In our proposed scheme, the periodicity and the symmetry of the cyclic spectrum will be exploited to establish a concise feature representation of multiple graphs. The modulated signal is first transformed from the cycle-frequency domain into the graph domain. Consequently, the concise graph-presentation, namely, a set of weighted directed rings, will be formulated as the robust features of the original signal. Those features can be easily expressed by the corresponding adjacency matrices. It can be verified that the adjacency matrices are sparse and the non-zero entries therein can be registered as the efficient feature parameters. Through the Hamming distance measure to enumerate the difference between the feature parameters resulting from the training data and the test data, one can perform the modulation classification. Monte Carlo simulation results demonstrate that our proposed method can achieve much better classification accuracy than the existing technique when the cyclic spectrum is used.","Feature extraction,
Frequency modulation,
Sparse matrices,
Training,
Indexes,
Robustness"
An Improved SDA Based Defect Prediction Framework for Both Within-Project and Cross-Project Class-Imbalance Problems,"Background. Solving the class-imbalance problem of within-project software defect prediction (SDP) is an important research topic. Although some class-imbalance learning methods have been presented, there exists room for improvement. For cross-project SDP, we found that the class-imbalanced source usually leads to misclassification of defective instances. However, only one work has paid attention to this cross-project class-imbalance problem. Objective. We aim to provide effective solutions for both within-project and cross-project class-imbalance problems. Method. Subclass discriminant analysis (SDA), an effective feature learning method, is introduced to solve the problems. It can learn features with more powerful classification ability from original metrics. For within-project prediction, we improve SDA for achieving balanced subclasses and propose the improved SDA (ISDA) approach. For cross-project prediction, we employ the semi-supervised transfer component analysis (SSTCA) method to make the distributions of source and target data consistent, and propose the SSTCA+ISDA prediction approach. Results. Extensive experiments on four widely used datasets indicate that: 1) ISDA-based solution performs better than other state-of-the-art methods for within-project class-imbalance problem; 2) SSTCA+ISDA proposed for cross-project class-imbalance problem significantly outperforms related methods. Conclusion. Within-project and cross-project class-imbalance problems greatly affect prediction performance, and we provide a unified and effective prediction framework for both problems.","Support vector machines,
Learning systems,
Predictive models,
Software,
Software engineering,
Measurement"
Dynamic base station repositioning to improve spectral efficiency of drone small cells,"With recent advancements in drone technology, researchers are now considering the possibility of deploying small cells served by base stations mounted on flying drones. A major advantage of such drone small cells is that the operators can quickly provide cellular services in areas of urgent demand without having to pre-install any infrastructure. Since the base station is attached to the drone, technically it is feasible for the base station to dynamic reposition itself in response to the changing locations of users for reducing the communication distance, decreasing the probability of signal blocking, and ultimately increasing the spectral efficiency. In this paper, we first propose distributed algorithms for autonomous control of drone movements, and then model and analyse the spectral efficiency performance of a drone small cell to shed new light on the fundamental benefits of dynamic repositioning. We show that, with dynamic repositioning, the spectral efficiency of drone small cells can be increased by nearly 100% for realistic drone speed, height, and user traffic model and without incurring any major increase in drone energy consumption.",
Performance-Monitoring-Based Traffic-Aware Virtual Machine Deployment on NUMA Systems,"Virtualization technology enables multiple virtual machines (VMs) to share a single physical server. Commercial servers increasingly use the nonuniform memory access (NUMA) architecture due to its scalable memory performance. However, multiple VMs running on a NUMA physical server will cause performance overheads such as remote memory access latency and shared microarchitectural resource contention, which makes the VM performance less efficient and stable. These performance overheads are mainly caused by memory traffic from data-intensive workloads. In this paper, we propose a traffic-aware VM optimization (TAVO) scheme on NUMA systems. Based on the performance monitoring of the data traffic and CPU/memory resource usages in the system, TAVO addresses VM memory access locality and shared resource contention problems via automatic VM initial placement and NUMA-aware VM online scheduling. Our experimental results show that TAVO improves VM performance in terms of benchmark runtime by up to 22.6% compared with the default KVM CFS scheduler. TAVO also achieves a much stable performance with benchmark's average runtime variation under 3%.","Monitoring,
Multicore processing,
Bandwidth,
Sockets,
Microarchitecture,
Hardware,
Servers"
Face Recognition Using Sparse Fingerprint Classification Algorithm,"Unconstrained face recognition is still an open problem as the state-of-the-art algorithms have not yet reached high recognition performance in real-world environments. This paper addresses this problem by proposing a new approach called sparse fingerprint classification algorithm (SFCA). In the training phase, for each enrolled subject, a grid of patches is extracted from each subject's face images in order to construct representative dictionaries. In the testing phase, a grid is extracted from the query image and every patch is transformed into a binary sparse representation using the dictionary, creating a fingerprint of the face. The binary coefficients vote for their corresponding classes and the maximum-vote class decides the identity of the query image. Experiments were carried out on seven widely-used face databases. The results demonstrate that when the size of the data set is small or medium (e.g., the number of subjects is not greater than one hundred), SFCA is able to deal with a larger degree of variability in ambient lighting, pose, expression, occlusion, face size, and distance from the camera than other current state-of-the-art algorithms.","Dictionaries,
Face,
Face recognition,
Feature extraction,
Fingerprint recognition,
Training,
Lighting"
Efficient and Fair Collaborative Mobile Internet Access,"The surging global mobile data traffic challenges the economic viability of cellular networks and calls for innovative solutions to reduce the network congestion and improve user experience. In this context, user-provided networks (UPNs), where mobile users share their Internet access by exploiting their diverse network resources and needs, turn out to be very promising. Heterogeneous users with advanced handheld devices can form connections in a distributed fashion and unleash dormant network resources at the network edge. However, the success of such services heavily depends on users' willingness to contribute their resources, such as network access and device battery energy. In this paper, we introduce a general framework for UPN services and design a bargaining-based distributed incentive mechanism to ensure users' participation. The proposed mechanism determines the resources that each user should contribute in order to maximize the aggregate data rate in UPN, and fairly allocate the benefit among the users. The numerical results verify that the service can always improve users' performance, and such improvement increases with the diversity of the users' resources. Quantitatively, it can reach an average 30% increase of the total served traffic for a typical scenario even with only six mobile users.","Internet,
Mobile communication,
IEEE 802.11 Standard,
Resource management,
NIST,
Mobile computing,
Batteries"
CACheck: Detecting and Repairing Cell Arrays in Spreadsheets,"Spreadsheets are widely used by end users for numerical computation in their business. Spreadsheet cells whose computation is subject to the same semantics are often clustered in a row or column as a cell array. When a spreadsheet evolves, the cells in a cell array can degenerate due to ad hoc modifications. Such degenerated cell arrays no longer keep cells prescribing the same computational semantics, and are said to exhibit ambiguous computation smells. We propose CACheck, a novel technique that automatically detects and repairs smelly cell arrays by recovering their intended computational semantics. Our empirical study on the EUSES and Enron corpora finds that such smelly cell arrays are common. Our study also suggests that CACheck is useful for detecting and repairing real spreadsheet problems caused by smelly cell arrays. Compared with our previous work AmCheck, CACheck detects smelly cell arrays with higher precision and recall rate.","Semantics,
Maintenance engineering,
Software,
Computer science,
Nonhomogeneous media,
Electronic mail,
Business"
Test Problems for Large-Scale Multiobjective and Many-Objective Optimization,"The interests in multiobjective and many-objective optimization have been rapidly increasing in the evolutionary computation community. However, most studies on multiobjective and many-objective optimization are limited to small-scale problems, despite the fact that many real-world multiobjective and many-objective optimization problems may involve a large number of decision variables. As has been evident in the history of evolutionary optimization, the development of evolutionary algorithms (EAs) for solving a particular type of optimization problems has undergone a co-evolution with the development of test problems. To promote the research on large-scale multiobjective and many-objective optimization, we propose a set of generic test problems based on design principles widely used in the literature of multiobjective and many-objective optimization. In order for the test problems to be able to reflect challenges in real-world applications, we consider mixed separability between decision variables and nonuniform correlation between decision variables and objective functions. To assess the proposed test problems, six representative evolutionary multiobjective and many-objective EAs are tested on the proposed test problems. Our empirical results indicate that although the compared algorithms exhibit slightly different capabilities in dealing with the challenges in the test problems, none of them are able to efficiently solve these optimization problems, calling for the need for developing new EAs dedicated to large-scale multiobjective and many-objective optimization.","Linear programming,
Pareto optimization,
Evolutionary computation,
Testing,
Benchmark testing"
Sparse Graph Regularization for Hyperspectral Remote Sensing Image Classification,"Regularization has appeared explicitly in hyperspectral image (HSI) classification community, which serves as a promising paradigm for leveraging labeled and unlabeled information, computer's automation and user's interaction, spectral and spatial information, and so on. Graph-based regularization is capable of modeling the nonlinear structures embedded in high-dimensional space, with the great potential for HSI classification. However, traditional methods exhibit low capacity when facing noisy and large-scale data, thus posing a big challenge for their successful use in this community. In this paper, we present two novel sparse graph regularization methods, SGR and SGR with total variation (TV-SGR). In SGR, the labels of large unknown data are propagated based on the fraction matrix and the prediction function, where the fraction matrix is obtained using an effective sparse representation (SR) algorithm with respect to the dictionary, and the prediction function is estimated by optimizing a typical graph-based regularization problem. In contrast, TV-SGR is an extension of SGR by considering spatial information modeled by total variation in SR. Propagating the prediction function from dictionary to large unknown data using the fraction matrix is the essence of the paradigm. SGR and TV-SGR can be equipped with semisupervised learning, active learning, and spectral-spatial classification with large flexibility. The experimental results with two popular hyperspectral data sets indicate that the proposed methods outperform some state-of-the-art approaches in terms of computational efficacy, classification accuracy, and robustness to noise.","Hyperspectral imaging,
Sparse matrices,
Support vector machines,
Dictionaries,
Laplace equations"
A Survey on Non-Orthogonal Multiple Access for 5G Networks: Research Challenges and Future Trends,"Non-orthogonal multiple access (NOMA) is an essential enabling technology for the fifth-generation (5G) wireless networks to meet the heterogeneous demands on low latency, high reliability, massive connectivity, improved fairness, and high throughput. The key idea behind NOMA is to serve multiple users in the same resource block, such as a time slot, subcarrier, or spreading code. The NOMA principle is a general framework, and several recently proposed 5G multiple access schemes can be viewed as special cases. This survey provides an overview of the latest NOMA research and innovations as well as their applications. Thereby, the papers published in this special issue are put into the context of the existing literature. Future research challenges regarding NOMA in 5G and beyond are also discussed.","NOMA,
5G mobile communication,
Quality of service,
Resource management,
Millimeter wave communication,
MIMO,
Cognitive radio"
A 6.78-MHz Single-Stage Wireless Power Receiver Using a 3-Mode Reconfigurable Resonant Regulating Rectifier,"A 6.78-MHz wireless power receiver using a 3-mode reconfigurable resonant regulating rectifier for resonant wireless power transfer is presented. The proposed receiver improves power conversion efficiency and reduces die area and off-chip components by achieving power conversion plus voltage regulation in one stage, using only four on-chip power transistors and one off-chip capacitor. Moreover, the proposed 3-mode operation reduces the output voltage ripples and accomplishes switching synchronization easily during mode switching. The proposed pulsewidth modulation controller using ramp-stacking technique and type-II compensation achieves tight voltage regulation in the full loading range with fast transient responses. An adaptive sizing method is also employed to further improve the light-load efficiency of the receiver. Fabricated in a standard 0.35-μm CMOS process using 5-V devices, the receiver regulates the output voltage at 5 V and delivers a maximum power of 6 W. The measured peak efficiency reaches 92.2% when delivering an output power of 3.5 W. For a load step between 0.5 and 5 W, the overshoot and undershoot are less than 300 mV and the settling times are less than 16 μs.","Receivers,
Voltage control,
Switches,
Wireless communication,
Capacitors,
Power conversion,
Power transistors"
SociRank: Identifying and Ranking Prevalent News Topics Using Social Media Factors,"Mass media sources, specifically the news media, have traditionally informed us of daily events. In modern times, social media services such as Twitter provide an enormous amount of user-generated data, which have great potential to contain informative news-related content. For these resources to be useful, we must find a way to filter noise and only capture the content that, based on its similarity to the news media, is considered valuable. However, even after noise is removed, information overload may still exist in the remaining data-hence, it is convenient to prioritize it for consumption. To achieve prioritization, information must be ranked in order of estimated importance considering three factors. First, the temporal prevalence of a particular topic in the news media is a factor of importance, and can be considered the media focus (MF) of a topic. Second, the temporal prevalence of the topic in social media indicates its user attention (UA). Last, the interaction between the social media users who mention this topic indicates the strength of the community discussing it, and can be regarded as the user interaction (UI) toward the topic. We propose an unsupervised framework-SociRank-which identifies news topics prevalent in both social media and the news media, and then ranks them by relevance using their degrees of MF, UA, and UI. Our experiments show that SociRank improves the quality and variety of automatically identified news topics.","Media,
Twitter,
Entertainment industry,
Cybernetics,
Internet,
Feeds"
Heavy Ion Induced Degradation in SiC Schottky Diodes: Bias and Energy Deposition Dependence,Experimental results on ion-induced leakage current increase in 4H-SiC Schottky power diodes are presented. Monte Carlo and TCAD simulations show that degradation is due to the synergy between applied bias and ion energy deposition. This degradation is possibly related to thermal spot annealing at the metal semiconductor interface. This thermal annealing leads to an inhomogeneity of the Schottky barrier that could be responsible for the increase leakage current as a function of fluence.,
Super-Resolution Person Re-Identification With Semi-Coupled Low-Rank Discriminant Dictionary Learning,"Person re-identification has been widely studied due to its importance in surveillance and forensics applications. In practice, gallery images are high resolution (HR), while probe images are usually low resolution (LR) in the identification scenarios with large variation of illumination, weather, or quality of cameras. Person re-identification in this kind of scenarios, which we call super-resolution (SR) person re-identification, has not been well studied. In this paper, we propose a semi-coupled low-rank discriminant dictionary learning (SLD2L) approach for SR person re-identification task. With the HR and LR dictionary pair and mapping matrices learned from the features of HR and LR training images, SLD2L can convert the features of the LR probe images into HR features. To ensure that the converted features have favorable discriminative capability and the learned dictionaries can well characterize intrinsic feature spaces of the HR and LR images, we design a discriminant term and a low-rank regularization term for SLD2L. Moreover, considering that low resolution results in different degrees of loss for different types of visual appearance features, we propose a multi-view SLD2L (MVSLD2L) approach, which can learn the type-specific dictionary pair and mappings for each type of feature. Experimental results on multiple publicly available data sets demonstrate the effectiveness of our proposed approaches for the SR person re-identification task.","Dictionaries,
Image resolution,
Cameras,
Training,
Probes,
Measurement,
Image restoration"
Deep Direct Reinforcement Learning for Financial Signal Representation and Trading,"Can we train the computer to beat experienced traders for financial assert trading? In this paper, we try to address this challenge by introducing a recurrent deep neural network (NN) for real-time financial signal representation and trading. Our model is inspired by two biological-related learning concepts of deep learning (DL) and reinforcement learning (RL). In the framework, the DL part automatically senses the dynamic market condition for informative feature learning. Then, the RL module interacts with deep representations and makes trading decisions to accumulate the ultimate rewards in an unknown environment. The learning system is implemented in a complex NN that exhibits both the deep and recurrent structures. Hence, we propose a task-aware backpropagation through time method to cope with the gradient vanishing issue in deep training. The robustness of the neural system is verified on both the stock and the commodity future markets under broad testing conditions.",
Exploring Structural Consistency in Graph Regularized Joint Spectral-Spatial Sparse Coding for Hyperspectral Image Classification,"In hyperspectral image classification, both spectral and spatial data distributions are important in describing and identifying different materials and objects in the image. Furthermore, consistent spatial structures across bands can be useful in capturing inherent structural information of objects. These imply that three properties should be considered when reconstructing an image using sparse coding methods. First, the distribution of different ground objects leads to different coding coefficients across the spatial locations. Second, local spatial structures change slightly across bands due to different reflectance properties of various object materials. Finally and more importantly, some sort of structural consistency shall be enforced across bands to reflect the fact that the same object appears at the same spatial location in all bands of an image. Based on these considerations, we propose a novel joint spectral-spatial sparse coding model that explores structural consistency for hyperspectral image classification. For each band image, we adopt a sparse coding step to reconstruct the structures in the band image. This allows different dictionaries be generated to characterize the band-wise image variation. At the same time, we enforce the same coding coefficients at the same spatial location in different bands so as to maintain consistent structures across bands. To further promote the discriminating power of the model, we incorporate a graph Laplacian sparsity constraint into the model to ensure spectral consistency in the dictionary generation step. Experimental results show that the proposed method outperforms some state-of-the-art spectral-spatial sparse coding methods.","Feature extraction,
Dictionaries,
Encoding,
Hyperspectral imaging,
Image coding,
Image reconstruction"
Dielectric Resonator Metasurface for Dispersion Engineering,"We introduce a practical dielectric metasurface design for microwave frequencies. The metasurface is made of an array of dielectric resonators held together by dielectric connections thus avoiding the need of a mechanical support in the form of a dielectric slab and the spurious multiple reflections that such a slab would generate. The proposed design can be used either for broadband metasurface applications or monochromatic wave transformations. The capabilities of the concept to manipulate the transmission phase and amplitude of the metasurface are supported by the numerical and experimental results. Finally, a half-wave plate and a quarter-wave plate have been realized with the proposed concept.","Dielectrics,
Optical resonators,
Dispersion,
Resonant frequency,
Slabs,
Broadband communication,
Antennas"
A Passive Current Sharing Method With Common Inductor Multiphase LLC Resonant Converter,"In this paper, a new common inductor current sharing method is proposed for a multiphase LLC resonant converter for high-power applications. Automatic current sharing is achieved by using a common resonant inductor connecting the resonant inductors in each LLC phase in parallel. The current sharing performance of the proposed method is evaluated under first harmonic approximation (FHA) assumption. The proposed method can automatically share the primary resonant current and the load current for all phases without any additional circuit and control strategy. A 600-W two-phase LLC converter prototype based on the proposed method is built to verify the feasibility. Excellent current sharing performance (less than 0.5% current sharing error at full load) has been achieved.","Inductors,
Capacitors,
Magnetic resonance,
Stress,
Switches,
Inductance"
Towards Ontological Approach on Trust-Aware Ambient Services,"With various information sources (e.g., from IoT sensors to social media), it is difficult to provide users with trustworthy services in ambient environment. The aim of this paper is i) to design trust ontology for representing semantics of the ambient services and ii ) to compute trust measures among users by using a personalized trust ontology. In particular, given a large amount of data collected from ambient sensors, efficient trust computation and reasoning are required for the stability and reliability. Thereby, we propose trust ontology-based framework for deriving personalized ontologies for individual users according to their preference, perspective, and purpose. To evaluate the proposed model, we have figured out a method how the degree of trust is estimated based on the trust ontology. Furthermore, we have proved that the proposed method is reliable with a case study on a social media (Twitter) for a particular domain (restaurant).","Ontologies,
Twitter,
Semantics,
Tagging,
Context,
Sparse matrices"
Active hot spot cooling of GaN transistors with electric field enhanced jumping droplet condensation,"Mitigating heat generated by hot spots inside of power electronic devices is a formidable obstacle to further increases in power density. This paper presents the first demonstration of active cooling for hot spots via jumping droplet condensation. This newly discovered phase change cooling mechanism comprises 10 to 100 μm sized droplets leaping from a cold superhydrophobic surface onto a hot GaN transistor and efficiently transferring heat via evaporation. After discussing how electric fields can enhance this process, observations from cooling GaN transistors with this method are outlined. Experimental measurements demonstrate increased cooling rates and steerable heat transfer through the application of electric fields.","Gallium nitride,
Cooling,
Surface treatment,
Heat transfer,
Field effect transistors,
Surface impedance"
A General and Transformable Model Platform for Emerging Multi-Gate MOSFETs,"The complete general solution of nonlinear 1-D undoped Poisson's equation, in both Cartesian and cylindrical coordinates, is derived by employing a special variable transformation method. A general model platform for various types of emerging multi-gate MOSFETs is further constructed and verified with TCAD simulations. It is shown that this model platform is suitable for analyzing a series of emerging devices, such as double-surrounding-gate, inner-surrounding-gate, and outer-surrounding-gate nanoshell MOSFETs, all of which require different boundary conditions from the conventional gate-all-around nanowire device.","MOSFET,
Mathematical model,
Semiconductor device modeling,
Boundary conditions,
Nanoscale devices,
Gallium arsenide,
Logic gates"
Quaternionic Weber Local Descriptor of Color Images,"This paper proposes a simple but effective framework named quaternionic Weber local descriptor (QWLD) for color image feature extraction. Integrating quaternionic representation (QR) of the color image and Weber's law (WL), QWLD possesses both their superiorities. It uses QR to handle all color channels of the image in a holistic way while preserving their relations, and applies WL to ensure that the derived descriptors are robust and discriminative. Using the QWLD framework, we further develop the quaternionic-increment-based Weber descriptor and quaternionic-distance-based Weber descriptor in terms of different perspectives. Extensive experiments on different color image recognition problems demonstrate that the proposed framework and descriptors outperform state-of-the-art local descriptors.","Quaternions,
Color,
Feature extraction,
Image color analysis,
Robustness,
Algebra,
Gray-scale"
Low-Complexity Modeling of Partially Available Second-Order Statistics: Theory and an Efficient Matrix Completion Algorithm,"State statistics of linear systems satisfy certain structural constraints that arise from the underlying dynamics and the directionality of input disturbances. In the present paper, we study the problem of completing partially known state statistics. Our aim is to develop tools that can be used in the context of control-oriented modeling of large-scale dynamical systems. For the type of applications we have in mind, the dynamical interaction between state variables is known while the directionality and dynamics of input excitation is often uncertain. Thus, the goal of the mathematical problem that we formulate is to identify the dynamics and directionality of input excitation in order to explain and complete observed sample statistics. More specifically, we seek to explain correlation data with the least number of possible input disturbance channels. We formulate this inverse problem as rank minimization, and for its solution, we employ a convex relaxation based on the nuclear norm. The resulting optimization problem is cast as a semidefinite program and can be solved using general-purpose solvers. For problem sizes that these solvers cannot handle, we develop a customized alternating minimization algorithm (AMA). We interpret AMA as a proximal gradient for the dual problem and prove sublinear convergence for the algorithm with fixed step-size. We conclude with an example that illustrates the utility of our modeling and optimization framework and draw contrast between AMA and the commonly used alternating direction method of multipliers (ADMM) algorithm.","Stochastic processes,
Mathematical model,
Linear systems,
Covariance matrices,
Optimization,
Steady-state,
Heuristic algorithms"
Robust Sampled-Data Output Synchronization of Nonlinear Heterogeneous Multi-Agents,"The note studies the synchronization problem of a class of nonlinear heterogeneous multiple agents with distributed sampled-data controllers. Through the design of a group of reference models, the synchronization problem reduces to a perturbed output regulation problem for each individual agent. The perturbed output regulation problem aims to achieve reference tracking in the presence of constant unknown system parameters, where the references are generated by a non-autonomous exosystem with external perturbation. A dynamic sampled-data controller with a sampled-data internal model is proposed for the perturbed output regulation problem. An asymptotic bound on the tracking error as a function of the perturbation's magnitude and sampling period is derived.","Synchronization,
Robustness,
Emulation,
Multi-agent systems,
Nonlinear systems,
Trajectory,
Network topology"
DC-30 GHz DPDT Switch Matrix Design in High Resistivity Trap-Rich SOI,"This paper presents low insertion loss, high isolation, ultra-wideband double-pole-double-throw (DPDT) switch matrix designed in a 0.13-μm commercial high resistivity trap-rich silicon-on-insulator (SOI) CMOS process for the first time. The switches are designed using series-shunt-series configuration in a ring-type structure with input and output matching networks. Transistor width and transistor channel length effects on the wideband DPDT switch performance are thoroughly investigated. The designed switches achieve widest bandwidth from dc to 30 GHz with a low insertion loss of 2.5 dB and a high isolation of 32 dB up to 30 GHz. The measured input P1dB of designed switches is higher than 18 dBm. It was found both second and third harmonics can be improved by widening switch transistor channel width, and third harmonic can be improved by shortening channel length. The active chip area of designed 2 × 2 switch matrix is very small size of only 0.28 mm × 0.21 mm.","Switches,
Transistors,
Switching circuits,
Loss measurement,
Ports (Computers),
Insertion loss,
Logic gates"
MitoGen: A Framework for Generating 3D Synthetic Time-Lapse Sequences of Cell Populations in Fluorescence Microscopy,"The proper analysis of biological microscopy images is an important and complex task. Therefore, it requires verification of all steps involved in the process, including image segmentation and tracking algorithms. It is generally better to verify algorithms with computer-generated ground truth datasets, which, compared to manually annotated data, nowadays have reached high quality and can be produced in large quantities even for 3D time-lapse image sequences. Here, we propose a novel framework, called MitoGen, which is capable of generating ground truth datasets with fully 3D time-lapse sequences of synthetic fluorescence-stained cell populations. MitoGen shows biologically justified cell motility, shape and texture changes as well as cell divisions. Standard fluorescence microscopy phenomena such as photobleaching, blur with real point spread function (PSF), and several types of noise, are simulated to obtain realistic images. The MitoGen framework is scalable in both space and time. MitoGen generates visually plausible data that shows good agreement with real data in terms of image descriptors and mean square displacement (MSD) trajectory analysis. Additionally, it is also shown in this paper that four publicly available segmentation and tracking algorithms exhibit similar performance on both real and MitoGen-generated data. The implementation of MitoGen is freely available.","Microscopy,
Three-dimensional displays,
Shape,
Computational modeling,
Algorithm design and analysis,
Sociology,
Statistics"
Big Data Analytics for System Stability Evaluation Strategy in the Energy Internet,"With the significant improvements in the Energy Internet, we have witnessed the explosion of multisource energy big data, whose characteristics of vast volume, fast velocity, and diverse variety not only formulate an essential infrastructure of the Energy Internet, but also bring threats to the system's stability. In this paper, we concern with the system-level stability issues in the Energy Internet and study how to maintain a stable and healthy energy network environment. To this end, we propose a system-level stability evaluation model in the Energy Internet based on a critical energy function to explore small disturbance stability region (SDSR), where SDSR can be acquired via estimating the operational data threshold of distributed generations. The threshold is estimated based on energy consumption rather than equilibrium nodes, which applies the energy function theory and reduces the computation complexity. Moreover, in our proposed model, we add the big data approximate analytics algorithm into hyperplane fitting to optimize and analyze the SDSR. Simulation results on SDSR in a single dominant oscillation mode and multiple dominant oscillation mode have demonstrated the advantages and superiority of our proposed method over the prior schemes.","Stability analysis,
Big Data,
Power system stability,
Internet,
Analytical models,
Mathematical model,
Computational modeling"
Recursive Geometric Simplex Growing Analysis for Finding Endmembers in Hyperspectral Imagery,"Simplex growing algorithm (SGA) is an endmember finding algorithm which searches for endmembers one after another by growing simplexes one vertex at a time via maximizing simplex volume (SV). Unfortunately, several issues arise in calculating SV. One is the use of dimensionality reduction (DR) because the dimensionality of a simplex is usually much smaller than data dimensionality. Second, calculating SV requires calculating the determinant of an ill-ranked matrix in which case singular value decomposition (SVD) is generally required to perform DR. Both approaches generally do not produce true SV. Finally, the computing time becomes excessive and numerically instable as the number of endmembers grows. This paper develops a new theory, called geometric simplex growing analysis (GSGA), to resolve these issues. It can be considered as an alternative to SGA from a rather different point of view. More specifically, GSGA looks into the geometric structures of a simplex whose volume can be actually calculated by multiplication of its base and height. As a result, it converts calculating maximal SV to finding maximal orthogonal projection as its maximal height becomes perpendicular to its base. To facilitate GSGA in practical applications, GSGA is further used to extend SGA to recursive geometric simplex growing algorithm (RGSGA) which allows GSGA to be implemented recursively in a similar manner that a Kalman filter does. Consequently, RGSGA can be very easily implemented with significant saving of computing time. Best of all, RGSGA is also shown to be most efficient and effective among all SGA-based variants.","Algorithm design and analysis,
Hyperspectral imaging,
Matrix decomposition,
Computer science,
Earth,
Singular value decomposition"
From Fall Detection to Fall Prevention: A Generic Classification of Fall-Related Systems,"Falls are a major health problem for the frail community dwelling old people. For more than two decades, falls have been extensively investigated by medical institutions to mitigate their impact (e.g., lack of independence and fear of falling) and minimize their consequences (e.g., cost of hospitalization and so on). However, the problem of elderly falling does not only concern health-professionals but has also drawn the interest of the scientific community. In fact, falls have been the object of many research studies and the purpose of many commercial products from academia and industry. These studies have tackled the problem using fall detection approaches exhausting a variety of sensing methods. Lately, researcher has shifted their efforts to fall prevention where falls might be spotted before they even happen. Despite their restriction to clinical studies, early fall prediction systems have started to emerge. At the same time, current reviews in this field lack a common ground classification. In this context, the main contribution of this paper is to give a comprehensive overview on elderly falls and to propose a generic classification of fall-related systems based on their sensor deployment. An extensive research scheme from fall detection to fall prevention systems have also been conducted based on this common ground classification. Data processing techniques in both fall detection and fall prevention tracks are also highlighted. The objective of this paper is to deliver medical technologists in the field of public health a good position regarding fall-related systems.",
Performance Analysis of Dual-Hop MIMO AF Relaying Network With Multiple Interferences,"In this paper, we investigate the performance of a dual-hop multiple-input-multiple-output (MIMO) amplify-and-forward (AF) relay network, where the source, relay, and destination are all equipped with multiple antennas. By using maximum ratio transmission (MRT) at the transmitter and maximum ratio combining (MRC) at the receiver, we first obtain the output signal-to-interference-plus-noise ratio (SINR) of the dual-hop AF relay system, considering multiple cochannel interferences (CCIs), as well as noise at the relay. Then, we derive an exact closed-form expression for the outage probability (OP), and the asymptotic result of OP at high SNR, which can be used to calculate the array gain and diversity order. Finally, computer simulations are conducted to validate the performance analysis. Our new analytical expressions not only provide a fast and efficient method to evaluate the system performance but enable us to gain valuable insights into the effects of key parameters on the MIMO AF relaying network performance that benefits from implementing multiple antennas at each of the three nodes as well.",
Designing Graphene-Based Absorber by Using HIE-FDTD Method,"A hybrid implicit explicit-finite-difference time-domain (HIE-FDTD) method is used to simulate a graphene-based absorber. Both the interband conductivity and intraband conductivity of the graphene are incorporated into the HIE-FDTD method directly through an auxiliary difference equation. Because the time step size in the proposed method is not confined by the fine spatial cells in the graphene layer, the simulation time of the proposed method is greatly reduced compared with that of the conventional FDTD method. By using the proposed HIE-FDTD method, a graphene-based absorber is simulated and analyzed. The numerical result shows that the operating frequency of the absorber is tunable through controlling graphene's chemical potential. It also shows that the interband conductivity has an important effect on the performance of the graphene device, especially at the frequency band larger than 10 THz.","Conductivity,
Graphene,
Finite difference methods,
Time-domain analysis,
Difference equations,
Chemicals,
Fitting"
FN-TOPSIS: Fuzzy Networks for Ranking Traded Equities,"Fuzzy systems consisting of networked rule bases, called fuzzy networks, capture various types of imprecision inherent in financial data and in the decision-making processes on them. This paper introduces a novel extension of the technique for ordering of preference by similarity to ideal solution (TOPSIS) method and uses fuzzy networks to solve multicriteria decision-making problems where both benefit and cost criteria are presented as subsystems. Thus, the decision maker evaluates the performance of each alternative for portfolio optimization and further observes the performance for both benefit and cost criteria. This approach improves significantly the transparency of the TOPSIS methods, while ensuring high effectiveness in comparison with established approaches. The proposed method is further tested to solve the problem of selection/ranking of traded equity covering developed and emergent financial markets. The ranking produced by the method is validated using Spearman rho rank correlation. Based on the case study, the proposed method outperforms the existing TOPSIS approaches in terms of ranking performance.","Decision making,
Fuzzy systems,
Uncertainty,
Fuzzy sets,
Reliability,
Gold,
Portfolios"
Functional Model-Based Design Methodology for Automotive Cyber-Physical Systems,"The high complexity of cross-domain engineering in combination with the pressure for system innovation, higher quality, time to market, and budget constraints makes it imperative for automotive companies to use integrated engineering methods and tools. Computer engineering tools are mainly focused on a particular domain, and therefore, it is difficult to integrate different tools for system-level analysis. In this paper, a novel multidisciplinary systems engineering methodology and associated design automation algorithms for the complex automotive cyber-physical systems are presented. Rather than starting from the domain-specific architecture/simulation models where most resources are spent, we preemptively target the early design stage at the functional level that determines 75% of an automobile's cost. In our methodology, the marriage of systems engineering principles with high-level synthesis techniques from design automation area results in a functional modeling compiler capable of generating high-fidelity simulation models for the design space exploration and validation of multiple cyber-physical automotive architectures. Using real-world automotive use cases, we demonstrate how functional models capturing integrated cyber-physical aspects are synthesized into high-fidelity multidomain simulation models.","Automotive engineering,
Biological system modeling,
Mathematical model,
Context modeling,
Algorithm design and analysis,
Computer architecture"
A Nonhomogeneous Cuckoo Search Algorithm Based on Quantum Mechanism for Real Parameter Optimization,"Cuckoo search (CS) algorithm is a nature-inspired search algorithm, in which all the individuals have identical search behaviors. However, this simple homogeneous search behavior is not always optimal to find the potential solution to a special problem, and it may trap the individuals into local regions leading to premature convergence. To overcome the drawback, this paper presents a new variant of CS algorithm with nonhomogeneous search strategies based on quantum mechanism to enhance search ability of the classical CS algorithm. Featured contributions in this paper include: 1) quantum-based strategy is developed for nonhomogeneous update laws and 2) we, for the first time, present a set of theoretical analyses on CS algorithm as well as the proposed algorithm, respectively, and conclude a set of parameter boundaries guaranteeing the convergence of the CS algorithm and the proposed algorithm. On 24 benchmark functions, we compare our method with five existing CS-based methods and other ten state-of-the-art algorithms. The numerical results demonstrate that the proposed algorithm is significantly better than the original CS algorithm and the rest of compared methods according to two nonparametric tests.","Algorithm design and analysis,
Optimization,
Birds,
Convergence,
Software algorithms,
Wave functions,
Pattern recognition"
Efficient and Confidentiality-Preserving Content-Based Publish/Subscribe with Prefiltering,"Content-based publish/subscribe provides a loosely-coupled and expressive form of communication for large-scale distributed systems. Confidentiality is a major challenge for publish/subscribe middleware deployed over multiple administrative domains. Encrypted matching allows confidentiality-preserving content-based filtering but has high performance overheads. It may also prevent the use of classical optimizations based on subscriptions containment. We propose a support mechanism that reduces the cost of encrypted matching, in the form of a prefiltering operator using Bloom filters and simple randomization techniques. This operator greatly reduces the amount of encrypted subscriptions that must be matched against incoming encrypted publications. It leverages subscription containment information when available, but also ensures that containment confidentiality is preserved otherwise. We propose containment obfuscation techniques and provide a rigorous security analysis of the information leaked by Bloom filters in this case. We conduct a thorough experimental evaluation of prefiltering under a large variety of workloads. Our results indicate that prefiltering is successful at reducing the space of subscriptions to be tested in all cases. We show that while there is a tradeoff between prefiltering efficiency and information leakage when using containment obfuscation, it is practically possible to obtain good prefiltering performance while securing the technique against potential leakages.","Subscriptions,
Cryptography,
Containers,
Arrays,
Cloud computing"
Maximum a Posterior and Perceptually Motivated Reconstruction Algorithm: A Generic Framework,"Most of the existing image reconstruction algorithms are application specific, and have generalization issues due to the need for parameter tuning and an unknown level of signal distortion. Addressing these problems, in this paper, we propose an efficient perceptually motivated and maximum a posterior (MAP)-based generic framework for image reconstruction. This can be applied to several image/video processing applications, where there is a necessity to improve reconstruction accuracy and suppress visible artifacts, such as denoising, deinterlacing, interpolation, de-blocking of Jpeg/Jpeg-2000, and demosaicing. The gradient magnitudes are noise insensitive to a moderate levels of noise and we propose to utilize this property for finding pixels with similar edge semantics in the neighborhood when neighboring pixels are noisy. With this view, we incorporate the gradient magnitude similarity based image quality assessment metric with the MAP estimation and, in turn, it can better approximate the variance of the MAP, as compared to nonlinear filters. The proposed generic algorithm (without manually tuning any parameters) is shown to produce a better quality of reconstruction when compared to the state-of-the-art application-specific algorithms, for most of the image processing applications.","Image reconstruction,
Measurement,
Nonlinear distortion,
Image restoration,
Image edge detection,
Interpolation"
A Convolutional Neural Network for Automatic Characterization of Plaque Composition in Carotid Ultrasound,"Characterization of carotid plaque composition, more specifically the amount of lipid core, fibrous tissue, and calcified tissue, is an important task for the identification of plaques that are prone to rupture, and thus for early risk estimation of cardiovascular and cerebrovascular events. Due to its low costs and wide availability, carotid ultrasound has the potential to become the modality of choice for plaque characterization in clinical practice. However, its significant image noise, coupled with the small size of the plaques and their complex appearance, makes it difficult for automated techniques to discriminate between the different plaque constituents. In this paper, we propose to address this challenging problem by exploiting the unique capabilities of the emerging deep learning framework. More specifically, and unlike existing works which require a priori definition of specific imaging features or thresholding values, we propose to build a convolutional neural network (CNN) that will automatically extract from the images the information that is optimal for the identification of the different plaque constituents. We used approximately 90 000 patches extracted from a database of images and corresponding expert plaque characterizations to train and to validate the proposed CNN. The results of cross-validation experiments show a correlation of about 0.90 with the clinical assessment for the estimation of lipid core, fibrous cap, and calcified tissue areas, indicating the potential of deep learning for the challenging task of automatic characterization of plaque composition in carotid ultrasound.",
Detecting Deceptive Behavior via Integration of Discriminative Features From Multiple Modalities,"Deception detection has received an increasing amount of attention in recent years, due to the significant growth of digital media, as well as increased ethical and security concerns. Earlier approaches to deception detection were mainly focused on law enforcement applications and relied on polygraph tests, which had proved to falsely accuse the innocent and free the guilty in multiple cases. In this paper, we explore a multimodal deception detection approach that relies on a novel data set of 149 multimodal recordings, and integrates multiple physiological, linguistic, and thermal features. We test the system on different domains, to measure its effectiveness and determine its limitations. We also perform feature analysis using a decision tree model, to gain insights into the features that are most effective in detecting deceit. Our experimental results indicate that our multimodal approach is a promising step toward creating a feasible, non-invasive, and fully automated deception detection system.","Feature extraction,
Physiology,
Face,
Pragmatics,
Sensors,
Cameras,
Visualization"
Role of H2O Molecules in Passivation Layer of a-InGaZnO Thin Film Transistors,"This letter analyzes performance and reliability of inverted staggered type amorphous indium-gallium-zinc oxide devices in a moist environment with H2O molecules in the passivation layer. There is a negative threshold voltage shift (Δ Vth) in the saturation region (VD = 10 V), which increases with decreasing channel length. We propose that this is explained by the drain-induced barrier lowering that is due to the H2O molecules. Moreover, a hydrogen bonding model under bias stress is also proposed, in contrast to the conventional H2O doping model. Recovery behavior after bias stress and ac operation were utilized to distinguish the difference between these models.","Water,
Degradation,
Passivation,
NIST,
Hydrogen,
Thin film transistors,
Stress"
Visual Tracking With Convolutional Random Vector Functional Link Network,"Deep neural network-based methods have recently achieved excellent performance in visual tracking task. As very few training samples are available in visual tracking task, those approaches rely heavily on extremely large auxiliary dataset such as ImageNet to pretrain the model. In order to address the discrepancy between the source domain (the auxiliary data) and the target domain (the object being tracked), they need to be finetuned during the tracking process. However, those methods suffer from sensitivity to the hyper-parameters such as learning rate, maximum number of epochs, size of mini-batch, and so on. Thus, it is worthy to investigate whether pretraining and fine tuning through conventional back-prop is essential for visual tracking. In this paper, we shed light on this line of research by proposing convolutional random vector functional link (CRVFL) neural network, which can be regarded as a marriage of the convolutional neural network and random vector functional link network, to simplify the visual tracking system. The parameters in the convolutional layer are randomly initialized and kept fixed. Only the parameters in the fully connected layer need to be learned. We further propose an elegant approach to update the tracker. In the widely used visual tracking benchmark, without any auxiliary data, a single CRVFL model achieves 79.0% with a threshold of 20 pixels for the precision plot. Moreover, an ensemble of CRVFL yields comparatively the best result of 86.3%.","Visualization,
Target tracking,
Biological neural networks,
Training,
Data models"
Reduced Active Switch Front-End Multipulse Rectifier With Medium-Frequency Transformer Isolation,"This paper presents a reduced switch count multipulse rectifier with medium-frequency (MF) transformer isolation. The proposed topology consists of a three-phase push-pull based ac to dc rectifier with a MF ac link employing two active switches. A three-phase, five-limb, multiwinding MF transformer is employed for isolation. The secondary side of the transformer is connected in a zig-zag configuration and is fed to two six-pulse diode rectifiers, achieving 12-pulse rectifier operation. The primary advantage of the proposed system is reduction in size/weight/volume compared to the conventional 60 Hz magnetic transformer isolation rectifier system. Operating the transformer at 600 Hz is shown to result in three times reduction in size. Furthermore, the proposed system employs only two active semiconductor switching devices operating under a simple pulse width modulation scheme. Also, the zig-zag transformer connection helps to balance leakage inductance on the secondary side. Detailed analysis, simulation, and experimental results on a 208Vl-l, 3.15 kW laboratory prototype are presented to validate the performance of the proposed approach.",
On Energy-Efficient Straight-Line Routing Protocol for Wireless Sensor Networks,"One of the limitations of a wireless sensor network (WSN) is its limited sensor node energy resource; this necessitates an energy-efficient routing protocol that maximizes the overall system performance. Rumor routing is a classic random-walk routing protocol that, unfortunately, is not scalable and can result in spiral paths. We consider that the shortest distance between two points is a straight line and that two straight lines in a plane are likely to intersect and develop for WSNs an improved protocol called straight-line routing (SLR), in which we construct a straight path using two-hop information without the assistance of geographic information. SLR thus reduces the energy consumption of sensor nodes in WSNs. We propose enhanced schemes to improve performance and conserve more energy and, with extensive simulation results, demonstrate the effectiveness of these SLR schemes in comparison with rumor routing.","Sensors,
Wireless sensor networks,
Routing protocols,
Global Positioning System,
Batteries,
Routing protocols"
Feasible Range and Optimal Value of the Virtual Impedance for Droop-Based Control of Microgrids,"This paper presents a systematic method to determine the feasible range and optimal value of the virtual impedance of the droop-based control to enhance a microgrid system performance with respect to power decoupling, reactive power sharing, system damping, and node voltage profile. A modified power flow analysis and an augmented small-signal dynamic model of the droop-based controlled microgrid, considering the impact of the virtual impedance, are developed. Subsequently, based on the developed methods, the feasible range of the virtual impedance, which can satisfy all the system performances requirements, is determined and presented. Based on a particle swarm optimization technique, an optimization process is introduced to select a virtual impedance value within the feasible range to achieve the overall optimal microgrid performance. Finally, simulation results in the PSCAD/EMTDC platform are provided to validate the feasibility and effectiveness of the proposed methods.",
Differential Ring Oscillator Based Capacitance Sensor for Microfluidic Applications,A simple high frequency capacitance sensor with 180 aF sensitivity is designed for a wide range of microfluidic applications. The sensor is implemented utilizing differential ring oscillators operating at ~240 MHz with a differential signal at ~20 MHz. The sensor occupies ~2 cm × 2 cm on a printed circuit board. The sensor is tuned using two precision variable capacitors and has a full scale range of ~1.5 pF. The sensor was able to detect less than 1% Isopropyl Alcohol in DI water and to detect 15 μm polystyrene spheres flowing over 25 μm lines and spaces coplanar electrodes in a microfluidic channel. The compact differential ring oscillator based architecture of the design makes it suitable to be integrated into microprocessor based systems for detection in Lab on Chip or Lab on Board applications.,"Capacitance,
Capacitors,
Microelectrodes,
Ring oscillators,
Printed circuits"
Quantum particle swarm optimization for multiobjective combined economic emission dispatch problem using cubic criterion function,"In this research, quantum particle swarm optimization (QPSO) is utilized to solve multiobjective combined economic emission dispatch (CEED) problem formulated using cubic criterion function considering a uni wise max/max price penalty factor. QPSO is implemented on a 6-unit power generation system and compared with Lagrangian relaxation, particle swarm optimization (PSO) and simulated annealing (SA). The obtained results verified the effectiveness and demonstrate the robustness of QPSO method. This research suggests that QPSO can be used as an effective and robust tool in other power dispatch problems.","Power generation,
Economics,
Mathematical model,
Convergence,
Particle swarm optimization,
Quantum computing,
Robustness"
Scheduling and Power Allocation for Hybrid Access Cognitive Femtocells,"This paper addresses the problem of resource and power allocation for hybrid access femtocells. We introduce a refund mechanism to incentivize femtocell basestations (FBSs) to serve macrocell users (MUEs) suffering from low signal to interference and noise ratio (SINR) to enhance overall performance. Our goal is to guarantee quality of service for users, while allowing spectrum sharing between macrocell basestation (MBS) and the underlying FBSs. We exploit overheard user channel quality indicator (CQI) reports using different channel models in order to assess the interfered channel state and channel parameter distribution. We analyze the distribution of the SINR for both femtocell users and MUEs. Based on the analytical results, our solution decomposes the scheduling and power allocation problem into two sub-problems and tackles them sequentially. Using problem reduction/transformation, we convert the decomposed problems into well known reduced forms and provide solutions in accordance. Finally, we verify the presented results through simulations.",
Statistical Anisotropy in Imperfect Electromagnetic Reverberation,"A probabilistic characterization is performed for a class of field anisotropy coefficients for local random electromagnetic fields. Isotropic stirring (ideal reverberation), anisotropic stirring (polarization bias), and incomplete stirring (line-of-sight coupling or direct illumination) are investigated individually. For small degrees of planar anisotropy or coupling, trapezoidal distributions are obtained, representing first-order departures from ideal rectangular distributions. Distributions for two definitions of total field anisotropy are found to be less sensitive than those for the individual planar anisotropies. The method and results are useful for the calibration and validation of reverberation chambers when field anisotropy requires a separate assessment. Theoretical results are compared to measured data in two chambers.","Anisotropic magnetoresistance,
Reverberation,
Probability density function,
Electromagnetics,
Probabilistic logic,
Reverberation chambers,
Standards"
Using Natural Language Processing to Automatically Detect Self-Admitted Technical Debt,"The metaphor of technical debt was introduced to express the trade off between productivity and quality, i.e., when developers take shortcuts or perform quick hacks. More recently, our work has shown that it is possible to detect technical debt using source code comments (i.e., self-admitted technical debt), and that the most common types of self-admitted technical debt are design and requirement debt. However, all approaches thus far heavily depend on the manual classification of source code comments. In this paper, we present an approach to automatically identify design and requirement self-admitted technical debt using Natural Language Processing (NLP). We study 10 open source projects: Ant, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JMeter, JRuby and SQuirrel SQL and find that 1) we are able to accurately identify self-admitted technical debt, significantly outperforming the current state-of-the-art based on fixed keywords and phrases; 2) words related to sloppy code or mediocre source code quality are the best indicators of design debt, whereas words related to the need to complete a partially implemented requirement in the future are the best indicators of requirement debt; and 3) we can achieve 90 percent of the best classification performance, using as little as 23 percent of the comments for both design and requirement self-admitted technical debt, and 80 percent of the best performance, using as little as 9 and 5 percent of the comments for design and requirement self-admitted technical debt, respectively. The last finding shows that the proposed approach can achieve a good accuracy even with a relatively small training dataset.","Software,
Natural language processing,
Manuals,
Entropy,
Unified modeling language,
Java,
Structured Query Language"
On the Optimality of Power Allocation for NOMA Downlinks With Individual QoS Constraints,"This letter investigates a power allocation problem in a downlink single-input single-output non-orthogonal multiple access (NOMA) system. Our goal is to maximize the sum rate of users subject to minimum user rate requirements. We rigorously prove the optimal user decoding order, and show that the sum rate maximization problem is convex, which guarantees the globally optimal solution. Numerical results validate the performance gain by the proposed NOMA compared with conventional schemes.","NOMA,
Resource management,
Downlink,
Decoding,
Quality of service,
Time division multiple access,
SISO"
A Game-Theoretic Framework for Network Coding Based Device-to-Device Communications,"This paper investigates the delay minimization problem for instantly decodable network coding (IDNC) based device-to-device (D2D) communications. In D2D enabled systems, users cooperate to recover all their missing packets. The paper proposes a game theoretic framework as a tool for improving the distributed solution by overcoming the need for a central controller or additional signaling in the system. The session is modeled by self-interested players in a non-cooperative potential game. The utility functions are designed so as increasing individual payoff results in a collective behavior which achieves both a desirable system performance in a shared network environment and the Nash equilibrium. Three games are developed whose first reduces the completion time, the second the maximum decoding delay and the third the sum decoding delay. The paper, further, improves the formulations by including a punishment policy upon collision occurrence so as to achieve the Nash bargaining solution. Learning algorithms are proposed for systems with complete and incomplete information, and for the imperfect feedback scenario. Numerical results suggest that the proposed game-theoretical formulation provides appreciable performance gain against the conventional point-to-multipoint (PMP), especially for reliable user-to-user channels.","Delays,
Decoding,
Network coding,
Games,
Minimization,
Reliability,
Electronic mail"
Channel Allocation for Adaptive Video Streaming in Vehicular Networks,"Video services in vehicular networks play an important role in future intelligent transportation systems and vehicular infotainment systems. Yet, at the presence of other services with high priorities, the remaining radio resources for video services are highly dynamic. To support video service of multiple vehicles in vehicular networks, we propose a joint channel allocation and adaptive video streaming algorithm that makes the vehicles compete for channel access opportunities and to request video data with a proper visual quality according to their utilities. A vehicle's request is determined by taking several key factors into consideration, including the location and the velocity of the vehicle, the activity of the high-priority services, the intensity of the competition among multiple vehicles, and the smoothness requirement of visual quality. Simulation results show that the proposed algorithm is superior to the existing algorithms in both interruption ratio and visual quality.","Vehicles,
Streaming media,
Channel allocation,
Visualization,
Vehicle dynamics,
Heuristic algorithms,
Dynamic scheduling"
Computational Intelligence in Music Composition: A Survey,"Composing music is an inspired yet challenging task, in that the process involves many considerations such as assigning pitches, determining rhythm, and arranging accompaniment. Algorithmic composition aims to develop algorithms for music composition. Recently, algorithmic composition using artificial intelligence technologies received considerable attention. In particular, computational intelligence is widely used and achieves promising results in the creation of music. This paper attempts to provide a survey on the computational intelligence techniques used in music composition. First, the existing approaches are reviewed in light of the major musical elements considered in composition, to wit, musical form, melody, and accompaniment. Second, the review highlights the components of evolutionary algorithms and neural networks designed for music composition.","Rhythm,
Neural networks,
Evolutionary computation,
Timbre,
Computers"
Relaxed Binaural LCMV Beamforming,"In this paper, we propose a new binaural beamforming technique, which can be seen as a relaxation of the linearly constrained minimum variance (LCMV) framework. The proposed method can achieve simultaneous noise reduction and exact binaural cue preservation of the target source, similar to the binaural minimum variance distortionless response (BMVDR) method. However, unlike BMVDR, the proposed method is also able to preserve the binaural cues of multiple interferers to a certain predefined accuracy. Specifically, it is able to control the trade-off between noise reduction and binaural cue preservation of the interferers by using a separate trade-off parameter per-interferer. Moreover, we provide a robust way of selecting these trade-off parameters in such a way that the preservation accuracy for the binaural cues of the interferers is always better than the corresponding ones of the BMVDR. The relaxation of the constraints in the proposed method achieves approximate binaural cue preservation of more interferers than other previously presented LCMV-based binaural beamforming methods that use strict equality constraints.","Noise reduction,
Microphones,
Speech,
Array signal processing,
Distortion,
Speech processing"
Enhancing GPS With Lane-Level Navigation to Facilitate Highway Driving,"Lane-level navigation has received a lot of attention in recent years. It has played a great role in assisting route planning, as well as navigating automated vehicles. Aside from sticking to the planned route, abnormal traffic situations which result in blocking lanes could impact lane switching decisions. Unfortunately, there is currently no navigation system that can sense and track a vehicle's lane position and to advise the driver of lane switching decisions. Google Maps stores a priori the number of lanes and their directions at each highway exit and provides this information to drivers when navigating. However, even with this information, some drivers may not be able to make an informed decision regarding when and where to make a correct lane switch. This motivated us to develop a mechanism for the detection and tracking of real-time lane changes. In this paper, we propose a GPS-aiding system that can sense and track a vehicle's lane position. The system leverages smart phones' computing capability, rear cameras, and inertial motion sensors. With little extra computational overhead, the system applies computer vision techniques to achieve lane-level positioning. We also design a machine learning-based algorithm to detect and track lane switching. We conduct a series of experiments, analyze our system in real-world environments, and achieve very promising results. We believe our system can be a great asset to current smart phone navigation systems.","Smart phones,
Global Positioning System,
Cameras,
Roads,
Sensors"
A Mean Field Game Computational Methodology for Decentralized Cellular Network Optimization,"In cellular communication networks, quality of service (QoS) is defined as the ratio of the user's signal level to the system noise plus other agents' signal interference levels, and is commonly used to measure the performance of a mobile user over the network. In this paper, Nash equilibrium strategies, which minimize a linear combination of the system QoS and the transmitted power in code division multiple access networks, are found via an application of mean field game (MFG) control theory. Computational investigations of decentralized cellular network optimization via the application of nonlinear MFG control theory to this class of problem are presented for downlink and uplink scenarios with uniform and nonuniform agent population with respect to localized and nonlocalized interferences.","Mathematical model,
Quality of service,
Interference,
Multiaccess communication,
Optimization,
Power control,
Games"
Hyperbolic Harmonic Mapping for Surface Registration,"Automatic computation of surface correspondence via harmonic map is an active research field in computer vision, computer graphics and computational geometry. It may help document and understand physical and biological phenomena and also has broad applications in biometrics, medical imaging and motion capture industries. Although numerous studies have been devoted to harmonic map research, limited progress has been made to compute a diffeomorphic harmonic map on general topology surfaces with landmark constraints. This work conquers this problem by changing the Riemannian metric on the target surface to a hyperbolic metric so that the harmonic mapping is guaranteed to be a diffeomorphism under landmark constraints. The computational algorithms are based on Ricci flow and nonlinear heat diffusion methods. The approach is general and robust. We employ our algorithm to study the constrained surface registration problem which applies to both computer vision and medical imaging applications. Experimental results demonstrate that, by changing the Riemannian metric, the registrations are always diffeomorphic and achieve relatively high performance when evaluated with some popular surface registration evaluation standards.","Harmonic analysis,
Measurement,
Topology,
Surface morphology,
Shape,
Isothermal processes,
Surface treatment"
On Joint BBU/RRH Resource Allocation in Heterogeneous Cloud-RANs,"Cloud radio access network (Cloud-RAN) is a promising wireless network architecture that can satisfy the fast growing mobile data traffic and improve the performance of Internet of Things. In this paper, we propose an energy-efficient resource allocation scheme based on heterogeneous Cloud-RAN jointly considering the remote radio head (RRH) antenna resource with baseband unit (BBU) computation resource. We formulate our joint resource allocation problem and decompose it into two subproblems. The first subproblem is a network-wide beamforming vectors optimization problem, and it is solved by weighted minimum mean square error approach. Based on the optimized beamforming vector, we propose an algorithm to get the RRH-user equipment clusters. The second subproblem is a BBU scheduling problem, and we reformulate it as a bin packing problem which aims to minimize the number of BBUs in working model to save more energy. Compared to some existed works which form the BBU scheduling problem as a bin packing problem, we propose a bin packing algorithm based on the best-fit-decreasing method, which has better performance. With simulation results and detailed analysis, the system performance of our proposed joint resource allocation scheme is verified, which is more energy-efficient than other existing schemes.","cloud computing,
data communication,
mean square error methods,
mobile computing,
mobile radio,
radio access networks,
resource allocation,
telecommunication scheduling"
Movement-Based Incentive for Crowdsourcing,"Most of the research on the incentive mechanism design in crowdsourcing has focused on how to allocate sensing tasks to participants to maximize the social welfare. However, none of them consider the coverage holes created by the uneven distribution of participants. As a result, most of the participants in some popular areas compete for tasks, while many tasks in unpopular areas cannot be completed due to the lack of participants. In this paper, we design a movement-based incentive mechanism for crowdsourcing, where participants are stimulated to move to the unpopular areas and complete the sensing tasks in these areas, which benefits both participants and the platform. We formulate a task allocation problem considering controlled mobility. Since the task allocation problem is NP-hard, we propose a greedy algorithm to solve it and design a critical payment policy to guarantee that participants declare their cost truthfully. Theoretical analysis shows that our proposed incentive mechanism satisfies the desired properties of truthfulness, individual rationality, platform profitability, and computational efficiency. Evaluation results show that the proposed movement-based incentive mechanism outperforms the existing solution under various conditions.","Sensors,
Crowdsourcing,
Cost function,
Resource management,
Smart phones,
Buildings,
Greedy algorithms"
Planar Miniaturized Balanced-to-Single-Ended Power Divider Based on Composite Left- and Right-Handed Transmission Lines,"A planar asymmetrical miniaturized circuit based on composite left- and right-handed transmission lines (CLRHTLs) is proposed to design a new balanced-to-single-ended (BTSE) power divider (PD) in this letter. The CLRHTLs are used to realize circuit miniaturization and positive-phase response. Conversion between the mixed-mode scattering parameters and the standard scattering parameters, and circuit analytical methods are discussed to realize the equal power division in phase from one differential input to two SE outputs. To verify the correctness of the proposed theory, a practical BTSE PD, which operates at 0.95 GHz, is designed and fabricated. The measured relative bandwidth is 26.3%, and the final circuit size is only 0.021λg2.","Scattering parameters,
Power dividers,
Impedance,
Wireless communication,
Ports (Computers),
Standards,
Circuit analysis"
Blockchain for IoT security and privacy: The case study of a smart home,"Internet of Things (IoT) security and privacy remain a major challenge, mainly due to the massive scale and distributed nature of IoT networks. Blockchain-based approaches provide decentralized security and privacy, yet they involve significant energy, delay, and computational overhead that is not suitable for most resource-constrained IoT devices. In our previous work, we presented a lightweight instantiation of a BC particularly geared for use in IoT by eliminating the Proof of Work (POW) and the concept of coins. Our approach was exemplified in a smart home setting and consists of three main tiers namely: cloud storage, overlay, and smart home. In this paper we delve deeper and outline the various core components and functions of the smart home tier. Each smart home is equipped with an always online, high resource device, known as “miner” that is responsible for handling all communication within and external to the home. The miner also preserves a private and secure BC, used for controlling and auditing communications. We show that our proposed BC-based smart home framework is secure by thoroughly analysing its security with respect to the fundamental security goals of confidentiality, integrity, and availability. Finally, we present simulation results to highlight that the overheads (in terms of traffic, processing time and energy consumption) introduced by our approach are insignificant relative to its security and privacy gains.","Smart homes,
Security,
Cloud computing,
Privacy,
Internet of Things,
Conferences,
Online banking"
Cost-Aware Streaming Workflow Allocation on Geo-Distributed Data Centers,"The virtual machine (VM) allocation problem in cloud computing has been widely studied in recent years, and many algorithms have been proposed in the literature. Most of them have been successfully applied to batch processing models such as MapReduce; however, none of them can be applied to streaming workflow well because of the following weaknesses: 1) failure to capture the characteristics of tasks in streaming workflow for the short life cycle of data streams; 2) most algorithms are based on the assumptions that the price of VMs and traffic among data centers (DCs) are static and fixed. In this paper, we propose a streaming workflow allocation algorithm that takes into consideration the characteristics of streaming work and the price diversity among geo-distributed DCs, to further achieve the goal of cost minimization for streaming big data processing. First, we construct an extended streaming workflow graph (ESWG) based on the task semantics of streaming workflow and the price diversity of geo-distributed DCs, and the streaming workflow allocation problem is formulated into mixed integer linear programming based on the ESWG. Second, we propose two heuristic algorithms to reduce the computational space based on task combination and DC combination in order to meet the strict latency requirement. Finally, our experimental results demonstrate significant performance gains with lower total cost and execution time.","Resource management,
Semantics,
Minimization,
Cloud computing,
Data models,
Big data,
Heuristic algorithms"
Predictive Set Point Modulation to Mitigate Transients in Lightly Damped Balanced and Unbalanced Systems,"Power system controllers are designed and tuned to achieve the desired dynamic performance under prespecified system conditions. However, changes in the system, e.g., load variation, generation changes, and faults, can cause departure of the system from previously assumed parameters. This in turn can change and reduce damping, which may enable large transients to violate the operational limits of a controlled apparatus. Set point automatic adjustment with correction enabled (SPAACE) is a strategy that modulates the set point of an apparatus to mitigate such transients. This paper 1) proposes a quadratic prediction algorithm for SPAACE to enhance its performance, 2) presents a supplemental strategy to improve set point tracking even when limits are not violated, 3) introduces an approach to implement SPAACE in unbalanced systems, and 4) analyzes the stability of SPAACE. Several case studies are presented to demonstrate the superior ability of this strategy for mitigating transients in different scenarios compared to conventional PI-based control strategies.","Transient analysis,
Power system stability,
Stability analysis,
Voltage control,
Control systems,
Prediction algorithms"
Motor Imagery Classification Based on Bilinear Sub-Manifold Learning of Symmetric Positive-Definite Matrices,"In motor imagery brain-computer interfaces (BCIs), the symmetric positive-definite (SPD) covariance matrices of electroencephalogram (EEG) signals carry important discriminative information. In this paper, we intend to classify motor imagery EEG signals by exploiting the fact that the space of SPD matrices endowed with Riemannian distance is a high-dimensional Riemannian manifold. To alleviate the overfitting and heavy computation problems associated with conventional classification methods on high-dimensional manifold, we propose a framework for intrinsic sub-manifold learning from a high-dimensional Riemannian manifold. Considering a special case of SPD space, a simple yet efficient bilinear sub-manifold learning (BSML) algorithm is derived to learn the intrinsic sub-manifold by identifying a bilinear mapping that maximizes the preservation of the local geometry and global structure of the original manifold. Two BSML-based classification algorithms are further proposed to classify the data on a learned intrinsic sub-manifold. Experimental evaluation of the classification of EEG revealed that the BSML method extracts the intrinsic sub-manifold approximately 5× faster and with higher classification accuracy compared with competing algorithms. The BSML also exhibited strong robustness against a small training dataset, which often occurs in BCI studies.","Manifolds,
Covariance matrices,
Symmetric matrices,
Electroencephalography,
Geometry,
Approximation algorithms,
Eigenvalues and eigenfunctions"
A Dual-Band Multiport MIMO Slot Antenna for WLAN Applications,"A novel compact dual-band multiple-input-multipleoutput (MIMO) antenna design for IEEE 802.11 applications is proposed. The antenna operates at 4.9-5.725 GHz with four ports and at 2.4-2.5 GHz with two ports and utilizes a dual-band dualport MIMO antenna to cover the 2.4/5-GHz bands alongside two single-band antennas to cover the 5-GHz band. This allows simultaneous operation at both WLAN frequencies while having only four ports in total. Isolation between ports is better than 12 dB and is achieved with no reconfigurable elements. The overall antenna size is compact, occupying 46 × 20 × 1.6 mm3, and is printed on an FR-4 printed circuit board. The proposed antenna is investigated by simulation and measurement, and results include radiation patterns, efficiency, S-parameters, signal correlations, and branch power ratios between ports. These show that in typical wireless environments, envelope cross correlations of less than 0.3 between the ports are obtained.","MIMO,
Slot antennas,
Antenna measurements,
Wireless LAN,
Dual band,
Ports (Computers)"
Quality of Service Oriented Access Point Selection Framework for Large Wi-Fi Networks,"This paper addresses the problem of access point (AP) selection in large Wi-Fi networks. Unlike current solutions that rely on received signal strength to determine the best AP that could serve a wireless user's request, we propose a novel framework that considers the quality of service (QoS) requirements of the user's data flow. The proposed framework relies on a function reflecting the suitability of a Wi-Fi AP to satisfy the QoS requirements of the data flow. The framework takes advantage of the flexibility and centralised nature of software defined networking (SDN). A performance comparison of this algorithm developed through an SDN-based simulator shows significant achievements against other state-of-the-art solutions in terms of provided QoS and improved wireless network capacity.","IEEE 802.11 Standard,
Measurement,
Quality of service,
Wireless communication,
Throughput,
Algorithm design and analysis"
Towards a Trust Prediction Framework for Cloud Services Based on PSO-Driven Neural Network,"Trustworthiness is an important indicator for service selection and recommendation in the cloud environment. However, predicting the trust rate of a cloud service based on its multifaceted quality of services (QoSs) is not an easy task due to the complicated and non-linear relations between service's QoS values and the final trust rate of the service. According to the existing studies, the adoption of intelligent technique is a rational way to attack this problem. Neural network (NN) has been validated as an effective way to predict the trust rate of the service. However, the parameter setting of NN, which plays an important role in its prediction performance, has not been properly addressed yet. In the paper, particle swarm optimization (PSO) is introduced to enhance NN by optimizing its initial settings. In the proposed hybrid prediction algorithm named PSO-NN, PSO is used to search the appropriate parameters for NN so as to realize accurate trust prediction of cloud services. In order to investigate the effectiveness of PSO-NN, extensive experiments are performed based on public QoS data set, as well as in-depth comparison analysis. The results show that our proposed approach has better performance than basic classification methods in most cases, and significantly outperforms the basic NN in the terms of prediction precision. In addition, PSO-NN demonstrates better stability than the basic NN.",
Online Multi-Task Learning Framework for Ensemble Forecasting,"Ensemble forecasting is a widely-used numerical prediction method for modeling the evolution of nonlinear dynamic systems. To predict the future state of such systems, a set of ensemble member forecasts is generated from multiple runs of computer models, where each run is obtained by perturbing the starting condition or using a different model representation of the system. The ensemble mean or median is typically chosen as a point estimate for the ensemble member forecasts. These approaches are limited in that they assume each ensemble member is equally skillful and may not preserve the temporal autocorrelation of the predicted time series. To overcome these limitations, we present an online multi-task learning framework called ORION to estimate the optimal weights for combining the ensemble member forecasts. Unlike other existing formulations, the proposed framework is novel in that its learning algorithm must backtrack and revise its previous forecasts before making future predictions if the earlier forecasts were incorrect when verified against new observation data. We termed this strategy as online learning with restart. Our proposed framework employs a graph Laplacian regularizer to ensure consistency of the predicted time series. It can also accommodate different types of loss functions, including ϵ-insensitive and quantile loss functions, the latter of which is particularly useful for extreme value prediction. A theoretical proof demonstrating the convergence of our algorithm is also given. Experimental results on seasonal soil moisture forecasts from 12 major river basins in North America demonstrate the superiority of ORION compared to other baseline algorithms.","Predictive models,
Forecasting,
Time series analysis,
Computational modeling,
Prediction algorithms,
Data models,
Numerical models"
On the Complexity of Duplication-Transfer-Loss Reconciliation with Non-Binary Gene Trees,"Duplication-Transfer-Loss (DTL) reconciliation has emerged as a powerful technique for studying gene family evolution in the presence of horizontal gene transfer. DTL reconciliation takes as input a gene family phylogeny and the corresponding species phylogeny, and reconciles the two by postulating speciation, gene duplication, horizontal gene transfer, and gene loss events. Efficient algorithms exist for finding optimal DTL reconciliations when the gene tree is binary. However, gene trees are frequently non-binary. With such non-binary gene trees, the reconciliation problem seeks to find a binary resolution of the gene tree that minimizes the reconciliation cost. Given the prevalence of non-binary gene trees, many efficient algorithms have been developed for this problem in the context of the simpler Duplication-Loss (DL) reconciliation model. Yet, no efficient algorithms exist for DTL reconciliation with non-binary gene trees and the complexity of the problem remains unknown. In this work, we resolve this open question by showing that the problem is, in fact, NP-hard. Our reduction applies to both the dated and undated formulations of DTL reconciliation. By resolving this long-standing open problem, this work will spur the development of both exact and heuristic algorithms for this important problem.","Vegetation,
Complexity theory,
Context,
Genomics,
Bioinformatics,
Evolution (biology)"
Delay and Power Evaluation of Negative Capacitance Ferroelectric MOSFET Based on SPICE Model,"The current evaluation on negative capacitance ferroelectric MOSFET (NC-FeFET) mostly reports device-level current/capacitance-voltage prediction and approaches with ease of integration in SPICE for circuit level performance prediction are very limited. For benchmarking against intrinsic MOSFET and beyond-CMOS devices, a new Landau-Khalatnikov theory-based SPICE model of ferroelectric is presented as a series connection of a voltage controlled voltage source and a resistor. It predicts both static and dynamic behaviors by including ferroelectric damping constant. Integration of this ferroelectric model with BSIM4 model of 45-nm CMOS technology allows prediction of circuit-level performance of NC-FeEFT. In current-voltage characteristics, both subthreshold swing and off-state current are reduced compared with intrinsic MOSFET. For an inverter chain, different values of damping constants give rise to a wide range of propagation delays and power consumptions. Only NC-FeFET using sufficiently low damping constant ferroelectric with similar response time to intrinsic MOSFET can be considered as a low-power device with a similar propagation delay. In this case, its dynamic power is suppressed by the same proportion as that of internal voltage amplification and static leakage power also drops. Our results reveal the ferroelectric switching time and Landau parameter requirements for FeFET use in low-power circuit applications.","Iron,
Integrated circuit modeling,
MOSFET,
Semiconductor device modeling,
Logic gates,
Mathematical model,
SPICE"
Receiver-Initiated Spectrum Management for Underwater Cognitive Acoustic Network,"Cognitive acoustic (CA) is emerging as a promising technique for environment-friendly and spectrum-efficient underwater communications. Due to the unique features of underwater acoustic networks (UANs), traditional spectrum management systems designed for cognitive radio (CR) need an overhaul to work efficiently in underwater environments. In this paper, we propose a receiver-initiated spectrum management (RISM) system for underwater cognitive acoustic networks (UCANs). RISM seeks to improve the performance of UCANs through a collaboration of physical layer and medium access control (MAC) layer. It aims to provide efficient spectrum utilization and data transmissions with a small collision probability for CA nodes, while avoiding harmful interference with both “natural acoustic systems”, such as marine mammals, and “artificial acoustic systems”, like sonars and other UCANs. In addition, to solve the unique challenge of deciding when receivers start to retrieve data from their neighbors, we propose to use a traffic predictor on each receiver to forecast the traffic loads on surrounding nodes. This allows each receiver to dynamically adjust its polling frequency according to the variation of a network traffic. Simulation results show that the performance of RISM with smart polling scheme outperforms the conventional sender-initiated approach in terms of throughput, hop-by-hop delay, and energy efficiency.","Sensors,
Receivers,
Acoustics,
Radio spectrum management,
Schedules,
Cognitive radio,
Collaboration"
Follow But No Track: Privacy Preserved Profile Publishing in Cyber-Physical Social Systems,"Due to the close correlation with individual’s physical features and status, the adoption of cyber-physical social systems (CPSSs) has been inevitably hindered by users’ privacy concerns. Such concerns keep growing as our bile devices have more embedded sensors, while the existing countermeasures only provide incapable and limited privacy preservation for sensitive physical information. Therefore, we propose a novel privacy preservation framework for CPSSs. We formulate both the privacy concerns and user expectations in CPSSs based on real-world knowledge. We also design a corresponding data publishing mechanism for users. It regulates the publishing behaviors to hide sensitive physical profiles. Meanwhile, the published data retain comprehensive social profiles for users. Our analysis demonstrates that the mechanism achieves a local maximized performance on the aspect published data size. The experiment results toward real datasets reveals that the performance is comparable to the global optimal one.",
Measurements of the 60 GHz UE to eNB Channel for Small Cell Deployments,"In this letter, we report the results of a series of experiments which were performed to examine the impact of terminal handling and movement upon the user equipment (UE) to evolved NodeB (eNB) communications channel at 60 GHz. Three key utilization scenarios, in which a user imitated making a voice call, sending a text message or simply carrying the device in a pocket, are investigated. Each of these three user cases were studied under line of sight (LOS) and non-LOS (NLOS) channel conditions when the user was mobile in a range of different indoor and outdoor small cell scenarios. It is shown that the mode of UE operation (i.e., how the device is handled) will be important for future 60 GHz cellular applications. In particular, for short-range UE to eNB links which are in true NLOS, body shadowing is the dominating factor. To allow our results to be readily incorporated into network simulations, we have characterized the channel by decomposing the received signal into its constituent path loss, shadowed and small-scale fading components. In particular, we have had good success modeling the shadowed fading using the gamma distribution, whereas the small-scale fading observed in the LOS and NLOS channels has been appropriately modeled using the Rice and Nakagami-m distributions, respectively.","Antenna radiation patterns,
Shadow mapping,
Fading channels,
Antenna measurements,
Gain,
Automobiles,
Loss measurement"
Dynamic Learning From Adaptive Neural Control of Robot Manipulators With Prescribed Performance,"This paper presents dynamic learning from adaptive neural control (ANC) with prescribed tracking error performance for an n-link robot manipulator subjected to unknown system dynamics and external disturbances. To achieve the prescribed performance, a performance function is introduced to describe the performance restrictions on tracking errors, and then specific performance requirements are served as a priori condition of tracking control design. By an error transformation method, the constrained tracking control problem of the original robot manipulator is transformed into the stabilization problem of an unconstrained augmented system. Then, a novel ANC scheme is proposed for the unconstrained system by combining a filter tracking error with radial basis function (RBF) neural network (NN) approximator, and all the signals in the closed-loop system are semi-globally uniformly ultimately bounded. The external disturbances might make it difficult to achieve the accurate convergence of NN weight estimates. To overcome this difficulty, an appropriate state transformation is introduced to transform the closed-loop system into a linear time-varying system with small perturbed terms. Under partial persistent excitation condition of RBF NNs, the convergence of NN weight estimates is guaranteed, and then the experienced knowledge on the unknown robot manipulator dynamics can be stored with NN constant weights. Using the experienced knowledge, a static neural learning control is proposed to improve the system performances without time-consuming online parameter adjustment process, and the proposed learning control can also guarantee the prescribed transient and steady-state tracking control performance. Simulation results demonstrate the effectiveness of the proposed method.","Artificial neural networks,
Manipulator dynamics,
System dynamics,
Trajectory,
Convergence"
Optimal Rule Caching and Lossy Compression for Longest Prefix Matching,"Packet classification is a building block in many network services, such as routing, monitoring, and policy enforcement. In commodity switches, classification is often performed by memory components of various rule matching patterns (longest prefix match, ternary matches, exact match, and so on). The memory components are fast but expensive and power-hungry with power consumption proportional to their size. In this paper, we study the applicability of rule caching and lossy compression to create packet classifiers requiring much less memory than the theoretical size limits of the semantically-equivalent representations, enabling significant reduction in their cost and power consumption. This paper focuses on the longest prefix matching. Our objective is to find a limited-size longest prefix match classifier that can correctly classify a high portion of the traffic, so that it can be implemented in commodity switches with classification modules of restricted size. While for the lossy compression scheme a small amount of traffic might observe classification errors, a special indication is returned for traffic that cannot be classified in the rule caching scheme. We develop optimal dynamic-programming algorithms for both problems and describe how to treat the small amount of traffic that cannot be classified. We generalize our solutions for a wide range of classifiers with different similarity metrics. We evaluate their performance on real classifiers and traffic traces and show that in some cases we can reduce a classifier size by orders of magnitude while still classifying almost all traffic correctly.","Routing,
Power demand,
Encoding,
Pattern matching,
IEEE transactions,
Measurement,
Hardware"
Leukocytes Classification and Segmentation in Microscopic Blood Smear: A Resource-Aware Healthcare Service in Smart Cities,"Smart cities are a future reality for municipalities around the world. Healthcare services play a vital role in the transformation of traditional cities into smart cities. In this paper, we present a ubiquitous and quality computer-aided blood analysis service for the detection and counting of white blood cells (WBCs) in blood samples. WBCs also called leukocytes or leucocytes are the cells of the immune system that are involved in protecting the body against both infectious disease and foreign invaders. Analysis of leukocytes provides valuable information to medical specialists, helping them in diagnosing different important hematic diseases, such as AIDS and blood cancer (Leukaemia). However, this task is prone to errors and can be time-consuming. A mobile-cloud-assisted detection and classification of leukocytes from blood smear images can enhance accuracy and speed up the detection of WBCs. In this paper, we propose a smartphone-based cloud-assisted resource aware framework for localization of WBCs within microscopic blood smear images using a trained multi-class ensemble classification mechanism in the cloud. In the proposed framework, nucleus is first segmented, followed by extraction of texture, statistical, and wavelet features. Finally, the detected WBCs are categorized into five classes: basophil, eosinophil, neutrophil, lymphocyte, and monocyte. Experimental results on numerous benchmark databases validate the effectiveness and efficiency of the proposed system in comparison to the other state-of-the-art schemes.","Smart cities,
Medical services,
Image classification,
Feature extraction,
White blood cells,
Medical image processing,
Cloud computing,
Hematology"
Hybridized krill herd algorithm for large-scale optimization problems,"In this paper we applied the krill herd algorithm hybridized with the firefly algorithm to bound-constrained large-scale optimization problems. We tested basic krill herd algorithm and basic firefly algorithm on the standard set of benchmark functions. The results were acceptable. Then, we hybridized the krill herd algorithm with the firefly algorithm by applying firefly algorithm's search equation to the original krill herd algorithm implementation. We tested the robustness and effectiveness of our hybridized algorithm on the same large-scale numerical benchmarks with different dimensionality in order to make comparative analysis and to measure optimization enhancements of our approach. Testing results proved that our proposed hybridized implementation improved results almost uniformly and that it has significant potential when dealing with global optimization problems.","Optimization,
Algorithm design and analysis,
Search problems,
Sociology,
Statistics,
Mathematical model,
Linear programming"
Feature encoding in band-limited distributed surveillance systems,"Distributed surveillance systems have become popular in recent years due to security concerns. However, transmitting high dimensional data in bandwidth-limited distributed systems becomes a major challenge. In this paper, we address this issue by proposing a novel probabilistic algorithm based on the divergence between the probability distributions of the visual features in order to reduce their dimensionality and thus save the network bandwidth in distributed wireless smart camera networks. We demonstrate the effectiveness of the proposed approach through extensive experiments on two surveillance recognition tasks.","Visualization,
Histograms,
Feature extraction,
Training,
Smart cameras,
Surveillance"
Curriculum Considerations for the Internet of Things,"Before IoT innovations can be broadly realized, we must consider the educational needs of those who will develop the IoT products and services of the future. This article sets forth curriculum topics for institutions to use when creating and evaluating new IoT-inclusive curricula.","Computer science education,
Education courses,
Internet of things"
Relay Selection in Full-Duplex Energy-Harvesting Two-Way Relay Networks,"In this paper, we investigate the relay selection (RS) problem in full-duplex (FD) two-way relay networks, where the relays are wirelessly powered by harvesting a portion of the received signal power from the sources. To the best of the authors' knowledge, this is the first investigation of FD two-way relays with simultaneous wireless and information transfer capabilities. For each relay, we prove the quasi convexity of the power splitting (PS) factor optimization, and obtain the optimal PS factor in terms of the outage probability by linear search. Both single relay selection (SRS) and general relay selection (GRS) without the limit on the number of cooperating relays are investigated and the corresponding RS methods are proposed. Since the optimal GRS problem is computationally intractable with exponential complexity, we propose several low-complexity heuristic GRS methods based on various relay ordering and greedy selection criteria. Simulations indicate that the proposed GRS methods perform better than the SRS methods and achieve very similar performance compared with the optimal RS method achieved by exhaustive search but with dramatically reduced complexity.","Relay networks (telecommunications),
Wireless communication,
Bandwidth,
High definition video,
Energy harvesting,
IP networks"
Modeling User Activity Patterns for Next-Place Prediction,"Location has played a very important role in pervasive computing systems. Beyond the current location, knowing an individual's next location in advance can also enable many novel mobile applications and services such as targeted advertising and the smooth handover between two separate networks. Although extensive studies about location prediction have been carried out, the existing prediction methods either encounter “cold start” problems when an individual's trajectory data are sparse or erratically perform when an individual performs activities in a new region. In this paper, we propose a novel approach based on the activity pattern for location prediction. Instead of directly predicting an individual's next location, we first infer the individual's next activity by modeling user activity patterns, and then, we predict his/her next location on the basis of the inferred next activity. Using real-life trajectory data, we demonstrate that the proposed approach can realize the smooth upgrade of the prediction performance and perform robustly.","Trajectory,
Predictive models,
Probability distribution,
Robustness,
Context modeling,
Global Positioning System,
Computer science"
Signal-Tracing Techniques for In-System FPGA Debugging of High-Level Synthesis Circuits,"High-level synthesis (HLS) promises to increase designer productivity in the face of increasing field-programmable gate array sizes, and broaden the market of use, allowing software designers to reap the benefits of hardware implementation. One roadblock to HLS adoption is the lack of an in-system debugging infrastructure. Although designers can run their software code on a workstation, or simulate the register-transfer level, neither can reliably capture the behaviors, and therefore bugs, that may be present in the final system. Debugging hardware circuits in-system requires using signal-tracing to record circuit behavior for later offline analysis. In this paper, we present a debugging architecture, which automatically records key hardware signals, and relates them back to the original software source code. This architecture allows designers to debug HLS circuits in-system, in the context of the original source code. We present several signal-tracing techniques, tailored to HLS circuits, which allow a much longer execution trace to be captured. These techniques include signal compression, dynamically changing which signals are recorded cycle-by-cycle, and offline signal restoration. Compared to using an embedded logic analyzer to perform signal-tracing, our architecture increases the length of execution trace that can be recorded by 127X. For each 100 Kb of trace buffer memory, our architecture can record 15 369 executed lines of C code.","Debugging,
Hardware,
Field programmable gate arrays,
Software,
Computer architecture,
Context,
Signal restoration"
A Wearable Device and System for Movement and Biometric Data Acquisition for Sports Applications,"This paper presents a miniature wearable device and a system for detecting and recording the movement and biometric information of a user during sport activities. The wearable device is designed to be worn on a wrist and can monitor skin temperature and pulse rate. Furthermore, it can monitor arm movement and detect gestures using inertial measurement unit. The device can be used for various professional and amateur sport applications and for health monitoring. Because of its small size and minimum weight, it is especially appropriate for swing-based sports like tennis or golf, where any additional weight on the arms would most likely disturb the player and have some influence on the player's performance. Basic signal processing is performed directly on the wearable device but for more complex signal analysis, the data can be uploaded via the Internet to a cloud service, where it can be processed by a dedicated application. The device is powered by a lightweight miniature LiPo battery and has about 6 h of autonomy at maximum performance.","Biomedical monitoring,
Monitoring,
Performance evaluation,
Bioinformatics,
Temperature measurement,
Cloud computing,
Accelerometers"
"Offloading in HetNet: A Coordination of Interference Mitigation, User Association, and Resource Allocation","The use of heterogeneous small cell-based networks to offload the traffic of existing cellular systems has recently attracted significant attention. One main challenge is solving the joint problems of interference mitigation, user association, and resource allocation. These problems are formulated as an optimization which is then analyzed using two different approaches: Markov approximation and log-linear learning. However, finding the optimal solutions of both approaches requires complete information of the whole network which is not scalable with the network size. Thus, an approach based on a Markov approximation with a novel Markov chain design and transition probabilities is proposed. This approach enables the Markov chain to converge to the bounded near optimal distribution without complete information. In the game-theoretic approach, the payoff-based log-linear learning is used, and it converges in probability to a mixed-strategy ε-Nash equilibrium. Based on the principles of these two approaches, a highly randomized self-organizing algorithm is proposed to reduce the gap between optimal and converged distributions. Simulation results show that all of the proposed algorithms effectively offload more than 90 percent of the traffic from the macrocell base station to small cell base stations. Moreover, the results also show that the algorithms converge quickly irrespective of the number of possible configurations.","Markov processes,
Resource management,
Games,
Base stations,
Algorithm design and analysis,
Interference,
Buildings"
Game User-Oriented Multimedia Transmission Over Cognitive Radio Networks,"Cognitive radio (CR) is an emerging technique to improve the efficiency of spectrum resource utilization. In CR networks, the selfish behavior of secondary users (SUs) can considerably affect the performance of primary users (PUs). Accordingly, game theory, which considers the game players' selfish behavior, has been applied to the design of CR networks. Most of the existing studies focus on the network design only from the network perspective to improve system performance, such as utility and throughput. However, the users' experience to the service, which cannot simply be reflected by quality of service, has been largely ignored. The user-perceived multimedia quality and service can be different from the actual received multimedia quality, and thus is very important to consider the network design. To better serve the network users, quality of experience (QoE) is adopted to measure the network service from the users' perspective and help improve the users' satisfaction to the CR network service. As CR networks require a lot of data storage and computation for spectrum sensing, spectrum sharing, and algorithm design, cloud computation comes as a convenient solution, because it can provide massive storage and fast computation. In this paper, we propose to design a user-oriented CR cloud network for multimedia applications, where the user's satisfaction is reflected in the CR cloud network design. In the proposed framework, the PU and SU game is formulated as Stackelberg game. In particular, a refunding term is defined in the users' utility function to effectively consider and to reflect the network users' QoE requirement. Our contributions are twofold: 1) a game-based CR cloud network design for multimedia transmission is proposed, and the network user's QoE requirement is satisfied in the design and 2) the existence and the uniqueness of the Stackelberg Nash equilibrium are proved, and the design is optimal. Our simulation results demonstrate the effectiveness of the game user-oriented CR cloud network design.","Games,
Multimedia communication,
Game theory,
Cloud computing,
Quality of service,
Mobile communication,
System performance"
Energy Harvesting Wireless Sensor Node With Temporal Death: Novel Models and Analyses,"Energy harvesting wireless sensor network (EH-WSN) is promising in applications, however the frequent occurrence of temporal death of nodes, due to the limited harvesting capability, presents a difficulty in meeting the quality-of-service requirements of the network. For a node with temporal death in an EH-WSN, this paper presents a new model, which consists of, a Markov model to trace the energy harvesting process, a queuing analytical model to model the working mechanism of the sensor node and a continuous fluid process to capture the evolution of the residual energy in the EH-WSN node. Using the Markov fluid queue (MFQ) theory, we discuss various performance aspects of the EH-WSN node with temporal death, including the temporal death occurrence probability, the probability density of the residual energy, the stationary energy consumption, the queue length distribution in the data buffer, the packet blocking probability, and so on. In order to obtain the dropping probability of a given packet, based on the structure of the MFQ, we develop an auxiliary MFQ and derive the formulations of two types of the packet dropping probabilities, i.e., the packet dropping probability due to energy depletion and that due to channel error. Numerical examples are provided to illustrate the theoretical findings, and new insights into understanding the impacts of the parameters on the performance metrics are presented.","Wireless sensor networks,
Energy harvesting,
Analytical models,
Measurement,
Wireless communication,
Quality of service,
Queueing analysis"
Analysis and Design of Graphene-Based Surface Plasmon Waveguide Switch at Long-Wavelength Infrared Frequencies,"A graphene-based surface plasmon (SP) waveguide switch is designed at near infrared frequencies. First, graphene is modeled in electronic and electromagnetic solvers, in order to use graphene strips for designing the waveguide. Because of finite size of these strips, propagating surface plasmon polaritons (SPPs) along them exhibit spatial dispersion. By considering this and shifting interband losses to higher frequencies (by doping the graphene strips), the waveguide switch is designed to operate at 30 THz. In this paper, chemical potential in the graphene strips is controlled through applying back and top gate voltages which provide a reconfigurable waveguide switch and the chemical potentials of the strips are changed so that ultra-confinement and extremely low-loss propagation are achieved. The designed switch provides extremely low return loss and ultra-bandwidth in 30--40 THz frequency range. Due to the spatial dispersion in the graphene strips, new procedures are proposed to calculate the return and insertion losses of the switch and also absorbed power in the graphene strips.","Graphene,
Dispersion,
Two dimensional displays,
Strips,
Optical waveguides,
Three-dimensional displays"
"MultiParameter Fiber-Optic Sensor for Simultaneous Measurement of Thermal Conductivity, Pressure, Refractive Index, and Temperature","The presented work addresses a problem of multi-parameter sensing, where a single optical structure performs efficient and simultaneous sensing of multiple physical parameters. True all-fiber and miniature solutions that can measure four parameters are not known in the literature to the best of our knowledge. Besides, this the present paper demonstrates for the first time a sensing of the gas thermal conductivity by optical means",
Joint Source-Relay Secure Precoding for MIMO Relay Networks With Direct Links,"In this paper, we propose a joint source-relay precoding scheme to secure an amplify-and-forward multiple-input multiple-output wireless relay network in the existence of a multi-antenna eavesdropper. Different from existing works that only consider some specific signal design to simplify the problem, we take both the direct links from the source to the destination and to the eavesdropper into account, and investigate the general joint signal covariance matrices optimization problem to maximize the secrecy rate, which leads to a difficult non-convex optimization problem. To handle it, we propose a group alternating optimization algorithm to find a solution, which alternately optimizes the signal covariance matrix and the linear precoding matrix at the source and the relay, respectively. For optimizing the linear precoding matrix at the relay, the problem is still non-convex, and we propose a minorization-maximization (MM) method to handle it. The MM method transforms the original non-convex problem into a series of convex problems and guarantees the convergence of a local optimum. For optimizing the signal covariance matrix at the source, we reveal the convex-concave property of the problem, and find its global optimum using a barrier method combined with the Newton iteration. We also provide an initialization method to trigger the algorithm and analyze the convergence and complexity. The numerical results show the computational efficiency and the prominent performance of the proposed algorithm.","MIMO,
Optimization,
Precoding,
Covariance matrices,
Relay networks (telecommunications),
Antennas"
Designing Robust Software Systems through Parametric Markov Chain Synthesis,"We present a method for the synthesis of software system designs that satisfy strict quality requirements, are Pareto-optimal with respect to a set of quality optimisation criteria, and are robust to variations in the system parameters. To this end, we model the design space of the system under development as a parametric continuous-time Markov chain (pCTMC) with discrete and continuous parameters that correspond to alternative system architectures and to the ranges of possible values for configuration parameters, respectively. Given this pCTMC and required tolerance levels for the configuration parameters, our method produces a sensitivity-aware Pareto-optimal set of designs, which allows the modeller to inspect the ranges of quality attributes induced by these tolerances, thus enabling the effective selection of robust designs. Through application to two systems from different domains, we demonstrate the ability of our method to synthesise robust designs with a wide spectrum of useful tradeoffs between quality attributes and sensitivity.","Markov processes,
Robustness,
Probabilistic logic,
Software systems,
Linear programming,
Computer science,
Optimization"
MobiCoRE: Mobile Device based Cloudlet Resource Enhancement for Optimal Task Response,"Cloudlets are small self maintained clouds, with hotspot like deployment, to enhance the computational capabilities of the mobile devices. The limited resources of cloudlets can become heavily loaded during peak utilization. Consequently, per user available computational capacity decreases and at times mobile devices find no execution time benefit for using the cloudlet. Researchers have proposed augmenting the cloudlet resources using mobile devices; however, the proposed approaches do not consider the offered service to load ratio while using mobile device resources. In this paper, we propose easy to implement Mobile Device based Cloudlet Resource Enhancement (MobiCoRE) while ensuring that: (i) mobile device always have time benefit for its tasks submitted to the cloudlet and (ii) cloudlet induced mobile device load is a fraction of its own service requirement from the cloudlet. We map MobiCoRE on M/M/c/K queue and model the system using birth death markov chain. Given the arrival rate of , c cpu cores in cloudlet, maximum tasks in the cloudlet to be K and P0 = f(; c;K; ) be probability of having no user in cloudlet, we derive the condition 1 P0 = K cK􀀀cc!K 1000 for optimal average service time 1 of cloudlet such that the mobile applications have maximum benefit for using cloudlet services. We show that the optimal average service time is independent of the applications service requirement. Evaluation shows that MobiCoRE can accommodate upto 50% extra users when operating at optimal service time and sharing mobile resources for remaining task, compared to completing the entire user applications in cloudlet. Similarly, up to 47% time benefit can be achieved for mobile devices by sharing only 16% computational resources with the cloudlet.","Cloud computing,
Mobile handsets,
Mobile communication,
Performance evaluation,
Resource management,
Computational modeling,
Mobile applications"
Surrogate-Assisted Genetic Programming With Simplified Models for Automated Design of Dispatching Rules,"Automated design of dispatching rules for production systems has been an interesting research topic over the last several years. Machine learning, especially genetic programming (GP), has been a powerful approach to dealing with this design problem. However, intensive computational requirements, accuracy and interpretability are still its limitations. This paper aims at developing a new surrogate assisted GP to help improving the quality of the evolved rules without significant computational costs. The experiments have verified the effectiveness and efficiency of the proposed algorithms as compared to those in the literature. Furthermore, new simplification and visualisation approaches have also been developed to improve the interpretability of the evolved rules. These approaches have shown great potentials and proved to be a critical part of the automated design system.","Dispatching,
Job shop scheduling,
Computational modeling,
Analytical models,
Processor scheduling,
Genetic programming,
Logic gates"
Sequential Deep Trajectory Descriptor for Action Recognition With Three-Stream CNN,"Learning the spatial-temporal representation of motion information is crucial to human action recognition. Nevertheless, most of the existing features or descriptors cannot capture motion information effectively, especially for long-term motion. To address this problem, this paper proposes a long-term motion descriptor called sequential deep trajectory descriptor (sDTD). Specifically, we project dense trajectories into two-dimensional planes, and subsequently a CNN-RNN network is employed to learn an effective representation for long-term motion. Unlike the popular two-stream ConvNets, the sDTD stream is introduced into a three-stream framework so as to identify actions from a video sequence. Consequently, this three-stream framework can simultaneously capture static spatial features, short-term motion, and long-term motion in the video. Extensive experiments were conducted on three challenging datasets: KTH, HMDB51, and UCF101. Experimental results show that our method achieves state-of-the-art performance on the KTH and UCF101 datasets, and is comparable to the state-of-the-art methods on the HMDB51 dataset.","Trajectory,
Feature extraction,
Optical imaging,
Cameras,
Streaming media,
Neural networks,
Histograms"
Petri Net Modeling and Scheduling of a Close-Down Process for Time-Constrained Single-Arm Cluster Tools,"In wafer fabrication, a robotic cluster tool is required to be closed down in order for engineers to perform its on-demand and preventive maintenance and switch between different wafer lots. They often deal with a close-down process subject to wafer residency time constraints, i.e., a wafer must exit from a processing chamber before its quality degradation within a certain time limit. To obtain higher yield, it is very important to optimize a close-down process for a cluster tool. Yet the existing literature pays no or little attention to this issue. By focusing on a time-constrained single-arm cluster tool, this paper intends: 1) to build its Petri net model to analyze its schedulability and 2) to develop computationally efficient algorithms to find an optimal and feasible schedule for its closing-down process under different workloads at its steps. Industrial examples are used to illustrate the application of the proposed method.","Robots,
Steady-state,
Semiconductor device modeling,
Time factors,
Schedules,
Optimal scheduling,
Transient analysis"
Generalized Injection Shift Factors,"Generalized injection shift factors (ISFs) are the sensitivities of active-power line flows to active-power bus injections. They are computed without designating an artifactual slack bus in the power network; therefore, conceptually, they reflect sensitivities of power flows more accurately than conventional ISFs, the values of which depend on the choice of the slack bus. This paper derives analytical closed-form expressions for generalized ISFs from a perturbative analysis of the ac circuit equations. In addition, they are computed from a system of linear equations that arise from high-frequency synchronized measurements collected from phasor measurement units. As an application, generalized ISFs are used to predict active-power line flows during the transient period following a contingency by leveraging inertial and governor power flows over appropriate time horizons.","Sensitivity,
Transmission line matrix methods,
Mathematical model,
Transient analysis,
Power system reliability"
Diffusive Mobile Molecular Communications Over Time-Variant Channels,"This letter introduces a formalism for modeling time-variant channels for diffusive molecular communication systems. In particular, we consider a fluid environment where one transmitter nano-machine and one receiver nano-machine are subjected to Brownian motion in addition to the diffusive motion of the information molecules used for communication. Due to the stochastic movements of the transmitter and receiver nano-machines, the statistics of the channel impulse response change over time. We show that the time-variant behavior of the channel can be accurately captured by appropriately modifying the diffusion coefficient of the information molecules. Furthermore, we derive an analytical expression for evaluation of the expected error probability of a simple detector for the considered system. The accuracy of the proposed analytical expression is verified via particle-based simulation of the Brownian motion.","Receivers,
Transmitters,
Mobile communication,
Nanobioscience,
Solid modeling,
Error probability,
Mathematical model"
Mechanism and Origin of Hysteresis in Oxide Thin-Film Transistor and Its Application on 3-D Nonvolatile Memory,"Hysteresis in the current-voltage characteristics of a ZnO thin-film transistor (TFT) has been studied. Electric dipoles at the interface of the dielectric and the channel have been proposed as the agents responsible for the hysteresis. From experimental results and theoretical analysis, the water diffusing into the active layer is found as the main origin of the hysteresis. Based on this finding, devices free of hysteresis were obtained by using heat treatment and a passivation layer to control water diffusion in the fabrication process. Conversely, the hysteresis characteristics can be engineered so as to benefit the application of electronic memory. The function of the TFT device that serves as a memory element was also investigated and demonstrated in this paper. Owing to its low temperature process and simplified structure (compared with the FeRAM), 3-D stacked or even transparent nonvolatile memory would be its potential application.","Hysteresis,
Zinc oxide,
II-VI semiconductor materials,
Thin film transistors,
Logic gates,
Nonvolatile memory,
Dielectrics"
Hot-Swapping Analysis and Implementation of Series-Stacked Server Power Delivery Architectures,"Current data center power delivery architectures consist of many cascaded power conversion stages, where the system-level power conversion efficiency is reduced each time the power is processed through the individual stages. Recently, series-stacked power delivery architectures have shown how the overall power conversion can be reduced through architectural changes, reporting above 99% system-level power conversion efficiencies for data centers. In this paper, we contribute to the development of the series-stacked power delivery architectures by addressing the important hot-swapping challenge, without sacrificing the high power conversion efficiency. We analyze the hot-swapped operation of the series-stacked architecture, and experimentally validate it on a testbed that includes four series-connected 12 V, 120 W servers and four custom-designed differential converters with associated circuitry for hot-swapping. The results show that continuous operation of the series-stacked servers can be maintained while a server is hot-swapped without a significant reduction in the high power conversion efficiency.","Servers,
Computer architecture,
DC-DC power converters,
Power distribution,
Substations,
Distributed databases"
DyScale: A MapReduce Job Scheduler for Heterogeneous Multicore Processors,"The functionality of modern multi-core processors is often driven by a given power budget that requires designers to evaluate different decision trade-offs, e.g., to choose between many slow, power-efficient cores, or fewer faster, power-hungry cores, or a combination of them. Here, we prototype and evaluate a new Hadoop scheduler, called DyScale, that exploits capabilities offered by heterogeneous cores within a single multi-core processor for achieving a variety of performance objectives. A typical MapReduce workload contains jobs with different performance goals: large, batch jobs that are throughput oriented, and smaller interactive jobs that are response time sensitive. Heterogeneous multi-core processors enable creating virtual resource pools based on “slow” and “fast” cores for multi-class priority scheduling. Since the same data can be accessed with either “slow” or “fast” slots, spare resources (slots) can be shared between different resource pools. Using measurements on an actual experimental setting and via simulation, we argue in favor of heterogeneous multi-core processors as they achieve “faster” (up to 40 percent) processing of small, interactive MapReduce jobs, while offering improved throughput (up to 40 percent) for large, batch jobs. We evaluate the performance benefits of DyScale versus the FIFO and Capacity job schedulers that are broadly used in the Hadoop community.","Multicore processing,
Program processors,
System-on-chip,
Cloud computing,
Processor scheduling,
Resource management,
Throughput"
Lower Bound Analysis and Perturbation of Critical Path for Area-Time Efficient Multiple Constant Multiplications,"In this paper, a precise systematic delay model is proposed for the analysis and estimation of critical path delay of multiple constant multiplication (MCM) blocks. For the first time in literature, the mathematical derivation of lower bound of critical path delay of MCM blocks is presented and necessary conditions for achieving the lower bound of critical path delay are discussed. It is shown that the lower bound of critical path delay of MCMs is significantly smaller than that achieved by existing MCM algorithms. An improved genetic algorithm-based approach, with a heuristic algorithm to generate the initial population, is proposed to search for low complexity MCM solutions with the lower bound of critical path delay. This is the first time that design algorithms with gate-level delay control is proposed. Moreover, it is shown that using the information of lower bound of critical path delay, perturbation of timing can be applied to tradeoff the lower bound critical path delay against hardware complexity. It is shown that area-time efficient design of MCM blocks can be obtained by using the proposed techniques.","Delays,
Adders,
Algorithm design and analysis,
Signal processing algorithms,
Complexity theory,
Integrated circuit modeling,
Heuristic algorithms"
Understanding Charge Collection Mechanisms in InGaAs FinFETs Using High-Speed Pulsed-Laser Transient Testing With Tunable Wavelength,"A tunable wavelength laser system and high-resolution transient capture system are introduced to characterize transients in high-mobility MOSFETs. The experimental configuration enables resolution of fast transient signals and new understanding of charge collection mechanisms. The channel layer is critical in the charge collection process for the InGaAs FinFETs examined here. The transient current mainly comes from the channel current, due to shunt effects and parasitic bipolar effects, instead of the junction collection. The charge amplification factor is found to be as high as 14, which makes this technology relatively sensitive to transient radiation. The peak current is inversely proportional to the device gate length. Simulations show that the parasitic bipolar effect is due to source-to-channel barrier lowering caused by hole accumulation in the source and channel. Charge deposited in the channel causes prompt current, while charge deposited below the channel causes delayed and slow current.","Indium gallium arsenide,
Transient analysis,
Laser beams,
Oscilloscopes,
Measurement by laser beam,
FinFETs"
Signal Quality Analysis of Ambulatory Electrocardiograms to Gate False Myocardial Ischemia Alarms,"Objective: The objective of this study is to propose and validate an alarm gating system for a myocardial ischemia monitoring system that uses ambulatory electrocardiogram. The PeriOperative ISchemic Evaluation study recommended the selective administration of β blockers to patients at risk of cardiac events following noncardiac surgery. Patients at risk are identified by monitoring ST segment deviations in the electrocardiogram (ECG); however, patients are encouraged to ambulate to improve recovery, which deteriorates the signal quality of the ECG leading to false alarms. Methods: The proposed alarm gating system computes a signal quality index (SQI) to quantify the ECG signal quality and rejects alarms with a low SQI. The system was validated by artificially contaminating ECG records with motion artifact records obtained from the long-term ST database and MIT-BIH noise stress test database, respectively. Results: Without alarm gating, the myocardial ischemia monitoring system attained a Precision of 0.31 and a Recall of 0.78. The alarm gating improved the Precision to 0.58 with a reduction of Recall to 0.77. Conclusion: The proposed system successfully gated false alarms with future work exploring the misidentification of fiducial points by myocardial ischemia monitoring systems. Significance: The reduction of false alarms due to the proposed system will decrease the incidence of the alarm fatigue condition typically found in clinicians. Alarm fatigue condition was rated as the top patient safety hazard from 2012 to 2015 by the Emergency Care Research Institute.","Monitoring,
Myocardium,
Electrocardiography,
Biomedical monitoring,
Surgery,
Indexes"
Coverage Analysis for Millimeter Wave Networks: The Impact of Directional Antenna Arrays,"Millimeter wave (mm-wave) communications is considered a promising technology for 5G networks. Exploiting beamforming gains with large-scale antenna arrays to combat the increased path loss at mm-wave bands is one of the defining features. However, previous works on mm-wave network analysis usually adopted oversimplified antenna patterns for tractability, which can lead to significant deviation from the performance with actual antenna patterns. In this paper, using tools from stochastic geometry, we carry out a comprehensive investigation on the impact of directional antenna arrays in mm-wave networks. We first present a general and tractable framework for coverage analysis with arbitrary distributions for interference power and arbitrary antenna patterns. It is then applied to mm-wave ad hoc and cellular networks, where two sophisticated antenna patterns with desirable accuracy and analytical tractability are proposed to approximate the actual antenna pattern. Compared with previous works, the proposed approximate antenna patterns help to obtain more insights on the role of directional antenna arrays in mm-wave networks. In particular, it is shown that the coverage probabilities of both types of networks increase as a non-decreasing concave function with the antenna array size. The analytical results are verified to be effective and reliable through simulations, and numerical results also show that large-scale antenna arrays are required for satisfactory coverage in mm-wave networks.","Antenna arrays,
Directional antennas,
Transmitters,
Interference,
Receivers,
Ad hoc networks"
Online Hashing,"Although hash function learning algorithms have achieved great success in recent years, most existing hash models are off-line, which are not suitable for processing sequential or online data. To address this problem, this paper proposes an online hash model to accommodate data coming in stream for online learning. Specifically, a new loss function is proposed to measure the similarity loss between a pair of data samples in hamming space. Then, a structured hash model is derived and optimized in a passive-aggressive way. Theoretical analysis on the upper bound of the cumulative loss for the proposed online hash model is provided. Furthermore, we extend our online hashing (OH) from a single model to a multimodel OH that trains multiple models so as to retain diverse OH models in order to avoid biased update. The competitive efficiency and effectiveness of the proposed online hash models are verified through extensive experiments on several large-scale data sets as compared with related hashing methods.","Data models,
Loss measurement,
Binary codes,
Adaptation models,
Upper bound,
Analytical models,
Sun"
On Constructions of a Class of Binary Locally Repairable Codes With Multiple Repair Groups,"Recently, Hao and Xia noted a connection between a class of binary locally repairable codes (LRCs) with multiple repair groups and binary low-density parity-check (LDPC) codes, and proposed a framework for constructing binary LRCs from LDPC codes as well as three specific constructions of binary LRCs that can achieve a distance bound. The connection between binary LRCs and LDPC codes, however, has not yet been fully disclosed and constructions of binary LRCs that can achieve the distance bound remain largely unknown. Accordingly, this paper comments on the connection and presents two infinite families of binary LRCs that can achieve the distance bound, based on circulant permutation matrices and affine permutation matrices. The proposed LRCs generalize the promising construction of high-rate codes proposed by Hao and Xia, and offer larger relative distances with the same or higher code rates when compared with other competitive codes.","Maintenance engineering,
Parity check codes,
Spread spectrum communication,
Systematics,
Zirconium,
Redundancy,
Upper bound"
Average Packet Delay Analysis for a Mobile User in a Two-Tier Heterogeneous Cellular Network,"In this paper, we analyze the average packet queueing delay of a slow-moving user in a macro-femto two-tier heterogeneous cellular network. We model the user as a queue that experiences vertical handover between macro and femto base stations. We define the queue states progression at each handover interval as a 2-D discrete time Markov chain. We determine the Markov chain's steady-state probability distribution so that the average packet delay can be calculated using the Little's Theorem. With the model, we can analyze the effects on packet delay as caused by variations in coverage area dwell time, packet service rate, and probability of entering a femtocell. We have verified the analytical model against results from random-event simulations. We find that the average packet delay can be lowered by deploying more femtocells only if the time a user stays in a femtocell is longer than a certain value. The model can help us in avoiding unnecessary vertical handovers, as well as in deciding the number and size of femtocells to achieve a desired packet delay.","Delays,
Base stations,
Handover,
Queueing analysis,
Macrocell networks"
Distributed Optimization of Hierarchical Small Cell Networks: A GNEP Framework,"Deployment of small cell base stations (SBSs) overlaying the coverage area of a macrocell BS (MBS) results in a two-tier hierarchical small cell network. Cross-tier and inter-tier interference not only jeopardize primary macrocell communication but also limit the spectral efficiency of small cell communication. This paper focuses on distributed interference management for downlink small cell networks. We address the optimization of transmit strategies from both the game theoretical and the network utility maximization (NUM) perspectives and show that they can be unified in a generalized Nash equilibrium problem (GNEP) framework. Specifically, the small cell network design is first formulated as a GNEP, where the SBSs and MBS compete for the spectral resources by maximizing their own rates while satisfying global quality of service (QoS) constraints. We analyze the GNEP via variational inequality theory and propose distributed algorithms, which only require the broadcasting of some pricing information, to achieve a generalized Nash equilibrium (GNE). Then, we also consider a nonconvex NUM problem that aims to maximize the sum rate of all BSs subject to global QoS constraints. We establish the connection between the NUM problem and a penalized GNEP and show that its stationary solution can be obtained via a fixed point iteration of the GNE. We propose GNEP-based distributed algorithms that achieve a stationary solution of the NUM problem at the expense of additional signaling overhead and complexity. The convergence of the proposed algorithms is proved and guaranteed for properly chosen algorithm parameters. The proposed GNEP framework can scale from a QoS constrained game to an NUM design for small cell networks by trading off signaling overhead and complexity.","Macrocell networks,
Interference,
Computer architecture,
Microprocessors,
Quality of service,
Games,
Optimization"
Resource Management Games for Distributed Network Localization,"Resource management in the power and time-frequency domains is an important issue in distributed network localization. Since highly accurate ranging requires a large amount of time-frequency resources, cooperation among nodes without proper link selection may not be feasible. To address this issue, two resource management games are formulated, and Stackelberg equilibrium and link bargaining equilibrium are proposed as the solution concepts for efficient link selection and power allocation. Distributed algorithms are derived and analyzed using game theoretical approaches. It is demonstrated that the proposed strategies can achieve a lower mean squared error of position estimation with fewer ranging measurements.","Resource management,
Games,
Distance measurement,
Estimation,
Position measurement,
Game theory,
Power measurement"
Toward Distributed/Decentralized DC Optimal Power Flow Implementation in Future Electric Power Systems,"This paper reviews distributed/decentralized algorithms to solve the optimal power flow (OPF) problem in electric power systems. Six decomposition coordination algorithms are studied, including analytical target cascading (ATC), optimality condition decomposition (OCD), alternating direction method of multipliers (ADMM), auxiliary problem principle (APP), consensus+ innovations (C+I), and proximal message passing (PMP). The basic concept, the general formulation, the application for DC-OPF, and the solution methodology for each algorithm are presented. We apply these six decomposition coordination algorithms on a test system, and discuss their key features and simulation results.","Power systems,
Couplings,
Heuristic algorithms,
Computers,
Convergence,
Algorithm design and analysis,
Message passing"
A survey on IoT communication and computation frameworks: An industrial perspective,"This paper surveys fog computing and embedded systems platforms as the building blocks of Internet of Things (IoT). Many concepts around IoT architectures, with various examples, are also discussed. This paper reviews a high-level conceptual layered architecture for IoT from a computational perspective. The architecture incorporates fog computing to address several issues associated with cloud computing; however, it is never a binary decision between fog and cloud. Many of the world's physical objects are being embedded with sensors and actuators, tied by communication infrastructures, and managed by computational algorithms. IoT sensor networks and embedded systems connecting smart objects are revolutionizing how we approach our daily lives, health care, energy, and transportation. Such computational needs are addressed with an array of various models and frameworks. In an attempt to consolidate the use of these models, this paper reviews the state-of-the-art research in IoT, cloud computing, and fog computing.","Internet of Things,
cloud computing,
embedded systems"
Redundancy Allocation Based on the Weighted Mismatch-Rate Slope for Multiple Description Video Coding,"Multiple description coding (MDC) is a robust coding technique for video transmission over error prone networks, whereby the video is encoded into multiple descriptions with some redundancy between the descriptions. This redundancy leads to error resiliency in the case of packet loss during the network transport. However, the amount of this redundancy has a critical role in MDC performance. Therefore, a crucial problem in MDC is to find what the optimum amount of redundancy budget is, and then how this redundancy budget can be optimally allocated to the frames. To solve this problem, we propose a scheme in which the redundancy budget is allocated to the frames based on the weighted mismatch-rate slopes so that this additional bitrate can attain maximum distortion reduction. The redundancy is added gradually so that fine tuning of the utilized bitrate is achievable. We have verified our proposed scheme by implementing it in H.264/AVC reference software JM16.0, and running experiments against two representative reference methods. Our experiments show that our scheme not only minimizes the end-to-end distortion with a rate-distortion performance that is better than the reference methods, especially for high PLRs, but also entirely uses the available bandwidth, unlike the reference methods.","Redundancy,
Distortion,
Optimization,
Decoding,
Encoding,
Bit rate,
Bandwidth"
Robust Co-Optimization Scheduling of Electricity and Natural Gas Systems via ADMM,"The significant growth of gas-fired power plants and emerging power-to-gas (PtG) technology has intensified the interdependency between electricity and natural gas systems. This paper proposes a robust co-optimization scheduling model to study the coordinated optimal operation of the two energy systems. The proposed model minimizes the total costs of the two systems, while considering power system key uncertainties and natural gas system dynamics. Because of the limitation on exchanging private data and the challenge in managing complex models, the proposed co-optimization model is tackled via alternating direction method of multipliers (ADMM) by iteratively solving a power system subproblem and a gas system subproblem. The power system subproblem is solved by column-and-constraint generation (C&CG) and outer approximation (OA), and the nonlinear gas system subproblem is solved by converting into a mixed-integer linear programming model. To overcome nonconvexity of the original problem with binary variables, a tailored ADMM with a relax-round-polish process is developed to obtain high-quality solutions. Numerical case studies illustrate the effectiveness of the proposed model for optimally coordinating electricity and natural gas systems with uncertainties.","Natural gas,
Uncertainty,
Robustness,
Production,
Wind power generation,
Load modeling,
Power systems"
VisFlow - Web-based Visualization Framework for Tabular Data with a Subset Flow Model,"Data flow systems allow the user to design a flow diagram that specifies the relations between system components which process, filter or visually present the data. Visualization systems may benefit from user-defined data flows as an analysis typically consists of rendering multiple plots on demand and performing different types of interactive queries across coordinated views. In this paper, we propose VisFlow, a web-based visualization framework for tabular data that employs a specific type of data flow model called the subset flow model. VisFlow focuses on interactive queries within the data flow, overcoming the limitation of interactivity from past computational data flow systems. In particular, VisFlow applies embedded visualizations and supports interactive selections, brushing and linking within a visualization-oriented data flow. The model requires all data transmitted by the flow to be a data item subset (i.e. groups of table rows) of some original input table, so that rendering properties can be assigned to the subset unambiguously for tracking and comparison. VisFlow features the analysis flexibility of a flow diagram, and at the same time reduces the diagram complexity and improves usability. We demonstrate the capability of VisFlow on two case studies with domain experts on real-world datasets showing that VisFlow is capable of accomplishing a considerable set of visualization and analysis tasks. The VisFlow system is available as open source on GitHub.","Data visualization,
Data models,
Computational modeling,
Rendering (computer graphics),
Pipelines,
Joining processes,
Data analysis"
An Enhancement of Crosstalk Avoidance Code Based on Fibonacci Numeral System for Through Silicon Vias,"Through silicon vias (TSVs) play an important role as the vertical electrical connections in 3-D stacked integrated circuits. However, the closely clustered TSVs suffer from the crosstalk noise between the neighboring TSVs, and result in the extra delay and the deterioration of signal integrity. For a 3 × 3 TSV array, the severity of crosstalk noise in the center victim TSV is classified into 11 levels, which is defined as 0C to 10C from low noise to high noise, depending on the combinations of the digital patterns applied to the TSV array. An enhanced code based on the Fibonacci number system (FNS) to suppress the crosstalk noise below 6C level is proposed, in which both the redundancy of numbers and the nonuniqueness of Fibonacci-based binary codeword are utilized to search the proper codeword. Experimental results show that the proposed technique decreases about 22% latency of TSVs comparing with the worst crosstalk cases. This technique is applicable in the large-scale TSV array for it has a quasi-linear hardware overhead, and its system overhead is less than that of the 3-D 4-LAT counterpart if the data width is greater than 18, and it has good usability for it consumes less power per TSV and achieves lower bit error rate at the interested frequency range comparing with that of the original FNS coding technique.","Through-silicon vias,
Crosstalk,
Couplings,
Capacitance,
Silicon,
Arrays"
"Control Under Stochastic Multiplicative Uncertainties: Part II, Optimal Design for Performance","This paper studies the optimal control design problem for linear discrete-time systems with stochastic multiplicative uncertainties. These uncertainties are assumed to be present in the control inputs and modeled as independent and identically distributed (i.i.d.) random processes. The optimal performance under study is defined in the mean-square sense, referred to as the mean-square optimal H2 performance. It is shown that the mean-square optimal H2 control problem via state feedback can be solved using a mean-square stabilizing solution to a modified algebraic Riccati equation (MARE). A necessary and sufficient condition for the existence of this solution is presented, which constitutes a generalization of the solution to the classic optimal H2 state feedback design problem, whereas the latter can be obtained by solving an algebraic Riccati equation (ARE). It is also proven that the optimal control design problem can be cast as an eigenvalue problem (EVP). For the output feedback case with possible input delays, we show that the mean-square optimal H2 control problem also amounts to solving an MARE, when the plant has no nonminimum phase zeros from the inputs to the measurement outputs. That is, the global optimal solution is obtained by solving an MARE incorporating the delays. The implication is that in this case a separation principle still holds.","Stochastic processes,
Uncertainty,
State feedback,
Linear systems,
Output feedback,
Optimal control,
Stability analysis"
Approaches to Co-Evolution of Metamodels and Models: A Survey,"Modeling languages, just as all software artifacts, evolve. This poses the risk that legacy models of a company get lost, when they become incompatible with the new language version. To address this risk, a multitude of approaches for metamodel-model co-evolution were proposed in the last 10 years. However, the high number of solutions makes it difficult for practitioners to choose an appropriate approach. In this paper, we present a survey on 31 approaches to support metamodel-model co-evolution. We introduce a taxonomy of solution techniques and classify the existing approaches. To support researchers, we discuss the state of the art, in order to better identify open issues. Furthermore, we use the results to provide a decision support for practitioners, who aim to adopt solutions from research.","Unified modeling language,
Companies,
Taxonomy,
Biological system modeling,
Atmospheric modeling,
Libraries,
Productivity"
Multi-Period Network Rate Allocation with End-to-End Delay Constraints,"QoS-aware networking applications such as realtime streaming and video surveillance systems require nearly fixed average end-to-end delay over long periods to communicate efficiently, although may tolerate some delay variations in short periods. This variability exhibits complex dynamics that makes rate control of such applications a formidable task. This paper addresses rate allocation for heterogeneous QoS-aware applications that preserves the long-term end-to-end delay constraint while seeking the maximum network utility cumulated over a fixed time interval. To capture the temporal dynamics of sources, we incorporate a novel time-coupling constraint in which delaysensitivity of sources is considered such that a certain end-toend average delay for each source over a pre-specified time interval is satisfied. We propose an algorithm, as a dual-based solution, which allocates source rates for the next time interval in a distributed fashion, given the knowledge of network parameters in advance. Also, we extend the algorithm to the case that the problem data is not known fully in advance to capture more realistic scenarios. Through numerical experiments, we show that our proposed algorithm attains higher average link utilization and a wider range of feasible scenarios in comparison with the best, to our knowledge, rate control schemes that may guarantee such constraints on delay.","Delays,
Resource management,
Control systems,
Streaming media,
Algorithm design and analysis,
Quality of service,
Electronic mail"
Wireless Mesh networking Protocol for sustained throughput in edge computing,"It is critical to provide sustained data throughput in edge computing, where several sensor devices generate information that needs to be fused and used for decision making in e.g., disaster incident scenes. To this end, we compare the effectiveness of two protocols, Hybrid Wireless Mesh Protocol (HWMP) and Greedy Perimeter Stateless Routing (GPSR), based upon their ability to stream data in a mesh network. We model the two protocols using three topologies consisting of a sender, receiver and multiple Mesh Points to relay the data. We perform experiments varying the density, scale and failure rates of the topology. Finally, we evaluate the effectiveness of both protocols by comparing the total throughput from sender to receiver in each experiment. We show that geographic routing algorithms such as GPSR, given their potential for statelessness, can be more effective in delivering sustained data throughput than the 802.11s standard HWMP in high failure and large scale topology cases.","Throughput,
Routing,
Protocols,
Network topology,
Measurement,
Mesh networks,
Topology"
DeepList: Learning Deep Features With Adaptive Listwise Constraint for Person Reidentification,"Person reidentification (re-id) aims to match a specific person across nonoverlapping cameras, which is an important but challenging task in video surveillance. Conventional methods mainly focus either on feature constructing or metric learning. Recently, some deep learning-based methods have been proposed to learn image features and similarity measures jointly. However, current deep models for person re-id are usually trained with either pairwise loss, where the number of negative pairs greatly outnumbering that of positive pairs may lead the training model to be biased toward negative pairs or constant margin hinge loss, without considering the fact that hard negative samples should be paid more attention in the training stage. In this paper, we propose to learn deep representations with an adaptive margin listwise loss. First, ranking lists instead of image pairs are used as training samples, in this way, the problem of data imbalance is relaxed. Second, by introducing an adaptive margin parameter in the listwise loss function, it can assign larger margins to harder negative samples, which can be interpreted as an implementation of the automatic hard negative mining strategy. To gain robustness against changes in poses and part occlusions, our architecture combines four convolutional neural networks, each of which embeds images from different scales or different body parts. The final combined model performs much better than each single model. The experimental results show that our approach achieves very promising results on the challenging CUHK03, CUHK01, and VIPeR data sets.","Training,
Probes,
Measurement,
Feature extraction,
Fasteners,
Machine learning,
Computer architecture"
Multi-Task Rank Learning for Image Quality Assessment,"In practice, images are distorted by more than one distortion. For image quality assessment (IQA), existing machine learning (ML)-based methods generally establish a unified model for all the distortion types, or each model is trained independently for each distortion type, which is therefore distortion aware. In distortion-aware methods, the common features among different distortions are not exploited. In addition, there are fewer training samples for each model training task, which may result in overfitting. To address these problems, we propose a multi-task learning framework to train multiple IQA models together, where each model is for each distortion type; however, all the training samples are associated with each model training task. Thus, the common features among different distortion types and the said underlying relatedness among all the learning tasks are exploited, which would benefit the generalization ability of trained models and prevent overfitting possibly. In addition, pairwise image quality ranking instead of image quality rating is optimized in our learning task, which is fundamentally departed from traditional ML-based IQA methods toward better performance. The experimental results confirm that the proposed multi-task rank-learning-based IQA metric is prominent against all state-of-the-art nonreference IQA approaches.","Distortion,
Training,
Image quality,
Electronic mail,
Solid modeling,
Transform coding,
Predictive models"
Security-Reliability Tradeoff Analysis of Artificial Noise Aided Two-Way Opportunistic Relay Selection,"In this paper, we investigate the physical-layer security of cooperative communications relying on multiple two-way relays using the decode-and-forward (DF) protocol in the presence of an eavesdropper, where the eavesdropper appears to tap the transmissions of both the source and of the relay. The design tradeoff to be resolved is that the throughput is improved by invoking two-way relaying, but the secrecy of wireless transmissions may be degraded, since the eavesdropper may overhear the signals transmitted by both the source and relay nodes. We conceive an artificial noise aided two-way opportunistic relay selection (ANaTWORS) scheme for enhancing the security of the pair of source nodes communicating with the assistance of multiple two-way relays. Furthermore, we analyze both the outage probability and intercept probability of the proposed ANaTWORS scheme, where the security and reliability are characterized in terms of the intercept probability and the security outage probability. For comparison, we also provide the security-reliability tradeoff (SRT) analysis of both the traditional direct transmission and of the one-way relaying schemes. It is shown that the proposed ANaTWORS scheme outperforms both the conventional direct transmission, as well as the one-way relay methods in terms of its SRT. More specifically, in the low main-user-to-eavesdropper ratio (MUER) region, the proposed ANaTWORS scheme is capable of guaranteeing secure transmissions, whereas no SRT gain is achieved by conventional one-way relaying. In fact, the one-way relaying scheme may even be inferior to the traditional direct transmission scheme in terms of its SRT.",
Modeling and Pre-Treatment of Photon-Starved CT Data for Iterative Reconstruction,"An increasing number of X-ray CT procedures are being conducted with drastically reduced dosage, due at least in part to advances in statistical reconstruction methods that can deal more effectively with noise than can traditional techniques. As data become photon-limited, more detailed models are necessary to deal with count rates that drop to the levels of system electronic noise. We present two options for sinogram pre-treatment that can improve the performance of photon-starved measurements, with the intent of following with model-based image reconstruction. Both the local linear minimum mean-squared error (LLMMSE) filter and pointwise Bayesian restoration (PBR) show promise in extracting useful, quantitative information from very low-count data by reducing local bias while maintaining the lower noise variance of statistical methods. Results from clinical data demonstrate the potential of both techniques.",
Deadbeat Weighted Average Current Control With Corrective Feed-Forward Compensation for Microgrid Converters With Nonstandard LCL Filter,"Microgrid converters are required to have the capability of both grid-tied mode and islanding mode operation. For this dual-mode operation, large shunt capacitors are often used in the interfacing converter output LCL filter, as it can help to stabilize supply voltage and to reduce switching ripple pollutions to sensitive loads during autonomous islanding operation. At the same time, this modification causes a few challenges, including the low-frequency harmonic distortions, the steady-state tracking errors and the slow dynamic response, to the line current regulation during grid-tied operation. To overcome these drawbacks, a modified weighted average current controller is developed. First, to realize a fast line current response, a deadbeat control of weighted average current is developed based on a reduced-order virtual filter plant. Second, a grid voltage feed-forward term is added to the weighted average current reference to mitigate the steady-state line current tracking errors. Note that this compensation term is directly added to the current reference, thus, it is very well decoupled from the closed-loop current regulator. In addition, it can be seen that the low-order line current harmonics caused by grid voltage distortion is inherently compensated by this proposed corrective feed-forward control.",
PDA: Semantically Secure Time-Series Data Analytics with Dynamic Subgroups,"Third-party analysis on private records is becoming increasingly important due to the widespread data collection for various analysis purposes. However, the data in its original form often contains sensitive information about individuals, and its publication will severely breach their privacy. In this paper, we present a novel Privacy-preserving Data Analytics framework PDA, which allows a third-party aggregator to obliviously conduct many different types of polynomial-based analysis on private data records provided by a dynamic sub-group of users. Notably, every user needs to keep only O(n) keys to join data analysis among O(2n) different groups of users, and any data analysis that is represented by polynomials is supported by our framework. Besides, a real implementation shows the performance of our framework is comparable to the peer works who present ad-hoc solutions for specific data analysis applications. Despite such nice properties of PDA, it is provably secure against a very powerful attacker (chosen-plaintext attack) even in the Dolev-Yao network model where all communication channels are insecure.","Data analysis,
Data privacy,
Privacy,
Handheld computers,
Encryption"
CLAP: Component-Level Approximate Processing for Low Tail Latency and High Result Accuracy in Cloud Online Services,"Modern latency-critical online services such as search engines often process requests by consulting large input data spanning massive parallel components. Hence the tail latency of these components determines the service latency. To trade off result accuracy for tail latency reduction, existing techniques use the components responding before a specified deadline to produce approximate results. However, they skip a large proportion of components when load gets heavier, thus incurring large accuracy losses. In this paper, we propose CLAP to enable component-level approximate processing of requests for low tail latency and small accuracy losses. CLAP aggregates information of input data to create small aggregated data points. Using these points, CLAP reduces latency variance of parallel components and allows them to produce initial results quickly; CLAP also identifies the parts of input data most related to requests' result accuracies, thus first using these parts to improve the produced results to minimize accuracy losses. We evaluated CLAP using real services and datasets. The results show: (i) CLAP reduces tail latency by 6.46 times with accuracy losses of 2.2 percent compared to existing exact processing techniques; (ii) when using the same latency, CLAP reduces accuracy losses by 31.58 times compared to existing approximate processing techniques.","Indexes,
Web pages,
Search engines,
Aggregates,
Recommender systems,
Correlation,
Web search"
Sequence-Impedance-Based Harmonic Stability Analysis and Controller Parameter Design of Three-Phase Inverter-Based Multibus AC Power Systems,"Three-phase inverter-based multibus ac power systems could suffer from the harmonic instability issue. The existing impedance-based stability analysis method using the Nyquist stability criterion once requires the calculation of right-half-plane (RHP) poles of impedance ratios, which would result in a heavy computation burden for complicated systems. In order to analyze the harmonic stability of multibus ac systems consisting of both voltage-controlled and current-controlled inverters without the need for RHP pole calculation, this paper proposes two sequence-impedance-based harmonic stability analysis methods. Based on the summary of all major connection types including mesh, the proposed Method 1 can analyze the harmonic stability of multibus ac systems by adding the components one by one from nodes in the lowest level to areas in the highest system level, and accordingly, applying the stability criteria multiple times in succession. The proposed Method 2 is a generalized extension of the impedance-sum-type criterion to be used for the harmonic stability analysis of any multibus ac systems based on Cauchy's theorem. The inverter controller parameters can be designed in the forms of stability regions in the parameter space, by repetitively applying the proposed harmonic stability analysis methods. Experimental results of inverter-based multibus ac systems validate the effectiveness of the proposed harmonic stability analysis methods and parameter design approach.",
Hybrid Analog and Digital Beamforming for mmWave OFDM Large-Scale Antenna Arrays,"Hybrid analog and digital beamforming is a promising candidate for large-scale millimeter wave (mmWave) multiple-input multiple-output (MIMO) systems because of its ability to significantly reduce the hardware complexity of the conventional fully digital beamforming schemes while being capable of approaching the performance of fully digital schemes. Most of the prior work on hybrid beamforming considers frequency-flat channels. However, broadband mmWave systems are frequency-selective. In broadband systems, it is desirable to design common analog beamformer for the entire band while employing different digital (baseband) beamformers in different frequency sub-bands. This paper considers the hybrid beamforming design for systems with orthogonal frequency division multiplexing modulation. First, for a single-user MIMO (SU-MIMO) system where the hybrid beamforming architecture is employed at both transmitter and receiver, we show that hybrid beamforming with a small number of radio frequency (RF) chains can asymptotically approach the performance of fully digital beamforming for a sufficiently large number of transceiver antennas due to the sparse nature of the mmWave channels. For systems with a practical number of antennas, we then propose a unified heuristic design for two different hybrid beamforming structures, the fully connected and the partially connected structures, to maximize the overall spectral efficiency of an mmWave MIMO system. Numerical results are provided to show that the proposed algorithm outperforms the existing hybrid beamforming methods, and for the fully connected architecture, the proposed algorithm can achieve spectral efficiency very close to that of the optimal fully digital beamforming but with much fewer RF chains. Second, for the multiuser multiple-input single-output case, we propose a heuristic hybrid percoding design to maximize the weighted sum rate in the downlink and show numerically that the proposed algorithm with practical number of RF chains can already approach the performance of fully digital beamforming.","Array signal processing,
OFDM,
Algorithm design and analysis,
Antenna arrays,
Radio frequency,
Precoding,
Covariance matrices"
The Useful Impact of Carrier Aggregation: A Measurement Study in South Korea for Commercial LTE-Advanced Networks,"Carrier aggregation (CA) is one of the main features of the long-term evolution (LTE)-Advanced network that was introduced in Third-Generation Partnership Project (3GPP) Release 10 (Rel-10). CA was applied to commercial cellular networks in South Korea in the middle of 2013; however, the performance of CA in commercial networks has not yet been well studied. This article describes how CA technology is applied to a commercial network and how it performs. An extensive field drive test was conducted to compare CA technology performance with that of non-CA technology by using commercial evolved node B (eNB) and user equipment (UE) in a dense urban area and a suburban area. Downlink (DL) CA with two component carriers (CCs) of 30-MHz aggregated bandwidth (BW) was used in the network with one CC of 20-MHz BW at Band 7 and the other with 10-MHz BW at Band 5. The measurement results verified that the maximum DL data rate of CA reached 203 Mb/s, close to the theoretical peak bit rate of 225 Mb/s, and the average DL data rate was 76 Mb/s during the suburban drive test. As a comparison, the maximum DL data rate of single-carrier Band 7 was 141 Mb/s, and the average DL data rate was 51 Mb/s in the same area.","Long Term Evolution,
MIMO,
Mobile communication,
Area measurement,
Antenna measurements,
3GPP,
Transmitting antennas"
"A High-Linearity, Ring-Oscillator-Based, Vernier Time-to-Digital Converter Utilizing Carry Chains in FPGAs","Time-to-digital converters (TDCs) using dedicated carry chains of field programmable gate arrays (FPGAs) are usually organized in tapped-delay-line type which are intensively researched in recent years. However this method incurs poor differential nonlinearity (DNL) which arises from the inherent uneven bin granularity. This paper proposes a TDC architecture which utilizes the carry chains in a quite different manner in order to alleviate this long-standing problem. Two independent carry chains working as the delay lines for the fine time interpolation are organized in a ring-oscillator-based Vernier style and the time difference between them is finely adjusted by assigning different number of basic delay cells. A specific design flow is described to obtain the desired delay difference. The TDC was implemented on a Stratix III FPGA. Test results show that the obtained resolution is 31 ps and the DNL\INL is in the range of (-0.080 LSB, 0.073 LSB)\(-0.087 LSB, 0.091 LSB). This demonstrates that the proposed architecture greatly improves linearity compared to previous techniques. Additionally the resource cost is rather low which uses only 319 LUTs and 104 registers per TDC channel.","Delays,
Delay lines,
Clocks,
Radiation detectors,
Ring oscillators,
Field programmable gate arrays"
Effective Capacity of NOMA and a Suboptimal Power Control Policy With Delay QoS,"In order to apply downlink nonorthogonal multiple access (NOMA) to delay-sensitive transmissions, we consider NOMA with delay quality of service (QoS) constraints and effective capacity with power control when the channel state information is available in this paper. As the power control problem to maximize the sum effective capacity with delay QoS constraints is not a convex problem, we propose a suboptimal approach based on the partial effective capacity. The resulting power control policy can be seen as a generalization of a well-known approach, which is the truncated channel inversion power control (TCIPC) policy, to NOMA. We can further optimize the NOMA-TCIPC policy with QoS constraints and confirm that the resulting policy can guarantee delay QoS from simulation results.","NOMA,
Power control,
Quality of service,
Delays,
Downlink,
Resource management,
Transmitters"
Near Optimal Data Gathering in Rechargeable Sensor Networks with a Mobile Sink,"We study data gathering problem in Rechargeable Sensor Networks (RSNs) with a mobile sink, where rechargeable sensors are deployed into a region of interest to monitor the environment and a mobile sink travels along a pre-defined path to collect data from sensors periodically. In such RSNs, the optimal data gathering is challenging because the required energy consumption for data transmission changes with the movement of the mobile sink and the available energy is time-varying. In this paper, we formulate data gathering problem as a network utility maximization problem, which aims at maximizing the total amount of data collected by the mobile sink while maintaining the fairness of network. Since the instantaneous optimal data gathering scheme changes with time, in order to obtain the globally optimal solution, we first transform the primal problem into an approximate network utility maximization problem by shifting the energy consumption conservation and analyzing necessary conditions for the optimal solution. As a result, each sensor does not need to estimate the amount of harvested energy and the problem dimension is reduced. Then, we propose a Distributed Data Gathering Approach (DDGA), which can be operated distributively by sensors, to obtain the optimal data gathering scheme. Extensive simulations are performed to demonstrate the efficiency of the proposed algorithm.",
User Interface Design with Combinatorial Optimization,"Optimization methods have revolutionized almost every field of engineering design, so why not user interface design? The author reviews progress and challenges in model-driven UI optimization, in which an optimizer utilizes predictive models of human perception, behavior, and experience to anticipate users' responses to computer-generated designs.",
Design of a New Mobile-Optimized Remote Laboratory Application Architecture for M-Learning,"As mobile learning (M-Learning) has demonstrated increasing impacts on online education, more and more mobile applications are designed and developed for the M-Learning. In this paper, a new mobile-optimized application architecture using Ionic framework is proposed to integrate the remote laboratory into mobile environment for the M-Learning. With this mobile-optimized application architecture, remote experiment applications can use a common codebase to deploy native-like applications on many different mobile platforms such as iOS, Android, Windows Mobile, and Blackberry. To demonstrate the effectiveness of the proposed new architecture for M-Learning, an innovative remote networked proportional-integral-derivative control experiment has been successfully implemented based on this new application architecture. The performance is validated by the Baidu mobile cloud testing bed.",
No-Reference Quality Assessment of Deblurred Images Based on Natural Scene Statistics,"Blurring is one of the most common distortions in digital images. In the past decade, extensive image deblurring algorithms have been proposed to restore a latent clean image from its blurred version. However, very little work has been dedicated to the quality assessment of deblurred images, which may hinder further development of more advanced deblurring techniques. Motivated by this, this paper presents a no-reference quality metric for defocus deblured images based on Natural Scene Statistics (NSS). Two categories of NSS features are extracted in both the spatial and frequency domains to account for both the global and local aspects of distortions in deblurred images. Specifically, the spatial domain NSS features are used to characterize the global naturalness, and the frequency domain NSS features are used to portray the local structural distortions. All features are combined to train a support vector regression model for quality prediction of defocus deblurred images. The performance of the proposed metric is evaluated in a subjectively rated defocus deblurred image database. The experimental results demonstrate the advantages of the proposed metric over the relevant state-of-the-arts. As an application, the proposed metric is further used for benchmarking deblurring algorithms and very encouraging results are achieved.",
A dew computing solution for IoT streaming devices,"Most people refer to modern mobile and wireless ubiquitous solutions as an IoT application. The advances of the technology and establishment of cloud-based systems emerge the idea of the connected world over Internet based on distributed processing sites. In this paper, we discuss the dew computing architectural approach for IoT solutions and give an organizational overview of the dew server and its connections with IoT devices in the overall cloud-based solutions. Dew servers act as another computing layer in the cloud-based architecture for IoT solutions, and we present its specific goals and requirements. This is compared to the fog computing and cloudlet solutions with an overview of the overall computing trends. The dew servers are analyzed from architectural and organizational aspect as devices that collect, process and offload streaming data from the IoT sensors and devices, besides the communication with higher-level servers in the cloud.","Servers,
Cloud computing,
Computer architecture,
Mobile communication,
Intelligent sensors"
Resistive CAM Acceleration for Tunable Approximate Computing,"The Internet of Things significantly increases the amount of data generated, straining the processing capability of current computing systems. Approximate computing is a promising solution to accelerate computation by trading off energy and accuracy. In this paper, we propose a resistive content addressable memory (CAM) accelerator, called RCA, which exploits data locality to have an approximate memory-based computation. RCA stores high frequency patterns and performs computation inside CAM without using processing cores. During execution time, RCA searches an input operand among all prestored values on a CAM and returns the row with the nearest distance. To manage accuracy, we use a distance metric which considers the impact of each bit indices on computation accuracy. We evaluate an application of proposed RCA on CPU approximation, where RCA can be used as a stand-alone or as a hybrid computing unit besides CPU cores for tunable CPU approximation. We evaluate the architecture of the proposed RCA using HSPICE and multi2sim by testing our results on x86 CPU processor. Our evaluation shows that RCA can accelerate CPU computation by 12.6 and improve the energy efficiency by 6.6 as compared to a traditional CPU architecture, while providing acceptable quality of service.","Associative memory,
Nonvolatile memory,
Acceleration,
Approximate computing,
Computer architecture,
Resistance,
Hamming distance"
A Low-Complexity Pedestrian Detection Framework for Smart Video Surveillance Systems,"Pedestrian detection is a key problem in computer vision and is currently addressed with increasingly complex solutions involving compute-intensive features and classification schemes. In this scope, histogram of oriented gradients (HOG) in conjunction with linear support vector machine (SVM) classifier is considered to be the single most discriminative feature that has been adopted as a stand-alone detector as well as a key instrument in advance systems involving hybrid features and cascaded detectors. In this paper, we propose a pedestrian detection framework that is computationally less expensive as well as more accurate than HOG-linear SVM. The proposed scheme exploits the discriminating power of the locally significant gradients in building orientation histograms without involving complex floating point operations while computing the feature. The integer-only feature allows the use of powerful histogram inter-section kernel SVM classifier in a fast lookup-table-based implementation. Resultantly, the proposed framework achieves at least 3% more accurate detection results than HOG on standard data sets while being 1.8 and 2.6 times faster on conventional desktop PC and embedded ARM platforms, respectively, for a single scale pedestrian detection on VGA resolution video. In addition, hardware implementation on Altera Cyclone IV field-programmable gate array results in more than 40% savings in logic resources compared with its HOG-linear SVM competitor. Hence, the proposed feature and classification setup is shown to be a better candidate as the single most discriminative pedestrian detector than the currently accepted HOG-linear SVM.","Feature extraction,
Support vector machines,
Detectors,
Histograms,
Streaming media,
Kernel,
Real-time systems"
Big Data Driven Hidden Markov Model Based Individual Mobility Prediction at Points of Interest,"With the emergence of smartphones and location-based services, user mobility prediction has become a critical enabler for a wide range of applications, like location-based advertising, early warning systems, and citywide traffic planning. A number of techniques have been proposed to either conduct spatio-temporal mobility prediction or forecast the next-place. However, both produce diverse prediction performance for different users and display poor performance for some users. This paper focuses on investigating the effect of living habits on the models of spatio-temporal prediction and next-place prediction, and selects one from these two models for an individual to achieve effective mobility prediction at users' points of interest. Based on the hidden Markov model (HMM), a spatio-temporal predictor and a next-place predictor are proposed. Living habits are analyzed in terms of entropy, upon which users are clustered into distinct groups. With large-scale factual mobile data captured from a big city, we compare the proposed HMM-based predictors with existing state-of-the-art predictors and apply them to different user groups. The results demonstrate the robust performance of the two proposed mobility predictors, which outperform the state of the art for various user groups.","Hidden Markov models,
Predictive models,
Mobile communication,
Global Positioning System,
Trajectory,
Clustering algorithms,
Urban areas"
Dynamic Differential Privacy for ADMM-Based Distributed Classification Learning,"Privacy-preserving distributed machine learning becomes increasingly important due to the recent rapid growth of data. This paper focuses on a class of regularized empirical risk minimization machine learning problems, and develops two methods to provide differential privacy to distributed learning algorithms over a network. We first decentralize the learning algorithm using the alternating direction method of multipliers, and propose the methods of dual variable perturbation and primal variable perturbation to provide dynamic differential privacy. The two mechanisms lead to algorithms that can provide privacy guarantees under mild conditions of the convexity and differentiability of the loss function and the regularizer. We study the performance of the algorithms, and show that the dual variable perturbation outperforms its primal counterpart. To design an optimal privacy mechanism, we analyze the fundamental tradeoff between privacy and accuracy, and provide guidelines to choose privacy parameters. Numerical experiments using customer information database are performed to corroborate the results on privacy and utility tradeoffs and design.","Privacy,
Heuristic algorithms,
Data privacy,
Algorithm design and analysis,
Machine learning algorithms,
Risk management,
Databases"
Image Quality Assessment Based on Local Linear Information and Distortion-Specific Compensation,"Image quality assessment (IQA) is a fundamental yet constantly developing task for computer vision and image processing. Most IQA evaluation mechanisms are based on the pertinence of subjective and objective estimation. Each image distortion type has its own property correlated with human perception. However, this intrinsic property may not be fully exploited by existing IQA methods. In this paper, we make two main contributions to the IQA field. First, a novel IQA method is developed based on a local linear model that examines the distortion between the reference and the distorted images for better alignment with human visual experience. Second, a distortion-specific compensation strategy is proposed to offset the negative effect on IQA modeling caused by different image distortion types. These score offsets are learned from several known distortion types. Furthermore, for an image with an unknown distortion type, a convolutional neural network-based method is proposed to compute the score offset automatically. Finally, an integrated IQA metric is proposed by combining the aforementioned two ideas. Extensive experiments are performed to verify the proposed IQA metric, which demonstrate that the local linear model is useful in human perception modeling, especially for individual image distortion, and the overall IQA method outperforms several state-of-the-art IQA approaches.","Distortion,
Image quality,
Measurement,
Visualization,
Correlation,
Computational modeling,
Neural networks"
SEINA: A stealthy and effective internal attack in Hadoop systems,"Big data processing frameworks such as Hadoop [1] are now widely adopted, however the security issues in large scale systems have not been well studied yet. Unlike prior work on data privacy and protection, this paper investigates a potential attack from a compromised internal node against the overall system performance. We develop an effective attack launched from the compromised node that can significantly degrade the data processing performance of the cluster without being detected and blacklisted for job execution, also present a mitigation scheme that protects a Hadoop system from such attack. The results of experiments show that this attack greatly slows down the job executions in the native Hadoop system even with some basic defense mechanisms, however, our mitigation schem can keep the whole cluster running efficiently under such attack.",
Layered Downlink Precoding for C-RAN Systems With Full Dimensional MIMO,"The implementation of a cloud radio access network (C-RAN) with full dimensional (FD) multiple-input multiple-output (MIMO) is faced with the challenge of controlling the fronthaul overhead for the transmission of baseband signals as the number of horizontal and vertical antennas grows larger. This paper proposes to leverage the special low-rank structure of the FD-MIMO channel, which is characterized by a time-invariant elevation component and a time-varying azimuth component, by means of a layered precoding approach, to reduce the fronthaul overhead. According to this scheme, separate precoding matrices are applied for the azimuth and elevation channel components, with different rates of adaptation to the channel variations and correspondingly different impacts on the fronthaul capacity. Moreover, we consider two different central unit (CU)-radio unit (RU) functional splits at the physical layer, namely, the conventional C-RAN implementation and an alternative one in which coding and precoding are performed at the RUs. Via numerical results, it is shown that the layered schemes significantly outperform conventional nonlayered schemes, particularly in the regime of low fronthaul capacity and a large number of vertical antennas.","Precoding,
Azimuth,
Downlink,
Antenna arrays,
Coherence,
Baseband"
Improving Diversity in Evolutionary Algorithms: New Best Solutions for Frequency Assignment,"Metaheuristics have yielded very promising results for the frequency assignment problem (FAP). However, the results obtainable using currently published methods are far from ideal in complex, large-scale instances. This paper applies and extends some of the most recent advances in evolutionary algorithms to two common variants of the FAP, and shows how, in traditional techniques, two common issues affect their performance: 1) premature convergence and 2) the way in which neutral networks are handled. A recent replacement-based diversity management strategy is successfully applied to alleviate the premature convergence drawback. Additionally, by properly defining a distance metric, the performance in the presence of neutrality can also be greatly improved. The replacement strategy combines the principle of transforming a single-objective problem into a multiobjective one by considering diversity as an additional objective, with the idea of adapting the balance induced between exploration and exploitation to the requirements of the different optimization stages. Tests with 44 publicly available instances yield very competitive results. New best-known frequency plans were generated for 11 instances, whereas in the remaining ones the best-known solutions were replicated. Comparisons with a large number of strategies designed to delay convergence of the population clearly show the advantages of our novel proposals.",
The Science of Sweet Dreams: Predicting Sleep Efficiency from Wearable Device Data,"Lack of sleep can erode mental and physical well-being, often exacerbating health problems such as obesity. Wearable devices that capture and analyze sleep quality through predictive methodologies can help patients and medical practitioners make behavioral health decisions that can lead to better sleep and improved health. In the web extra at https://youtu.be/_zL-t4gk210, guest editor Katarzyna Wac interviews lead author Aarti Sathyanarayana, a PhD student in the University of Minnesota's Department of Computer Science.","Sleep apnea,
Biomedical monitoring,
Data models,
Monitoring,
Predictive models,
Activity recognition,
Quality of service,
Data analysis,
Tracking"
Plug-in Free Web-Based 3-D Interactive Laboratory for Control Engineering Education,"This paper introduces the design and implementation of a plug-in free online 3-D interactive laboratory based on networked control system laboratory (NCSLab) framework. The system relying only on HTML5 provides full supports for control engineering experimentation. The users are allowed to design their own control algorithms and apply them to the remote test rigs. Using the web-based interface, multiple widgets such as real-time charts, virtual gauges, and live images are available to customize the monitoring interfaces. To enhance the sense of immersion, 3-D animations which are synchronized with the remote experimental processes are also provided. The users can watch and interact with the remote experiments through the 3-D replicas. Various HTML5 based toolkits are integrated seamlessly under the NCSLab framework. NCSLab provides visualized services for the whole process of control experimentation including remote monitoring, tuning, configuration, and control algorithm implementation. As the network delay could disturb the 3-D representation, a communication scheme using web protocols is also implemented. The feedback from teaching shows the general acceptance and effectiveness of NCSLab is notably high. As most existing online laboratories adopt either native applications or plug-ins, the methodologies and technologies used in NCSLab could be insightful for other online laboratories toward web-based cross-platform systems.","Real-time systems,
Algorithm design and analysis,
Monitoring,
Animation,
Visualization,
Synchronization,
Java"
Designing Optimal and Resilient Intrusion Detection Architectures for Smart Grids,"We formulate two intrusion detection system (IDS) design problems for smart grids. The first one optimally places IDS devices on communication paths, while the second one addresses the resilient communications requirement and enhances the first problem with the provisioning of K distinct back-up paths and additional IDS devices. The developed problems harmonize real-time communication requirements with the infrastructure's resource limitations (e.g., bandwidth), detection requirements, and the available budget. A heuristic approach is developed based on the column-generation model to reduce the computation time. Experimental results comprising the Romanian 440 kV and 220 kV power transmission networks, the Romanian Educational Communication Network, alongside synthetic topologies demonstrate the effectiveness and applicability of the heuristic methodology on large problem instances.",
Reward Rate Maximization and Optimal Transmission Policy of EH Device With Temporal Death in EH-WSNs,"For the perpetual wireless sensor network (WSN), energy harvesting (EH) technology is emerging as a promising solution. However, the randomness and the instability of the harvested energy may lead to the occurrence of the temporal death, which is harmful to the functions of the WSN, and has negative impact on the quality of service of the network. With temporal death being taken into account, this paper proposes a novel and overall framework, namely, a multi-layer Markov fluid queue (MLMFQ) model, for modeling and analyzing the data transmission nature of the EH devices (EHDs). We formulate the model of the whole system in terms of MLMFQ, and obtain the stead-state probabilities of the EHD. We study the issue of how to maximize the steady-state average reward rate of the reported data packets. We then propose an optimization model, in which one can maximize the overall steady-state average reward rate with relation to transmission policy under the specific constraints. On this basis, we are able to propose an algorithm for calculating the optimal transmission policy of the EHD with temporal death. We validate our results using a numerical example and report some interesting findings from our numerical studies.",
Bounds for Eigenvalues of Spatial Correlation Matrices With the Exponential Model in MIMO Systems,"It is important to understand the properties of spatial correlation matrices in multiple-input multiple-output (MIMO) systems. In this paper, we derive new bounds for the maximum and minimum eigenvalues of spatial correlation matrices characterized by the exponential model. The new upper bounds for the maximum and minimum eigenvalues are tighter than the previously known bounds. Moreover, the new lower bound for the minimum eigenvalue, which has not yet been derived in the literature as a function of the number of antennas, is also tight. In order to predict the behavior of these bounds, we investigate the gap between the lower and upper bounds. These bounds are directly applicable to the analysis of wireless communication scenarios, such as uniform planar arrays and ill-conditioned channels, which are expected to be widely used for massive MIMO systems.","Eigenvalues and eigenfunctions,
Correlation,
MIMO,
Upper bound,
Transmission line matrix methods,
Antennas,
Training"
A Dissipative Systems Theory for FDTD With Application to Stability Analysis and Subgridding,"A connection between the finite-difference time-domain (FDTD) method and the theory of dissipative systems is established. The FDTD equations for a rectangular region are interpreted as a dynamical system having the magnetic field on the boundary as input and the electric field on the boundary as output. Suitable expressions for the energy stored in the region and the energy absorbed from the boundaries are introduced, and used to show that the FDTD system is dissipative under a generalized Courant-Friedrichs-Lewy condition. Based on the concept of dissipation, a powerful theoretical framework to investigate the stability of FDTD-like methods is devised. The new method makes FDTD stability proofs simpler, more intuitive, and modular. Stability conditions can indeed be given on the individual components (e.g., boundary conditions, meshes, and embedded models) instead of the whole coupled setup. As an example of application, we derive a new subgridding scheme with support for material traverse, arbitrary grid refinement, and guaranteed stability. The method is easy to implement and has a straightforward stability proof. Numerical results confirm its stability, low reflections, and ability to handle material traverse.",
"A Portable FMCW Interferometry Radar With Programmable Low-IF Architecture for Localization, ISAR Imaging, and Vital Sign Tracking","This paper presents a portable radar system for short-range localization, inverse synthetic aperture radar imaging, and vital sign tracking. The proposed sensor incorporates frequency-modulated continuous-wave (FMCW) and interferometry (Doppler) modes, which enable this radar system to obtain both absolute range information and tiny vital signs (i.e., respiration and heartbeat) of human targets. These two different operation modes can be switched through an on-board microcontroller. To simplify the system, the proposed radar utilizes the audio card of a laptop to sample the baseband signal. The FMCW mode of the radar uses operational-amplifier-based circuits to generate an analog sawtooth signal and a reference pulse sequence (RPS). The RPS is locked to the sawtooth signal to obtain coherence for the radar system. For the interferometry mode, a low-intermediate-frequency modulation method is implemented to avoid the slow vital signs from being distorted by the high-pass filter of the audio card. Several experiments were carried out to reveal the capability and distinct operational features of the proposed portable hybrid radar. The experiments also showed that the system can easily detect glass, which is usually difficult to identify for optical-based sensors. In addition, 2-D scanning in a complex environment revealed that the proposed radar was able to differentiate human targets from other objects. Moreover, ISAR images were used to isolate moving human targets from surrounding clutter. Finally, the proposed radar also demonstrated its ability to accurately measure vital signs when a human subject sits still.","Doppler radar,
Interferometry,
Robot sensing systems,
Radar imaging,
Voltage-controlled oscillators,
Doppler effect"
Backhaul-aware robust 3D drone placement in 5G+ wireless networks,"Using drones as flying base stations is a promising approach to enhance the network coverage and area capacity by moving supply towards demand when required. However deployment of such base stations can face some restrictions that need to be considered. One of the limitations in drone base stations (drone-BSs) deployment is the availability of reliable wireless backhaul link. This paper investigates how different types of wireless backhaul offering various data rates would affect the number of served users. Two approaches, namely, network-centric and user-centric, are introduced and the optimal 3D backhaul-aware placement of a drone-BS is found for each approach. To this end, the total number of served users and sum-rates are maximized in the network-centric and user-centric frameworks, respectively. Moreover, as it is preferred to decrease drone-BS movements to save more on battery and increase flight time and to reduce the channel variations, the robustness of the network is examined as how sensitive it is with respect to the users displacements.",
Cross-Layer Design for Downlink Multihop Cloud Radio Access Networks With Network Coding,"There are two fundamentally different fronthaul techniques in the downlink communication of cloud radio access network (C-RAN): the data-sharing strategy and the compression-based strategy. Under the former strategy, each user's message is multicast from the central processor (CP) to all the serving remote radio heads (RRHs) over the fronthaul network, which then cooperatively serve the users through joint beamforming; while under the latter strategy, the user messages are first beamformed then quantized at the CP, and the compressed signal is unicast to the corresponding RRH, which then decompresses its received signal for wireless transmission. Previous works show that in general the compression-based strategy outperforms the data-sharing strategy. This paper, on the other hand, points out that in a C-RAN model where the RRHs are connected to the CP via multihop routers, data-sharing can be superior to compression if the network coding technique is adopted for multicasting user messages to the cooperating RRHs, and the RRH's beamforming vectors, the user-RRH association, and the network coding design over the fronthaul network are jointly optimized based on the techniques of sparse optimization and successive convex approximation. This is in comparison to the compression-based strategy, where information is unicast over the fronthaul network by simple routing, and the RRH's compression noise covariance and beamforming vectors, as well as the routing strategy over the fronthaul network are jointly optimized based on the successive convex approximation technique. The observed gain in overall network throughput is due to that information multicast is more efficient than information unicast over the multihop fronthaul of a C-RAN.",
Energy Efficient User Association and Power Allocation in Millimeter-Wave-Based Ultra Dense Networks With Energy Harvesting Base Stations,"Millimeter wave (mmWave) communication technologies have recently emerged as an attractive solution to meet the exponentially increasing demand on mobile data traffic. Moreover, ultra dense networks (UDNs) combined with mmWave technology are expected to increase both energy efficiency and spectral efficiency. In this paper, user association and power allocation in mmWave-based UDNs is considered with attention to load balance constraints, energy harvesting by base stations, user quality of service requirements, energy efficiency, and cross-tier interference limits. The joint user association and power optimization problem are modeled as a mixed-integer programming problem, which is then transformed into a convex optimization problem by relaxing the user association indicator and solved by Lagrangian dual decomposition. An iterative gradient user association and power allocation algorithm is proposed and shown to converge rapidly to an optimal point. The complexity of the proposed algorithm is analyzed and its effectiveness compared with existing methods is verified by simulations.","Resource management,
Interference,
Quality of service,
Energy harvesting,
Base stations,
Macrocell networks,
Electronic mail"
Human Motion Tracking by Multiple RGBD Cameras,"The advent of low-cost depth cameras, such as the Microsoft Kinect in the consumer market, has made many indoor applications and games based on motion tracking available to the everyday user. However, it is a large challenge to track human motion via such a camera because of its low-quality images, missing depth values, and noise. In this paper, we propose a novel human motion capture method based on a cooperative structure of multiple low-cost RGBD cameras, which can effectively avoid these problems. This structure can also manage the problem of body occlusions that appears when a single camera is used. Moreover, the whole process does not require training data, which makes this approach easily deployed and reduces operation time. We use the color image, depth image, and point cloud acquired in each view as the data source, and an initial pose is extracted in our optimization framework by aligning multiple point clouds from different cameras. The pose is dynamically updated by combining a filtering approach with a Markov model to estimate new poses in video streams. To verify the efficiency and robustness of our approach, we capture a wide variety of human actions via three cameras in indoor scenes and compare the tracking results of the proposed method to those of the current state-of-the-art methods. Moreover, our system is tested on more complex situations, in which multiple humans move within a scene, possibly occluding each other to some extent. The actions of multiple humans are tracked simultaneously, which would assist group behavior analysis.",
Three-Dimensional Local Binary Patterns for Hyperspectral Imagery Classification,"The local binary pattern (LBP) is a simple and efficient texture descriptor for image processing. Recently, LBP has been introduced for feature extraction of hyperspectral imagery. Specifically, the LBP codes are extracted from the 2-D band images to capture the spatial correlation among neighboring pixels, and then the statistical histogram features from all bands, which could estimate the underlying distribution in local area, are concatenated together for pixel-wise classification. However, since hyperspectral imagery contains rich spectral and spatial information, which is actually a 3-D data cube, the 2-D LBP (2-DLBP) model cannot fully exploit the joint spectral-spatial structure. In this paper, the 2-DLBP has been extended into 3-D LBP (3-DLBP) model through forming a 3-D regular octahedral frame to characterize the spectral-spatial relationship. In order to reflect the local continuous property of hyperspectral data in both the spectral and spatial domains, while ensuring the rotational invariance of the 3-DLBP model, the code patterns of 3-DLBP model have been divided into eight groups (including seven groups of “dense” patterns and one group of “nondense” patterns) based on the consistency of spectral-spatial topology structure. Specifically, the patterns in seven “dense” groups correspond to the microstructures in the 3-D domains (such as spots, edges, and flat areas), which has a high percentage in all the 3-DLBP patterns, while the rest patterns are aggregated and treated as the “nondense” patterns. The proposed method is thus called 3-D dense LBP (3-D2LBP) model. Moreover, instead of taking zero as the hard threshold, a slack variable has been introduced to enable the difference between the central pixel and the neighboring ones varying in a small interval, which could greatly decrease the impact of spectral variability and noise, and the discriminative power of the features has been further boosted. The slack threshold-based 3-D2LBP model is named ST-3-D2LBP. A series of experiments is conducted on three real hyperspectral imageries to demonstrate the effectiveness of the proposed two 3-D2LBP-based methods. The experimental results show that the performance of the proposed ST-3-D2LBP is significantly superior to that of 2-DLBP, which is also better than the 3-D2LBP model and several state-of-the-art hyperspectral classification methods.",
Retrieval Compensated Group Structured Sparsity for Image Super-Resolution,"Sparse representation-based image super-resolution is a well-studied topic; however, a general sparse framework that can utilize both internal and external dependencies remains unexplored. In this paper, we propose a group-structured sparse representation approach to make full use of both internal and external dependencies to facilitate image super-resolution. External compensated correlated information is introduced by a two-stage retrieval and refinement. First, in the global stage, the content-based features are exploited to select correlated external images. Then, in the local stage, the patch similarity, measured by the combination of content and high-frequency patch features, is utilized to refine the selected external data. To better learn priors from the compensated external data based on the distribution of the internal data and further complement their advantages, nonlocal redundancy is incorporated into the sparse representation model to form a group sparsity framework based on an adaptive structured dictionary. Our proposed adaptive structured dictionary consists of two parts: one trained on internal data and the other trained on compensated external data. Both are organized in a cluster-based form. To provide the desired over-completeness property, when sparsely coding a given LR patch, the proposed structured dictionary is generated dynamically by combining several of the nearest internal and external orthogonal subdictionaries to the patch instead of selecting only the nearest one as in previous methods. Extensive experiments on image super-resolution validate the effectiveness and state-of-the-art performance of the proposed method. Additional experiments on contaminated and uncorrelated external data also demonstrate its superior robustness.","Dictionaries,
Image resolution,
Data models,
Adaptation models,
Image reconstruction,
Training,
Encoding"
Aggregated Packet Transmission in Duty-Cycled WSNs: Modeling and Performance Evaluation,"Duty cycling (DC) is a popular technique for energy conservation in wireless sensor networks (WSNs) that allows nodes to wake up and sleep periodically. Typically, a single-packet transmission (SPT) occurs per cycle, leading to possibly long delay. With aggregated packet transmission (APT), nodes transmit a batch of packets in a single cycle. The potential benefits brought by an APT scheme include shorter delay, higher throughput, and higher energy efficiency. In the literature, different analytical models have been proposed to evaluate the performance of SPT schemes. However, no analytical models for the APT mode on synchronous DC medium access control (MAC) mechanisms exist. In this paper, we first develop a 3-D discrete-time Markov chain (DTMC) model to evaluate the performance of an APT scheme with packet retransmission enabled. The proposed model captures the dynamics of the state of the queue of nodes and the retransmission status and the evolution of the number of active nodes in the network, i.e., nodes with a nonempty queue. We then study the number of retransmissions needed to transmit a packet successfully. Based on the observations, we develop another less-complex DTMC model with infinite retransmissions, which embodies only two dimensions. Furthermore, we extend the 3-D model into a 4-D model by considering error-prone channel conditions. The proposed models are adopted to determine packet delay, throughput, packet loss, energy consumption, and energy efficiency. Furthermore, the analytical models are validated through discrete-event-based simulations. Numerical results show that an APT scheme achieves substantially better performance than its SPT counterpart in terms of delay, throughput, packet loss, and energy efficiency and that the developed analytical models reveal precisely the behavior of the APT scheme.","Wireless sensor networks,
Media Access Protocol,
Analytical models,
Delays,
Three-dimensional displays,
Solid modeling,
Numerical models"
Cartoon and Texture Decomposition-Based Color Transfer for Fabric Images,"A color design process for fabric images can resort to a solution of a color transfer problem based on given color themes. Usually, the color transfer process contains an image segmentation phase and an image construction phase. In this paper, a novel color transfer method for fabric images is proposed. Compared with classical color transfer methods, the new method has the following three main innovations. First, the new method, in its image segmentation phase, follows an assumption that a fabric image can be decomposed into cartoon and texture components, which means the new color transfer method, in its image segmentation, phase incorporates an image decomposition process. The advantage of the innovation is that the cartoon component is more suitable than the original image to be used to partition the fabric image. Second, the new color transfer method can generate more vivid color transfer results since the above texture component is used to describe yarn texture details in the image construction phase. Third, the total generalized variation (TGV) regularizer is used to further improve the performance of image decomposition. Here, the TGV regularizer is good at estimating the weak lightness variation of the cartoon component with the CIELab color scheme. In addition, by using the augmented Lagrange multiplier method, we derive an efficient algorithm to search for the solutions to the proposed color transfer problem. Numerical results demonstrate that the proposed color transfer method can generate better results for fabric images.","Image color analysis,
Fabrics,
Image decomposition,
Image segmentation,
Feature extraction,
Algorithm design and analysis,
Histograms"
RAP-CLA: A Reconfigurable Approximate Carry Look-Ahead Adder,"In this paper, we propose a fast yet energy-efficient reconfigurable approximate carry look-ahead adder (RAP-CLA). This adder has the ability of switching between the approximate and exact operating modes making it suitable for both error-resilient and exact applications. The structure, which is more area and power efficient than state-of-the-art reconfigurable approximate adders, is achieved by some modifications to the conventional carry look ahead adder (CLA). The efficacy of the proposed RAP-CLA adder is evaluated by comparing its characteristics to those of two state-of-the-art reconfigurable approximate adders as well as the conventional (exact) CLA in a 15nm FinFET technology. The results reveal that, in the approximate operating mode, the proposed 32-bit adder provides up to 55% and 28% delay and power reductions compared to those of the exact CLA, respectively, at the cost of up to 35.16% error rate. It also provides up to 49% and 19% lower delay and power consumption, respectively, compared to other approximate adders considered in this work. Finally, the effectiveness of the proposed adder on two image processing applications of smoothing and sharpening is demonstrated. The study shows that, on average, PSNR reductions of 12% and 16%, respectively, may be achieved by employing the proposed adder.","Adders,
Delays,
Power demand,
Logic gates,
Multiplexing,
Error correction,
Generators"
Post-Quantum Cryptography on FPGA Based on Isogenies on Elliptic Curves,"To the best of our knowledge, we present the first hardware implementation of isogeny-based cryptography available in the literature. Particularly, we present the first implementation of the supersingular isogeny Diffie-Hellman (SIDH) key exchange, which features quantum-resistance. We optimize this design for speed by creating a high throughput multiplier unit, taking advantage of parallelization of arithmetic in Fp2, and minimizing pipeline stalls with optimal scheduling. Consequently, our results are also faster than software libraries running affine SIDH even on Intel Haswell processors. For our implementation at 85-bit quantum security and 128-bit classical security, we generate ephemeral public keys in 1.655 million cycles for Alice and 1.490 million cycles for Bob. We generate the shared secret in an additional 1.510 million cycles for Alice and 1.312 million cycles for Bob. On a Virtex-7, these results are approximately 1.5 times faster than known software implementations running the same 512-bit SIDH. Our results and observations show that the isogeny-based schemes can be implemented with high efficiency on reconfigurable hardware.","Elliptic curve cryptography,
Elliptic curves,
Quantum computing,
Computers,
Protocols"
Fuzzy Group-Based Intersection Control via Vehicular Networks for Smart Transportations,"Vehicular network has been recently used to achieve high efficient and flexible traffic scheduling at intersection roads for smart transportation systems. Different from existing works, where traffic signal is used to schedule waiting vehicles at each lane, we propose to divide vehicles in the same lane into small groups and schedule vehicle groups via wireless communication rather than traffic lights. Such direct scheduling of vehicles can reduce waiting time and improve fairness, especially when the traffic volume in different lanes is imbalanced. The key challenge in such a design lies in determining appropriate size of groups with respect to real-time traffic conditions. To cope with this issue, we propose a neuro-fuzzy network-based grouping mechanism, where the network is trained using reinforcement learning technique. Also, vehicle groups are scheduled via a neuro-fuzzy network. Simulations using ns3 are conducted to evaluate the performance of our algorithm and compare it with similar works. The results show that our algorithm can reduce waiting time and at the same time improve fairness in various cases, and the advantage against traffic light algorithms can be up to 40%.",
On the Security of Data Access Control for Multiauthority Cloud Storage Systems,"Data access control has becoming a challenging issue in cloud storage systems. Some techniques have been proposed to achieve the secure data access control in a semitrusted cloud storage system. Recently, K. Yang et al. proposed a basic data access control scheme for multiauthority cloud storage system (DAC-MACS) and an extensive data access control scheme (EDAC-MACS). They claimed that the DAC-MACS could achieve efficient decryption and immediate revocation and the EDAC-MACS could also achieve these goals even though nonrevoked users reveal their Key Update Keys to the revoked user. However, through our cryptanalysis, the revocation security of both schemes cannot be guaranteed. In this paper, we first give two attacks on the two schemes. By the first attack, the revoked user can eavesdrop to obtain other users' Key Update Keys to update its Secret Key, and then it can obtain proper Token to decrypt any secret information as a nonrevoked user. In addition, by the second attack, the revoked user can intercept Ciphertext Update Key to retrieve its ability to decrypt any secret information as a nonrevoked user. Secondly, we propose a new extensive DAC-MACS scheme (NEDAC-MACS) to withstand the above two attacks so as to guarantee more secure attribute revocation. Then, formal cryptanalysis of NEDAC-MACS is presented to prove the security goals of the scheme. Finally, the performance comparison among NEDAC-MACS and related schemes is given to demonstrate that the performance of NEDAC-MACS is superior to that of DACC, and relatively same as that of DAC-MACS.",
Optimal Energy-Efficient Downlink Transmission Scheduling for Real-Time Wireless Networks,"It has been shown that by using appropriate channel coding schemes in wireless environments, transmission energy can be significantly reduced by controlling the packet transmission rate. This paper seeks optimal solutions for downlink transmission control problems, motivated by this observation and by the need to minimize energy consumption in real-time wireless networks. Our problem formulation deals with a more general setting than the paper authored by Gamal et al., in which the MoveRight algorithm is proposed. The MoveRight algorithm is an iterative algorithm that converges to the optimal solution. We show that even under the more general setting, the optimal solution can be efficiently obtained through an approach decomposing the optimal sample path through certain “critical tasks” which, in turn, can be efficiently identified. We include simulation results showing that our algorithm is significantly faster than the MoveRight algorithm. We also discuss how to utilize our results and receding horizon control to perform online transmission scheduling where future task information is unknown.","Transmitters,
Scheduling,
Real-time systems,
Wireless networks,
Energy consumption,
Quality of service"
Islands of heaters: A novel thermal management framework for photonic NoCs,"Silicon photonics has become a promising candidate for future networks-on-chip (NoCs) as it can enable high bandwidth density and lower latency with traversal of data at the speed of light. But the operation of photonic NoCs (PNoCs) is very sensitive to temperature variations that frequently occur on a chip. These variations can create significant reliability issues for PNoCs. For example, microring resonators (MRRs) which are the building blocks of PNoCs, may resonate at another wavelength instead of their designated wavelength due to thermal variations, which can lead to bandwidth wastage and data corruption in PNoCs. This paper proposes a novel run-time framework to overcome temperature-induced issues in PNoCs. The framework consists of (i) a PID controlled heater mechanism to nullify the thermal gradient across PNoCs, (ii) a device-level thermal island framework to distribute MRRs across regions of temperatures; and (iii) a system-level proactive thread migration technique to avoid on-chip thermal threshold violations and to reduce MRR tuning/trimming power by migrating threads between cores. Our experimental results with 64-core Corona and Flexishare PNoCs indicate that the proposed approach reliably satisfies on-chip thermal thresholds and maintains high network bandwidth while reducing total power by up to 64.1%.","Heating,
Photonics,
Tuning,
Thermal management,
Bandwidth,
System-on-chip,
Temperature sensors"
Improving on the Cut-Set Bound via Geometric Analysis of Typical Sets,"We consider the discrete memoryless symmetric primitive relay channel, where, a source X wants to send information to a destination Y with the help of a relay Z and the relay can communicate to the destination via an error-free digital link of rate R0, while Y and Z are conditionally independent and identically distributed given X. We develop two new upper bounds on the capacity of this channel that are tighter than existing bounds, including the celebrated cut-set bound. Our approach significantly deviates from the standard information-theoretic approach for proving upper bounds on the capacity of multi-user channels. We build on the blowing-up lemma to analyze the probabilistic geometric relations between the typical sets of the n-letter random variables associated with a reliable code for communicating over this channel. These relations translate to new entropy inequalities between the n-letter random variables involved. As an application of our bounds, we study an open question posed by (Cover, 1987), namely, what is the minimum rate R0* needed for the Z-Y link in order for the capacity of the relay channel to be equal to that of the broadcast cut. We consider the special case when the X-Y and X-Z links are both binary symmetric channels. Our tighter bounds on the capacity of the relay channel immediately translate to tighter lower bounds for R0*. More interestingly, we show that when p → 1/2, R0* ≥ 0.1803; even though the broadcast channel becomes completely noisy as p → 1/2 and its capacity, and therefore the capacity of the relay channel, goes to zero, a strictly positive rate R0 is required for the relay channel capacity to be equal to the broadcast bound. Existing upper bounds on the capacity of the relay channel, and the cut-set bound in particular, would rather imply R0* → 0, while achievability schemes require R0* → 1. We conjecture that R0* → 1 as p → 1/2.",
A Multisensor Mobile Interface for Industrial Environment and Healthcare Monitoring,"This paper presents a reconfigurable multisensor mobile interface architecture that is applicable to heterogeneous sensor applications and also easy to generate new types of combined services. The multisensor interface attributes compactness and flexibility to reconfigurable readout integrated circuits (ROICs) and migration of signal processing and computation burdens from a sensor tag to a smartphone. Two reconfigurable ROICs which were designed and fabricated in a 0.18-μm CMOS process generate raw digital data from environmental and healthcare sensors. Their detected raw data are wirelessly sent to the smartphone where real-time calibration and postprocessing are performed optimally for each sensor. In an application to industrial systems, an in-vehicle system prototype supporting combined monitoring services of air-quality and healthcare was integrated into a steering wheel cover and experimentally verified to provide real-time measurement of three environmental sensor signals and two healthcare physiological signals with the results displayed on a smartphone.","Medical services,
Monitoring,
Mobile communication,
Capacitive sensors,
Integrated circuits,
Biomedical monitoring,
Power demand"
Anonymous Secure Framework in Connected Smart Home Environments,"The smart home is an environment, where heterogeneous electronic devices and appliances are networked together to provide smart services in a ubiquitous manner to the individuals. As the homes become smarter, more complex, and technology dependent, the need for an adequate security mechanism with minimum individual's intervention is growing. The recent serious security attacks have shown how the Internet-enabled smart homes can be turned into very dangerous spots for various ill intentions, and thus lead the privacy concerns for the individuals. For instance, an eavesdropper is able to derive the identity of a particular device/appliance via public channels that can be used to infer in the life pattern of an individual within the home area network. This paper proposes an anonymous secure framework (ASF) in connected smart home environments, using solely lightweight operations. The proposed framework in this paper provides efficient authentication and key agreement, and enables devices (identity and data) anonymity and unlinkability. One-time session key progression regularly renews the session key for the smart devices and dilutes the risk of using a compromised session key in the ASF. It is demonstrated that computation complexity of the proposed framework is low as compared with the existing schemes, while security has been significantly improved.","Authentication,
Smart homes,
Home appliances,
Internet,
Smart devices,
Protocols"
A Meander Line UHF RFID Reader Antenna for Near-field Applications,"A novel ultrahigh frequency radio frequency identification reader antenna based on electromagnetic coupling between two open-ended microstrip (MS) meander lines for near-field applications is investigated in this paper. The corresponding currents flowing along the two MS meander lines are reversed in phase with approximately identical amplitudes. Meander-line units are introduced to achieve a uniform distribution of strong magnetic and electric fields. The performance of an antenna prototype comprised of six pairs of meander lines is analyzed. The proposed antenna simultaneously exhibits a uniform magnetic field distribution with a reading region of 480 mm × 200 mm × 20 mm and a uniform linear electric field distribution with a reading region of 480 mm × 420 mm × 300 mm. The proposed antenna exhibits a low far-field gain, and has a bandwidth from 914 to 929 MHz. Both simulated and measured results have shown a good performance of the antenna.","Microstrip antennas,
Microstrip,
Magnetic fields,
Radiofrequency identification,
Phase shifters,
UHF antennas"
Proposed security model for web based applications and services,"Internet security is a branch of computer sciences often involving browser security, network security, applications and operating systems to keep the internet as a secure channel to exchange information by reducing the risk and attacks. There are a number of studies that have been conducted in this field resulting in the development of various security models to achieve internet security. However, periodic security reports and previous studies prove that the most secure systems are not immune from risk and much effort is needed to improve internet security. This paper proposed a simple security model to improve internet applications security and services protections, specified access control, cryptographic, cookies and session managements, defense programming practices, care for security from early stage on development life cycle, use hardware authentication techniques in access control, then propose cryptographic approach by mix MD5 with Based64, consider session and cookies types and ways to keep it secure. Additionally, these practices discussed the most important web security vulnerability and access control weakness and how to overcome such weaknesses, proposed an approach to measure, analyze and evaluate security project according to software quality standard ISO 25010 by using Likert scale, finally ended by case study. The effort of this paper represents a set of techniques and tips that should be applied within each web application development process to maintain its security.","Access control,
Cryptography,
Servers,
Hardware,
Internet,
Authentication"
Automated synthesis of compact crossbars for sneak-path based in-memory computing,"The rise of data-intensive computational loads has exposed the processor-memory bottleneck in Von Neumann architectures and has reinforced the need for in-memory computing using devices such as memristors. Existing literature on computing Boolean formula using sneak-paths in nanoscale memristor crossbars has only focussed on short Boolean formula. There are two open questions: (i) Can one synthesize sneak-path based crossbars for computing large Boolean formula? (ii) What is the size of a memristor crossbar that can compute a given Boolean formula using sneak paths? In this paper, we make progress on both these problems. First, we show that the number of rows and columns required to compute a Boolean formula is at most linear in the size of the Reduced Ordered Binary Decision Diagram representing the Boolean function. Second, we demonstrate how Boolean Decision Diagrams can be used to synthesize nanoscale crossbars that can compute a given Boolean formula using naturally occurring sneak paths. In particular, we synthesize large logical circuits such as 128-bit adders for the first-time using sneak-path based crossbar computing.","Memristors,
Boolean functions,
Nanoscale devices,
Adders,
Binary decision diagrams,
Nanowires"
Multiuser Steered Multiset Space-Time Shift Keying for Millimeter-Wave Communications,"The recently proposed concept of multiset space-time shift keying (MS-STSK) is intrinsically amalgamated with the multiple-input multiple-output (MIMO) philosophy for the sake of enhancing the attainable system throughput. Explicitly, we propose a multiuser steered MS-STSK (MU-SMS-STSK) scheme for the downlink of millimeter-wave (mmWave) communications, which is combined with analogue beamforming (BF) that relies on phase shifters and power amplifiers to overcome the high attenuation of mmWaves. Hence, our MU-SMS-STSK system combines the concepts of MU-MIMO, MS-STSK, BF, and orthogonal frequency-division multiplexing for communicating with multiple users relying on the same time and frequency resources.","Radio frequency,
OFDM,
Antenna arrays,
Transmitting antennas,
MIMO,
Array signal processing,
Throughput"
Solution to GW TEM-Circular Polarized TE11 Mode Converter Design for High Frequency Bands,"The solution utilized to design a compact transverse electromagnetic mode (TEM)-CPT (circular polarized TE11) mode converter with high power handling capability and high efficiency, especially at high frequency bands is proposed in this paper. The analysis shows that increasing the quantity of the arms of the converter could make the converter work under overmoded state. The problem that the power capability of the converter working at high frequency bands is low will be addressed. To verify the feasibility of this solution, simulations and experiments on a 20 arms converter are carried out, and the results show that the converter would convert the TEM mode into CPT mode efficiently in a 2-3 free wavelengths longitudinal size and that the power capability is in gigawatt (GW) class. Moreover, this kind of converter can also be utilized in the design of GW TEM phase shifter, whether at low or high frequency bands, which plays a key role in the power combining technology.",
Quality-Driven Joint Rate and Power Adaptation for Scalable Video Transmissions Over MIMO Systems,"We propose a joint rate and power adaptation scheme to maximize the decoding quality for scalable video coding (SVC)-based video transmissions over multi-input multioutput (MIMO) systems. The rate adaptation in our proposed scheme includes selection of the best modulation and coding schemes, set of spatial channels, number of SVC layers (source coding rates), and their corresponding application layer forward error correction (APP-FEC) coding rates. The power adaptation involves the proper allocation of the power to each antenna in the MIMO system. SVC-based video transmissions require unequal error protection (UEP) for different SVC layers due to the inter-layer dependency. In most of the previous works, the bit stream of each particular SVC layer is allocated to one spatial channel and the UEP is achieved by transmitting the more important SVC layers through the spatial channels with higher channel gains. However, in our proposed scheme, the bit stream of each particular SVC layer is distributed to multiple spatial channels so that additional diversity gain can be exploited by applying APP-FEC. The UEP can also be achieved by allocating different APP-FEC coding rates on each video layer. Moreover, transmit power allocation is also effectively and jointly determined to improve the system performance. The effectiveness and favorable performance of our proposed scheme are shown by simulations with H.264 SVC traces of high-definition video clips over MIMO systems.",
Distributed State Estimation of Sensor-Network Systems Subject to Markovian Channel Switching With Application to a Chemical Process,"This paper addresses a distributed estimator design problem for linear systems deployed over sensor networks within a multiple communication channels (MCCs) framework. A practical scenario is taken into account such that the channel used for communication can be switched and the switching is governed by a Markov chain. With the existence of communicational imperfections and external disturbances, an estimation algorithm is proposed such that the developed distributed estimators are able to give accurate state estimates against the channel switching phenomenon. The distributed estimation framework is applied to a chemical process to illustrate the effectiveness of the proposed methodology and the superiority of the MCCs framework featured by channel switching.","Switches,
State estimation,
Robot sensing systems,
Delays,
Data communication,
Channel estimation,
Chemical processes"
A thermo-electrodynamic electric field dependent molecular ionization model to realize positive streamer propagation in a wet-mate DC connector,"Complete subsea factory concept, an equivalent of the full topsides processing facility to be operated on the seabed, is envisaged to power longer, deeper and colder subsea oil and gas fields in the future. This concept has been envisioned through a modular stacked subsea DC transmission and distribution system whose subsea umbilical cables and electrical power component on the seabed can be interfaced with each other by wet-mate (WM) DC connectors. Laboratory and theoretical investigations have been carried out to assess various electrical insulation systems and electrode geometries for a WM DC connector which should operate in the steady state as well as switching transients in a corrosive environment for high reliability and minimum maintenance in its lifetime. In this paper, the electrical insulation performance of a needle-sphere electrode geometry defined by IEC 60897 under a positive step voltage is studied. To approach the complicated solid-liquid insulation system envisaged in a WM DC connector after mating, the electrodes are covered by a dielectric solid and oil is enclosed by the dielectric solid as well. A full thermo-electrodynamic electric field dependent molecular ionization Multiphysics model was developed for the simulation of streamer initiation and growth in the oil while dielectric solid is modeled as a perfect insulator. It is shown that stabilization methods, mesh strategies and time step have a great influence on simulation results and guidelines to choose them properly are presented. Based on simulation results, it was found that the higher relative permittivity of the solid insulation the slower streamer propagation in the oil and the less electrical stress on the solid insulation.","Electric fields,
Ionization,
Insulators"
Video eCommerce++: Toward Large Scale Online Video Advertising,"The prevalence of online videos provides an opportunity for e-commerce companies to recommend their products in videos. In this paper, we propose an online video advertising system named Video eCommerce ++, to exhibit appropriate product ads to particular users at proper time stamps of videos, which takes into account video semantics, user shopping preference, and viewing behavior feedback. First, an incremental co-relation regression (ICRR) model is novelly proposed to construct the semantic association between videos and products. To meet the requirement of online advertising, ICRR is implemented in an incremental way to reduce the time complexity. User preference diffusion (UPD) is induced under the framework of heterogeneous information network to construct user-product association from two different e-commerce platforms, Tmall and MagicBox, which alleviates the problems of data sparsity and cold start. A video scene importance model (VSIM) is proposed to model the scene importance by utilizing the user viewing behavior, so that ads can be embedded at the most attractive positions in the video stream. To combine the outputs of ICRR, UPD, and VSIM, a unified distributed heterogeneous relation matrix factorization (D-HRMF) is applied for online video advertising, which is efficiently conducted in parallel to address the real-time update problem, so that the whole system can be performed in real time. Extensive experiments conducted on a variety of online videos from Tmall MagicBox demonstrate that Video eCommerce++ significantly outperforms the state-of-the-art advertising methods, and can handle large-scale data in real time.","Advertising,
Streaming media,
Real-time systems,
Semantics,
TV,
Multimedia communication,
Collaboration"
An optimal resource allocation algorithm for D2D communication underlaying cellular networks,"In a device to device (D2D) communication underlaying cellular network, total system sum rate can be improved if cellular user equipments (UEs) and D2D pairs share resource blocks (RBs). We consider such an optimization problem where the objective is to maximize the total sum rate of the system while sharing RBs among cellular UEs and D2D pairs and maintaining some quality of service (QoS) requirements. Most of the existing algorithms consider that sharing can only improve the sum rate. However, some sharing can also decrease the sum rate. Considering this observation, we design an optimal algorithm based on weighted bipartite matching which avoids such sharing and maximize the total system sum rate. We prove that our algorithm is optimal and validate the results through simulations which shows that our algorithm outperforms other existing heuristics in terms of maximizing system sum rate. Our algorithm also performs better in terms of total interference introduced through the sharing of resource blocks among cellular equipments and D2D pairs.","Device-to-device communication,
Interference,
Cellular networks,
Algorithm design and analysis,
Resource management,
Signal to noise ratio,
Quality of service"
0.2-THz Dual Mode Sheet Beam Traveling Wave Tube,"Equipping the adjustable horizontal focusing electrodes (FEs), a dual mode electron gun providing different current beams, has been proposed and evaluated. Employing this tunable FE electron gun, a continuous wave (CW)/pulsed dual mode, 0.2-THz sheet beam traveling wave tube (SB-TWT) has been designed. The tube employs a high density and high current sheet beam for pulsed mode operation, and a reduced size and lower current sheet beam for the CW mode. This scheme provides CW mode increased efficiency and higher beam transmission factor than other, more conventional, dualmode techniques such as by changing the RF drive power. Using a 1.2-T uniform focusing magnetic field, both beams are predicted to have excellent transmission factor (more than 99%) to the collector through the 65-mm beam tunnel. Driven by the pulsed, high current electron beam, the 0.2-THz SB-TWT exhibits more than 100-W power over a 20-GHz bandwidth. Driven by the low current electron beam, the tube provides 20-dB gain and 10-W CW output power over the required bandwidth of 0.19 THz-0.21 THz.",
Cache-Aware Query Optimization in Multiapplication Sharing Wireless Sensor Networks,"Hosting multiple applications in a shared infrastructure of wireless sensor networks is a trend nowadays, and sharing sensory data for answering concurrent applications is a promising and energy-efficient strategy. To address this challenge, this paper proposes an energy-efficient query optimization mechanism for supporting multiple concurrent applications leveraging our two-tier cooperative caching mechanism. Specifically, query requests for concurrent applications are represented as binary strings, which are reduced to a single one for avoiding the reprocessing of shared subquery requests. This reduced query request is answered through our cooperative caching mechanism, where sensory data, which are highly possible to be reused for answering forthcoming query requests, are cached at the sink node (SN). Besides, the gray model GM(1, 1) is adopted for forecasting sensory data units which may be interested mostly by forthcoming query requests. These units of sensory data may be prefetched from the network and cached at the SN. Experimental evaluation shows that this approach can reduce the energy consumption significantly, and improve the network capacity to an extent, especially when the number of concurrent query requests is relatively large.","Wireless sensor networks,
Energy consumption,
Computational modeling,
Predictive models,
Query processing,
Forecasting,
Indexes"
Spectrum-Availability Based Routing for Cognitive Sensor Networks,"With the occurrence of Internet of Things (IoT) era, the proliferation of sensors coupled with the increasing usage of wireless spectrums especially the ISM band makes it difficult to deploy real-life IoT. Currently, the cognitive radio technology enables sensors transmit data packets over the licensed spectrum bands as well as the free ISM bands. The dynamic spectrum access technology enables secondary users (SUs) access wireless channel bands that are originally licensed to primary users. Due to the high dynamic of spectrum availability, it is challenging to design an efficient routing approach for SUs in cognitive sensor networks. We estimate the spectrum availability and spectrum quality from the view of both the global statistical spectrum usage and the local instant spectrum status, and then introduce novel routing metrics to consider the estimation. In our novel routing metrics, one retransmission is allowed to restrict the number of rerouting and then increase the routing performance. Then, the related two routing algorithms according to the proposed routing metrics are designed. Finally, our routing algorithms in extensive simulations are implemented to evaluate the routing performance, and we find that the proposed algorithms achieve a significant performance improvement compared with the reference algorithm.","Routing,
Measurement,
Wireless sensor networks,
Cognitive radio,
Algorithm design and analysis,
Routing protocols"
Nb Doped TiO2 Protected Back-Channel-Etched Amorphous InGaZnO Thin Film Transistors,"A new back-channel-etched process for the fabrication of amorphous InGaZnO (a-IGZO) thin film transistors (TFTs) is demonstrated, in which a conductive Nb doped TiO2 (TNO) thin film is used to serve as protective layer for the a-IGZO active layer. It is shown that the TNO film provides the active layer with excellent protection even when the thickness is only 1 nm. With treatment by N2O plasma +200°C annealing, the conductive TNO can be converted into an insulator to serve as an in situ passivation layer. Besides, by the introduction of the TNO layer, the source-drain parasitic resistance of the BCE process fabricated TFTs is significantly reduced and the positive bias stress stability is improved as well.","Annealing,
Plasmas,
Films,
Thin film transistors,
Fabrication,
Electrodes,
Resistance"
GaN Nanowire Schottky Barrier Diodes,"A new concept of vertical gallium nitride (GaN) Schottky barrier diode based on nanowire (NW) structures and the principle of dielectric REduced SURface Field (RESURF) is proposed in this paper. High-threading dislocation density in GaN epitaxy grown on foreign substrates has hindered the development and commercialization of vertical GaN power devices. The proposed NW structure, previously explored for LEDs offers an opportunity to reduce defect density and fabricate low cost vertical GaN power devices on silicon (Si) substrates. In this paper, we investigate the static characteristics of high-voltage GaN NW Schottky diodes using 3-D TCAD device simulation. The NW architecture theoretically achieves blocking voltages upward of 700 V with very low specific on-resistance. Two different methods of device fabrication are discussed. Preliminary experimental results are reported on device samples fabricated using one of the proposed methods. The fabricated Schottky diodes exhibit a breakdown voltage of around 100 V and no signs of current collapse. Although more work is needed to further explore the nano-GaN concept, the preliminary results indicate that superior tradeoff between the breakdown voltage and specific on-resistance can be achieved, all on a vertical architecture and a foreign substrate. The proposed NW approach has the potential to deliver low cost reliable GaN power devices, circumventing the limitations of today's high electron mobility transistors (HEMTs) technology and vertical GaN on GaN devices.","Gallium nitride,
Substrates,
Silicon,
Schottky diodes,
Epitaxial growth,
Fabrication,
Schottky barriers"
Regularized Dual Averaging Image Reconstruction for Full-Wave Ultrasound Computed Tomography,"Ultrasound computed tomography (USCT) holds great promise for breast cancer screening. Waveform inversion-based image reconstruction methods account for higher order diffraction effects and can produce high-resolution USCT images, but are computationally demanding. Recently, a source encoding technique has been combined with stochastic gradient descent (SGD) to greatly reduce image reconstruction times. However, this method bundles the stochastic data fidelity term with the deterministic regularization term. This limitation can be overcome by replacing SGD with a structured optimization method, such as the regularized dual averaging method, that exploits knowledge of the composition of the cost function. In this paper, the dual averaging method is combined with source encoding techniques to improve the effectiveness of regularization while maintaining the reduced reconstruction times afforded by source encoding. It is demonstrated that each iteration can be decomposed into a gradient descent step based on the data fidelity term and a proximal update step corresponding to the regularization term. Furthermore, the regularization term is never explicitly differentiated, allowing nonsmooth regularization penalties to be naturally incorporated. The wave equation is solved by the use of a time-domain method. The effectiveness of this approach is demonstrated through computer simulation and experimental studies. The results suggest that the dual averaging method can produce images with less noise and comparable resolution to those obtained by the use of SGD.",
Octave-Spanning Supercontinuum Generation From an NALM Mode-Locked Yb-Fiber Laser System,"We demonstrated an allPMfiber Yb-doped modelocked laser system based on the NALM. A compact phase shifter was employed to decrease the mode-locking threshold whilst intracavity dispersion management allowed as broad as 29 nm spectral width. With 20-W pump power in the amplifier, the laser system delivered pulses with 137-nJ energy and 140-fs duration. More than one octave spanning supercontinuum was generated in the nonlinear PCF and subsequently lead to an fceo signal with >30 dB S/N ratio.","Laser mode locking,
Optical fiber amplifiers,
Optical fiber polarization,
Optical fiber dispersion,
Fiber lasers,
Gratings,
Oscillators"
Problem Specific MOEA/D for Barrier Coverage with Wireless Sensors,"Barrier coverage with wireless sensors aims at detecting intruders who attempt to cross a specific area, where wireless sensors are distributed remotely at random. This paper considers limited-power sensors with adjustable ranges deployed along a linear domain to form a barrier to detect intruding incidents. We introduce three objectives to minimize: 1) total power consumption while satisfying full coverage; 2) the number of active sensors to improve the reliability; and 3) the active sensor nodes' maximum sensing range to maintain fairness. We refer to the problem as the tradeoff barrier coverage (TBC) problem. With the aim of obtaining a better tradeoff among the three objectives, we present a multiobjective optimization framework based on multiobjective evolutionary algorithm (MOEA)/D, which is called problem specific MOEA/D (PS-MOEA/D). Specifically, we define a 2-tuple encoding scheme and introduce a cover-shrink algorithm to produce feasible and relatively optimal solutions. Subsequently, we incorporate problem-specific knowledge into local search, which allows search procedures for neighboring subproblems collaborate each other. By considering the problem characteristics, we analyze the complexity and incorporate a strategy of computational resource allocation into our algorithm. We validate our approach by comparing with four competitors through several most-used metrics. The experimental results demonstrate that PS-MOEA/D is effective and outperforms the four competitors in all the cases, which indicates that our approach is promising in dealing with TBC.",
Online-Learning-Based Mode Prediction Method for Quality Scalable Extension of the High Efficiency Video Coding (HEVC) Standard,"SHVC, the scalable extension of High Efficiency Video Coding (HEVC), uses advanced inter-layer prediction features in addition to the advanced compression tools of HEVC to improve the compression performance. Using combined features has brought us improved compression performance at the cost of huge computational complexity for the SHVC encoder. This complexity is mainly because of the the inter/intra-prediction mode search of the coding units. The focus of this study is on developing an efficient complexity reduction for quality scalability of SHVC encoder, with the intention to facilitate the adoption of SHVC for real-time applications. In this regard, first, we build a probabilistic model that uses the mode information and motion homogeneity of already encoded blocks in the enhancement layer (EL) and the base layer to predict the probabilities of all the available inter/intra modes of the to-be-coded block in the EL. Then, we propose an online-learning-based fast mode, assigning (FMA) method that uses the proposed probabilistic model to predict the mode of the to-be-coded block in the EL. Performance evaluation shows that our proposed FMA method reduces the total execution time of the SHVC encoder by 45.40% on average compared with unmodified SHVC codec while maintaining the overall video quality.",
Computing Maximum Cardinality Matchings in Parallel on Bipartite Graphs via Tree-Grafting,"It is difficult to obtain high performance when computing matchings on parallel processors because matching algorithms explicitly or implicitly search for paths in the graph, and when these paths become long, there is little concurrency. In spite of this limitation, we present a new algorithm and its shared-memory parallelization that achieves good performance and scalability in computing maximum cardinality matchings in bipartite graphs. Our algorithm searches for augmenting paths via specialized breadthfirst searches (BFS) from multiple source vertices, hence creating more parallelism than single source algorithms. Algorithms that employ multiple-source searches cannot discard a search tree once no augmenting path is discovered from the tree, unlike algorithms that rely on single-source searches. We describe a novel tree-grafting method that eliminates most of the redundant edge traversals resulting from this property of multiple-source searches. We also employ the recent direction-optimizing BFS algorithm as a subroutine to discover augmenting paths faster. Our algorithm compares favorably with the current best algorithms in terms of the number of edges traversed, the average augmenting path length, and the number of iterations. We provide a proof of correctness for our algorithm. Our NUMA-aware implementation is scalable to 80 threads of an Intel multiprocessor and to 240 threads on an Intel Knights Corner coprocessor. On average, our parallel algorithm runs an order of magnitude faster than the fastest algorithms available. The performance improvement is more significant on graphs with small matching number.","Bipartite graph,
Vegetation,
Parallel algorithms,
Algorithm design and analysis,
Instruction sets,
Impedance matching"
No-Reference and Robust Image Sharpness Evaluation Based on Multiscale Spatial and Spectral Features,"The human visual system exhibits multiscale characteristic when perceiving visual scenes. The hierarchical structures of an image are contained in its scale space representation, in which the image can be portrayed by a series of increasingly smoothed images. Inspired by this, this paper presents a no-reference and robust image sharpness evaluation (RISE) method by learning multiscale features extracted in both the spatial and spectral domains. For an image, the scale space is first built. Then sharpness-aware features are extracted in gradient domain and singular value decomposition domain, respectively. In order to take into account the impact of viewing distance on image quality, the input image is also down-sampled by several times, and the DCT-domain entropies are calculated as quality features. Finally, all features are utilized to learn a support vector regression model for sharpness prediction. Extensive experiments are conducted on four synthetically and two real blurred image databases. The experimental results demonstrate that the proposed RISE metric is superior to the relevant state-of-the-art methods for evaluating both synthetic and real blurring. Furthermore, the proposed metric is robust, which means that it has very good generalization ability.","Feature extraction,
Measurement,
Image quality,
Robustness,
Entropy,
Computational modeling,
Image edge detection"
Information Without Rolling Dice,"The deterministic notions of capacity and entropy are studied in the context of communication and storage of information using square-integrable and bandlimited signals subject to perturbation. The (E, δ)-capacity that extends the Kolmogorov E-capacity to packing sets of overlap at most δ is introduced and compared with the Shannon capacity. The functional form of the results indicates that in both Kolmogorov and Shannon's settings, capacity and entropy grow linearly with the number of degrees of freedom, but only logarithmically with the signal to noise ratio. This basic insight transcends the details of the stochastic or deterministic description of the information theoretic model. For δ = 0, the analysis leads to a tight asymptotic expression of the Kolmogorov E-entropy of bandlimited signals. A deterministic notion of error exponent is introduced. Applications of the theory are briefly discussed.","Entropy,
Signal to noise ratio,
Stochastic processes,
Information theory,
Rate distortion theory"
D2D-U: Device-to-Device Communications in Unlicensed Bands for 5G System,"Device-to-device (D2D) communication, which enables direct communication between nearby mobile devices, is an attractive add-on component to improve spectrum efficiency and user experience by reusing licensed cellular spectrum in 5G system. In this paper, we propose to enable D2D communication in unlicensed spectrum (D2D-U) as an underlay of the uplink LTE network for further booming the network capacity. A sensing-based protocol is designed to support the unlicensed channel access for both LTE and D2D users. We further investigate the subchannel allocation problem to maximize the sum rate of LTE and D2D users while considering their interference to the existing Wi-Fi systems. Specifically, we formulate the subchannel allocation as a many-to-many matching problem with externalities, and develop an iterative user-subchannel swap algorithm. Analytical and simulation results show that the proposed D2D-U scheme can significantly improve the system sum rate.",
A Signal-Space Aligned Network Coding Approach to Distributed MIMO,"This paper studies an uplink distributed MIMO (DMIMO) system that consists of K users and K' distributed base stations (BSs), where the BSs are connected to a central unit (CU) via independent rate-constrained backhaul (BH) links. We propose anew signal-space aligned network coding scheme. First, a network coding generator matrix is selected subject to certain structural properties. Next, distributed linear precoding is employed by the users to create aligned signal-spaces at the BSs, according to the pattern determined by the network coding generator matrix. For each aligned signal-space at a BS, physical-layer network coding is utilized to compute the corresponding network-coded (NC) messages, where the actual number of NC messages forwarded to the CU is determined by the BH rate-constraint. We derive an achievable rate of the proposed scheme based on the existence of the NC generator matrix and signal-space alignment precoding matrices. For DMIMO with two and three BSs, the achievable rates and degrees of freedom (DoF) are evaluated and shown to outperform existing schemes. For example, for DMIMO with two BSs where each user and BS have N and N' antennas, respectively, the proposed scheme achieves a DoF of 2 min (N, N') - 1, if the BH capacity scales like (2 min (N, N') - 1) log SNR. This leads to greater DoF compared to that utilizes the strategy for interference channel, whose DoF is min (N, N'). Numerical results demonstrate the performance advantage of the proposed scheme.","Network coding,
MIMO,
Uplink,
Generators,
Interference channels,
Base stations"
Transient Community Detection and Its Application to Data Forwarding in Delay Tolerant Networks,"Community detection has received considerable attention because of its applications to many practical problems in mobile networks. However, when considering temporal information associated with a community (i.e., transient community), most existing community detection methods fail due to their aggregation of contact information into a single weighted or unweighted network. In this paper, we propose a contact-burst-based clustering method to detect transient communities by exploiting pairwise contact processes. In this method, we formulate each pairwise contact process as a regular appearance of contact bursts, during which most contacts between the pair of nodes happen. Based on this formulation, we detect transient communities by clustering the pairs of nodes with similar contact bursts. Since it is difficult to collect global contact information at individual nodes, we further propose a distributed method to detect transient communities. In addition to transient community detection, we also propose a new data forwarding strategy for delay tolerant networks, in which transient communities serve as the data forwarding unit. Evaluation results show that our strategy can achieve a much higher data delivery ratio than traditional community-based strategies with comparable network overhead.","Transient analysis,
Peer-to-peer computing,
Delays,
IEEE transactions,
Clustering methods,
Mobile handsets,
Image edge detection"
Observer Design and Exponential Stabilization for Wave Equation in Energy Space by Boundary Displacement Measurement Only,"In this technical note, we consider finite-time and exponential stabilization for one-dimensional wave equations by boundary displacement measurement only. We limit ourselves in the energy state space where the usual observability inequality is not valid anymore. However, in the optimal state space, the boundary displacement is indeed exactly observable. This motivates us to design observer via displacement output only for these systems. We first discuss a simple case as a motivation. An observer is designed and an output feedback control is then synthesized to make system finite-time stable in energy space. In this same spirit, we consider the same problem for an unstable wave equation and the finite-time stability is also achieved by displacement output feedback. Finally, we consider an anti-stable wave equation. A direct delayed output feedback control can achieve exponential stability with arbitrary decay rate. Simulation results are presented to validate the theoretical conclusions.",
FiDoop-DP: Data Partitioning in Frequent Itemset Mining on Hadoop Clusters,"Traditional parallel algorithms for mining frequent itemsets aim to balance load by equally partitioning data among a group of computing nodes. We start this study by discovering a serious performance problem of the existing parallel Frequent Itemset Mining algorithms. Given a large dataset, data partitioning strategies in the existing solutions suffer high communication and mining overhead induced by redundant transactions transmitted among computing nodes. We address this problem by developing a data partitioning approach called FiDoop-DP using the MapReduce programming model. The overarching goal of FiDoop-DP is to boost the performance of parallel Frequent Itemset Mining on Hadoop clusters. At the heart of FiDoop-DP is the Voronoi diagram-based data partitioning technique, which exploits correlations among transactions. Incorporating the similarity metric and the Locality-Sensitive Hashing technique, FiDoop-DP places highly similar transactions into a data partition to improve locality without creating an excessive number of redundant transactions. We implement FiDoop-DP on a 24-node Hadoop cluster, driven by a wide range of datasets created by IBM Quest Market-Basket Synthetic Data Generator. Experimental results reveal that FiDoop-DP is conducive to reducing network and computing loads by the virtue of eliminating redundant transactions on Hadoop nodes. FiDoop-DP significantly improves the performance of the existing parallel frequent-pattern scheme by up to 31 percent with an average of 18 percent.","Data mining,
Itemsets,
Partitioning algorithms,
Programming,
Computational modeling,
Distributed databases,
Correlation"
Impact of Lubberts Effect on Amorphous Selenium Indirect Conversion Avalanche Detector for Medical X-Ray Imaging,"The exponential X-ray absorption makes the indirect conversion X-ray image sensors vulnerable to the Lubberts effect, which in turn makes the sensor more sensitive to the electronic noise. A cascaded linear-system model is proposed to find the required electric field to overcome the effect of electronic noise and depth dependent X-ray absorption (Lubberts effect) in amorphous selenium indirect conversion avalanche detectors. The model also includes scattering due to K-fluorescence reabsorption. The effect of depth dependent X-ray absorption is more pronounced in thicker detectors. It is observed that, at the Nyquist frequency (fN) of 2.5 mm-1, the presampling modulation transfer function of CsI deteriorates from 0.75 to 0.1 due to Lubberts effect in a CsI layer having thickness of 0.6 mm. The detective quantum efficiency (DQE) at fN (2.5 mm-1) drops from 0.037 to 0.01 at a field of 60 V/μm due to Lubberts effect. The Lubberts fraction decreases with increasing the field thereafter. The avalanche gain enhances the signal strength and improves the frequency dependent DQE(f) by overcoming the Lubberts effect and as well as the effect of the electronic noise. An avalanche gain of 45 is sufficient to overcome the effect of the electronic noise.",
An Asymmetric Distance Model for Cross-View Feature Mapping in Person Reidentification,"Person reidentification, which matches person images of the same identity across nonoverlapping camera views, becomes an important component for cross-camera-view activity analysis. Most (if not all) person reidentification algorithms are designed based on appearance features. However, appearance features are not stable across nonoverlapping camera views under dramatic lighting change, and those algorithms assume that two cross-view images of the same person can be well represented either by exploring robust and invariant features or by learning matching distance. Such an assumption ignores the nature that images are captured under different camera views with different camera characteristics and environments, and thus, mostly there exists large discrepancy between the extracted features under different views. To solve this problem, we formulate an asymmetric distance model for learning camera-specific projections to transform the unmatched features of each view into a common space where discriminative features across view space are extracted. A cross-view consistency regularization is further introduced to model the correlation between view-specific feature transformations of different camera views, which reflects their nature relations and plays a significant role in avoiding overfitting. A kernel cross-view discriminant component analysis is also presented. Extensive experiments have been conducted to show that asymmetric distance modeling is important for person reidentification, which matches the concerns on cross-disjoint-view matching, reporting superior performance compared with related distance learning methods on six publically available data sets.","Cameras,
Feature extraction,
Image color analysis,
Lighting,
Computer aided instruction,
Histograms,
Robustness"
Distributed Model Predictive Load Frequency Control of the Multi-Area Power System After Deregulation,"This paper proposes a distributed model predictive control scheme for the load frequency control (LFC) problem of the deregulated multi-area interconnected power system with contracted and uncontracted load demands. The traditional LFC of the interconnected power system is modified to take into account the effect of bilateral contracts on the dynamics. The concept of the distribution company participation matrix and area participation matrix are introduced to simulate these bilateral contracts and reflected in the multi-area block diagram. The distributed model predictive controller is designed by posing the LFC problem as a tracking control problem in the presence of both external disturbances and constraints that represent generation rate constraint and load reference setpoint constraint, respectively. Analysis and simulation results for a deregulated three-area interconnected power system show possible improvements on closed-loop performance and computational burden, while respecting the physical hard constraints.","Contracts,
Load modeling,
Power generation,
Power system stability,
Power system dynamics,
Frequency control"
Knowledge-Based Resource Allocation for Collaborative Simulation Development in a Multi-tenant Cloud Computing Environment,"Cloud computing technologies have enabled a new paradigm for advanced product development powered by the provision and subscription of computational services in a multi-tenant distributed simulation environment. The description of computational resources and their optimal allocation among tenants with different requirements holds the key to implementing effective software systems for such a paradigm. To address this issue, a systematic framework for monitoring, analyzing and improving system performance is proposed in this research. Specifically, a radial basis function neural network is established to transform simulation tasks with abstract descriptions into specific resource requirements in terms of their quantities and qualities. Additionally, a novel mathematical model is constructed to represent the complex resource allocation process in a multi-tenant computing environment by considering priority-based tenant satisfaction, total computational cost and multi-level load balance. To achieve optimal resource allocation, an improved multi-objective genetic algorithm is proposed based on the elitist archive and the K-means approaches. As demonstrated in a case study, the proposed framework and methods can effectively support the cloud simulation paradigm and efficiently meet tenants’ computational requirements in a distributed environment.","Computational modeling,
Cloud computing,
Resource management,
Collaboration,
Load modeling,
Optimization,
Service-oriented architecture"
Analysis in the Effect of Co-phase Traction Railway HPQC Coupled Impedance on Its Compensation Capability and Impedance-Mapping Design Technique Based on Required Compensation Capability for Reduction in Operation Voltage,"Railway hybrid power quality conditioner (HPQC) is one of the newly proposed devices for power quality compensation in co-phase high-speed traction power supply for its benefit in reduction of operation voltage over conventional railway power quality conditioner (RPC). However, initial railway HPQC design is developed based on minimum operation voltage at predefined fixed rated load. This may not be applicable in practical condition when load varies. In order to solve this problem, a railway HPQC design with increased operation voltage has been investigated to enhance the compensation capability. Nevertheless, the compensation capability is even larger than that required during load variations such that the operation voltage is higher than it actually requires. A lower operation voltage can actually be used to provide required compensation capability when the coupled impedance is different from the designed rated one. In this paper, the effect of coupled impedance on the compensation capability in co-phase railway HPQC is being analyzed. An impedance-mapping design technique based on required compensation capability is then proposed based on the analysis. The proposed method is advantageous for lower operation voltage and smaller capacitance value. The effectiveness of impedance-mapping technique is verified via simulation and experimental results.","Rail transportation,
Power quality,
Impedance,
Traction power supplies,
Control systems,
Reactive power,
Hybrid power systems"
Low-cost 3-axis soft tactile sensors for the human-friendly robot Vizzy,"In this paper we present a low-cost and easy to fabricate 3-axis tactile sensor based on magnetic technology. The sensor consists in a small magnet immersed in a silicone body with an Hall-effect sensor placed below to detect changes in the magnetic field caused by displacements of the magnet, generated by an external force applied to the silicone body. The use of a 3-axis Hall-effect sensor allows to detect the three components of the force vector, and the proposed design assures high sensitivity, low hysteresis and good repeatability of the measurement: notably, the minimum sensed force is about 0.007N. All components are cheap and easy to retrieve and to assemble; the fabrication process is described in detail and it can be easily replicated by other researchers. Sensors with different geometries have been fabricated, calibrated and successfully integrated in the hand of the human-friendly robot Vizzy. In addition to the sensor characterization and validation, real world experiments of object manipulation are reported, showing proper detection of both normal and shear forces.","Robot sensing systems,
Force,
Magnetic hysteresis,
Sensitivity,
Force sensors"
Fault Diagnosis for a Wind Turbine Generator Bearing via Sparse Representation and Shift-Invariant K-SVD,"It is always a primary challenge in fault diagnosis of a wind turbine generator to extract fault character information under strong noise and nonstationary condition. As a novel signal processing method, sparse representation shows excellent performance in time-frequency analysis and feature extraction. However, its result is directly influenced by dictionary, whose atoms should be as similar with signal's inner structure as possible. Due to the variability of operation environment and physical structure in industrial systems, the patterns of impulse signals are changing over time, which makes creating a proper dictionary even harder. To solve the problem, a novel data-driven fault diagnosis method based on sparse representation and shift-invariant dictionary learning is proposed. The impulse signals at different locations with the same characteristic can be represented by only one atom through shift operation. Then, the shift-invariant dictionary is generated by taking all the possible shifts of a few short atoms and, consequently, is more applicable to represent long signals that in the same pattern appear periodically. Based on the learnt shift-invariant dictionary, the coefficients obtained can be sparser, with the extracted impulse signal being closer to the real signal. Finally, the time-frequency representation of the impulse component is obtained with consideration of both the Wigner-Ville distribution of every atom and the corresponding sparse coefficient. The excellent performance of different fault diagnoses in a fault simulator and a wind turbine proves the effectiveness and robustness of the proposed method. Meanwhile, the comparison with the state-of-the-art method is illustrated, which highlights the superiority of the proposed method.","Dictionaries,
Generators,
Wind turbines,
Vibrations,
Fault diagnosis,
Harmonic analysis,
Rotors"
Outage Analysis of Mixed Underlay Cognitive RF MIMO and FSO Relaying With Interference Reduction,"The main contribution of this work is to understand the impact of PU interference on the SU system performance when the PU transmitters is allocated in close vicinity to the SU receiver, and the impact of pointing error, intensity modulation/direct detection, and heterodyne detection of FSO links. Our proposed work include hybrid RF/FSO relaying system with multiple sources, antennas at the relay, and multiple destinations at FSO ends.","Radio frequency,
Relays,
Receiving antennas,
MIMO,
Interference cancellation,
Signal to noise ratio"
RGBD Salient Object Detection via Deep Fusion,"Numerous efforts have been made to design various low-level saliency cues for RGBD saliency detection, such as color and depth contrast features as well as background and color compactness priors. However, how these low-level saliency cues interact with each other and how they can be effectively incorporated to generate a master saliency map remain challenging problems. In this paper, we design a new convolutional neural network (CNN) to automatically learn the interaction mechanism for RGBD salient object detection. In contrast to existing works, in which raw image pixels are fed directly to the CNN, the proposed method takes advantage of the knowledge obtained in traditional saliency detection by adopting various flexible and interpretable saliency feature vectors as inputs. This guides the CNN to learn a combination of existing features to predict saliency more effectively, which presents a less complex problem than operating on the pixels directly. We then integrate a superpixel-based Laplacian propagation framework with the trained CNN to extract a spatially consistent saliency map by exploiting the intrinsic structure of the input image. Extensive quantitative and qualitative experimental evaluations on three data sets demonstrate that the proposed method consistently outperforms the state-of-the-art methods.","Feature extraction,
Image color analysis,
Laplace equations,
Object detection,
Neural networks,
Three-dimensional displays,
Electronic mail"
Power system supplementary damping controllers in the presence of saturation,"This paper presents the analysis and a method to design supplementary damping controllers (SDCs) for synchronous generators considering the effects of saturation limits. Usually such saturations of control signals are imposed in order to enforce practical limitations such as component ratings. However, to guarantee the stability in the presence of saturation limits, the state trajectories must remain inside the domain of attraction (DA). In this paper, the domain of attraction of a single-machine infinite-bus (SMIB) power system with saturation nonlinearity is estimated and compared with the exact description of the null controllable region. Then, state-feedback controllers are designed to enlarge the DA. Our analysis shows that nonlinear effects of saturation should be considered to guarantee stability and satisfactory performance. Simulation results on a detailed nonlinear model of a synchronous generator indicate that the DA enlarges with the proposed controller. The results also indicate that Critical Clearing Time (CCT) and damping of the system with saturation can be improved by the proposed method.","Power system stability,
Damping,
Stability analysis,
Voltage control,
Mathematical model,
Synchronous generators"
Evolutionary Many-Objective Optimization of Hybrid Electric Vehicle Control: From General Optimization to Preference Articulation,"Many real-world optimization problems have more than three objectives, which has triggered increasing research interest in developing efficient and effective evolutionary algorithms for solving many-objective optimization problems. However, most many-objective evolutionary algorithms have only been evaluated on benchmark test functions and few applied to real-world optimization problems. To move a step forward, this paper presents a case study of solving a many-objective hybrid electric vehicle controller design problem using three state-of-the-art algorithms, namely, a decomposition based evolutionary algorithm (MOEA/D), a non-dominated sorting based genetic algorithm (NSGA-III), and a reference vector guided evolutionary algorithm (RVEA). We start with atypical setting aimed at approximating the Pareto front without introducing any user preferences. Based on the analyses of the approximated Pareto front, we introduce a preference articulation method and embed it in the three evolutionary algorithms for identifying solutions that the decision-maker prefers. Our experimental results demonstrate that by incorporating user preferences into many-objective evolutionary algorithms, we are not only able to gain deep insight into the trade-off relationships between the objectives, but also to achieve high-quality solutions reflecting the decision-maker's preferences. In addition, our experimental results indicate that each of the three algorithms examined in this work has its unique advantages that can be exploited when applied to the optimization of real-world problems.","Optimization,
Evolutionary computation,
Hybrid electric vehicles,
Convergence,
Algorithm design and analysis,
Sorting"
From Activity Recognition to Intention Recognition for Assisted Living Within Smart Homes,"The global population is aging; projections show that by 2050, more than 20% of the population will be aged over 64. This will lead to an increase in aging related illness, a decrease in informal support, and ultimately issues with providing care for these individuals. Assistive smart homes provide a promising solution to some of these issues. Nevertheless, they currently have issues hindering their adoption. To help address some of these issues, this study introduces a novel approach to implementing assistive smart homes. The devised approach is based upon an intention recognition mechanism incorporated into an intelligent agent architecture. This approach is detailed and evaluated. Evaluation was performed across three scenarios. Scenario 1 involved a web interface, focusing on testing the intention recognition mechanism. Scenarios 2 and 3 involved retrofitting a home with sensors and providing assistance with activities over a period of 3 months. The average accuracy for these three scenarios was 100%, 64.4%, and 83.3%, respectively. Future will extend and further evaluate this approach by implementing advanced sensor-filtering rules and evaluating more complex activities.","Intelligent agents,
Activity recognition,
Smart homes,
Hidden Markov models,
Aging,
Intelligent sensors"
Memristive Model for Synaptic Circuits,"As a promising alternative for next-generation memory, memristors provide several useful features such as high density, nonvolatility, low power, and good scalability as compared with conventional CMOS-based memories. In this brief, a voltage-controlled threshold memristive model is proposed, which is based on experimental data of memristive devices. Moreover, the model is more suitable for the design of memristor-based synaptic circuits as compared with other memristive models. The effects of memristance variations are considered in the proposed model to evaluate the behavior of memristive synapses within memristor-based neural networks.","Memristors,
Integrated circuit modeling,
Threshold voltage,
Neural networks,
Voltage control,
Computational modeling,
Ions"
BDMA for Millimeter-Wave/Terahertz Massive MIMO Transmission With Per-Beam Synchronization,"We propose beam division multiple access (BDMA) with per-beam synchronization (PBS) in time and frequency for wideband massive multiple-input multiple-output (MIMO) transmission over millimeter-wave (mmW)/Terahertz (THz) bands. We first introduce a physically motivated beam domain channel model for massive MIMO and demonstrate that the envelopes of the beam domain channel elements tend to be independent of time and frequency when both the numbers of antennas at base station and user terminals (UTs) tend to infinity. Motivated by the derived beam domain channel properties, we then propose PBS for mmW/THz massive MIMO. We show that both the effective delay and Doppler frequency spreads of wideband massive MIMO channels with PBS are reduced by a factor of the number of UT antennas compared with the conventional synchronization approaches. Subsequently, we apply PBS to BDMA, investigate beam scheduling to maximize the ergodic achievable rates for both uplink and downlink BDMA, and develop a greedy beam scheduling algorithm. Simulation results verify the effectiveness of BDMA with PBS for mmW/THz wideband massive MIMO systems in typical mobility scenarios.","MIMO,
Delays,
Wireless communication,
Channel models,
Time-frequency analysis,
Antennas,
OFDM"
SDN Based Optimal User Cooperation and Energy Efficient Resource Allocation in Cloud Assisted Heterogeneous Networks,"Cloud radio access network (C-RAN) is considered to be a promising architecture for the future network due to its competitive advantage in both spectral efficiency and energy efficiency (EE). However, the tremendous increase in the mobile data traffic lead resource allocation in C-RANs to be less flexible and efficient. To solve this problem, an energy efficient resource allocation scheme for uplink C-RAN is investigated, and its software-based architecture, which provides the proposed framework in a software-defined network fashion is designed. The proposed framework analyzes the information from the data plane, and completes the resource allocation process in the control plane. In the control plane, a relay region selection algorithm is designed to reduce the computational complexity after the user classification module. Then an optimal power allocation, relay selection and network selection scheme with total power constraint, quality of service requirements, and radio resource constraints are proposed to maximize EE. Based on the dual decomposition method and the Dinkelbach method, optimal power allocation, relay selection, and network selection can be obtained from the reformulated convex problem. Numerical results demonstrate the effectiveness of the proposed scheme.","Relays,
Resource management,
Energy efficiency,
Mobile communication,
Quality of service,
Optimization,
Computer architecture"
A Regulated Charge Pump for Tunneling Floating-Gate Transistors,"Flash memory is an important component in many embedded system-on-a-chip applications, which drives the need to generate high write/erase voltages in generic CMOS processes. In this paper, we present a regulated, high-voltage charge pump for erasing Flash memory and floating-gate transistors. This 0.069-mm2 charge pump was fabricated in a 0.35 μm standard CMOS process. While operating from a 2.5 V supply, the charge pump generates regulated voltages up to 16 V with a PSRR of 52 dB and an output impedance of 6.8 kQ. To reduce power consumption for use in battery-powered applications, this charge pump uses a variable-frequency regulation technique and a new circuit for minimizing short-circuit current in the clock-generation circuitry; the resulting charge pump is able to erase the charge on floating-gate transistors using only 1.45μJ.","Charge pumps,
Tunneling,
Transistors,
Voltage control,
Logic gates,
Standards,
CMOS process"
Stochastic modelling and analysis of cloud computing data center,"Cloud data centers (CDC) are an integral part of today's internet services. Enterprises and Businesses around the world rely heavily on data centers for their daily computation and IT operations. In fact, every time we search for an information on the internet, or we use an application on our smartphones, we access data centers. In CDC, most compute resources are represented as virtual machines (VMs) which are mapped into physical machines (PMs). Performance is often is a key metric for CDC. This paper presents a stochastic model based on queuing theory to aid in studying and analyzing performance in CDC. CDC platforms are modeled with an open queuing system that can be used to estimate the expected Quality of Service (QoS) guarantees the cloud can offer. We give numerical examples to show how the model estimates the number of required VM instances needed to satisfy a given the QoS parameters. In particular, we plot the response time, drop rate and CPU utilization while varying the incoming request arrival rate, and for different number of VM instances. We cross-validate our analytical model using a DES (Discrete Event Simulator). Our analysis and simulation results show that the proposed model is able to estimate the number of VMs needed to achieve QoS targets when varying the arrival request rate.",
"Big IoT Data Analytics: Architecture, Opportunities, and Open Research Challenges","Voluminous amounts of data have been produced, since the past decade as the miniaturization of Internet of things (IoT) devices increases. However, such data are not useful without analytic power. Numerous big data, IoT, and analytics solutions have enabled people to obtain valuable insight into large data generated by IoT devices. However, these solutions are still in their infancy, and the domain lacks a comprehensive survey. This paper investigates the state-of-the-art research efforts directed toward big IoT data analytics. The relationship between big data analytics and IoT is explained. Moreover, this paper adds value by proposing a new architecture for big IoT data analytics. Furthermore, big IoT data analytic types, methods, and technologies for big data mining are discussed. Numerous notable use cases are also presented. Several opportunities brought by data analytics in IoT paradigm are then discussed. Finally, open research challenges, such as privacy, big data mining, visualization, and integration, are presented as future research directions.","data mining,
Internet of Things"
Learning Discriminative Subspaces on Random Contrasts for Image Saliency Analysis,"In visual saliency estimation, one of the most challenging tasks is to distinguish targets and distractors that share certain visual attributes. With the observation that such targets and distractors can sometimes be easily separated when projected to specific subspaces, we propose to estimate image saliency by learning a set of discriminative subspaces that perform the best in popping out targets and suppressing distractors. Toward this end, we first conduct principal component analysis on massive randomly selected image patches. The principal components, which correspond to the largest eigenvalues, are selected to construct candidate subspaces since they often demonstrate impressive abilities to separate targets and distractors. By projecting images onto various subspaces, we further characterize each image patch by its contrasts against randomly selected neighboring and peripheral regions. In this manner, the probable targets often have the highest responses, while the responses at background regions become very low. Based on such random contrasts, an optimization framework with pairwise binary terms is adopted to learn the saliency model that best separates salient targets and distractors by optimally integrating the cues from various subspaces. Experimental results on two public benchmarks show that the proposed approach outperforms 16 state-of-the-art methods in human fixation prediction.","Visualization,
Image color analysis,
Estimation,
Principal component analysis,
Computational modeling,
Eigenvalues and eigenfunctions,
Optimization"
An Energy-Efficient ECC Processor of UHF RFID Tag for Banknote Anti-Counterfeiting,"In this paper, we present the design and analysis of an energy-efficient 163-b elliptic curve cryptographic (ECC) processor suitable for passive ultrahigh frequency (UHF) radio frequency identification (RFID) tags that are usable for banknote authentication and anti-counterfeiting. Even partial public key cryptographic functionality has long been thought to consume too much power and to be too slow to be usable in passive UHF RFID systems. Utilizing a low-power design strategy with optimized register file management and an architecture based on the López-Dahab Algorithm, we designed a low-power ECC processor that is used with a modified ECC-DH authentication protocol. The ECC-DH authentication protocol is compatible with the ISO/IEC 18000-63 (“Gen2”) passive UHF RFID protocol. The ECC processor requires 12 145 gate equivalents. The ECC processor consumes 5.04 nJ/b at a frequency of 960 kHz when implemented in a 0.13-μm standard CMOS process. The tag identity authentication function requires 30 600 cycles to complete all scalar multiplication operations. This size, speed, and power of the ECC processor makes it practical to use within a passive UHF RFID tag and achieve up to 1500 banknote authentications per minute, which is sufficient for use in the fastest banknote counting machines.","Radio frequency identification,
Identification,
Cyrptography,
Low power electronics,
Authentication,
Elliptic curve cryptograpjy,
Passive RFID tags,
Energy efficiency"
"Optimal Power Control in Green Wireless Sensor Networks With Wireless Energy Harvesting, Wake-Up Radio and Transmission Control","Wireless sensor networks (WSNs) are autonomous networks of spatially distributed sensor nodes that are capable of wirelessly communicating with each other in a multihop fashion. Among different metrics, network lifetime and utility, and energy consumption in terms of carbon footprint are key parameters that determine the performance of such a network and entail a sophisticated design at different abstraction levels. In this paper, wireless energy harvesting (WEH), wake-up radio (WUR) scheme, and error control coding (ECC) are investigated as enabling solutions to enhance the performance of WSNs while reducing its carbon footprint. Specifically, a utility-lifetime maximization problem incorporating WEH, WUR, and ECC, is formulated and solved using distributed dual subgradient algorithm based on the Lagrange multiplier method. Discussion and verification through simulation results show how the proposed solutions improve network utility, prolong the lifetime, and pave the way for a greener WSN by reducing its carbon footprint.","Green communication,
Wireless sensor networks,
Energy harvesting,
Radio communication,
Error correction codes,
Encoding,
Autonomous networks,
Energy consumption"
"Unhappy Developers: Bad for Themselves, Bad for Process, and Bad for Software Product","Recent research in software engineering supports the ""happy-productive"" thesis, and the desire of flourishing happiness among programmers is often expressed by industry practitioners. Recent literature has suggested that a cost-effective way to foster happiness and productivity among workers could be to limit unhappiness of developers due to its negative impact. However, possible negative effects of unhappiness are still largely unknown in the software development context. In this paper, we present the first results from a study exploring the consequences of the unhappy developers. Using qualitative data analysis of the survey responses given by 181 participants, we identified 49 potential consequences of unhappiness while developing software. These results have several implications. While raising the awareness of the role of moods, emotions and feelings in software development, we foresee that our classification scheme will spawn new happiness studies linking causes and effects, and it can act as a guideline for developers and managers to foster happiness at work.","Software,
Software engineering,
Productivity,
Mood,
Encoding,
Conferences,
Computer science"
A Distributed Finite-Time Consensus Algorithm for Higher-Order Leaderless and Leader-Following Multiagent Systems,"By employing the finite-time control method, the consensus control algorithm for higher-order multiagent systems is designed in this paper. Under a neighbor-based rule, a higher-order finite-time consensus algorithm is explicitly constructed, which only uses local information. The finite-time consensus control algorithm can guarantee that the state consensus is achieved in a finite time. In addition, for multiagent systems having a leader-following structure, the consensus algorithm is also designed. Finally, two examples are presented to show the effectiveness.","Multi-agent systems,
Algorithm design and analysis,
Heuristic algorithms,
Convergence,
Design methodology,
Protocols,
Control systems"
Information theoretic structure learning with confidence,"Information theoretic measures (e.g. the Kullback Liebler divergence and Shannon mutual information) have been used for exploring possibly nonlinear multivariate dependencies in high dimension. If these dependencies are assumed to follow a Markov factor graph model, this exploration process is called structure discovery. For discrete-valued samples, estimates of the information divergence over the parametric class of multinomial models lead to structure discovery methods whose mean squared error achieves parametric convergence rates as the sample size grows. However, a naive application of this method to continuous nonparametric multivariate models converges much more slowly. In this paper we introduce a new method for nonparametric structure discovery that uses weighted ensemble divergence estimators that achieve parametric convergence rates and obey an asymptotic central limit theorem that facilitates hypothesis testing and other types of statistical validation.","Estimation,
Testing,
Convergence,
Kernel,
Bandwidth,
Mutual information,
Random variables"
Action Recognition Using 3D Histograms of Texture and A Multi-Class Boosting Classifier,"Human action recognition is an important yet challenging task. This paper presents a low-cost descriptor called 3D histograms of texture (3DHoTs) to extract discriminant features from a sequence of depth maps. 3DHoTs are derived from projecting depth frames onto three orthogonal Cartesian planes, i.e., the frontal, side, and top planes, and thus compactly characterize the salient information of a specific action, on which texture features are calculated to represent the action. Besides this fast feature descriptor, a new multi-class boosting classifier (MBC) is also proposed to efficiently exploit different kinds of features in a unified framework for action classification. Compared with the existing boosting frameworks, we add a new multi-class constraint into the objective function, which helps to maintain a better margin distribution by maximizing the mean of margin, whereas still minimizing the variance of margin. Experiments on the MSRAction3D, MSRGesture3D, MSRActivity3D, and UTD-MHAD data sets demonstrate that the proposed system combining 3DHoTs and MBC is superior to the state of the art.","Feature extraction,
Boosting,
Three-dimensional displays,
Histograms,
Robustness,
Classification algorithms,
Hidden Markov models"
Complex Networks Theory For Modern Smart Grid Applications: A Survey,"This paper provides a survey of studying complex network theory for modern smart grid applications. A brief overview of complex network theory will be explored first. Topological characteristics, statistic characteristics, such as self-organized criticality and critically slow down, and dynamical characteristics, including synchronizations, consensus control, and pinning control, will be briefly addressed. Then, we will illustrate how complex network theory can be applied to modern smart grids in structural vulnerability assessment, cascading blackouts, grid synchronization, network reconfigurations, distributed droop control, pinning control for micro-grid autonomous operations, and effective grid expansions. Some emerging topics and future perspectives are also addressed.","Smart grids,
Complex networks,
Power system faults,
Power system protection,
Complexity theory,
Couplings"
On Reliable Task Assignment for Spatial Crowdsourcing,"The large quantity of mobile devices equipped with various built-in sensors and the easy access to the high-speed wireless networks have made spatial crowdsourcing receive much attention in the research community recently. Generally, the objective of spatial crowdsourcing is to outsource location-based sensing tasks (e.g., traffic monitoring and pollution monitoring) to ordinary mobile workers (e.g., users carrying smartphones) efficiently. In this paper, we study a reliable task assignment problem for spatial crowdsourcing in a large worker market. Specifically, we use worker confidence to represent the reliability of successfully completing the assigned sensing tasks, and we formulate two optimization problems, maximum reliability assignment (MRA) under a recruitment budget and minimum cost assignment (MCA) under a task reliability requirement. We reveal the special structure properties of these problems, based on which we design effective approaches to assign tasks to the most suitable workers. The performances of the proposed algorithms are verified by theoretic analysis and experimental results on both real and synthetic datasets.","Sensors,
Crowdsourcing,
Reliability,
Mobile communication,
Mobile handsets,
Monitoring,
Servers"
JAMMY: A Distributed and Dynamic Solution to Selective Jamming Attack in TDMA WSNs,"Time division multiple access (TDMA) is often used in wireless sensor networks (WSNs), especially for critical applications, as it provides high energy efficiency, guaranteed bandwidth, bounded and predictable latency, and absence of collisions. However, TDMA is vulnerable to selective jamming attacks. In TDMA transmission, slots are typically pre-allocated to sensor nodes, and each slot is used by the same node for a number of consecutive superframes. Hence, an adversary could thwart a victim node's communication by simply jamming its slot(s). Such attack turns out to be effective, energy efficient, and extremely difficult to detect. In this paper, we present JAMMY, a distributed and dynamic solution to selective jamming in TDMA-based WSNs. Unlike traditional approaches, JAMMY changes the slot utilization pattern at every superframe, thus making it unpredictable to the adversary. JAMMY is decentralized, as sensor nodes determine the next slot utilization pattern in a distributed and autonomous way. Results from performance analysis of the proposed solution show that JAMMY introduces negligible overhead yet allows multiple nodes to join the network, in a limited number of superframes.","Jamming,
Wireless sensor networks,
Time division multiple access,
Generators,
Monitoring,
IEEE 802.15 Standard,
Interference"
Image Sensor Based Visible Light Positioning System With Improved Positioning Algorithm,"We optimize an image sensor-based indoor visible light positioning (VLP) system by improving the positioning algorithm. Specifically, we derive a close-form expression to determine the receiver's position and orientation using the singular value decomposition (SVD) technique, which speeds up the positioning process and enhances the robustness. Simulation results show that the proposed SVD-based noniterative positioning algorithm is 50-80 times faster than the conventional iterative Levenberg-Marquardt-based algorithm and avoids the possible failures caused by the bad initial guesses. Meanwhile, we theoretically investigate the VLP system by deriving the Cramer-Rao lower bound and the root mean square error bound as the positioning accuracy limit and study the impact of system parameters on the positioning error. Finally, we experimentally evaluate the performance of the improved VLP system. It achieves highly robust and fast 3-D positioning with centimeter-level accuracy.","LED lamps,
Receivers,
Cameras,
Robustness,
Matrices,
Root mean square"
SAF: Stochastic Adaptive Forwarding in Named Data Networking,"Forwarding decisions in classical IP-based networks are predetermined by routing. This is necessary to avoid loops, inhibiting opportunities to implement an adaptive and intelligent forwarding plane. Consequently, content distribution efficiency is reduced due to a lack of inherent multi-path transmission. In Named Data Networking (NDN) instead, routing shall hold a supporting role to forwarding, providing sufficient potential to enhance content dissemination at the forwarding plane. In this paper, we design, implement, and evaluate a novel probability-based forwarding strategy, called Stochastic Adaptive Forwarding (SAF) for NDN. SAF imitates a self-adjusting water pipe system, intelligently guiding and distributing interests through network crossings circumventing link failures and bottlenecks. Just as real pipe systems, SAF employs overpressure valves enabling congested nodes to lower pressure autonomously. Through an implicit feedback mechanism, it is ensured that the fraction of the traffic forwarded via congested nodes decreases. By conducting simulations, we show that our approach outperforms existing forwarding strategies in terms of the interest satisfaction ratio in the majority of the evaluated scenarios. This is achieved by extensive utilization of NDN's multipath and content-lookup capabilities without relying on the routing plane. SAF explores the local environment by redirecting requests that are likely to be dropped anyway. This enables SAF to identify new paths to the content origin or to cached replicas, circumventing link failures, and resource shortages without relying on routing updates.","Routing,
Adaptive systems,
Valves,
Delays,
IEEE transactions,
Stochastic processes,
IP networks"
Wideband MIMO Frequency-Modulated Emission Design With Space-Frequency Nulling,"A design approach is presented that jointly optimizes the beampattern and spectral content of a wideband multiple-input multiple-output (MIMO) radar emission within the context of physically realizable frequency-modulated (FM) waveforms emitted from a uniform linear array. Such waveforms minimize the distortion induced by the power amplifier by virtue of being constant amplitude and inherently well-contained spectrally. The design approach is a specific form of alternating projections that shapes the emission spectrum as a function of spatial angle while intrinsically addressing the problem of reactive power that arises for the wideband MIMO emission. This scheme also permits incorporation of joint space-frequency nulling to facilitate spectrum cohabitation with other nearby RF users. The design process is performed in a discretized manner that is oversampled relative to waveform 3-dB bandwidth to capture a sufficient portion of the spectral roll-off to realize the physical waveform, which is subsequently implemented via the polyphase-coded FM structure.","Wideband,
Frequency modulation,
MIMO,
Chirp modulation,
Array signal processing,
Antennas"
Cell Switch-Off for Networks Deployed With Variable Spatial Regularity,"Cell switch-off (CSO) is considered to be a promising approach to reducing the energy consumed by cellular networks. In this letter, we set a new CSO research direction that focuses on saving energy and increasing the performance of a network-deployed with variable amounts of spatial regularity-by switching off some cells so as to maximize the spatial regularity of the remaining active cells. We propose three greedy algorithms for tackling this new problem. Improving the spatial regularity using a greedy algorithm results in either: (1) much extra energy could be saved while maintaining network performance or (2) saving the same amount of energy as the random CSO with better network performance.",
Performance Comparison of Cognitive Radio Sensor Networks for Industrial IoT With Different Deployment Patterns,"Square lattice (SL), triangle lattice (TL), and hexagon lattice (HL) are widely used regular deployment patterns for industrial Internet of Things (IoT). However, the performance of cognitive-radio-based access with these three deployment patterns has not been explored yet. This paper first designs a transmission scheduling method named cognitive access for regular topology (CART) in cognitive radio sensor networks (CRSNs) with minimal occupation of channels and high transmission efficiency. CART consists of a timeslot-and-channel allocation scheme, a cooperative spectrum-sensing scheme, and a scheme for reporting spectrum-sensing results (SSRs) in SL, TL, and HL. This paper also analyzes CART's cooperative spectrum-sensing performance, reception bandwidth, and transmission delay for different transmission interference range and coverage patterns. Based on numerical analysis and simulation, this paper makes comparison between CART and optimal transmission scheduling method for single channel, and that among these three deployment patterns. Results show the following insights for efficient deployment of CRSN: 1) TL yields the optimal cooperative spectrum-sensing performance among three patterns by data fusion rule of 3-out-of-7; 2) under the same conditions and area for deployment, SL provides the optimal reception bandwidth; 3) SL and TL lead to low transmission delay for critical complete coverage; 4) SL leads to the lowest transmission delay for critical multiple coverage; 5) the false alarm (FA) probability of individual node has little influence on transmission delay, while the probability of primary user's (PU) occurrence has noticeably influence on it; and 6) increasing the ratio of transmission timeslot to spectrum-sensing timeslot may decrease transmission delay","Topology,
Interference,
Delays,
Monitoring,
Lattices,
Resource management,
Bandwidth"
Wideband Circularly Polarized Antipodal Curvedly Tapered Slot Antenna Array for 5G Applications,"This paper presents and characterizes a novel high gain circularly polarized (CP) antenna array for 5G applications. The array element is an antipodal curvedly tapered slot antenna (ACTSA) generating circularly polarized field. The CP ACTSA fed by substrate integrated waveguide (SIW) is convenient to integrate with substrates. By introducing two sheet metals on the two sides of the rectangular Rogers 6002 substrate, an impedance bandwidth of 18.2%, a wide 3-dB axial ratio (AR) bandwidth of 16.9%, and stable gain of 8 ± 0.6 dBic over the operating band are achieved. By employing the proposed CP ACTSA as radiating elements, a 4 × 4 high-gain wideband antenna array is proposed for 5G E-band and W-band millimeter-wave applications. Fabrications are carried out using wire cutting electrical discharge machine and print circuit board process, which have advantages of low cost. The whole feeding network is realized by SIW with low insertion loss at millimeter-wave band. Benefiting from the wide impedance and AR bandwidth of the new antenna element, good impedance matching and AR characteristics can be achieved over the whole working frequency band from 81 to 95 GHz by this antenna array. Gain up to 18.5 ± 1.3 dBic is also obtained.","Antenna arrays,
Slot antennas,
Bandwidth,
Substrates,
Antenna measurements,
5G mobile communication"
A Multiobjective Approach for Multistage Reliability Growth Planning by Considering the Timing of New Technologies Introduction,"This paper proposes a new multiobjective multiple stage reliability growth planning (MO-MS-RGP) model. The model is based on multiobjective consideration of developing a new product, including the cost, time, and product reliability. The number of test units, test time, and the percentage of introduced new technologies are considered as decision variables in the model. Varying reliability growth rates are considered for each subsystem in each stage. Product new technologies or contents can be completely introduced in one stage or partially introduced to the product over multiple stages. New product development time limit and budget are considered as constraints in the MO-MS-RGP model. An integrated approach is developed to formulate and solve the proposed MO-MS-RGP problem. The approach starts with a multiobjective evolutionary algorithm, called multipleobjective particle swarm optimization to find a set of Pareto optimal solutions. Then, clustering methods are applied to cluster the solutions obtained by the evolutionary algorithm. Finally, the clustered solutions are ranked using a multiple criteria decision making method. A numerical example illustrates the application of the proposed MO-MS-RGP model for the reliability growth planning optimization of a next generation engine development.","Reliability engineering,
Testing,
Product development,
Planning,
Data models,
Upper bound"
Performance Assessment of Cross-Directional Control for Paper Machines,"The minimum variance controller has been extensively used as a benchmark in the performance assessment of both univariate and multivariate control loops when time delay is the fundamental performance limitation. In this paper, the spatial and temporal performance limitations in the cross-directional (CD) control of paper machines are analyzed. The idea of minimum variance benchmarking is extended to the CD process based on these performance limitations. Based on an industrial CD controller, a user-specified benchmark, which is more practical and less aggressive, is also proposed. In addition, several related performance indices are proposed for the CD process based on both the minimum variance benchmark and the user-specified benchmark. Illustrative examples from a paper machine simulator and industrial data sets are provided to show the effectiveness of the proposed performance indices.","Benchmark testing,
Steady-state,
Process control,
Performance analysis,
Delay effects,
Actuators,
Monitoring"
"A Reversible Watermarking Technique for Social Network Data Sets for Enabling Data Trust in Cyber, Physical, and Social Computing","Social network data are being mined for extracting interesting patterns. Such data are collected by different researchers and organizations and are usually also shared via different channels. These data usually have huge volume because there are millions of social network users throughout the world. In this context, ownership protection of such data sets with huge volume becomes relevant. Digital watermarking is a more demanding solution than any other technique for ensuring rights protection and integrity of the original data sets. The objective of this paper is to devise a reversible watermarking technique for the social network data to prove ownership rights and also provide a mechanism for data recovery. Robustness of the proposed technique is evaluated through attack analysis using experimental study. In this paper, Z notation-based formal specification is also provided to show the working of the proposed reversible watermarking technique for social network data sets for enabling data trust in Cyber, Physical, and Social Computing (CPSCom).","Watermarking,
Social network services,
Data mining,
Decoding,
Robustness,
Encoding,
Data models"
Versatile Manufacturing of Split-Block Microwave Devices Using Rapid Prototyping and Electroplating,"We present a novel method of rapid prototyping waveguide and antenna using plating on plastic technique. The part is created by high-precision three-dimensional printing and plated with copper using both electroless plating and electroplating. The performance is comparable to industry-made waveguides and antennas, but the time and cost for creating these parts are largely reduced.","Surface treatment,
Three-dimensional displays,
Surface waves,
Copper,
Plating,
Waveguide components"
Three-Bandgap Absolute Quantum Efficiency in GaSb/GaAs Quantum Dot Intermediate Band Solar Cells,"In this work, we study type-II GaSb/GaAs quantum-dot intermediate band solar cells (IBSCs) by means of quantum efficiency (QE) measurements. We are able, for the first time, to measure an absolute QE which clearly reveals the three characteristic bandgaps of an IBSC; EG, EH, and EL, for which we found the values 1.52, 1.02, and 0.49 eV, respectively, at 9 K. Under monochromatic illumination, QE at the energies EH and EL is 10-4 and 10-8, respectively. These low values are explained by the lack of efficient mechanisms of completing the second sub-bandgap transition when only monochromatic illumination is used. The addition of a secondary light source (E = 1.32 eV) during the measurements produces an increase in the measured QE at EL of almost three orders of magnitude.","Temperature measurement,
Photovoltaic cells,
Quantum dots,
Absorption,
Energy measurement,
Silicon carbide,
Gallium arsenide"
A Human-Centered Activity Tracking System: Toward a Healthier Workplace,"Lost productivity from lower back injuries in workplaces costs billions of U.S. dollars per year. A significant fraction of such workplace injuries are the result of workers not following best practices. In this paper, we present the design, implementation, and evaluation of a novel computer-vision-based system that aims to increase the workers' compliance to best practices. The system consists of inexpensive programmable depth sensors, wearable devices, and smart phones. The system is designed to track the activities of consented workers using the depth sensors, alert them discreetly on detection of noncompliant activities, and produce cumulative reports on their performance. Essentially, the system provides a valuable set of services for both workers and administrators toward a healthier and, therefore, more productive workplace. This study advances the state of the art in the following ways: 1) a set of mechanisms that enable nonintrusive privacy-aware selective tracking of consented workers in the presence of people that should not be tracked; 2) a single sign-on worker identification mechanism; 3) a method that provides realtime detection of noncompliant activities; and 4) a usability study that provides invaluable feedback regarding system design and deployment, as well as future areas of improvements.","Injuries,
Intelligent sensors,
Sensor systems,
Employment,
Iris recognition"
Automated Assessment of Disease Progression in Acute Myeloid Leukemia by Probabilistic Analysis of Flow Cytometry Data,"Objective: Flow cytometry (FC) is a widely acknowledged technology in diagnosis of acute myeloid leukemia (AML) and has been indispensable in determining progression of the disease. Although FC plays a key role as a posttherapy prognosticator and evaluator of therapeutic efficacy, the manual analysis of cytometry data is a barrier to optimization of reproducibility and objectivity. This study investigates the utility of our recently introduced nonparametric Bayesian framework in accurately predicting the direction of change in disease progression in AML patients using FC data. Methods: The highly flexible nonparametric Bayesian model based on the infinite mixture of infinite Gaussian mixtures is used for jointly modeling data from multiple FC samples to automatically identify functionally distinct cell populations and their local realizations. Phenotype vectors are obtained by characterizing each sample by the proportions of recovered cell populations, which are, in turn, used to predict the direction of change in disease progression for each patient. Results: We used 200 diseased and nondiseased immunophenotypic panels for training and tested the system with 36 additional AML cases collected at multiple time points. The proposed framework identified the change in direction of disease progression with accuracies of 90% (nine out of ten) for relapsing cases and 100% (26 out of 26) for the remaining cases. Conclusions: We believe that these promising results are an important first step toward the development of automated predictive systems for disease monitoring and continuous response evaluation. Significance: Automated measurement and monitoring of therapeutic response is critical not only for objective evaluation of disease status prognosis but also for timely assessment of treatment strategies.","Diseases,
Training,
Sociology,
Statistics,
Bayes methods,
Electron tubes,
Monitoring"
Construction of Barrier in a Fishing Game With Point Capture,"This paper addresses a particular pursuit-evasion game, called as “fishing game” where a faster evader attempts to pass the gap between two pursuers. We are concerned with the conditions under which the evader or pursuers can win the game. This is a game of kind in which an essential aspect, barrier, separates the state space into disjoint parts associated with each player's winning region. We present a method of explicit policy to construct the barrier. This method divides the fishing game into two subgames related to the included angle and the relative distances between the evader and the pursuers, respectively, and then analyzes the possibility of capture or escape for each subgame to ascertain the analytical forms of the barrier. Furthermore, we fuse the games of kind and degree by solving the optimal control strategies in the minimum time for each player when the initial state lies in their winning regions. Along with the optimal strategies, the trajectories of the players are delineated and the upper bounds of their winning times are also derived.",
Efficient Orchestration Mechanisms for Congestion Mitigation in NFV: Models and Algorithms,"Network Functions Virtualization (NFV) has recently gained momentum among network operators as a means to share their physical infrastructure among virtual operators, which can independently compose and configure their communication services. However, the spatio-temporal correlation of traffic demands and computational loads can result in high congestion and low network performance for virtual operators, thus leading to service level agreement breaches. In this paper, we analyze the congestion resulting from the sharing of the physical infrastructure and propose innovative orchestration mechanisms based on both centralized and distributed approaches, aimed at unleashing the potential of the NFV technology. In particular, we first formulate the network functions composition problem as a non-linear optimization model to accurately capture the congestion of physical resources. To further simplify the network management, we also propose a dynamic pricing strategy of network resources, proving that the resulting system achieves a stable equilibrium in a completely distributed fashion, even when all virtual operators independently select their best network configuration. Numerical results show that the proposed approaches consistently reduce resource congestion. Furthermore, the distributed solution well approaches the performance that can be achieved using a centralized network orchestration system.","Virtualization,
Computational modeling,
Pricing,
Bandwidth,
Optimization,
Dynamic scheduling,
Quality of service"
Analysis and Experimental Evaluation of IEEE 802.15.4e TSCH CSMA-CA Algorithm,"Time-slotted channel hopping (TSCH) is one of the medium access control (MAC) behavior modes defined in the IEEE 802.15.4e standard. It combines time-slotted access and channel hopping, thus providing predictable latency, energy efficiency, communication reliability, and high network capacity. TSCH provides both dedicated and shared links. The latter is special slots assigned to more than one transmitter, whose concurrent access is regulated by a carrier-sense multiple access with collision avoidance (CSMA-CA) algorithm. In this paper, we develop an analytical model of the TSCH CSMA-CA algorithm to predict the performance experienced by nodes when using shared links. The model allows for deriving a number of metrics, such as delivery probability, packet latency, and energy consumption of nodes. Moreover, it considers the capture effect (CE) that typically occurs in real wireless networks. We validate the model through simulation experiments and measurements in a real testbed. Our results show that the model is very accurate. Furthermore, we found that the CE plays a fundamental role as it can significantly improve the performance experienced by nodes.","IEEE 802.15 Standard,
Analytical models,
Algorithm design and analysis,
Measurement,
Prediction algorithms,
Actuators"
Model-Based Optimization of EULAG Kernel on Intel Xeon Phi Through Load Imbalancing,"Load balancing is a widely accepted technique for performance optimization of scientific applications on parallel architectures. Indeed, balanced applications do not waste processor cycles on waiting at points of synchronization and data exchange, maximizing this way the utilization of processors. In this paper, we challenge the universality of the load-balancing approach to optimization of the performance of parallel applications. First, we formulate conditions that should be satisfied by the performance profile of an application in order for the application to achieve its best performance via load balancing. Then we use a real-life scientific application, EULAG MPDATA kernel, to demonstrate that its performance profile on a modern parallel architecture, Intel Xeon Phi, significantly deviates from these conditions. Based on this observation, we propose a method of performance optimization of scientific applications through load imbalancing. In the case of data parallel application, the method uses functional performance models of the application to find partitioning that minimizes its computation time but not necessarily balances the load of processors. We apply this method to optimization of MPDATA on Intel Xeon Phi. Experimental results demonstrate that the performance of this carefully optimized load-balanced application can be further improved by 15percent using the proposed load-imbalancing technique.",
uSOP: A Microprocessor-Based Service-Oriented Platform for Control and Monitoring,"uSOP is a general purpose single-board computer designed for deep embedded applications in control and monitoring of detectors, sensors, and complex laboratory equipment. In this paper, we present and discuss the main aspects of the hardware and software designs and the expandable peripheral architecture built around serial busses. We show the tests done with state-of-the-art ΔΣ 24-b ADC acquisition modules, in order to assess the achievable noise floor in a typical application. Eventually, we report on the deployment of uSOP in the monitoring system framework of the Belle2 experiment, presently under construction at the KEK Laboratory (Tsukuba, Japan).","Random access memory,
Monitoring,
Software,
Hardware,
Computer architecture,
Microcontrollers,
System-on-chip"
Fractional Hopfield Neural Networks: Fractional Dynamic Associative Recurrent Neural Networks,"This paper mainly discusses a novel conceptual framework: fractional Hopfield neural networks (FHNN). As is commonly known, fractional calculus has been incorporated into artificial neural networks, mainly because of its long-term memory and nonlocality. Some researchers have made interesting attempts at fractional neural networks and gained competitive advantages over integer-order neural networks. Therefore, it is naturally makes one ponder how to generalize the first-order Hopfield neural networks to the fractional-order ones, and how to implement FHNN by means of fractional calculus. We propose to introduce a novel mathematical method: fractional calculus to implement FHNN. First, we implement fractor in the form of an analog circuit. Second, we implement FHNN by utilizing fractor and the fractional steepest descent approach, construct its Lyapunov function, and further analyze its attractors. Third, we perform experiments to analyze the stability and convergence of FHNN, and further discuss its applications to the defense against chip cloning attacks for anticounterfeiting. The main contribution of our work is to propose FHNN in the form of an analog circuit by utilizing a fractor and the fractional steepest descent approach, construct its Lyapunov function, prove its Lyapunov stability, analyze its attractors, and apply FHNN to the defense against chip cloning attacks for anticounterfeiting. A significant advantage of FHNN is that its attractors essentially relate to the neuron's fractional order. FHNN possesses the fractional-order-stability and fractional-order-sensitivity characteristics.",
TCABRP: A Trust-Based Cooperation Authentication Bit-Map Routing Protocol Against Insider Security Threats in Wireless Ad Hoc Networks,"In recent years, threats in wireless ad hoc networks (WANETs) could be further divided into outside and insider threats. It is important to consider that the majority of insider threats come from the users who are fully authorized to use the systems they are accessing. This new situation would greatly inhibit the normal activity for data communications, and cause the WANETs to spend a longer time for delivering the same data volumes. Therefore, a Trust-Based Cooperation Authentication Bit-Map Routing Protocol (TCABRP) against insider threats in WANETs is proposed in this paper. It could reduce the damages away from the insider threats in a WANET. Specifically, the cooperation evaluations are employed that include three factors: cooperative scores, cooperative trust values and authenticated codes. The routing protocol is not only a type of behavioral-based technique but also a kind of efficient cryptographic protocol. The cooperative evaluations route vector could protect the chain of the router vector authentication codes for verifying the delivery process and determining whether it is correct or incorrect. Moreover, the proposed routing protocol in WANET could not only prevent InTs efficiently, but also evaluate the behaviors of the compromised node or a selfish node as well.","Nickel,
Routing protocols,
Authentication,
Communication system security,
Wireless communication,
Public key"
Close-to-optimal placement and routing for continuous-flow microfluidic biochips,"Continuous-flow microfluidics rapidly evolved in the last decades as a solution to automate laboratory procedures in molecular biology and biochemistry. Therefore, the physical design of the corresponding chips, i.e., the placement and routing of the involved components and channels, received significant attention. Recently, several physical design solutions for this task have been presented. However, they often rely on general heuristics which traverse the search space in a rather arbitrary fashion and, additionally, consider placement and routing independently from each other. Consequently, the obtained results are often far from being optimal. In this work, a methodology is proposed which aims for determining close-to-optimal physical designs for continuous-flow microfluidic biochips. To this end, we consider all - or, at least, as much as possible - of the valid solutions. As this obviously yields a significant complexity, solving engines are utilized to efficiently traverse the search space and pruning schemes are proposed to reduce the search space without discarding too many promising solutions. Evaluations show that the proposed methodology is capable of determining optimal results for small experiments to be realized. For larger experiments, close-to-optimal results can efficiently be derived. Moreover, compared to the current state-of-the-art, improvements of up to 1-2 orders of magnitude can be observed.","Routing,
Physical design,
Valves,
Complexity theory,
Mixers,
Engines,
Design methodology"
Extreme Kernel Sparse Learning for Tactile Object Recognition,"Tactile sensors play very important role for robot perception in the dynamic or unknown environment. However, the tactile object recognition exhibits great challenges in practical scenarios. In this paper, we address this problem by developing an extreme kernel sparse learning methodology. This method combines the advantages of extreme learning machine and kernel sparse learning by simultaneously addressing the dictionary learning and the classifier design problems. Furthermore, to tackle the intrinsic difficulties which are introduced by the representer theorem, we develop a reduced kernel dictionary learning method by introducing row-sparsity constraint. A globally convergent algorithm is developed to solve the optimization problem and the theoretical proof is provided. Finally, we perform extensive experimental validations on some public available tactile sequence datasets and show the advantages of the proposed method.","Kernel,
Object recognition,
Learning systems,
Robot sensing systems,
Encoding"
Voltage Regulation in Islanded Microgrids Using Distributed Constraint Satisfaction,"Droop control is a key control method for operating islanded microgrids (IMGs). The settings of the droop parameters for distributed generation (DG) units can considerably affect the ability of an IMG to satisfy the required voltage tolerance boundary prescribed in steady-state voltage regulation standards. This paper analyzes the complexity of voltage regulations in droop-controlled IMGs. A new algorithm is proposed to satisfy the voltage regulation requirements of IMGs. The proposed algorithm obviates the need for a centralized secondary controller, where each DG unit updates its own voltage droop parameters, autonomously, via interaction with other DG units, using a low-bandwidth, peer-to-peer communication network. To that end, a distributed constraint satisfaction approach is adopted to formulate the problem of voltage regulation in a multi-agent environment. An asynchronous weak commitment technique is proposed to solve the formulated problem. Several case studies are simulated to evaluate the performance of the proposed algorithm. The results show that the proposed algorithm can effectively mitigate the challenges of voltage regulation in IMG systems.","Voltage control,
Reactive power,
Microgrids,
Steady-state,
Load flow,
Impedance,
Peer-to-peer computing"
Retinal Disease Screening Through Local Binary Patterns,"This paper investigates discrimination capabilities in the texture of fundus images to differentiate between pathological and healthy images. For this purpose, the performance of local binary patterns (LBP) as a texture descriptor for retinal images has been explored and compared with other descriptors such as LBP filtering and local phase quantization. The goal is to distinguish between diabetic retinopathy (DR), age-related macular degeneration (AMD), and normal fundus images analyzing the texture of the retina background and avoiding a previous lesion segmentation stage. Five experiments (separating DR from normal, AMD from normal, pathological from normal, DR from AMD, and the three different classes) were designed and validated with the proposed procedure obtaining promising results. For each experiment, several classifiers were tested. An average sensitivity and specificity higher than 0.86 in all the cases and almost of 1 and 0.99, respectively, for AMD detection were achieved. These results suggest that the method presented in this paper is a robust algorithm for describing retina texture and can be useful in a diagnosis aid system for retinal disease screening.","Retina,
Image segmentation,
Feature extraction,
Optical imaging,
Reactive power,
Biomedical imaging,
Databases"
Sparse Signal Detection With Compressive Measurements via Partial Support Set Estimation,"In this paper, we consider the problem of sparse signal detection based on partial support set estimation with compressive measurements in a distributed network. Multiple nodes in the network are assumed to observe sparse signals, which share a common but unknown support. While in the traditional compressive sensing framework, the goal is to recover the complete sparse signal, in sparse signal detection, complete signal recovery may not be necessary to make a reliable detection decision. In particular, detection can be performed based on partially or inaccurately estimated signals, which requires less computational burden than that is required for complete signal recovery. To that end, we investigate the problem of sparse signal detection based on partially estimated support set. First, we discuss how to determine the minimum fraction of the support set to be known so that a desired detection performance is achieved in a centralized setting. Second, we develop two distributed algorithms for sparse signal detection when the raw compressed observations are not available at the central fusion center. In these algorithms, the final decision statistic is computed based on locally estimated partial support sets via orthogonal matching pursuit at individual nodes. The proposed distributed algorithms with less communication overhead are shown to provide comparable performance (sometimes better) to the centralized approach when the size of the estimated partial support set is very small.","Signal detection,
Matching pursuit algorithms,
Distributed algorithms,
Algorithm design and analysis,
Compressed sensing"
"Noncircular Measurement and Mitigation of
I/Q
Imbalance for OFDM-Based WLAN Transmitters","In future high-speed communication networks, the in-phase/quadrature (I/Q) imbalance mitigation and oscillator drift compensation is a key issue in the design of orthogonal frequency division multiplexing (OFDM)-based wireless LAN (WLAN) transmitters. To this end, we propose a two-stage I/Q imbalance measurement method, where by virtue of the WLAN standard-compliant training sequences, a coarse I/Q imbalance estimation is initially performed jointly with channel equalization. This makes it possible to decouple the effects of frequency-selective channels from the exact amplitude and phase imbalances induced by the local oscillator. Next, the so recovered symbols in DATA field of standardized OFDM systems, such as the IEEE 802.11ac, are recalibrated using a decision-directed scheme; this facilitates least squares-based fine I/Q imbalance estimation. For rigor, augmented complex statistics is employed to account for the effects of data noncircularity and widely linear natures of communication channels. Computer simulations and real world experiments based on the IEEE 802.11ac compliant signals demonstrate the high accuracy of the proposed technique for OFDM-based WLAN transmitters.","OFDM,
Wireless LAN,
Frequency measurement,
Transmitters,
Baseband,
Modulation,
Estimation"
Natural Interaction Techniques for an Unmanned Aerial Vehicle System,"This article provides an overview of existing interaction techniques for controlling unmanned aerial vehicle (UAV) systems. This work focuses on user interfaces with nontraditional input modalities, such as gestures, speech, and gaze direction. Although the authors analyze interaction with UAV systems, most of the findings can be applied to human-robot interaction in general. The authors report on interaction techniques employed to control single as well as multiple UAV systems, define intuitiveness of input vocabularies in the considered context, and introduce a new classification scheme based on the mental models underlying the interaction vocabulary. This article is part of a special issue on drones.","Cognitive science,
Mobile robots,
User centered design,
User interfaces,
Unmanned aerial vehicles"
DOA Estimation Based on Combined Unitary ESPRIT for Coprime MIMO Radar,"Direction of arrival (DOA) estimation for coprime multiple-input multiple-output radar is studied, and a combined unitary estimation of signal parameters via rotational invariance technique (ESPRIT)-based algorithm is proposed. The transmitter and the receiver adopt coprime arrays, which are sparse but still uniform. Therefore, unitary ESPRIT is first used to obtain arbitrary ambiguous DOA estimations based on the rotational invariances of transmit and receive arrays, respectively. After recovering all the other estimations, unique DOA estimation is achieved by finding the coincide results from transmit and receive arrays based on the coprimeness. The proposed algorithm obtains more accurate DOA estimation, achieves higher angle resolution, and identifies more targets than conventional methods. Multiple simulations are conducted to verify the improvement of the proposed algorithm.","Estimation,
Direction-of-arrival estimation,
Covariance matrices,
MIMO radar,
Multiple signal classification,
Eigenvalues and eigenfunctions,
MIMO"
A Laplacian-Based Approach for Finding Near Globally Optimal Solutions to OPF Problems,"A semidefinite programming (SDP) relaxation globally solves many optimal power flow (OPF) problems. For other OPF problems where the SDP relaxation only provides a lower bound on the objective value rather than the globally optimal decision variables, recent literature has proposed a penalization approach to find feasible points that are often nearly globally optimal. A disadvantage of this penalization approach is the need to specify penalty parameters. This paper presents an alternative approach that algorithmically determines a penalization appropriate for many OPF problems. The proposed approach constrains the generation cost to be close to the lower bound from the SDP relaxation. The objective function is specified using iteratively determined weights for a Laplacian matrix. This approach yields feasible points to the OPF problem that are guaranteed to have objective values near the global optimum due to the constraint on generation cost. The proposed approach is demonstrated on both small OPF problems and a variety of large test cases representing portions of European power systems.",
Performance Analysis of IEEE 802.11p DCF for Multiplatooning Communications With Autonomous Vehicles,"Platooning has been identified as a promising framework to improve road capacity, on-road safety, and energy efficiency. Enabling communications among vehicles in platoons is expected to enhance platoon control by keeping constant intervehicle and interplatoon distances. Characterizing the performance of intra- and interplatoon communications in terms of throughput and packet transmission delays is crucial for validating the effectiveness of information sharing on platoon control. In this paper, we introduce an IEEE 802.11p-based communication model for multiplatooning (a chain of platoons) scenarios. We present a probabilistic performance analysis of distributed-coordination-function-based intra- and interplatoon communications. Expressions for the transmission attempt probability, collision probability, packet delay, packet-dropping probability, and network throughput are derived. Numerical results show that the performance of interplatoon communications is affected by the transmissions of the first and last vehicles in a multiplatoon. This effect is reduced with an increase of the platoon number in the multiplatoon. In addition, the communication performance for three typical multiplatooning application scenarios is investigated, indicating that the IEEE 802.11p-based communication can support the timely delivery of vehicle information among platoons for diverse on-road applications.","Vehicles,
Transceivers,
Delays,
Throughput,
Performance analysis,
Safety,
Acceleration"
On Strategic Multi-Antenna Jamming in Centralized Detection Networks,"In this letter, we model a complete-information zero-sum game between a centralized detection network with a multiple access channel between the sensors and the fusion center (FC), and a jammer with multiple transmitting antennas. We choose error probability at the FC as the performance metric, and investigate pure strategy equilibria for this game, and show that the jammer has no impact on the FC's error probability by employing pure strategies at the Nash equilibrium. Furthermore, we also show that the jammer has an impact on the expected utility if it employs mixed strategies.","Jamming,
Sensors,
Game theory,
Games,
Error probability,
Antennas,
Electronic mail"
A Mixed Transmission Strategy to Achieve Energy Balancing in Wireless Sensor Networks,"In this paper, we investigate the problem of energy balanced data collection in wireless sensor networks, aiming to balance energy consumption among all sensor nodes during the data propagation process. Energy balanced data collection can potentially save energy consumption and prolong network lifetime, and hence, it has many practical implications for sensor network design and deployment. The traditional hop-by-hop transmission model allows a sensor node to propagate its packets in a hop-by-hop manner toward the sink, resulting in poor energy balancing for the entire network. To address the problem, we apply a slice-based energy model, and divide the problem into inter-slice and intra-slice energy balancing problems. We then propose a probability-based strategy named inter-slice mixed transmission protocol and an intra-slice forwarding technique to address each of the problems. We propose an energy-balanced transmission protocol by combining both techniques to achieve total energy balancing. In addition, we study the condition of switching between inter-slice transmission and intra-slice transmission, and the limitation of hops in an intra-slice transmission. Through our extensive simulation studies, we demonstrate that the proposed protocols achieve energy balancing, prolong network lifespan, and decrease network delay, compared with the hop-by-hop transmission and a cluster-based routing protocol under various parameter settings.","Wireless sensor networks,
Energy consumption,
Protocols,
Data collection,
Batteries,
Relays,
Silicon"
3-D Displacement Measurement for Structural Health Monitoring Using Low-Frequency Magnetic Fields,"Smart structures of the future will require a cost-effective, easily deployable solution for structural health monitoring. High loads on structures cause stresses that may lead to expansion of gaps, which are of utmost importance when it comes to overall structural health, as they absorb excess stress. Existing methods for direct displacement measurement of expansion joints are not ideal, as they operate under line-of-sight assumptions, are sensitive to moisture, or employ moving parts. In addition, the majority of existing sensors for structural health monitoring are uniaxial, and hence are fundamentally unable to measure 3-D displacement. Importantly, none of the existing wireless sensors for structural health monitoring can be embedded in concrete. We propose a system that uses low-frequency magnetic fields to conduct 3-D displacement measurement directly from within concrete, with a median displacement error of 0.5 mm in all directions, with a maximum separation distance of 50 mm between the transmitter and the receiver. The sensors can be attached to the concrete surface after the building is erected, or can be included in the concrete mix at manufacture, to monitor displacement between gaps in expansion joints, perform crack detection in concrete ties for railroads and in pavements, as well as aid position measurement for the assembly of premanufactured concrete blocks. Embedment in concrete allows operation throughout the lifetime of a structure, providing early warning of impending disaster and helping to inform repair operations.","Concrete,
Magnetic sensors,
Displacement measurement,
Monitoring,
Frequency measurement,
Position measurement"
Using Information-Flow Methods to Analyze the Security of Cyber-Physical Systems,"Securing information flow is essential to methods that must ensure confidentiality, but information-flow disruption is equally important because it points to an integrity vulnerability. A proposed security model addresses both aspects, accounting for cyber-physical systems' unique confidentiality and integrity vulnerabilities.",
On Deep Learning for Trust-Aware Recommendations in Social Networks,"With the emergence of online social networks, the social network-based recommendation approach is popularly used. The major benefit of this approach is the ability of dealing with the problems with cold-start users. In addition to social networks, user trust information also plays an important role to obtain reliable recommendations. Although matrix factorization (MF) becomes dominant in recommender systems, the recommendation largely relies on the initialization of the user and item latent feature vectors. Aiming at addressing these challenges, we develop a novel trust-based approach for recommendation in social networks. In particular, we attempt to leverage deep learning to determinate the initialization in MF for trust-aware social recommendations and to differentiate the community effect in user's trusted friendships. A two-phase recommendation process is proposed to utilize deep learning in initialization and to synthesize the users' interests and their trusted friends' interests together with the impact of community effect for recommendations. We perform extensive experiments on real-world social network data to demonstrate the accuracy and effectiveness of our proposed approach in comparison with other state-of-the-art methods.","Social network services,
Motion pictures,
Machine learning,
Optimization,
Reliability,
Recommender systems,
Computer science"
The Interaction Between Schema Matching and Record Matching in Data Integration,"Schema Matching (SM) and Record Matching (RM) are two necessary steps in integrating multiple relational tables of different schemas, where SM unifies the schemas and RM detects records referring to the same real-world entity. The two processes have been thoroughly studied separately, but few attention has been paid to the interaction of SM and RM. In this work, we find that, even alternating them in a simple manner, SM and RM can benefit from each other to reach a better integration performance (i.e., in terms of precision and recall). Therefore, combining SM and RM is a promising solution for improving data integration. To this end, we define novel matching rules for SM and RM, respectively, that is, every SM decision is made based on intermediate RM results, and vice versa, such that SM and RM can be performed alternately. The quality of integration is guaranteed by a Matching Likelihood Estimation model and the control of semantic drift, which prevent the effect of mismatch magnification. To reduce the computational cost, we design an index structure based on q-grams and a greedy search algorithm that can reduce around 90 percent overhead of the interaction. Extensive experiments on three data collections show that the combination and interaction between SM and RM significantly outperforms previous works that conduct SM and RM separately.","Indexes,
Joining processes,
Data integration,
Semantics,
Estimation,
Computational modeling,
Electronic mail"
A Generalized Framework for Inference-Based Diagnosis of Discrete Event Systems Capturing Both Disjunctive and Conjunctive Decision-Making,"We have previously introduced an inference-based framework for decentralized decision-making, comprising of multiple observers, each with its own partial observation, where inferencing over the ambiguities of the self and the others is used to issue local decisions, and a global decision is taken to be the one possessing the minimum ambiguity level. In this setting, we previously introduced the notion of N-inference ⋁-diagnosability to characterize the existence of a disjunctive decentralized diagnosis scheme so that any fault can be detected within a bounded delay, using at most N-levels of inferencing, by one of the diagnosers. While the disjunctive scheme relies on one of the diagnosers making the failure decision, the dual conjunctive scheme relies on none of the diagnosers making the nonfailure decision. It is known that the two schemes are incomparable, and in this paper we extend our earlier work to provide a more general framework, introducing the notion of N-inference diagnosability, capturing both disjunctive and conjunctive schemes. We also develop a method for verifying N-inference diagnosability, as well as discuss several of its useful properties.","Decision making,
Delays,
Discrete-event systems,
Fault detection,
Automata,
Indexes,
Sensors"
IGMM-Based Co-Localization of Mobile Users With Ambient Radio Signals,"Co-localization of mobile users combines methods of detecting nearby users and providing them interesting and useful services or information. By exploiting the massive use of smartphones, nearby users can be co-localized using only their captured ambient radio signals. In this paper, we propose a real-time co-localization system, in a centralized manner, that leverages co-located users with high accuracy. We exploit the similarity of radio frequency measurements from users' mobile terminal. We do not require any further information about them. Our co-localization system is based on a nonparametric Bayesian method called infinite Gaussian mixture model that allows the model parameters to change with observed input data. In addition, we propose a modified version of Gibbs sampling technique with an average similarity threshold to better fit user's group. We design our system in a completely centralized manner. Hence, it enables the network to control and manage the formation of the users' groups. We first evaluate the performance of our proposal numerically. Then, we carry out an extensive experiment to demonstrate the feasibility, and the efficiency of our approach with data sets from a real-world setting. Results on experiment favor our algorithm over the state-of-the-art community detection-based clustering method.","Mobile communication,
Servers,
Internet of things,
Smart phones,
IEEE 802.11 Standard,
Real-time systems,
Clustering algorithms"
An Efficient Safety Confirmation Method Using Image Database in Multiple-MDRU-Based Disaster Recovery Network,"Safety confirmation is one of the most important applications of disaster-resilient networking based on the movable and deployable resource unit (MDRU). With an embedded image database, a single MDRU can provide the safety confirmation application that allows users to search for the images that look similar to the people they are looking for. However, a network with multiple MDRUs may increase the image searching time of the safety confirmation application because the image databases are distributed and the capacity of the backbone wireless network constructed by connecting the MDRUs is also limited. Therefore, in this paper, we propose a safety confirmation method that guarantees the minimum searching time of users. The method includes four phases, namely, resizing and storing images, broadcasting small-size images, routing, and deciding image size to deliver to users. Based on mathematical analysis using the absorbing Markov chain, we estimate the expected searching time for each different size of images and choose the most appropriate size. Furthermore, we conduct extensive computer-based simulations to verify the findings of our analysis. The simulation results prove the existence of the optimal image size that minimizes the searching time and demonstrate the effectiveness of our proposed method.","Safety,
Image databases,
Routing,
Multimedia communication,
Wireless networks,
Image recognition"
Learning utterance-level representations for speech emotion and age/gender recognition using deep neural networks,"Accurately recognizing speaker emotion and age/gender from speech can provide better user experience for many spoken dialogue systems. In this study, we propose to use deep neural networks (DNNs) to encode each utterance into a fixed-length vector by pooling the activations of the last hidden layer over time. The feature encoding process is designed to be jointly trained with the utterance-level classifier for better classification. A kernel extreme learning machine (ELM) is further trained on the encoded vectors for better utterance-level classification. Experiments on a Mandarin dataset demonstrate the effectiveness of our proposed methods on speech emotion and age/gender recognition tasks.","Emotion recognition,
Speech recognition,
Speech,
Kernel,
Training,
Detectors,
Feature extraction"
"Compressive Video Sensing: Algorithms, architectures, and applications","The design of conventional sensors is based primarily on the Shannon?Nyquist sampling theorem, which states that a signal of bandwidth W Hz is fully determined by its discrete time samples provided the sampling rate exceeds 2 W samples per second. For discrete time signals, the Shannon?Nyquist theorem has a very simple interpretation: the number of data samples must be at least as large as the dimensionality of the signal being sampled and recovered. This important result enables signal processing in the discrete time domain without any loss of information. However, in an increasing number of applications, the Shannon-Nyquist sampling theorem dictates an unnecessary and often prohibitively high sampling rate (see ""What Is the Nyquist Rate of a Video Signal?""). As a motivating example, the high resolution of the image sensor hardware in modern cameras reflects the large amount of data sensed to capture an image. A 10-megapixel camera, in effect, takes 10 million measurements of the scene. Yet, almost immediately after acquisition, redundancies in the image are exploited to compress the acquired data significantly, often at compression ratios of 100:1 for visualization and even higher for detection and classification tasks. This example suggests immense wastage in the overall design of conventional cameras.","Sensors,
Streaming media,
Spatial resolution,
Cameras,
Bandwidth,
Compression algorithms"
Direction-Aware Why-Not Spatial Keyword Top-k Queries,"With the continued proliferation of location-based services, a growing number of web-accessible data objects are geotagged and have text descriptions. An important query over such web objects is the direction-aware spatial keyword query that aims to retrieve the top-k objects that best match query parameters in terms of spatial distance and textual similarity in a given query direction. In some cases, it can be difficult for users to specify appropriate query parameters. After getting a query result, users may find some desired objects are unexpectedly missing and may therefore question the entire result. Enabling why-not questions in this setting may aid users to retrieve better results, thus improving the overall utility of the query functionality. This paper studies the direction-aware why-not spatial keyword top-k query problem. We propose efficient query refinement techniques to revive missing objects by minimally modifying users' directionaware queries. Experimental studies demonstrate the efficiency and effectiveness of the proposed techniques.","Search problems,
Legged locomotion,
Computer science,
Spatial databases,
Computational modeling,
Q measurement,
Computer aided software engineering"
An HLA-Based Distributed Cosimulation Framework in Mixed-Signal System-on-Chip Design,"In mixed-signal system-on-chip (SoC) design, distributed cosimulation is one of the practical approaches for unifying various abstracted hardware models using different description languages. Conventional ad hoc distributed cosimulation solutions do not have formal theoretical backgrounds of simulator integration into their solutions. In this brief, we propose a general cosimulation framework based on the high-level architecture (HLA) and newly defined programming language interface for interoperation (PLI-I) as a formal simulator interface. Based on the PLI-I and HLA, we propose formal integration and interoperation procedures. To reduce integration costs, the procedures have been developed into a common library and then merged with model-dependent signal-event converter to handle differently abstracted in/out signals. During the interoperation, to resolve the different time-advance mechanisms of the digital and analog simulators, the adapter executes an advanced HLA-based synchronization based on the presimulation concepts. The case study shows the reduced design effort in integrating and validating the heterogeneous models and simulators using the proposed framework in mixed-signal SoC design.",
Sudden Power-Outage Resilient In-Processor Checkpointing for Energy-Harvesting Nonvolatile Processors,"This paper introduces a sudden power-outage resilient in-processor checkpointing for energy-harvesting nonvolatile processors. In energy harvesting applications, a power supply generated from a renewable power source is unstable that may induce frequent sudden power outages, causing the inconsistency among distributed nonvolatile flip-flops (NVFFs) and hence failure rollbacks in conventional nonvolatile processors. To realize continuous operations upon the frequent sudden power outages, the proposed in-processor checkpointing technique fixes the inconsistency using time-reminding redundant NVFFs (TM-RNVFFs). The TM-RNVFFs store the current and the past few data with the timing information of storing. If several NVFFs fail to store the current data due to the sudden power outages, the proposed in-processor checkpointing technique exploits the timing information to find the common newest state among distributed NVFFs, leading to correct rollbacks to the state with consistency. The sudden power-outage effect is modeled to perform design space explorations at different configurations, such as redundancy and checkpointing period. Nonvolatile ARM Cortex-M0 processors are designed using hybrid 90 nm CMOS and 70 nm magnetic tunnel junction (MTJ) technologies. Based on the design space explorations, the proposed nonvolatile processor achieves a several order-of magnitude reduction in rollback error probability with a power dissipation overhead of 11.6 percent and an area overhead of 52.1 percent in comparison with the conventional nonvolatile processor.","Program processors,
Power system faults,
Power system restoration,
Nonvolatile memory,
Checkpointing,
Timing,
Distributed databases"
Least Power Point Tracking Method for Photovoltaic Differential Power Processing Systems,"Differential power processing (DPP) systems are a promising architecture for future photovoltaic (PV) power systems that achieve high system efficiency through processing a faction of the full PV power, while achieving distributed local maximum power point tracking (MPPT). In the PV-to-bus DPP architecture, the power processed through the DPP converters depends on the string current, which must be controlled to minimize the power processed through the DPP converters. A real-time least power point tracking (LPPT) method is proposed to minimize power stress on PV DPP converters. Mathematical analysis shows the uniqueness of the least power point for the total power processed through the system. The perturb-and-observe LPPT method is presented that enables the DPP converters to maintain optimal operating conditions, while reducing the total power loss and converter stress. This work validates through simulation and experimentation that LPPT in the string-level converter successfully operates with MPPT in the DPP converters to maximize output power for the PV-to-bus architecture. Hardware prototypes were developed and tested at 140 and 300 W, and the LPPT control algorithm showed effective operation under steady-state operation and an irradiance step change. Peak system efficiency achieved with a 140-W prototype DPP system employing LPPT is 95.7%.","Maximum power point trackers,
Computer architecture,
Process control,
Topology,
Microwave integrated circuits,
Bidirectional control,
Photovoltaic systems"
Design-Space Exploration and Optimization of an Energy-Efficient and Reliable 3-D Small-World Network-on-Chip,"A 3-D network-on-chip (NoC) enables the design of high performance and low power many-core chips. Existing 3-D NoCs are inadequate for meeting the ever-increasing performance requirements of many-core processors since they are simple extensions of regular 2-D architectures and they do not fully exploit the advantages provided by 3-D integration. Moreover, the anticipated performance gain of a 3-D NoC-enabled many-core chip may be compromised due to the potential failures of through-silicon-vias that are predominantly used as vertical interconnects in a 3-D IC. To address these problems, we propose a machine-learning-inspired predictive design methodology for energy-efficient and reliable many-core architectures enabled by 3-D integration. We demonstrate that a small-world network-based 3-D NoC (3-D SWNoC) performs significantly better than its 3-D MESH-based counterparts. On average, the 3-D SWNoC shows 35% energy-delay-product improvement over 3-D MESH for the PARSEC and SPLASH2 benchmarks considered in this paper. To improve the reliability of 3-D NoC, we propose a computationally efficient spare-vertical link (sVL) allocation algorithm based on a state-space search formulation. Our results show that the proposed sVL allocation algorithm can significantly improve the reliability as well as the lifetime of 3-D SWNoC.","Three-dimensional displays,
Through-silicon vias,
Computer architecture,
Reliability,
Resource management,
Algorithm design and analysis"
A Novel Cluster Head Selection Algorithm Based on Fuzzy Clustering and Particle Swarm Optimization,"An important objective of wireless sensor network is to prolong the network life cycle, and topology control is of great significance for extending the network life cycle. Based on previous work, for cluster head selection in hierarchical topology control, we propose a solution based on fuzzy clustering preprocessing and particle swarm optimization. More specifically, first, fuzzy clustering algorithm is used to initial clustering for sensor nodes according to geographical locations, where a sensor node belongs to a cluster with a determined probability, and the number of initial clusters is analyzed and discussed. Furthermore, the fitness function is designed considering both the energy consumption and distance factors of wireless sensor network. Finally, the cluster head nodes in hierarchical topology are determined based on the improved particle swarm optimization. Experimental results show that, compared with traditional methods, the proposed method achieved the purpose of reducing the mortality rate of nodes and extending the network life cycle.","Clustering algorithms,
Wireless sensor networks,
Topology,
Energy consumption,
Network topology,
Mathematical model,
Base stations"
Finite-Control Set Model Predictive Control Method for Torque Control of Induction Motors Using a State Tracking Cost Index,"This paper presents a novel torque control method for two-level-inverter-fed induction motor drives. The control principle is based on a finite-control set model predictive control (FCS-MPC) using a state tracking cost index. In the online procedure of the proposed FCS-MPC, the optimal voltage vector and its corresponding optimal modulation factor are determined based on the principle of torque and rotor flux error minimization. In this method, a reference state is determined in a systematic way so that the reference torque tracking with maximum torque per ampere and flux-limited operation could be achieved. In addition, a weighting matrix for the state tracking error is optimized in offline using the linear matrix inequality based optimization problem. The efficacy of the proposed FCS-MPC method is proved by the simulation and experimental results at different working circumstances. The comparison of the presented control system with the conventional FCS-MPC and with other reported FCS-MPC with modulation control is made. The proposed algorithm yields fast dynamic performance and minimum torque and current ripples at different speed and torque levels.","Torque,
Rotors,
Stators,
Torque control,
Indexes,
Modulation,
Voltage control"
Ghost Imaging for a Reflected Object with Large Incident Angles,"We investigate the effects from large incident angles on imaging resolution, and firstly give the expression of PSF of RGI. It is shown that for direct imaging, not enough details of a reflected object can be obtained when the incident angle increases to a critical value. While RGI can reconstruct the image with good resolution. In addition, we experimentally demonstrate the influence of the transverse size of the test detector on RGI, and the result is quite different from that in TGI.","Imaging,
Detectors,
Image resolution,
Correlation,
Photonics,
Image reconstruction,
Light sources"
Searching Genome-Wide Multi-Locus Associations for Multiple Diseases Based on Bayesian Inference,"Taking the advantage of high-throughput single nucleotide polymorphism (SNP) genotyping technology, large genome-wide association studies (GWASs) have been considered to hold promise for unraveling complex relationships between genotypes and phenotypes. Current multi-locus-based methods are insufficient to detect interactions with diverse genetic effects on multifarious diseases. Also, statistic tests for high-order epistasis (
≥2
SNPs) raise huge computational and analytical challenges because the computation increases exponentially as the growth of the cardinality of SNPs combinations. In this paper, we provide a simple, fast and powerful method, named DAM, using Bayesian inference to detect genome-wide multi-locus epistatic interactions in multiple diseases. Experimental results on simulated data demonstrate that our method is powerful and efficient. We also apply DAM on two GWAS datasets from WTCCC, i.e., Rheumatoid Arthritis and Type 1 Diabetes, and identify some novel findings. Therefore, we believe that our method is suitable and efficient for the full-scale analysis of multi-disease-related interactions in GWASs.","Diseases,
Genomics,
Bioinformatics,
Bayes methods,
Computational modeling,
Diabetes"
Characterization and Modeling of 10-kV Silicon Carbide Modules for Naval Applications,"This paper presents a detailed characterization and modeling effort applied to a set of 10-kV SiC MOSFET modules, which have not been exhaustively described in the literature to date. This paper builds on a previous effort by the authors, in which an empirical performance evaluation was performed using a reduced-scale variant of the medium-voltage direct current (MVDC)-rated SiC MOSFET module. In this paper, full-scale module samples are used, which are capable of continuous operation at 120 A. Thus, the evaluation provided here offers improved relevance to the category of full-scale MVDC applications of which future naval shipboard power systems are expected to be a part. The evaluation effort described here considers both the static and dynamic performances of the considered 10-kV SiC MOSFET module, along with the identification of integration considerations that will be of use to designers of future applications based on this technology. Specific contributions of this paper that belong to this category include the presentation of a custom gate-drive circuit designed to operate the modules under consideration and the presentation of a detailed behavioral simulation model created to predict the performance of the same. The output of this model is compared with experimental waveforms captured during pulsed switching experiments at a bus voltage of 2 kV and a load current of 100 A. The simulation output is demonstrated to offer good agreement with the experimental waveforms during both turn-on and turn-off transitions. The availability of such a model is important because it makes possible the execution of a wide range of feasibility and trade studies for future applications by researchers without physical access to this technology.","Silicon carbide,
MOSFET,
Integrated circuit modeling,
Marine vehicles,
Semiconductor device modeling,
Performance evaluation,
Power systems"
Synchronized Laser Chaos Communication: Statistical Investigation of an Experimental System,"The paper is concerned with analyzing data from an experimental antipodal laser-based chaos shift-keying communication system. Binary messages are embedded in a chaotically behaving laser wave, which is transmitted through a fiber-optic cable and are decoded at the receiver using a second laser synchronized with the emitter laser. Instrumentation in the experimental system makes it particularly interesting to be able to empirically analyze both optical noise and synchronization error as well as bit error rate. Both the noise and error are found to significantly depart in distribution from independent Gaussian. The conclusion from bit error rate results is that the antipodal laser chaos shift-keying system can offer a feasible approach to optical communication. The non-Gaussian optical noise and synchronous error results are a challenge to current theoretical modeling.","Synchronization,
Chaos,
Optical fiber amplifiers,
Semiconductor lasers,
Optical attenuators,
Optical fiber communication"
Robust Large-Scale Spectrum Auctions against False-Name Bids,"Auction is a promising approach for dynamic spectrum access in cognitive radio networks. Existing auction mechanisms are mainly strategy-proof to stimulate bidders to reveal their valuations of spectrum truthfully. However, they can suffer significantly from a new cheating pattern, named false-name bids, where a bidder can manipulate the auction by submitting bids under multiple fictitious names. We show such false-name bid cheating is easy to make but difficult to detect in dynamic spectrum auctions. To address this issue, we propose ALETHEIA, a novel flexible, false-name-proof auction framework for large-scale dynamic spectrum access. ALETHEIA not only guarantees strategy-proofness but also resists false-name bids. Moreover, ALETHEIA enables spectrum reuse across a large number of bidders, to improve spectrum utilization. Following that, we extend ALETHEIA to its general version that supports more practical and flexible auction, where bidders accept the spectrum allocation under their partial satisfactions. Theoretical analysis and simulation results show that ALETHEIA achieves both high spectrum redistribution efficiency and auction efficiency.","Cost accounting,
Resource management,
Cognitive radio,
Radio frequency,
Mobile computing,
Dynamic spectrum access,
Electronic mail"
"Optically Upconverted, Spatially Coherent Phased-Array-Antenna Feed Networks for Beam-Space MIMO in 5G Cellular Communications","The densification of cellular networks and their soon-to-increase operational frequency is forcing new topological considerations in 5G networks. In particular, networks that enable extreme spatial discrimination are being considered as a means to significantly increase data capacity by realizing spatial-spectral channels that offer frequency reuse without co-channel or adjacent-channel interference. In this paper, we present a new approach to realizing such a capability based on optically upconverted, spatially coherent phased-array feed networks. The details of our approach, presented herein, include the design and initial demonstration of both transmit (Tx) and receive (Rx) array systems that are used in tandem to form a down-/up-link for the purpose of characterizing both array and link performance. Design parameters and initial link characterization results are presented.",
Scalable Anti-Censorship Framework Using Moving Target Defense for Web Servers,"Although the Internet has become a hub around which every aspect of our lives-from commerce to leisurely activities-is centered, many around the world are not able to freely access information over the Internet. Some governments censor what the people can and cannot see. In this paper, regardless of the socio-political view points, we focus on the design of anti-censorship technology that can be implemented on the side of the information purveyors. The primary objective is to develop a framework for combating censorship. Our approach aims to make it too expensive and impractical for the adversary to censor Web sites. In particular, we propose the use of Mobile IPv6 to form a moving target defense strategy, where the Web servers logically behave as if they are the mobile nodes (without actually moving). The potential efficacy of this framework is modeled analytically. Probabilistic models are used to derive important metrics and parameters. One key factor termed swarming ratio enables hosting sites to reason about the amount of resources needed to force the adversary's costs over practical limits. This model is used to guide the performance goals and architectural setup of the prototype implementation (modifications are made on the server-side software and Kernel without changing the standard Mobile IPv6 protocol). Hence, the solution can be utilized without any changes to the existing network infrastructure. Furthermore, we introduce a novel, credit-based accounting strategy for grouping of users to drastically shift resource requirements in our favor. Lab-based tests are used to measure performance overheads, and based on the findings, targeted optimizations are performed to consider practical deployment scenarios. The end result is a solution that may also be combined with existing anti-censorship methods (that are end-user-based and/or assisted by friendly network assets) to form a robust anti-censorship solution.","Censorship,
IP networks,
Computer crime,
Routing,
Web servers"
Provably Secure Key-Aggregate Cryptosystems with Broadcast Aggregate Keys for Online Data Sharing on the Cloud,"Online data sharing for increased productivity and efficiency is one of the primary requirements today for any organization. The advent of cloud computing has pushed the limits of sharing across geographical boundaries, and has enabled a multitude of users to contribute and collaborate on shared data. However, protecting online data is critical to the success of the cloud, which leads to the requirement of efficient and secure cryptographic schemes for the same. Data owners would ideally want to store their data/files online in an encrypted manner, and delegate decryption rights for some of these to users, while retaining the power to revoke access at any point of time. An efficient solution in this regard would be one that allows users to decrypt multiple classes of data using a single key of constant size that can be efficiently broadcast to multiple users. Chu et al. proposed a key aggregate cryptosystem (KAC) in 2014 to address this problem, albeit without formal proofs of security. In this paper, we propose CPA and CCA secure KAC constructions that are efficiently implementable using elliptic curves and are suitable for implementation on cloud based data sharing environments. We lay special focus on how the standalone KAC scheme can be efficiently combined with broadcast encryption to cater to m data users and m' data owners while reducing the reducing the secure channel requirement from O(mm') in the standalone case to O(m + m').",
Resource Usage Prediction Models for Optimal Multimedia Content Provision,"This paper proposes a network architecture that utilizes novel resource prediction models for optimal selection of multimedia content provision methods. The proposed research approach is based on a prototype system, which exploits a resource prediction engine (RPE), utilizing time series and epidemic spread models, for optimal and balanced distribution of the streaming data among content delivery networks, cloud-based providers and home media gateways. The proposed epidemic diseases models adopt the characteristics of the multimedia content delivery over the network architecture. In this context, this paper aims to present the advantages of using such models, by presenting and analyzing an epidemic spread scheme for video-on-demand (VoD) delivery, to predict future epidemic spread behavior. In addition, this paper presents two algorithms, adopted in the prototype network architecture, for optimal selection of multimedia content delivery methods, as well as balanced delivery load, by exploiting the RPE. Both algorithms and models are evaluated to establish their efficiency, toward effectively predicting future network traffic demands. The simulation results verify the validity of the proposed approach, identifying fields for future research and experimentation.","Predictive models,
Multimedia communication,
Hidden Markov models,
Streaming media,
Mathematical model,
Computational modeling"
Video-Based Pedestrian Re-Identification by Adaptive Spatio-Temporal Appearance Model,"Pedestrian re-identification is a difficult problem due to the large variations in a person's appearance caused by different poses and viewpoints, illumination changes, and occlusions. Spatial alignment is commonly used to address these issues by treating the appearance of different body parts independently. However, a body part can also appear differently during different phases of an action. In this paper, we consider the temporal alignment problem, in addition to the spatial one, and propose a new approach that takes the video of a walking person as input and builds a spatiotemporal appearance representation for pedestrian re-identification. Particularly, given a video sequence, we exploit the periodicity exhibited by a walking person to generate a spatiotemporal body-action model, which consists of a series of body-action units corresponding to certain action primitives of certain body parts. Fisher vectors are learned and extracted from individual body-action units and concatenated into the final representation of the walking person. Unlike previous spatiotemporal features that only take into account local dynamic appearance information, our representation aligns the spatiotemporal appearance of a pedestrian globally. Extensive experiments on public data sets show the effectiveness of our approach compared with the state of the art.",
HVDC converter transformer saturation in hybrid AC/DC system caused by coupled transmission lines,"Hybrid ac/dc transmission can increase the power transfer capability of long ac transmission lines. High voltage dc (HVDC) converters are needed, and the line-commutated converter (LCC) is used considering the dc fault current controllability. However, zero-sequence current can be generated due to the coupled transmission lines, and it will flow into the HVDC converters as a fundamental frequency current component on dc side (i60). The LCC will convert i60 to dc current components on the ac side, which may cause potential converter transformer saturation. This paper analyzes the influence of coupled transmission lines on i60 and the converter transformer saturation and proposes two possible solutions to avoid converter transformer saturation. The simulation results verify the effectiveness of the proposed methods.","Power transmission lines,
HVDC transmission,
Circuit faults,
Capacitors,
Impedance,
Windings,
Hybrid power systems"
A probabilistic process learning approach for service composition in cloud networks,We present a formal probabilistic framework for process learning to compose service specific overlays (SSO) in cloud networks. The approach provides a learning mechanism that relies on previous composition results to build service composition process models that can be adopted for future composition requests. The process is then translated into a workflow-net to provide guaranteed delivery of requested cloud media services to clients. A mathematical merge technique is also presented to converge multiple process threads into a single composed process. We provide simulation results to show that our approach can adequately establish sound composition paths in a timely manner.,
Robust Voltage Instability Predictor,This letter presents a robust voltage instability predictor using local noisy PMU measurements. A robust recursive least squares estimation is proposed to mitigate the impacts of gross PMU measurement errors on estimating the bus impedance and the Thevenin equivalent impedance used for voltage stability analysis. Numerical results on the IEEE 39-bus system validate the effectiveness and robustness of the proposed method.,"Voltage measurement,
Robustness,
Phasor measurement units,
Power system stability,
Impedance,
Stability analysis,
Noise measurement"
Online Inter-Datacenter Service Migrations,"Service migration between datacenters can reduce the network overhead within a cloud infrastructure; thereby, also improving the quality of service for the clients. Most of the algorithms in the literature assume that the client access pattern remains stable for a sufficiently long period so as to amortize such migrations. However, if such an assumption does not hold, these algorithms can take arbitrarily poor migration decisions that can substantially degrade system performance. In this paper, we approach the issue of performing service migrations for an unknown and dynamically changing client access pattern. We propose an online algorithm that minimizes the inter-datacenter network, taking into account the network load of migrating a service between two datacenters, as well as the fact that the client request pattern may change “quickly”, before such a migration is amortized. We provide a rigorous mathematical proof showing that the algorithm is 3.8-competitive for a cloud network structured as a tree of multiple datacenters. We briefly discuss how the algorithm can be modified to work on general graph networks with an O(log|V|) probabilistic approximation of the optimal algorithm. Finally, we present an experimental evaluation of the algorithm based on extensive simulations.","Cloud computing,
Approximation algorithms,
Delays,
Context,
Wireless sensor networks,
Linear programming,
Data transfer"
Integrated HIFU Drive System on a Chip for CMUT-Based Catheter Ablation System,"Conventional High Intensity Focused Ultrasound (HIFU) is a therapeutic modality which is extracorporeally administered. In applications where a relatively small HIFU lesion is required, an intravascular HIFU probe can be deployed to the ablation site. In this paper, we demonstrate the design and implementation a fully integrated HIFU drive system on a chip to be placed on a 6 Fr catheter probe. An 8-element capacitive micromachined ultrasound transducer (CMUT) ring array of 2 mm diameter has been used as the ultrasound source. The driver chip is fabricated in 0.35
μ
m AMS high-voltage CMOS technology and comprises eight continuous-wave (CW) high-voltage CMUT drivers (10.9 ns and 9.4 ns rise and fall times at 20 V
pp
output into a 15 pF), an eight-channel digital beamformer (8–12 MHz output frequency with 11.25
∘
phase accuracy) and a phase locked loop with an integrated VCO as a tunable clock source (128–192 MHz). The chip occupies 1.85
×
1.8 mm
2
area including input and output (I/O) pads. When the transducer array is immersed in sunflower oil and driven by the IC with eight 20
V
pp
CW pulses at 10 MHz, real-time thermal images of the HIFU beam indicate that the focal temperature rises by 16.8 
∘
C in 11 seconds. Each HV driver consumes around 67 mW of power when driving the CMUT array at 10 MHz, which adds up to 560 mW for the whole chip. FEM based analysis reveals that the outer surface temperature of the catheter is expected to remain below the 42 
∘
C tissue damage limit during therapy.","Catheters,
Transducers,
Ultrasonic imaging,
Probes,
Acoustics,
Integrated circuits,
Phase locked loops"
A dependability analysis model in the context of Cyber-Physical Systems,"Cyber-Physical Systems (CPSs) represent a new generation of engineered systems facing significant scientific challenges in terms of modeling, architecture, distributed computations and network control, verification/validation mechanisms, and many others. CPSs modeling, a significant aspect of their design and development, can be performed using the Model-Driven Engineering (MDE) paradigm. This approach implies that a model of the CPS under study has to be developed, and that this model is finally transformed into reality. It contains several sub-models corresponding to the main features of the CPS. One of those addresses CPS dependability, a characteristic that integrates availability, reliability, safety, integrity, and maintainability properties in order to provide services that can be trusted within a specific time-period. The work presented in this paper discusses a dependability model achieved through the knowledge representation of the related domain. A pilot test was carried out to evaluate and to demonstrate the applicability of the proposed approach.","Unified modeling language,
Sensors,
Ontologies,
Computational modeling,
Actuators,
Analytical models,
Software"
Sensitivity Map Analysis of Adaptive Electrical Capacitance Volume Tomography Using Nonuniform Voltage Excitation Envelopes,"Electrical capacitance tomography (ECT) is a low-cost high-speed imaging technique, which can be applied in many fields. ECT is predicted by the data of the sensitivity map to reconstruct an image of the interested field. Thus, the resolution of the predicted image is highly dependent on the computation of the sensitivity map. In this paper, we compared the differences of sensitivity maps between electrical capacitance volume tomography (ECVT) system and adaptive electrical capacitance tomography (AECVT) system. The experiment sensors used for comparison were of the same size yet different plates, namely, conventional and synthetic. The synthetic plates were excited by different voltage envelopes, while the conventional ones could only be excited by single voltage at the same time. Then, the voltage distributions and the sensitivity maps of both systems were analyzed in both horizontal and vertical directions, respectively. The results had shown that AECVT system was similar to ECVT system with single voltage excitation yet it offered multiple distributions in cross sections, which could improve the lateral resolution while reducing the sensitivity in the vertical direction with multiple voltages excitation.","Sensitivity,
Capacitance,
Capacitive sensors,
Electrodes,
Image sensors"
Semi-Online Algorithms for Computational Task Offloading with Communication Delay,"We study the scheduling of computational tasks on one local processor and one remote processor with communication delay. This problem has important application in cloud computing. Although the communication time to transmit a task can be inferred from the known data size of the task and the transmission bandwidth, the processing time of the task is generally unknown until it is processed to completion. Given a set of independent tasks with unknown processing times, our objective is to minimize makespan. We study the problem under two scenarios: (1) the communication times of the tasks to the remote processor are smaller than their corresponding processing times on the remote processor, and (2) the communication times of the tasks to the remote processor are larger than their corresponding processing times on the remote processor. For the first scenario we propose the Semi-online Partitioning and Communication (SPaC) algorithm, and for the second scenario we propose the SPaC-Restart (SPaC-R) algorithm. Even though the offline version of this problem, with a priori known processing times, is NP-hard, we show that the proposed semionline algorithms achieve O(1) competitive ratios for their intended scenarios. We also provide competitive ratios for both algorithms for more general communication times. We use simulation to demonstrate that SPaC and SPaC-R outperform online list scheduling and performs comparably well with the best known offline heuristics.","Delays,
Processor scheduling,
Cloud computing,
Scheduling,
Computational modeling,
Optimal scheduling,
Partitioning algorithms"
Comparative analysis of air-gap PD characteristics: Vegetable oil/pressboard and mineral oil/pressboard,"Partial Discharge (PD) is considered to be one of the main reasons for aging and degradation of the oil/pressboard insulation system in power transformers. Vegetable oils which own excellent dielectric performance are introduced as potential insulation liquids substituting traditional mineral oil. In this paper, an air-gap PD model was adopted to investigate the PD characteristics of refined rapeseed oil and Karamay 25# mineral oil that are both currently employed in liquid filled power transformers. The PD current pulse waveform analysis (PD-CPWA) method was used to investigate PD mechanisms of two different insulation systems: mineral oil/pressboard and vegetable oil/pressboard. For both insulation systems, phase resolved partial discharge (PRPD) patterns throughout the accelerated deterioration experiments were compared. The extracted φ-q-n plots with respect to various PD times were analyzed. It is found that, the air-gap PD stage characteristics of vegetable oil/pressboard are more notable. It has fewer double-peak pulses, smaller inception phase angle, lower charge amplitude, higher repetition rate, and more remarkable `rabbit-ear' patterns than mineral oil/pressboard. The PD development process of both insulation systems can be characterized by four stages: initial discharge stage, weak developing stage, discharge burst stage and pre-breakdown stage.","Partial discharges,
Vegetable oils,
Insulation,
Air gaps,
Minerals,
Power transformer insulation"
Analysis of Short-Channel Effects in Junctionless DG MOSFETs,This brief investigates short-channel effects (SCEs) in junctionless (JL) double-gate (DG) MOSFETs analytically by solving the 2-D potential in subthreshold. Ids-Vg curves and Vt rolloff generated from the model are validated by 2-D numerical simulations (Technology Computer Aided Design). It is shown that the SCE of JL MOSFETs is inherently worse than that of undoped DG MOSFETs. The SCE worsens with increasing doping concentration in the channel.,"MOSFET,
Doping,
Semiconductor device modeling,
Logic gates,
Analytical models,
Silicon,
Electric potential"
Fuzzy Color Spaces: A Conceptual Approach to Color Vision,"In this paper, we introduce formal definitions of the concepts of fuzzy color and fuzzy color space. First, we formalize the notion of fuzzy color for representing the correspondence between computational representation of colors and perceptual color categories identified by a color name. Second, we propose a methodology for learning fuzzy colors based on the paradigm of conceptual spaces, where prototypes are used for each category to be learnt. Since the conceptual space approach yields crisp categorizations, we introduce a novel methodology for defining fuzzy boundaries of color categories on the basis of a Voronoi tessellation of a color space. Finally, we also formalize the notion of fuzzy color space as the collection of fuzzy colors corresponding to the color categories employed in a certain context/application and/or for a specific user. Different typologies of fuzzy color spaces are proposed in order to be consistent with the nature of the categories we want to model. Our approach is illustrated by defining fuzzy color spaces using RGB with the Euclidean distance. Examples based on the well-known ISCC-NBS color naming system are presented, as well as others based on collections of color names and prototypes provided by users. The proposal is evaluated and compared with the most used approaches for color modeling. Additionally, a website located at http://www.jfcssoftware.com including all experimentation data, software implementing our models, and additional materials is available to researchers in color modeling.","Image color analysis,
Color,
Prototypes,
Computational modeling,
Pragmatics,
Semantics,
Proposals"
Training Engineers for the Ambient Intelligence Challenge,"The increasing complexity of the new breed of distributed intelligent systems, such as the Internet of Things, which require a diversity of languages and protocols, can only be tamed with design and programming best practices. Interest is also growing for including the human factor, as advocated by the ambient intelligence (AmI) research field, whose focus is on transparently and intelligently supporting people. These new design methodologies are increasingly needed in the toolbox of new electronic and computer engineers, and teaching strategies should be devised that allow students to acquire a systems-level view instead of getting lost in technology-oriented approaches. This paper describes a study carried out over two academic years, in a course in AmI at Politecnico di Torino, Italy. In the course, a project-based learning approach was adopted, in which students design and prototype an AmI system, and their progress is closely monitored throughout the semester. This paper presents the learning goals and teaching strategies, analyzes the learning outcomes from the qualitative and quantitative points of view, and highlights the lessons learned in the process.","Internet of things,
Education,
Protocols,
Computers,
Knowledge engineering,
Prototypes,
Ambient intelligence"
Real time Hand Gesture Recognition using different algorithms based on American Sign Language,"Human Computer Interaction (HCI) is a broad research field based on human interaction with computers or machines. Basically, Hand Gesture Recognition (HGR) is a subfield of HCI. Today, many researchers are working on different HGR applications like game controlling, robot control, smart home system, medical services etc. The purpose of this paper is to represent a real time HGR system based on American Sign Language (ASL) recognition with greater accuracy. This system acquires gesture images of ASL with black background from mobile video camera for feature extraction. In the processing phase, the system extracts five features such as fingertip finder, eccentricity, elongatedness, pixel segmentation and rotation. For feature extraction, a new algorithm is proposed which basically combines K curvature and convex hull algorithms. It can be called “K convex hull” method which can detect fingertip with high accuracy. In our system, Artificial Neural Network (ANN) is used with feed forward, back propagation algorithm for training a network using 30 feature vectors to recognize 37 signs of American alphabets and numbers properly which is helpful for HCI system. The total gesture recognition rate of this system is 94.32% in real time environment.","Feature extraction,
Gesture recognition,
Assistive technology,
Image segmentation,
Shape,
Real-time systems,
Cameras"
Sidelobe Suppression and Beam Collimation in the Generation of Vortex Electromagnetic Waves for Radar Imaging,"For the electromagnetic (EM) vortex imaging purposes, the sidelobe suppression and the beam collimation method in the generation of orbital angular momentum (OAM) beams is proposed. Based on the concentric ring array, the objective function for the generic algorithm is defined to calculate the signal amplitude for each ring. Comprehensive simulations are conducted to validate the effectiveness of the proposed method. Results show that the main lobes of the radiation pattern of different OAM modes are collimated in the same direction and the sidelobes are all lower than -20 dB. Furthermore, the imaging model of the concentric-ring array is established, and the target image is obtained through numerical simulations. The work can advance the development of the EM vortex imaging technique and novel radar detection technology as well.","Imaging,
Radar imaging,
Antenna radiation patterns,
Beams,
Brain modeling,
Electromagnetics,
Electromagnetic scattering"
A Memory-Based FFT Processor Design With Generalized Efficient Conflict-Free Address Schemes,"This paper presents the design and implementation of memory-based fast Fourier transform (FFT) processors with generalized efficient, conflict-free address schemes. We unified the conflict-free address schemes of three different FFT lengths, including the single-power points, the common nonsingle-power points, and the nonsingle-power points applied with a prime factor algorithm. Though the three cases differ in terms of decomposition, they are all compatible with memory-based architecture by the way of the proposed address schemes. Moreover, the decomposition algorithm utilizes a method, named high-radix–small-butterfly (HRSB), to decrease the computation cycles and eliminate the complexity of the processing engine. In addition, an efficient index generator, a simplified multipath delay commutator engine, and a unified Winograd Fourier transform algorithm butterfly core were also designed. We designed two FFT examples in long-term evolution system to verify the availability of the address scheme, including a 2n (128–2048)-point FFT unit and a 35 different point (12–1296) DFT unit. Compared with previous works with similar address schemes, this paper supports more generalized lengths and achieves more flexible throughput.","Indexes,
Signal processing algorithms,
Discrete Fourier transforms,
Computer architecture,
Algorithm design and analysis,
Throughput,
Engines"
Circularly Polarized Substrate Integrated Waveguide Antenna With Wide Axial-Ratio Beamwidth,"A circularly polarized (CP) substrate integrated waveguide (SIW) antenna is presented. First, our study demonstrates that wide axial-ratio beamwidth can be achieved by exciting a square slot with four pins. Second, gap rings are employed around the pins to control the resonant frequency of the antenna. After the variation of thee diameters of gap rings, the frequency of best impedance match corresponds to that of the widest axial-ratio beamwidth. Finally, a CP antenna is designed and fabricated. Experimental results are found in good agreement with simulations in terms of radiation patterns, gain, axial ratio, and reflection coefficient. In particular, the 3-dB axial-ratio beamwidth at the center frequency of 7.98 GHz is extended to 150°.","Dipole antennas,
Antenna measurements,
Substrates,
Resonant frequency,
Impedance,
Antenna radiation patterns"
Stochastic Interchange Scheduling in the Real-Time Electricity Market,"The problem of inter-regional interchange scheduling in the presence of stochastic generation and load is considered. An interchange scheduling technique based on a two-stage stochastic minimization of expected operating cost is proposed. Because directly solving the stochastic optimization is intractable, an equivalent problem that maximizes the expected social welfare is formulated. The proposed technique leverages the operator's capability of forecasting locational marginal prices and obtains the optimal interchange schedule without iterations among operators. Several extensions of the proposed technique are also discussed.","Optimization,
Uncertainty,
Economics,
Stochastic processes,
Job shop scheduling,
Schedules,
ISO"
Compressed Sensing Based Synthetic Transmit Aperture Imaging: Validation in a Convex Array Configuration,"According to the linear acoustic theory, the channel data of a plane wave emitted by a linear array is a linear combination of the full dataset of synthetic transmit aperture (STA). Combining this relationship with compressed sensing (CS), a novel CS based ultrasound beamforming strategy, named compressed sensing based synthetic transmit aperture (CS-STA), was previously proposed to increase the frame rate of ultrasound imaging without sacrificing the image quality for a linear array. In this paper, assuming linear transfer function of pulse-echo ultrasound system, we derived and applied the theory of CS-STA for a slightly curved array and validated CS-STA in a convex array configuration. Computer simulations demonstrated that, in the convex array configuration, the normalized root-mean-square error (NRMSE) between the beamformed radio-frequency data of CS-STA and STA was smaller than 1% while CS-STA achieves 4-fold higher frame rate than STA. In addition, CS-STA was capable of achieving good image quality at depths over 100 mm. It was validated in phantom experiments by comparing CS-STA with STA, multi-element synthetic transmit aperture (ME-STA), and the conventional focused method (focal depth = 110 mm). The experimental results showed that STA and CS-STA performed qualitatively better than ME-STA and the focused method at small depths. At the depth of 110 mm, CS-STA, ME-STA, and the focused methods improved the contrast and contrast-to-noise ratio of STA. The improvements in CS-STA are higher than those in ME-STA but lower than those in the focused mode. These results can also be observed qualitatively in the in vivo experiments on the liver of a healthy male volunteer. The CS-STA method is thus proved to increase the frame rate and achieve high image quality at full depth in the convex array configuration.","Ultrasonic imaging,
Imaging,
Compressed sensing,
Arrays,
Apertures,
RF signals,
Image quality"
Using Multimodal Wearable Technology to Detect Conflict among Couples,"By monitoring human behavior unobtrusively, mobile sensing technologies have the potential to improve our daily lives. Initial results from a field study demonstrate that such passive technologies can detect a complex psychological state in an uncontrolled, real-life environment. In the web extra at https://youtu.be/n8Ap3Z44ojQ, guest editor Katarzyna Wac interviews authors Adela Timmons and Theodora Chaspari, quality-of-life technology researchers at the University of Southern California.","Biomedical monitoring,
Psychology,
Monitoring,
Sensors,
Electrocardiography,
Mobile communication,
Wearable computing,
Human factors,
Behavioral sciences"
Secrecy-Rate Analysis in Multitier Heterogeneous Networks Under Generalized Fading Model,"In this paper, the secrecy-rate characteristics of multitier downlink heterogeneous networks under generalized fading model is investigated for two types of base-station (BS)-user(s) association scenarios. Each tier within the network has a single multiantenna BS that intends to serve multiple single-antenna mobile users. These users are assumed to be distributed according to homogeneous Poisson point process (PPP) with particular density parameter. Single-antenna eavesdroppers which intend to wiretap the communication between the chosen BS and intended mobile user are also assumed to coexist within the network distributed as PPP with different intensity parameter. We have adopted the maximum received path gain, rather than distance, as a metric to describe the association scenario between a BS and typical user. Therefore, a typical user associates itself with: 1) a BS that provides the user with the maximum path gain or 2) any potential BS that provides the kth maximum path gain to the user. Using stochastic geometry as a tool, the received path gain distributions and the achievable average secrecy rate expressions from the perspective of association with the “best” and the kth best BS are analyzed analytically. Tractable numerical and simulation results are presented under various assumptions of fading scenario, path loss exponent, eavesdropper density, and antenna figures to support the lemmas and propositions stated within this paper.","Fading channels,
Mobile communication,
Internet of Things,
Heterogeneous networks,
Wireless networks,
Physical layer,
Analytical models"
Routing method with flow entry aggregation for software-defined networking,"In recent years, software-defined networking (SDN), which performs centralized network management with software, has attracted much attention. In SDN, the data plane is separated from the control plane. Network administrators can dynamically change the setting of the data plane and control routing on the control plane through a control protocol such as OpenFlow. Although packets are transmitted based on flow entries in the data plane, the number of flow entries that data plane can have is limited. It is difficult to perform flexible routing control with a small number of flow entries. To overcome this difficulty, this paper proposes a routing method that reduces the number of flow entries, while reducing the maximum link utilization. The proposed method allocates common paths to flows that can be aggregated, considering the utilization of the links. Through numerical experiments, this paper shows the effectiveness of the proposed method.","Switches,
Routing,
Receivers,
Ports (Computers),
Topology,
Aggregates"
Secure State Estimation for Cyber-Physical Systems Under Sensor Attacks: A Satisfiability Modulo Theory Approach,"Secure state estimation is the problem of estimating the state of a dynamical system from a set of noisy and adversarially corrupted measurements. Intrinsically a combinatorial problem, secure state estimation has been traditionally addressed either by brute force search, suffering from scalability issues, or via convex relaxations, using algorithms that can terminate in polynomial time but are not necessarily sound. In this paper, we present a novel algorithm that uses a satisfiability modulo theory approach to harness the complexity of secure state estimation. We leverage results from formal methods over real numbers to provide guarantees on the soundness and completeness of our algorithm. Moreover, we discuss its scalability properties, by providing upper bounds on the runtime performance. Numerical simulations support our arguments by showing an order of magnitude decrease in execution time with respect to alternative techniques. Finally, the effectiveness of the proposed algorithm is demonstrated by applying it to the problem of controlling an unmanned ground vehicle.","State estimation,
Semiconductor device measurement,
Process control,
Noise measurement,
Scalability,
Heuristic algorithms,
Upper bound"
Economic Analysis of Crowdsourced Wireless Community Networks,"Crowdsourced wireless community networks can effectively alleviate the limited coverage issue of Wi-Fi access points (APs), by encouraging individuals (users) to share their private residential Wi-Fi APs with others. In this paper, we provide a comprehensive economic analysis for such a crowdsourced network, with the particular focus on the users' behavior analysis and the community network operator's pricing design. Specifically, we formulate the interactions between the network operator and users as a two-layer Stackelberg model, where the operator determining the pricing scheme in Layer I, and then users determining their Wi-Fi sharing schemes in Layer II. First, we analyze the user behavior in Layer II via a two-stage membership selection and network access game, for both small-scale networks and large-scale networks. Then, we design a partial price differentiation scheme for the operator in Layer I, which generalizes both the complete price differentiation scheme and the single pricing scheme (i.e., no price differentiation). We show that the proposed partial pricing scheme can achieve a good tradeoff between the revenue and the implementation complexity. Numerical results demonstrate that when using the partial pricing scheme with only two prices, we can increase the operator's revenue up to 124.44 percent comparing with the single pricing scheme, and can achieve an average of 80 percent of the maximum operator revenue under the complete price differentiation scheme.","IEEE 802.11 Standard,
Pricing,
Wireless communication,
Mobile computing,
Economics,
Complexity theory,
Mobile communication"
Parallel autonomy in automated vehicles: Safe motion generation with minimal intervention,"Current state-of-the-art vehicle safety systems, such as assistive braking or automatic lane following, are still only able to help in relatively simple driving situations. We introduce a Parallel Autonomy shared-control framework that produces safe trajectories based on human inputs even in much more complex driving scenarios, such as those commonly encountered in an urban setting. We minimize the deviation from the human inputs while ensuring safety via a set of collision avoidance constraints. We develop a receding horizon planner formulated as a Non-linear Model Predictive Control (NMPC) including analytic descriptions of road boundaries, and the configurations and future uncertainties of other traffic participants, and directly supplying them to the optimizer without linearization. The NMPC operates over both steering and acceleration simultaneously. Furthermore, the proposed receding horizon planner also applies to fully autonomous vehicles. We validate the proposed approach through simulations in a wide variety of complex driving scenarios such as left-turns across traffic, passing on busy streets, and under dynamic constraints in sharp turns on a race track.","Vehicles,
Roads,
Optimization,
Safety,
Acceleration,
Trajectory,
Uncertainty"
Enhancing Network Robustness via Shielding,"We consider shielding critical links to enhance the robustness of a network, in which shielded links are resilient to failures. We first study the problem of increasing network connectivity by shielding links that belong to small cuts of a network, which improves the network reliability under random link failures. We then focus on the problem of shielding links to guarantee network connectivity under geographical and general failure models. We develop a mixed integer linear program (MILP) to obtain the minimum cost shielding to guarantee the connectivity of a single source-destination pair under a general failure model, and exploit geometric properties to decompose the shielding problem under a geographical failure model. We extend our MILP formulation to guarantee the connectivity of the entire network, and use Benders decomposition to significantly reduce the running time. We also apply simulated annealing to obtain near-optimal solutions in much shorter time. Finally, we extend the algorithms to guarantee partial network connectivity, and observe significant reduction in the shielding cost, especially when the geographical failure region is small.","Robustness,
Resists,
IEEE transactions,
Optical fiber networks,
Algorithm design and analysis,
Communication networks"
"Single-Event Effects in a Millimeter-Wave Receiver Front-End Implemented in 90 nm, 300 GHz SiGe HBT Technology","The single-event transient (SET) response of a W-band (75-110 GHz) radar receiver front-end is investigated in this paper. A new technique to facilitate the SET testing of the high frequency transceivers is proposed and demonstrated experimentally. The entire radar receiver front-end, including the high frequency signal sources and modulators, were designed and fully integrated in 90 nm 300 GHz SiGe process technology (Global Foundries SiGe 9HP). Two-photon absorption (TPA) laser pulses were utilized to induce transient currents in different devices in various circuit blocks. The study shows how short transient pulses from the high frequency tuned circuits are propagated throughout the receiver and are broadened while passing through low-pass filters present at supply nodes and the low-pass filter following the down-conversion mixer, thus affecting the digital data at the output of the receiver. The proposed methodology allows the study of the effect of SETs on the recovered digital data at the output of the high frequency receivers, thus allowing bit error rate calculations. Comprehensive device and circuit level simulations were also performed, and a close agreement between the measurement results and simulation data was demonstrated. To the authors' best knowledge, this is the first study of SET on full receiver at millimeter-wave (mmW) frequencies.","Receivers,
Transient analysis,
Silicon germanium,
Frequency modulation,
Integrated circuit modeling,
Radar"
SE3-nets: Learning rigid body motion using deep neural networks,"We introduce SE3-Nets which are deep neural networks designed to model and learn rigid body motion from raw point cloud data. Based only on sequences of depth images along with action vectors and point wise data associations, SE3-Nets learn to segment effected object parts and predict their motion resulting from the applied force. Rather than learning point wise flow vectors, SE3-Nets predict SE(3) transformations for different parts of the scene. Using simulated depth data of a table top scene and a robot manipulator, we show that the structure underlying SE3-Nets enables them to generate a far more consistent prediction of object motion than traditional flow based networks. Additional experiments with a depth camera observing a Baxter robot pushing objects on a table show that SE3-Nets also work well on real data.","Three-dimensional displays,
Transforms,
Predictive models,
Decoding,
Motion segmentation,
Dynamics"
Multicast-Aware High-Performance Wireless Network-on-Chip Architectures,"Today's multiprocessor platforms employ the network-on-chip (NoC) architecture as the preferable communication backbone. Conventional NoCs are designed predominantly for unicast data exchanges. In such NoCs, the multicast traffic is generally handled by converting each multicast message to multiple unicast transmissions. Hence, applications dominated by multicast traffic experience high queuing latencies and significant performance penalties when running on systems designed with unicast-based NoC architectures. Various multicast mechanisms such as XY-tree multicast and path multicast have already been proposed to enhance the performance of the traditional wireline mesh NoC incorporating multicast traffic. However, even with such added features, the multihop nature of the wireline mesh NoC leads to high network latencies and thus limits the achievable system performance. In this paper, to sustain the high-bandwidth and high-throughput requirements of emerging applications, we propose the design of a wireless NoC (WiNoC) architecture incorporating necessary multicast support. By integrating congestion-aware multicast routing with network coding, the WiNoC is able to efficiently handle heavy multicast injections. For applications running with a broadcast-heavy Hammer cache coherence protocol, the proposed multicast-aware WiNoC achieves an average of 47% reduction in message latency compared with the XY-tree-based multicast-aware mesh NoC. This network level improvement translates into a 26% saving in full-system energy delay product.","Protocols,
Wireless communication,
Coherence,
System-on-chip,
Unicast,
Delays,
System performance"
Structure-guided Protein Transition Modeling with a Probabilistic Roadmap Algorithm,"Proteins are macromolecules in perpetual motion, switching between structural states to modulate their function. A detailed characterization of the precise yet complex relationship between protein structure, dynamics, and function requires elucidating transitions between functionally-relevant states. Doing so challenges both wet and dry laboratories, as protein dynamics involves disparate temporal scales. In this paper we present a novel, sampling-based algorithm to compute transition paths. The algorithm exploits two main ideas. First, it leverages known structures to initialize its search and define a reduced conformation space for rapid sampling. This is key to address the insufficient sampling issue suffered by sampling-based algorithms. Second, the algorithm embeds samples in a nearest-neighbor graph where transition paths can be efficiently computed via queries. The algorithm adapts the probabilistic roadmap framework that is popular in robot motion planning. In addition to efficiently computing lowest-cost paths between any given structures, the algorithm allows investigating hypotheses regarding the order of experimentally-known structures in a transition event. This novel contribution is likely to open up new venues of research. Detailed analysis is presented on multiple-basin proteins of relevance to human disease. Multiscaling and the AMBER ff14SB force field are used to obtain energetically-credible paths at atomistic detail.","Proteins,
Heuristic algorithms,
Algorithm design and analysis,
Computational modeling,
Dynamics,
Robot motion"
Analysis and Experiments on a Single-Inductor Half-Bridge LED Driver With Magnetic Control,"This paper presents the analysis and experiments of a variable inductor (VI) based LED driver for dc grid lighting applications. The proposed driver requires only a series inductor and a transformer as major components to drive the LED lamp from a half-bridge inverter. By introducing a VI as the series inductor, the LED current can be controlled independently from any other parameter, which makes it possible to drive and regulate several LED branches from the same half-bridge output. Other advantages of the proposed converter include inherent open-circuit and short-circuit protections, zero-voltage switching for the bridge transistor and zero-current switching for the output rectifier diodes, simple dynamics, possibility of analog and pulse width modulation dimming, constant switching frequency operation, and high efficiency. The converter is thoroughly analyzed and modeled for both steady-state and dynamic operation. As another novelty of this paper, the dynamic response of the VI has been studied and taken into account to obtain the complete transfer function of the VI-controlled system. In addition, some housekeeping issues that usually arise when dealing with VI, e.g., how to drive the VI bias winding, are solved in this work. Experimental results provided from a 50 W laboratory prototype demonstrate the correctness of the performed analysis and the good possibilities of the proposed converter.","LED lamps,
Inductors,
Bridge circuits,
Rectifiers,
Capacitors"
Local Pattern Collocations Using Regional Co-occurrence Factorization,"Human vision benefits a lot from pattern collocations in visual activities such as object detection and recognition. Usually, pattern collocations display as the co-occurrences of visual primitives, e.g., colors, gradients, or textons, in neighboring regions. In the past two decades, many sophisticated local feature descriptors have been developed to describe visual primitives, and some of them even take into account the co-occurrence information for improving their discriminative power. However, most of these descriptors only consider feature co-occurrence within a very small neighborhood, e.g., 8-connected or 16-connected area, which would fall short in describing pattern collocations built up by feature co-occurrences in a wider neighborhood. In this paper, we propose to describe local pattern collocations by using a new and general regional co-occurrence approach. In this approach, an input image is first partitioned into a set of homogeneous superpixels. Then, features in each superpixel are extracted by a variety of local feature descriptors, based on which a number of patterns are computed. Finally, pattern co-occurrences within the superpixel and between the neighboring superpixels are calculated and factorized into a final descriptor for local pattern collocation. The proposed regional co-occurrence framework is extensively tested on a wide range of popular shape, color, and texture descriptors in terms of image and object categorizations. The experimental results have shown significant performance improvements by using the proposed framework over the existing popular descriptors.","Visualization,
Image color analysis,
Feature extraction,
Histograms,
Shape,
Image coding,
Pattern recognition"
Battlefield surveillance formalism using WSANs,"Battlefield surveillance have come into attention to address the issue of national security. In battlefield not only weapons or firepower is required but also an effective command, control system, intelligent pre-planning, and run time decision capability for the effective use of firepower and weapons to win in the war. This increases burden on the army and sometimes in spite of huge efforts they may lose the war. To increase the probability of success in a war Wireless Sensor and Actor Networks WSANs can be used in the battlefield because of their capability of sensing environment, intelligent decision making, commanding capability and performing action on the environment. Therefore this work presents a model for battlefield surveillance using WSANs. Quadrant-based clustering is used to increase the network lifetime. A quadrant consists of sensors, actors (robots) and a controller node for issuing commands. The controllers can communicate with each other to share the information of the quadrant. The proposed model for battlefield surveillance is represented graphically which exhibits the logical architecture. The graph-based model is transformed into an equivalent formal specification using formal specification language, i.e., Vienna Development Method-Specification Language (VDM-SL). VDM-SL is used because of its descriptive nature and effective power of modeling networks. The developed formal specification is analyzed through various techniques available in VDM-SL Toolbox which validates and verifies it.","Robot sensing systems,
Surveillance,
Robot kinematics,
Weapons,
Formal specifications,
Algorithm design and analysis"
Finger Vein Recognition with Anatomy Structure Analysis,"Finger vein recognition has received a lot of attention recently and is viewed as a promising biometric trait. In related methods, vein pattern-based methods explore intrinsic finger vein recognition, but their performance remains unsatisfactory owing to defective vein networks and weak matching. One important reason may be the neglect of deep analysis of the vein anatomy structure. By comprehensively exploring the anatomy structure and imaging characteristic of vein patterns, this paper proposes a novel finger vein recognition framework, including an anatomy structure analysis-based vein extraction (ASAVE) algorithm and an integration matching strategy. Specifically, the vein pattern is extracted by the orientation map-guided curvature based on the valley- or half valley-shaped cross-sectional profile. In addition, the extracted vein pattern is further thinned and refined to obtain a reliable vein network. In addition to the vein network, the relatively clear vein branches in the image are mined from the vein pattern, referred to as the vein backbone. In matching, the vein backbone is used in vein network calibration to overcome finger displacements. The similarity of two calibrated vein networks is measured by the proposed elastic matching and further recomputed by integrating the overlap degree of corresponding vein backbones. Extensive experiments on two public finger vein databases verify the effectiveness of the proposed framework.","Veins,
Pattern matching,
Imaging,
Image recognition,
Fingers,
Character recognition"
Proactive Serving Decreases User Delay Exponentially: The Light-Tailed Service Time Case,"In online service systems, the delay experienced by users from service request to service completion is one of the most critical performance metrics. To improve user delay experience, recent industrial practices suggest a modern system design mechanism: proactive serving, where the service system predicts future user requests and allocates its capacity to serve these upcoming requests proactively. This approach complements the conventional mechanism of capability boosting. In this paper, we propose queuing models for online service systems with proactive serving capability and characterize the user delay reduction by proactive serving. In particular, we show that proactive serving decreases average delay exponentially (as a function of the prediction window size) in the cases where service time follows light-tailed distributions. Furthermore, the exponential decrease in user delay is robust against prediction errors (in terms of miss detection and false alarm) and user demand fluctuation. Compared with the conventional mechanism of capability boosting, proactive serving is more effective in decreasing delay when the system is in the light-load regime. Our trace-driven evaluations demonstrate the practical power of proactive serving: for example, for the data trace of light-tailed YouTube videos, the average user delay decreases by 50% when the system predicts 60 s ahead. Our results provide, from a queuing-theoretical perspective, justifications for the practical application of proactive serving in online service systems.","Delays,
Cloud computing,
Boosting,
Mobile communication,
Predictive models,
Servers,
Queueing analysis"
Distributed Shortcut Networks: Low-Latency Low-Degree Non-Random Topologies Targeting the Diameter and Cable Length Trade-Off,"Low communication latency becomes a main concern in highly parallel computers and supercomputers that reach millions of processing cores. Random network topologies are better suited to achieve low average shortest path length and low diameter in terms of the hop counts between nodes. However, random topologies lead to two problems: (1) increased aggregate cable length on a machine room floor that would become dominant for communication latency in next-generation custom supercomputers, and (2) high routing complexity that typically requires a routing table at each node (e.g., topology-agnostic deadlock-free routing). In this context, we first propose low-degree non-random topologies that exploit the small-world effect, which has been well modeled by some random network models. Our main idea is to carefully design a set of various-length shortcuts that keep the diameter small while maintaining a short cable length for economical passive electric cables. We also propose custom routing that uses the regularity of the various-length shortcuts. Our experimental graph analyses show that our proposed topology has low diameter and low average shortest path length, which are considerably better than those of the counterpart 3-D torus and are near to those of a random topology with the same average degree. The proposed topology has average cable length drastically shorter than that of the counterpart random topology, which leads to low cost of interconnection networks. Our custom routing takes non-minimal paths to provide lower zero-load latency than the minimal custom routings on different counterpart topologies. Our discrete-event simulation results using SimGrid show that our proposed topology is suitable for applications that have irregular communication patterns or non-nearest neighbor collective communication patterns.","Topology,
Network topology,
Switches,
Delays,
Routing,
Communication cables,
Supercomputers"
Fully Reversible Privacy Region Protection for Cloud Video Surveillance,"Privacy becomes one of the major concerns of cloud-based multimedia applications such as cloud video surveillance. Privacy protection of surveillance videos aims to protect privacy information without hampering normal processing tasks of the cloud. Privacy Region Protection only protects the privacy region while keeping the non-privacy region visually intact to facilitate processing in the cloud. However, full reversibility, i.e. the complete recovery of the original video which is critical to digital investigation and law enforcement has not been properly addressed in privacy region protection. In this paper, we introduce fully reversible privacy region protection into cloud video surveillance and propose a novel fully reversible privacy protection method for H.264/AVC compressed video. All the operations are performed in the compressed domain and avoid lossy re-encoding, so the original H.264/AVC compressed video can be fully recovered. To our best knowledge, the proposed scheme is the first fully reversible one for privacy region protection. Experimental results and performance comparison demonstrate the effectiveness and efficiency of the proposed approach.","Privacy,
Discrete cosine transforms,
Video surveillance,
Cameras,
Video coding,
Cloud computing,
Entropy"
Analytical Model for Resistivity and Mean Free Path in On-Chip Interconnects with Rough Surfaces,"Planar copper interconnects suffer from surface roughness that results in performance degradation. This paper presents a novel analytical model for calculation effective resistivity and mean free path in on-chip copper interconnects. The closed form expressions are obtained from a generalized surface and grain boundary scattering approach that is combined with Mandelbrot-Weierstrass (MW) fractal function. It is observed that resistivity increases while mean free path reduces significantly for rough on-chip interconnects when compared with that of smooth lines. Current and future technology nodes i.e. 45 nm, 22 nm, 13 nm and 7 nm are considered for our analysis. The analytical models are validated against industry standard field solvers Ansys Q3D Extractor and previous data available in literature that exhibit excellent accuracy. Finally, we also present computational overhead in terms of simulation time, matrix size, number of tetrahedrons and memory for different values of roughness and technology nodes.","Rough surfaces,
Surface roughness,
Conductivity,
System-on-chip,
Fractals,
Analytical models,
Computational modeling"
Mutual Privacy Preserving k -Means Clustering in Social Participatory Sensing,"In this paper, we consider the problem of mutual privacy protection in social participatory sensing in which individuals contribute their private information to build a (virtual) community. Particularly, we propose a mutual privacy preserving k-means clustering scheme that neither discloses an individual's private information nor leaks the community's characteristic data (clusters). Our scheme contains two privacy-preserving algorithms called at each iteration of the k-means clustering. The first one is employed by each participant to find the nearest cluster while the cluster centers are kept secret to the participants; and the second one computes the cluster centers without leaking any cluster center information to the participants while preventing each participant from figuring out other members in the same cluster. An extensive performance analysis is carried out to show that our approach is effective for k-means clustering, can resist collusion attacks, and can provide mutual privacy protection even when the data analyst colludes with all except one participant.","Privacy,
Data privacy,
Clustering algorithms,
Sensors,
Protocols,
Encryption,
Resists"
Building Proteins in a Day: Efficient 3D Molecular Structure Estimation with Electron Cryomicroscopy,Discovering the 3D atomic-resolution structure of molecules such as proteins and viruses is one of the foremost research problems in biology and medicine. Electron Cryomicroscopy (cryo-EM) is a promising vision-based technique for structure estimation which attempts to reconstruct 3D atomic structures from a large set of 2D transmission electron microscope images. This paper presents a new Bayesian framework for cryo-EM structure estimation that builds on modern stochastic optimization techniques to allow one to scale to very large datasets. We also introduce a novel Monte-Carlo technique that reduces the cost of evaluating the objective function during optimization by over five orders of magnitude. The net result is an approach capable of estimating 3D molecular structure from large-scale datasets in about a day on a single CPU workstation.,"Three-dimensional displays,
Estimation,
Image reconstruction,
Proteins,
Two dimensional displays,
Optimization,
Computational modeling"
Preparing Tomorrow's Software Engineers for Work in a Global Environment,Global software engineering (GSE) is becoming common. It's thus important to educate university software engineering students in GSE. The authors discuss challenges to and recommendations for implementing such instruction.,"Education courses,
Software engineering,
Teamwork,
Cultural differences,
Computer science education,
Professional development,
Globalization"
A novel vCPE framework for enabling virtual network functions with multiple flow tables architecture in SDN switches,"The virtual Customer Premise Equipment (vCPE) concept has been proposed recently to reduce OPEX and CAPEX. Software-defined networking (SDN) and network functions virtualization (NFV) are key roles for this innovation. This paper proposes a vCPE framework enables deploying VNFs as edge of network. These VNFs are achieved by the synergies between a VNF controller on the cloud and an SDN switch at the edge. A multiple flow table management model is also proposed to implement virtual network functions. Through the proposed vCPE framework, the customer only needs a generic SDN switch at local network and very easy to subscribing different network services, such as Firewall, NAT, DHCP, and applications quality of service (QoS) by a browser-based dashboard. Experiments are conducted to evaluate the performance of VNFs implemented by the proposed multiple flow table management model. The flexibility of framework to integrate with other application classification systems, such as IDS or IPS, is also demonstrated.","IP networks,
Quality of service,
Control systems,
Ports (Computers),
Computer architecture,
Cloud computing,
Containers"
Design and benchmarking of ferroelectric FET based TCAM,"We consider how emerging transistor technologies, specifically ferroelectric field effect transistors (or FeFETs), can realize compact and energy efficient ternary content addressable memories (TCAMs). As Moore's Law-based performance scaling trends slow, and many computational tasks of interest are now more data-centric than compute-centric, researchers are looking to improve performance/save energy by integrating efficient and compact logic/processing elements into various levels of the memory hierarchy. Potential benefits include reduced I/O traffic, energy/delay from data transfers, etc. A TCAM is an example of a logic-in-memory element that is ubiquitous in routers, caches, databases, and even neural networks. Not surprisingly, researchers continue to study how emerging technologies could lead to improved TCAMs. Recent work has considered how non-volatile (NV) memory technologies (e.g., resistive random access memory (ReRAM) or magnetic tunnel junctions (MTJs)) could best be used to construct low energy, NV TCAMs. However, acceptable Ron-Roff ratios and the two terminal nature of these devices introduce energy and area overheads. Due to hysteresis in a device's I-V curve, an FeFET-based NV TCAM, offers low area overhead, as well as search energies and search speeds that are superior to other TCAM designs (i.e., based on MTJ, ReRAM and CMOS in array- and architectural-level evaluations).","Computer architecture,
Magnetic tunneling,
Microprocessors,
Iron,
MOSFET,
Layout"
Wearable Medical Sensor-Based System Design: A Survey,"Wearable medical sensors (WMSs) are garnering ever-increasing attention from both the scientific community and the industry. Driven by technological advances in sensing, wireless communication, and machine learning, WMS-based systems have begun transforming our daily lives. Although WMSswere initially developed to enable low-cost solutions for continuous health monitoring, the applications of WMS-based systems now range far beyond health care. Several research efforts have proposed the use of such systems in diverse application domains, e.g., education, human-computer interaction, and security. Even though the number of such research studies has grown drastically in the last few years, the potential challenges associated with their design, development, and implementation are neither well-studied nor well-recognized. This article discusses various services, applications, and systems that have been developed based on WMSs and sheds light on their design goals and challenges. We first provide a brief history of WMSs and discuss how their market is growing. We then discuss the scope of applications of WMS-based systems. Next, we describe the architecture of a typical WMS-based system and the components that constitute such a system, and their limitations. Thereafter, we suggest a list of desirable design goals that WMS-based systems should satisfy. Finally, we discuss various research directions related to WMSs and how previous research studies have attempted to address the limitations of the components used in WMS-based systems and satisfy the desirable design goals.","Monitoring,
Biomedical monitoring,
Human computer interaction,
Sensors,
Drugs,
Automation"
Low-Power Scan-Based Built-In Self-Test Based on Weighted Pseudorandom Test Pattern Generation and Reseeding,"A new low-power (LP) scan-based built-in self-test (BIST) technique is proposed based on weighted pseudorandom test pattern generation and reseeding. A new LP scan architecture is proposed, which supports both pseudorandom testing and deterministic BIST. During the pseudorandom testing phase, an LP weighted random test pattern generation scheme is proposed by disabling a part of scan chains. During the deterministic BIST phase, the design-for-testability architecture is modified slightly while the linear-feedback shift register is kept short. In both the cases, only a small number of scan chains are activated in a single cycle. Sufficient experimental results are presented to demonstrate the performance of the proposed LP BIST approach.","Built-in self-test,
Circuit faults,
Generators,
Computer architecture,
Discrete Fourier transforms,
Test pattern generators"
Categorization of Anomalies in Smart Manufacturing Systems to Support the Selection of Detection Mechanisms,"An important issue in anomaly detection in smart manufacturing systems is the lack of consistency in the formal definitions of anomalies, faults, and attacks. The term anomaly is used to cover a wide range of situations that are addressed by different types of solutions. In this letter, we categorize anomalies in machines, controllers, and networks along with their detection mechanisms, and unify them under a common framework to aid in the identification of potential solutions. The main contribution of the proposed categorization is that it allows the identification of gaps in anomaly detection in smart manufacturing systems.","Manufacturing systems,
Market research,
Robot sensing systems"
Occupancy Detection via Environmental Sensing,"Sensing by proxy (SbP) is proposed in this paper as a sensing paradigm for occupancy detection, where the inference is based on ``proxy'' measurements such as temperature and CO₂ concentrations. The effects of occupants on indoor environments are captured by constitutive models comprising a coupled partial differential equation-ordinary differential equation system that exploits the spatial and physical features. Sensor fusion of multiple environmental parameters is enabled in the proposed framework. We report on experiments conducted under simulated conditions and real-life circumstances, when the variation of occupancy follows a schedule as the ground truth. The inference of the number of occupants in the room based on CO₂ concentration at the air return and air supply vents by our approach achieves an overall mean squared error of 0.6044 (fractional person), while the best alternative by Bayes net is 1.2061 (fractional person). Results from the projected ventilation analysis show that SbP can potentially save 55% of total ventilation compared with the traditional fixed schedule ventilation strategy, while at the same time maintain a reasonably comfort profile for the occupants.","Vents,
Atmospheric modeling,
Temperature measurement,
Robot sensing systems,
Ventilation,
Estimation"
Ensemble Learning With Weak Classifiers for Fast and Reliable Unknown Terrain Classification Using Mobile Robots,"We propose a lightweight and fast learning algorithm for classifying the features of an unknown terrain that a robot is navigating in. Most of the existing research on unknown terrain classification by mobile robots relies on a single powerful classifier to correctly identify the terrain using sensor data from a single sensor like laser or camera. In contrast, our proposed approach uses multiple modalities of sensed data and multiple, weak but less-complex classifiers for classifying the terrain types. The classifiers are combined using an ensemble learning algorithm to improve the algorithm's training rate as compared to an individual classifier. Our algorithm was tested with data collected by navigating a four-wheeled, autonomous robot, called Explorer, over different terrains including brick, grass, rock, sand, and concrete. Our results show that our proposed approach performs better with up to 63% better prediction accuracy for some terrains as compared to a support vector machine (SVM)-based learning technique that uses sensor data from a single sensor. Despite using multiple classifiers, our algorithm takes only a fraction (1/65) of the time on average, as compared to the SVM technique.","Robot sensing systems,
Support vector machines,
Bagging,
Cameras,
Mobile robots,
Navigation"
Categorical liveness checking by corecursive algebras,"Final coalgebras as “categorical greatest fixed points” play a central role in the theory of coalgebras. Somewhat analogously, most proof methods studied therein have focused on greatest fixed-point properties like safety and bisimilarity. Here we make a step towards categorical proof methods for least fixed-point properties over dynamical systems modeled as coalgebras. Concretely, we seek a categorical axiomatization of well-known proof methods for liveness, namely ranking functions (in nondeterministic settings) and ranking supermartingales (in probabilistic ones). We find an answer in a suitable combination of coalgebraic simulation (studied previously by the authors) and corecursive algebra as a classifier for (non-)well-foundedness.","Algebra,
Probabilistic logic,
Games,
Concrete,
Safety,
Standards,
Computer science"
Fast Connected Components Computation in Large Graphs by Vertex Pruning,"Finding connected components is a fundamental task in applications dealing with graph analytics, such as social network analysis, web graph mining and image processing. The exponentially growing size of today's graphs has required the definition of new computational models and algorithms for their efficient processing on highly distributed architectures. In this paper we present CRACKER, an efficient iterative MapReduce-like algorithm to detect connected components in large graphs. The strategy of CRACKER is to transform the input graph in a set of trees, one for each connected component in the graph. Nodes are iteratively removed from the graph and added to the trees, reducing the amount of computation at each iteration. We prove the correctness of the algorithm, evaluate its computational cost and provide an extensive experimental evaluation considering a wide variety of synthetic and real-world graphs. The experimental results show that CRACKER consistently outperforms state-of-the-art approaches both in terms of total computation time and volume of messages exchanged.","Labeling,
Heuristic algorithms,
Computational modeling,
Convergence,
Social network services,
Algorithm design and analysis,
Skeleton"
Optimized WiMAX Profile Configuration for Smart Grid Communications,"Worldwide interoperability for microwave access (WiMAX) is one of the wireless communication technologies adopted for communication in smart grids. Due to the inherent differences between smart grid and mobile broadband applications, it is important to adjust planning and deployment of wireless technologies, including WiMAX. To this end, WiMAX is being amended to feature a smart grid system profile known as WiGrid. In this paper, we investigate the optimized configuration of this WiGrid profile, i.e., the choice of frame duration, type-of-service to traffic mapping, scheduling strategies, as well as the system architecture, such that smart grid communication requirements are met. The simulation-based evaluation of WiGrid networks with optimized configurations is facilitated through a newly developed WiGrid module for the network simulator-3 environment. Our results indicate that a priority-based scheduler is an appropriate solution for scheduling time-critical smart grid applications. Furthermore, schedulers should be implemented in such a way that grant sizes smaller than the packet size are avoided, and adjusting the uplink/downlink bandwidth ratio to favor uplink traffic is important to achieve the required latency defined for smart grid applications.","WiMAX,
Smart grids,
Bandwidth,
Quality of service,
IEEE 802.16 Standard,
Reliability"
Motivating a market or regulatory solution to IoT insecurity with the Mirai botnet code,"Botnets compromised of IoT devices have been on the rise recently with attacks originating from compromised refrigerators, DVRs, security cameras, and other consumer networking equipment. Most owners of these devices are neither security aware or motivated to secure their IoT devices. Manufacturers of these devices are not currently motivated by market forces or regulatory requirements to improve the security of their products. At 7:00 a.m. on October 21st of 2016 the Mirai IoT botnet launched a DDoS attack against Dyn, a major DNS provider. The attacking hosts generated 1.2 terabits of malicious traffic forcing Dyn off the Internet for hours. This was the second high profile attack by the Mirai botnet. Noted security blogger Brian Krebs' site was the target of the first high profile Mirai attack on September 20, 2016. As a result of the publicity the source code for the botnet was published in early October. We have reviewed the source code and devised a tactic that will use the same compromise vector as the Mirai botnet to catalog vulnerable IoT devices and motivate operators to address their poor security practices. In this paper we discuss our approach and show experimental results that indicate feasibility.","source code (software),
computer network security,
Internet of Things,
invasive software"
Linearized DC-MMC Models for Control Design Accounting for Multi-Frequency Power Transfer Mechanisms,"The DC-MMC is one of a new class of single-stage modular multilevel dc-dc converters that has recently emerged for HVDC applications. This paper presents the first smallsignal state-space model for the DC-MMC that is able to account for the multi-frequency power transfer mechanisms within the converter. Derived from a dynamic phasor model representation of the DC-MMC, the developed model is linear time-invariant (LTI), allowing application of conventional LTI tools for both analysis and design. The small-signal dynamics are validated by simulation results from a full switched model demonstrating its accuracy. A simplified model derived from the full LTI system is presented that readers can utilize to develop dynamic controls for the DC-MMC. As a case study, this benchmark model is leveraged to propose a dynamic controller that regulates dc power transfer between networks and balances the capacitor voltages. Control block diagrams are also provided that enable systematic control design of the DC-MMC via standard linear methods. Case study simulations verify efficacy of the developed controls for dc network applications. The presented small-signal modeling and control design methodology can be readily applied to any MMC-based topology.",
Metaheuristic Optimization for Long-term IaaS Service Composition,"We propose a novel dynamic metaheuristic optimization approach to compose an optimal set of IaaS service requests to align with an IaaS provider’s long-term economic expectation. This approach is designed for the context that the IaaS provisioning subjects to resource and QoS constraints. In addition, the IaaS service requests have the features of dynamic resource and QoS requirements and variable arrival times. A new economic model is proposed to evaluate the similarity between the provider’s long-term economic expectation and a composition of service requests. The evaluation incorporates the factors of dynamic pricing and operation cost modeling of the service requests. An innovative hybrid genetic algorithm is proposed that incorporates the economic inter-dependency among the requests as a heuristic operator and performs repair operations in local solutions to meet the resource and QoS constraints. The proposed approach generates dynamic global solutions by updating the heuristic operator at regular intervals with the runtime behavior data of an existing service composition. Experimental results preliminarily prove the feasibility of the proposed approach.","Economics,
Optimization,
Cloud computing,
Quality of service,
Hidden Markov models,
Computational modeling,
Stochastic processes"
Indoor Localization and Automatic Fingerprint Update with Altered AP Signals,"Wi-Fi fingerprinting has been extensively studied for indoor localization due to its deployability under pervasive indoor WLAN. As the signals from access points (APs) may change due to, for example, AP movement or power adjustment, the traditional approach is to conduct site survey regularly in order to maintain localization accuracy, which is costly and time-consuming. Here, we study how to accurately locate a target and automatically update fingerprints in the presence of altered AP signals (or simply, “altered APs”). We propose Localization with Altered APs and Fingerprint Updating (LAAFU) system, employing implicit crowdsourced signals for fingerprint update and survey reduction. Using novel subset sampling, LAAFU identifies any altered APs and filter them out before a location decision is made, hence maintaining localization accuracy under altered AP signals. With client locations anywhere in the region, fingerprint signals can be adaptively and transparently updated using non-parametric Gaussian process regression. We have conducted extensive experiments in our campus hall, an international airport, and a premium shopping mall. Compared with traditional weighted nearest neighbors and probabilistic algorithms, results show that LAAFU is robust against altered APs, achieving 20 percent localization error reduction with the fingerprints adaptive to environmental signal changes.",
Parallel Continuous Preference Queries over Out-of-Order and Bursty Data Streams,"Techniques to handle traffic bursts and out-of-order arrivals are of paramount importance to provide real-time sensor data analytics in domains like traffic surveillance, transportation management, healthcare and security applications. In these systems the amount of raw data coming from sensors must be analyzed by continuous queries that extract value-added information used to make informed decisions in real-time. To perform this task with timing constraints, parallelism must be exploited in the query execution in order to enable the real-time processing on parallel architectures. In this paper we focus on continuous preference queries, a representative class of continuous queries for decision making, and we propose a parallel query model targeting the efficient processing over out-of-order and bursty data streams. We study how to integrate punctuation mechanisms in order to enable out-of-order processing. Then, we present advanced scheduling strategies targeting scenarios with different burstiness levels, parameterized using the index of dispersion quantity. Extensive experiments have been performed using synthetic datasets and real-world data streams obtained from an existing real-time locating system. The experimental evaluation demonstrates the efficiency of our parallel solution and its effectiveness in handling the out-of-orderness degrees and burstiness levels of real-world applications.",
Power Plane Filter Using Higher Order Virtual Ground Fence,"The virtual ground fence (VGF) has been recently proposed to filter power plane noise in gigahertz frequency range. The VGF has distinct advantages over existing approaches, such as power islands and electromagnetic bandgap structures: The IR drop is not increased; transmission-line return-path discontinuities can be avoided; and the design procedure is simple. The basic VGF is created by using quarter-wave resonators referenced to the power or the ground plane. At the design frequency, the resonator creates an ac short circuit between the power and ground planes. An array of such resonators can be placed in electrically short intervals to create a VGF. Power plane noise will then ideally be shorted to ground at the location of the VGF. The operation principle is similar to the series resonance of a decoupling capacitor, which is usually ineffective in the gigahertz frequency range. This paper proposes a new design procedure for determining the number of quarter-wave resonators needed, their characteristic impedances, and their placement on the board. The design approach is based on the well-known insertion loss method in microwave filter theory, which allows for higher order VGF designs consisting of multiple rows of resonators.","Bandwidth,
Impedance,
Periodic structures,
Dielectrics,
Resonator filters,
Resonant frequency,
Metamaterials"
Cyber Inference System for Substation Anomalies Against Alter-and-Hide Attacks,"Alarms reported to energy control centers are an indication of abnormal events caused by either weather interruptions, system errors, or possibly intentional anomalies. Although these initiating events are random, e.g., faults on transmission lines struck by lightning, the existence of electronically altered measurements may implicate the process to identify root causes of abnormal events. This paper is concerned with alter-and-hide (AaH) attacks by tampering the actual measurements to normal states with the background of disruptive switching actions that hide the true values of local events from operators at the control center. A cyber inference system framework is proposed to synthesize all sequential, missing, or altered alarms of related substations against AaH attacks. The stochastic nature of such attack events is modeled with probabilities as an integer programming problem with multiple scenarios. The proposed method is utilized to verify alarm scenarios for a conclusion of the potential AaH attacks on the substations.","Substations,
Topology,
Circuit breakers,
Program processors,
Power measurement"
Can a Continuum Manipulator Fetch an Object in an Unknown Cluttered Space?,"Continuum manipulators are particularly suitable for performing tasks in cluttered environments with limited space for maneuvering. While there is progress on continuum grasping of an object in a cluttered space, if the environment is unknown where the target object is occluded and only partially visible, such as in a search and rescue scenario, an open problem is how to determine if it is possible to fetch the object. In this letter, we address this problem of online determining whether a partially occluded object nested in an unknown cluttered space can be fetched by a continuum manipulator based on sensing the surrounding obstacles progressively with a distance sensor attached to its tip, and if so, how to fetch the object autonomously. Our method formulates constraints that can be quickly checked from sensed information to decide if a solution exists for a multisection spatial continuum manipulator to access and grasp an object in a cluttered space. Examples using point clouds of unknown obstacles from RGB-D sensing illustrate the effectiveness of our approach.",
The Impact of Charged Grain Boundaries on CdTe Solar Cell: EBIC Measurements Not Predictive of Device Performance,"We conduct 2-D simulations of device structures typical of electron-beam-induced current (EBIC) imaging and solar cell structures for p-type CdTe absorber layers with charged grain boundaries. A large signal enhancement is found near depleted (positively charged) grain boundaries for EBIC simulation, but in contrast with previous claims, solar cell performance drops. In contrast, little EBIC contrast is seen, but the cell performance improves when accumulated (negatively charged) grain boundaries are introduced. We explore the impact of doping level, lifetimes, and grain boundary charge to provide insight for design of improved thin film solar cells.",
Sampling Rate Distortion,"Consider a discrete memoryless multiple source with m components of which k ≤ m possibly different sources are sampled at each time instant and jointly compressed in order to reconstruct all the m sources under a given distortion criterion. A new notion of sampling rate distortion function is introduced, and is characterized first for the case of fixed-set sampling. Next, for independent random sampling performed without knowledge of the source outputs, it is shown that the sampling rate distortion function is the same regardless of whether or not the decoder is informed of the sequence of sampled sets. Furthermore, memoryless random sampling is considered with the sampler depending on the source outputs and with an informed decoder. It is shown that deterministic sampling, characterized by a conditional point-mass, is optimal and suffices to achieve the sampling rate distortion function. For memoryless random sampling with an uninformed decoder, an upper bound for the sampling rate distortion function is seen to possess a similar property of conditional point-mass optimality. It is shown by example that memoryless sampling with an informed decoder can outperform strictly any independent random sampler, and that memoryless sampling can do strictly better with an informed decoder than without.","Decoding,
Rate-distortion,
Distortion,
Rate distortion theory,
Temperature measurement,
Temperature sensors"
NVM Way Allocation Scheme to Reduce NVM Writes for Hybrid Cache Architecture in Chip-Multiprocessors,"Hybrid cache architectures (HCAs) containing both SRAM and non-volatile memory (NVM) have been proposed to overcome the disadvantages of NVM-based cache architecture. Most previous works have concentrated on managing write-intensive blocks by storing these blocks to SRAM to reduce the number of the write operations to NVM. However, they have not focused on reducing linefill operations which also occupy a large portion of overall NVM write counts in chip-multiprocessor (CMP) environments. This paper proposes an NVM way allocation scheme, taking into account the NVM linefill counts as well as cache miss rate and the NVM write hit counts during victim selection. Three metrics are introduced to estimate the effectiveness of NVM way allocation: Miss counts change (ΔM), write counts change (ΔW), and NVM write counts change (ΔNVMW). An algorithm to minimize the write counts of NVM based on these metrics is proposed as well. Our experimental results show that dynamic energy consumption is reduced by 37.5 percent on average.","Nonvolatile memory,
Random access memory,
Resource management,
Measurement,
Energy consumption,
Heuristic algorithms,
Computer architecture"
Sub-lithographic Patterning via Tilted Ion Implantation for Scaling Beyond the 7-nm Technology Node,"Tilted ion implantation (TII) can be used in conjunction with pre-existing masking features on the surface of a substrate to form features with smaller dimensions and smaller pitch. In this paper, the resolution limit of this sub-lithographic patterning approach is examined via experiments as well as Monte Carlo process simulations. TII is shown to be capable of defining features with size below 10 nm, in a self-aligned manner, reproducing with high fidelity the line-edge roughness of the pre-existing masking features. Since it has relatively low associated process cost, TII-enhanced patterning is a promising approach to advance high-volume manufacture of integrated circuits beyond the 7-nm technology node.",
Controlling the Stormram 2: An MRI-compatible robotic system for breast biopsy,"Breast cancer is the most frequently life-threatening diagnosed type of cancer among women. Early and accurate diagnosis by acquiring a tissue sample using biopsy techniques is essential. However, small lesions only visible by MRI are often missed in standard methods, indicating the need for a robotic-assisted biopsy system that is MRI-compatible. Existing proof-of-concepts are difficult to employ due to large sizes and/or actuation complexities. Therefore, a compact pneumatically-actuated 5 DOF MRI-compatible robot was further developed and controlled by a computerized valve manifold. Accuracy and efficiency measurements have been performed using two different PVC breast phantoms with embedded fish oil capsules (mimicking lesions) inside a 0.25T MRI scanner. Preliminary results show that the end-effector was able to hit the targeted capsules, and that the position accuracy is in the range of 4.7-7.3 mm. The developed robotic system has potential to perform MRI-guided breast biopsies accurately and improve the clinical workflow.","Robots,
Needles,
Pneumatic systems,
Magnetic resonance imaging,
Pistons,
Biopsy,
Kinematics"
Coarse-to-Fine Learning for Single-Image Super-Resolution,"This paper develops a coarse-to-fine framework for single-image super-resolution (SR) reconstruction. The coarse-to-fine approach achieves high-quality SR recovery based on the complementary properties of both example learning-and reconstruction-based algorithms: example learning-based SR approaches are useful for generating plausible details from external exemplars but poor at suppressing aliasing artifacts, while reconstruction-based SR methods are propitious for preserving sharp edges yet fail to generate fine details. In the coarse stage of the method, we use a set of simple yet effective mapping functions, learned via correlative neighbor regression of grouped low-resolution (LR) to high-resolution (HR) dictionary atoms, to synthesize an initial SR estimate with particularly low computational cost. In the fine stage, we devise an effective regularization term that seamlessly integrates the properties of local structural regularity, nonlocal self-similarity, and collaborative representation over relevant atoms in a learned HR dictionary, to further improve the visual quality of the initial SR estimation obtained in the coarse stage. The experimental results indicate that our method outperforms other state-learned HR dictionaryof-the-art methods for producing high-quality images despite that both the initial SR estimation and the followed enhancement are cheap to implement.","Dictionaries,
Image reconstruction,
Image edge detection,
Estimation,
Electronic mail,
Image resolution,
Learning systems"
Latent-data Privacy Preserving with Customized Data Utility for Social Network Data,"Social network data can help with obtaining valuable insight into social behaviors and revealing the underlying benefits. New big data technologies are emerging to make it easier to discover meaningful social information from market analysis to counterterrorism. Unfortunately, both diverse social datasets and big data technologies raise stringent privacy concerns. Adversaries can launch inference attacks to predict sensitive latent information which is unwilling to be published by social users. Therefore, there is a tradeoff between data benefits and privacy concerns. In this paper, we investigate how to optimize the tradeoff between latent-data privacy and customized data utility. We propose a data sanitization strategy that does not greatly reduce the benefits brought by social network data, while sensitive latent information can still be protected. Even considering powerful adversaries with optimal inference attacks, the proposed data sanitization strategy can still preserve both data benefits and social structure, while guaranteeing optimal latent-data privacy. To the best of our knowledge, this is the first work that preserves both data benefits and social structure simultaneously and combats against powerful adversaries.","Data privacy,
Privacy,
Big Data,
Servers,
Loss measurement,
Facebook"
Relay Cooperation and Outage Analysis in Cognitive Radio Networks With Energy Harvesting,"Cooperative cognitive radio (CCR) is a novel paradigm to improve both radio spectrum efficiency and communication quality. In this paper, we consider a CCR network (CCRN) with energy harvesting in which multiple secondary transmitters (STs) are able to harvest energy from the received signals to serve their own receivers and primary transmitters (PTs). Besides, not only PT’s transmitting signal but also interferers, i.e., RF signals in ambient environment received at STs can be used for energy harvesting. Moreover, we aim to analyze the outage probability (OP) for two relay cooperation schemes including single-relay cooperation (SC) and multirelay cooperation (MC) in CCRNs while considering energy harvesting. In addition, we consider Nakagami-
m
fading rather than Rayleigh fading channels as it is more practical and general for characterizing the fading effect over wireless channels. Most importantly, we compare the outage performance of SC and MC with that of direct transmission and investigate the tradeoff between the primary and secondary users’ performance. Simulation results are presented to validate our analysis, which show the exact performance for different parameter settings.","Relays,
Energy harvesting,
Receivers,
Fading channels,
Cognitive radio,
RF signals"
On Covert Communication With Noise Uncertainty,"Prior studies on covert communication with noise uncertainty adopted a worst-case approach from the warden's perspective. That is, the worst-case detection performance of the warden is used to assess covertness, which is overly optimistic. Instead of simply considering the worst limit, we take the distribution of noise uncertainty into account to evaluate the overall covertness in a statistical sense. Specifically, we define new metrics for measuring the covertness, which are then adopted to analyze the maximum achievable rate for a given covertness requirement under both bounded and unbounded noise uncertainty models.","Uncertainty,
Noise measurement,
Measurement uncertainty,
Wireless communication,
Robustness,
Analytical models"
Work Function Engineering for Performance Improvement in Leaky Negative Capacitance FETs,"We analyze the effects of ferroelectric leakage on the performance of a negative capacitance field-effect transistor (NCFET), which has an intermediate metallic layer between the ferroelectric and the high-K dielectric. We show that, when designed without taking the dielectric leakage into account, the NCFET performance can actually degrade significantlywith respect to that of the baseline FET. To overcome these detrimental effects of leakage, we propose the concept of work-function engineering, where metals of dissimilar work-functions are used for the external gate electrode and the intermediate metallic layer. Using this approach, the ferroelectric charge-voltage characteristic is shifted along the voltage axis, which results in superior performance of the NCFET.","Field effect transistors,
Capacitance,
Logic gates,
Mathematical model,
Metals,
Semiconductor device modeling,
Performance evaluation"
OptiFEX: A Framework for Exploring Area-Efficient Floating Point Expressions on FPGAs With Optimized Exponent/Mantissa Widths,"Field-programmable gate arrays (FPGAs) could outperform microprocessors on floating point computations due to massive parallelism, freedom on the selection of exponent/mantissa width, and utilization of simplified adders and multipliers. However, optimized use of resources and accuracy of the final implemented expression are two important issues in the implementation of floating point arithmetic expressions on FPGAs. High-level optimizations such as changing the form of floating point initial expression by arithmetic rules or deciding on the exponent and mantissa widths have significant effects on the resource usage, accuracy, and efficiency of the final implementation. In this paper, we introduce an optimization framework called OptiFEX, which enables designers to optimize an initial floating point expression in terms of the resource usage and the exponent and mantissa widths based on: 1) input intervals; 2) the smallest presentable number in the implementation; and 3) the maximum permitted error interval provided by the designer. First, we come up with some techniques to generate equivalent expressions for the initial expression, and we make use of some heuristics to speed up the process of equivalent expressions' generation. We also propose a method to estimate the mantissa width. Finally, we introduce an algorithm to choose the best expressions in terms of the resource usage based on the estimated mantissa and exponent widths.","Field programmable gate arrays,
Optimization,
Adders,
Algorithm design and analysis,
Delays,
Very large scale integration,
Standards"
Incentive Mechanism for Mobile Crowdsourcing Using an Optimized Tournament Model,"With the wide adoption of smart mobile devices, there is a rapid development of location-based services. One key feature of supporting a pleasant/excellent service is the access to adequate and comprehensive data, which can be obtained by mobile crowdsourcing. The main challenge in crowdsourcing is how the service provider (principal) incentivizes a large group of mobile users to participate. In this paper, we investigate the problem of designing a crowdsourcing tournament to maximize the principal’s utility in crowdsourcing and provide continuous incentives for users by rewarding them based on the rank achieved. First, we model the user’s utility of reward from achieving one of the winning ranks in the tournament. Then, the utility maximization problem of the principal is formulated, under the constraint that the user maximizes its own utility by choosing the optimal effort in the crowdsourcing tournament. Finally, we present numerical results to show the parameters’ impact on the tournament design and compare the system performance under the different proposed incentive mechanisms. We show that by using the tournament, the principal successfully maximizes the utilities, and users obtain the continuous incentives to participate in the crowdsourcing activity.","Crowdsourcing,
Electric shock,
Contracts,
Mobile communication,
Electronic mail,
Measurement errors,
Numerical models"
An Online Convex Optimization Approach to Proactive Network Resource Allocation,"Existing approaches to online convex optimization make sequential one-slot-ahead decisions, which lead to (possibly adversarial) losses that drive subsequent decision iterates. Their performance is evaluated by the so-called regret that measures the difference of losses between the online solution and the best yet fixed overall solution in hindsight. The present paper deals with online convex optimization involving adversarial loss functions and adversarial constraints, where the constraints are revealed after making decisions, and can be tolerable to instantaneous violations but must be satisfied in the long term. Performance of an online algorithm in this setting is assessed by the difference of its losses relative to the best dynamic solution with one-slot-ahead information of the loss function and the constraint (that is here termed dynamic regret); and the accumulated amount of constraint violations (that is here termed dynamic fit ). In this context, a modified online saddle-point (MOSP) scheme is developed, and proved to simultaneously yield sublinear dynamic regret and fit, provided that the accumulated variations of per-slot minimizers and constraints are sublinearly growing with time. MOSP is also applied to the dynamic network resource allocation task, and it is compared with the well-known stochastic dual gradient method. Numerical experiments demonstrate the performance gain of MOSP relative to the state of the art.","Heuristic algorithms,
Signal processing algorithms,
Resource management,
Benchmark testing,
Loss measurement,
Convex functions"
Robust Estimation of Sparse Narrowband Spectra from Neuronal Spiking Data,"Objective: Characterizing the spectral properties of neuronal responses is an important problem in computational neuroscience, as it provides insight into the spectral organization of the underlying functional neural processes. Although spectral analysis techniques are widely used in the analysis of noninvasive neural recordings such as EEG, their application to spiking data is limited due to the binary and nonlinear nature of neuronal spiking. In this paper, we address the problem of estimating the power spectral density of the neural covariate driving the spiking statistics of a neuronal population from binary observations. Methods: We consider a neuronal ensemble spiking according to Bernoulli statistics, for which the conditional intensity function is given by the logistic map of a harmonic second-order stationary process with sparse narrowband spectra. By employing sparsity-promoting priors, we compute the maximum a posteriori estimate of the power spectral density of the process from the binary spiking observations. Furthermore, we construct confidence intervals for these estimates by an efficient posterior sampling procedure. Results: We provide simulation studies which reveal that our method outperforms the existing methods for extracting the frequency content of spiking data. Application of our method to clinically recorded spiking data from a patient under general anesthesia reveals a striking resemblance between our estimated power spectral density and that of the local field potential signal. This result corroborates existing findings regarding the salient role of the local field potential as a major neural covariate of rhythmic cortical spiking activity under anesthesia. Conclusion: Our technique allows us to analyze the harmonic structure of spiking activity in a robust fashion, independently of the local field potentials, and without any prior assumption of the spectral spread and content of the underlying neural processes. Significance: Other than its usage in the spectral analysis of neuronal spiking data, our technique can be applied to a wide variety of binary data, such as heart beat data, in order to obtain a robust spectral representation.",
ERTDS: A dynamic CPU scheduler for Xen virtualization systems,"Real-time deferrable server (RTDS) scheduler is presented since Xen 4.5. Under RTDS, a guaranteed physical CPU capacity is provided to every virtual CPU so that the performance can be better predicted. However, the guaranteed capacity is defined off-line, it might not fit the requirement of a virtual CPU at the run-time. In this paper, an RTDS-based CPU scheduler is proposed, called enhanced real-time deferrable server (ERTDS), to provide an additional capacity to virtual CPUs when their run-time requirements are higher than expected. The proposed ERTDS has been implemented in Xen 4.7 and a series of experiments has been conducted for which we have some encouraging results.","Real-time systems,
Servers,
Schedules,
Virtualization,
Conferences,
Technological innovation,
Resource management"
Reference Injected Phase-Locked Loops (PLL-RIs),"In this paper, we use synchronization to reduce phase-locked loop (PLL) phase noise and improve its locking behavior with an attenuated reference signal injection (RI) into a voltage-controlled CMOS delay-line ring-type oscillator. The transient and steady-state behavior of the PLL-RI are described by a nonlinear differential equation, which is further studied by the phase-plane method. The nonlinear equation is linearized for the small-signal condition and the s-domain noise transfer functions and noise bandwidths for different noise sources are derived. The effect of the loop parameters and the injection strength on the output phase noise, loop settling time, and lock in range is analyzed. Finally, the analysis is verified by the SPICE simulation and measurement results from an 1-GHz PLL-RI with 130-nm standard RF CMOS technology. Simulation and measurement results show phase noise reduction and improved settling behavior of a PLL-RI compared with a conventional PLL.",
Efficient feature selection for Blind Image Quality Assessment based on natural scene statistics,"Blind Image Quality Assessment (BIQA) has received considerable importance with the increase in the use of multimedia in our daily lives. The main objective of BIQA is to predict the quality of distorted images without any prior information about the original image. In this work, we propose an efficient feature selection method for blind image quality assessment based on natural scene statistics i.e., Distortion Identification-based Image Verity and Integrity Evaluation (DIIVINE). The proposed method produces better results for non-reference image quality assessment by selecting features, which produce the best Spearman Rank Order Correlation Constant (SROCC) scores averaged over 1000 random runs. The experimental results conducted on the LIVE database show that the proposed method strongly correlates to the subjective mean observer score and is competitive to the state-of-the-art image quality assessment techniques with a minimum number of features that reduces the computational expense.","Support vector machines,
Transform coding,
Training,
Correlation"
Detection of Global and Local Motion Changes in Human Crowds,"Crowds arise in a variety of situations, such as public concerts and sporting matches. In typical conditions, the crowd moves in an orderly manner, but panic situations may lead to catastrophic results. We propose a computer vision method to identify motion pattern changes in human crowds that can be related to an unusual event. The proposed approach can identify global changes, by evaluating 2D motion histograms in time, and also local effects, by identifying clusters that present similar spatial locations and velocity vectors. The method is tested both on publicly available data sets involving crowded scenarios and on synthetic data produced by a crowd simulation algorithm, which allows the creation of controlled environments with known motion patterns that are particularly suitable for multicamera scenarios.",
Enabling proactive self-healing by data mining network failure logs,"Self-healing is a key desirable feature in emerging communication networks. While legacy self-healing mechanisms that are reactive in nature can minimize recovery time substantially, the recently conceived extremely low latency and high Quality of Experience (QoE) requirements call for self-healing mechanisms that are pro-active instead of reactive thereby enabling minimal recovery times. A corner stone in enabling proactive self-healing is predictive analytics of historical network failure logs (NFL). In current networks NFL data remains mostly dark, i.e., though they are stored but they are not exploited to their full potential. In this paper, we present a case study that investigates spatio-temporal trends in a large NFL database of a nationwide broadband operator. To discover hidden patterns in the data we leverage five different unsupervised pattern recognition and clustering along with density based outlier detection techniques namely: K-means clustering, Fuzzy C-means clustering, Local Outlier Factor, Local Outlier Probabilities and Kohonen's Self Organizing Maps. Results indicate that self-organizing maps with local outlier probabilities outperform K-means and Fuzzy C-means clustering in terms of sum of squared errors (SSE) and Davis Boulden index (DBI) values. Through an extensive data analysis leveraging a rich combination of the aforementioned techniques, we extract trends that can enable the operator to proactively tackle similar faults in future and improve QoE and recovery times and minimize operational costs, thereby paving the way towards proactive self-healing.","Clustering algorithms,
Big data,
Market research,
Broadband communication,
Self-organizing feature maps,
Algorithm design and analysis"
Optimal Sensor Configuration and Feature Selection for AHU Fault Detection and Diagnosis,"Experiments show that operation efficiency and reliability of buildings can greatly benefit from rich and relevant datasets. More specifically, data can be analyzed to detect and diagnose system and component failures that undermine energy efficiency. Among the huge quantity of information, some features are more correlated with the failures than others. However, there has been little research to date focusing on determining the types of data that can optimally support fault detection and diagnosis (FDD). This paper presents a novel optimal feature selection method, named information greedy feature filter (IGFF), to select essential features that benefit building FDD. On one hand, the selection results can serve as reference for configuring sensors in the data collection stage, especially when the measurement resource is limited. On the other hand, with the most informative features selected by the IGFF, the performance of building FDD could be improved and theoretically justified. A case study on air-handling unit (AHU) is conducted based on the dataset of the ASHRAE Research Project 1312. Numerical results show that, compared with several baselines, the FDD performances of conventional classification methods are greatly enhanced by the IGFF.",
Learning the Conformal Transformation Kernel for Image Recognition,"In this paper, we present a multiclass data classifier, denoted by optimal conformal transformation kernel (OCTK), based on learning a specific kernel model, the CTK, and utilize it in two types of image recognition tasks, namely, face recognition and object categorization. We show that the learned CTK can lead to a desirable spatial geometry change in mapping data from the input space to the feature space, so that the local spatial geometry of the heterogeneous regions is magnified to favor a more refined distinguishing, while that of the homogeneous regions is compressed to neglect or suppress the intraclass variations. This nature of the learned CTK is of great benefit in image recognition, since in image recognition we always have to face a challenge that the images to be classified are with a large intraclass diversity and interclass similarity. Experiments on face recognition and object categorization show that the proposed OCTK classifier achieves the best or second best recognition result compared with that of the state-of-the-art classifiers, no matter what kind of feature or feature representation is used. In computational efficiency, the OCTK classifier can perform significantly faster than the linear support vector machine classifier (linear LIBSVM) can.","Kernel,
Geometry,
Image recognition,
Face recognition,
Feature extraction,
Measurement,
Transforms"
Human Facial Age Estimation by Cost-Sensitive Label Ranking and Trace Norm Regularization,"Human facial age estimation has attracted much attention due to its potential applications in forensics, security, and biometrics. In contrast to existing approaches that cast facial age estimation as either a multiclass classification or regression problem, in this work, we propose a novel approach that combines the strength of cost-sensitive label ranking methods with the power of low-rank matrix recovery theories. Instead of having to make a binary decision for each age label, our approach ranks age labels in a descending order in terms of their predicted relevance to the given facial image. In addition, the proposed approach aggregates the linear prediction functions for different ages into a matrix, and introduces the matrix trace norm regularization to explicitly capture the correlations among different age labels and control the model complexity as well. Furthermore, motivated by nonlinear generalization performance of kernel methods, we extend the trace norm regularization from a finite dimensional space to an infinite dimensional space. We also provide theoretical analysis on the efficiency of the proposed kernelized trace normalization, which guarantees the feasibility of the proposed method for solving large-scale prediction problems. Comprehensive experiments on multiple well-known facial image datasets demonstrate the effectiveness of the proposed framework for age estimation compared to the state-of-the-arts.","Estimation,
Training,
Aging,
Neural networks,
Predictive models,
Kernel,
Aerospace electronics"
A Magnus Wind Turbine Power Model Based on Direct Solutions Using the Blade Element Momentum Theory and Symbolic Regression,"A model of the power coefficient of a mid-scale Magnus wind turbine using numerical solutions of the Blade Element Momentum Theory and symbolic regression is presented. A direct method is proposed for solving the nonlinear system of equations which govern the phenomena under study. The influence of the tip-speed ratio and the number, aspect ratio, and the angular speed of the cylinders on the turbine performance is obtained. Results show that the maximum power coefficient is on the order of 0.2, which is obtained with two low aspect ratio cylinders, a dimensionless cylinder speed ratio of 2, and a turbine tip-speed ratio between 2 and 3. The predicted power coefficient at low tip-speed ratio suggests that a Magnus turbine may be adequate in the urban environment.","Wind turbines,
Blades,
Drag,
Numerical models,
Mathematical model,
Force,
Wind speed"
Novel Design on Multiple Channel Sensing for Partially Observable Cognitive Radio Networks,"A great amount of research has devoted to cognitive radio (CR) in recent years in order to improve spectrum efficiency. In decentralized CR networks, it is not realistic for CR users to sense entire spectrum in practice due to hardware limitations. Consequently, the partially observable Markov decision process (POMDP) can be utilized to provide CR users with sufficient information in partially observable environments. Existing POMDP-based protocols adopt channel aggregation techniques in order to improve spectrum opportunities and system performance. However, the required time for channel sensing is neglected which can result in large sensing time overhead and spectrum opportunity loss in realistic environments. In this paper, based on partially observable channel state with the consideration of sensing overhead, the stochastic multiple channel sensing (SMCS) protocol is proposed to conduct optimal channel selection for maximizing the aggregated throughput of CR users. By adopting the proposed SMCS protocol, CR users can highly accommodate themselves to rapidly varying environment based on the dynamically adjustable channel sensing strategy. Moreover, the channel sensing problem is further extended to imperfect sensing scenario, which can severely degrade system throughput due to packet collision between primary users (PUs) and CR users. Consequently, in addition to channel selection, it is required for CR users to determine the sensing time length in order to address the collision problem. The two-phase SMCS (TSMCS) protocol is proposed to maximize the aggregated throughput of CR users while still fulfilling PUs' quality-of-service (QoS) requirements. Numerical results show that the proposed SMCS and TSMCS protocols can effectively maximize the aggregated throughput for decentralized CR networks.","Sensors,
Protocols,
Throughput,
Wideband,
OFDM,
Narrowband,
Mobile computing"
An Automatic Health Monitoring System for Patients Suffering From Voice Complications in Smart Cities,"Current evolutions in the Internet of Things and cloud computing make it believable to build smart cities and homes. Smart cities provide smart technologies to residents for the improved and healthier life, where smart healthcare systems cannot be ignored due to rapidly growing elderly people around the world. Smart healthcare systems can be cost-effective and helpful in the optimal use of healthcare resources. The voice is a primary source of communication and any complication in the production of voice affects the personal as well as professional life of a person. Early screening of voice through an automatic voice disorder detection system may save life of a person. In this paper, an automatic voice disorder detection system to monitor the resident of all age group and professional backgrounds is implemented. The proposed system detects the voice disorder by determining the source signal from the speech through the linear prediction analysis. The analysis calculates the features from normal and disordered subjects. Based on these features, the spectrum is computed, which provided distribution of energy in normal and voice disordered subjects to differentiate between them. It is found that lower frequencies from 1 to 1562 Hz contributes significantly in the detection of voice disorders. The system is developed by using sustained vowel and running speech so that it can be deployed in a real world. The obtained accuracy for the detection of voice disorder with the sustained vowel is 99.94% ± 0.1, and that is for running speech is 99.75% ± 0.8.","Speech,
Smart cities,
Monitoring,
Medical services,
Senior citizens,
Feature extraction,
Acoustics"
The Three-Terminal Interactive Lossy Source Coding Problem,"In this paper, we explore the three-node multiterminal lossy source coding problem, which seems to offer a formidable mathematical complexity. We derive an inner bound to the general rate-distortion region of this problem, which is a natural extension of the seminal work by Kaspi on the interactive two-terminal source coding problem. It is shown that this (rather involved) inner bound contains several rate-distortion regions of some relevant source coding settings. In this way, besides the non-trivial extension of the interactive two terminal problem, our results can be seen as a generalization and hence unification of several previous works in the field. By specializing the inner bound to particular cases, we obtain some novel rate-distortion regions for several multi-terminal lossy source coding problems.","Source coding,
Decoding,
Rate-distortion,
Distortion,
Random variables,
Complexity theory"
Joint interference management and resource allocation for device-to-device (D2D) communications underlying downlink/uplink decoupled (DUDe) heterogeneous networks,"In this paper, resource allocation and co-tier/cross-tier interference management are investigated for D2D-enabled heterogeneous networks (HetNets) where tiers 1, 2, and 3 consist of macrocells, smallcells, and D2D pairs, respectively. We first propose a D2D-enabled fractional frequency reuse scheme for uplink (UL) HetNets where macrocell subregions are preassigned to different subbands (SBs) in order to mitigate the tier-1↔tier-1 interference. Nevertheless, cell-edge macrocell user equipments (MUEs) with high transmission powers still form dead-zones for nearby smallcell UEs (SUEs) and D2D UEs (DUEs). One of the simple but yet novel means of the dead-zone alleviation is associating the cell-edge MUEs with nearby smallcells, which is also known as downlink (DL)/UL decoupling (DUDe). Subject to quality of service (QoS) requirements and power constraints, we formulate a joint SB assignment and resource block (RB) allocation optimization as a mixed integer non-linear programming (MINLP) problem to maximize the D2D sum rate and minimize the co-tier/cross-tier interference. Based on tolerable interference limit, we propose a fast yet high-performance suboptimal solution to jointly assign available SBs and RBs to smallcells. A D2D mode selection and resource allocation framework is then developed for DUEs. As traditional DL/UL Coupled (DUCo) scheme generates significant interference proportional to cellular user density and user association bias factor, results obtained from the combination of proposed methods and developed algorithms reveal the potential of DUDe for co-tier/cross-tier interference mitigation which opens more room for spectrum reuse of DUEs.","Interference,
Device-to-device communication,
Resource management,
Macrocell networks,
Quality of service,
Indexes,
Wireless communication"
Effective Static and Adaptive Carrier Sensing for Dense Wireless CSMA Networks,"The increasingly dense deployments of wireless CSMA networks arising from applications of Internet-of-things call for an improvement to mitigate the interference among simultaneous transmitting wireless devices. For cost efficiency and backward compatibility with legacy transceiver hardware, a simple approach to address interference is by appropriately configuring the carrier sensing thresholds in wireless CSMA protocols, particularly in dense wireless networks. Most prior studies of the configuration of carrier sensing thresholds are based on a simplified conflict graph model, whereas this paper considers a realistic signal-to-interference-and-noise ratio model. We provide a comprehensive study for two effective wireless CSMA protocols: Cumulative-interference-Power Carrier Sensing and Incremental-interference-Power Carrier Sensing, in two aspects: (1) static approach that sets a universal carrier sensing threshold to ensure interference-safe transmissions regardless of network topology, and (2) adaptive approach that adjusts the carrier sensing thresholds dynamically based on the feedback of nearby transmissions. We also provide simulation studies to evaluate the starvation ratio, fairness, and goodput of our approaches.","Sensors,
Multiaccess communication,
Interference,
Wireless communication,
Transmitters,
Wireless sensor networks,
Signal to noise ratio"
On Optimal PMU Placement-Based Defense Against Data Integrity Attacks in Smart Grid,"State estimation plays a critical role in self-detection and control of the smart grid. Data integrity attacks (also known as false data injection attacks) have shown significant potential in undermining the state estimation of power systems, and corresponding countermeasures have drawn increased scholarly interest. Nonetheless, leveraging optimal phasor measurement unit (PMU) placement to defend against these attacks, while simultaneously ensuring the system observability, has yet to be addressed without incurring significant overhead. In this paper, we enhance the least-effort attack model, which computes the minimum number of sensors that must be compromised to manipulate a given number of states, and develop an effective greedy algorithm for optimal PMU placement to defend against data integrity attacks. Regarding the least-effort attack model, we prove the existence of smallest set of sensors to compromise and propose a feasible reduced row echelon form (RRE)-based method to efficiently compute the optimal attack vector. Based on the IEEE standard systems, we validate the efficiency of the RRE algorithm, in terms of a low computation complexity. Regarding the defense strategy, we propose an effective PMU-based greedy algorithm, which cannot only defend against data integrity attacks, but also ensure the system observability with low overhead. The experimental results obtained based on various IEEE standard systems show the effectiveness of the proposed defense scheme against data integrity attacks.","Phasor measurement units,
Power grids,
State estimation,
Current measurement,
Power measurement,
Transmission line measurements,
Sensors"
Linear Transceiver Designs for MIMO Indoor Visible Light Communications Under Lighting Constraints,"In this paper, we study linear transceiver designs for indoor visible light communications (VLCs) with multiple light emitting diodes (LEDs). Specifically, we investigate VLCs including white emitting diodes and VLCs including red/green/blue (RGB) LEDs. The transmitter precoding and the offset are jointly designed by considering certain key practical lighting constraints, such as optical power, non-negativeness, and color illumination. Various non-convex transceiver design problems are formulated aiming to minimize total mean-square-error to improve transmission reliability. We show that for multi-input single-output white VLCs, the optimal precoding reduces to a simple LED selection strategy. For multi-input multi-output (MIMO) white VLCs, we prove that the optimization problem with multiple constraints can be equivalently simplified to a problem with single constraint, which enables us to propose efficient algorithms to search local optimal solutions. For MIMO RGB VLCs, by using certain useful transformations, we show that the precoding design is equivalent to covariance matrix design of transmit signals, which can be further transformed to a convex optimization problem. To develop an algorithm to find the optimal solution, we derive the optimal structure of the covariance matrix and show that the optimal solution can be obtained via a water-filling approach. Extensive simulation results are provided to verify the performance of the proposed designs.","MIMO,
Light emitting diodes,
Lighting,
Precoding,
Covariance matrices,
Image color analysis,
Color"
Energy-Efficient Query Processing in Web Search Engines,"Web search engines are composed by thousands of query processing nodes, i.e., servers dedicated to process user queries. Such many servers consume a significant amount of energy, mostly accountable to their CPUs, but they are necessary to ensure low latencies, since users expect sub-second response times (e.g., 500 ms). However, users can hardly notice response times that are faster than their expectations. Hence, we propose the Predictive Energy Saving Online Scheduling Algorithm (\sf{PESOS}
) to select the most appropriate CPU frequency to process a query on a per-core basis. \sf{PESOS}
aims at process queries by their deadlines, and leverage high-level scheduling information to reduce the CPU energy consumption of a query processing node. \sf{PESOS}
bases its decision on query efficiency predictors, estimating the processing volume and processing time of a query. We experimentally evaluate \sf{PESOS}
upon the TREC ClueWeb09B collection and the MSN2006 query log. Results show that \sf{PESOS}
can reduce the CPU energy consumption of a query processing node up to {\sim}
48 percent compared to a system running at maximum CPU core frequency. \sf{PESOS}
outperforms also the best state-of-the-art competitor with a {\sim}
20 percent energy saving, while the competitor requires a fine parameter tuning and it may incurs in uncontrollable latency violations.","Query processing,
Energy consumption,
Web search,
Engines,
Servers,
Time factors,
Indexes"
Mitigating Large Errors in WiFi-Based Indoor Localization for Smartphones,"Although WiFi fingerprint-based indoor localization is attractive, its accuracy remains a primary challenge, especially in mobile environments. Existing approaches either appeal to physical layer information or rely on extra wireless signals for high accuracy. In this paper, we revisit the received signal strength (RSS) fingerprint-based localization scheme and reveal crucial observations that act as the root causes of localization errors, yet are surprisingly overlooked or not adequately addressed in previous works. Specifically, we recognize access points' (APs) diverse discrimination for fingerprinting a specific location, observe the RSS inconsistency caused by signal fluctuations and human body blockages, and uncover the transitional fingerprint problem on commodity smartphones. Inspired by these insights, we devise a discrimination factor to quantify different APs' discrimination, incorporate robust regression to tolerate outlier measurements, and reassemble different normal fingerprints to cope with transitional fingerprints. Integrating these techniques in a unified system, we propose DorFin, i.e., a novel scheme of fingerprint generation, representation, and matching, which yields remarkable accuracy without incurring extra cost. Extensive experiments in three campus buildings demonstrate that DorFin achieves a mean error of 2.5 m and, more importantly, decreases the 95th percentile error under 6.2 m, both significantly outperforming existing approaches.",
Simplified High-Order DOA and Range Estimation With Linear Antenna Array,"In this letter, we propose a new efficient method to estimate the direction-of-arrival (DOA) and range of near-field sources in a decoupled way. First, a non-Hermitian cumulant matrix is constructed, whose eigenvectors associated with zero eigenvalues are used to directly estimate the DOA by using the MUSIC algorithm. Then, the ranges are estimated with the estimated DOA by orthogonalizing the remained eigenvectors. Compared with other modified 2-D MUSIC, the proposed algorithm can greatly reduce the computational complexity by avoiding a 2-D search with only one matrix and one eigenvalue decomposition. Simulation results show the effectiveness of the proposed method.","Direction-of-arrival estimation,
Estimation,
Two dimensional displays,
Multiple signal classification,
Matrix decomposition,
Covariance matrices,
Eigenvalues and eigenfunctions"
Eliminating Driving Distractions: Human-Computer Interaction with Built-In Applications,"This article proposes a novel smart car demonstration platform, with a focus on the intuitive paradigm of human-computer interaction (HCI). The main objective here is to circumvent driver distraction when manipulating built-in car-appropriate applications (apps) for future smart car development. Two major development directions for a smart car's HCI are investigated and discussed in detail: 1) an in-vehicle user interface, which focuses on utilizing the user interface of a transparent windshield display to keep the driver's head up and eyes focused on the roadway, and 2) an in-vehicle interaction design, which emphasizes an intuitive interaction framework to minimize distractions while driving. This article addresses the major difficulties of each direction and discusses related challenges and solutions to achieve safety and comfort during smart car operation.",
Worst-Case Bias for Proton and 10-keV X-Ray Irradiation of AlGaN/GaN HEMTs,"Responses to 1.8 MeV proton irradiation and 10-keV X-ray irradiation under typical bias conditions are investigated for AlGaN/GaN HEMTs fabricated with different types of process technologies. We find that, in contrast to previous generations of process technologies, total ionizing dose effects can be significant in these devices. For proton irradiation, worst-case bias for transconductance degradation for GaN-on-SiC substrate devices is ON bias, and for devices built on free-standing GaN substrates, the worst-case bias condition is semi-ON bias. Low-frequency noise measurements demonstrate that these differences result from differences in defect types and energy distributions for the different types of devices, both before and after irradiation. These results emphasize the need to test devices under a wide range of conditions during characterization and qualification testing.",
Social Cloud for Information Technology Skills: An Experience With Universities in Ecuador,"Instruction in technical disciplines requires hands-on laboratories. Such laboratories are difficult to find and maintain for administrative and cost reasons. The use of a new ecosystem of practical education is necessary. Here, we present a model and an architecture of e-learning for hands-on information technology learning. We use virtual technology and cloud computing access from any computer or student-owned device. The model has been experimentally tested. The results demonstrate the validity of the model that permits the transmission of practical skills in a fashion similar to face-to-face training, but with the advantage that only virtual resources are needed.","Cloud computing,
Education,
Computational modeling,
Virtual machining,
Computers,
Laboratories,
Tools"
Medical Image Retrieval via Histogram of Compressed Scattering Coefficients,"The features used in many current medical image retrieval systems are usually low-level hand-crafted features. This limitation may adversely affect the retrieval performance. To address this problem, this paper proposes a simple yet discriminative feature, called histogram of compressed scattering coefficients (HCSC), for medical image retrieval. In the proposed work, the scattering transform, a particular variation of deep convolutional networks, is first performed to yield more abstract representations of a medical image. A projection operation is then conducted to compress the obtained scattering coefficients for efficient processing. Finally, a bag-of-words (BoW) histogram is derived from the compressed scattering coefficients as the features of the medical image. The proposed HCSC takes the advantages of both scattering transform and BoW model. Experiments on three benchmark medical computer tomography image databases demonstrate that HCSC outperforms several state-of-the-art features.","Scattering,
Feature extraction,
Medical diagnostic imaging,
Wavelet transforms,
Image retrieval"
A Few Photons Among Many: Unmixing Signal and Noise for Photon-Efficient Active Imaging,"Conventional LIDAR systems require hundreds or thousands of photon detections per pixel to form accurate depth and reflectivity images. Recent photon-efficient computational imaging methods are remarkably effective with only 1.0 to 3.0 detected photons per pixel, but they are not demonstrated at signal-to-background ratio (SBR) below 1.0 because their imaging accuracies degrade significantly in the presence of high background noise. We introduce a new approach to depth and reflectivity estimation that emphasizes the unmixing of contributions from signal and noise sources. At each pixel in an image, short-duration range gates are adaptively determined and applied to remove detections likely to be due to noise. For pixels with too few detections to perform this censoring accurately, data are combined from neighboring pixels to improve depth estimates, where the neighborhood formation is also adaptive to scene content. Algorithm performance is demonstrated on experimental data at varying levels of noise. Results show improved performance of both reflectivity and depth estimates over state-of-the-art methods, especially at low SBR. In particular, accurate imaging is demonstrated with SBR as low as 0.04. This validation of a photon-efficient, noise-tolerant method demonstrates the viability of rapid, long-range, and low-power LIDAR imaging.",
Gain-Improved Broadband Circularly Polarized Antenna Array With Parasitic Patches,"A broadband circularly polarized (CP) antenna array with improved gain is proposed. The antenna consists of a CP loop that provides sequential phase, a 2 × 2 patch array, and four parasitic rectangular elements. The square patches are capacitively coupled with four strips, which are connected to the loop feeding network. Moreover, four parasitic rectangular patches are introduced to enhance the gain in the lower band. The measured 10-dB impedance bandwidth is 15.9% (5.01-5.87 GHz), and the 3-dB axial-ratio bandwidth of 640 MHz (5.08-5.72 GHz) is also obtained. Besides, the proposed antenna array has a flat gain over the operating frequency and the maximum gain of 12.5 dBi is achieved at 5.3 GHz.",
Localization of Health Center Assets Through an IoT Environment (LoCATE),"The rapid advances in modern wireless technology opens the door for new applications using the Internet of Things (IoT) technology. In the medical field, staff members of a certain hospital are in need for a system that tracks where patients/medical staff/devices are at any given time. LoCATE, which is Localization of Health Center Assets Through an IoT Environment, provides a near-real time tracking tool for medical systems using the existing 802.11 WiFi infrastructure. The primary goal of this system is to track assets and personnel at any hospital (e.g., Sentara® RMH hospital) and continuously log a real-time location data on a cloud computing platform such as Amazon Web Services (AWS). Using LoCATE, administrators can view the location of doctors, patients, and assets in real-time via a web UI or a mobile app, within the organization. The collected data, stored and processes on a Cloud Storage platform, is then analyzed to expose inefficiencies in daily operations and improve the health care system. Low-level functionality of the LoCATE system is unlike that of typical Radio-frequency identification (RFID) technologies. The spirit of the IoT paradigm employed by LoCATE makes the system both flexible and scalable, by leveraging collaboration between embedded and cloud systems. This flexibility will allow for the future support of additional applications such as hardware integration (e.g., New hardware components). This can include data acquisition such as usage statistics and historical patient health data. Compiling this data might pave the way for future research into disease vectors or could be used to optimize care delivered for specific conditions. While implications for an IoT system such as LoCATE are wide-ranging; its primary objective is to provide an easy to use, low-cost solution to track the location of medical assets in real-time.","Cloud computing,
Wireless communication,
IEEE 802.11 Standard,
Wireless fidelity,
Transmitters,
Hospitals"
An Insect Eye Inspired Miniaturized Multi-Camera System for Endoscopic Imaging,"In this work, we present a miniaturized high definition vision system inspired by insect eyes, with a distributed illumination method, which can work in dark environments for proximity imaging applications such as endoscopy. Our approach is based on modeling biological systems with off-the-shelf miniaturized cameras combined with digital circuit design for real time image processing. We built a 5 mm radius hemispherical compound eye, imaging a 180° × 180° degrees field of view while providing more than 1.1 megapixels (emulated ommatidias) as real-time video with an inter-ommatidial angle Δφ = 0.50 at 18 mm radial distance. We made an FPGA implementation of the image processing system which is capable of generating 25 fps video with 1080 × 1080 pixel resolution at a 120 MHz processing clock frequency. When compared to similar size insect eye mimicking systems in literature, the system proposed in this paper features 1000 × resolution increase. To the best of our knowledge, this is the first time that a compound eye with built-in illumination idea is reported. We are offering our miniaturized imaging system for endoscopic applications like colonoscopy or laparoscopic surgery where there is a need for large field of view high definition imagery. For that purpose we tested our system inside a human colon model. We also present the resulting images and videos from the human colon model in this paper.",
A Stochastic Computational Approach for the Analysis of Fuzzy Systems,"Fault tree analysis (FTA) has been widely utilized as a reliability evaluation technique for complex systems, such as nuclear power plants and aerospace systems. However, it is hard to obtain the crisp failure probabilities of basic events, owning to the insufficient information about some complex engineering systems. Hence, fuzzy set theory and fuzzy arithmetic operation (FAO) have been used as effective methods to analyze system reliability. However, it is cumbersome to evaluate complex systems based on FAO. To improve the evaluation efficiency, stochastic computational models are proposed in this paper to perform reliability analysis of a fuzzy system. Due to the features of Gaussian distribution in stochastic computation, a basic event's failure possibility given by a fuzzy number is transformed into the expected value of it. The standard deviation of stochastic computational results gives the spread of the fuzzy number. A fuzzy system is then converted into a deterministic system. The analysis of an illustrating example shows that the proposed stochastic approach can efficiently evaluate the failure probability of a system.",
Efficient Alignment Between Event Logs and Process Models,"The aligning of event logs with process models is of great significance for process mining to enable conformance checking, process enhancement, performance analysis, and trace repairing. Since process models are increasingly complex and event logs may deviate from process models by exhibiting redundant, missing, and dislocated events, it is challenging to determine the optimal alignment for each event sequence in the log, as this problem is NP-hard. Existing approaches utilize the cost-based A* algorithm to address this problem. However, scalability is often not considered, which is especially important when dealing with industrial-sized problems. In this paper, by taking advantage of the structural and behavioral features of process models, we present an efficient approach which leverages effective heuristics and trace replaying to significantly reduce the overall search space for seeking the optimal alignment. We employ real-world business processes and their traces to evaluate the proposed approach. Experimental results demonstrate that our approach works well in most cases, and that it outperforms the state-of-the-art approach by up to 5 orders of magnitude in runtime efficiency.","Petri nets,
Business,
Analytical models,
Electronic mail,
Computational modeling,
Jacobian matrices,
Performance analysis"
Imitation Learning for Dynamic VFI Control in Large-Scale Manycore Systems,"Manycore chips are widely employed in high-performance computing and large-scale data analysis. However, the design of high-performance manycore chips is dominated by power and thermal constraints. In this respect, voltage-frequency island (VFI) is a promising design paradigm to create scalable energy-efficient platforms. By dynamically tailoring the voltage and frequency of each island, we can further improve the energy savings within given performance constraints. Inspired by the recent success of imitation learning (IL) in many application domains and its significant advantages over reinforcement learning (RL), we propose the first architecture-independent IL-based methodology for dynamic VFI (DVFI) control in manycore systems. Due to its popularity in the EDA community, we consider an RL-based DVFI control methodology as a strong baseline. Our experimental results demonstrate that IL is able to obtain higher quality policies than RL (on average, 5% less energy with the same level of performance) with significantly less computation time and hardware area overheads (3.1X and 8.8X, respectively).",
Fault-Tolerant Small Cells Locations Planning in 4G/5G Heterogeneous Wireless Networks,"Fourth/Fifth Generation heterogeneous wireless networks (4G/5G HetNets) use or will use small cells (SCs) to extend network coverage and increase spectrum efficiency. However, the standard and technical specifications do not specify how to plan the locations of the SCs within the network. Several papers introduced strategies for planning the locations of SCs in the 4G HetNet architecture. However, SCs placement strategies to support the self-healing functionality of the 4G/5G self organizing networks framework has not been studied in the literature. The placement of SCs in 4G HetNets such that an SC failure will not interrupt service, hence making the network fault tolerant, is an important design and planning problem that is addressed in this paper. We present an integer linear program formulation for planning operators of managed SC locations with fault tolerance. We allow one SC to fail and by using self-healing, a fault-tolerance service is provided at designated fail-over levels (defined in terms of users throughput). We consider the problem of SC location planning by using offloading in both out-band and in-band modes, and an interference model is presented to consider the in-band mode and to address the effect of interference on SCs placement planning. A novel approach to provide a linear interference model by using an expanded state space to get rid of nonlinearity is introduced. We present numerical results that show how our model can be used to plan the positions of SCs. We also incorporate the existence of obstacles in the planning, such as large structures or natural formations, that might happen in real life. To the best of our knowledge, this is the first work that addresses the planning of SC locations in 4G/5G HetNets in a fault-tolerant manner.",
Dynamics and Feedback Control of Electrospinning Processes,"Due to its superb flexibility, efficiency, and tractility, flexible electronic production is widely used in the manufacturing of thin-film solar cells, microscale sensors, high-resolution displayers, illumination equipments, and integrated artificial tissues. Electrospinning is an essential procedure in flexible electronic production, where a microscale/nanoscale fiber is dragged from a Taylor cone by a static electrical field power and afterward be deposited onto a flexible substrate. In this brief, we established a closed-loop control system of electrospinning processes composed of a high-speed camera, an National Instruments (NI) image processor, an NI controller, a control signal amplifier, and a high-voltage static electricity supplier. It is the first time to apply model predictive control on practical electrospinning processes to modulate the diameter of electrospinning fiber subject to external disturbances and uncertainties. Extensive experimental results have shown that the fiber diameter becomes tunable and stabilized by the closed-loop controller, which is beneficial to enhance the consistency and controllability of the microelectrical elements. More significantly, the adjustability of fiber diameter enables the manufacturing of more specified structures like island-bridge microstructure widely used in microscale sensors and electrical unit manufacturing and tissue engineering.",
Causal Decision Trees,"Uncovering causal relationships in data is a major objective of data analytics. Currently, there is a need for scalable and automated methods for causal relationship exploration in data. Classification methods are fast and they could be practical substitutes for finding causal signals in data. However, classification methods are not designed for causal discovery and a classification method may find false causal signals and miss the true ones. In this paper, we develop a causal decision tree (CDT) where nodes have causal interpretations. Our method follows a well-established causal inference framework and makes use of a classic statistical test to establish the causal relationship between a predictor variable and the outcome variable. At the same time, by taking the advantages of normal decision trees, a CDT provides a compact graphical representation of the causal relationships, and the construction of a CDT is fast as a result of the divide and conquer strategy employed, making CDTs practical for representing and finding causal signals in large data sets. Experiment results demonstrate that CDTs can identify meaningful causal relationships and the CDT algorithm is scalable.","Decision trees,
Bayes methods,
Mathematical model,
Context,
Knowledge engineering,
Data analysis,
Remuneration"
Minimizing Redundancy to Satisfy Reliability Requirement for a Parallel Application on Heterogeneous Service-oriented Systems,"Reliability is widely identified as an increasingly relevant issue in heterogeneous service-oriented systems because processor failure affects the quality of service to users. Replication-based fault-tolerance is a common approach to satisfy application’s reliability requirement. This study solves the problem of minimizing redundancy to satisfy reliability requirement for a directed acyclic graph (DAG)- based parallel application on heterogeneous service-oriented systems. We first propose the enough replication for redundancy minimization (ERRM) algorithm to satisfy application’s reliability requirement, and then propose heuristic replication for redundancy minimization (HRRM) to satisfy application’s reliability requirement with low time complexity. Experimental results on real and randomly generated parallel applications at different scales, parallelism, and heterogeneity verify that ERRM can generate least redundancy followed by HRRM, and the state-of-the-art MaxRe and RR algorithm. In addition, HRRM implements approximate minimum redundancy with a short computation time.",
"Compact, Popularity-Aware and Adaptive Hybrid Data Placement Schemes for Heterogeneous Cloud Storage","Cloud storage systems frequently have a large user base that requires huge cloud resources. Sometimes, cloud devices become overloaded because of an imbalance in input/output (I/O) or space demand. How can data with different popularity be distributed over heterogeneous devices? The key to resolving this problem is to balance the workload of multi-dimension resources. A consistent hash-aware cloud storage system constitutes a good solution for data placement. It can achieve only 1-D balance, usually the balance of the space resource. However, it is not straightforward to obtain a balance of space, I/O, and other resources simultaneously. Many users have experienced the overloading of devices in these systems. We focus mainly on this problem in this paper. In this paper, we discuss the factors that cause the overload of devices that occurs in the hash-aware cloud. Furthermore, we design some schemes with three algorithms to facilitate the assignment of hybrid data of different size and popularity to the heterogeneous cloud. The system can reduce the probability of an overload occurring. Most systems do not easily accommodate the movement of data. However, we argue that relocating part of the necessary data is helpful. This relocation can achieve a balance of resource usage and use fewer resources, without the need for replicas. Our system can provide a better quality of service, because the imbalance in the usage of resources is reduced. We performed an evaluation using extensive simulations driven by real-world traces. We demonstrate that our system can effectively reduce the overload probability of devices in cloud storage systems.",
Applications of Transductive Spectral Clustering Methods in a Military Medical Concussion Database,"Traumatic brain injury (TBI) is one of the most common forms of neurotrauma that has affected more than 250,000 military service members over the last decade alone. While in battle, service members who experience TBI are at significant risk for the development of normal TBI symptoms, as well as risk for the development of psychological disorders such as Post-Traumatic Stress Disorder (PTSD). As such, these service members often require intense bouts of medication and therapy in order to resume full return-to-duty status. The primary aim of this study is to identify the relationship between the administration of specific medications and reductions in symptomology such as headaches, dizziness, or light-headedness. Service members diagnosed with mTBI and seen at the Concussion Restoration Care Center (CRCC) in Afghanistan were analyzed according to prescribed medications and symptomology. Here, we demonstrate that in such situations with sparse labels and small feature sets, classic analytic techniques such as logistic regression, support vector machines, naïve Bayes, random forest, decision trees, and k-nearest neighbor are not well suited for the prediction of outcomes. We attribute our findings to several issues inherent to this problem setting and discuss several advantages of spectral graph methods.","Medical diagnostic imaging,
Databases,
Brain injuries,
Learning systems,
Bioinformatics"
Lessons learned from OSIRIS-REx autonomous navigation using natural feature tracking,"The Origins, Spectral Interpretation, Resource Identification, Security-Regolith Explorer (OSIRIS-REx) spacecraft launched on September 8, 2016 to embark on an asteroid sample return mission. It is expected to rendezvous with the asteroid, Bennu, navigate to the surface, collect a sample (July'20), and return the sample to Earth (September'23). The original mission design called for using one of two Flash Lidar units to provide autonomous navigation to the surface. Following Preliminary design and initial development of the Lidars, reliability issues with the hardware and test program prompted the project to begin development of an alternative navigation technique to be used as a backup to the Lidar. At the critical design review, Natural Feature Tracking (NFT) was added to the mission. NFT is an onboard optical navigation system that compares observed images to a set of asteroid terrain models which are rendered in real-time from a catalog stored in memory on the flight computer. Onboard knowledge of the spacecraft state is then updated by a Kalman filter using the measured residuals between the rendered reference images and the actual observed images. The asteroid terrain models used by NFT are built from a shape model generated from observations collected during earlier phases of the mission and include both terrain shape and albedo information about the asteroid surface. As a result, the success of NFT is dependent on selecting a set of topographic features that can be both identified during descent as well as reliably rendered using the shape model data available. During development, the OSIRIS-REx team faced significant challenges in developing a process conducive to robust operation. This was especially true for terrain models to be used as the spacecraft gets close to the asteroid and higher fidelity models are required for reliable image correlation. This paper will present some of the challenges and lessons learned from the development of the NFT system which includes not just the flight hardware and software but the development of the terrain models used to generate the onboard rendered images.",
Optimizing availability in CoMP and CA-enabled HetNets,"Traditional cellular networks are moving towards heterogenous cellular networks (HetNets) to satisfy the stringent demand for data rates and capacity. To enable the new applications in 5G, such as haptic communications, we face new challenges of achieving high availability with low latency in HetNets. In this paper, we introduce coordinated multi-point (CoMP) and carrier aggregation (CA) techniques in HetNets to guarantee the availability of all UEs, where CoMP improves the single-path availability, and CA enhances availability via multi carrier gain combining. To characterize the availability, we first derive an exact closed-form expression for the availability of a random UE in a CoMP&CA-enabled HetNets. To achieve the maximum UE availability, we formulate a max-min optimization problem. To solve it, we then propose a joint two-step optimization algorithm (JTOA), and our results showcase the effective of our proposed JTOA, and the effective of CoMP in availability improvement in HetNets.",
Multimodal Similarity Gaussian Process Latent Variable Model,"Data from real applications involve multiple modalities representing content with the same semantics from complementary aspects. However, relations among heterogeneous modalities are simply treated as observation-to-fit by existing work, and the parameterized modality specific mapping functions lack flexibility in directly adapting to the content divergence and semantic complicacy in multimodal data. In this paper, we build our work based on the Gaussian process latent variable model (GPLVM) to learn the non-parametric mapping functions and transform heterogeneous modalities into a shared latent space. We propose multimodal Similarity Gaussian Process latent variable model (m-SimGP), which learns the mapping functions between the intra-modal similarities and latent representation. We further propose multimodal distance-preserved similarity GPLVM (m-DSimGP) to preserve the intra-modal global similarity structure, and multimodal regularized similarity GPLVM (m-RSimGP) by encouraging similar/dissimilar points to be similar/dissimilar in the latent space. We propose m-DRSimGP, which combines the distance preservation in m-DSimGP and semantic preservation in m-RSimGP to learn the latent representation. The overall objective functions of the four models are solved by simple and scalable gradient decent techniques. They can be applied to various tasks to discover the nonlinear correlations and to obtain the comparable low-dimensional representation for heterogeneous modalities. On five widely used real-world data sets, our approaches outperform existing models on cross-modal content retrieval and multimodal classification.","Gaussian processes,
Semantics,
Data models,
Correlation,
Neural networks,
Laboratories,
Probabilistic logic"
Probabilistic Forecasting of Real-Time LMP and Network Congestion,"The short-term forecasting of real-time locational marginal price (LMP) and network congestion is considered from a system operator perspective. A new probabilistic forecasting technique is proposed based on a multiparametric programming formulation that partitions the uncertainty parameter space into critical regions from which the conditional probability distribution of the real-time LMP/congestion is obtained. The proposed method incorporates load/generation forecast, time varying operation constraints, and contingency models. By shifting the computation associated with multiparametric programs offline, the online computational cost is significantly reduced. An online simulation technique by generating critical regions dynamically is also proposed, which results in several orders of magnitude improvement in the computational cost over standard Monte Carlo methods.",
Two-Dimensional Precoding for 3-D Massive MIMO,"A 2-D precoding scheme is proposed for 3-D massive multiple-input multiple-output (MMIMO) systems for efficiently exploiting the 2-D antenna array of the base station. Specifically, by exploiting the Kronecker structure of the 3-D MIMO channel matrix, the transmit precoding operation is divided into elevation-domain precoding and azimuth-domain precoding. Explicitly, in contrast to the existing beamforming schemes, precoding is also performed in the vertical dimension. Consequently, the proposed scheme is capable of fully exploiting the extra degrees of freedom provided by the vertical dimension for avoiding the interuser interference to improve the attainable system performance. Compared to the conventional scheme relying on the equivalent 1-D precoding, the proposed 2-D precoding scheme offers an improved performance in severe intercell interference-contaminated environments, despite its lower complexity.",
Recycling Edge Devices in Sustainable Internet of Things Networks,"Internet of Things (IoT) devices have different operation principles, which weakens the data interoperability. Virtualization is an economic way of solving this problem. The data-collected by different vendors' sensors-share the same computing program encapsulated by the virtual machine (VM), so that the physical-layer difference can be hidden. To eliminate the extra cost and long delay of transferring VMs to the remote cloud, the edge device (ED) processes local VMs' requirements in prior. Hence, the sustainable strategy for recycling EDs is an important way to safeguard the network sustainability. To improve the recycling efficiency, most of the EDs should be upgraded simultaneously during one batch by migrating their local VMs to others for the service continuity. We investigate the least upgrade batch for recycling EDs in IoT networks. A two-step algorithm called minimized upgrade batch VM scheduling and bandwidth planning (MSBP) is designed to minimize the number of upgrade batches. As the frequent VM migration brings the bandwidth consumption and contention of trajectories, in our MSBP, two strategies: 1) shortest trajectory first and 2) least bandwidth utilization first (LBUF), are also considered. The simulation results show that: 1) MSBP has the optimal recycling efficiency (least number of upgrade batches) for EDs and 2) LBUF more effectively mitigates the negative impact of the path contention level on the recycling efficiency.","Bandwidth,
Trajectory,
Recycling,
Optical fiber communication,
Batteries,
Internet of Things,
Optical sensors"
A Fully Integrated Broadband Sub-mmWave Chip-to-Chip Interconnect,"A new type of broadband link enabling extremely high-speed chip-to-chip communication is presented. The link is composed of fully integrated sub-mmWave on-chip traveling wave power couplers and a low-cost planar dielectric waveguide. This structure is based on a differentially driven half-mode substrate integrated waveguide supporting the first higher order hybrid microstrip mode. The cross-sectional width of the coupler structure is tapered in the direction of wave propagation to increase the coupling efficiency and maintain a large coupling bandwidth while minimizing its on-die size. A rectangular dielectric waveguide, constructed from Rogers Corporation R3006 material, is codesigned with the on-chip coupler structure to minimize coupling loss. The coupling structure achieves an average insertion loss of 4.8 dB from 220 to 270 GHz, with end-to-end link measurements presented. This system provides a packaging-friendly, cost effective, and high performance planar integration solution for ultrabroadband chip-to-chip communication utilizing millimeter waves.","Couplers,
Bandwidth,
Couplings,
System-on-chip,
Silicon,
Optical waveguides,
Dielectrics"
Energy-Efficient Power Delivery System Paradigms for Many-Core Processors,"The design of power delivery system plays a crucial role in guaranteeing the proper functionality of many-core processor systems. The power loss suffered on power delivery has become a salient part of total power consumption, and the energy efficiency of a highly dynamic system has been significantly challenged. Being able to achieve a fast response time and multiple voltage domain control, on-chip voltage regulators (VRs) have become popular choices to enable fine-grain power management, which also enlarge the design space of power delivery systems. This paper analytically studies different power delivery system paradigms and power management schemes in terms of energy efficiency, area overhead, and power pin occupation. The analysis shows that compared to the conventional paradigm with off-chip VRs, hybrid paradigms with both on-chip and off-chip VRs are able to maintain high efficiency in a larger range of workloads, though they suffer from low efficiency at light workload. Employed with the quantized power management scheme, the hybrid paradigm can improve the system energy efficiency at light workload by a maximum of 136% compared to the traditional load balanced scheme. Besides this, the in-package (iP) hybrid paradigm further shows its advantage in reducing the physical overheads. The results reveal that at 120 W workload, it occupies only a 10.94% total footprint area or 39.07% power pins of that of the off-chip paradigm. We conclude that the iP hybrid paradigm achieves the best tradeoffs between efficiency, physical overhead, and realization of fine-grain power management.","Voltage control,
Regulators,
System-on-chip,
Inductors,
Program processors,
Switches,
Electric potential"
An Asymmetric Distributed Method for Sorting a Robot Swarm,"We consider the problem of sorting a swarm of labeled robots in Euclidean space. Our goal is to organize the robots into a sorted and equally-spaced straight line between the robots with lowest and highest labels, while maintaining a connected communication network. We break the symmetry between the minimum and maximum, in order to keep time, travel distance, and communication costs low, without using central control. We run in parallel a set of functions, including leader election, tree formation, path formation, path modification, and geometric straightening. We show that our algorithm is safe, correct, efficient, and robust to changes in population and connectivity. We validate our theoretical results with simulations. Our implementation uses messages of fixed size and robots of constant memory, and is a practical solution for large populations of low-cost robots.","Robot kinematics,
Robot sensing systems,
Sorting,
Collision avoidance,
Mobile robots,
Algorithm design and analysis"
Choice of Sampling Interval and Extent for Finite-Energy Fields,"We focus on the problem of representing a nonstationary finite-energy random field, with finitely many samples. We do not require the field to be of finite extent or to be bandlimited. We propose an optimizable procedure for obtaining a finite-sample representation of the given field. We estimate the reconstruction error of the procedure, showing that it is the sum of the truncation errors in the space and frequency domains. We also optimize the truncation parameters analytically and present the resultant Pareto-optimal tradeoff curves involving the error in reconstruction and the sample count, for several examples. These tradeoff curves can be used to determine the optimal sampling strategy in a practical situation based on the relative importance of error and sample count for that application.","Fourier transforms,
Image reconstruction,
Splines (mathematics),
Interpolation,
Frequency-domain analysis,
Error analysis"
A Weighted Crowdsourcing Approach for Network Quality Measurement in Cellular Data Networks,"With ubiquitous smartphone usages, it is important for network providers to provide high-quality service to every user in the network. To make more effective planning and scheduling, network providers need an accurate estimate of network quality for base stations and cells from the perspective of user experience. Traditional drive testing approach provides a quality measurement for each area and the quality measurement is obtained from the equipment in a moving vehicle. This approach suffers from the limitations of high costs, low coverage, and out-of-date values. In this paper, we propose a novel crowdsourcing approach for the task of network quality estimation, which incurs little costs and provides timely and accurate quality estimation. The proposed approach collects quality measurements from individual end users within a certain network or cell coverage area, and then aggregates these measurements to obtain a global measurement of network quality. We propose an effective aggregation scheme which infers the information weights of end users and incorporates such weights into the estimation of network quality. Experiments are conducted on two datasets collected from citywide 3G networks, which involve 616,796 users and 22,715 cells. We validate the effectiveness of the proposed approach compared with baseline method. From the aggregated measurement results, we observe some interesting patterns about network quality, which can be explained by network usage and traffic behavior. We also show that proposed approach runs in linear time.",
IF-Matching: Towards Accurate Map-Matching with Information Fusion,"With the advance of various location-acquisition technologies, a myriad of GPS trajectories can be collected every day. However, the raw coordinate data captured by sensors often cannot reflect real positions due to many physical constraints and some rules of law. How to accurately match GPS trajectories to roads on a digital map is an important issue. The problem of map-matching is fundamental for many applications. Unfortunately, many existing methods still cannot meet stringent performance requirements in engineering. In particular, low/unstable sampling rate and noisy/lost data are usually big challenges. Information fusion of different data sources is becoming increasingly promising nowadays. As in practice, some other measurements such as speed and moving direction are collected together with the spatial locations acquired, we can make use of not only location coordinates but all data collected. In this paper, we propose a novel model using the related meta-information to describe a moving object, and present an algorithm called IF-Matching for map-matching. It can handle many ambiguous cases which cannot be correctly matched by existing methods. We run our algorithm with taxi trajectory data on a city-wide road network. Compared with two state-of-the-art algorithms of ST-Matching and the winner of GIS Cup 2012, our approach achieves more accurate results.","Roads,
Trajectory,
Public transportation,
Global Positioning System,
Uncertainty,
Measurement errors,
Sensors"
Successive bandwidth division NOMA systems: Uplink power allocation with proportional fairness,"Non-orthogonal multiple access (NOMA) is considered as a promising candidate for fifth generation (5G) wireless networks. Although, NOMA promises large data rates, however, it also offers significant interference especially when the number of users is large. Therefore, in this paper, we propose a low complexity orthogonal frequency division multiple access (OFDMA)-based NOMA system, which uses the concept of successive bandwidth division (SBD) that not only reduces the complexity of the receiver, but also enhances the overall signal-to-interference plus noise ratio (SINR) of the uplink NOMA by supporting 2N users with just N base station (BS) antennas. Power allocation is being performed in SBD-NOMA to maximize the sum rate using a divide-and-allocate approach such that all users are allocated with an optimal transmission power. Simulations results are provided to access and compare the performance of the proposed scheme with other contemporary approaches.","NOMA,
Resource management,
Interference,
Uplink,
Complexity theory,
Bandwidth,
Receivers"
Focusing Properties of Single-Focus Photon Sieve,"In this letter, we present a single-focus photon sieve (SFPS), which can produce single focus with suppressed sidelobes, featuring a higher signal-to-noise ratio and improved image contrast. This is achieved through combining single-focus zone plates (SZPs) and photon sieves (PSs). Simulations and experiments were conducted to verify the single focusing property of SFPSs. The results illustrated the advantages of SFPSs over conventional PSs, as well as improved resolution compared with SZPs in terms of the same specific minimum feature size. SFPSs are extremely promising to replace PSs and Fresnel zone plates in the fields such as X-ray focusing, imaging, and nanometer lithography.","Photonics,
Manganese,
Focusing,
Modulation,
Signal to noise ratio,
X-ray imaging"
Survey of Security Advances in Smart Grid: A Data Driven Approach,"With the integration of advanced computing and communication technologies, smart grid is considered as the next-generation power system, which promises self healing, resilience, sustainability, and efficiency to the energy critical infrastructure. The smart grid innovation brings enormous challenges and initiatives across both industry and academia, in which the security issue emerges to be a critical concern. In this paper, we present a survey of recent security advances in smart grid, by a data driven approach. Compared with existing related works, our survey is centered around the security vulnerabilities and solutions within the entire lifecycle of smart grid data, which are systematically decomposed into four sequential stages: 1) data generation; 2) data acquisition; 3) data storage; and 4) data processing. Moreover, we further review the security analytics in smart grid, which employs data analytics to ensure smart grid security. Finally, an effort to shed light on potential future research concludes this paper.",
Miniaturized Broadband Coupler Made of Slow-Wave Half-Mode Substrate Integrated Waveguide,"In this work, a size-reduced wideband coupler is presented and demonstrated, which explores the slow-wave half-mode substrate integrated waveguide (SW-HMSIW) technique on a printed circuit board process. The SW-HMSIW coupler is composed of two SW-HMSIW transmission lines loaded with a polyline network. Along the coupler, energy is coupled by the electric and magnetic field between the two parallel SW-HMSIW lines. Compared with conventional microstrip coupler, the proposed coupler presents lower loss owning to the HWSIW structure performance. In addition, the proposed SW-HMSIW coupler exhibits a smaller size against its SIW and HWSIW counterparts, thanks to slow-wave effects of the loaded polyline. Measured and simulated results are in a good agreement.","Couplers,
Substrates,
Wireless communication,
Microstrip,
Ports (Computers),
Transmission line measurements,
Frequency measurement"
SimGrid VM: Virtual Machine Support for a Simulation Framework of Distributed Systems,"As real systems become larger and more complex, the use of simulator frameworks grows in our research community. By leveraging them, users can focus on the major aspects of their algorithm, run in-siclo experiments (i.e., simulations), and thoroughly analyze results, even for a large-scale environment without facing the complexity of conducting in-vivo studies (i.e., on real testbeds). Since nowadays the virtual machine (VM) technology has become a fundamental building block of distributed computing environments, in particular in cloud infrastructures, our community needs a full-fledged simulation framework that enables us to investigate large-scale virtualized environments through accurate simulations. To be adopted, such a framework should provide easy-to-use APIs as well as accurate simulation results. In this paper, we present a highly-scalable and versatile simulation framework supporting VM environments. By leveraging SimGrid, a widely-used open-source simulation toolkit, our simulation framework allows users to launch hundreds of thousands of VMs on their simulation programs and control VMs in the same manner as in the real world (e.g., suspend/resume and migrate). Users can execute computation and communication tasks on physical machines (PMs) and VMs through the same SimGrid API, which will provide a seamless migration path to IaaS simulations for hundreds of SimGrid users. Moreover, SimGrid VM includes a live migration model implementing the precopy migration algorithm. This model correctly calculates the migration time as well as the migration traffic, taking account of resource contention caused by other computations and data exchanges within the whole system. This allows user to obtain accurate results of dynamic virtualized systems.We confirmed accuracy of both the VM and the live migration models by conducting several micro-benchmarks under various conditions. Finally, we conclude the article by presenting a first usecase of one consolidation algorithm dealing with a significant number of VMs/PMs. In addition to confirming the accuracy and scalability of our framework, this first scenario illustrates the main interest of SimGrid VM: investigating through in-siclo experiments pros/cons of new algorithms in order to limit expensive in-vivo experiments only to the most promising ones.","Computational modeling,
Workstations,
Cloud computing,
Virtual machining,
Engines,
Databases,
Servers"
Securing the hardware of cyber-physical systems,"The cyber-physical system (CPS) paradigm offers tremendous advantages in many application scenarios and promises a solution to a large number of pressing individual and societal needs. However, their properties such as heterogeneity, lack of perimeter protection, longevity, pervasive diffusion and strictly constrained resources also give rise to new security vulnerabilities. In this paper, we discuss security threats related to the hardware blocks of a CPS. We first review attack scenarios affecting security attributes confidentiality, integrity and authenticity, and then outline novel attack vectors that target the cyber and the physical aspects of a CPS simultaneously.","Hardware,
Trojan horses,
Security,
Circuit faults,
Cyber-physical systems,
Sensors"
Keyword Search With Access Control Over Encrypted Cloud Data,"In this paper, we study the problem of keyword search with access control (KSAC) over encrypted data in cloud computing. We first propose a scalable framework where user can use his attribute values and a search query to locally derive a search capability, and a file can be retrieved only when its keywords match the query and the user's attribute values can pass the policy check. Using this framework, we propose a novel scheme called KSAC, which enables keyword search with access control over encrypted data. KSAC utilizes a recent cryptographic primitive called hierarchical predicate encryption to enforce fine-grained access control and perform multi-field query search. Meanwhile, it also supports the search capability deviation, and achieves efficient access policy update as well as keyword update without compromising data privacy. To enhance the privacy, KSAC also plants noises in the query to hide users' access privileges. Intensive evaluations on real-world dataset are conducted to validate the applicability of the proposed scheme and demonstrate its protection for user's access privilege.","Access control,
Servers,
Keyword search,
Encryption,
Indexes,
Sensors"
A RISC-V Processor SoC With Integrated Power Management at Submicrosecond Timescales in 28 nm FD-SOI,"This paper presents a RISC-V system-on-chip (SoC) with integrated voltage regulation, adaptive clocking, and power management implemented in a 28 nm fully depleted silicon-on-insulator process. A fully integrated simultaneous-switching switched-capacitor DC-DC converter supplies an application core using a clock from a free-running adaptive clock generator, achieving high system conversion efficiency (82%-89%) and energy efficiency (41.8 double-precision GFLOPS/W) while delivering up to 231 mW of power. A second core serves as an integrated power-management unit that can measure system state and actuate changes to core voltage and frequency, allowing the implementation of a wide variety of power-management algorithms that can respond at submicrosecond timescales while adding just 2.0% area overhead. A voltage dithering program allows operation across a wide continuous voltage range (0.45 V-1 V), while an adaptive voltage-scaling algorithm reduces the energy consumption of a synthetic benchmark by 39.8% with negligible performance penalty, demonstrating practical microsecond-scale power management for mobile SoCs.","Clocks,
Voltage control,
Generators,
Delays,
Electrical engineering,
Adaptive systems,
Switches"
Efficient Unsupervised Temporal Segmentation of Motion Data,"We introduce a method for automated temporal segmentation of human motion data into distinct actions and compositing motion primitives based on self-similar structures in the motion sequence. We use neighborhood graphs for the partitioning and the similarity information in the graph is further exploited to cluster the motion primitives into larger entities of semantic significance. The method requires no assumptions about the motion sequences at hand and no user interaction is required for the segmentation or clustering. In addition, we introduce a feature bundling preprocessing technique to make the segmentation more robust to noise, as well as a notion of motion symmetry for more refined primitive detection. We test our method on several sensor modalities, including markered and markerless motion capture as well as on electromyograph and accelerometer recordings. The results highlight our system's capabilities for both segmentation and for analysis of the finer structures of motion data, all in a completely unsupervised manner.","Motion segmentation,
Hidden Markov models,
Data models,
Computer vision,
Principal component analysis,
Robustness,
Accelerometers"
"\mu
-Stability of Nonlinear Positive Systems With Unbounded Time-Varying Delays","The stability of the zero solution plays an important role in the investigation of positive systems. In this brief, we discuss the μ-stability of positive nonlinear systems with unbounded time-varying delays. The system is modeled by the continuous-time ordinary differential equation. Under some assumptions on the nonlinear functions, such as homogeneous, cooperative, and nondecreasing, we propose a novel transform, by which the nonlinear system reduces to a new system. Thus, we analyze its dynamics, which can simplify the nonlinear homogenous functions with respect to the arbitrary dilation map to those with respect to the standard dilation map. We finally get some new criteria for the global μ-stability taking the degree into consideration. A numerical example is given to demonstrate the validity of obtained results.","Delays,
Asymptotic stability,
Stability criteria,
Time-varying systems,
Numerical stability,
Transforms"
Efficient and Robust Corner Detectors Based on Second-Order Difference of Contour,"As one of the most significant local features of image, corner is widely used in many computer vision tasks. Corner detection aims to achieve the highest possible detection accuracy while minimizing the computational complexity. In this letter, we first introduce a new measurement termed as second-order difference of contour (SODC), and then examine its regular distribution, which is found to provide useful information to distinguish corners from noncorners. Based on the SODC distribution characteristics, we propose two novel corner detectors to measure the response of contour points using Manhattan distance and Euclidean distance, respectively. Numerical experiments demonstrate that the Manhattan detector greatly decreases the computational complexity, while the Euclidean detector outperforms the state-of-the-art corner detectors in terms of repeatability and localization error.","Detectors,
Cascading style sheets,
Computational complexity,
Robustness,
Euclidean distance,
Indexes"
High-speed power MOSFET with low reverse transfer capacitance using a trench/planar gate architecture,"A trench/planar MOSFET (TP-MOS) is proposed in this work as a high speed switching device. The device is comprehensively studied with numerical simulations, and comparisons are made with the conventional MOSFET (C-MOS) and the split-gate MOSFET (SG-MOS). Compared to the C-MOS, the removal of the MOS-structure above the JFET region results in a dramatic reduction of the reverse transfer capacitance (Crss) in the SG-MOS and TP-MOS. The top p-base in the TP-MOS expedites the depletion in the JFET region, which helps further reduce the Crss and alleviates the electric field crowding. The additional trench channels in the TP-MOS lowers the total channel resistance, which compensates the increase of JFET resistance caused by the absence of the electron accumulation layer under the MOS-structure. Therefore, the TP-MOS achieves the best RON-Crss trade-off.","electric fields,
field effect transistor switches,
numerical analysis,
power MOSFET,
power semiconductor switches,
semiconductor device models"
"A Data Mining Approach Combining
K
-Means Clustering With Bagging Neural Network for Short-Term Wind Power Forecasting","Wind power forecasting (WPF) is significant to guide the dispatching of grid and the production planning of wind farm effectively. The intermittency and volatility of wind leading to the diversity of the training samples have a major impact on the forecasting accuracy. In this paper, to deal with the training samples dynamics and improve the forecasting accuracy, a data mining approach consisting of K-means clustering and bagging neural network (NN) is proposed for short-term WPF. Based on the similarity among historical days, K-means clustering is used to classify the samples into several categories, which contain the information of meteorological conditions and historical power data. In order to overcome the over fitting and instability problems of conventional networks, a bagging based ensemble approach is integrated into the back propagation NN. To confirm the effectiveness, the proposed data mining approach is examined on real wind generation data traces. The simulation results show that it can obtain better forecasting accuracy than other baseline and existed short-term WPF approaches.","Forecasting,
Wind power generation,
Training,
Autoregressive processes,
Wind speed,
Wind turbines,
Neural networks"
The case for semi-automated design of microfluidic very large scale integration (mVLSI) chips,"In recent years, significant interest has emerged in the problem of fully automating the design of microfluidic very large scale integration (mVLSI) chips, a popular class of Lab-on-a-Chip (LoC) devices that can automatically execute a wide variety of biological assays. To date, this work has been carried out with little to no input from LoC designers. We conducted interviews with approximately 100 LoC designers, biologists, and chemists from academia and industry; uniformly, they expressed frustration with existing design solutions, primarily commercially available software such as AutoCAD and Solidworks; however, they expressed limited interest and considerable skepticism about the potential for “push-button” end-to-end automation. In response, we have developed a semi-automated mVLSI drawing tool that is designed specifically to address the pain points elucidated by our interviewees. We have used this tool to rapidly reproduce several previously published LoC architectures and generate fabrication ready specifications.","Software,
Algorithm design and analysis,
Pain,
Routing,
Fabrication,
Microvalves,
Automation"
Laser Spike Annealing for Shallow Junctions in Ge CMOS,"An annealing method capable of forming highly activated shallow junctions in Ge CMOS is still lacking. For the first time, nonmelt submillisecond laser spike annealing (LSA) is demonstrated to achieve high activation level, excellent diffusion control, and resulting low contact resistivity for both n-type and p-type Ge junctions when using P and B as the dopants, respectively. The thermal stability of the junctions activated by LSA is investigated. In addition, our results on Ge junctions and contacts are benchmarked systematically against published results using sheet resistance-junction depth (Rs -Xj) plots and contact resistivity-dopant concentration (ρc - N) plots.","Junctions,
Annealing,
Semiconductor lasers,
Resistance,
Thermal stability,
Solids,
Temperature measurement"
TLP measurement and analysis of graphene NEMS switches for on-chip ESD protection,"Compact and robust electrostatic discharging (ESD) protection structures are critical to on-chip ESD protection for ICs. Conventional in-Si ESD protection structures have many disadvantages. A new above-IC graphene NEMS (gNEMS) switch is reported as an ESD protection structure, which features almost zero leakage and robust ESD protection. A systematic characterization of gNEMS ESD structures was conducted by transient transmission line pulse (TLP) testing. The statistical analysis reveals the relationship between ESD discharging behaviors and the influences of gNEMS device dimensions and TLP testing conditions on ESD discharging.","Electrostatic discharges,
Graphene,
Testing,
Integrated circuits,
Transient analysis,
Current measurement,
Pollution measurement"
Majority logic circuits optimisation by node merging,"Quantum-dot Cellular Automata (QCA) has emerged as a new design paradigm for nanotechnologies. Since the operational logic in QCA is the majority logic, much research about the synthesis and optimisation of majority logic has been proposed recently. In this paper, we propose an optimisation method by merging nodes in the Majority-Inverter-Graph, which is the representation of majority logic circuits. Instead of using satisfiability solvers, our approach can identify the node mergers by using logic implications for circuit size reduction. The experimental results show that for a set of EPFL benchmarks, our approach can minimise the node count by 21% when integrated with the state-of-the-art on average.","Logic gates,
Circuit faults,
Merging,
Logic circuits,
Optimization,
Wires,
Inverters"
Approximate MMSE Estimator for Linear Dynamic Systems With Gaussian Mixture Noise,"In this work, we propose an approximate minimum mean-square error filter for linear dynamic systems with Gaussian Mixture (GM) noise. The proposed estimator tracks each component of the GM posterior with an individual filter and minimizes the trace of the covariance matrix of the bank of filters, as opposed to minimizing the MSE of individual filters filters in the commonly used Gaussian sum filter (GSF). Hence, the spread of means in the proposed method is smaller than that of GSF which makes it more robust to removing components. Consequently, reduction schemes with lower computational complexity can be used with the proposed filter without losing estimation accuracy and precision. This is supported through simulations on synthetic data as well as experimental data related to an indoor localization system. Additionally, we show that in two limit cases the state estimation provided by our proposed method converges to that of GSF, and we provide simulation results supporting this in other cases.","Noise measurement,
Covariance matrices,
Kalman filters,
Current measurement,
State estimation,
Mathematical model"
Coprime array adaptive beamforming with enhanced degrees-of-freedom capability,"In this paper, we propose a novel coprime array adaptive beamforming algorithm based on virtual array spatial spectrum estimation to enhance the degrees-of-freedom (DOFs) capability. Specifically, the coprime array received signals are derived to virtual domain, where the spectrum estimation is performed on an equivalent virtual uniform linear array. Since the virtual array contains more virtual sensors than physical sensors, the DOFs capability is effectively enhanced. Meanwhile, the large array aperture offered by coprime array provides a higher resolution than uniform linear array. With the estimated sources' directions and interferences' power, the coprime array adaptive beamformer is designed by reconstructing the interference-plus-noise covariance matrix and desired signal steering vector. Simulation results demonstrate the effectiveness of the proposed adaptive beamforming algorithm.",
Plug-and-Play Voltage Stabilization in Inverter-Interfaced Microgrids via a Robust Control Strategy,"This paper proposes a decentralized control strategy for the voltage regulation of islanded inverter-interfaced microgrids. We show that an inverter-interfaced microgrid under plug-and-play (PnP) functionality of distributed generations (DGs) can be cast as a linear time-invariant system subject to polytopic-type uncertainty. Then, by virtue of this novel description and use of the results from theory of robust control, the microgrid control system guarantees stability and a desired performance even in the case of PnP operation of DGs. The robust controller is a solution of a convex optimization problem. The main properties of the proposed controller are that: 1) it is fully decentralized and local controllers of DGs that use only local measurements; 2) the controller guarantees the stability of the overall system; 3) the controller allows PnP functionality of DGs in microgrids; and 4) the controller is robust against microgrid topology change. Various case studies, based on time-domain simulations in MATLAB/SimPowerSystems Toolbox, are carried out to evaluate the performance of the proposed control strategy in terms of voltage tracking, microgrid topology change, PnP capability features, and load changes.","Microgrids,
Voltage control,
Power system stability,
Stability analysis,
Topology,
Frequency control,
Control systems"
Optimal Design of SWIPT Systems With Multiple Heterogeneous Users Under Non-linear Energy Harvesting Model,"This paper investigates the optimal power minimization design of simultaneous wireless information and power transfer systems under non-linear energy harvesting (EH) model, where a multi-antenna hybrid access point (H-AP) simultaneously transmits information and power to multiple heterogeneous users, such as information-energy receivers (IERs), information receivers (IRs), and ERs. Power splitting (PS) receiver architecture is adopted at all IERs. In order to achieve green system design, an optimization problem is formulated to minimize the transmit power of H-AP subject to the required signal-to-interference-plusnoise ratios (SINRs) constraints at IERs and IRs, and the harvested energy constrains at IERs and ERs, by jointly optimizing the beamforming vector at H-AP and the PS ratios at IERs. Since the problem is nonconvex and the employ of the non-linear EH model makes it more difficult to solve, the semidefinite relaxation and variable substitutions are used to handle it. For some cases, we theoretically prove that the globe optimal solution can be guaranteed by using our method, and for rest cases, we discuss its optimality via simulations. Numerical results show that although the traditional linear EH model is feasible for the practical EH circuits in some cases, the corresponding system consumes more transmit power than that under the non-linear model EH. Moreover, the effects of the numbers of users, the required SINRs, and the harvested energy on the system transmit power are also discussed.","Erbium,
Receivers,
Integrated circuit modeling,
RF signals,
Numerical models,
Wireless sensor networks,
Wireless communication"
An Overview and Classification of Service Description Approaches in Automated Service Composition Research,"In recent years, automated service composition has been a fervid research area in service computing. Within this area, service description plays a crucial role in terms of the development of a diverse number of automation schemes. In this paper, we provide an investigation and classification of the service description approaches that have been used in a diverse collection of automated service composition studies. To position the service description approaches used in automated service composition throughout the service description world and to clearly classify them, we propose five two-value dimensions. Using the proposed dimensions, we first perform a categorization and provide a simple introduction to current representative industrial service description standards. Subsequently, because we discovered that most of the studied automated composition approaches follow a tuple-based service description paradigm, an exhaustive classification and discussion of this paradigm is made, with the automated composition approaches adopting this paradigm as an example. Finally, we discuss issues that are currently relevant to the service description field and possible solutions. With this study, the reader can obtain a complete understanding of service description approaches used in automated service composition research, including their common formulation and assumptions.","Standards,
Semantics,
Syntactics,
Simple object access protocol,
Ontologies,
Quality of service,
Computer science"
A Fast Asymmetric Extremum Content Defined Chunking Algorithm for Data Deduplication in Backup Storage Systems,"Chunk-level deduplication plays an important role in backup storage systems. Existing Content-Defined Chunking (CDC) algorithms, while robust in finding suitable chunk boundaries, face the key challenges of (1) low chunking throughput that renders the chunking stage a serious deduplication performance bottleneck, (2) large chunk size variance that decreases deduplication efficiency, and (3) being unable to find proper chunk boundaries in low-entropy strings and thus failing to deduplicate these strings. To address these challenges, this paper proposes a new CDC algorithm called the Asymmetric Extremum (AE) algorithm. The main idea behind AE is based on the observation that the extreme value in an asymmetric local range is not likely to be replaced by a new extreme value in dealing with the boundaries-shifting problem. As a result, AE has higher chunking throughput, smaller chunk size variance than the existing CDC algorithms, and is able to find proper chunk boundaries in low-entropy strings. The experimental results based on realworld datasets show that AE improves the throughput performance of the state-of-the-art CDC algorithms by more than 2.3×, which is fast enough to remove the chunking-throughput performance bottleneck of deduplication, and accelerates the system throughput by more than 50 percent, while achieving comparable deduplication efficiency.","Throughput,
Optimization,
Power capacitors,
Approximation algorithms,
Redundancy,
Robustness,
Acceleration"
Random Access and Virtual Resource Allocation in Software-Defined Cellular Networks With Machine-to-Machine Communications,"Machine-to-machine (M2M) communications have attracted great attention from both academia and industry. In this paper, with recent advances in wireless network virtualization and software-defined networking (SDN), we propose a novel framework for M2M communications in software-defined cellular networks with wireless network virtualization. In the proposed framework, according to different functions and quality-of-service (QoS) requirements of machine-type communication devices, a hypervisor enables the virtualization of the physical M2M network, which is abstracted and sliced into multiple virtual M2M networks. In addition, we develop a decision-theoretic approach to optimize the random access process of M2M communications. Furthermore, we develop a feedback and control loop to dynamically adjust the number of resource blocks that are used in the random access phase in a virtual M2M network by the SDN controller. Extensive simulation results with different system parameters are presented to show the performance of the proposed scheme.","Machine-to-machine communications,
Wireless networks,
Virtualization,
Cellular networks,
Quality of service,
Resource management,
Computer architecture"
An infrastructure as a Service for Mobile Ad-hoc Cloud,"In this era of growing mobile device technology, the direction of growth is moving towards providing powerful computational capabilities and expanding memory in the device. Nevertheless, this growth has objectively put a lot of the device computational power to an unused state which calls for a better management of intra-device resources. Over a period of time, it has been studied that a mobile “edge-cloud” formed by these devices could be as productive or close to the productivity of the public cloud in terms of providing a service. However, the ease of access to this pool of devices is much more arbitrary and based purely on the needs of the user. This could categorically be summed as the building block of a cloud built for providing an infrastructure for various services that can be processed with volunteer node participation. This representation of cloud formation to engender a constellation of devices in turn providing a service is the basis for the concept of Mobile Ad-hoc Cloud Computing. In this manuscript, an Infrastructure as a Service paradigm in Mobile Ad-hoc Cloud Computing is delineated. A novel architecture for discovering a dedicated pool of devices and the dependencies it should satisfy while formation of this pool for computation is designed. Moreover, a peer-to-peer composition algorithm to form this dedicated resource pool is proposed.","Cloud computing,
Mobile communication,
Ad hoc networks,
Computer architecture,
Mobile handsets,
Mobile computing,
Performance evaluation"
Construction and Encoding of QC-LDPC Codes Using Group Rings,"Quasi-cyclic (QC) low-density parity-check (LDPC) codes which are known as QC-LDPC codes, have many applications due to their simple encoding implementation by the means of cyclic shift registers. In this paper, we construct QC-LDPC codes from group rings. A group ring is a free module (at the same time a ring) constructed in a natural way from any given ring and any given group. We present a structure based on the elements of a group ring for constructing QC-LDPC codes. Some of the previously addressed methods for constructing QC-LDPC codes based on finite fields are special cases of the proposed construction method. The constructed QC-LDPC codes perform very well over the additive white Gaussian noise channel with iterative decoding in terms of bit-error probability and block-error probability. Simulation results demonstrate that the proposed codes have competitive performance in comparison with the similar existing LDPC codes. Finally, we propose a new encoding method for the proposed group ring-based QC-LDPC codes that can be implemented faster than the current encoding methods. The encoding complexity of the proposed method is analyzed mathematically, and indicates a significate reduction in the required number of operations, even when compared to the available efficient encoding methods that have linear time and space complexities.","Channel coding,
Complexity theory,
AWGN channels,
Iterative decoding,
Decoding"
Privacy-Preserving Image Denoising From External Cloud Databases,"Along with the rapid advancement of digital image processing technology, image denoising remains a fundamental task, which aims to recover the original image from its noisy observation. With the explosive growth of images on the Internet, one recent trend is to seek high quality similar patches at cloud image databases and harness rich redundancy therein for promising denoising performance. Despite the well-understood benefits, such a cloud-based denoising paradigm would undesirably raise security and privacy issues, especially for privacy-sensitive image data sets. In this paper, we initiate the first endeavor toward privacy-preserving image denoising from external cloud databases. Our design enables the cloud hosting encrypted databases to provide secure query-based image denoising services. Considering that image denoising intrinsically demands high quality similar image patches, our design builds upon recent advancements on secure similarity search, Yao's garbled circuits, and image denoising operations, where each is used at a different phase of the design for the best performance. We formally analyze the security strengths. Extensive experiments over real-world data sets demonstrate that our design achieves the denoising quality close to the optimal performance in plaintext.","Image denoising,
Noise reduction,
Cryptography,
Databases,
Cloud computing,
Noise measurement"
Hierarchical Contextual Attention Recurrent Neural Network for Map Query Suggestion,"The query logs from an on-line map query system provide rich cues to understand the behaviors of human crowds. With the growing ability of collecting large scale query logs, the query suggestion has been a topic of recent interest. In general, query suggestion aims at recommending a list of relevant queries w.r.t. users' inputs via an appropriate learning of crowds' query logs. In this paper, we are particularly interested in map query suggestions (e.g., the predictions of location-related queries) and propose a novel model Hierarchical Contextual Attention Recurrent Neural Network (HCAR-NN) for map query suggestion in an encoding-decoding manner. Given crowds map query logs, our proposed HCAR-NN not only learns the local temporal correlation among map queries in a query session (e.g., queries in a short-term interval are relevant to accomplish a search mission), but also captures the global longer range contextual dependencies among map query sessions in query logs (e.g., how a sequence of queries within a short-term interval has an influence on another sequence of queries). We evaluate our approach over millions of queries from a commercial search engine (i.e., Baidu Map). Experimental results show that the proposed approach provides significant performance improvements over the competitive existing methods in terms of classical metrics (i.e., Recall@K and MRR) as well as the prediction of crowds' search missions.","Context modeling,
Data models,
Recurrent neural networks,
Computational modeling,
Predictive models,
Correlation"
Technological requirements for microwave ablation of adrenal masses,"Microwave thermal ablation is under consideration for minimally invasive treatment of bilateral adrenal adenomas, symptomatic of Conn's syndrome. Currently available microwave technologies are ill-suited to precise ablation of small adrenal targets. We report on our preliminary computational and experimental efforts towards the design of microwave ablation systems for targeting adrenal masses. Broadband dielectric properties of ex vivo bovine adrenal glands were experimentally measured. Computer simulations demonstrated the feasibility of achieving precise ablation of adrenal lesions with 2.45 GHz systems. Experiments in ex vivo adrenal tissue using a water-cooled 2.45 GHz antenna illustrated the feasibility of heating 10–20 mm adrenal targets with 40 W power applied for 1 min. These preliminary results warrant further investigation and development of microwave technology for precise ablation of adrenal masses.","Glands,
Antenna measurements,
Dielectric measurement,
Dielectrics,
Temperature measurement,
Microwave antennas"
Fuzzy Wavelet Polynomial Neural Networks: Analysis and Design,"In this study, we propose a concept of fuzzy wavelet polynomial neural networks (FWPNNs) based on concepts and constructs of polynomial neural networks and fuzzy wavelet neurons (FWNs). These networks exhibit a rule-based architecture while each rule in the FWN consists of the premise part and consequence part. The premise part is realized by using C-means clustering method, while the consequence part is realized by means of wavelet functions whose parameters are estimated with the aid of the least square method. In some sense, the FWPNN can be regarded as a generalized fuzzy wavelet neural network (FWNN). Unlike Gaussian membership functions that are commonly utilized to implement the premise part of the rules in typical FWNNs, C-means method is employed here to overcome a possible curse of dimensionality. Polynomial neural networks (PNNs) are used to express the nonlinearity of a complex system. Furthermore, the particle swarm optimization is used to optimize the design parameters of the proposed network. Based on the PNNs and FWNNs, the proposed FWPNNs take advantages of these two neural networks: it exhibits the abilities to describe high-order nonlinear relations between input and output variables and it is beneficial to describe models impacted by uncertainty. The proposed FWPNNs are applied for time-series prediction and regression problems (e.g., control of dynamic plants). Several well-known modeling benchmarks including regression and time series are considered to evaluate the performance of the proposed FWPNNs. A comparative analysis shows that the proposed FWPNNs result in better performance when comparing with some previous models reported in the literature.","Neurons,
Biological neural networks,
Particle swarm optimization,
Computers,
Electronic mail,
Input variables"
Extending formal concept analysis using intuitionistic l-fuzzy sets,A two-fold general approach to the theory of formal concept analysis is introduced by considering intuitionistic fuzzy sets valued on a residuated lattice as underlying structure for the construction.,"Lattices,
Fuzzy sets,
Formal concept analysis,
Ice,
Electronic mail,
Computer science,
Collaboration"
HiQuadLoc: A RSS Fingerprinting Based Indoor Localization System for Quadrotors,"Indoor localization for quadrotors has attracted much attention recently. While efforts have been made to perform location estimation of quadrotors leveraging dedicated indoor infrastructures, the low-cost and commonly used RSS fingerprinting based approach utilizing existing Wi-Fi APs has yet to be applied. The challenge is that the high-speed flight reduces the RSS measuring opportunities for fingerprints comparison; moreover, the 3D space fingerprints collection incurs more overhead than in the traditional 2D case. In this paper, we present HiQuadLoc, a RSS fingerprinting based indoor localization system for quadrotors. We propose a series of mechanisms including path estimation, path fitting, and location prediction to deal with the negative influence incurred by the high-speed flight; moreover, we develop a 4D RSS interpolation algorithm to reduce the site survey overhead, where 3D is for the indoor physical space and 1D is for the RSS sample space. Experimental results demonstrate that HiQuadLoc reduces the average location error by more than 50 percent compared with simply applying the RSS fingerprinting based approach for 2D localization, and the overhead of RSS training data collection is reduced by more than 80 percent.","Servers,
Interpolation,
Estimation,
Databases,
Mobile computing,
IEEE 802.11 Standard,
Buildings"
Sampling Requirements for Stable Autoregressive Estimation,"We consider the problem of estimating the parameters of a linear univariate autoregressive (AR) model with sub-Gaussian innovations from a limited sequence of consecutive observations. Assuming that the parameters are compressible, we analyze the performance of the ℓ1-regularized least squares as well as a greedy estimator of the parameters and characterize the sampling tradeoffs required for stable recovery in the nonasymptotic regime. In particular, we show that for a fixed sparsity level, stable recovery of AR parameters is possible when the number of samples scale sublinearly with the AR order. Our results improve over existing sampling complexity requirements in AR estimation using the Lasso, when the sparsity level scales faster than the square root of the model order. We further derive sufficient conditions on the sparsity level that guarantee the minimax optimality of the ℓ1-regularized least squares estimate. Applying these techniques to simulated data as well as real-world datasets from crude oil prices and traffic speed data confirm our predicted theoretical performance gains in terms of estimation accuracy and model selection.","Estimation,
Autoregressive processes,
Data models,
Time series analysis,
Stability analysis,
Technological innovation,
Mathematical model"
Cyclic Interference Alignment for Full-Duplex Multi-Antenna Cellular Networks,"This paper studies full-duplex (FD) cellular networks in which a base station (BS) operated in FD mode with multiple antennas supports multiple uplink and downlink users simultaneously in the same wireless channel. Two typical FD cellular scenarios are considered, one with half-duplex (HD) users and the other with FD users along with the FD BS. For both the cases, a novel constructive method is developed for finding a closed-form interference alignment (IA) solution, named cyclic IA. The core idea behind this approach is to construct a set of loop-equations enabling IA in a cyclic manner, so that beamforming vectors are sequentially determined by solving an eigenvalue problem. It is shown analytically that the proposed cyclic IA can achieve the optimal sum degrees-of-freedom (DoF) when the number of user antennas is large enough to meet the derived conditions. In particular, it is shown that the proposed scheme achieves a twofold DoF gain compared with conventional HD cellular networks even in the presence of inter-link interference, provided the number of users becomes large enough compared with the ratio of the number of BSs and user antennas. Simulation results demonstrate that not only are the analytical DoF results valid, but under a practical multi-cell scenario, the proposed cyclic IA offers significant throughput gains depending on the cell radius.","Cellular networks,
Interference,
Antennas,
Uplink,
Downlink,
High definition video,
MIMO"
Robust Web Image Annotation via Exploring Multi-Facet and Structural Knowledge,"Driven by the rapid development of Internet and digital technologies, we have witnessed the explosive growth of Web images in recent years. Seeing that labels can reflect the semantic contents of the images, automatic image annotation, which can further facilitate the procedure of image semantic indexing, retrieval, and other image management tasks, has become one of the most crucial research directions in multimedia. Most of the existing annotation methods, heavily rely on well-labeled training data (expensive to collect) and/or single view of visual features (insufficient representative power). In this paper, inspired by the promising advance of feature engineering (e.g., CNN feature and scale-invariant feature transform feature) and inexhaustible image data (associated with noisy and incomplete labels) on the Web, we propose an effective and robust scheme, termed robust multi-view semi-supervised learning (RMSL), for facilitating image annotation task. Specifically, we exploit both labeled images and unlabeled images to uncover the intrinsic data structural information. Meanwhile, to comprehensively describe an individual datum, we take advantage of the correlated and complemental information derived from multiple facets of image data (i.e., multiple views or features). We devise a robust pairwise constraint on outcomes of different views to achieve annotation consistency. Furthermore, we integrate a robust classifier learning component via ℓ2,p loss, which can provide effective noise identification power during the learning process. Finally, we devise an efficient iterative algorithm to solve the optimization problem in RMSL. We conduct comprehensive experiments on three different data sets, and the results illustrate that our proposed approach is promising for automatic image annotation.","Semisupervised learning,
Manifolds,
Robustness,
Semantics,
Supervised learning,
Multimedia communication"
On the Analysis of Diseases and Their Related Geographical Data,"Electronic medical records (EMRs) store data related to patients information enrolled during their stay in health structures. Data stored into EMRs span from data crawled from biological laboratories to textual description of diseases and diagnostic device results (e.g., biomedical images). Each EMR is related to a diagnosis related group (DRG) record. A DRG record is a record associated with a citizen that has been cured in a hospital. It contains a code, called major diagnostic category (MDC), which summarizes the treated disease and allows to reimburse costs related to patient treatments during his staying in health structures. DRGs are used for administrative process (e.g., costs and reimbursement management) as well as disease monitoring. Associating diagnostic codes with external information (such as environmental and geographical data) and with information filtered from EMRs (e.g., biological results or analytes values) can be useful to monitor citizens wellness status. We propose a methodology to analyze such data based on a multistep process. First, we cross reference data by using a semantics-based clustering procedure, extract information from EMRs, and then, cluster them by looking for similar patterns of diseases. Then, biological records in each disease cluster are analyzed to evaluate intracluster similarity by selecting analytes typologies and values. Finally, biological data is related to diagnosis codes and geometrically projected in areas of interest in order to map calculated outlier patients. We applied the methodology on two case studies: 1) diagnosis codes and biochemical analytes of 20 000 biological analyses about hospitalized patients during one observation year and 2) the correlation between cardiovascular diseases and water quality in a southern Italian region. Preliminary findings show the effectiveness of our method.","Diseases,
Data mining,
Unified modeling language,
Pathology,
Medical diagnostic imaging,
Biological information theory,
Semantics"
Improving Separability of Structures with Similar Attributes in 2D Transfer Function Design,"The 2D transfer function based on scalar value and gradient magnitude (SG-TF) is popularly used in volume rendering. However, it is plagued by the boundary-overlapping problem: different structures with similar attributes have the same region in SG-TF space, and their boundaries are usually connected. The SG-TF thus often fails in separating these structures (or their boundaries) and has limited ability to classify different objects in real-world 3D images. To overcome such a difficulty, we propose a novel method for boundary separation by integrating spatial connectivity computation of the boundaries and set operations on boundary voxels into the SG-TF. Specifically, spatial positions of boundaries and their regions in the SG-TF space are computed, from which boundaries can be well separated and volume rendered in different colors. In the method, the boundaries are divided into three classes and different boundary-separation techniques are applied to them, respectively. The complex task of separating various boundaries in 3D images is then simplified by breaking it into several small separation problems. The method shows good object classification ability in real-world 3D images while avoiding the complexity of high-dimensional transfer functions. Its effectiveness and validation is demonstrated by many experimental results to visualize boundaries of different structures in complex real-world 3D images.","Three-dimensional displays,
Transfer functions,
Visualization,
Image color analysis,
Rendering (computer graphics),
Computed tomography,
Complexity theory"
An Improved Deep Computation Model Based on Canonical Polyadic Decomposition,"Deep computation models achieve super performance for big data feature learning. However, training a deep computation model poses a significant challenge since a deep computation model typically involves a large number of parameters. Specially, it needs a high-performance computing server with a large-scale memory and a powerful computing unit to train a deep computation model, making it difficult to increase the size of a deep computation model further for big data feature learning on low-end devices such as conventional desktops and portable CPUs. In this paper, we propose an improved deep computation model based on the canonical polyadic decomposition scheme to compress the parameters and to improve the training efficiency. Furthermore, we devise a learning algorithm based on the back-propagation strategy to train the parameters of the proposed model. The learning algorithm can be directly performed on the compressed parameters to improve the training efficiency. Finally, we carry on the experiments on three representative datasets, i.e., CUAVE, SNAE2, and STL-10, to evaluate the performance of the proposed model by comparing with the conventional deep computation model and other two improved deep computation models based on the Tucker decomposition and the tensor-train network. Results demonstrate that the proposed model can compress parameters greatly and improve the training efficiency significantly with a low classification accuracy drop.","Computational modeling,
Tensile stress,
Data models,
Training,
Big Data,
Machine learning,
Neural networks"
Guided HTM: Hierarchical Topic Model with Dirichlet Forest Priors,"Despite the proliferation of topic models, the organization of topics from the probabilistic models needs improvement in two ways: the better structured presentation of topics and the incorporation of domain knowledge on the corpus. The structured presentation, i.e., the hierarchical topic model, helps in categorizing similar topics; the incorporation of domain knowledge enables the concentrated sampling of predefined keywords in the mixture parameter learning. This paper presents a hierarchical topic models with incorporated domain knowledge, called Guided Hierarchical Topic Model (GHTM). Specifically, we allocated the prior information from the knowledge to the Dirichlet Forest prior. From the prior adjustment, we obtained the topic tree guided by the domain knowledge. This paper also contributes in enumerating four different knowledge extraction methods and applying the extracted knowledge to GHTM. We evaluated the performance of GHTM in terms of the hierarchical clustering accuracy, and we found a significant improvement of hierarchical clustering measured by F-measures. This improvement is also verified by the perplexity analyses. Additionally, we measured topic quality with KL-divergence and visualization, and these confirm the ability to better separate topic distributions. Finally, we tested the hierarchical topic quality through human experiments, and this also revealed significant improvements originating from the guidance.","Vegetation,
Probabilistic logic,
Resource management,
Data models,
Encoding,
Organizations,
Knowledge engineering"
Hybrid Approximate Message Passing,"Gaussian and quadratic approximations of message passing algorithms on graphs have attracted considerable recent attention due to their computational simplicity, analytic tractability, and wide applicability in optimization and statistical inference problems. This paper presents a systematic framework for incorporating such approximate message passing (AMP) methods in general graphical models. The key concept is a partition of dependencies of a general graphical model into strong and weak edges, with the weak edges representing small, linearizable couplings of variables. AMP approximations based on the central limit theorem can be readily applied to aggregates of many weak edges and integrated with standard message passing updates on the strong edges. The resulting algorithm, which we call hybrid generalized approximate message passing (HyGAMP), can yield significantly simpler implementations of sum-product and max-sum loopy belief propagation. By varying the partition of strong and weak edges, a performance-complexity tradeoff can be achieved. Group sparsity and multinomial logistic regression problems are studied as examples of the proposed methodology.","Message passing,
Inference algorithms,
Signal processing algorithms,
Optimization,
Graphical models,
Approximation algorithms,
Standards"
How Much Computing Capability Is Enough to Run a Cloud Radio Access Network?,"Cloud radio access network (C-RAN) has emerged as a promising solution to support exponentially increasing demand in data rate. The attractive capacity enhancement mainly comes from centralized and coordinated processing, which poses great challenges on computing capability in the baseband unit pool. This requires the efficient allocation of computing resources to minimize the hardware and energy costs of C-RANs. Therefore, in this letter, we first model the computing resource consumption of joint downlink transmissions from remote radio heads (RRHs) to users. Then, we investigate the computing resource minimization problem on how much computing capability is needed given certain number of RRHs and user density. Numerical results show that the computing resource consumption increases non-linearly with the user density. In particular, the required computing resource drastically increases when densely populated hotspots are present in the system.","Computational modeling,
Baseband,
Signal to noise ratio,
Interference,
Minimization,
Customer relationship management,
Array signal processing"
Hyperspectral Image Restoration Using Low-Rank Representation on Spectral Difference Image,"This letter presents a novel mixed noise (i.e., Gaussian, impulse, stripe noises, or dead lines) reduction method for hyperspectral image (HSI) by utilizing low-rank representation (LRR) on spectral difference image. The proposed method is based on the assumption that all spectra in the spectral difference space of HSI lie in the same low-rank subspace. The LRR on the spectral difference space was exploited by nuclear norm of difference image along the spectral dimension. It showed great potential in removing structured sparse noise (e.g., stripes or dead lines located at the same place of each band) and heavy Gaussian noise. To simultaneously solve the proposed model and reduce computational load, alternating direction method of multipliers was utilized to achieve robust reconstruction. The experimental results on both simulated and real HSI data sets validated that the proposed method outperformed many state-of-the-art methods in terms of quantitative assessment and visual quality.",
HeteRBar: Construction of Heterogeneous Reinforced Barrier in Wireless Sensor Networks,"Recently, a barrier-coverage has gained much interest due to potentiality of various applications. In this letter, we introduce a reinforced barrier-coverage in heterogeneous wireless sensor networks, which guarantees that any penetration variation of intruder is detected by at least one sensor with a consideration of heterogeneous sensors with different capabilities. Also, we formally define a problem whose objective is to maximize the lifetime of heterogeneous reinforced barriers and propose two novel approaches, including a creation of base graph. Then, the performances of the proposed schemes are analyzed through various scenarios.","Robot sensing systems,
Wireless sensor networks,
Base stations,
Monitoring,
Intrusion detection,
Computer science"
Exploring the Possibilities of Embedding Heterogeneous Data Attributes in Familiar Visualizations,"Heterogeneous multi-dimensional data are now sufficiently common that they can be referred to as ubiquitous. The most frequent approach to visualizing these data has been to propose new visualizations for representing these data. These new solutions are often inventive but tend to be unfamiliar. We take a different approach. We explore the possibility of extending well-known and familiar visualizations through including Heterogeneous Embedded Data Attributes (HEDA) in order to make familiar visualizations more powerful. We demonstrate how HEDA is a generic, interactive visualization component that can extend common visualization techniques while respecting the structure of the familiar layout. HEDA is a tabular visualization building block that enables individuals to visually observe, explore, and query their familiar visualizations through manipulation of embedded multivariate data. We describe the design space of HEDA by exploring its application to familiar visualizations in the D3 gallery. We characterize these familiar visualizations by the extent to which HEDA can facilitate data queries based on attribute reordering.",
A Proposal of Software Architecture for Java Programming Learning Assistant System,"To improve Java programming educations, we have developed a Web-based Java Programming Learning System (JPLAS). To deal with students at different levels, JPLAS provides three levels of problems, namely, element fill-in-blank problems, statement fill-in-blank problems, and code writing problems. Unfortunately, since JPLAS has been implemented by various students who studied in our group at different years, the code has become complex and redundant, which makes further extensions of JPLAS extremely hard. In this paper, we propose the software architecture for JPLAS to avoid redundancy to the utmost at implementations of new functions that will be continued with this JPLAS project. Following the MVC model, our proposal basically uses Java for the model (M), JavaScript/CSS for the view (V), and JSP for the controller (C). For the evaluation, we implement JPLAS by this architecture and compare the number of code files with the previous implementation.",
Traffic-Aware Geo-Distributed Big Data Analytics with Predictable Job Completion Time,"Big data analytics has attracted close attention from both industry and academic because of its great benefits in cost reduction and better decision making. As the fast growth of various global services, there is an increasing need for big data analytics across multiple data centers (DCs) located in different countries or regions. It asks for the support of a cross-DC data processing platform optimized for the geo-distributed computing environment. Although some recent efforts have been made for geo-distributed big data analytics, they cannot guarantee predictable job completion time, and would incur excessive traffic overthe inter-DC network that is a scarce resource shared by many applications. In this paper, we study to minimize the inter-DC traffic generated by MapReduce jobs targeting on geo-distributed big data, while providing predicted job completion time. To achieve this goal, we formulate an optimization problem by jointly considering input data movement and task placement. Furthermore, we guarantee predictable job completion time by applying the chance-constrained optimization technique, such that the MapReduce job can finish within a predefined job completion time with high probability. To evaluate the performance of our proposal, we conduct extensive simulations using real traces generated by a set of queries on Hive. The results show that our proposal can reduce 55 percent inter-DC traffic compared with centralized processing by aggregating all data to a single data center.","Big data,
Optimization,
Distributed databases,
Scheduling,
Data models,
Proposals"
Splitting Large Medical Data Sets based on Normal Distribution in Cloud Environment,"The surge of medical and e-commerce applications has generated tremendous amount of data, which brings people to a so-called “Big Data” era. Different from traditional large data sets, the term “Big Data” not only means the large size of data volume but also indicates the high velocity of data generation. However, current data mining and analytical techniques are facing the challenge of dealing with large volume data in a short period of time. This paper explores the efficiency of utilizing the Normal Distribution (ND) method for splitting and processing large volume medical data in cloud environment, which can provide representative information in the split data sets. The ND-based new model consists of two stages. The first stage adopts the ND method for large data sets splitting and processing, which can reduce the volume of data sets. The second stage implements the ND-based model in a cloud computing infrastructure for allocating the split data sets. The experimental results show substantial efficiency gains of the proposed method over the conventional methods without splitting data into small partitions. The ND-based method can generate representative data sets, which can offer efficient solution for large data processing. The split data sets can be processed in parallel in Cloud computing environment.","Gaussian distribution,
Data models,
Cloud computing,
Distributed databases,
Big data,
Partitioning algorithms"
Understanding Social Causalities Behind Human Action Sequences,"Social causality study on human action sequences is useful and important to improve our understandings to human behaviors on online social networks. The redundant indirect causalities and unobserved confounding factors, such as homophily and simultaneity phenomena, contribute to the huge challenges on accurate causal discovery on such human actions. A causal relationship exists between two persons, if the actions of one person are significantly affected by the actions of the other person, while fairly independent of her/his own prior actions. In this paper, we design a systematic approach based on conditional independence testing to detect such asymmetric relations, even when there are latent confounders underneath the observational action sequences. Technically, a group of asymmetric independence tests are conducted to infer the loose causal directions between action sequence pairs, followed by another group of tests to distinguish different types of relationships, e.g., homophily and simultaneity. Finally, a causal structure learning method is employed to output pairwise causalities with redundant indirect causalities eliminated. Empirical evaluations on simulated data verify the effectiveness and scalability of our proposals. We also present four interesting patterns of causal relations found by our algorithm, on real Sina Weibo feeds, including two new patterns never reported in previous studies.","Social network services,
Entropy,
Data models,
Learning systems,
Electronic mail,
Computational modeling,
Media"
Compact Modeling and Evaluation of Magnetic Skyrmion-Based Racetrack Memory,"Racetrack memory (RM) has been considered as one of the most attractive nonvolatile memories in the future advanced computer architectures. Current RM is based on domain wall (DW) motion, which, however, has some intrinsic limitations, such as scalability, density, and energy consumption owing to the physical property of DW. Recently, magnetic skyrmion, one new type of spintronic object, has emerged as an alternative of DW in RM application. The advantageous features of skyrmion, such as nanoscale size, topological stability, as well as ultralow depinning current density, make it promising as an information carrier in the future ultradense, high-speed, and low-power electronics in addition to RM design. In this paper, we primarily investigate the prospects of the skyrmion-based RM (Sky-RM). We developed a physics-based compact model for Sky-RM electronic design and performance evaluation. Experimentalmaterial parameterswere included and micromagnetic investigations were carried out simultaneously to calibrate the accuracy of the model. Using the developed model, hybrid simulations were performed to evaluate the Sky-RM performance, in comparison with the DW-based RM (DW-RM). Our results show that Sky-RM outperforms DW-RM in terms of storage density and energy efficiency.",
Data science for decision aiding UAV control,"The dynamics of a human operated nonlinear unmanned aerial vehicle (NUAV) with a given controller at the inner loop is governed by the admissible nonzero initial conditions and the pilot inputs. The movements of the joystick connected to the throttle and the control surfaces in a way are the indications of the pilot decision points to operate the stabilized NUAV. If these decisions fall short to avoid an obstacle or a denied air space, data science to generate the admissible control inputs through appropriate initial conditions becomes an important problem. Such control inputs at the autonomous decision points (decisions not made by the human pilot) complement the pilot inputs and may be used to avoid the obstacles and the denied airspace. In this paper, the rules to choose these control inputs at the autonomous decision points are discussed. A three degree of freedom aircraft in pitch plane is considered for illustrations.","Aircraft,
Stability analysis,
Mathematical model,
Vehicle dynamics,
Trajectory,
Data science,
Unmanned aerial vehicles"
Total Ionizing Dose Effects on HfO2-Passivated Black Phosphorus Transistors,"Electrical stress and 10-keV x-ray irradiation and annealing responses are evaluated for HfO2-passivated black phosphorous (BP) MOSFETs with HfO2 gate dielectrics. Device characteristics are stable during constant gate-voltage stress up to at least ±1 V. Significant negative threshold shifts, mobility degradation, and increases in subthreshold swing occur during both positive and negative bias irradiation. Hole trapping in the HfO2 gate dielectric dominates the TID response in these passivated BP MOSFETs. Reversibility of electrical parameters and magnitude of low frequency noise is observed during switched-bias annealing after irradiation. The voltage dependence of the low-frequency noise suggests that the trap distribution of the defects contributing to the noise becomes more uniform in energy after the devices are irradiated and annealed.","Logic gates,
Hafnium compounds,
Annealing,
Radiation effects,
Charge carrier processes,
MOSFET"
Variability Analysis of Crosstalk Among Differential Vias Using Polynomial-Chaos and Response Surface Methods,"The variability of crosstalk due to changes in differential and ground via configurations is studied in this paper. The polynomial-chaos method and the response surface method are adopted to mathematically model the variability. One goal of the work is to exploit the obtained models to locate the optimal response that both meets the performance requirement and remains robust to geometry variations due to manufacturing tolerances. Both methods correlate well with simulations and show great capabilities in practical applications for optimization and sensitivity analysis. The other goal of the work is to compare the two methods in terms of mathematical theories, sampling schemes, postprocessing, accuracy, efficiency, and limitations. Details of the comparison is given through this paper and a summary table is included in Section V.","Mathematical model,
Crosstalk,
Optimization,
Sensitivity analysis,
Input variables,
Stochastic processes,
Response surface methodology"
Common-Signal-Induced Synchronization in Semiconductor Lasers With Broadband Optical Noise Signal,"We experimentally observe common-signal-induced synchronization between two semiconductor lasers driven by a broadband optical noise signal. We use a super-luminescent diode as a source of the optical noise signal, whose bandwidth is over THz. Synchronization is achieved even without injection locking between the drive noise signal and the semiconductor lasers; however, the optical wavelengths of the two semiconductor lasers need to be precisely matched. We investigate the parameter dependence of synchronization on the injection strength of the drive signal and the relaxation oscillation frequency of the semiconductor lasers. We apply optical band-pass-filters to change the bandwidth of the noise signal, and investigate the quality of synchronization. We found that high-quality synchronization can be achieved when the bandwidth of the optical spectra of the semiconductor lasers are within the bandwidth of the optical noise signal.",
Bayesian Modeling of Temporal Coherence in Videos for Entity Discovery and Summarization,"A video is understood by users in terms of entities present in it. Entity Discovery is the task of building appearance model for each entity (e.g., a person), and finding all its occurrences in the video. We represent a video as a sequence of tracklets, each spanning 10-20 frames, and associated with one entity. We pose Entity Discovery as tracklet clustering, and approach it by leveraging Temporal Coherence (TC): the property that temporally neighboring tracklets are likely to be associated with the same entity. Our major contributions are the first Bayesian nonparametric models for TC at tracklet-level. We extend Chinese Restaurant Process (CRP) to TC-CRP, and further to Temporally Coherent Chinese Restaurant Franchise (TC-CRF) to jointly model entities and temporal segments using mixture components and sparse distributions. For discovering persons in TV serial videos without meta-data like scripts, these methods show considerable improvement over state-of-the-art approaches to tracklet clustering in terms of clustering accuracy, cluster purity and entity coverage. The proposed methods can perform online tracklet clustering on streaming videos unlike existing approaches, and can automatically reject false tracklets. Finally we discuss entity-driven video summarization- where temporal segments of the video are selected based on the discovered entities, to create a semantically meaningful summary.","Videos,
Bayes methods,
Coherence,
TV,
YouTube,
Computational modeling,
Feature extraction"
A Broadband Dual-Polarized Base Station Antenna With Anti-Interference Capability,"A broadband dual-polarized antenna with antiinterference capability is presented in this letter for base station applications. The proposed antenna contains three parts: main radiator, feed structures, and reflector. Specifically, the main radiator has two crossed dipoles to realize ±45° polarizations; two vertical substrates, which have Γ-shaped feeding lines on the front side and rectangle patches on the back side, are placed between the main radiator and reflector for feeding; the reflector placed below is used to get high gain and unidirectional radiation. In addition, C-shaped stubs are arranged next to the feeding lines in order to filter the unwanted frequency band. A prototype of the antenna was fabricated and tested. The measured results show that it has a bandwidth of 52.6% (VSWR <; 1.5) along with a sharp notch band from 2.27 to 2.53 GHz. Measured isolation of higher than 25.4 dB, half-power beamwidth of around 60° and average gain of 7.57 dBi across the operating band are also obtained. Having the advantages of anti-interference capability, dual polarization, wide bandwidth, high isolation, and good radiation performance, the proposed antenna can find its application in the next-generation wireless communication systems.",
Collaborative Joint Training With Multitask Recurrent Model for Speech and Speaker Recognition,"Automatic speech and speaker recognition are traditionally treated as two independent tasks and are studied separately. The human brain in contrast deciphers the linguistic content, and the speaker traits from the speech in a collaborative manner. This key observation motivates the work presented in this paper. A collaborative joint training approach based on multitask recurrent neural network models is proposed, where the output of one task is backpropagated to the other tasks. This is a general framework for learning collaborative tasks and fits well with the goal of joint learning of automatic speech and speaker recognition. Through a comprehensive study, it is shown that the multitask recurrent neural net models deliver improved performance on both automatic speech and speaker recognition tasks as compared to single-task systems. The strength of such multitask collaborative learning is analyzed, and the impact of various training configurations is investigated.","Speech,
Collaboration,
Speech recognition,
Training,
Speech processing,
Speaker recognition,
Hidden Markov models"
Layered Space Shift Keying Modulation Over MIMO Channels,"Space shift keying (SSK) modulation is an emerging transmission technique for multiple-input multiple-output (MIMO) wireless channels, which exploits the spatial domain to convey information. In this paper, we present a layered space shift keying (LSSK) modulation scheme to fully exploit the spatial domain to transmit information bits, where a layered architecture is developed to achieve spatial multiplexing transmission in an SSK system. Specifically, LSSK leverages the rotated signals predetermined at the transceiver to identify different layers and improve the bit-error-rate (BER) performance. The layered signals are directly generated by the proposed LSSK modulation method with a low computational overhead. Furthermore, we propose a layered-and-joint (LJ) near-optimal detection algorithm based on the layered architecture of LSSK to reduce the detection complexity. In LJ detection, layered detection is performed to find a set of detection candidates for each layer, and then, joint detection is performed with these candidates. We show that the performance of LJ detection is quite close to that of optimal maximum-likelihood detection with significantly reduced detection complexity for high-spectrum-efficiency scenarios. Results demonstrate that the proposed LSSK scheme substantially improves the spectrum efficiency of an SSK system and outperforms other existing MIMO schemes.","Modulation,
MIMO,
Transmitting antennas,
GSM,
Computer architecture,
Complexity theory"
Automatic Synchronization of Multi-user Photo Galleries,"In this paper we address the issue of photo galleries synchronization, where pictures related to the same event are collected by different users. Existing solutions to address the problem are usually based on unrealistic assumptions, like time consistency across photo galleries, and often heavily rely on heuristics, therefore limiting the applicability to real-world scenarios. We propose a solution that achieves better generalization performance for the synchronization task compared to the available literature. The method is characterized by three stages: at first, deep convolutional neural network features are used to assess the visual similarity among the photos; then, pairs of similar photos are detected across different galleries and used to construct a graph; eventually, a probabilistic graphical model is used to estimate the temporal offset of each pair of galleries, by traversing the minimum spanning tree extracted from this graph. The experimental evaluation is conducted on four publicly available datasets covering different types of events, demonstrating the strength of our proposed method. A thorough discussion of the obtained results is provided for a critical assessment of the quality in synchronization.",
Classification of road curves and corresponding driving profile via smartphone trip data,"Smart cities are the new settlement structures formed by new technologies that change human life. Among these technologies, intelligent automobiles have an important place, and many scientific studies on it have been realized. Especially Tesla, Apple, and Google have completed their prototypes of autonomous automobiles. One of the indispensable part of recent automotive technologies is Advanced Driver Assistance System (ADAS). This system has been developed to improve safety and comfort of driver while driving. In this study, we have tried to predict road geometry and driving profile by using sensor data acquired by driver smartphone on steering wheel for a certain trip. Driving profiles are identified as aggressive and safe. GPS, accelerometer and gyroscope sensors are employed in this study. Using smartphone sensor data, road portions are initially determined by the proposed algorithm. Then, road shapes are obtained by a Fuzzy Classifier, which are straight, right curved, and left curved. Afterwards, the acceleration data corresponding road shapes are considered to find acceleration type for the portion of that road. Transitions between straight and curved roads including vehicle speed are determined by Hidden Markov Model (HMM). Thus, speed preference of subject driver for corresponding road shapes are obtained in probabilistic manner. Validation results have shown that the error rate between ground truth and observation data for proposed approach is obtained as 11.81%. Consequently, driving profile have been estimated considering road shapes.",
WR-3 Band Quasi-Elliptical Waveguide Filters Using Higher Order Mode Resonances,"Two types of WR-3 band quasi-elliptical waveguide bandpass filters (BPFs) using higher order mode resonators are presented based on physical cross coupling and modal bypass coupling, respectively. Under the situation of physical folded structure, a TE102-mode in an oversized waveguide resonator is utilized to reverse the magnetic field direction of main path to implement a negative cross coupling (Filter-I). Limited to the structure of Filter-I itself, the simulated 3 dB fractional bandwidth (FBW) of 8.5% is slightly narrower than desired 10% FBW. For the other case, two TE101/TE201 overmode resonant cavities with suitable input and output coupling locations are employed to generate two transmission zeros in the vicinity of the passband through modal bypass couplings (Filter-II). The benefit from the realization of the wideband source and load couplings in the fringe first and fourth oversized cavities is that the FBW of 10% is achieved in the Filter-II. The two BPFs fabricated by computer numerical control milling technology exhibit an insertion loss (IL) of about 0.7 dB and a 3 dB FBW of 8.77% centered at 257.7 GHz (Filter-I), IL of around 0.5 dB, and FBW of 9.83% with center frequency of 256.3 GHz (Filter-II), which are all in good agreement with the simulations. The performance of the two BPFs based on one or two oversized waveguide resonators is highlighted comparing with the reported similar terahertz waveguide filters.","Couplings,
Resonator filters,
Cavity resonators,
Band-pass filters,
Magnetic resonance,
Optical waveguides"
A Distributed Parallel Cooperative Coevolutionary Multiobjective Evolutionary Algorithm for Large-Scale Optimization,"A considerable amount of research has been devoted to multiobjective optimization problems. However, few studies have aimed at multiobjective large-scale optimization problems (MOLSOPs). To address MOLSOPs, which may involve big data, this paper proposes a message passing interface MPI -based distributed parallel cooperative coevolutionary multiobjective evolutionary algorithm (DPCCMOEA). DPCCMOEA tackles MOLSOPs based on decomposition. First, based on a modified variable analysis method, we separate decision variables into several groups, each of which is optimized by a subpopulation (species). Then, the individuals in each subpopulation are further separated to several sets. DPCCMOEA is implemented with MPI distributed parallelism and a two-layer parallel structure is constructed. We examine the proposed algorithm using the multiobjective test suites Deb-Thiele-Laumanns-Zitzler and Walking-Fish-Group. In comparison with cooperative coevolutionary generalized differential evolution 3 and multiobjective evolutionary algorithm based on decision variable analyses, which are state-of-the-art cooperative coevolutionary multiobjective evolutionary algorithms, experimental results show that the novel algorithm has better performance in both optimization results and time consumption.","application program interfaces,
Big Data,
evolutionary computation,
message passing,
optimisation,
parallel algorithms"
A System for Profiling and Monitoring Database Access Patterns by Application Programs for Anomaly Detection,"Database Management Systems (DBMSs) provide access control mechanisms that allow database administrators (DBAs) to grant application programs access privileges to databases. Though such mechanisms are powerful, in practice finer-grained access control mechanism tailored to the semantics of the data stored in the DMBS is required as a first class defense mechanism against smart attackers. Hence, custom written applications which access databases implement an additional layer of access control. Therefore, securing a database alone is not enough for such applications, as attackers aiming at stealing data can take advantage of vulnerabilities in the privileged applications and make these applications to issue malicious database queries. An access control mechanism can only prevent application programs from accessing the data to which the programs are not authorized, but it is unable to prevent misuse of the data to which application programs are authorized for access. Hence, we need a mechanism able to detect malicious behavior resulting from previously authorized applications. In this paper, we present the architecture of an anomaly detection mechanism, DetAnom, that aims to solve such problem. Our approach is based the analysis and profiling of the application in order to create a succinct representation of its interaction with the database. Such a profile keeps a signature for every submitted query and also the corresponding constraints that the application program must satisfy to submit the query. Later, in the detection phase, whenever the application issues a query, a module captures the query before it reaches the database and verifies the corresponding signature and constraints against the current context of the application. If there is a mismatch, the query is marked as anomalous. The main advantage of our anomaly detection mechanism is that, in order to build the application profiles, we need neither any previous knowledge of application vulnerabilities nor any example of possible attacks. As a result, our mechanism is able to protect the data from attacks tailored to database applications such as code modification attacks, SQL injections, and also from other data-centric attacks as well. We have implemented our mechanism with a software testing technique called concolic testing and the PostgreSQL DBMS. Experimental results show that our profiling technique is close to accurate, requires acceptable amount of time, and the detection mechanism incurs low runtime overhead.","Databases,
Access control,
Software testing,
Software,
Engines"
Trajectory Privacy Preservation Based on a Fog Structure for Cloud Location Services,"The development of mobile cloud computing technology has made location-based service (LBS) increasingly more popular. Given the continuous requests to cloud LBS servers, the amounts of location and trajectory information collected by LBS servers are continuously increasing. Privacy awareness for LBS has been extensively studied in recent years. Among the privacy concerns about LBS, trajectory privacy preservation is particularly important. Based on privacy preservation models, previous work have mainly focused on peer-to-peer and centralized architectures. However, the burden on users is heavy in peer-to-peer architectures, because user devices need to communicate with LBS servers directly. In centralized architectures, a trusted third party (TTP) is introduced, and acts as a bridge between users and the LBS server. Anonymity technologies, such as k-anonymity, mix-zone, and dummy technologies, are usually implemented by the TTP to ensure safety. There are certain drawbacks in TTP architectures: Users have no physical control of the TTP. Moreover, the TTP is more attractive to adversaries, because substantially more sensitive information is stored by the TTP. To solve the above-mentioned problems, in this paper, we propose a fog structure to store partial important data with the dummy anonymity technology to ensure physical control, which can be considered as absolutely trust. Compared with cloud computing, fog computing is a promising technique that extends the cloud computing to the edge of a network. Moreover, fog computing provides local computation and storage abilities, wide geo-distribution, and support for mobility. Therefore, mobile users' partial important information can be stored on a fog server to ensure better management. We take the principles of similarity, intersection, practicability, and correlation into consideration and design a dummy rotation algorithm with several properties. The effectiveness of the proposed method is validated through extensive simulations, which show that the proposed method can provide enhanced privacy preservation.",
An Offline Framework for the Diagnosis of Time Reliability by Automatic Vehicle Location Data,"Time reliability problems are unavoidable, owing to the stochastic context in which bus services are operated. Therefore, characterizing their reliability and understanding possible sources of unreliability provides an opportunity to keep buses on schedule and/or maintain planned headways. Measuring time reliability is technologically feasible by automatic vehicle location (AVL) systems, which can collect disaggregated data on the delivered service and disclose information on its performance. This paper proposes the first offline framework applicable to any bus route in order to accurately characterize the bus stops and the time periods in which reliability is insufficient, and to disclose the systematic unreliability sources from collected AVL data and select preventive strategies, accordingly. The framework is tested on the real case study of a bus route, using about 40 000 AVL data records provided by the bus operator CTM in Cagliari, Italy. The experimentation shows that this framework can be adopted by transit managers for accurate reliability analysis.","Reliability,
Vehicles,
Schedules,
Companies,
Time measurement,
Biological system modeling,
Data collection"
Coordinated Supervisory Control of Multi-Terminal HVDC Grids: A Model Predictive Control Approach,"A coordinated supervisory control scheme for future multi-terminal high-voltage direct-current (HVDC) grids is proposed. The purpose is to supervise the grid and take appropriate actions to ensure power balance and prevent or remove voltage or current limit violations. First, using DC current and voltage measurements, the power references of the various Voltage Source Converters are updated according to participation factors. Next, the setpoints of the converters are smoothly adjusted to track those power references, while avoiding or correcting limit violations. The latter function resorts to model predictive control and a sensitivity model of the system. The efficiency of the proposed scheme has been tested through dynamic simulations of a five-terminal HVDC grid interconnecting two asynchronous AC areas and a wind farm.","Power conversion,
Voltage control,
HVDC transmission,
Supervisory control,
Frequency control,
Predictive control"
Single-carrier index modulation and CS detection,"We consider index modulation (IM) for single-carrier (SC) systems in this paper. Compared with conventional orthogonal frequency division multiplexing (OFDM) IM, the resulting approach, which is referred to as SCIM, has a better performance due to the path diversity gain under a multipath fading environment. For sparse IM, since compressive sensing (CS) algorithms can be used for low-complexity signal detection, we consider the orthogonal matching pursuit (OMP) algorithm to perform the signal detection in SCIM. A transmit diversity scheme is also proposed for both OFDM-IM and SCIM, which can not only improve the performance in terms of the diversity gain, but also increase the number of information bits per signal block.","Complexity theory,
OFDM,
Diversity methods,
Matching pursuit algorithms,
Indexes,
Modulation,
Detectors"
Dynamic Degradation in SiC Trench MOSFET With a Floating p-Shield Revealed With Numerical Simulations,"A p-type shield region (p-shield) under the gate trench is typically adopted in a SiC trench MOSFET for achieving a lower oxide field and reverse transfer capacitance (Crss). This paper comparatively studies the effects of a grounded p-shield and a floating p-shield. Device simulations using Sentaurus TCAD are carried out in this paper to reveal the devices' internal dynamics. The floating p-shield can effectively reduce the OFF-state oxide field as a grounded p-shield does, without degrading its static performance. However, after being switched from the OFF-state, the ON-state oxide field in the trench MOSFET with a floating p-shield (FS-MOS) is dramatically elevated. Compared with the trench MOSFET with a grounded p-shield, the FS-MOS also exhibits a higher Crss and a consequently slower switching speed. Furthermore, the FS-MOS exhibits a degradation of dynamic RON during switching operation. A charge storage mechanism is then presented to explain the dynamics in FS-MOS. Upon a high VDS, holes are emitted from the floating p-shield when the parasitic p-n-p structure consisting of p-shield, p-body, and n-region between them is punched through, leaving negative charges in the floating p-shield even when the high VDS is removed. Based on this mechanism, the behaviors of the FS-MOS are well explained.","MOSFET,
Silicon carbide,
Switches,
Logic gates,
Capacitance,
Degradation,
Electron mobility"
Toward Cost-Oriented Forecasting of Wind Power Generation,"Forecasting is considered to be one of the most cost-efficient solutions to integrating wind power into existing power systems. In some applications, unbiased forecasting is necessary, while in others, the forecasting value can be biased for optimal decision making. In this paper, we study optimal point forecasting problems under cost-oriented loss functions, which can lead to a forecasting process that is far more sensitive to the actual cost associated with forecasting errors. Theoretical points of optimal forecasting under different loss functions are illustrated, then a cost-oriented, boosted regression tree method is presented to formulate the optimal forecasting problem under study. Case studies using real wind farm data are conducted. A comparison between cost-oriented forecasting and traditional unbiased forecasting demonstrates the efficiency of the proposed method in maximizing benefits for the decision-making process.","Forecasting,
Wind forecasting,
Wind power generation,
Predictive models,
Regression tree analysis,
Decision making"
Bank Stealing for a Compact and Efficient Register File Architecture in GPGPU,"Modern general-purpose graphic processing units (GPGPUs) have emerged as pervasive alternatives for parallel high-performance computing. The extreme multithreading in modern GPGPUs demands a large register file (RF), which is typically organized into multiple banks to support the massive parallelism. Although a heavily banked structure benefits RF throughput, its associated area and energy costs with diminishing performance gains greatly limit the future RF scaling. In this paper, we propose an improved RF design with bank stealing techniques, which enable a high RF throughput with compact area. By deeply investigating the GPGPU microarchitecture, we find that the state-of-the-art RF designs' is far from optimal due to the deficiency in bank utilization, which is the intrinsic limitation to a high RF throughput and a compact RF area. We investigate the causes for bank conflicts and identify that most conflicts can be eliminated by leveraging the fact that the highly banked RF oftentimes experiences underutilization. This is especially true in GPGPUs, where multiple ready warps are available at the scheduling stage with their operands to be wisely coordinated. In this paper, we propose two lightweight bank stealing techniques that can opportunistically fill the idle banks and register entries for better operand service. Using the proposed architecture, the average GPGPU performance can be improved under a smaller energy budget with significant area saving, which makes it promising for sustainable RF scaling.","Radio frequency,
Registers,
Throughput,
Message systems,
Computer architecture,
Graphics processing units,
Parallel processing"
A Review on Soft Set-Based Parameter Reduction and Decision Making,"Many real world decision making problems often involve uncertainty data, which mainly originating from incomplete data and imprecise decision. The soft set theory as a mathematical tool that deals with uncertainty, imprecise, and vagueness is often employed in solving decision making problem. It has been widely used to identify irrelevant parameters and make reduction set of parameters for decision making in order to bring out the optimal choices. In this paper, we present a review on different parameter reduction and decision making techniques for soft set and hybrid soft sets under unpleasant set of hypothesis environment as well as performance analysis of the their derived algorithms. The review has summarized this paper in those areas of research, pointed out the limitations of previous works and areas that require further research works. Researchers can use our review to quickly identify areas that received diminutive or no attention from researchers so as to propose novel methods and applications.","Decision making,
Information systems,
Uncertainty,
Rough sets,
Fuzzy sets,
Electronic mail"
Data-Dependent Label Distribution Learning for Age Estimation,"As an important and challenging problem in computer vision, face age estimation is typically cast as a classification or regression problem over a set of face samples with respect to several ordinal age labels, which have intrinsically cross-age correlations across adjacent age dimensions. As a result, such correlations usually lead to the age label ambiguities of the face samples. Namely, each face sample is associated with a latent label distribution that encodes the cross-age correlation information on label ambiguities. Motivated by this observation, we propose a totally data-driven label distribution learning approach to adaptively learn the latent label distributions. The proposed approach is capable of effectively discovering the intrinsic age distribution patterns for cross-age correlation analysis on the basis of the local context structures of face samples. Without any prior assumptions on the forms of label distribution learning, our approach is able to flexibly model the sample-specific context aware label distribution properties by solving a multi-task problem, which jointly optimizes the tasks of age-label distribution learning and age prediction for individuals. Experimental results demonstrate the effectiveness of our approach.","Face,
Context,
Feature extraction,
Correlation,
Estimation,
Context modeling,
Videos"
Tri-Clustered Tensor Completion for Social-Aware Image Tag Refinement,"Social image tag refinement, which aims to improve tag quality by automatically completing the missing tags and rectifying the noise-corrupted ones, is an essential component for social image search. Conventional approaches mainly focus on exploring the visual and tag information, without considering the user information, which often reveals important hints on the (in)correct tags of social images. Towards this end, we propose a novel tri-clustered tensor completion framework to collaboratively explore these three kinds of information to improve the performance of social image tag refinement. Specifically, the inter-relations among users, images and tags are modeled by a tensor, and the intra-relations between users, images and tags are explored by three regularizations respectively. To address the challenges of the super-sparse and large-scale tensor factorization that demands expensive computing and memory cost, we propose a novel tri-clustering method to divide the tensor into a certain number of sub-tensors by simultaneously clustering users, images and tags into a bunch of tri-clusters. And then we investigate two strategies to complete these sub-tensors by considering (in)dependence between the sub-tensors. Experimental results on a real-world social image database demonstrate the superiority of the proposed method compared with the state-of-the-art methods.","Tensile stress,
Visualization,
Semantics,
Correlation,
Buildings,
Noise measurement,
Electronic mail"
DiP-SVM : Distribution Preserving Kernel Support Vector Machine for Big Data,"In literature, the task of learning a support vector machine for large datasets has been performed by splitting the dataset into manageable sized “partitions” and training a sequential support vector machine on each of these partitions separately to obtain local support vectors. However, this process invariably leads to the loss in classification accuracy as global support vectors may not have been chosen as local support vectors in their respective partitions. We hypothesize that retaining the original distribution of the dataset in each of the partitions can help solve this issue. Hence, we present DiP-SVM, a distribution preserving kernel support vector machine where the first and second order statistics of the entire dataset are retained in each of the partitions. This helps in obtaining local decision boundaries which are in agreement with the global decision boundary, thereby reducing the chance of missing important global support vectors. We show that DiP-SVM achieves a minimal loss in classification accuracy among other distributed support vector machine techniques on several benchmark datasets. We further demonstrate that our approach reduces communication overhead between partitions leading to faster execution on large datasets and making it suitable for implementation in cloud environments.","Support vector machines,
Training,
Big data,
Kernel,
Quadratic programming,
Training data,
Indexes"
"A Low-Profile, High-Gain, and Full-Band SubArray of Cavity-Backed Slot Antenna","A four-element array of cavity-backed slot antennas with high-gain and low cross-polarization is presented. The subarray is fed by a single microstrip line coupled to the low-profile cavity and provides the entire X-band bandwidth. This subarray is envisioned as the building block (tile) for the construction of scalable low-profile ultrawideband antenna arrays. The slot array is composed of a thin rectangular cavity of dimensions 1.2λL × 1.2λL × 0.15λL (λL is the free space wavelength at the lowest frequency of operation) on which four slots are cut out for electromagnetic radiation. It is demonstrated that by inserting metallic septa with appropriate locations and sizes inside the cavity, multiple resonances with desired field distribution can be excited resulting in a wideband slot antenna with consistent radiation characteristics over 60% fractional bandwidth. Also, a compact end-launch microstrip to reduced-height waveguide transition is presented to feed the antenna. Silver 3-D printing is used to fabricate the cavity and the standard printed circuit board technology is used to fabricate the feed. The overall antenna bandwidth, when integrated with the microstrip feed section, is shown to be 40% over which a minimum gain of 11 dBi is demonstrated.",
Event-Triggered Distributed Control of Nonlinear Interconnected Systems Using Online Reinforcement Learning With Exploration,"In this paper, a distributed control scheme for an interconnected system composed of uncertain input affine nonlinear subsystems with event triggered state feedback is presented by using a novel hybrid learning scheme-based approximate dynamic programming with online exploration. First, an approximate solution to the Hamilton-Jacobi-Bellman equation is generated with event sampled neural network (NN) approximation and subsequently, a near optimal control policy for each subsystem is derived. Artificial NNs are utilized as function approximators to develop a suite of identifiers and learn the dynamics of each subsystem. The NN weight tuning rules for the identifier and event-triggering condition are derived using Lyapunov stability theory. Taking into account, the effects of NN approximation of system dynamics and boot-strapping, a novel NN weight update is presented to approximate the optimal value function. Finally, a novel strategy to incorporate exploration in online control framework, using identifiers, is introduced to reduce the overall cost at the expense of additional computations during the initial online learning phase. System states and the NN weight estimation errors are regulated and local uniformly ultimately bounded results are achieved. The analytical results are substantiated using simulation studies.","Artificial neural networks,
Optimal control,
Interconnected systems,
System dynamics,
Cost function,
Decentralized control,
Learning (artificial intelligence)"
A speech enhancement algorithm by iterating single- and multi-microphone processing and its application to robust ASR,"We propose a speech enhancement algorithm based on single- and multi-microphone processing techniques. The core of the algorithm estimates a time-frequency mask which represents the target speech and use masking-based beamforming to enhance corrupted speech. Specifically, in single-microphone processing, the received signals of a microphone array are treated as individual signals and we estimate a mask for the signal of each microphone using a deep neural network (DNN). With these masks, in multi-microphone processing, we calculate a spatial covariance matrix of noise and steering vector for beamforming. In addition, we propose a masking-based post-filter to further suppress the noise in the output of beamforming. Then, the enhanced speech is sent back to DNN for mask re-estimation. When these steps are iterated for a few times, we obtain the final enhanced speech. The proposed algorithm is evaluated as a frontend for automatic speech recognition (ASR) and achieves a 5.05% average word error rate (WER) on the real environment test set of CHiME-3, outperforming the current best algorithm by 13.34%.",
FPGA-based neural probe positioning to improve spike sorting with OSort algorithm,"The extracellular measurement of brain electrical activity contains local field potentials and mixtures of action potentials generated by the neurons. It is essential to determine which individual neuron produces the recorded unit activity, so spike sorting methods are used. High channel-count neural probes are capable of recording the activity of large neural ensembles from up to more than hundred individual brain positions simultaneously, pose an even greater challenge for spike sorting applied on general-purpose hardware. Real-time clinical applications could greatly benefit from a hardware-accelerated data processing, especially in the case of Field-Programmable Gate Arrays (FPGAs) or Application Specific Integrated Circuits (ASICs), which are energy-efficient compared to traditional CPUs or GPUs, and can significantly reduce the computation time required to process large amounts of high-dimensional data. In this paper, we present a real-time FPGA-based implementation of a multi-channel Online Sorting (OSort) algorithm to pre-cluster neural data. Based on this pre-processing the neurobiologists can fine-tune the position of neural probe and improve the efficiency of offline spike sorting.",
Event-Triggered Adaptive Dynamic Programming for Continuous-Time Systems With Control Constraints,"In this paper, an event-triggered near optimal control structure is developed for nonlinear continuous-time systems with control constraints. Due to the saturating actuators, a nonquadratic cost function is introduced and the Hamilton-Jacobi-Bellman (HJB) equation for constrained nonlinear continuous-time systems is formulated. In order to solve the HJB equation, an actor-critic framework is presented. The critic network is used to approximate the cost function and the action network is used to estimate the optimal control law. In addition, in the proposed method, the control signal is transmitted in an aperiodic manner to reduce the computational and the transmission cost. Both the networks are only updated at the trigger instants decided by the event-triggered condition. Detailed Lyapunov analysis is provided to guarantee that the closed-loop event-triggered system is ultimately bounded. Three case studies are used to demonstrate the effectiveness of the proposed method.","Optimal control,
Nonlinear systems,
Cost function,
Neural networks,
Adaptive systems,
Dynamic programming"
Analytical Model and Performance Evaluation of Long-Term Evolution for Vehicle Safety Services,"In a traffic jam or dense vehicle environment, vehicular ad hoc networks (VANETs) cannot meet the safety requirement due to serious packet collisions. The traditional cellular network solves packet collisions but suffers from long end-to-end delay. Third-Generation Partnership Project (3GPP) Long-Term Evolution (LTE) overcomes both drawbacks; thus, it may be used, instead of VANETs, in some extreme environments. We use Markov models with dynamic scheduling and semipersistent scheduling (SPS) to evaluate how many idle resources of LTE can be provided for safety services and how safety applications impact LTE traditional users. Based on the analysis, we propose to reserve the idle radio resources in LTE for vehicular safety services (LTE-V). Additionally, we propose the weighted-fair-queuing (WFQ) algorithm to schedule beacons for safety services using the LTE reserved resources. Numerical results verify that the proposed mechanism can significantly improve the reliability of safety applications by borrowing limited LTE bandwidth. We also build an NS3 simulation platform to verify the effectiveness of the proposed Markov models. Finally, the reliability of applications, including cooperation collision warning (CCW), slow vehicle indication (SVI), and rear-end collision warning (RCW), using dedicated short-range communication (DSRC) with LTE-V, are evaluated. The simulation results demonstrate that the stringent quality-of-service (QoS) requirement of the aforementioned three applications can be satisfied, even under heavy traffic.","Analytical models,
Safety,
Vehicular ad hoc networks,
Vehicles,
Markov processes,
Dynamic scheduling,
Reliability"
Online Training of an Opto-Electronic Reservoir Computer Applied to Real-Time Channel Equalization,"Reservoir computing is a bioinspired computing paradigm for processing time-dependent signals. The performance of its analog implementation is comparable to other state-of-the-art algorithms for tasks such as speech recognition or chaotic time series prediction, but these are often constrained by the offline training methods commonly employed. Here, we investigated the online learning approach by training an optoelectronic reservoir computer using a simple gradient descent algorithm, programmed on a field-programmable gate array chip. Our system was applied to wireless communications, a quickly growing domain with an increasing demand for fast analog devices to equalize the nonlinear distorted channels. We report error rates up to two orders of magnitude lower than previous implementations on this task. We show that our system is particularly well suited for realistic channel equalization by testing it on a drifting and a switching channel and obtaining good performances.","Reservoirs,
Computers,
Training,
Field programmable gate arrays,
Wireless communication,
Nonlinear distortion,
Real-time systems"
Ant Colony Optimization-Inspired ICN Routing with Content Concentration and Similarity Relation,"In this letter, we propose a novel Ant Colony Optimization (ACO)-inspired Information-Centric Networking (ICN) Routing mechanism based on Content concentration and Similarity relation (AIRCS). At first, we propose a continuous content concentration model to conduct the interest forwarding. Second, we propose a similarity relation model between two content routers to act as a heuristic factor to facilitate the interest forwarding. Third, we propose a computation scheme about the forwarding probability with content concentration and similarity relation to determine which outgoing interface is used to forward interest request. Finally, we design the ICN routing mechanism based on the probabilistic forwarding to retrieve the closest content copy. The experimental results show that AIRCS has good performance.",
Real-time human detection with depth camera via a physical radius-depth detector and a CNN descriptor,"Real-time human detection is important for a wide range of applications. In this paper, a two-staged method has been developed for real-time human detection in cluttered and dynamic environments with depth data. We start with generating a set of possible human head-tops to ensure all human locations are included. To this end, a novel physical radius-depth (PRD) detector is proposed to quickly detect human candidates. The second stage applies a convolutional neural network (CNN), aiming at extracting feature of human upper body automatically instead of hand-crafting, and then on the basis of CNN feature genuine human candidates are preserved while false ones are filtered out. Experiment results on four publicly available datasets, including a dataset under weak illumination or even total darkness, show that the proposed method can reliably detect human in RGB-D videos in real time without GPU acceleration, and yields higher accuracy than the compared state-of-the-art approaches.","Head,
Detectors,
Feature extraction,
Real-time systems,
Cameras,
Lighting,
Video sequences"
Video-Based Heartbeat Rate Measuring Method Using Ballistocardiography,"Video-based heartbeat rate measurement is a rapidly growing application in remote health monitoring. Video-based heartbeat rate measuring methods operate mainly by estimating photoplethysmography or ballistocardiography signals. These methods operate by estimating the microscopic color change in the face or by estimating the microscopic rigid motion of the head/ facial skin. However, the robustness to motion artifacts caused by illumination variance and motion variance of the subject poses main challenge. We present a video-based heartbeat rate measuring framework to overcome these problems by using the principle of ballistocardiography. In this paper, we proposed a ballistocardiography model based on Newtons third law of force and dynamics of harmonic oscillation. We formulate a framework based on the ballistocardiography model to measure the rigid involuntary head motion caused by the ejection of the blood from the heart. Our proposed framework operates by estimating the motion of multivariate feature points to estimate the heartbeat rate autonomously. We evaluated our proposed framework along with existing video-based heartbeat rate measuring methods with three databases, namely; MAHNOB HCI database, human-computer interaction database, and driver health monitoring database. Our proposed framework outperformed existing methods by reporting a low mean error rate of 4.34 bpm with a standard deviation of 3.14 bpm, root mean square error of 5.29 with a high Pearson correlation coefficient of 0.91. The proposed method also operated robustly in the human-computer interaction database and driver health monitoring database by overcoming the issues related to illumination and motion variance.","Heart beat,
Blood,
Face,
Force,
Biomedical measurement,
Databases"
Structure-From-Motion in Spherical Video Using the von Mises-Fisher Distribution,"In this paper, we present a complete pipeline for computing structure-from-motion from the sequences of spherical images. We revisit problems from multiview geometry in the context of spherical images. In particular, we propose methods suited to spherical camera geometry for the spherical-n-point problem (estimating camera pose for a spherical image) and calibrated spherical reconstruction (estimating the position of a 3-D point from multiple spherical images). We introduce a new probabilistic interpretation of spherical structure-from-motion which uses the von Mises-Fisher distribution to model noise in spherical feature point positions. This model provides an alternate objective function that we use in bundle adjustment. We evaluate our methods quantitatively and qualitatively on both synthetic and real world data and show that our methods developed for spherical images outperform straightforward adaptations of methods developed for perspective images. As an application of our method, we use the structure-from-motion output to stabilise the viewing direction in fully spherical video.",
A Novel High-Gain Tetrahedron Origami,"In this letter, a novel high-gain tetrahedron origami antenna is introduced. The antenna comprises a triangular-shaped monopole, a reflector, and two parasitic strip directors on a paper substrate. The directors and the reflector are employed to increase the antenna gain. The step-by-step origami folding procedure is presented in detail. The proposed design of antenna is verified by both simulations and measurements with a fabricated prototype. The antenna exhibits a 10-dB impedance bandwidth of 66% (2-4 GHz) and a peak gain of 9.5 dBi at 2.6 GHz.","Antenna measurements,
Gain,
Reflector antennas,
Impedance,
Bandwidth,
Reflection coefficient"
Dynamic Clustering and User Association in Wireless Small-Cell Networks With Social Considerations,"In this paper, a novel social network-aware user association in wireless small cell networks with underlaid deviceto-device (D2D) communication is investigated. The proposed approach exploits strategic social relationships between user equipments (TIEs) and their physical proximity to optimize the overall network performance. This problem is formulated as a matching game between TIEs and their serving nodes (SNs) in which, an SN can be a small cell base station (SCBS) or an important UE with D2D capabilities. The problem is cast as a many-to-one matching game in which TIEs and SNs rank one another using preference relations that capture both the wireless aspects (i.e., received signal strength, traffic load, etc.) and users' social ties (e.g., TIE proximity and social distance). Due to the combinatorial nature of the network-wide TIE-SN matching, the problem is decomposed into a dynamic clustering problem in which SCBSs are grouped into disjoint clusters based on mutual interference. Subsequently, an TIE-SN matching game is carried out per cluster. The game under consideration is shown to belong to a class of matching games with externalities arising from interference and peer effects due to users social distance, enabling TIEs and SNs to interact with one another until reaching a stable matching. Simulation results show that the proposed social-aware user association approach yields significant performance gains, reaching up to 26%, 24%, and 31% for 5th, 50th, and 95th percentiles for TIE throughputs, respectively, as compared to the classical social-unaware baseline.",
QoE-Guided Warping for Stereoscopic Image Retargeting,"In the field of stereoscopic 3D (S3D) display, it is an interesting as well as meaningful issue to retarget the stereoscopic images to the target resolution, while the existing stereoscopic image retargeting methods do not fully take user's Quality of Experience (QoE) into account. In this paper, we have presented a QoE-guided warping method for stereoscopic image retargeting, which retarget the stereoscopic image and adapt its depth range to the target display while promoting user's QoE. Our method takes shape preservation, visual comfort preservation, and depth perception preservation energies into account, and simultaneously optimizes the 2D coordinates and depth information in 3D space. It also considers the specific viewing configuration in the visual comfort and depth perception preservation energy constraints. Experimental results on visually uncomfortable and comfortable stereoscopic images demonstrate that in comparison with the existing stereoscopic image retargeting methods, the proposed method can achieve a reasonable performance optimization among the QoE's factors of image quality, visual comfort, and depth perception, leading to promising overall S3D experience.","Stereo image processing,
Three-dimensional displays,
Visualization,
Two dimensional displays,
Optimization,
Distortion"
Decentralized Dynamic Optimization for Power Network Voltage Control,"Voltage control in power distribution networks has been greatly challenged by the increasing penetration of volatile and intermittent devices. These devices can also provide limited reactive power resources that can be used to regulate the network-wide voltage. A decentralized voltage control strategy can be designed by minimizing a quadratic voltage mismatch error objective using gradient-projection (GP) updates. Coupled with the power network flow, the local voltage can provide the instantaneous gradient information. This paper aims to analyze the performance of this decentralized GP-based voltage control design under two dynamic scenarios: First, the nodes perform the decentralized update in an asynchronous fashion. Second, the network operating condition is time varying. For the asynchronous voltage control, we improve the existing convergence condition by recognizing that the voltage-based gradient is always up-to-date. By modeling the network dynamics using an autoregressive process and considering time-varying resource constraints, we provide an error bound in tracking the instantaneous optimal solution to the quadratic error objective. This result can be extended to more general constrained dynamic optimization problems with smooth strongly convex objective functions under stochastic processes that have bounded iterative changes. Extensive numerical tests have been performed to demonstrate and validate our analytical results for realistic power networks.","Voltage control,
Reactive power,
Optimization,
Numerical models,
Stochastic processes,
Voltage measurement,
Information processing"
Feature Sensitive Label Fusion With Random Walker for Atlas-Based Image Segmentation,"In this paper, a novel label fusion method is proposed for brain magnetic resonance image segmentation. This label fusion method is formulated on a graph, which embraces both label priors from atlases and anatomical priors from target image. To represent a pixel in a comprehensive way, three kinds of feature vectors are generated, including intensity, gradient, and structural signature. To select candidate atlas nodes for fusion, rather than exact searching, randomized k-d tree with spatial constraint is introduced as an efficient approximation for high-dimensional feature matching. Feature sensitive label prior (FSLP), which takes both the consistency and variety of different features into consideration, is proposed to gather atlas priors. As FSLP is a non-convex problem, one heuristic approach is further designed to solve it efficiently. Moreover, based on the anatomical knowledge, parts of the target pixels are also employed as the graph seeds to assist the label fusion process, and an iterative strategy is utilized to gradually update the label map. The comprehensive experiments carried out on two publicly available databases give results to demonstrate that the proposed method can obtain better segmentation quality.","Image segmentation,
Feature extraction,
Biomedical imaging,
Sensitivity,
Labeling,
Image analysis,
Image registration"
Transparent cross-technology communication over data traffic,"Cross-technology communication (CTC) techniques are introduced in recent literatures to explore the opportunities of collaboration between heterogeneous wireless technologies, such as WiFi and ZigBee. Their applications include context-aware services and global channel coordination. However, state-of-the-art CTC schemes either suffer from channel inefficiency, low throughput, or disruption to existing networks. This paper presents the CTC via data packets (DCTC), which takes advantage of abundant existing data packets to construct recognizable energy patterns. DCTC features (i) a significant enhancement in CTC throughput while (ii) keeping transparent to upper layer protocols and applications. Our design also features advanced functions including multiplexing to support concurrent transmissions of multiple DCTC senders and adaptive rate control according to the traffic volume. Testbed implementations across WiFi and ZigBee platforms demonstrate reliable bidirectional communication of over 95% in accuracy while achieving throughput 2.3x of the state of the art. Meanwhile, experiment results show that DCTC has little and bounded impact on the delay and throughput of original data traffic.",
Experimental Implementation of Frequency Regulation Services Using Commercial Buildings,"This paper illustrates the potential of commercial buildings to act as frequency reserves providers through an experimental demonstration conducted in a multi-zone university building. The proposed control methodology is presented in detail, including the control architecture, the controller design, model identification, and hardware description. Finally, the effectiveness of the presented approach is tested by means of simulations and experiments in a controlled environment.","Buildings,
Power demand,
Frequency control,
Automatic generation control,
Uncertainty,
Optimization,
Computer architecture"
3D Feature Constrained Reconstruction for Low Dose CT Imaging,"Low dose computed tomography (LDCT) images are often highly degraded by amplified mottle noise and streak artifacts. How to maintain image quality under low dose scan protocols is a well-known challenge. Recently, sparse representation based techniques have been shown efficient in improving such CT images. In this paper, we propose a 3D feature constrained reconstruction (3D-FCR) algorithm for LDCT image reconstruction. The feature information used in the 3D-FCR algorithm relies on a 3D feature dictionary constructed from available high quality standard-dose CT (SDCT) sample. The CT voxels and the sparse coefficients are sequentially updated using an alternating minimization scheme. The performance of the 3D-FCR algorithm was assessed through experiments conducted on phantom simulation data and clinical data. A comparison with previously reported solutions was also performed. Qualitative and quantitative results show that the proposed method can lead to a promising improvement of LDCT image quality.","Dictionaries,
Image reconstruction,
Computed tomography,
Three-dimensional displays,
Minimization,
Algorithm design and analysis,
Image quality"
Secrecy Analysis of MIMO Wiretap Channels With Low-Complexity Receivers Under Imperfect Channel Estimation,"This paper studies the achievable secrecy performance of multiple-input multiple-output wiretap channels in the presence of imperfect channel state information (CSI) with practical low-complexity transmission schemes. In particular, we propose a general order transmit antenna selection and power-efficient output-threshold maximal ratio combining scheme. Two separate cases depending on the availability of the eavesdropper's CSI at the transmitter are considered. New closed-form expressions of the secrecy outage probability and the average secrecy rate are obtained. In addition, the secrecy diversity order and array gains, high signal-to-noise ratio slope, and power offset are characterized through asymptotic analysis, which enables the characterization of the effect of imprecise transmit antenna selection, output-threshold, and imperfect CSI on the secrecy performance. Numerical results are presented to validate the main outcomes of this paper.","Transmitting antennas,
Receiving antennas,
Channel estimation,
Signal to noise ratio,
Fading channels,
Diversity reception"
"GuideBeacon: Beacon-based indoor wayfinding for the blind, visually impaired, and disoriented","There are currently few options for navigational aids for the blind and visually impaired (BVI) in large indoor spaces. Such indoor spaces can be difficult to navigate even for the general sighted population if they are disoriented due to unfamiliarity or other reasons. This paper presents an indoor wayfinding system called GuideBeacon for the blind, visually impaired, and disoriented (BVID) that assists people in navigating between any two points within indoor environments. The GuideBeacon system allows users equipped with smartphones to interact with low cost Bluetooth-based beacons deployed strategically within the indoor space of interest to navigate their surroundings. This paper describes the technical challenges faced in designing such a system, the design decisions made in building the current version of the GuideBeacon system, the solutions developed to meet the technical challenges, and results from the evaluation of the system. Results presented in this paper obtained from field testing GuideBeacon with BVI and sighted participants suggests that it can be used by the BVID for navigation in large indoor spaces independently and effectively.","Navigation,
User interfaces"
Adaptive Mode Control for Few-Mode Fiber Based Sensors and Sensor Networks,"The development of mode division multiplexing has found numerous interesting applications in optical sensing. A major challenge has been how to control the mode composition of the interrogation signals. In this work, we presented a time-domain method that can adaptively control the form of optical signals at multiple locations in a two-mode-fiber. We also carry out a preliminary study that suggests the method of adaptive mode control is compatible with the requirements of optical sensing.","Optical fiber sensors,
Bragg gratings,
Optical reflection,
Optical feedback"
Single Image Super-Resolution via Adaptive High-Dimensional Non-Local Total Variation and Adaptive Geometric Feature,"Single image super-resolution (SR) is very important in many computer vision systems. However, as a highly ill-posed problem, its performance mainly relies on the prior knowledge. Among these priors, the non-local total variation (NLTV) prior is very popular and has been thoroughly studied in recent years. Nevertheless, technical challenges remain. Because NLTV only exploits a fixed non-shifted target patch in the patch search process, a lack of similar patches is inevitable in some cases. Thus, the non-local similarity cannot be fully characterized, and the effectiveness of NLTV cannot be ensured. Based on the motivation that more accurate non-local similar patches can be found by using shifted target patches, a novel multishifted similar-patch search (MSPS) strategy is proposed. With this strategy, NLTV is extended as a newly proposed super-high-dimensional NLTV (SHNLTV) prior to fully exploit the underlying non-local similarity. However, as SHNLTV is very high-dimensional, applying it directly to SR is very difficult. To solve this problem, a novel statistics-based dimension reduction strategy is proposed and then applied to SHNLTV. Thus, SHNLTV becomes a more computationally effective prior that we call adaptive high-dimensional non-local total variation (AHNLTV). In AHNLTV, a novel joint weight strategy that fully exploits the potential of the MSPS-based non-local similarity is proposed. To further boost the performance of AHNLTV, the adaptive geometric duality (AGD) prior is also incorporated. Finally, an efficient split Bregman iteration-based algorithm is developed to solve the AHNLTV-AGD-driven minimization problem. Extensive experiments validate the proposed method achieves better results than many state-of-the-art SR methods in terms of both objective and subjective qualities.","Image resolution,
Kernel,
Indexes,
Image reconstruction,
Learning systems,
Interpolation,
Image edge detection"
Identity management using blockchain for cognitive cellular networks,"Cloud-centric cognitive cellular networks utilize dynamic spectrum access and opportunistic network access technologies as a means to mitigate spectrum crunch and network demand. However, furnishing a carrier with personally identifiable information for user setup increases the risk of profiling in cognitive cellular networks, wherein users seek secondary access at various times with multiple carriers. Moreover, network access provisioning - assertion, authentication, authorization, and accounting - implemented in conventional cellular networks is inadequate in the cognitive space, as it is neither spontaneous nor scalable. In this paper, we propose a privacy-enhancing user identity management system using blockchain technology which places due importance on both anonymity and attribution, and supports end-to-end management from user assertion to usage billing. The setup enables network access using pseudonymous identities, hindering the reconstruction of a subscriber's identity. Our test results indicate that this approach diminishes access provisioning duration by up to 4x, decreases network signaling traffic by almost 40%, and enables near real-time user billing that may lead to approximately 3x reduction in payments settlement time.","Integrated circuits,
Contracts,
Cellular networks,
Privacy,
Cryptography,
Protocols"
Construction of MDS Codes With Complementary Duals,"A linear complementary dual (LCD) code is a linear code with complimentary dual. LCD codes have been extensively studied in literature. On the other hand, maximum distance separable (MDS) codes are an important class of linear codes that have found wide applications in both theory and practice. However, little is known about MDS codes with complimentary duals. The main purpose of this paper is to construct several classes of MDS codes with complimentary duals, i.e., LCD MDS codes, through generalized Reed-Solomon codes.","Reed-Solomon codes,
Liquid crystal displays,
Linear codes,
Geometry,
Hamming weight,
Indexes,
Linear programming"
Discontinuous Observers Design for Finite-Time Consensus of Multiagent Systems With External Disturbances,"This brief investigates the problem of finite-time robust consensus (FTRC) for second-order nonlinear multiagent systems with external disturbances. Based on the global finite-time stability theory of discontinuous homogeneous systems, a novel finite-time convergent discontinuous disturbed observer (DDO) is proposed for the leader-following multiagent systems. The states of the designed DDO are then used to design the control inputs to achieve the FTRC of nonlinear multiagent systems in the presence of bounded disturbances. The simulation results are provided to validate the effectiveness of these theoretical results.","Multi-agent systems,
Observers,
Computer crime,
Uncertain systems,
Robustness,
Topology,
Learning systems"
Single-Perturbation-Cycle Online Battery Impedance Spectrum Measurement Method With Closed-Loop Control of Power Converter,"This paper presents a method for an online real-time electrochemical impedance spectroscopy (EIS) measurement of batteries using closed-loop control of power converter. Unlike the previously proposed method which allows the measurement of the ac impedance for a single frequency, the presented method in this paper allows for obtaining the EIS for a spectrum of frequencies by using the information included in a single perturbation cycle, or a few cycles of perturbation to obtain a more accurate EIS with a very wide frequency range. This will result in faster EIS measurement for a spectrum of frequencies and under the same battery operating conditions. The presented method utilizes closed-loop control operation for the EIS measurement functionality, which allows for better control of the output voltage and for upgrading the concept to be able to achieve no added perturbation ripple at the output of the system. The presented online real-time EIS measurement method utilizes a power converter with closed-loop control in order to create an output voltage step-function perturbation at a given frequency to generate battery voltage and current responses. By applying Fourier analysis to these responses, an EIS can be obtained for a range of frequencies equal or higher than the perturbation frequency of the step function. In addition, this paper presents a method to eliminate the added perturbation ripple when two or more power converters are used. The theoretical basis and experimental prototype results are provided to illustrate and validate the presented method.",
Quantitative measures to evaluate neural network weight initialization strategies,"It has been reported numerous times in the neural network research literature that weight initialization in neural networks affects the learning rate, the convergence rate and the probability of correct classification. In this research paper we develop a theory for objectively testing various weight initialization strategies. Our theory provides a quantitative measure for each available weight initialization strategy. Thus for each initialization strategy and each epoch we estimate the conditional probability distribution function of correct classification given the epoch number. For each initialization strategy and for a given epoch the conditional probability is a random variable with certain probability distribution function and certain mean and variance. Based on multivariate analysis, statistics of extremes, analysis of variance and estimation theory we develop an objective framework and measurements to assess if one strategy is better than another or if the differences between strategies are not significant but they are due to random fluctuations.","Neurons,
Random variables,
Convergence,
Training,
Neural networks,
Probability distribution,
Weight measurement"
Lateral Organic Semiconductor Photodetector: Effect of Electrode Spacing,"We have studied the effect of electrode spacing in a bottom contact multilayer lateral metal-insulator-organic semiconductor-insulator-metal (MIOSIM) photodetector. Measured results show that the darkcurrent and photocurrent of the lateral MIOSIM photodetector are independent of the lateral spacing between the electrodes, which is in contrast to previously reported lateral organic photodetectors. Also, the ratio of darkcurrent and photocurrent remains constant for a range of optical illumination intensities and biasing voltages. We conclude that the conduction path for both the photocurrent and darkcurrent in the reported lateral MIOSIM photodetector is primarily due to vertical charge transport starting at the metal electrodes and reaching the organic semiconductor layer through a polystyrene (PS) intermediate interface layer.","Photodetectors,
Organic semiconductors,
Detectors,
Semiconductor device measurement,
Dark current,
Photoconductivity,
Electrodes"
Using Sensitivity Analysis and Cross-Association for the Design of Intrusion Detection Systems in Industrial Cyber-Physical Systems,"The fourth industrial revolution, also known as Industry 4.0, brings many advantages including innovative applications and services, new technologies and advanced features, increased operational benefits, and reduced installation costs. However, this technological advancement also exposes several challenges pertaining to the development of cyber-physical industrial architectures, resilient communication systems, and secure data exchange. This paper develops a systematic methodology for designing intrusion detection systems (IDS) specially tailored to address the cyber and physical dimensions of these systems. The approach is aimed at reducing the number of monitored parameters by adopting a three-phase design strategy embracing sensitivity analysis, cross-association, and optimal IDS design. To this end, phase 1 embraces sensitivity analysis to identify sensitive variables to specific interventions (e.g., control signals and cyber attacks), phase 2 adopts the cross-association assessment to optimally structure the process variables in groups that are the most sensitive to groups of interventions, and finally, phase 3 optimally assigns the most sensitive process variables to IDS, while enforcing the IDS capacity limitations and redundancy requirements. Numerical results on a realistic vinyl acetate monomer process show that the approach can reduce the number of variables by 76.8%, thus reducing the complexity and the costs of the detection infrastructure.","Monitoring,
Cyber-physical systems,
Sensitivity analysis,
Intrusion detection,
Redundancy,
Industries,
Systematics"
Identifying Core Concepts of Cybersecurity: Results of Two Delphi Processes,"This paper presents and analyzes results of two Delphi processes that polled cybersecurity experts to rate cybersecurity topics based on importance, difficulty, and timelessness. These ratings can be used to identify core concepts-cross-cutting ideas that connect knowledge in the discipline. The first Delphi process identified core concepts that should be learned in any first course on cybersecurity. The second identified core concepts that any cybersecurity professional should know upon graduating from college. Despite the rapidly growing demand for cybersecurity professionals, it is not clear what defines foundational cybersecurity knowledge. Initial data from the Delphi processes lay a foundation for defining the core concepts of the field and, consequently, provide a common starting point to accelerate the development of rigorous cybersecurity education practices. These results provide a foundation for developing evidence-based educational cybersecurity assessment tools that will identify and measure effective methods for teaching cybersecurity. The Delphi results can also be used to inform the development of curricula, learning exercises, and other educational materials and policies.","Computer security,
Education,
Tools,
Cats,
Computer science,
Engineering profession"
Person Reidentification in a Distributed Camera Network Framework,"Plenty of research has been conducted to obtain the best reidentification performance between a single camera-pairs. None of the current approaches has addressed the reidentification in a camera network by considering the network topology (i.e., the structure of the monitored environment). We introduce a distributed network person reidentification framework which introduces the following contributions. 1) a camera matching cost to measure the reidentification performance between nodes of the network and 2) a derivation of the distance vector algorithm which allows to learn the network topology thus to prioritize and limit the cameras inquired for the matching of the probe. Results on three benchmark datasets show that the network topology can be learned in an unsupervised fashion and network-wise reidentification performance improves. As a side effect, we obtain that the communication bandwidth usage is reduced.","Cameras,
Probes,
Routing,
Measurement,
Network topology,
Feature extraction,
Bandwidth"
Vector Quantization and Clustered Key Mapping for Channel-Based Secret Key Generation,"This paper proposes a vector-quantization-based secret key generation (SKG) procedure to efficiently extract shared secret keys from correlated channel observations at two communicating terminals, Alice and Bob. Most existing SKG schemes utilize scalar quantization to extract secret key bits separately from each individual channel observation. This approach is simple to implement but yields higher key disagreement probability (or lower key entropy) compared with vector-quantization-based approaches. However, regardless of the quantizer design, quantization for SKG often suffers from the so-called cell-boundary problem, which occurs when the channel observations at Alice and Bob lie close to the quantization cell boundaries, resulting in high probability of key disagreement. In this paper, a general SKG procedure that utilizes sample and quantizer selection techniques to avoid this problem is first proposed. The vector quantizer adopted in the above procedure is designed by minimizing the quadratic distortion between the true channel vector and the noisy observation at Alice (or Bob). Then, by considering the case where the eavesdropper (Eve) may observe a channel vector that is correlated with that observed by Alice and Bob, a clustered key mapping scheme that assigns each secret key to multiple quantization cells in different clusters is also proposed to induce additional randomness at Eve and, thus, maintain high conditional key entropy. The effectiveness of the proposed schemes is demonstrated through computer simulations.",
Models for Music Analysis From a Markov Logic Networks Perspective,"Analyzing and formalizing the intricate mechanisms of music is a very challenging goal for Artificial Intelligence. Dealing with real audio recordings requires the ability to handle both uncertainty and complex relational structure at multiple levels of representation. Until now, these two aspects have been generally treated separately, probability being the standard way to represent uncertainty in knowledge, while logical representation being the standard way to represent knowledge and complex relational information. Several approaches attempting a unification of logic and probability have recently been proposed. In particular, Markov logic networks (MLNs), which combine first-order logic and probabilistic graphical models, have attracted increasing attention in recent years in many domains. This paper introduces MLNs as a highly flexible and expressive formalism for the analysis of music that encompasses most of the commonly used probabilistic and logic-based models. We first review and discuss existing approaches for music analysis. We then introduce MLNs in the context of music signal processing by providing a deep understanding of how they specifically relate to traditional models, specifically hidden Markov models and conditional random fields. We then present a detailed application of MLNs for tonal harmony music analysis that illustrates the potential of this framework for music processing.","Hidden Markov models,
Music,
Probabilistic logic,
Multiple signal classification,
Computational modeling,
Estimation,
Analytical models"
Advancing Nonvolatile Computing With Nonvolatile NCFET Latches and Flip-Flops,"Nonvolatile computing has been proven to be effective in dealing with power supply outages for on-chip check-pointing in emerging energy-harvesting Internet-of-Things applications. It also plays an important role in power-gating to cut off leakage power for higher energy efficiency. However, existing on-chip state backup solutions for D flip-flop (DFF) have a bottleneck of significant energy and/or latency penalties which limit the overall energy efficiency and computing progress. Meanwhile, these solutions rely on external control that limits compatibility and increases system complexity. This paper proposes an approach to fundamentally advancing the nonvolatile computing paradigm by intrinsically nonvolatile area-efficient latches and flip-flops designs using negative capacitance FET. These designs consume fJ-level energy and ns-level intrinsic latency for a backup plus restore operation, e.g., 2.4 fJ in energy and 1.1 ns in time for one proposed nonvolatile DFF with a supply power of 0.80 V.","Nonvolatile memory,
Capacitors,
Logic gates,
Latches,
Hysteresis,
MOSFET,
Capacitance"
Fuzzy Linear Regression Discriminant Projection for Face Recognition,"How to capture distinctive features from facial images when there are large variations in illumination, poses, and expressions is important for the face recognition problems. This paper introduces a novel algorithm called fuzzy linear regression discriminant projection (FLRDP) for face recognition. The proposed algorithm FLRDP seeks to generate an efficient subspace for the LRC method and could effectively handle variations between facial images. To be specific, FLRDP first computes the gradual membership degrees of each sample to corresponding classes, and then incorporates such membership degree information into the construction of the fuzzy between-class and within-class reconstruction errors. Finally, the criterion function is derived via maximizing the ratio of the fuzzy between-class reconstruction error to the fuzzy within-class reconstruction error. Experimental results carried out on the ORL, CMU PIE, and FERET face databases show the superiority of our proposed method over other state-of-the-art algorithms.","Feature extraction,
Image reconstruction,
Face recognition,
Testing,
Training,
Principal component analysis,
Manifolds"
Malaria Parasite Detection From Peripheral Blood Smear Images Using Deep Belief Networks,"In this paper, we propose a novel method to identify the presence of malaria parasites in human peripheral blood smear images using a deep belief network (DBN). This paper introduces a trained model based on a DBN to classify 4100 peripheral blood smear images into the parasite or non-parasite class. The proposed DBN is pre-trained by stacking restricted Boltzmann machines using the contrastive divergence method for pre-training. To train the DBN, we extract features from the images and initialize the visible variables of the DBN. A concatenated feature of color and texture is used as a feature vector in this paper. Finally, the DBN is discriminatively fine-tuned using a backpropagation algorithm that computes the probability of class labels. The optimum size of the DBN architecture used in this paper is 484-600-600-600-600-2, in which the visible layer has 484 nodes and the output layer has two nodes with four hidden layers containing 600 hidden nodes in every layer. The proposed method has performed significantly better than the other state-of-the-art methods with an F-score of 89.66%, a sensitivity of 97.60%, and specificity of 95.92%. This paper is the first application of a DBN for malaria parasite detection in human peripheral blood smear images.","Diseases,
Blood,
Computer architecture,
Feature extraction,
Image color analysis,
Training,
Microscopy"
Towards Social-Aware Ridesharing Group Query Services,"With the deep penetration of smartphones and geo-locating devices, ridesharing is envisioned as a promising solution to transportation-related problems in metropolitan cities, such as traffic congestion and air pollution. Despite the potential to provide significant societal and environmental benefits, ridesharing has not so far been as popular as expected. Notable barriers include social discomfort and safety concerns when traveling with strangers. To overcome these barriers, in this paper, we propose a new type of Social-aware Ridesharing Group (SaRG) queries which retrieve a group of riders by taking into account their social connections and spatial proximities. While SaRG queries are of practical usefulness, we prove that, however, the SaRG query problem is NP-hard. Thus, we design an efficient algorithm with a set of powerful pruning techniques to tackle this problem. We also present several incremental strategies to accelerate the search speed by reducing repeated computations. Moreover, we propose a novel index tailored to our problem to further speed up query processing. Experimental results on real datasets show that our proposed algorithms achieve desirable performance.","Vehicles,
Social network services,
Cities and towns,
Algorithm design and analysis,
Indexes,
Silicon,
Query processing"
Random Access in C-RAN for User Activity Detection With Limited-Capacity Fronthaul,"Cloud-radio access network (C-RAN) is characterized by a hierarchical structure, in which the baseband-processing functionalities of remote radio heads (RRHs) are implemented by means of cloud computing at a central unit (CU). A key limitation of C-RANs is given by the capacity constraints of the fronthaul links connecting RRHs to the CU. In this letter, the impact of this architectural constraint is investigated for the fundamental functions of random access and active user equipment (UE) identification in the presence of a potentially massive number of UEs. In particular, the standard C-RAN approach based on quantize-and-forward and centralized detection is compared to a scheme based on an alternative CU-RRH functional split that enables local detection. Both techniques leverage Bayesian sparse detection. Numerical results illustrate the relative merits of the two schemes as a function of the system parameters.","Fading channels,
Quantization (signal),
Baseband,
Cloud computing,
Standards,
Bayes methods,
Time-frequency analysis"
Rating Credits of Online Merchants Using Negative Ranks,"Electronic commerce has become increasingly popular. Although it brings significant convenience to people's lives, a purchaser often hesitates to provide a negative rating to a merchant (or commodity) after a bad online shopping experience because his sensitive information (e.g., address, telephone number, and email address) would be available to the merchant. This makes the purchaser uncomfortable and even unsafe, and the purchaser tends to contribute better but untrue ratings. Hence, the privacy of the purchaser's score is vitally important to the development of electronic commerce. In this study, we apply for the first time an artificial immune technique (i.e., the negative survey) to rate the credits of online merchants, and we propose a new credit rating model, called a negative rating model, that could preserve the privacy of the purchaser's score with low additional computational cost. Moreover, the results obtained from our credit rating model exhibited a high correlation with those from the traditional evaluation model. Therefore, the proposed model has promising application prospects.",
JLS-PPC: A Jump Linear System Framework for Networked Control,"We present a unified formalism for multiagent networked control and estimation with scheduling, delays, and packet loss in the communication channels between the controller and distributed sensors and actuators. The modular framework is a combined construction of a stochastic jump linear system (JLS) description of the plant and network effects, a Kalman filter-based estimator, and packetized predictive control, a receding horizon optimization technique with buffering at the actuator. Integration of these elements enables the synthesis of a novel estimation technique that generalizes prior approaches for control and measurement packet loss to the case with schedules, delays, control buffering, and most importantly, delayed and lossy control packet acknowledgments (ACKs). The JLS framework allows a clean separation of jump variable estimation and a posteriori state estimation using a backup-and-rerun strategy, and can handle variable-length ACK histories for multiple independent control communication channels. Finally, we derive modified covariance priors for the filter that account for uncertainty in the control action applied at the vehicle when ACKs are not available and control buffers are used. Simulations with single vehicle and multivehicle systems demonstrate the methods and show the benefits of utilizing delayed and lossy ACKs.","Delays,
Vehicles,
Estimation,
Packet loss,
Scheduling,
Actuators"
Automatic matching and synchronization of user generated videos from a large scale sport event,"Exploiting correlations in the audio, several works in the past have demonstrated the ability to automatically match and synchronize User Generated Video (UGV) files of the same event. In this paper, we focus on the challenging acoustic environment of a large scale athletic event. We show that the chanting of the crowd produces an acoustic background common in the audio streams of different UGVs and we design a novel audio fingerprinting method for organizing the UGV collection based on that content. Results presented with recordings from a crowded football match demonstrate that the proposed approach provides significantly better audio matching performance in comparison to three of the most well known audio fingerprinting techniques.","Videos,
Acoustics,
Radio frequency,
Synchronization,
Correlation,
Robustness"
Perfect Recovery Conditions for Non-negative Sparse Modeling,"Sparse modeling has been widely and successfully used in many applications, such as computer vision, machine learning, and pattern recognition. Accompanied with those applications, significant research has studied the theoretical limits and algorithm design for convex relaxations in sparse modeling. However, theoretical analyses on non-negative versions of sparse modeling are limited in the literature either to a noiseless setting or a scenario with a specific statistical noise model, such as Gaussian noise. This paper studies the performance of non-negative sparse modeling in a more general scenario where the observed signals have an unknown arbitrary distortion, especially focusing on non-negativity constrained and L1-penalized least squares, and gives an exact bound for which this problem can recover the correct signal elements. We pose two conditions to guarantee the correct signal recovery: minimum coefficient condition and nonlinearity versus subset coherence condition. The former defines the minimum weight for each of the correct atoms present in the signal and the latter defines the tolerable deviation from the linear model relative to the positive subset coherence, a novel type of “coherence” metric. We provide rigorous performance guarantees based on these conditions and experimentally verify their precise predictive power in a hyperspectral data unmixing application.","Dictionaries,
Computational modeling,
Analytical models,
Hyperspectral sensors,
Distortion,
Coherence,
Indexes"
EPAS: A Sampling Based Similarity Identification Algorithm for the Cloud,"The explosive growth of data brings new challenges to the data storage and management in cloud environment. These data usually have to be processed in a timely fashion in the cloud. Thus, any increased latency may cause a massive loss to the enterprises. Similarity detection plays a very important role in data management. Many typical algorithms such as Shingle, Simhash, Traits and Traditional Sampling Algorithm (TSA) are extensively used. The Shingle, Simhash and Traits algorithms read entire source file to calculate the corresponding similarity characteristic value, thus requiring lots of CPU cycles and memory space and incurring tremendous disk accesses. In addition, the overhead increases with the growth of data set volume and results in a long delay. Instead of reading entire file, TSA samples some data blocks to calculate the fingerprints as similarity characteristics value. The overhead of TSA is fixed and negligible. However, a slight modification of source files will trigger the bit positions of file content shifting. Therefore, a failure of similarity identification is inevitable due to the slight modifications. This paper proposes an Enhanced Position-Aware Sampling algorithm (EPAS) to identify file similarity for the cloud by modulo file length. EPAS concurrently samples data blocks from the head and the tail of the modulated file to avoid the position shift incurred by the modifications. Meanwhile, an improved metric is proposed to measure the similarity between different files and make the possible detection probability close to the actual probability. Furthermore, this paper describes a query algorithm to reduce the time overhead of similarity detection. Our experimental results demonstrate that the EPAS significantly outperforms the existing well known algorithms in terms of time overhead, CPU and memory occupation. Moreover, EPAS makes a more preferable tradeoff between precision and recall than that of other similarity detection algorithms. Therefore, it is an effective approach of similarity identification for the cloud.",
Spectrum Inference in Cognitive Radio Networks: Algorithms and Applications,"Spectrum inference, also known as spectrum prediction in the literature, is a promising technique of inferring the occupied/free state of radio spectrum from already known/measured spectrum occupancy statistics by effectively exploiting the inherent correlations among them. In the past few years, spectrum inference has gained increasing attention owing to its wide applications in cognitive radio networks (CRNs), ranging from adaptive spectrum sensing, and predictive spectrum mobility, to dynamic spectrum access and smart topology control, to name just a few. In this paper, we provide a comprehensive survey and tutorial on the recent advances in spectrum inference. Specifically, we first present the preliminaries of spectrum inference, including the sources of spectrum occupancy statistics, the models of spectrum usage, and characterize the predictability of spectrum state evolution. By introducing the taxonomy of spectrum inference from a time-frequency-space perspective, we offer an in-depth tutorial on the existing algorithms. Furthermore, we provide a comparative analysis of various spectrum inference algorithms and discuss the metrics of evaluating the efficiency of spectrum inference. We also portray the various potential applications of spectrum inference in CRNs and beyond, with an outlook to the 5th generation mobile communications (5G) and next generation high frequency (HF) communications systems. Last but not least, we highlight the critical research challenges and open issues ahead.",
Delay compensation of 1 PPS timetags in fiber-optic time distribution,"In various fiber-optic time and frequency distribution systems the delay of 1 PPS timetags is stabilized and precisely calibrated. However in a case of long fiber path the 1 PPS signal is seriously delayed in respect to UTC, which is cumbersome in various applications. In this work we present an idea and experimental evaluation of a circuit designed for compensating this delay. The compensation up to 1 s may be introduced in 10 ns steps, and the standard uncertainty of the compensation is app. 550 fs.","Delays,
Time-frequency analysis,
Radiation detectors,
Uncertainty,
Optical fibers,
Jitter,
Phase noise"
ReViNE: Reallocation of Virtual Network Embedding to eliminate substrate bottlenecks,"Perceived as a key enabling technology for the future Internet, Network Virtualization (NV) allows an Infrastructure Provider (InP) to better utilize their Substrate Network (SN) by provisioning multiple Virtual Networks (VNs) from different Service Providers (SPs). A key challenge in NV is to efficiently map the VN requests from SPs on an SN, known as the Virtual Network Embedding (VNE) problem. VNE algorithms are typically online in nature. A VN embedding can become suboptimal over time due to the arrival and departure of other VNs as well as due to changes in SN such as failures. One way to mitigate the impact of such dynamism is to periodically reallocate resources for the existing VNs. VNE reallocation can increase an InP's revenue by decreasing bandwidth consumption and by increasing the possibility of accepting future VNs. In this paper, we study Reallocation of Virtual Network Embedding (ReViNE) problem to minimize the number of over utilized substrate links and total bandwidth cost on the SN. We propose an Integer Linear Programming formulation for the optimal solution (ReViNE-OPT) and a simulated annealing based heuristic (ReViNE-FAST) to solve larger problem instances. Simulation results show that on average our proposed heuristic performs within ~19% of the optimal solution. Moreover, ReViNE-FAST generates more than 2.5× better solutions compared to the state-of-the-art simulated annealing based heuristic for VNE reallocation.","Bandwidth,
Substrates,
Indium phosphide,
III-V semiconductor materials,
Simulated annealing,
Linear programming,
Resource management"
Large-Scale Image Clustering Based on Camera Fingerprints,"Practical applications of digital forensics are often faced with the challenge of grouping large-scale suspicious images into a vast number of clusters, each containing images taken by the same camera. This task can be approached by resorting to the use of sensor pattern noise (SPN), which serves as the fingerprint of the camera. The challenges of large-scale image clustering come from the sheer volume of the image set and the high dimensionality of each image. The difficulties can be further aggravated when the number of classes (i.e., the number of cameras) is much higher than the average size of class (i.e., the number of images acquired by each camera). We refer to this as the NC ≫ SC problem, which is not uncommon in many practical scenarios. In this paper, we propose a novel clustering framework that is capable of addressing the NC ≫ SC problem without a training process. The proposed clustering framework was evaluated on the Dresden image database and compared with the state-of-the-art SPN-based image clustering algorithms. Experimental results show that the proposed clustering framework is much faster than the state-of-the-art algorithms while maintaining a high level of clustering quality.","Cameras,
Clustering algorithms,
Databases,
Training,
Partitioning algorithms,
Algorithm design and analysis,
Computational efficiency"
Glyphs for General Second-Order 2D and 3D Tensors,"Glyphs are a powerful tool for visualizing second-order tensors in a variety of scientic data as they allow to encode physical behavior in geometric properties. Most existing techniques focus on symmetric tensors and exclude non-symmetric tensors where the eigenvectors can be non-orthogonal or complex. We present a new construction of 2d and 3d tensor glyphs based on piecewise rational curves and surfaces with the following properties: invariance to (a) isometries and (b) scaling, (c) direct encoding of all real eigenvalues and eigenvectors, (d) one-to-one relation between the tensors and glyphs, (e) glyph continuity under changing the tensor. We apply the glyphs to visualize the Jacobian matrix fields of a number of 2d and 3d vector fields.","Tensile stress,
Eigenvalues and eigenfunctions,
Two dimensional displays,
Jacobian matrices,
Matrix decomposition,
Symmetric matrices,
Three-dimensional displays"
Towards Perceptual Optimization of the Visual Design of Scatterplots,"Designing a good scatterplot can be difficult for non-experts in visualization, because they need to decide on many parameters, such as marker size and opacity, aspect ratio, color, and rendering order. This paper contributes to research exploring the use of perceptual models and quality metrics to set such parameters automatically for enhanced visual quality of a scatterplot. A key consideration in this paper is the construction of a cost function to capture several relevant aspects of the human visual system, examining a scatterplot design for some data analysis task. We show how the cost function can be used in an optimizer to search for the optimal visual design for a user's dataset and task objectives (e.g., “reliable linear correlation estimation is more important than class separation”). The approach is extensible to different analysis tasks. To test its performance in a realistic setting, we pre-calibrated it for correlation estimation, class separation, and outlier detection. The optimizer was able to produce designs that achieved a level of speed and success comparable to that of those using human-designed presets (e.g., in R or MATLAB). Case studies demonstrate that the approach can adapt a design to the data, to reveal patterns without user intervention.","Visualization,
Measurement,
Correlation,
Cost function,
Data analysis,
Data visualization"
VLCcube: A VLC Enabled Hybrid Network Structure for Data Centers,"Recent results have made a promising case for offering oversubscribed wired data center networks (DCN) with extreme costs. Inter-rack wireless networks are drawing intensive attention to augment such wired DCNs with a few wireless links. Inspired by the promise of easy deployment and plug-and-play, we present VLCcube, a novel inter-rack wireless solution that extends the design of wireless DCN into three further dimensions: (1) all inter-rack links are wireless; (2) there is no imposition of any infrastructure-level alteration on wired production data centers; and (3) it should be plug-and-play, without any need of additional mechanical or electronic control operations. This vision, if realized, will lead to increased flexibility, reduced reconstructing cost, simplified configuration and usage, and outstanding compatibility with existing wired DCNs. Previous proposals, however, are opposed to the last two design rationales. To achieve this vision, the proposed VLCcube augments Fat-Tree, a representative DCN in production data centers, by organizing all racks into a wireless Torus structure via the emerging visible light links. We further present the topology design, hybrid routing, and flow scheduling schemes for VLCcube. Extensive evaluations indicate that VLCcube outperforms Fat-Tree significantly under the existing ECMP flow scheduling scheme, irrespective of the undergoing traffic pattern. Moreover, the performance of VLCcube can be significantly promoted by our congestion-aware flow scheduling scheme. More precisely, compared to ECMP, our flow scheduling scheme makes VLCcube achieve
×1.50
throughput under batched flows,
×2.21
and
×2.59
throughput under two different kinds of online flows.","Servers,
Topology,
Wireless networks,
Scheduling,
Network topology,
Proposals"
A Cooperative Learning-Based Clustering Approach to Lip Segmentation Without Knowing Segment Number,"It is usually hard to predetermine the true number of segments in lip segmentation. This paper, therefore, presents a clustering-based approach to lip segmentation without knowing the true segment number. The objective function in the proposed approach is a variant of the partition entropy (PE) and features that the coincident cluster centroids in pattern space can be equivalently substituted by one centroid with the function value unchanged. It is shown that the minimum of the proposed objective function can be reached provided that: 1) the number of positions occupied by cluster centroids in pattern space is equal to the true number of clusters and 2) these positions are coincident with the optimal cluster centroids obtained under PE criterion. In implementation, we first randomly initialize the clusters provided that the number of clusters is greater than or equal to the ground truth. Then, an iterative algorithm is utilized to minimize the proposed objective function. For each iterative step, not only is the winner, i.e., the centroid with the maximum membership degree, updated to adapt to the corresponding input data, but also the other centroids are adjusted with a specific cooperation strength, so that they are each close to the winner. Subsequently, the initial overpartition will be gradually faded out with the redundant centroids superposed over the convergence of the algorithm. Based upon the proposed algorithm, we present a lip segmentation scheme. Empirical studies have shown its efficacy in comparison with the existing methods.","Entropy,
Image segmentation,
Clustering algorithms,
Linear programming,
Image color analysis,
Partitioning algorithms,
Learning systems"
Accurate Lungs Segmentation on CT Chest Images by Adaptive Appearance-Guided Shape Modeling,"To accurately segment pathological and healthy lungs for reliable computer-aided disease diagnostics, a stack of chest CT scans is modeled as a sample of a spatially inhomogeneous joint 3D Markov-Gibbs random field (MGRF) of voxel-wise lung and chest CT image signals (intensities). The proposed learnable MGRF integrates two visual appearance sub-models with an adaptive lung shape submodel. The first-order appearance submodel accounts for both the original CT image and its Gaussian scale space (GSS) filtered version to specify local and global signal properties, respectively. Each empirical marginal probability distribution of signals is closely approximated with a linear combination of discrete Gaussians (LCDG), containing two positive dominant and multiple sign-alternate subordinate DGs. The approximation is separated into two LCDGs to describe individually the lungs and their background, i.e., all other chest tissues. The second-order appearance submodel quantifies conditional pairwise intensity dependencies in the nearest voxel 26-neighborhood in both the original and GSS-filtered images. The shape submodel is built for a set of training data and is adapted during segmentation using both the lung and chest appearances. The accuracy of the proposed segmentation framework is quantitatively assessed using two public databases (ISBI VESSEL12 challenge and MICCAI LOLA11 challenge) and our own database with, respectively, 20, 55, and 30 CT images of various lung pathologies acquired with different scanners and protocols. Quantitative assessment of our framework in terms of Dice similarity coefficients, 95-percentile bidirectional Hausdorff distances, and percentage volume differences confirms the high accuracy of our model on both our database (98.4±1.0%, 2.2±1.0 mm, 0.42±0.10%) and the VESSEL12 database (99.0±0.5%, 2.1±1.6 mm, 0.39±0.20%), respectively. Similarly, the accuracy of our approach is further verified via a blind evaluation by the organizers of the LOLA11 competition, where an average overlap of 98.0% with the expert's segmentation is yielded on all 55 subjects with our framework being ranked first among all the state-of-the-art techniques compared.",
Electrooculography based electronic communication device for individuals with ALS,"Unfortunately, nearly one million individuals in the United States are affected with paralysis, loss of motor skills, motor neuron disease such as Amyotrophic Lateral Sclerosis (ALS). As a result, there are many people who are unable to operate a computer or other electronic devices. This paper presents a low-cost electrooculography (EOG) based electronic communication system that allows a user, specifically a persons diagnosed with ALS, to perform basic computer tasks by recording eye movement. Subjects who participated in the prototype testing were healthy, and instructed to keep head movements to a minimum so that there would be no influence on how the mouse functions. Each subject was instructed to complete a set of tasks for a total of two trials. The prototype test results showed that healthy subjects could complete most tasks within a given timeframe. Results also showed improved performance in subjects as they become more comfortable with the device.","Electrooculography,
Mice,
Electrodes,
Testing,
Calibration,
Motion measurement"
Multiobjective Optimization in Cloud Brokering Systems for Connected Internet of Things,"Currently, over nine billion things are connected in the Internet of Things (IoT). This number is expected to exceed 20 billion in the near future, and the number of things is quickly increasing, indicating that numerous data will be generated. It is necessary to build an infrastructure to manage the connected things. Cloud computing (CC) has become important in terms of analysis and data storage for IoT. In this paper, we consider a cloud broker, which is an intermediary in the infrastructure that manages the connected things in CC. We study an optimization problem for maximizing the profit of the broker while minimizing the response time of the request and the energy consumption. A multiobjective particle swarm optimization (MOPSO) is proposed to solve the problem. The performance of the proposed MOPSO is compared with that of a genetic algorithm and a random search algorithm. The results show that the MOPSO outperforms a well-known genetic algorithm for multiobjective optimization.",
False Key-Controlled Aggressive Voltage Scaling: A Countermeasure Against LPA Attacks,"A false key-controlled aggressive voltage scaling (AVS) technique is proposed as a countermeasure against leakage power analysis (LPA) attacks. A random number of false keys are utilized to control the supply voltage scaling to mask the possible leakage of the information related to the correct key to a malicious attacker. Contrary to the random AVS technique, false key-controlled AVS technique can guarantee that the added false keys always exhibit higher correlation coefficients than that of the correct key even if sufficient number of plaintexts (>10 million) are enabled. As demonstrated with the simulation results, the measurement-to-disclose (MTD) value of a cryptographic circuit can be enhanced over ten million against LPA attacks by utilizing the proposed technique, while the MTD values of a conventional cryptographic circuit without countermeasure and one with random AVS are, respectively, less than 500 and 100,000.",
Performance comparison of resilience mechanisms for stateless multicast using BIER,"Bit Indexed Explicit Replication (BIER) is a novel multicast forwarding scheme for IP networks that avoids states in replicating routers by encoding the multicast information into a bit string in the packet header. In addition, the BIER-TE variant encodes the multicast tree in the header and allows for network programmability. We propose the use of maximally redundant trees (MRTs) for 1+1 protection in BIER that currently lacks this feature. We further discuss three different fast reroute (FRR) protection schemes for BIER-TE we have proposed in the Internet Engineering Task Force (IETF). They use header modification only (HM), rely on point-to-point tunnels (PPT), or leverage BIER-in-BIER encapsulation (BBE). We compare them regarding protection coverage, path lengths, traffic loads, required network capacity, state requirements and overhead in a large number of networks. The results serve the discussions in IETF where BIER and BIER-TE are currently standardized.","Routing,
Topology,
Computer architecture,
Network topology,
IP networks,
Protocols,
Layout"
Direction Priority Control Method for Magnetic Manipulation System in Current and Voltage Limits,"Magnetic manipulation system generates a magnetic field and gradient so that it can control the position and attitude of the microrobot, a magnetized agent of size under 1 mm. The system generates the force, torque, and magnetic field with currents. To date, no adjustment method concerned with voltage and current limits for the current controller of the system is researched. This paper proposes a control method that multiplies a ratio with all current or voltage references, making the largest one bounded to the rated value. Modified force, torque, and magnetic field commands are scaled down from the original ones keeping the same directions, respectively. Such adjustment may degrade the control performance but helps to control the position and attitude of the microrobot without distortion. Detailed adjustment steps considering gravity compensation and voltage feedforward terms are proposed. Simulative and experimental comparisons between two reference adjustment methods are done.","attitude control,
electric current control,
magnetic fields,
manipulators,
microrobots,
position control,
voltage control"
High altitude monocular visual-inertial state estimation: Initialization and sensor fusion,"Obtaining reliable state estimates at high altitude but GPS-denied environments, such as between high-rise buildings or in the middle of deep canyons, is known to be challenging, due to the lack of direct distance measurements. Monocular visual-inertial systems provide a possible way to recover the metric distance through proper integration of visual and inertial measurements. However, the nonlinear optimization problem for state estimation suffers from poor numerical conditioning or even degeneration, due to difficulties in obtaining observations of visual features with sufficient parallax, and the excessive period of inertial measurement integration. In this paper, we propose a spline-based high altitude estimator initialization method for monocular visual-inertial navigation system (VINS) with special attention to the numerical issues. Our formulation takes only inertial measurements that contain sufficient excitation, and drops uninformative measurements such as those obtained during hovering. In addition, our method explicitly reduces the number of parameters to be estimated in order to achieve earlier convergence. Based on the initialization results, a complete closed-loop system is constructed for high altitude navigation. Extensive experiments are conducted to validate our approach.","Cameras,
Visualization,
Robot vision systems,
Splines (mathematics),
Tracking"
PAPR Reduction for Hybrid ACO-OFDM Aided IM/DD Optical Wireless Vehicular Communications,"Hybrid asymmetrically clipped optical orthogonal frequency division multiplexing (HACO-OFDM) improves the spectral efficiency compared to asymmetrically clipped optical OFDM (ACO-OFDM) and pulse-amplitude-modulated discrete multitone (PAM-DMT) modulation, while retaining the advantage of high power efficiency. HACO-OFDM has found favor in numerous applications, but its peak-to-average-power ratio (PAPR) has remained a concern in optical wireless communications, since the family of existing PAPR reduction methods cannot be directly invoked for the superimposed HACO-OFDM signals. Hence, we analyze the characteristics of HACO-OFDM signals and develop a specific PAPR reduction technique relying on tone injection. Our numerical results show that the proposed method achieves significantly improved PAPR statistics compared to the conventional methods, leading to a significant bit error ratio (BER) reduction.",
Low-Rank and Adaptive Sparse Signal (LASSI) Models for Highly Accelerated Dynamic Imaging,"Sparsity-based approaches have been popular in many applications in image processing and imaging. Compressed sensing exploits the sparsity of images in a transform domain or dictionary to improve image recovery from undersampled measurements. In the context of inverse problems in dynamic imaging, recent research has demonstrated the promise of sparsity and low-rank techniques. For example, the patches of the underlying data are modeled as sparse in an adaptive dictionary domain, and the resulting image and dictionary estimation from undersampled measurements is called dictionary-blind compressed sensing, or the dynamic image sequence is modeled as a sum of low-rank and sparse (in some transform domain) components (L+S model) that are estimated from limited measurements. In this work, we investigate a data-adaptive extension of the L+S model, dubbed LASSI, where the temporal image sequence is decomposed into a low-rank component and a component whose spatiotemporal (3D) patches are sparse in some adaptive dictionary domain. We investigate various formulations and efficient methods for jointly estimating the underlying dynamic signal components and the spatiotemporal dictionary from limited measurements. We also obtain efficient sparsity penalized dictionary-blind compressed sensing methods as special cases of our LASSI approaches. Our numerical experiments demonstrate the promising performance of LASSI schemes for dynamic magnetic resonance image reconstruction from limited k-t space data compared to recent methods such as k-t SLR and L+S, and compared to the proposed dictionary-blind compressed sensing method.","Dictionaries,
Data models,
Image reconstruction,
Magnetic resonance imaging,
Adaptation models,
Compressed sensing"
Video Processing From Electro-Optical Sensors for Object Detection and Tracking in a Maritime Environment: A Survey,"We present a survey on maritime object detection and tracking approaches, which are essential for the development of a navigational system for autonomous ships. The electro-optical (EO) sensor considered here is a video camera that operates in the visible or the infrared spectra, which conventionally complements radar and sonar for situational awareness at sea and has demonstrated its effectiveness over the last few years. This paper provides a comprehensive overview of various approaches of video processing for object detection and tracking in the maritime environment. We follow an approach-based taxonomy wherein the advantages and limitations of each approach are compared. The object detection system consists of the following modules: horizon detection, static background subtraction, and foreground segmentation. Each of these has been studied extensively in maritime situations and has been shown to be challenging due to the presence of background motion especially due to waves and wakes. The key processes involved in object tracking include video frame registration, dynamic background subtraction, and the object tracking algorithm itself. The challenges for robust tracking arise due to camera motion, dynamic background, and low contrast of tracked object, possibly due to environmental degradation. The survey also discusses multisensor approaches and commercial maritime systems that use EO sensors. The survey also highlights methods from computer vision research, which hold promise to perform well in maritime EO data processing. Performance of several maritime and computer vision techniques is evaluated on Singapore Maritime Dataset.","Image edge detection,
Object detection,
Intelligent sensors,
Radar tracking,
Cameras,
Marine vehicles"
Silicon Photonic Ring-Assisted MZI for 50 Gb/s DAC-Less and DSP-Free PAM-4 Transmission,"We present the design and characterization of a silicon photonic ring-assisted Mach–Zehnder interferometer for four-level pulse amplitude modulation (PAM-4) short-reach transmission without the use of digital-to-analog converter (DAC) or digital signal processing (DSP). The PAM-4 optical signals are generated by driving two microring modulators with independent 2-level radio frequency signals. The device is operated at 25 Gbaud and the PAM-4 optical signals are transmitted over 2 km of standard single mode fiber. The bit error rate is estimated to be lower than the hard-decision forward error correction threshold of 3.8 \times 10^{-3}
, showing a successful DAC-less and DSP-free PAM-4 transmission at 50 Gb/s.","Radio frequency,
Power transmission,
Voltage measurement,
Adaptive optics,
Optical modulation,
Digital signal processing"
A New Single Image Super-Resolution Method Based on the Infinite Mixture Model,"As a powerful nonparametric Bayesian model, the infinite mixture model has been successfully used in machine learning and computer vision. The success of the infinite mixture model owes to the capability clustering and density estimation. In this paper, we propose a nonparametric Bayesian model for single-image super-resolution. Specifically, we combine the Dirichlet process and Gaussian process regression for estimating the distribution of the training patches and modeling the relationship between the low-resolution and high-resolution patches: 1) the proposed method groups the training patches by utilizing the clustering property of Dirichlet process; 2) the proposed method relates the low-resolution and high-resolution patches by predicting the property of Gaussian process; and 3) the mentioned two points are not independent but jointly learned. Hence, the proposed method can make full use of the nonparametric Bayesian model. First, the Dirichlet process mixture model is used to obtain more accurate clusters for training patches. Second, Gaussian process regression is established on each cluster, and this directly reduces the computational complexity. Finally, the two procedures are learned simultaneously to gain the suitable clusters with the ability of prediction. The parameters can be inferred simply via the Gibbs sampling technique. Thorough super-resolution experiments on various images demonstrate that the proposed method is superior to some state-of-the-art methods.","Image resolution,
Training,
Ground penetrating radar,
Dictionaries,
Gaussian processes,
Computational modeling,
Bayes methods"
Nonlinear Antiswing Control for Crane Systems With Double-Pendulum Swing Effects and Uncertain Parameters: Design and Experiments,"In practical applications, industrial cranes may exhibit double-pendulum swing effects, due to many factors, such as large payload scales and non-negligible hook masses. Currently, for double-pendulum cranes, most available methods are open-loop controllers designed based on linearized crane dynamics; even for existing closed-loop approaches, they are also mostly developed using linearized dynamics and require the exact knowledge of system parameters, which makes them sensitive to parametric uncertainties. To handle these issues, we present an adaptive antiswing control strategy for crane systems with double-pendulum swing effects and uncertain/unknown parameters, which can make the trolley accurately reach the target position with reduced overshoots and effectively eliminate the double-pendulum swing angles at the same time. A complete stability analysis, based upon the full nonlinear dynamics (i.e., without linearizing the dynamics), is included to support the theoretical derivations. We present hardware experimental results to demonstrate that the proposed controller achieves better performance than existing ones and exhibits good robustness.","Cranes,
Payloads,
Friction,
Stability analysis,
Hardware,
Robustness,
Control systems"
Non-Intrusive Energy Disaggregation Using Non-Negative Matrix Factorization With Sum-to-k Constraint,"Energy disaggregation or non-intrusive load monitoring addresses the issue of extracting device-level energy consumption information by monitoring the aggregated signal at one single measurement point without installing meters on each individual device. Energy disaggregation can be formulated as a source separation problem, where the aggregated signal is expressed as linear combination of basis vectors in a matrix factorization framework. In this paper, an approach based on Sum-to-k constrained non-negative matrix factorization (S2K-NMF) is proposed. By imposing the sum-to-k constraint and the non-negative constraint, S2K-NMF is able to effectively extract perceptually meaningful sources from complex mixtures. The strength of the proposed algorithm is demonstrated through two sets of experiments: Energy disaggregation in a residential smart home; and heating, ventilating, and air conditioning components energy monitoring in an industrial building testbed maintained at the Oak Ridge National Laboratory. Extensive experimental results demonstrate the superior performance of S2K-NMF as compared to state-of-the-art decomposition-based disaggregation algorithms.","Home appliances,
Buildings,
Hidden Markov models,
Monitoring,
Matrix decomposition,
Source separation,
Energy consumption"
"Chair Rise Peak Power in Daily Life Measured With a Pendant Sensor Associates With Mobility, Limitation in Activities, and Frailty in Old People","The aim of this study was to analyze the clinical relevance of sensor-based daily life chair rise performance measured in old people. A pendant-sensor was worn during standardized tests and in daily life to detect chair rise transfers and analyze transfer peak power. Linear correlations between mean, median, 25th, and 75th percentile transfer peak powers in daily life and mean peak power in standardized tests were evaluated with Pearson correlation ( r). Associations between transfer peak powers in different experiments and outcomes of a clinical mobility test [timed-up-and-go (TUG)], a test of limitation in activities [Groningen activity restriction scale (GARS)], and a frailty test [Groningen frailty indicator (GFI)] were evaluated with Spearman correlation (ρ). Twenty-five old people (70-85 years) participated in the study. The results showed that chair rise peak powers assessed based upon one-week of daily life activities significantly correlated with peak power measured in standardized tests (r: [0.66, 0.74], p <; 0.01). Chair rise peak power in daily life significantly associated with TUG scores (ρ: [-0.71, -0.58], p <; 0.01), GARS (ρ: [-0.62, -0.48], p <; 0.05), and GFI (ρ: [-0.52, -0.43], p <; 0.05). Chair rise peak powers in daily life had stronger associations with clinical measurements than standardized tests. In addition, chair rise peak powers measured in old people using assistive devices was significantly lower compared to those not using assistive devices. These results indicate usefulness of the pendant-sensor-based chair rise performance analysis in continuous monitoring and assessment of mobility, limitations in activities and frailty associated variables in old people's daily life.","Power measurement,
Biomedical measurement,
Assistive devices,
Monitoring,
Correlation,
Instruments,
Signal processing"
Low Complexity Automatic Modulation Classification Based on Order-Statistics,"In this paper, we propose three automatic modulation classification classifiers based on order-statistics and reduced order-statistics, where the order-statistics are the random variables sorted by ascending order and the reduced order-statistics represent a subset of the original order-statistics. Specifically, the linear support vector machine classifier applies the linear combination of the order-statistics of the received signals, while the approximate maximum likelihood and the backpropagation neural networks (BPNNs) classifier resort to the reduced order-statistics to decrease the computational complexity. Moreover, BPNN is applicable for modulation classification both in known and unknown channel scenarios. It is shown that in the known channel scenario, the proposed classifiers provide a good tradeoff between performance and computational complexity, while in the unknown channel scenario, the proposed BPNN classifier outperforms the expectation maximization classifier in terms of both classification performance and computational complexity. Simulations results are provided to evaluate the proposed classifiers.","Computational complexity,
Phase shift keying,
Neural networks,
Probability density function,
Wireless communication"
RaPare: A Generic Strategy for Cold-Start Rating Prediction Problem,"In recent years, recommender system is one of indispensable components in many e-commerce websites. One of the major challenges that largely remains open is the cold-start problem, which can be viewed as a barrier that keeps the cold-start users/items away from the existing ones. In this paper, we aim to break through this barrier for cold-start users/items by the assistance of existing ones. In particular, inspired by the classic Elo Rating System, which has been widely adopted in chess tournaments, we propose a novel rating comparison strategy (RAPARE) to learn the latent profiles of cold-start users/items. The centerpiece of our RAPARE is to provide a fine-grained calibration on the latent profiles of cold-start users/items by exploring the differences between cold-start and existing users/items. As a generic strategy, our proposed strategy can be instantiated into existing methods in recommender systems. To reveal the capability of RAPARE strategy, we instantiate our strategy on two prevalent methods in recommender systems, i.e., the matrix factorization based and neighborhood based collaborative filtering. Experimental evaluations on five real data sets validate the superiority of our approach over the existing methods in cold-start scenario.","Recommender systems,
Collaboration,
Interviews,
Optimization,
Algorithm design and analysis,
Calibration,
Electronic mail"
Immediate Neighborhood Temperature Adaptive Routing for Dynamically Throttled 3-D Networks-on-Chip,"In this brief, we present the immediate neighborhood temperature (INT) routing algorithm, which balances thermal profiles across dynamically throttled 3-D networks-on-chip by adaptively routing interconnect traffic based on runtime temperature monitoring. INT avoids the overheads of system-wide temperature monitoring by relying on the heat transfer characteristics of 3-D integrated circuits that enable temperature information from routers in the immediate neighborhood to guide adaptive routing decisions. Experimental results indicate that INT yields balanced thermal profiles with up to 25% lower gradients than competing schemes and shortens communication latency by decreasing average network congestion by up to 50%, with negligible overheads.","Temperature sensors,
Routing,
Temperature measurement,
Ports (Computers),
Three-dimensional displays,
Monitoring,
Integrated circuit interconnections"
Online Reconfiguration of Active Distribution Networks for Maximum Integration of Distributed Generation,"This paper proposes the online reconfiguration of active distribution networks. The control of the active/reactive output power of distributed generation (DG) units combined with the control of remote controlled switches are employed in order to minimize DG curtailment, alleviate lines congestion, and mitigate voltage rise issues due to DG integration. Convex relaxations of the ac power flow equations and mixed integer linear disjunctive formulations are adopted to the optimization model in order to obtain fast and optimal solutions using standard branch and bound solvers. The computation burden of the optimization procedure is drastically reduced by exploiting the assessment of switching actions, which is performed using multiple load/generation scenarios. The effectiveness of the proposed optimization model is verified using different distribution test systems.","Optimization,
Control systems,
Voltage control,
Mathematical model,
Reactive power,
Minimization,
Distributed power generation"
WOLoc: WiFi-only outdoor localization using crowdsensed hotspot labels,"Given the ever-expanding scale of WiFi deployments in metropolitan areas, we have reached the point where accurate GPS-free outdoor localization becomes possible by relying solely on the WiFi infrastructure. Nevertheless, the existing industrial practices do not seem to have the right implementation to achieve an adequate accuracy, while the academic researches that are mostly attracted by indoor localization have largely neglected this outdoor aspect. In this paper, we propose WOLoc (WiFi-only Outdoor Localization) as a solution that offers meter-level accuracy, by holistically treating the large number of WiFi hotspot labels gather by crowdsensing. On one hand, we do not take these labels as fingerprints as it is almost impossible to extend indoor localization mechanisms by fingerprinting metropolitan areas. On the other hand, we avoid the over-simplified local synthesis methods (e.g., centroid) that significantly lose the information contained in the labels. Instead, we accommodate all the labeled and unlabeled data for a given area using a semi-supervised manifold learning technique, and the output concerning the unlabeled part will become the estimated locations for both users and WiFi hotspots. We conduct extensive experiments with WOLoc in several outdoor areas, and the results have strongly indicated the efficacy of our solution.","Wireless fidelity,
Urban areas,
Manifolds,
Conferences,
Global Positioning System,
Estimation,
Roads"
Representation Learning Based Speech Assistive System for Persons With Dysarthria,"An assistive system for persons with vocal impairment due to dysarthria converts dysarthric speech to normal speech or text. Because of the articulatory deficits, dysarthric speech recognition needs a robust learning technique. Representation learning is significant for complex tasks such as dysarthric speech recognition. We focus on robust representation for dysarthric speech recognition that involves recognizing sequential patterns of varying length utterances. We propose a hybrid framework that uses a generative learning based data representation with a discriminative learning based classifier. In this hybrid framework, we propose to use Example Specific Hidden Markov Models (ESHMMs) to obtain log-likelihood scores for a dysarthric speech utterance to form fixed dimensional score vector representation. This representation is used as an input to discriminative classifier such as support vector machine. The performance of the proposed approach is evaluated using UA-Speech database.The recognition accuracy is much better than the conventional hidden Markov model based approach and Deep Neural Network-Hidden Markov Model (DNN-HMM). The efficiency of the discriminative nature of score vector representation is proved for “very low” intelligibility words.","Hidden Markov models,
Speech recognition,
Speech,
Databases,
Mel frequency cepstral coefficient,
Support vector machines,
Feature extraction"
Fast and Accurate Time-Domain Simulations of Integer-N PLLs,"We present a methodology to simulate industrial integer-N phase-locked loops (PLLs) at a verification level, as accurate as and faster than transistor-level simulation. The accuracy is measured on the PLL factors of interest, i.e., locking time, power consumption, phase noise and jitter (period and long-term). The speedup factor tends to the division ratio N for device-noise simulations. We develop a unifying technique which is able to deal with both noise-free and device-noise analyses, taking into account nonlinear and second-order effects visible at transistor-level simulation only, whereas previous works focused on one of the two analyses, separately. The procedure is based on oscillator's sensitivity analysis and on the creation of a phase macromodel for the voltage-controlled oscillator (VCO) together with the loop divider (the phase model is called VCODIV), whilst the other PLL's blocks remain at transistor level. The macromodel's phase law is characterized by a piecewise linear curve, representing the sensitivity of the VCODIV output's phase deviation with respect to the voltage variation of the VCO's control pin, and by the effects of all the VCO's and divider's noise sources on the model's output. We show two experiments on industrial PLLs, and provide guidelines for designers which highlight the steps needed to implement the methodology by using well-known analyses in circuit simulation and Verilog-A for the creation of the macromodel.","Phase locked loops,
Integrated circuit modeling,
Mathematical model,
Phase noise,
Computational modeling,
Jitter,
Analytical models"
Application Oriented Dynamic Resource Allocation for Data Centers Using Docker Containers,"Docker offers an opportunity for further improvement in data centers' (DCs) efficiency. However, existing models and schemes fall short to be efficiently used for Docker container-based resource allocation. We design a novel application oriented Docker container (AODC)-based resource allocation framework to minimize the application deployment cost in DCs, and to support automatic scaling while the workload of cloud applications varies. We then model the AODC resource allocation problem considering features of Docker, various applications' requirements, and available resources in cloud data centers, and propose a scalable algorithm for DCs with diverse and dynamic applications and massive physical resources.","Containers,
Resource management,
Libraries,
Virtual machine monitors,
Optimization,
Cloud computing,
Heuristic algorithms"
Parameter Estimation for VSI-Fed PMSM Based on a Dynamic PSO With Learning Strategies,"A dynamic particle swarm optimization with learning strategy (DPSO-LS) is proposed for key parameter estimation for permanent magnet synchronous machines (PMSMs), where the voltage-source inverter (VSI) nonlinearities are taken into account in the parameter estimation model and can be estimated simultaneously with other machine parameters. In the DPSO-LS algorithm, a novel movement modification equation with variable exploration vector is designed to effectively update particles, enabling swarms to cover large areas of search space with large probability and thus the global search ability is enhanced. Moreover, a Gaussian-distribution-based dynamic opposition-based learning strategy is developed to help the pBest jump out local optima. The proposed DPSO-LS can significantly enhance the estimator model accuracy and dynamic performance. Finally, the proposed algorithm is applied to multiple parameter estimation including the VSI nonlinearities of a PMSM. The performance of DPSO-LS is compared with several existing PSO algorithms, and the comparison results show that the proposed parameters estimation method has better performance in tracking the variation of machine parameters effectively and estimating the VSI nonlinearities under different operation conditions.","Parameter estimation,
Mathematical model,
Voltage measurement,
Resistance,
Windings,
Rotors,
Heuristic algorithms"
Application identification system for SDN QoS based on machine learning and DNS responses,"In recent years, the demand for application-specific qualify of service (QoS) management has grown. To effectively do application-specific QoS, a system albe to do flow classification at the application level is required. This paper presents an application identification system that can be integrated with a QoS management system in a software defined network (SDN). This paper describes the method to obtain ground truth (label) of the flow from four mainstream operating systems (OS), and the method to classify flow based on supervised machine learning and DNS responses. In our experiment, average F-measure of all applications reached 93.48%. The testing data set contained 294 applications, given that each platform version or execution file of an application was one application. The testing data set included Skype, Facebook, and other popular applications. Results showed that this system can identify application traffic on different platforms with high accuracy.","IP networks,
Training data,
Servers,
Quality of service,
Testing,
Androids,
Humanoid robots"
An Approximate Approach to Automatic Kernel Selection,"Kernel selection is a fundamental problem of kernel-based learning algorithms. In this paper, we propose an approximate approach to automatic kernel selection for regression from the perspective of kernel matrix approximation. We first introduce multilevel circulant matrices into automatic kernel selection, and develop two approximate kernel selection algorithms by exploiting the computational virtues of multilevel circulant matrices. The complexity of the proposed algorithms is quasi-linear in the number of data points. Then, we prove an approximation error bound to measure the effect of the approximation in kernel matrices by multilevel circulant matrices on the hypothesis and further show that the approximate hypothesis produced with multilevel circulant matrices converges to the accurate hypothesis produced with kernel matrices. Experimental evaluations on benchmark datasets demonstrate the effectiveness of approximate kernel selection.","Kernel,
Approximation algorithms,
Support vector machines,
Optimization,
Complexity theory,
Yttrium,
Algorithm design and analysis"
Preventive and Reactive Cyber Defense Dynamics Is Globally Stable,"The recently proposed cybersecurity dynamics approach aims to understand cybersecurity from a holistic perspective by modeling the evolution of the global cybersecurity state.These models describe the interactions between the various kinds of cyber attacks and the various kinds of cyber defenses that take place in complex networks.In this paper, we study a particular kind of cybersecurity dynamics caused by the interactions between two classes of attacks (called push-based attacks and pull-based attacks) and two classes of defenses (called preventive and reactive defenses). The dynamics was previously shown to be globally stable in a special regime of the parameter universe of a model with node-independent and edge-independent parameters, but little is known beyond this regime. In this paper, we prove that the dynamics is globally stable in the entire parameter universe of a more general model with node-dependent and edge-dependent parameters. This means that the dynamics always converges to a unique equilibrium.We also prove that the dynamics converges exponentially to the equilibrium except fora particular parameter regime, in which the dynamics converges polynomially. Since it is often difficult to compute the equilibrium, we propose bounds of the equilibrium and numerically show that they are tighter than those proposed in the literature.","Computer security,
Computational modeling,
Biological system modeling,
Computers,
Numerical models,
Analytical models,
Complex networks"
Internet of Vehicles for E-Health Applications: A Potential Game for Optimal Network Capacity,"Wireless technologies are pervasive to support ubiquitous healthcare applications. However, a critical issue of using wireless communications under a healthcare scenario rests at the electromagnetic interference (EMI) caused by RF transmission, and a high level of EMI may lead to a critical malfunction of medical sensors. In view of EMI on medical sensors, we propose a power control algorithm under a noncooperative game theoretic framework to schedule data transmission. Our objective is to ensure that the noncooperative game of power control can achieve a network-level objective-the optimal network capacity, although the wireless users are selfish and only interested in optimizing their own channel capacity. To obtain this objective, we show that our proposed noncooperative game is a potential game and propose the best-response-dynamics algorithm which can ensure that the game strategy of each user is induced to the optimal solution to the problem of network-level optimal capacity. Numerical results illustrate that the proposed algorithm can achieve an enhancement of 8% of network performance than the existing algorithm against the variations of mobile hospital environments.",
Utility Maximization for Multimedia Data Dissemination in Large-Scale VANETs,"With the increasing demand of media-rich entertainment and location-aware services from people on the road, how to disseminate the multimedia data in large-scale Vehicular Ad-Hoc Networks (VANETs) efficiently and reliably is a pressing issue. Due to the high mobility, large scale, and limited contact time between vehicles, it is quite challenging to support the multimedia data dissemination in VANETs. In this paper, we first utilize a hybrid framework to model the VANETs to address the mobility and scalability issues. Then, we formulate a utility-based maximization problem to find the best delivery strategy and select an optimal path for the multimedia data dissemination, where the utility function has taken the delivery delay, Quality of Services (QoS), and storage cost into consideration. With rigorous analysis, we obtain the closed-form of the expected utility of a path, and then obtain the optimal solution of the problem with the convex optimization theory. Finally, we conduct trace-driven simulations to evaluate the performance of the proposed algorithm with real traces collected by taxis in Shanghai. The simulation results demonstrate the rigorousness of our theoretical analysis, and the effectiveness of the proposed solution.",
Semisupervised Online Multikernel Similarity Learning for Image Retrieval,"Metric learning plays a fundamental role in the fields of multimedia retrieval and pattern recognition. Recently, an online multikernel similarity (OMKS) learning method has been presented for content-based image retrieval (CBIR), which was shown to be promising for capturing the intrinsic nonlinear relations within multimodal features from large-scale data. However, the similarity function in this method is learned only from labeled images. In this paper, we present a new framework to exploit unlabeled images and develop a semisupervised OMKS algorithm. The proposed method is a multistage algorithm consisting of feature selection, selective ensemble learning, active sample selection, and triplet generation. The novel aspects of our work are the introduction of classification confidence to evaluate the labeling process and select the reliably labeled images to train the metric function, and a method for reliable triplet generation, where a new criterion for sample selection is used to improve the accuracy of label prediction for unlabeled images. Our proposed method offers advantages in challenging scenarios, in particular, for a small set of labeled images with high-dimensional features. Experimental results demonstrate the effectiveness of the proposed method as compared with several baseline methods.",
Scalable Spectrum Allocation and User Association in Networks With Many Small Cells,"A scalable framework is developed to allocate radio resources across a large number of densely deployed small cells with given traffic statistics on a slow timescale. Joint user association and spectrum allocation is first formulated as a convex optimization problem by dividing the spectrum among all possible transmission patterns of active access points (APs). To improve scalability with the number of APs, the problem is reformulated using local patterns of interfering APs. To maintain global consistency among local patterns, inter-cluster interaction is characterized as hyper-edges in a hyper-graph with nodes corresponding to subcarriers allocated to APs. A scalable solution is obtained by iteratively solving a convex optimization problem for bandwidth allocation with reduced complexity and followed by a global spectrum allocation using hyper-graph coloring. Numerical results demonstrate the proposed solution for a network with 100 APs and several hundred user equipment. For a given quality of service, the proposed scheme can often increase the network capacity severalfold compared with assigning each user to the strongest AP with full-spectrum reuse.","Resource management,
Optimization,
Interference,
Quality of service,
OFDM,
Bandwidth,
Convex functions"
A Logic Circuit Design for Perfecting Memristor-Based Material Implication,"Memristor-based material implication (M-IMP) logic is popular with logic operations, which provides a possibility that memory is operated directly. However, there is a small limitation that memristor is not able to reach the lowest resistance in M-IMP. In this brief, the M-IMP limitation and its influence are analyzed briefly. In addition, a circuit structure that performs a stateful logic operation on memristor memory based on a nanocrossbar is proposed, which can perfect the M-IMP limitation and eliminate the influence. Moreover, we simulate the proposed circuit design and the simulation results verify the correctness of the analysis.","Memristors,
Steady-state,
Threshold voltage,
Integrated circuit modeling,
Logic circuits,
Computer architecture,
CMOS integrated circuits"
Addressing job processing variability through redundant execution and opportunistic checkpointing: A competitive analysis,"The completion times of jobs in a computing cluster may be influenced by a variety of factors including job size and machine processing variability. In this paper, we explore online resource allocation policies which combine size-dependent scheduling with redundant execution and opportunistic checkpointing to minimize the overall job flowtime. We introduce a simplified model for the job service capacity of a computing cluster while leveraging redundant execution/checkpointing. In this setting, we propose two resource allocation algorithms, SRPT+R and LAPS+R(β) subject to checkpointing overhead not exceeding the number of jobs which are processed. We provide new theoretical performance bounds for these algorithms: SRPT+R is shown to be O(1/ϵ) competitive under (1 + ϵ)-speed resource augmentation, while LAPS+R(β) is shown to be O(1/βϵ) competitive under (2+ 2β + 2ϵ)-speed resource augmentation.","Redundancy,
Algorithm design and analysis,
Multitasking,
Checkpointing,
Servers,
Scheduling algorithms"
Online Stochastic Buy-Sell Mechanism for VNF Chains in the NFV Market,"With the recent advent of network functions virtualization (NFV), enterprises and businesses are looking into network service provisioning through the service chains of virtual network functions (VNFs), instead of relying on dedicated hardware middleboxes. Accompanying this trend, an NFV market is emerging, where NFV service providers create VNF instances, assemble VNF service chains, and sell them for the use of customers, using resources (computing, bandwidth) that they own or rent from other resource suppliers. Efficient service chain provisioning and pricing mechanisms are still missing, to charge assembled service chains according to demand and the supply of resources at any time. We propose an online stochastic auction mechanism for on-demand service chain provisioning and pricing at an NFV provider. Our auction takes in buy bids for service chains from multiple customers and sell bids from various resource suppliers to supplement the NFV provider's geo-distributed resource pool, with resource occupation/contribution durations. We extend online primal-dual optimization framework for handling both buyers and sellers, with a new competitive analysis. The online mechanism maximizes the expected social welfare of the NFV ecosystem (the NFV provider, customers and resource suppliers) with a good competitive ratio as compared with the expected offline optimal social welfare, while guaranteeing truthfulness in bidding, individual rationality for both buyers and sellers, and polynomial time for computation. We evaluate our mechanism through trace-driven simulation studies, and demonstrate a close-to-offline-optimal performance in expected social welfare under realistic settings.",
Maximum Lifetime Combined Barrier-Coverage of Weak Static Sensors and Strong Mobile Sensors,"Recently, the concept of barrier-coverage of wireless sensor network has been introduced for various civilian and military defense applications. This paper studies the problem of how to organize hybrid sensor network, which consists of a number of energy-scarce ground sensors with homogenous initial battery level and energy-plentiful mobile sensors, to maximum the lifetime of barrier-coverage. Two key observations are (a) as the lifetime of each mobile sensor is much longer than that of the static ground sensors, each mobile sensor is capable of contributing multiple sensor barrier formations, and (b) no mobile sensor node can join two hybrid barriers which will be successively used to continuously protect the area of interest due to the moving delay. Based on these, we introduce a new maximum lifetime barrier-coverage problem in hybrid sensor network. We first propose a simple heuristic algorithm by combining existing ideas along with our own. Then, we design another efficient algorithm for the problem and prove that the lifetime of hybrid barrier constructed by this algorithm is at least three times greater than the existing one on average. Our simulation result shows that the second algorithm outperforms the first algorithm at least 33 percent and up to 100 percent.","Sensors,
Wireless sensor networks,
Mobile computing,
Algorithm design and analysis,
Wireless communication,
Mobile nodes"
Multifrequency Compressed Sensing for 2-D Near-Field Synthetic Aperture Radar Image Reconstruction,"This paper investigates a new multifrequency compressed sensing (CS) model for 2-D near-field microwave and millimeter-wave synthetic aperture radar (SAR) imaging system, which usually collects multifrequency sparse data. Spatial data of each frequency are represented as a hierarchical tree structure under a wavelet basis and spatial data of different frequencies are modeled as a joint structure, because they are highly correlated. Based on the developed multifrequency CS model, a new CS approach is proposed by exploiting both the intrafrequency and interfrequency correlations, and enriches the existing CS approaches for 2-D near-field microwave and millimeter-wave SAR image reconstruction from undersampled measurements. Combining a splitting Bregman update with a variation of the parallel Fast Iterative Shrinkage-Thresholding Algorithm-like proximal algorithm, the proposed CS approach minimizes a linear combination of five terms: a least squares data fitting, a multi-ℓ1 norm, a multitotal variation norm, a joint-sparsity ℓ21 norm, and a tree-sparsity overlapping ℓ21 norm. Simulation and experimental results demonstrate the superior performance of the proposed approach in terms of both efficiency and convergence speed.",
Stability analysis of a Scanning Tunneling Microscope control system,"Control system of a Scanning Tunneling Microscope is analyzed. For the aim of model-based control system analysis and design, open-loop model of the plant is obtained based on the closed-loop system identification tests. We conduct identification tests in the frequency-domain, derive transfer function models of the open-loop system, and discuss the main sources that lead to model uncertainties. We define appropriate closed-loop stability and performance measures, and evaluate performance of a conventional PI controller in the framework of the defined criteria. We show that uncertainties arising from a quantum mechanical property of the tunneling junction, known as the Work Function, can have a destabilizing effect on the control system. This increases the risk of tip-sample crash which is a prevalent operational problem in STM. We experimentally evaluate the presented analysis, and suggest guidelines for PI gain tuning.","Tunneling,
Uncertainty,
Surface topography,
Mathematical model,
Resonant frequency,
Closed loop systems"
Policy-based Secure and Trustworthy Sensing for Internet of Things in Smart Cities,"The internet of things (IoT), which is known as one of the key enabling technologies of smart cities, generally refers to the network of smart objects, which are embedded with sensing, computing, networking, and actuating capabilities that all together enable them to collect and exchange data. The IoT devices are usually wirelessly networked, and they serve as a key enabling technology for many critical smart city applications, such as intelligent transportation, smart grid, smart building, and mobile healthcare. However, security has become a key challenge for the wide deployment of IoT: because of the environmental influences, the IoT data are inherently noisy. Moreover, the IoT devices may be compromised by attackers to intentionally generate fake data. Finally, the underlying wireless network can also be subverted. To address the security issue in IoT, we propose a policy-based secure and trustworthy sensing scheme for IoT named RealAlert, in which the trustworthiness of both data and the IoT devices are evaluated based on both the reporting history and the context in which the data are collected using policy rules. Experimental results have shown that the RealAlert scheme can accurately assess the trust of the sensor nodes as well as data in IoT.","Security,
Smart cities,
Internet of Things,
Sensors,
Smart grids,
Data collection,
Context"
"Secure, efficient and practical double spectrum auction","Truthful spectrum auction is believed to be an effective method for spectrum redistribution. However, privacy concerns have largely hampered the practical applications of truthful spectrum auctions. In this paper, to make the applications of double spectrum auctions practical, we present a secure, efficient and practical double spectrum auction design, SDSA. Specifically, by combining three security techniques: homomorphic encryption, secret sharing and garbled circuits, we design a secure two-party protocol computing a socially efficient double spectrum auction, TDSA, without leaking any information about sellers' requests or buyers' bids beyond the auction outcome. We give the formal security definition in our context, and theoretically prove the security that our design achieves. Experimental results show that our design is efficient and practical even for large-scale double spectrum auctions.","Protocols,
Encryption,
Privacy,
Public key,
Virtual groups"
"Strengthening the SDP Relaxation of AC Power Flows With Convex Envelopes, Bound Tightening, and Valid Inequalities","This work revisits the semidefine programming (SDP) relaxation of the ac power flow equations in light of recent results illustrating the benefits of bounds propagation, valid inequalities, and the convex quadratic relaxation. By integrating all of these results into the SDP model a new hybrid relaxation is proposed, which combines the benefits from all of these recent works. This strengthened SDP formulation is evaluated on 71 AC Optimal Power Flow test cases from the NESTA archive and is shown to have an optimality gap of less than 1% on 63 cases. This new hybrid relaxation closes 50% of the open cases considered, leaving only eight for future investigation.",
Stochastically Transitive Models for Pairwise Comparisons: Statistical and Computational Issues,"There are various parametric models for analyzing pairwise comparison data, including the Bradley-Terry-Luce (BTL) and Thurstone models, but their reliance on strong parametric assumptions is limiting. In this paper, we study a flexible model for pairwise comparisons, under which the probabilities of outcomes are required only to satisfy a natural form of stochastic transitivity. This class includes parametric models, including the BTL and Thurstone models as special cases, but is considerably more general. We provide various examples of models in this broader stochastically transitive class for which classical parametric models provide poor fits. Despite this greater flexibility, we show that the matrix of probabilities can be estimated at the same rate as in standard parametric models up to logarithmic terms. On the other hand, unlike in the BTL and Thurstone models, computing the minimax-optimal estimator in the stochastically transitive model is non-trivial, and we explore various computationally tractable alternatives. We show that a simple singular value thresholding algorithm is statistically consistent but does not achieve the minimax rate. We then propose and study algorithms that achieve the minimax rate over interesting sub-classes of the full stochastically transitive class. We complement our theoretical results with thorough numerical simulations.","Parametric statistics,
Stochastic processes,
Computational modeling,
Estimation,
Noise measurement,
Data models,
Analytical models"
Novel Framework of Risk-Aware Virtual Network Embedding in Optical Data Center Networks,"The traffic between geographically distributed data centers (DCs) becomes bandwidth hungry. Since the optical interconnection has a high capacity, the optical data center network (ODCN)—where DCs are located at the edge of the optical backbone—emerges. By virtualization, the virtual networks—representing service requirements—are embedded onto the same part of the substrate ODCN. Each virtual network has virtual machine (VM) nodes interconnected by virtual links (VLs). Therefore, a virtual network embedding (VNE) operation includes two components: 1) the VM mapping for putting a VM into the server of an appropriate DC and 2) the VL mapping for establishing one substrate path to support inter-VM communications. In this paper, we focus on a risk-aware VNE framework because a blind VNE operation would result in severe information leakage among coresident VMs in the server. By evaluating VM threat and vulnerability, risky VMs are identified according to experimental results. To perform physical isolation between risky and security VMs, a risk-aware VNE heuristic algorithm is proposed. The simulation results show that our heuristic algorithm performs better than the benchmark in terms of maintaining ODCN security and earning rental revenue. There is also a good match between our algorithm solution and the problem bound.","Servers,
Substrates,
Optical interconnections,
Security,
Monitoring,
Bandwidth"
Cognitive-Biometric Recognition From Language Usage: A Feasibility Study,"We propose a novel cognitive biometrics modality based on written language-usage of an individual. This is a feasibility study using the Internet-scale blogs, with tens of thousands of authors to create a cognitive fingerprint for an individual. Existing cognitive biometric modalities involve learning from obtrusive sensors placed on human body. Our modality is based on the characteristic pattern of how individuals express their thoughts through written language. The problems of cognitive authentication (1:1 comparison of genuine versus impostor) and identification (1:n search) are formulated. We detail the algorithms to learn a classifier to distinguish between genuine and impostor classes (for authentication) and multiple classes (for identification). We conclude that a cognitive fingerprint can be successfully learnt, using stylistic (writing style), semantic (themes), and syntactic (grammatical) features extracted from blogs. Our methodology shows promising results (with 79% as the area under the ROC (AUC) in case of authentication). For identification, the individual class accuracies are up to 90%. We performed stricter tests to see how our system performs for unseen user, and report the accuracies of 72% (genuine) and 71% (impostor). Such a study lays the groundwork for building alternative cognitive systems. The modality, presented here, is easy to obtain, unobtrusive and needs no additional hardware.","Blogs,
Feature extraction,
Authentication,
Iris recognition,
Vocabulary,
Semantics"
"Optimizing MR Scan Design for Model-Based
T
1
,
T
2
Estimation From Steady-State Sequences","Rapid, reliable quantification of MR relaxation parameters T1 and T2 is desirable for many clinical applications. Steady-state sequences such as Spoiled Gradient-Recalled Echo (SPGR) and Dual-Echo Steady-State (DESS) are fast and well-suited for relaxometry because the signals they produce are quite sensitive to T1 and T2 variation. However, T1, T2 estimation with these sequences typically requires multiple scans with varied sets of acquisition parameters. This paper describes a systematic framework for selecting scan types (e.g., combinations of SPGR and DESS scans) and optimizing their respective parameters (e.g., flip angles and repetition times). The method is based on a Cramér-Rao Bound (CRB)-inspired min-max optimization that finds scan parameter combinations that robustly enable precise object parameter estimation. We apply this technique to optimize combinations of SPGR and DESS scans for T1, T2 relaxometry in white matter (WM) and grey matter (GM) regions of the human brain at 3T field strength. Phantom accuracy experiments show that SPGR/DESS scan combinations are in excellent agreement with reference measurements. Phantom precision experiments show that trends in T1,T2 pooled sample standard deviations reflect CRB-based predictions. In vivo experiments show that in WM and GM, T1 and T2 estimates from a pair of optimized DESS scans exhibit precision (but not necessarily accuracy) comparable to that of optimized combinations of SPGR and DESS scans. To our knowledge, T1 maps from DESS acquisitions alone are new. This example application illustrates that scan optimization may help reveal new parameter mapping techniques from combinations of established pulse sequences.",
VPSearch: Achieving Verifiability for Privacy-Preserving Multi-Keyword Search over Encrypted Cloud Data,"Although cloud computing offers elastic computation and storage resources, it poses challenges on verifiability of computations and data privacy. In this work we investigate verifiability for privacy-preserving multi-keyword search over outsourced documents. As the cloud server may return incorrect results due to system faults or incentive to reduce computation cost, it is critical to offer verifiability of search results and privacy protection for outsourced data at the same time. To fulfill these requirements, we design a Verifiable Privacy-preserving keyword Search scheme, called VPSearch, by integrating an adapted homomorphic MAC technique with a privacy-preserving multi-keyword search scheme. The proposed scheme enables the client to verify search results efficiently without storing a local copy of the outsourced data. We also propose a random challenge technique with ordering for verifying top-k search results, which can detect incorrect top-k results with probability close to 1. We provide detailed analysis on security, verifiability, privacy, and efficiency of the proposed scheme. Finally, we implement VPSearch using Matlab and evaluate its performance over three UCI bag-of-words data sets. Experiment results show that authentication tag generation incurs about 3% overhead only and a search query over 300,000 documents takes about 0.98 seconds on a laptop. To verify 300,000 similarity scores for one query, VPSearch costs only 0.29 seconds.","Keyword search,
Cloud computing,
Servers,
Encryption,
Data privacy,
Computational modeling"
Cost-benefit analysis game for efficient storage allocation in cloud-centric Internet of Things systems: A game theoretic perspective,"The advances in Internet of Everything (IoE) and the market-oriented cloud computing have provided opportunities to resolve the challenges caused by the Internet of Things (IoT) infrastructure virtualization, capacity planning, data storage or complexity. The volume and types of IoT data motivate the need for a data storage framework towards the integration of both structured and unstructured data. In this paper, we propose a novel game theoretic technique for efficient and dynamic storage allocation in cloud-centric IoT systems. The benefit maximization problem is formulated as a cost-benefit analysis game investigating the storage capacity currently used in the cloud. In view of each player's strategy to lease additional storage capacity, the game property is analyzed and we prove that the game always admits a pure strategy Nash equilibrium. Since the player's decision affects the level of benefit maximization, we elaborate on a cost-optimal storage allocation incentive mechanism, which scales effectively once non-linear or linear demand for storage capacity occurs, towards achieving optimal leasing conditions on cloud storage and computing capacity level. The experimental validation tests prove the effectiveness of the proposed game theoretic approach allocating the requests for more storage capacity in a cost-effective manner, which achieves to maximize the benefits.","Cloud computing,
Games,
Resource management,
Companies,
Memory,
Cost benefit analysis,
Nash equilibrium"
Age Dependence of Arterial Pulse Wave Parameters Extracted From Dynamic Blood Pressure and Blood Volume Pulse Waves,"Atherosclerosis is a significant cause of mortality in the aged population, and it affects arterial wall properties causing differences in measured arterial pulse wave (PW). In this study, both dynamic arterial blood pressure PWs and blood volume PWs are analyzed. The PWs are recorded noninvasively from multiple measurement points from the upper and lower limbs from 52 healthy (22-90-year-old) volunteers without known cardiovascular diseases. For each signal, various parameters earlier proposed in the literature are computed, and 25 different novel parameters are formed by combining these parameters. The results are evaluated in terms of age and heart rate (HR) dependence of the parameters. In general, the results show that 14 out of 25 tested combined parameters have stronger age dependence than any of the individual parameters. The highest obtained linear correlation coefficients between the age and combined parameter and individual parameter equal to 0.85 (p <; 10-4) and 0.79 (p <; 10-4), respectively. Most of the combined parameters have also improved discrimination capability when classifying the test subjects into different age groups. This is a promising result for further studies, but indicate that the age dependence of the parameters must be taken into account in further studies with atherosclerotic patients.","Biomedical measurement,
Atherosclerosis,
Indexes,
Sensors,
Arteries,
Informatics,
Aging"
Routing or Computing? The Paradigm Shift Towards Intelligent Computer Network Packet Transmission Based on Deep Learning,"Recent years, Software Defined Routers (SDRs) (programmable routers) have emerged as a viable solution to provide a cost-effective packet processing platform with easy extensibility and programmability. Multi-core platforms significantly promote SDRs' parallel computing capacities, enabling them to adopt artificial intelligent techniques, i.e., deep learning, to manage routing paths. In this paper, we explore new opportunities in packet processing with deep learning to inexpensively shift the computing needs from rule-based route computation to deep learning based route estimation for high-throughput packet processing. Even though deep learning techniques have been extensively exploited in various computing areas, researchers have, to date, not been able to effectively utilize deep learning based route computation for high-speed core networks. We envision a supervised deep learning system to construct the routing tables and show how the proposed method can be integrated with programmable routers using both Central Processing Units (CPUs) and Graphics Processing Units (GPUs). We demonstrate how our uniquely characterized input and output traffic patterns can enhance the route computation of the deep learning based SDRs through both analysis and extensive computer simulations. In particular, the simulation results demonstrate that our proposal outperforms the benchmark method in terms of delay, throughput, and signaling overhead.","Machine learning,
Routing,
Computer architecture,
Software defined networking,
Graphics processing units,
Central Processing Unit,
Telecommunication traffic"
Coherent Semantic-Visual Indexing for Large-Scale Image Retrieval in the Cloud,"The rapidly increasing number of images on the internet has further increased the need for efficient indexing for digital image searching of large databases. The design of a cloud service that provides high efficiency but compact image indexing remains challenging, partly due to the well-known semantic gap between user queries and the rich semantics of large-scale data sets. In this paper, we construct a novel joint semantic-visual space by leveraging visual descriptors and semantic attributes, which narrows the semantic gap by combining both attributes and indexing into a single framework. Such a joint space embraces the flexibility of coherent semantic-visual indexing, which employs binary codes to boost retrieval speed while maintaining accuracy. To solve the proposed model, we make the following contributions. First, we propose an interactive optimization method to find the joint semantic and visual descriptor space. Second, we prove convergence of our optimization algorithm, which guarantees a good solution after a certain number of iterations. Third, we integrate the semantic-visual joint space system with spectral hashing, which finds an efficient solution to search up to billion-scale data sets. Finally, we design an online cloud service to provide a more efficient online multimedia service. Experiments on two standard retrieval datasets (i.e., Holidays1M, Oxford5K) show that the proposed method is promising compared with the current state-of-the-art and that the cloud system significantly improves performance.","Semantics,
Cloud computing,
Visualization,
Indexing,
Image retrieval,
Feature extraction,
Algorithm design and analysis"
Traffic Sign Detection Using a Cascade Method With Fast Feature Extraction and Saliency Test,"Automatic traffic sign detection is challenging due to the complexity of scene images, and fast detection is required in real applications such as driver assistance systems. In this paper, we propose a fast traffic sign detection method based on a cascade method with saliency test and neighboring scale awareness. In the cascade method, feature maps of several channels are extracted efficiently using approximation techniques. Sliding windows are pruned hierarchically using coarse-to-fine classifiers and the correlation between neighboring scales. The cascade system has only one free parameter, while the multiple thresholds are selected by a data-driven approach. To further increase speed, we also use a novel saliency test based on mid-level features to pre-prune background windows. Experiments on two public traffic sign data sets show that the proposed method achieves competing performance and runs 2~7 times as fast as most of the state-of-the-art methods.","Feature extraction,
Support vector machines,
Image color analysis,
Traffic control,
Detectors"
Publicly Verifiable Inner Product Evaluation over Outsourced Data Streams under Multiple Keys,"Uploading data streams to a resource-rich cloud server for inner product evaluation, an essential building block in many popular stream applications (e.g., statistical monitoring), is appealing to many companies and individuals. On the other hand, verifying the result of the remote computation plays a crucial role in addressing the issue of trust. Since the outsourced data collection likely comes from multiple data sources, it is desired for the system to be able to pinpoint the originator of errors by allotting each data source a unique secret key, which requires the inner product verification to be performed under any two parties' different keys. However, the present solutions either depend on a single key assumption or powerful yet practically-inefficient fully homomorphic cryptosystems. In this paper, we focus on the more challenging multi-key scenario where data streams are uploaded by multiple data sources with distinct keys. We first present a novel homomorphic verifiable tag technique to publicly verify the outsourced inner product computation on the dynamic data streams, and then extend it to support the verification of matrix product computation. We prove the security of our scheme in the random oracle model. Moreover, the experimental result also shows the practicability of our design.","Servers,
Computational modeling,
Outsourcing,
Algorithm design and analysis,
Sun,
Cryptography"
"Exploring ways to exploit UMI technologies in STEM education: Comparison of secondary computer science curricula of Greece, Cyprus and England","Ubiquitous and Mobile Computing technologies, as well as the Internet of Things, affect the way we live and learn. Ongoing research efforts aim at providing an educational framework that would exploit these technologies in order to support and enhance STEM education. The foundations for the development of the framework are laid by a comparison of secondary Computer Science education curricula in Greece, Cyprus and England. The methodology and results of this research are described and discussed in this paper and the next steps of the research are specified.","Computers,
STEM,
Programming profession,
Mobile computing"
Toward Seamless Multiview Scene Analysis From Satellite to Street Level,"In this paper, we discuss and review how combined multiview imagery from satellite to street level can benefit scene analysis. Numerous works exist that merge information from remote sensing and images acquired from the ground for tasks such as object detection, robots guidance, or scene understanding. What makes the combination of overhead and street-level images challenging are the strongly varying viewpoints, the different scales of the images, their illuminations and sensor modality, and time of acquisition. Direct (dense) matching of images on a per-pixel basis is thus often impossible, and one has to resort to alternative strategies that will be discussed in this paper. For such purpose, we review recent works that attempt to combine images taken from the ground and overhead views for purposes like scene registration, reconstruction, or classification. After the theoretical review, we present three recent methods to showcase the interest and potential impact of such fusion on real applications (change detection, image orientation, and tree cataloging), whose logic can then be reused to extend the use of ground-based images in remote sensing and vice versa. Through this review, we advocate that cross fertilization between remote sensing, computer vision, and machine learning is very valuable to make the best of geographic data available from Earth observation sensors and ground imagery. Despite its challenges, we believe that integrating these complementary data sources will lead to major breakthroughs in Big GeoData. It will open new perspectives for this exciting and emerging field.","Remote sensing,
Geology,
Satellites,
Computer vision,
Image reconstruction,
Image analysis,
Robot sensing systems,
Spatial resolution,
Social network services,
Data fusion"
Remote Sensing Image Classification: A survey of support-vector-machine-based advanced techniques,"Land-cover mapping in remote sensing (RS) applications renders rich information for decision support and environmental monitoring systems. The derivation of such information increasingly relies on robust classification methods for identifying the complex land-cover area of different categories. Numerous classification techniques have been designed for the analysis of RS imagery. In this context, support vector machines (SVMs) have recently received increasing interest. However, the need for a small-size training set remains a bottleneck to design efficient supervised classifiers, while an adequate number of unlabeled data is readily available in RS images and can be exploited as a supplementary source of information. To fully leverage these precious unlabeled data, a number of promising advanced SVM-based methods, such as active SVMs, semisupervised SVMs (S3VMs), and SVMs combined with other algorithms, have been developed to analyze satellite imagery. In this literature review, we have surveyed these learning techniques to explore RS images. Moreover, we have provided the empirical evidences of SVMs and three representative techniques. It is our hope that this review will provide guidelines to future researchers to enhance further algorithmic developments in RS applications.","Training,
Classification algorithms,
Remote sensing,
Support vector machines,
Image classification,
Data models"
Computation Partitioning for Mobile Cloud Computing in a Big Data Environment,"The growth of mobile cloud computing (MCC) is challenged by the need to adapt to the resources and environment that are available to mobile clients while addressing the dynamic changes in network bandwidth. Big data can be handled via MCC. In this paper, we propose a model of computation partitioning for stateful data in the dynamic environment that will improve the performance. First, we constructed a model of stateful data streaming and investigated the method of computation partitioning in a dynamic environment. We developed a definition of direction and calculation of the segmentation scheme, including single-frame data flow, task scheduling, and executing efficiency. We also defined the problem for a multiframe data flow calculation segmentation decision that is optimized for dynamic conditions and provided an analysis. Second, we proposed a computation partitioning method for single-frame data flow. We determined the data parameters of the application model, the computation partitioning scheme, and the task and work order data stream model. We followed the scheduling method to provide the optimal calculation for data frame execution time after computation partitioning and the best computation partitioning method. Third, we explored a calculation segmentation method for single-frame data flow based on multiframe data using multiframe data optimization adjustment and prediction of future changes in network bandwidth. We were able to demonstrate that the calculation method for multiframe data in a changing network bandwidth environment is more efficient than the calculation method with the limitation of calculations for single-frame data. Finally, our research verified the effectiveness of single-frame data in the application of the data stream and analyzed the performance of the method to optimize the adjustment of multiframe data. We used a MCC platform prototype system for face recognition to verify the effectiveness of the method.",
Delay Analysis and Routing for Two-Dimensional VANETs Using Carry-and-Forward Mechanism,"For disconnected Vehicular Ad hoc NETworks (VANETs), the carry-and-forward mechanism is promising to ensure the delivery success ratio at the cost of a longer delay, as the vehicle travel speed is much lower than the wireless signal propagation speed. Estimating delay is critical to select the paths with low delay, and is also challenging given the random topology and high mobility, and the difficulty to let the message propagate along the selected path. In this paper, we first propose a simple yet effective propagation strategy considering bidirectional vehicle traffic for two-dimensional VANETs, so the opposite-direction vehicles can be used to accelerate the message propagation and the message can largely follow the selected path. Focusing on the propagation delay, an analytical framework is developed to quantify the expected path delay. Using the analytical model, a source node can apply the shortest-path algorithm to select the path with the lowest expected delay. Performance evaluation by simulation show that, when the vehicle density is uneven but known, the proposed Minimum Delay Routing Algorithm can achieve a substantial reduction in delay compared with the geocast-routing approach, and its performance is close to the flooding-based Epidemic algorithm, while our solution maintains only a single copy of the message.",
21.1% UMG Silicon Solar Cells,"We present n-type Czochralski-grown silicon solar cells made from 100% upgraded metallurgical grade silicon feedstock, with an independently certified peak efficiency of 21.1%. We look at the impact of net doping and minority carrier lifetime and mobility on the short-circuit current and the open-circuit voltage.","Doping,
Silicon,
Photovoltaic cells,
Charge carrier lifetime,
Short-circuit currents,
Electrical resistance measurement,
Photovoltaic systems"
Control Path Management Framework for Enhancing Software-Defined Network (SDN) Reliability,"Software-defined networking (SDN) is a softwarization technology of networks that can optimize processes and operation costs and bring new values to infrastructures. The issue of reliability, however, becomes more complex in SDN due to new and multi-lateral network domains, and poses many critical challenges on the existing network reliability mechanisms in order to achieve the same reliability services. In this paper, we first identify and illustrate reliability challenges in a control path network that lies between a control plane network and a data plane network to connect them through either an in-band SDN or an out-of-band traditional network. We then observe a number of distinctive control path reliability problems. Accordingly, we propose and develop a control path management framework to enhance SDN reliability addressing the observed issues. It includes several control path reliability algorithms that enhance performance, network protocols that simplify management of control path reliability, as well as a novel control message classification and prioritization system that serves as a fundamental approach to improve scalability and then reliability for SDN. Recognizing the control path as a network and understanding its potential and practical reliability problems enable us to provide effective solutions that prior approaches fall short of. We validate our proposed management framework through extensive experiments through a real network system as well as numerical analyses.","Telecommunication network reliability,
Protocols,
Control systems,
Software reliability,
Scalability,
Heart beat"
Big Health Application System based on Health Internet of Things and Big Data,"The world is facing problems, such as uneven distribution of medical resources, the growing chronic diseases, and the increasing medical expenses. Blending the latest information technology into the healthcare system will greatly mitigate the problems. This paper presents the big health application system based on the health Internet of Things and big data. The system architecture, key technologies, and typical applications of big health system are introduced in detail.","Medical services,
Internet of things,
Big data,
Wearable computing,
Cloud computing,
Diseases,
System architecture,
Computer applications"
Three-Dimensional Printed Fluid-Filled Electrostatic Rotating Machine Designed with Conformal Mapping Methods,"Recently, fluid-filled electrostatic machines demonstrated specific and volumetric torque densities that hold promise to be competitive with electromagnetic machines in niche applications, e.g., air-cooled, low-speed, and direct-drive machines. These demonstrations of variable capacitance (or elastance, which is the dual of reluctance) machines were nonoptimized from an electrostatics perspective as their geometry was heavily constrained by manufacturability issues. This paper proposes a semi-analytical design method that combines conformal mapping techniques with finite element analysis, leading to more optimal electrostatic machine geometries. Parametric sweeps of key relative dimensions establish best practices/guidelines for design. A fractional horsepower proof of concept machine was designed using the new approach and was built using stereolithographic three-dimensional printing to circumvent manufacturing constraints. The machine is mostly plastic, plated with conductor, and is, therefore, lightweight. This manufacturing approach suggests that a machine can be injected molded or cast in a single step. Measurements of the prototype demonstrate a torque density of 0.31 Nm/L and specific torque density of 0.22 Nm/kg, comparable with similar size NEMA frame fractional horsepower induction motors. Also the Nm/kV2 of the prototype machine is two orders of magnitude greater than prior nonliquid-filled work.","Torque,
Electrostatics,
Capacitance,
Conformal mapping,
Two dimensional displays,
Geometry,
Force"
Information-distilling quantizers,"Let X and Y be dependent random variables. We consider the problem of designing a scalar quantizer for Y to maximize the mutual information between its output and X, and study fundamental properties and bounds for this form of quantization. Our main focus is the regime of low I(X; Y), where we show that for a binary X, there always exists an M-level quantizer attaining mutual information of Ω(-M · I(X;Y)/log(I(X;Y)) and that there exist pairs of X, Y for which the mutual information attained by any M-level quantizer is O(-M · I (X;Y)/ log (I(X;Y))).","Mutual information,
Quantization (signal),
Random variables,
Electronic mail,
AWGN channels,
Information rates"
Short term power load forecasting using Deep Neural Networks,"Accurate load forecasting greatly influences the planning processes undertaken in operation centres of energy providers that relate to the actual electricity generation, distribution, system maintenance as well as electricity pricing. This paper exploits the applicability of and compares the performance of the Feed-forward Deep Neural Network (FF-DNN) and Recurrent Deep Neural Network (R-DNN) models on the basis of accuracy and computational performance in the context of time-wise short term forecast of electricity load. The herein proposed method is evaluated over real datasets gathered in a period of 4 years and provides forecasts on the basis of days and weeks ahead. The contribution behind this work lies with the utilisation of a time-frequency (TF) feature selection procedure from the actual “raw” dataset that aids the regression procedure initiated by the aforementioned DNNs. We show that the introduced scheme may adequately learn hidden patterns and accurately determine the short-term load consumption forecast by utilising a range of heterogeneous sources of input that relate not necessarily with the measurement of load itself but also with other parameters such as the effects of weather, time, holidays, lagged electricity load and its distribution over the period. Overall, our generated outcomes reveal that the synergistic use of TF feature analysis with DNNs enables to obtain higher accuracy by capturing dominant factors that affect electricity consumption patterns and can surely contribute significantly in next generation power systems and the recently introduced SmartGrid.","Load modeling,
Feature extraction,
Frequency-domain analysis,
Load forecasting,
Neural networks,
Time-domain analysis,
Predictive models"
Performance Analysis of LDPC-Based RFID Group Coding,"In this paper, we analyze some recently proposed radio-frequency identification group codes based on low-density parity-check matrices that check the integrity of collections of tagged objects. These codes write additional data to the memory of tags to compute the number of missing tags. By studying the underlying requirements for these computations, we obtain bounds and show that there are simpler group codes that perform better, requiring less tag memory.","Parity check codes,
Memory management,
Encoding,
Decoding,
Databases,
RFID tags"
VML-HD: The historical Arabic documents dataset for recognition systems,"In this paper we present a new database with handwritten Arabic script. It is based on five books written by different writers from the years 1088-1451. We took 680 pages from these five books, and fully annotated them on the sub-word level. For each page we manually applied bounding boxes on the different sub-words and annotated the sequence of characters. It consists of 121,636 sub-word appearances consisted of 244,553 characters out of a vocabulary of 1,731 forms of sub-words. The database is described in detail and is designed for training and testing recognition systems for handwritten Arabic sub-words. This database is available for the purpose of research, and we encourage researchers to develop and test new methods using our database.","Databases,
Handwriting recognition,
Writing,
Text analysis,
Conferences,
Computer science,
Cameras"
A Semisupervised Approach to the Detection and Characterization of Outliers in Categorical Data,"In this paper, we introduce a new approach of semisupervised anomaly detection that deals with categorical data. Given a training set of instances (all belonging to the normal class), we analyze the relationship among features for the extraction of a discriminative characterization of the anomalous instances. Our key idea is to build a model that characterizes the features of the normal instances and then use a set of distance-based techniques for the discrimination between the normal and the anomalous instances. We compare our approach with the state-of-the-art methods for semisupervised anomaly detection. We empirically show that a specifically designed technique for the management of the categorical data outperforms the general-purpose approaches. We also show that, in contrast with other approaches that are opaque because their decision cannot be easily understood, our proposed approach produces a discriminative model that can be easily interpreted and used for the exploration of the data.",
Local communities of computing education in Norway,"The paper seeks to examine how existing communities in computing education thrive in Norway and manage to empower school pupils and tutors realising their role in the digital society, learn programming, and become familiar with Computer Science and Information Technology. Two semi-structured interviews were conducted with organisers and designers of activities that promote computing education and programming in Norway. Also, one focus group discussion was conducted with high school students that participated in a small number of learning activities on design thinking, programming and Internet of Things. The results were qualitatively analysed using the Grounded Theory in order to conclude how different aspects (cognitive, social, organisational, policy) are manifested and interweaved in these communities.","Interviews,
Education,
Programming profession,
Computers,
Instruments,
Protocols"
Kernel-Based Reconstruction of Space-Time Functions on Dynamic Graphs,"Graph-based methods pervade the inference toolkits of numerous disciplines including sociology, biology, neuroscience, physics, chemistry, and engineering. A challenging problem encountered in this context pertains to determining the attributes of a set of vertices given those of another subset at possibly different time instants. Leveraging spatiotemporal dynamics can drastically reduce the number of observed vertices, and hence the sampling cost. Alleviating the limited flexibility of the existing approaches, the present paper broadens the kernel-based graph function estimation framework to reconstruct time-evolving functions over possibly time-evolving topologies. This approach inherits the versatility and generality of kernel-based methods, for which no knowledge on distributions or second-order statistics is required. Systematic guidelines are provided to construct two families of space-time kernels with complementary strengths: the first facilitates judicious control of regularization on a space-time frequency plane, whereas the second accommodates time-varying topologies. Batch and online estimators are also put forth. The latter comprise a novel kernel Kalman filter, developed to reconstruct space-time functions at affordable computational cost. Numerical tests with real datasets corroborate the merits of the proposed methods relative to competing alternatives.","Kernel,
Topology,
Kalman filters,
Spatiotemporal phenomena,
Social network services,
Computers,
Laplace equations"
Quickly finding a truss in a haystack,"The k-truss of a graph is a subgraph such that each edge is tightly connected to the remaining elements in the k-truss. The k-truss of a graph can also represent an important community in the graph. Finding the k-truss of a graph can be done in a polynomial amount of time, in contrast finding other subgraphs such as cliques. While there are numerous formulations and algorithms for finding the maximal k-truss of a graph, many of these tend to be computationally expensive and do not scale well. Many algorithms are iterative and use static graph triangle counting in each iteration of the graph. In this work we present a novel algorithm for finding both the k-truss of the graph (for a given k), as well as the maximal k-truss using a dynamic graph formulation. Our algorithm has two main benefits. 1) Unlike many algorithms that rerun the static graph triangle counting after the removal of non-conforming edges, we use a new dynamic graph formulation that only requires updating the edges affected by the removal. As our updates are local, we only do a fraction of the work compared to the other algorithms. 2) Our algorithm is extremely scalable and is able to concurrently detect deleted triangles in contrast to past sequential approaches. While our algorithm is architecture independent, we show a CUDA based implementation for NVIDIA GPUs. In numerous instances, our new algorithm is anywhere from 100X-10000X faster than the Graph Challenge benchmark. Furthermore, our algorithm shows significant speedups, in some cases over 70X, over a recently developed sequential and highly optimized algorithm.","Heuristic algorithms,
Algorithm design and analysis,
Graphics processing units,
Benchmark testing,
Approximation algorithms,
Image edge detection,
Data structures"
A statistical description of pairwise interaction between nerve fibres?,"In this paper, the interaction between axons in nerve trunks has been characterized in the statistical sense while the mechanism model is investigated based on two different observation scales. In order to describe the interaction phenomena, a symmetric coupling factor matrix has been presented which is considered as a transverse mode combining the standard cable equation. It has been shown that the presented model is an extension of the existing individual membrane potential models. The simulation results indicate that the responses of the nerve fibres are sensitive to the couplings and the action potential could be generated by other coupled axons even if there is no external artificial stimulation.","Axons,
Mathematical model,
Couplings,
Extracellular,
Electric potential,
Integrated circuit modeling"
"Via-First Process to Enable Copper Metallization of Glass Interposers With High-Aspect-Ratio, Fine-Pitch Through-Package-Vias","A via-first process for metallizing copper on glass substrates is presented using a thin, patternable polymer film, electroless copper deposition, and semiadditive processing. A procedure for partially precuring the polymer was developed in order to achieve a tented via structure after dry-film lamination and curing. The flexibility of the process is demonstrated by the use of plasma etching, CO2, and UV laser ablation as patterning technologies. Metallization by electroless copper deposition and semiadditive processing is shown to be conformal, continuous, and without defects on the surface and in the vias as demonstrated by cross-sectional analysis. Glass of 100 μm thickness with vias of 10-20 μm diameter and 40 μm pitch was metallized to demonstrate the dimensional capability of the process. Thermomechanical reliability was validated by copper peel testing after highly accelerated stress testing and daisy-chain resistance measurements taken throughout thermal cycle testing.","Glass,
Polymers,
Copper,
Metallization,
Substrates,
Lamination,
Curing"
BLMA: A Blind Matching Algorithm With Application to Cognitive Radio Networks,"We consider a two-sided one-to-one abstract matching problem with a defined notion of pairwise stability. The formulated problem is shown to encompass the ordinal and cardinal utility markets. We propose a distributed blind matching algorithm (BLMA) to solve the problem. The BLMA is characterized by random activations of agents, and by generic negotiation and aspiration (utility) update processes. We prove that the solution produced by the BLMA will converge to an ϵ-pairwise stable, equivalently ϵ-core, outcome with probability one. We then consider three BLMA applications in cognitive radio networks. We propose a simple BLMA negotiation and aspiration update dynamic to produce an ϵ-pairwise stable solution for the case of quasi-convex and quasi-concave utilities. In the case of more general utility forms, we show another BLMA process to provide equilibrium. We also consider the use of the BLMA in an ordinal utility market. In all applications of the BLMA, we impose a limited information exchange in the network so that agents can only calculate their own utilities, but no information is available about the utilities of any other user in the network.","Games,
Cognitive radio,
Heuristic algorithms,
Stability criteria,
Convergence,
Context"
Comparison Study of Noncontact Vital Signs Detection Using a Doppler Stepped-Frequency Continuous-Wave Radar and Camera-Based Imaging Photoplethysmography,"In this paper, we compare the performance of radar and optical (camera based) techniques in detecting vital signs such as respiratory rate (RR), heart rate (HR), and blood oxygen saturation (SpO2). Specifically, we investigate the application of ultrawideband stepped-frequency continuous-wave radar and imaging photoplethysmography (iPPG) techniques to measure vital signs. The radar performance can be enhanced by using phase information of backscattered signal instead of its amplitude. On the other hand, the iPPG system can be enhanced by using more than one camera and utilizing very selective narrowband filters coupled with good illumination. In either system, use of advanced signal processing is required to improve accuracy. Generally, HR and RR can be accurately read by either microwave radar or optical techniques with 500 lx illumination level to have <; ±2% error up to 2 m distance between the subject and the system, but optical technique errors increase significantly to <; ±15% for <;200 lx. However, each system has its unique advantages as the radar can be used for seeing-through walls and optical technique is uniquely capable of measuring SpO2).","Heart rate,
Monitoring,
Radar imaging,
Doppler radar,
Laser radar,
Ultra wideband radar"
Pattern-Reconfigurable Printed Dipole Antenna Using Loaded Parasitic Elements,"A printed dipole antenna is designed with two parasitic elements loaded by embedded resonators to provide reconfigurable patterns. The embedded resonators in the parasitic elements are loaded by varactor diodes, which change the phase and the transmission coefficient responses of the parasitic elements. This allows the parasitic elements to act as either a director, a reflector, or a neutral element. The proposed printed dipole antenna with two loaded parasitic elements acts as a printed Yagi-Uda antenna. Because the parasitic elements can act as either a director or a reflector, the directed gain can be increased, and the front-to-back ratio (FBR) may be improved up to 42 dB. It is also possible to achieve different target FBR if broadcasting is needed in two directions of the boresight. This pattern reshaping can be obtained as quickly as the diodes can change their capacitance. The antenna is designed to operate at 2.4 GHz, but this design approach can be applied to other frequency bands. The simulation and measurement results are in good agreement.","Dipole antennas,
Gain,
Antenna radiation patterns,
Loaded antennas,
Varactors,
Antenna measurements,
Resonant frequency"
The Use of Inverse-Mode SiGe HBTs as Active Gain Stages in Low-Noise Amplifiers for the Mitigation of Single-Event Transients,"A cascode configuration with inverse-mode (IM) common-emitter silicon-germanium (SiGe) heterojunction bipolar transistors (HBTs) is proposed for the mitigation of single-event transients (SETs) in low-noise amplifiers (LNAs). Conventionally, despite their SET-mitigation capability, IM SiGe HBTs have been considered to be unsuitable for active gain stages due to severe degradation in RF performance. However, with the benefits of aggressive technology scaling, the high frequency performance of IM SiGe HBTs has been significantly improved, thereby enabling them to be utilized in active gain stages with acceptable RF performance. The cascode with IM common-emitter and common-base SiGe HBTs is used for a 2.4 GHz prototype LNA and it achieves adequate RF gain (10 dB) and noise figure (1.9 dB). With regard to SET mitigation, a through-wafer two-photon absorption pulsed-laser experiment is conducted to test the efficacy of this radiation-hardening approach in an advanced 90 nm SiGe BiCMOS platform. The proposed IM-SiGe-HBT-based LNA exhibits 85% reduction in transient peaks compared to the conventional forward-mode cascode LNA.","Silicon germanium,
Radio frequency,
Transient analysis,
Heterojunction bipolar transistors,
Frequency modulation,
Noise figure"
Virtualized Execution Runtime for FPGA Accelerators in the Cloud,"FPGAs offer high performance coupled with energy efficiency, making them extremely attractive computational resources within a cloud ecosystem. However, to achieve this integration and make them easy to program, we first need to enable users with varying expertise to easily develop cloud applications that leverage FPGAs. With the growing size of FPGAs, allocating them monolithically to users can be wasteful due to potentially low device utilization. Hence, we also need to be able to dynamically share FPGAs among multiple users. To address these concerns, we propose a methodology and a runtime system that together simplify the FPGA application development process by providing: 1) a clean abstraction with high-level APIs for easy application development; 2) a simple execution model that supports both hardware and software execution; and 3) a shared memory-model which is convenient to use for the programmers. Akin to an operating system on a computer, our lightweight runtime system enables the simultaneous execution of multiple applications by virtualizing computational resources, i.e., FPGA resources and on-board memory, and offers protection facilities to isolate applications from each other. In this paper, we illustrate how these features can be developed in a lightweight manner and quantitatively evaluate the performance overhead they introduce on a small set of applications running on our proof of concept prototype. Our results demonstrate that these features only introduce marginal performance overheads. More importantly, by sharing resources for simultaneous execution of multiple user applications, our platform improves FPGA utilization and delivers higher aggregate throughput compared to accessing the device in a time-shared manner.",
Efficient Privacy-Preserving Facial Expression Classification,"This paper proposes an efficient algorithm to perform privacy-preserving (PP) facial expression classification (FEC) in the client-server model. The server holds a database and offers the classification service to the clients. The client uses the service to classify the facial expression (FaE) of subject. It should be noted that the client and server are mutually untrusted parties and they want to perform the classification without revealing their inputs to each other. In contrast to the existing works, which rely on computationally expensive cryptographic operations, this paper proposes a lightweight algorithm based on the randomization technique. The proposed algorithm is validated using the widely used JAFFE and MUG FaE databases. Experimental results demonstrate that the proposed algorithm does not degrade the performance compared to existing works. However, it preserves the privacy of inputs while improving the computational complexity by
120
times and communication complexity by
31
percent against the existing homomorphic cryptography based approach.","Servers,
Training,
Feature extraction,
Cryptography,
Privacy,
Databases,
Principal component analysis"
Localization Based on Social Big Data Analysis in the Vehicular Networks,"Location-based services, especially for vehicular localization, are an indispensable component of most technologies and applications related to the vehicular networks. However, because of the randomness of the vehicle movement and the complexity of a driving environment, attempts to develop an effective localization solution face certain difficulties. In this paper, an overlapping and hierarchical social clustering model (OHSC) is first designed to classify the vehicles into different social clusters by exploring the social relationship between them. By using the results of the OHSC model, we propose a social-based localization algorithm (SBL) that use location prediction to assist in global localization in the vehicular networks. The experiment results validate the performance of the OHSC model and show that the presented SBL algorithm demonstrates superior localization performance compared with the existing methods.",
Channel Estimation for Residual Self-Interference in Full-Duplex Amplify-and-Forward Two-Way Relays,"Training schemes for full duplex two-way relays are investigated. We propose a novel one-block training scheme with a maximum likelihood estimator to estimate the channels between the nodes as well as the residual self-interference (RSI) channel simultaneously. A quasi-Newton algorithm is used to solve the estimator. As a baseline, a multi-block training scheme is also considered. The Cramer-Rao bounds of the one-block and multi-block training schemes are derived. By using the Szegö's theorem about Toeplitz matrices, we analyze how the channel parameters and transmit powers affect the Fisher information. We show analytically that exploiting the structure arising from the RSI channel increases its Fisher information. Numerical results show the benefits of estimating the RSI channel.",
Design and Management of Battery-Supercapacitor Hybrid Electrical Energy Storage Systems for Regulation Services,"Regulation services (RS) play an important role in maintaining the stability of electric grids by correcting for short-term mismatches between electricity generation and demand. RS providers dynamically supply electricity to the grid or consume electricity from it, in response to regulation signals, in return for economic compensation. This capability is commonly realized through large-scale electrical energy storage (EES) systems based on batteries. However, the highly transient nature of the regulation signals implies that the batteries used for RS are subject to frequent charge and discharge cycles, leading to shortened battery life and thereby impacting the profitability of RS. In this work, we explore the use of hybrid EES (HEES) systems, which combine batteries and supercapacitors, to improve the profitability of RS. HEES systems have the potential to reduce the cost of providing RS by utilizing supercapacitors to respond to the high-frequency components of the regulation signal, prolonging battery life. However, realizing this potential presents several challenges. First, the benefits of HEES systems have a profound dependence on the type of hybrid topology (i.e., active or passive), which results in a tradeoff between the implementation cost and the utilization of the supercapacitor capacity. Second, the allocation of energy storage capacity to batteries and supercapacitors should be carefully determined in the design phase because the reduction in battery replacement cost due to the use of supercapacitors must be balanced against the increased upfront cost for supercapacitors. Third, active HEES systems involve the problem of managing the power flows to batteries and supercapacitors so as to realize maximum cost benefits. To address these challenges, we present a framework for the design and management of a HEES system, so as to maximize the profit from the perspective of an RS provider. This framework consists of i) a design-time capacity optimization phase that determines the best allocation of capacity to batteries and supercapacitors and ii) a run-time management scheme that selects how the different storage devices are orchestrated considering their characteristics and the incoming regulation signal. Our experiments show that, with the proposed capacity optimization and management framework, the use of a passive or an active HEES system can improve the profit of RS providers by 1.16× or 5.44×, respectively.",
Compressed sensing under optimal quantization,"We consider the problem of recovering a sparse vector from a quantized or a lossy compressed version of its noisy random linear projections. We characterize the minimal distortion in this recovery as a function of the sampling ratio, the sparsity rate, the noise intensity and the total number of bits in the quantized representation. We first derive a singe-letter expression that can be seen as the indirect distortion-rate function of the sparse source observed through a Gaussian channel whose signal-to-noise ratio is derived from these parameters. Under the replica symmetry postulation, we prove that there exists a quantization scheme that attains this expression in the asymptotic regime of large system dimensions. In addition, we prove a converse demonstrating that the MMSE in estimating any fixed sub-block of the source from the quantized measurements at a fixed number of bits does not exceed this expression as the system dimensions go to infinity. Thus, under these conditions, the expression we derive describes the excess distortion incurred in encoding the source vector from its noisy random linear projections in lieu of the full source information.",
"Power Distribution System Outage Management with Co-Optimization of Repairs, Reconfiguration, and DG Dispatch","This paper proposes a two-stage method for the outage management of power distribution systems. The first stage is to cluster repair tasks of damaged power generation and delivery components based on their distances from the depots (central crew stations) and the availability of resources, to improve the computational efficiency in solving outage management problems for large distribution systems. The second stage is to co-optimize the repair, reconfiguration, and DG dispatch to maximize the picked-up loads and minimize the repair time. The distribution system repair and restoration problem (DSRRP) is formulated as a mixed integer linear program (MILP), considering constraints of system operation and routing repair crews (RRC). Crews are dispatched considering equipment resources, traveling time, and repair time. The proposed method is tested on modified IEEE 34 and 123-bus distribution test systems with multiple damages. The results demonstrate the advantages of co-optimizing repair and restoration.",
Exploring Vision-Based Techniques for Outdoor Positioning Systems: A Feasibility Study,"Recent advances from wearables have significantly changed the way how humans communicate with the surrounding environment. To some extent, they have extended and augmented the capability of humans. For example, with a Google Glass, people can take pictures simply by winking eyes twice, which releases human hands from the cumbersome image-taking process. Thus, it enables new application scenarios that were not possible before. In this paper, we investigate utilizing vision-based techniques to provide a wearable positioning system. Specifically, we propose a Human-centric Positioning System (HoPS) that utilizes traffic signposts together with context information for real-time positioning. Towards that direction, we make three primary contributions: (1) we make several important observations that guide our design of HoPS system; for example, we find out that approximately 40 percent of traffic signposts monopolize a cell tower, and there are at most six signposts within the coverage of a single cell tower; (2) we investigate the impact factors of object detection success rate, and find its correlation with image quality, and resolution; and (3) we design and implement HoPS and an advanced version of HoPS based on additional context information from Wi-Fi network, which we name HoPS-WiFi. Experimental results demonstrate the effectiveness of HoPS, especially HoPS-WiFi, which can estimate the relevant location correctly within 1.3 seconds.","Position control,
Context awareness,
Human factors,
Traffic control,
Mobile computing,
Wearable computing,
Object detection,
Image processing,
Wireless fidelity"
Pilot Power Allocation Through User Grouping in Multi-Cell Massive MIMO Systems,"In this paper, we propose a relative channel estimation error (RCEE) metric, and derive closed-form expressions for its expectation Exprcee and the achievable uplink rate holding for any number of base station antennas M, with the least squares (LS) and minimum mean squared error (MMSE) methods. It is found that RCEE and Exprcee converge to the same constant value when M → ∞, which renders the pilot power allocation (PPA) substantially simplified and a PPA algorithm is proposed to minimize the average Exprcee per user under a total pilot power budget F in multi-cell massive multipleinput multiple-output systems. Numerical results show that the PPA algorithm brings considerable gains for the LS estimation compared with equal PPA (EPPA), while the gains are significant only with large frequency reuse factor (FRF) for the MMSE estimation. Moreover, for large FRF and large F, the performance of the LS approaches to that of the MMSE. Besides, a scheduling strategy is proposed to allocate pilot power in the whole system, which can approach the optimal performance. For the achievable uplink rate, the PPA scheme and improves the minimum achievable uplink rate compared with the EPPA scheme.",
Deadtime Compensation for Model Predictive Control of Power Inverters,"When employed as a modulator in power inverters, model predictive control has an equivalence to a recently proposed modulation technique known as feedback quantizer modulation (FBQM). Both schemes produce a random-like switching pattern that can facilitate explicit control over the shape of frequency spectra associated with inverter output voltages and currents. This is useful to satisfy electromagnetic interference and acoustic noise requirements, and to avoid excitation of external system resonances. However, it will be shown in this paper that inverter deadtime introduces a disturbance into FBQM that significantly degrades the ability to shape the frequency spectra. Several compensation techniques, designed to model the effect of deadtime inside the formulation of FBQM, are proposed and experimentally verified on a two-level three-phase inverter.","Inverters,
Modulation,
Delays,
Harmonic analysis,
Switches,
Quantization (signal)"
SimRadar: A Polarimetric Radar Time-Series Simulator for Tornadic Debris Studies,"In an effort to study and characterize scattering mechanisms of debris particles in tornadoes, a numerical polarimetric radar emulator was developed. This paper is primarily motivated by attempts to explain radar observations near tornadoes. One such observation is the regions of negative differential reflectivity, which have been found near tornadoes but they are yet to be explained physically. There are hypotheses that suggest common debris alignment and/or dominant scattering from objects with high radar-cross-section (RCS) values that cause negative ZDR, but they are extremely challenging to verify due to the inherent danger near the vicinity of tornadoes. It is, however, possible to numerically construct the scenes through representative simulations to verify the plausible causes. This serves as our primary motivation to develop the radar emulator. The novel aspects of this paper are the realistic trajectory derivation, which is based on a physical air-drag model, and the representative diversity of RCS contributions from each debris object, developed through realistic polarimetric RCS modeling and anechoic chamber measurements.","Radar cross-sections,
Tornadoes,
Radar polarimetry,
Meteorology,
Atmospheric modeling,
Numerical models"
Knowledge Base Semantic Integration Using Crowdsourcing,"The semantic Web has enabled the creation of a growing number of knowledge bases (KBs), which are designed independently using different techniques. Integration of KBs has attracted much attention as different KBs usually contain overlapping and complementary information. Automatic techniques for KB integration have been improved but far from perfect. Therefore, in this paper, we study the problem of knowledge base semantic integration using crowd intelligence. There are both classes and instances in a KB, in our work, we propose a novel hybrid framework for KB semantic integration considering the semantic heterogeneity of KB class structures. We first perform semantic integration of the class structures via crowdsourcing, then apply the blocking-based instance matching approach according to the integrated class structure. For class structure (taxonomy) semantic integration, the crowd is leveraged to help identifying the semantic relationships between classes to handle the semantic heterogeneity problem. Under the conditions of both large scale KBs and limited monetary budget for crowdsourcing, we formalize the class structure (taxonomy) semantic integration problem as a Local Tree Based Query Selection (LTQS) problem. We show that the LTQS problem is NP-hard and propose two greedy-based algorithms, i.e., static query selection and adaptive query selection. Furthermore, the KBs are usually of large scales and have millions of instances, direct pairwise-based instance matching is inefficient. Therefore, we adopt the blockingbased strategy for instance matching, taking advantage of the class structure (taxonomy) integration result. The experiments on real large scale KBs verify the effectiveness and efficiency of the proposed approaches.","Taxonomy,
Semantics,
Knowledge based systems,
Ontologies,
Crowdsourcing,
Data integration,
Computer science"
Ancillary Services Through Demand Scheduling and Control of Commercial Buildings,"Prior work showed building Heating, Ventilation, Air Conditioning (HVAC) systems can provide ancillary services to the power grid without sacrificing occupant comfort if the reference power variation is of high frequency (seconds to a few minutes). This paper addresses the question of how to do that when the reference power variation is of lower frequency, e.g., periods of a few minutes to an hour. The proposed control system to do so uses a two-layer architecture. An optimizer schedules the baseline cooling and heating power of a building based on load forecasts. A lower level controller is then used to track the scheduled baseline plus ancillary service reference signal. The schedule is periodically updated based on indoor measurements to ensure quality of service in spite of load forecasting error. The algorithm is tested in simulation. Results show that ancillary services in the frequency range of f ∈ [1/(1 hour), 1/(10 minutes)] can be extracted from commercial building HVAC systems while still maintaining a comfortable indoor climate.","Buildings,
Meteorology,
Load modeling,
Cooling,
Temperature measurement,
Frequency control"
HeteroSim: A Heterogeneous CPU-FPGA Simulator,"Heterogeneous Computing is a promising direction to address the challenges of performance and power walls in high-performance computing, where CPU-FPGA architectures are particularly promising for application acceleration. However, the development of such architectures associated with optimal memory hierarchies is challenging due to the absence of an integrated simulator to support full system simulation and architectural exploration. In this work, we present HeteroSim, a full system simulator supporting x86 multi-cores integrated with an FPGA via bus connection. It can support fast architectural exploration with respect to number of cores, number of accelerated kernels on FPGA, and different memory hierarchies between CPU and FPGA. Various performance metrics are returned for further performance analysis and architectural configuration optimization.","Kernel,
Field programmable gate arrays,
Hardware design languages,
Registers,
Computer architecture,
Acceleration,
Computational modeling"
Oscillatory Behaviors in Genetic Regulatory Networks Mediated by MicroRNA With Time Delays and Reaction-Diffusion Terms,"In this paper, we investigate the oscillatory expression in Escherichia coli mediated by microRNA with time delays and reaction-diffusion terms. First of all, the integrated effects of delays and diffusions are first introduced into the genetic regulatory networks involving microRNAs, and a general model of genetic regulatory networks is then formulated. Second, two functional issues on gene regulatory networks, i.e. stability and oscillation of such model, are addressed in detail, and an explicit algorithm determining the properties of periodic oscillation is also presented. We demonstrate that the oscillatory expression of Escherichia coli is not only crucially dependent on the transcriptional and translational delays, but also heavily influenced by the diffusion coefficients. The conclusion is practically verified by a lot of biological experiments and observations. We also find that if the diffusion coefficients of miRNA, mRNA, and protein are suitably small, it can predict that inhomogeneous periodic oscillations can occur unless there only exhibits spatially homogeneous periodic oscillations. The obtained results indicate that the effects of transcriptional and translational delays are essential factors for designing or controlling genetic regulatory networks, in the meantime the functions of reaction-diffusion must beconsidered. Finally, numerical examples are presented to illustrate and visualize theoretical results.","Proteins,
Genetics,
Mathematical model,
Delays,
Delay effects,
Oscillators,
Stability analysis"
A Bio-Inspired Cognitive Agent for Autonomous Urban Vehicles Routing Optimization,"Autonomous urban vehicle prototypes are expected to be efficient even in not explicitly planned circumstances and dynamic environments. The development of autonomous vehicles for urban driving needs real-time information from vehicles and road network to optimize traffic flows. In traffic agent-based models, each vehicle is an agent, while the road network is the environment. Cognitive agents are able to reason on the perceived data, to evaluate the information obtained by reasoning, and to learn and respond, preserving their self-sufficiency, independency, self-determination, and self-reliance. In this paper, a bio-inspired cognitive agent for autonomous urban vehicles routing optimization is proposed. The use of selected bio-inspired analyzing techniques, which are commonly employed to investigate the topological and functional features of a metabolic network, allows the agent to analyze the structural aspects of a road network, find its extreme pathways and outline the balanced flow combinations. This approach optimizes traffic flows over network, minimizes road congestions, and maximizes the number of autonomous vehicles reaching their destination target. Agent behavior has been tested using data coming from Palermo urban road network, Italy, while the adopted bio-inspired analysis techniques have been compared with the A* literature algorithm. Experimental results demonstrate that the approach permits to find a better global routing optimization solution. To the best of our knowledge, it is the first time that metabolic mechanisms involved in a cell survival process have been used to design a congestion solution.","Vehicles,
Roads,
Routing,
Biochemistry,
Optimization,
Heuristic algorithms,
Manganese"
"Explaining Explanation, Part 1: Theoretical Foundations","This is the first in a series of essays that addresses the manifest programmatic interest in developing intelligent systems that help people make good decisions in messy, complex, and uncertain circumstances by exploring several questions: What is an explanation? How do people explain things? How might intelligent systems explain their workings? How might intelligent systems help humans be better understanders as well as better explainers? This article addresses the theoretical foundations.",
Dual-Quality 4:2 Compressors for Utilizing in Dynamic Accuracy Configurable Multipliers,"In this paper, we propose four 4:2 compressors, which have the flexibility of switching between the exact and approximate operating modes. In the approximate mode, these dual-quality compressors provide higher speeds and lower power consumptions at the cost of lower accuracy. Each of these compressors has its own level of accuracy in the approximate mode as well as different delays and power dissipations in the approximate and exact modes. Using these compressors in the structures of parallel multipliers provides configurable multipliers whose accuracies (as well as their powers and speeds) may change dynamically during the runtime. The efficiencies of these compressors in a 32-bit Dadda multiplier are evaluated in a 45-nm standard CMOS technology by comparing their parameters with those of the state-of-the-art approximate multipliers. The results of comparison indicate, on average, 46% and 68% lower delay and power consumption in the approximate mode. Also, the effectiveness of these compressors is assessed in some image processing applications.",
"Efficient and Private Scoring of Decision Trees, Support Vector Machines and Logistic Regression Models based on Pre-Computation","Many data-driven personalized services require that private data of users is scored against a trained machine learning model. In this paper we propose a novel protocol for privacypreserving classification of decision trees, a popular machine learning model in these scenarios. Our solutions is composed out of building blocks, namely a secure comparison protocol, a protocol for obliviously selecting inputs, and a protocol for multiplication. By combining some of the building blocks for our decision tree classification protocol, we also improve previously proposed solutions for classification of support vector machines and logistic regression models. Our protocols are information theoretically secure and, unlike previously proposed solutions, do not require modular exponentiations. We show that our protocols for privacy-preserving classification lead to more efficient results from the point of view of computational and communication complexities. We present accuracy and runtime results for 7 classification benchmark datasets from the UCI repository.","Protocols,
Cryptography,
Computational modeling,
Decision trees,
Data models,
Logistics"
Variational Bayesian Adaptive Cubature Information Filter Based on Wishart Distribution,"This paper presents a noise adaptive variational Bayesian cubature information filter based on Wishart distribution. In the frame of recursive Bayesian estimation, the noise adaptive information filter propagating the information matrix and information state is derived. And the integration of recursive Bayesian estimation is approximated by cubature integration rule. Then, the inverse of measurement noise matrix is modeled as a Wishart distribution, so the joint distribution of posterior state and measurement noise can be approximated by the product of independent Gaussian and Wishart. Furthermore, the corresponding square root version is also derived to improve numerical characteristics. Simulation results with unknown and correlated measurement noise demonstrate the effectiveness of the proposed algorithms.","Covariance matrices,
Bayes methods,
Noise measurement,
Estimation,
Symmetric matrices,
Adaptation models,
Approximation algorithms"
Optical and Mechanical Excitation Thermography for Impact Response in Basalt-Carbon Hybrid Fiber-Reinforced Composite Laminates,"In this paper, optical and mechanical excitation thermography were used to investigate basalt fiber reinforced polymer (BFRP), carbon fiber reinforced polymer (CFRP) and basalt-carbon fiber hybrid specimens subjected to impact loading. Interestingly, two different hybrid structures including sandwich-like and intercalated stacking sequence were used. Pulsed phase thermography (PPT), principal component thermography (PCT) and partial least squares thermography (PLST) were used to process the thermographic data. X-ray computed tomography (CT) was used for validation. In addition, signal-to-noise ratio (SNR) analysis was used as a means of quantitatively comparing the thermographic results. Of particular interest, the depth information linked to Loadings in PLST was estimated for the first time. Finally, a reference was provided for taking advantage of different hybrids in view of special industrial applications.","Optical surface waves,
Inspection,
Cameras,
Heating systems,
Optical imaging,
Carbon,
Informatics"
"ATOM: Efficient Tracking, Monitoring, and Orchestration of Cloud Resources","The emergence of Infrastructure as a Service framework brings new opportunities, which also accompanies with new challenges in auto scaling, resource allocation, and security. A fundamental challenge underpinning these problems is the continuous tracking and monitoring of resource usage in the system. In this paper, we present ATOM, an efficient and effective framework to automatically track, monitor, and orchestrate resource usage in an Infrastructure as a Service (IaaS) system that is widely used in cloud infrastructure. We use novel tracking method to continuously track important system usage metrics with low overhead, and develop a Principal Component Analysis (PCA) based approach to continuously monitor and automatically find anomalies based on the approximated tracking results. We show how to dynamically set the tracking threshold based on the detection results, and further, how to adjust tracking algorithm to ensure its optimality under dynamic workloads. Lastly, when potential anomalies are identified, we use introspection tools to perform memory forensics on VMs guided by analyzed results from tracking and monitoring to identify malicious behavior inside a VM. We demonstrate the extensibility of ATOM through virtual machine (VM) clustering. The performance of our framework is evaluated in an open source IaaS system.","Monitoring,
Cloud computing,
Atomic measurements,
Security,
Principal component analysis,
Resource management"
Asymptotically Locally Optimal Weight Vector Design for a Tighter Correlation Lower Bound of Quasi-Complementary Sequence Sets,"A quasi-complementary sequence set (QCSS) refers to a set of two-dimensional matrices with low nontrivial aperiodic auto- and cross-correlation sums. For multicarrier code-division multiple-access applications, the availability of large QCSSs with low correlation sums is desirable. The generalized Levenshtein bound (GLB) is a lower bound on the maximum aperiodic correlation sum of QCSSs. The bounding expression of GLB is a fractional quadratic function of a weight vector w and is expressed in terms of three additional parameters associated with QCSS: the set size K, the number of channels M, and the sequence length N. It is known that a tighter GLB (compared to the Welch bound) is possible only if the condition M ≥ 2 and K ≥ K̅ + 1, where K̅ is a certain function of M and N, is satisfied. A challenging research problem is to determine if there exists a weight vector that gives rise to a tighter GLB for all (not just some) K ≥ K̅ + 1 and M ≥ 2, especially for large N, i.e., the condition is asymptotically both necessary and sufficient. To achieve this, we analytically optimize the GLB which is (in general) nonconvex as the numerator term is an indefinite quadratic function of the weight vector. Our key idea is to apply the frequency domain decomposition of the circulant matrix (in the numerator term) to convert the nonconvex problem into a convex one. Following this optimization approach, we derive a new weight vector meeting the aforementioned objective and prove that it is a local minimizer of the GLB under certain conditions.","Correlation,
Multicarrier code division multiple access,
Frequency-domain analysis,
Quadratic programming,
Upper bound,
Matrix converters"
Performance comparison of SISO and MIMO-OFDM based on SDR platform,"Due to requirement of reliable high-speed wireless communication, OFDM combined with multiple antennas (MIMO) system is a key technology for next-generation wireless communications to improve transmission performance. In this paper, we conduct field experiment for SISO and MIMO-OFDM using USRP N210 hardware as SDR platform. The research is conducted in LOS and NLOS environment with 16-QAM modulation technique. The result shows that MIMO-OFDM achieves better performance than SISO-OFDM. 2×2 MIMO spatial diversity with Alamouti STBC algorithm gives 2 dB diversity gain at BER of 5.10-4 in LOS scheme and 6.7 dB in NLOS scheme at BER of 5.10-3.","Receiving antennas,
OFDM,
MIMO,
Signal to noise ratio,
Transmitting antennas"
Mitigating Power Contention: A Scheduling Based Approach,"Shared resource contention has been a major performance issue for CMPs. In this paper, we tackle the power contention problem in power constrained CMPs by considering and treating power as a first-class shared resource. Power contention occurs when multiple processes compete for power, and leads to degraded system performance. In order to solve this problem, we develop a shared resource contention-aware scheduling algorithm that mitigates the contention for power and the shared memory subsystem at the same time. The proposed scheduler improves system performance by balancing the shared resource usage among scheduling groups. Evaluation results across a variety of multiprogrammed workloads show performance improvements over a state-of-the-art scheduling policy which only considers memory subsystem contention.","Random access memory,
Benchmark testing,
Power demand,
Processor scheduling,
Scheduling,
Memory management,
System performance"
Resource renting for periodical cloud workflow applications,"Cloud computing is a new resource provisioning mechanism, which represents a convenient way for users to access different computing resources. Periodical workflow applications commonly exist in scientific and business analysis, among many other fields. One of the most challenging problems is to determine the right amount of resources for multiple periodical workflow applications. In this paper, the periodical workflow applications scheduling problem with total renting cost minimization is considered. The novelty of this work relies precisely on this objective function, which is more realistic in practice than the more commonly considered makespan minimization. An integer programming model is constructed for the problem under study. A Precedence Tree based Heuristic (PTH) is developed which considers three types of initial schedule construction methods. Based on the initial schedule, two improvement procedures are presented. The proposed methods are compared with existing algorithms for the related makespan based multiple workflow scheduling problem. Experimental and statistical results demonstrate the effectiveness and efficiency of the proposed algorithm.","Cloud computing,
Processor scheduling,
Scheduling,
Schedules,
Quality of service,
Minimization,
Partitioning algorithms"
Multi-Object Classification via Crowdsourcing With a Reject Option,"Consider designing an effective crowdsourcing system for M-ary classification where crowd workers complete simple binary microtasks, which are aggregated to give the final result. We consider the novel scenario where workers have a reject option, so they may skip microtasks they are unable or unwilling to do. For example, in mismatched speech transcription, workers who do not know the language may be unable to respond to microtasks in phonological dimensions outside their categorical perception. We present an aggregation approach using a weighted majority voting rule, where each worker's response is assigned an optimized weight to maximize the crowd's classification performance. We evaluate system performance in both exact and asymptotic forms. Furthermore, we consider the setting where there may be a set of greedy workers that complete microtasks even when they are unable to perform it reliably. We consider an oblivious and an expurgation strategy to deal with greedy workers, developing an algorithm to adaptively switch between the two based on the estimated fraction of greedy workers in the anonymous crowd. Simulation results show improved performance compared with conventional majority voting.","Crowdsourcing,
Speech,
Reliability,
Speech processing,
Bayes methods,
Signal processing algorithms"
A Planar Polarization-Reconfigurable Antenna,"This paper reports a planar polarization-reconfigurable antenna with a simple switching topology. A dual-mode substrate integrated waveguide (SIW) cavity is adopted for the element antenna having two input ports. Four radiation slots are etched on the top surface of the SIW cavity for generating the circularly polarized radiation, whose radiation phases can be adjusted by switching the input port. The left-hand circular polarization, right-hand circular polarization, and linear polarization can be realized by properly choosing the state of the excitation. A 2 × 2 array antenna is designed for the demonstration of the array application, and experiments are carried out to validate the design. Good agreement among the simulated and measured results is obtained. Different to the reported antenna architectures in the studies, which usually require complicated switching networks and more switching elements when designing an array for obtaining a high radiation gain, the proposed array antenna does not need additional switching elements for the large array applications. It has a low cost and a simple structure, and can be used for the polarization diverse applications of the wireless system.",
On quantifying diffusion of health information on Twitter,"With the increasing use of digital technologies, online social networks are emerging as major means of communication. Recently, social networks such as Facebook and Twitter are also being used by consumers, care providers (physicians, hospitals), and government agencies to share health related information. The asymmetric user network and the short message size have made Twitter particularly popular for propagating health related content on the Web. Besides tweeting on their own, users can choose to retweet particular tweets from other users (even if they do not follow them on Twitter.) Thus, a tweet can diffuse through the Twitter network via the follower-friend connections. In this paper, we report results of a pilot study we conducted to quantitatively assess how health related tweets diffuse in the directed follower-friend Twitter graph through the retweeting activity. Our effort includes (1). development of a retweet collection and Twitter retweet graph formation framework and (2). a preliminary analysis of retweet graphs and associated diffusion metrics for health tweets. Given the ambiguous nature (due to polysemy and sarcasm) of health relatedness of tweets collected with keyword based matches, our initial study is limited to ≈ 200 health related tweets (which were manually verified to be on health topics) each with at least 25 retweets. To our knowledge, this is first attempt to study health information diffusion on Twitter through retweet graph analysis.","Twitter,
Measurement,
Databases,
Uniform resource locators,
Cancer,
Facebook"
Wall-Less Flow Phantoms With Tortuous Vascular Geometries: Design Principles and a Patient-Specific Model Fabrication Example,"Flow phantoms with anatomically realistic geometry and high acoustic compatibility are valuable investigative tools in vascular ultrasound studies. Here, we present a new framework to fabricate ultrasound-compatible flow phantoms to replicate human vasculature that is tortuous, nonplanar, and branching in nature. This framework is based upon the integration of rapid prototyping and investment casting principles. A pedagogical walkthrough of our engineering protocol is presented in this paper using a patient-specific cerebral aneurysm model as an exemplar demonstration. The procedure for constructing the flow circuit component of the phantoms is also presented, including the design of a programmable flow pump system, the fabrication of blood mimicking fluid, and flow rate calibration. Using polyvinyl alcohol cryogel as the tissue mimicking material, phantoms developed with the presented protocol exhibited physiologically relevant acoustic properties [attenuation coefficient: 0.229±0.032 dB/(cm·MHz) and acoustic speed: 1535±2.4 m/s], and their pulsatile flow dynamics closely resembled the flow profile input. As a first application of our developed phantoms, the flow pattern of the patient-specific aneurysm model was visualized by performing high-frame-rate color-encoded speckle imaging over multiple time-synchronized scan planes. Persistent recirculation was observed, and the vortex center was found to shift in position over a cardiac cycle, indicating the 3-D nature of flow recirculation inside an aneurysm. These findings suggest that phantoms produced from our reported protocol can serve well as acoustically compatible test beds for vascular ultrasound studies, including 3-D flow imaging.",
Multi-Layer Interaction Graph for Analysis and Mitigation of Cascading Outages,"This paper proposes a multi-layer interaction graph on cascading outages of power systems as an extension of a single-layer interaction network proposed previously. This multi-layer interaction graph provides a practical framework for the prediction of outage propagation and decision making on mitigation actions. It has multiple layers to, respectively, identify key intra-layer links and components within each layer and key inter-layer links and components between layers, which contribute the most to outage propagation. Each layer focuses on one of several aspects that are critical for system operators' decision support, such as the number of line outages, the amount of load shedding, and the electrical distance of outage propagation. Besides, the proposed integrated mitigation strategies can limit the propagation of cascading outages by weakening key intra-layer links. All layers are constructed offline from a database of simulated cascades and then used online. A three-layer interaction graph is presented in detail and demonstrated on the Northeastern Power Coordinating Council 48-machine 140-bus system. The key intra- and inter-layer links and key components revealed by the multi-layer interaction graph provide useful insights on the mechanism and mitigation of cascading outages, which cannot be obtained from any single-layer.","Databases,
Power system faults,
Analytical models,
Power system protection,
Computational modeling,
Joining processes"
High resolution and linearity enhanced SAR ADC for wearable sensing systems,"This paper presents linearity enhancement capacitor re-configuring technique to improve the Spurious Free Dynamic Range (SFDR) and Signal-to-Noise-and-Distortion Ratio (SNDR) of ADC simultaneously without sacrificing the sampling rate in a 14-bit successive approximation register (SAR) analog-to-digital converter (ADC) for wearable electronics application. Behavioural Monte-Carlo simulations are presented to demonstrate the effect of the proposed method where no complex least-mean-square (LMS) algorithm. Simulation results show that with a mismatch error typical of modern technology, the SFDR is enhanced by about 18 dB and the SNDR is 15 dB better with the proposed technique for a 14-bit SAR ADC, which makes it suitable for accurate and linear smart sensor nodes in wearable sensing systems.","Capacitors,
Calibration,
Linearity,
Monte Carlo methods,
Simulation,
Sensors,
Biomedical monitoring"
Evolving fuzzy models for the position control of magnetic levitation systems,"This paper proposes evolving Takagi-Sugeno (T-S) fuzzy models that characterize the nonlinear dynamics phenomena occurring in the position of magnetic levitation systems. A state feedback control structure is first designed to stabilize the nonlinear process by linearization at certain operating points, and the evolving T-S fuzzy models are next derived for the stabilized closed-loop system. The rule bases and the parameters of the T-S fuzzy models are evolved by an incremental online identification algorithm (OIA). Real-time experiments are conducted in order to validate the evolving T-S fuzzy models that give the sphere position in magnetic levitation system laboratory equipment. The experimental results prove the very good performance of the T-S fuzzy models in terms of output responses and root mean square error values. The performance comparison with similar T-S fuzzy models evolved by another incremental OIA and three nature-inspired optimization algorithms is included.","Magnetic levitation,
Adaptation models,
Computational modeling,
Optimization,
Process control,
Electromagnets,
Takagi-Sugeno model"
A New Zigzag-Decodable Code with Efficient Repair in Wireless Distributed Storage,"A code is said to possess the combination property if k source packets are mapped into n k packets and any k out of these n packets are able to recover the information of the original k packets. While the class of maximum-distance-separable codes are well known to have this property, its decoding complexity is generally high. For this reason, a new class of codes which can be decoded by the zigzag-decoding algorithm is considered. It has a lower decoding complexity at the expense of extra storage overhead in each parity packet. In this work, a new construction of a zigzag decodable code is proposed. The novelty of this new construction lies in the careful selection of the amount of bit-shift of each source packet in obtaining each parity packet. Besides, an efficient on-the-air repair scheme based on physical-layer network coding is designed.","Decoding,
Decision support systems,
Complexity theory,
Network coding,
Encoding,
Maintenance engineering,
Wireless sensor networks"
Fuzzy Identity-Based Data Integrity Auditing for Reliable Cloud Storage Systems,"Data integrity, a core security issue in reliable cloud storage, has received much attention. Data auditing protocols enable a verifier to efficiently check the integrity of the outsourced data without downloading the data. A key research challenge associated with existing designs of data auditing protocols is the complexity in key management. In this paper, we seek to address the complex key management challenge in cloud data integrity checking by introducing fuzzy identity-based auditing, the first in such an approach, to the best of our knowledge. More specifically, we present the primitive of fuzzy identity-based data auditing, where a user’s identity can be viewed as a set of descriptive attributes. We formalize the system model and the security model for this new primitive. We then present a concrete construction of fuzzy identity-based auditing protocol by utilizing biometrics as the fuzzy identity. The new protocol offers the property of error-tolerance, namely, it binds with private key to one identity which can be used to verify the correctness of a response generated with another identity, if and only if both identities are sufficiently close. We prove the security of our protocol based on the computational Diffie-Hellman assumption and the discrete logarithm assumption in the selective-ID security model. Finally, we develop a prototype implementation of the protocol which demonstrates the practicality of the proposal.","Cloud computing,
Protocols,
Servers,
Cryptography,
Computational modeling,
Biological system modeling"
Variations in graph energy: A measure for network resilience,"There are many models and metrics developed to study the resilience of networks. Eigenvalues are the roots of the characteristic polynomial for a given graph and are mathematically rigorous compared to a statistical measure such as degree distribution. The graph energy is the sum of absolute values of eigenvalues; there is a subtle difference between the adjacency, Laplacian, and normalized Laplacian graph energy calculations. Our primary objective in this paper is to understand what different graph energy mean from a network resilience point of view. We calculate the adjacency, Laplacian, and normalized Laplacian graph energies on four backbone networks under targeted node and link attack scenarios. While adjacency and Laplacian graph energy decrease with node and link attacks, the normalized Laplacian energy increases with link attacks converging to a maximum value equal to the network order. The structural similarities of physical-level topologies is revealed by the close values of adjacency and Laplacian energies.","Laplace equations,
Eigenvalues and eigenfunctions,
Measurement,
Symmetric matrices,
Toy manufacturing industry,
Resilience,
Mathematical model"
Year,,
A Proactive Workflow Model for Healthcare Operation and Management,"Advances in real-time location systems have enabled us to collect massive amounts of fine-grained semantically rich location traces, which provide unparalleled opportunities for understanding human activities and generating useful knowledge. This, in turn, delivers intelligence for real-time decision making in various fields, such as workflow management. Indeed, it is a new paradigm to model workflows through knowledge discovery in location traces. To that end, in this paper, we provide a focused study of workflow modeling by integrated analysis of indoor location traces in the hospital environment. In particular, we develop a workflow modeling framework that automatically constructs the workflow states and estimates the parameters describing the workflow transition patterns. More specifically, we propose effective and efficient regularizations for modeling the indoor location traces as stochastic processes. First, to improve the interpretability of the workflow states, we use the geography relationship between the indoor rooms to define a prior of the workflow state distribution. This prior encourages each workflow state to be a contiguous region in the building. Second, to further improve the modeling performance, we show how to use the correlation between related types of medical devices to reinforce the parameter estimation for multiple workflow models. In comparison with our preliminary work [11], we not only develop an integrated workflow modeling framework applicable to general indoor environments, but also improve the modeling accuracy significantly. We reduce the average log-loss by up to 11 percent.","Hidden Markov models,
Hospitals,
Real-time systems,
Analytical models,
Data models,
Buildings"
Sharing It My Way: Efficient M2M Access in LTE/LTE-A Networks,"When a large number of machine-to-machine (M2M) terminals attempt to access the Long-Term Evolution (LTE)/LTE Advanced (LTE-A) cellular network using the physical random access channel (PRACH), congestion and overload may result, which can lead to serious degradation of performance for both M2M and human-to-human (H2H) terminals. The main cause for this is the inherent complexity of the four-way handshake used for random access, which is well suited for H2H terminal access but unsuitable for massive M2M access. In this paper, we describe an efficient scheme for concurrent M2M and H2H access on the PRACH, which separates the resources for M2M and H2H access at the level of preamble codes and avoids the use of the four-step handshake for M2M terminals by implementing a carrier sense multiple access with collision avoidance (CSMA/CA) overlay network using the designated preamble codes. We analyze the performance of the scheme for both H2H and M2M traffic and show the values of the most important design parameters that enable this scheme to support concurrent access by H2H and M2M terminals with little performance degradation.","Uplink,
Interference,
Long Term Evolution,
Computer architecture,
Microprocessors,
Bandwidth,
Performance evaluation"
Multimodal Bio-Inspired Tactile Sensing Module,"Tactile sensors are the last frontier to robots that can handle everyday objects and interact with humans through contact. To be effective, such sensors have to sense the geometry of touched surfaces and objects, as well as any other relevant information for their tasks, such as forces, vibrations, and temperature, that allow them to safely and securely interact within an environment. Given the capability of humans to easily capture and interpret tactile data, one promising direction in order to produce enhanced robotic tactile sensors is to explore and imitate human tactile sensing capabilities. In this context, this paper presents design and hardware implementation issues related to the construction a novel bio-inspired tactile sensing module. Drawing inspiration from the type, functionality, and organization of cutaneous tactile elements, the proposed solution comprises two shallow sensors, namely, a 32-taxel-tactile array and a nine DOF magnetic, angular rate, and gravity sensor, a flexible compliant structure, and a deep pressure sensor placed in a structure similar to human skin. The module's compliant structure and sensor placement provides useful data to overcome the problem of estimating nonnormal forces accommodating sensing modalities essential for acquiring tactile images, and classifying surfaces by vibrations and accelerations. Issues related to the module calibration, its sensing capabilities and possible real world applications are also presented.","Magnetic sensors,
Sensor arrays,
Tactile sensors,
Skin"
Subarray-Based Coordinated Beamforming Training for mmWave and Sub-THz Communications,"Millimeter-wave (mmWave) and sub-Terahertz (THz) communications are compelling as an enabler for next-generation wireless networks. In this paper, we study mmWave and sub-THz systems with array-of-subarray architecture. To accommodate the ultrabroad bandwidth in the mmWave and sub-THz bands, time-delay phase shifters are introduced in system design. Our goal is to investigate beamforming training with hybrid processing to extract the dominant channel information, which would fully exploit channel characteristics while respecting the nature of circuit hardware. In particular, codebooks based on time-delay phase shifters are defined and structured. Then, two multi-resolution time-delay codebooks are designed through subarray coordination. One is built on adaptation of physical beam directions, and the other relies on dynamic approximation of beam patterns. Also, a low-complexity system implementation with modifications on the time-delay codebooks is studied. Furthermore, based on the proposed codebooks, a hierarchical beamforming training strategy with reduced overhead is developed to enable simultaneous training for multiple users. Simulation results show that the proposed multi-resolution time-delay codebooks could provide sufficient beam gains and are robust over large bandwidth. Also, the effectiveness of the hierarchical beamforming training is verified.","Array signal processing,
Training,
Phase shifters,
Radio frequency,
Bandwidth,
Antennas,
Hardware"
Terrestrial link rain attenuation measurements at 84 GHz,"We present 560 m terrestrial link rain attenuation measurements at 84 GHz in Albuquerque, New Mexico. Both empirical and theoretical rain attenuation models such as ITU-R, Mie and Rayleigh will be examined with the measurements. This study will contribute to the understanding of signal propagation phenomena and the utilization of the W/V-bands for satellite communication.",
STA compatible backend design flow for TSV-based 3-D ICs,"In the era of post-device scaling, three-dimensional (3-D) integration is a promising solution to meet performance, power, and cost requirements in modern applications, such as IoT, high performance computing, and cyber-physical systems. A novel design automation flow, compatible with static timing analysis (STA), for exploring the timing and power of 3-D ICs is proposed. Among the different types of vertical interconnects, TSVs modeled as RC wires, are considered in this work. The flow enables design space exploration and optimization utilizing existing timing and power analysis tools, e.g. PrimeTime and PrimeTimePX. The design experience is similar to a 2-D design flow where the placement in multiple tiers is merely performed by an open-source 3-D placer. Application of the flow to different benchmark circuits shows that even with no optimization effort, a two tier 3-D stack produced by the flow achieves up to 14.6% average power reduction, 18.7% performance improvement, and 49% footprint reduction as compared to the 2-D design for a specific circuit.",
Handwritten Arabic numeral recognition using deep learning neural networks,"Handwritten character recognition is an active area of research with applications in numerous fields. Past and recent works in this field have concentrated on various languages. Arabic is one language where the scope of research is still widespread, with it being one of the most popular languages in the world and being syntactically different from other major languages. Das et al. [1] has pioneered the research for handwritten digit recognition in Arabic. In this paper, we propose a novel algorithm based on deep learning neural networks using appropriate activation function and regularization layer, which shows significantly improved accuracy compared to the existing Arabic numeral recognition methods. The proposed model gives 97.4 percent accuracy, which is the recorded highest accuracy of the dataset used in the experiment. We also propose a modification of the method described in [1], where our method scores identical accuracy as that of [1], with the value of 93.8 percent.","Neurons,
Training,
Computational modeling,
Character recognition,
Handwriting recognition,
Biological neural networks,
Optical character recognition software"
Towards reliable and lightweight source switching for datacenter networks,"A low-latency and reliable message switching network is critical for constructing high-speed datacenter networks. In this paper, we present the design, implementation, and evaluation of a novel Location basEd Source Switching (LESS) for datacenter networks. LESS enables lightweight source switching through a location-based addressing scheme. Each switch and host can independently derive a source route to reach a destination without requiring the full knowledge of the network topology. We demonstrate that using location-based source routes as forwarding labels allows LESS to eliminate the need for routing tables and integrate with minimum required functionality for packet forwarding. Moreover, we propose a fast rerouting solution to address the issue of fault tolerance in source routing. Each switch can locally derive an alternative source route during a failure. The paper evaluates the performance of LESS. Our evaluation results suggest that LESS improves the performance of datacenter networks in terms of latency, throughput, and reliability.",
Orienting Parts With Shape Variation,"We study the problem of orienting a part with given admitted shape variations by means of pushing with a single frictionless jaw. We use a very general model for shape variations that is defined by two given convex polygons PI ⊆ PE. In this model, any valid instance must contain PI while it must be contained in PE. The problem that we solve is to determine, for a given h, the sequence of h push actions that puts all valid instances of a part with given shape variation into the smallest possible interval of final orientations. The resulting algorithm runs in O(hn) time, where n=|PI|+|PE|.","Shape,
Solid modeling,
Sensors,
Planning,
Manipulators,
Uncertainty,
Algorithm design and analysis"
Leader-Follower Synchronization of Euler-Lagrange Systems With Time-Varying Leader Trajectory and Constrained Discrete-Time Communication,"This paper addresses the leader-follower synchronization problem of uncertain networked Euler-Lagrange systems under directed interconnection graphs in the presence of communication constraints. We present an adaptive distributed control algorithm such that a group of Euler-Lagrange systems asymptotically synchronize their states to those of a dynamic leader with a time-varying trajectory. The information exchange between all systems in the network is assumed to be discrete in time, intermittent, and subject to irregular communication delays and possible packets dropouts. It is shown that leader-follower synchronization is reached for arbitrary characteristics of the communication process provided that the directed interconnection graph contains a spanning tree. Simulation results are given to illustrate the effectiveness of the proposed control scheme.","Synchronization,
Trajectory,
Delays,
Heuristic algorithms,
Mathematical model,
Time-varying systems,
Eigenvalues and eigenfunctions"
MDPs with energy-parity objectives,"Energy-parity objectives combine ω-regular with quantitative objectives of reward MDPs. The controller needs to avoid to run out of energy while satisfying a parity objective. We refute the common belief that, if an energy-parity objective holds almost-surely, then this can be realised by some finite memory strategy. We provide a surprisingly simple counterexample that only uses coBuchi conditions. We introduce the new class of bounded (energy) storage objectives that, when combined with parity objectives, preserve the finite memory property. Based on these, we show that almostsure and limit-sure energy-parity objectives, as well as almostsure and limit-sure storage parity objectives, are in NP ∩ coNP and can be solved in pseudo-polynomial time for energy-parity MDPs.","Markov processes,
Games,
Memory management,
Energy storage,
Color,
Probability distribution,
Probabilistic logic"
Improved Lower Bounds on the Size of Balls Over Permutations With the Infinity Metric,"We study the size (or volume) of balls in the metric space of permutations, Sn, under the infinity metric. We focus on the regime of balls with radius r = p · (n-1), p ∈ [0, 1], i.e., a radius that is a constant fraction of the maximum possible distance. We provide new lower bounds on the size of such balls. These new lower bounds reduce the asymptotic gap to the known upper bounds to at most 0.029 bits per symbol. Additionally, they imply an improved ball-packing bound for error-correcting codes, and an improved upper bound on the size of optimal covering codes.","Upper bound,
Error correction codes,
Extraterrestrial measurements,
Distortion,
Modulation,
Nonvolatile memory"
Learning Sparse Representation for No-Reference Quality Assessment of Multiply Distorted Stereoscopic Images,"Binocular combination under different distortion types poses a great challenge to three-dimensional image quality assessment (3D-IQA). However, the research works on 3D-IQA with multiple distortion types are very limited. In this paper, we first construct a new multiply distorted stereoscopic image database (NBU-MDSID), which is composed of 270 multiply distorted stereoscopic images and 90 singly distorted stereoscopic images that are corrupted simultaneously and independently by blurring, JPEG compression, and noise injection. We then propose a new multimodal blind metric for quality assessment of multiply distorted stereoscopic images. Inspired by multimodal sparse representation framework, modality-specific dictionaries and the corresponding projection matrices are learned from the singly distorted training database at the training stage, and the testing stage only needs to estimate the quality score based on the reconstruction errors. Experimental results demonstrate the effectiveness of our blind metric.","Stereo image processing,
Distortion,
Three-dimensional displays,
Measurement,
Image quality,
Visualization,
Databases"
Using Proactive Fault-Tolerance Approach to Enhance Cloud Service Reliability,"The large-scale utilization of cloud computing services for hosting industrial/enterprise applications has led to the emergence of cloud service reliability as an important issue for both cloud service providers and users. To enhance cloud service reliability, two types of fault tolerance schemes, reactive and proactive, have been proposed. Existing schemes rarely consider the problem of coordination among multiple virtual machines (VMs) that jointly complete a parallel application. Without VM coordination, the parallel application execution results will be incorrect. To overcome this problem, we first propose an initial virtual cluster allocation algorithm according to the VM characteristics to reduce the total network resource consumption and total energy consumption in the data center. Then, we model CPU temperature to anticipate a deteriorating physical machine (PM). We migrate VMs from a detected deteriorating PM to some optimal PMs. Finally, the selection of the optimal target PMs is modeled as an optimization problem that is solved using an improved particle swarm optimization algorithm. We evaluate our approach against five related approaches in terms of the overall transmission overhead, overall network resource consumption, and total execution time while executing a set of parallel applications. Experimental results demonstrate the efficiency and effectiveness of our approach.","Cloud computing,
Checkpointing,
Fault tolerant systems,
Redundancy,
Monitoring"
"Low Loss, Compact TM-Pass Polarizer Based on Hybrid Plasmonic Grating","A low-loss, compact TM-pass polarizer is demonstrated based on hybrid plasmonic grating on silicon-on-insulator platform. Since the large mode distribution mismatch and plasmonic effect significantly influence the transmission and reflection spectrum of the device, the traditional theory of Bragg grating cannot fully explain this phenomenon. Here, we proposed an analysis method which takes effective index and mode overlap together into consideration to design this polarizer. A compact length of 2.5 μm with extinction ratio over 25 dB is realized simultaneously. Moreover, the insertion loss is only 0.088 dB, which is comparable to dielectric-based devices.","Gratings,
Metals,
Plasmons,
Optical polarization,
Optical reflection,
Silicon"
MURS: Mitigating Memory Pressure in Service-Oriented Data Processing System,"Although a data processing system often works as a batch processing system, many enterprises deploy such a system as a service, which we call the service-oriented data processing system. It has been shown that in-memory data processing systems suffer from serious memory pressure. The situation becomes even worse for the service-oriented data processing systems due to various reasons. For example, in a service-oriented system, multiple submitted tasks are launched at the same time and executed in the same context in the resources, compared with the batch processing mode where the tasks are processed one by one. Therefore, the memory pressure will affect all submitted tasks, including the tasks that only incur the light memory pressure when they are run alone. In this paper, we find that the reason why memory pressure arises is because the running tasks produce massive long-living data objects in the limited memory space. Our studies further reveal that the long-living data objects are generated by the API functions that are invoked by the in-memory processing frameworks. Based on these findings, we propose a method to classify the API functions based on the memory usage rate. Further, we design a scheduler called MURS to mitigate the memory pressure. We implement MURS in Spark and conduct the experiments to evaluate the performance of MURS. The results show that when comparing to Spark, MURS can 1) decrease the execution time of the submitted jobs by up to 65.8%, 2) mitigate the memory pressure in the server by decreasing the garbage collection time by up to 81%, and 3) reduce the data spilling, and hence disk I/O, by approximately 90%.","Sparks,
Batch production systems,
Memory management,
Data models,
Big Data,
Computer science"
Electric properties of Y-Ba-Cu-O micro-diodes based on asymmetrically narrowed mesas,"We present our studies of electric properties of micro-diodes based on asymmetrically narrowed, partially oxygen-depleted, semiconducting YBa2Cu3O7-x thin-film mesas. A level of asymmetry of nonlinear current-voltage characteristics of our diodes increases with the decrease of the residual oxygen content in their neck region and with increasing the operating temperature. The largest asymmetry is observed for diodes with x ~ 0.5 and at T = 300 K. An asymmetric distribution of the electric potential for different bias polarities initiate an asymmetric, non-uniform distribution of intrinsic electric field due to heating of carriers in the diode. The experimental results and possible diode's technology are discussed.",
Data-Driven Modeling Using System Integration Scaling Factors and Positioning Performance of an Exposure Machine System,"A data-driven modeling approach is proposed for using system integration scaling factors and positioning performance of an exposure machine system to build models for predicting positioning errors and for analyzing parameter sensitivity. The proposed approach uses a uniform experimental design (UED), multiple regression (MR), back-propagation neural network (BPNN), adaptive neuro-fuzzy inference system (ANFIS), and analysis of variance (ANOVA). The UED reduces the number of experimental runs needed to collect data for modeling. The MR, BPNN, and ANFIS are used to construct positioning models of an exposure machine system. The significant system integration scaling factors are determined by ANOVA. The inputs to the data-driven model are system integration scaling factors fx, fy, and fq, and the output is the positioning error. The UED was used to collect 41 experimental data, which comprised 0.0595% of the full-factorial experimental data. Performance tests demonstrated the excellent performance of the UED in collecting data used to build the MR, BPNN, and ANFIS data-driven models. The data-driven models can accurately predict positioning errors during validation. In addition, a sensitivity analyses of parameters showed that design parameters fx and fy have the greatest influence on positioning performance.","System integration,
Predictive models,
Adaptation models,
Analytical models,
Sensitivity,
Data models,
Analysis of variance"
The prediction of energy-absorption on the car crush box,"This paper describes a computationally aided design process of a thin-walled structure of a retail car crash box subjected to a progressive crashing in longitudinal axial direction. The study was broken up into three phases: (1) digitising of the existing retail car crash box structure, (2) the crash simulation of the structure using dynamic explicit formulation (3) the verification of the simulation of the accident. In the digitalization phase of this structure, the perimeter of the cross section, the shape, the length and the thickness of profile were made the same as the Original Equipment Manufacturer (OEM) the product of a compact car found in the local market. The crashing procedure and parameter follow the New Car Assessment Program (NCAP) by National Highway Traffic Safety Administration (NHTSA). It found that the value of energy absorbed by the crash box was 5.91 KJ. The specific energy absorption is 21.53 KJ/kg. The crash force efficiency is 0.54. The simulation method, that was verified using square tube structure, resulting in the value that matches to the current simulation done by another researcher.",
ARM: Anonymous Rating Mechanism for Discrete Power Control,"Wireless interference management through continuous power control has been extensively studied in the literature. However, practical systems often adopt discrete power control with a limited number of power levels and MCSs (Modulation Coding Schemes). In general, discrete power control is NP-hard due to its combinatorial nature. To tackle this challenge, we propose an innovative approach of interference management: ARM (Anonymous Rating Mechanism). Inspired by the successes of the simple anonymous rating mechanism in E-commerce, we develop ARM as distributed near-optimal algorithm for solving the discrete power control problem (i.e., the joint scheduling, power allocation, and modulation coding adaption problem) under the physical interference model. We show that ARM achieves a close-to-optimal network throughput with a low control overhead. We also characterize the performance gap of ARM with the theoretical optimal solution due to the loss of rating information, and study the trade-off between such gap and the convergence time of ARM. We present numerical results with practical parameter choices to validate the theoretical findings, and highlight the impacts of approximation factor, the number of power levels, and the incomplete rating information.",
Tensor Voting Guided Mesh Denoising,"Mesh denoising is imperative for improving imperfect surfaces acquired by scanning devices. The main challenge is to faithfully retain geometric features and avoid introducing additional artifacts when removing noise. Unlike the existing mesh denoising techniques that focus only on either the first-order features or high-order differential properties, our approach exploits the synergy when facet normals and quadric surfaces are integrated to recover a piecewise smooth surface. In specific, we vote on surface normal tensors from robust statistics to guide the creation of consistent subneighborhoods subsequently used by moving least squares (MLS). This voting naturally leads to a conceptually simple way that gives a unified mesh-denoising framework for not only handling noise but also enabling the recovering of surfaces with both sharp and small-scale features. The effectiveness of our framework stems from: 1) the multiscale tensor voting that avoids the influence from noise; 2) the effective energy minimization strategy to searching the consistent subneighborhoods; and 3) the piecewise MLS that fully prevents the side effects from different subneighborhoods during surface fitting. Our framework is direct, practical, and easy to understand. Comparisons with the state-of-the-art methods demonstrate its outstanding performance on feature preservation and artifact suppression.","Noise reduction,
Tensile stress,
Surface reconstruction,
Surface treatment,
Noise measurement,
Geometry,
Robustness"
Sufficient Image Appearance Transfer Combining Color and Texture,"Traditional color transfer methods can achieve satisfactory results for transferring the color style from a reference image to a source image, provided that the source image shares the similar color mood with the reference image. However, color transfer solutions are always sensitive to color category, which cannot generate natural results when the contents of the reference image and the source image are different, e.g., a lush tree in the reference image and a bare tree in the source image. In this situation, it is insufficient only through color transfer to transfer the appearance from the reference image to the source image only through color transfer, since other information such as texture should also be considered. To obtain sufficient appearance transfer results, we propose a new image appearance transfer method combining both color and texture features. Given a source image and a reference image, our method starts with feature detection and matching between the source image and the reference image. Then, we design a new method for expanding feature point sets to get texture transfer mark (TTM) and color transfer mark (CTM). TTM and CTM will guide texture transfer and color transfer, respectively. We demonstrate our appearance transfer algorithm between quantities of images and compare with results of existing methods. Experiment results show that given only a single reference image, our approach can produce more sufficient appearance transfer results than the state-of-the-art algorithms.","Image color analysis,
Feature extraction,
Algorithm design and analysis,
Mood,
Lighting,
Visualization,
Prediction algorithms"
Reliability of SiC power MOSFETs under high repetitive pulse current conditions,"Due to technology advancements in material sciences, power MOSFETs manufactured with wide band gap materials such as silicon carbide (SiC), gallium nitride (GaN) have been proposed as an alternative to silicon (Si) based MOSFETs and IGBTs. Reliability of these power switches is important when considering their vital role in power converters for aerospace, railways, hybrid electric vehicles, and power system applications. In this paper, 1200V 4H-SiC MOSFET 2D device model is designed and simulated using technology computer-aided design (TCAD). Later mixed mode simulations are carried out under repetitive pulse current conditions. During the testing, device characteristics such as threshold voltage (Vth), on state resistance (Rds-on), and junction temperature (Tj) are recorded. Instability in the threshold voltage of the device is identified due to trapping of interface charges at the gate oxide as a result of the pulse current stress on the device. Furthermore it is identified that junction temperature and on state resistance increases with the increase in the number of pulse current cycles which can eventually lead to device failure.","MOSFET,
Silicon carbide,
Logic gates,
Threshold voltage,
Stress,
Doping,
Immune system"
Study of Text Segmentation and Recognition Using Leap Motion Sensor,"Recognition of 3-D texts drawn by fingers using Leap motion sensor can be challenging for existing text recognition frameworks. The texts sensed by Leap motion device are different from traditional offline and on-line writing systems. This is because of frequent jitters and non-uniform character sizes while writing using Leap motion interface. Moreover, because of air writing, characters, words, and lines are usually connected by continuous stroke that makes it difficult to recognize. In this paper, we present a study of segmentation and recognition of text recorded using Leap motion sensor. The segmentation task of continuous text into words is performed using a heuristic analysis of stroke length between two successive words. Next, the recognition of each segmented word is performed using sequential classifiers. In this paper, we have performed 3-D text recognition using hidden Markov model (HMM) and bidirectional long short-term memory neural networks (BLSTM-NNs). We have created a data set consisting of 560 Latin sentences drawn by ten participants using Leap motion sensor for experiments. An accuracy of 78.2% has been obtained in word segmentation, whereas 86.88% and 81.25% accuracies have been recorded in word recognition using BLSTM-NN and HMM classifiers, respectively.","Three-dimensional displays,
Sensors,
Text recognition,
Motion segmentation,
Writing,
Hidden Markov models,
Character recognition"
Observability-Aware Trajectory Optimization for Self-Calibration With Application to UAVs,We study the nonlinear observability of a system's states in view of how well they are observable and what control inputs would improve the convergence of their estimates. We use these insights to develop an observability-aware trajectory-optimization framework for nonlinear systems that produces trajectories well suited for self-calibration. Our method reasons about the quality of observability while respecting system dynamics and motion constraints to yield the optimal trajectory for rapid convergence of the self-calibration states (or other user-chosen states). Self-calibration trials with a real and a simulated quadrotor provide compelling evidence that the proposed method is both faster and more accurate compared to other state-of-the-art approaches.,
Real-time robot path planning around complex obstacle patterns through learning and transferring options,"We consider the problem of path planning in an initially unknown environment where a robot does not have an a priori map of its environment but has access to prior information accumulated by itself from navigation in similar but not identical environments. To address the navigation problem, we propose a novel, machine learning-based algorithm called Semi-Markov Decision Process with Unawareness and Transfer (SMDPU-T) where a robot records a sequence of its actions around obstacles as action sequences called options which are then reused by it to learn suitable, collision-free maneuvers around more complex obstacles in future. Our results illustrate that SMDPU-T takes 24% planning time and 39% total time to solve same navigation tasks as compared to a recent, sampling-based path planner.",
Throughput maximization and resource optimization in NFV-enabled networks,"Network function virtualization (NFV) has been emerging as a new paradigm to enable elastic and inexpensive network services in modern computer networks, through deploying flexible virtualized network functions (VNFs) running in virtual computing platforms. Different VNFs can be chained together to form different service chains, to meet various user data routing demands for different network services. In this paper we consider provisioning network services in an NFV-enabled network that consists of data centers for implementing VNF instances of service chains and switches. We study the throughput maximization problem with the aim to admit as many user requests as possible while minimizing the implementation cost of the requests, assuming that limited numbers of instances of each service chain have been stored in data centers. We first propose an optimal algorithm for the problem if all requests have identical packet rates; otherwise, we devise two approximation algorithms with probable approximation ratios, depending on whether the packet traffic of each request is splittable. We finally conduct experiments to evaluate the performance of the proposed algorithms by simulations. Experimental results show that the proposed algorithms achieve at least 15% more throughput than that of a greedy algorithm.","Delays,
Throughput,
Approximation algorithms,
Virtualization,
Routing,
Cloud computing,
Virtual machining"
Dynamic Phasor Modeling of Line-Commutated Rectifiers With Harmonics Using Analytical and Parametric Approaches,"Line-commutated rectifiers (LCRs) are widely used in various industrial applications, wherein they are also known to be a significant source of harmonics. The dynamic phasor (DP) modeling approaches have been well studied in the literature to simulate the dynamics of power systems and their components including harmonics. In this paper, the state-of-the-art analytical DP (ADP) models of LCRs, which relate the ac and dc subsystems through complicated switch functions, are first investigated. Then, a new parametric DP (PDP) model of LCRs is proposed, wherein the DP dynamics of rectifier/dc-link are represented using a set of explicit algebraic functions that are numerically established. Rigorous computer studies demonstrate that the proposed PDP methodology is capable of accurately predicting the steady-state and transient responses of LCR systems under a wide range of loading conditions, while providing significant computational advantages over the conventional detailed model and the established ADP models.",
Characterization and Inference of Graph Diffusion Processes from Observations of Stationary Signals,"Many tools from the field of graph signal processing exploit knowledge of the underlying graph's structure (e.g., as encoded in the Laplacian matrix) to process signals on the graph. Therefore, in the case when no graph is available, graph signal processing tools cannot be used anymore. Researchers have proposed approaches to infer a graph topology from observations of signals on its nodes. Since the problem is ill-posed, these approaches make assumptions, such as smoothness of the signals on the graph, or sparsity priors. In this paper, we propose a characterization of the space of valid graphs, in the sense that they can explain stationary signals. To simplify the exposition in this paper, we focus here on the case where signals were i.i.d. at some point back in time and were observed after diffusion on a graph. We show that the set of graphs verifying this assumption has a strong connection with the eigenvectors of the covariance matrix, and forms a convex set. Along with a theoretical study in which these eigenvectors are assumed to be known, we consider the practical case when the observations are noisy, and experimentally observe how fast the set of valid graphs converges to the set obtained when the exact eigenvectors are known, as the number of observations grows. To illustrate how this characterization can be used for graph recovery, we present two methods for selecting a particular point in this set under chosen criteria, namely graph simplicity and sparsity. Additionally, we introduce a measure to evaluate how much a graph is adapted to signals under a stationarity assumption. Finally, we evaluate how state-of-the-art methods relate to this framework through experiments on a dataset of temperatures.",
Quantification of Secrecy in Partially Observed Stochastic Discrete Event Systems,"While cryptography is used to protect the content of information (e.g., a message) by making it undecipherable, behaviors (as opposed to information) may not be encrypted and may only be protected by partially or fully hiding through creation of ambiguity (by providing covers that generate indistinguishable observations from secrets). Having a cover together with partial observability does cause ambiguity about the system behaviors desired to be kept secret, yet some information about secrets may still be leaked due to statistical difference between the occurrence probabilities of the secrets and their covers. In this paper, we propose a Jensen-Shannon divergence (JSD)-based measure to quantify secrecy loss in systems modeled as partially observed stochastic discrete event systems, which quantifies the statistical difference between two distributions, one over the observations generated by secret and the other over those generated by cover. We further show that the proposed JSD measure for secrecy loss is equivalent to the mutual information between the distributions over possible observations and that over possible system status (secret versus cover). Since an adversary is likely to discriminate more if he/she observes for a longer period, our goal is to evaluate the worst case loss of secrecy as obtained in the limit over longer and longer observations. Computation for the proposed measure is also presented. Illustrative examples, including the one with side-channel attack, are provided to demonstrate the proposed computation approach.","Loss measurement,
Stochastic processes,
Discrete-event systems,
Observers,
Cryptography,
Observability,
Mutual information"
Estimation and Fusion for Tracking Over Long-Haul Links Using Artificial Neural Networks,"In a long-haul sensor network, sensors are remotely deployed over a large geographical area to perform certain tasks, such as tracking and/or monitoring of one or more dynamic targets. A remote fusion center fuses the information provided by these sensors so that a final estimate of certain target characteristics—such as the position—is expected to possess much improved quality. In this work, we pursue learning-based approaches for estimation and fusion of target states in long-haul sensor networks. In particular, we consider learning based on various implementations of artificial neural networks (ANNs). The joint effect of 1) imperfect communication condition, namely, link-level loss and delay, and 2) computation constraints, in the form of low-quality sensor estimates, on ANN-based estimation and fusion, is investigated by means of analytical and simulation studies.","State estimation,
Data integration,
Root mean square,
Artificial neural networks,
Target tracking"
Energy Efficient Scheduling and Management for Large-Scale Services Computing Systems,"With the increasing popularity of services published online, energy consumption of services computing systems is growing dramatically. Besides Quality of Service (QoS), energy efficiency has become an important issue and drawn significant attention. However, energy efficient request scheduling and service management for large-scale services computing systems face challenges because of the high dynamics and unpredictability of request arrivals. In this paper, we jointly consider the conflicting metrics of performance, queue congestion and energy consumption. We propose a distributed online scheduling and management algorithm which does not require any priori statistical knowledge of request arrivals. Mathematical analysis is conducted which demonstrates that our algorithm can achieve arbitrary tradeoff between performance and energy efficiency. Numerical and real trace data based experiments are carried out to validate the effectiveness of our algorithm in optimizing energy efficiency while stabilizing the system.","Servers,
Quality of service,
Service computing,
Energy consumption,
Optimization,
Processor scheduling,
Computational modeling"
Wireless Powered Dense Cellular Networks: How Many Small Cells Do We Need?,"This paper focuses on wireless powered 5G dense cellular networks, where base station (BS) delivers energy to user equipment (UE) via the microwave radiation in sub-6 GHz or millimeter wave (mmWave) frequency, and UE uses the harvested energy for uplink information transmission. By addressing the impacts of employing different numbers of antennas and bandwidths at lower and higher frequencies, we evaluate the amount of harvested energy and throughput in such networks. Based on the derived results, we obtain the required small cell density to achieve an expected level of harvested energy or throughput. Also, we obtain that when the ratio of the number of sub-6-GHz BSs to that of the mmWave BSs is lower than a given threshold, UE harvests more energy from an mmWave BS than a sub-6-GHz BS. We find how many mmWave small cells are needed to perform better than the sub-6-GHz small cells from the perspectives of harvested energy and throughput. Our results reveal that the amount of harvested energy from the mmWave tier can be comparable to the sub-6-GHz counterpart in the dense scenarios. For the same tier scale, mmWave tier can achieve higher throughput. Furthermore, the throughput gap between different mmWave frequencies increases with the mmWave BS density.","Antenna arrays,
Wireless communication,
Throughput,
Cellular networks,
Energy harvesting,
Radio frequency,
5G mobile communication"
MeTDiff: a Novel Differential RNA Methylation Analysis for MeRIP-Seq Data,"N6-Methyladenosine (m6A) transcriptome methylation is an exciting new research area that just captures the attention of research community. We present in this paper, MeTDiff, a novel computational tool for predicting differential m6A methylation sites from Methylated RNA immunoprecipitation sequencing (MeRIP-Seq) data. Compared with the existing algorithm exomePeak, the advantages of MeTDiff are that it explicitly models the reads variation in data and also devices a more power likelihood ratio test for differential methylation site prediction. Comprehensive evaluation of MeTDiff’s performance using both simulated and real datasets showed that MeTDiff is much more robust and achieved much higher sensitivity and specificity over exomePeak. The R package “MeTDiff” and additional details are available at: https://github.com/compgenomics/MeTDiff",
Year,,
Smart computing mechanism for noise detection and elimination in ECG signal,"The cardiovascular disease is one of the most common causes of death around the world. The analysis of electrocardiograms (ECGs) is an important tool in early diagnosis of arrhythmias. However, sometime the measurement data would be corrupted by noises which may cause by the wrong equipment operation, poor contact of the electrode, or even the breath of the users. These noises would make cardiologists or automatic detection system hard to make a correct diagnosis. Therefore, the noise detection and elimination of ECG data become an important issue. In this study, we proposed a detection and elimination mechanism for the five types of noise. Besides, if the segment does not have any important information and cannot be repaired, we will eliminate it and combine the remaining usable segments into a pure signal for ECG enhancement. The experimental results showed that the noise recognition classifier yielded 0.956 area under the ROC curve, 84.4% accuracy, 97.8% sensitivity, and 80.5% specificity, respectively. The accuracy of disease detection system also could be improved by using the combination of usable segments. Hence, we believed this smart computing mechanism could address ECG enhancement and interpret a contaminated ECG signal more accurately.",
Dynamic Load Balancing Applying Water-Filling Approach in Smart Grid Systems,"To enhance the reliability of the power grid, further processing of the power demand to achieve load balancing is regarded as a critical step in the context of smart grids with Internet of Things technology. In this paper, dynamic offline and online scheduling algorithms are proposed to minimize the power fluctuations by applying a geometric water-filling approach. For the offline approach, full information in the power demand is available, possibly by predicting from the power utilities. We present an exact approach in order to allocate the elastic loads based on the inelastic load's information considering the group-and node-power upper constraints. For the online approach, the reference level is computed dynamically using historical demand data to minimize the fluctuation in the grid, and the elastic loads can only be scheduled in the future time slots. Two dynamic algorithms are investigated to achieve load balancing in the power grid without influencing user experience by real-time reference level adjustment. Facilitated by the proposed methodologies, the power utilities can significantly reduce the cost of improving the power capacity, and the consumers are able to enjoy more stable electrical power.","geometry,
Internet of Things,
load management,
minimisation,
power generation scheduling,
power system reliability,
smart power grids"
A Marked Poisson Process Driven Latent Shape Model for 3D Segmentation of Reflectance Confocal Microscopy Image Stacks of Human Skin,"Segmenting objects of interest from 3D data sets is a common problem encountered in biological data. Small field of view and intrinsic biological variability combined with optically subtle changes of intensity, resolution, and low contrast in images make the task of segmentation difficult, especially for microscopy of unstained living or freshly excised thick tissues. Incorporating shape information in addition to the appearance of the object of interest can often help improve segmentation performance. However, the shapes of objects in tissue can be highly variable and design of a flexible shape model that encompasses these variations is challenging. To address such complex segmentation problems, we propose a unified probabilistic framework that can incorporate the uncertainty associated with complex shapes, variable appearance, and unknown locations. The driving application that inspired the development of this framework is a biologically important segmentation problem: the task of automatically detecting and segmenting the dermal-epidermal junction (DEJ) in 3D reflectance confocal microscopy (RCM) images of human skin. RCM imaging allows noninvasive observation of cellular, nuclear, and morphological detail. The DEJ is an important morphological feature as it is where disorder, disease, and cancer usually start. Detecting the DEJ is challenging, because it is a 2D surface in a 3D volume which has strong but highly variable number of irregularly spaced and variably shaped “peaks and valleys.” In addition, RCM imaging resolution, contrast, and intensity vary with depth. Thus, a prior model needs to incorporate the intrinsic structure while allowing variability in essentially all its parameters. We propose a model which can incorporate objects of interest with complex shapes and variable appearance in an unsupervised setting by utilizing domain knowledge to build appropriate priors of the model. Our novel strategy to model this structure combines a spatial Poisson process with shape priors and performs inference using Gibbs sampling. Experimental results show that the proposed unsupervised model is able to automatically detect the DEJ with physiologically relevant accuracy in the range 10-20 μm.","Skin,
Shape,
Three-dimensional displays,
Image segmentation,
Microscopy,
Solid modeling"
Sociability-Driven Framework for Data Acquisition in Mobile Crowdsensing Over Fog Computing Platforms for Smart Cities,"Smart cities exploit the most advanced information technologies to improve and add value to existing public services. Having citizens involved in the process through mobile crowdsensing (MCS) augments the capabilities of the platform without enquiring additional costs. In this paper, we propose a novel framework for data acquisition in MCS deployed over a fog computing platform which facilitates a number of key operations including user recruitment and task completion. Proper data acquisition minimizes the monetary expenditure the platform sustains to recruit and compensate users as well as the energy they spend to sense and deliver data. We propose a new user recruitment policy called Distance, Sociability, Energy (DSE). This policy exploits three criteria: (i) spatial distance between users and tasks, (ii) user sociability, which is an estimate of the willingness of users to contribute to sensing tasks, and (iii) remaining battery charge of the devices. Performance evaluation is conducted in a real urban environment for a large number of participants with new metrics assessing the efficiency of recruitment and the accuracy of task completion. Results reveal that the average number of recruited users improves by nearly 20 percent if compared to policies using only spatial distance as selection criterion.",
Self-Calibrated Microwave Characterization of High-Speed Optoelectronic Devices by Heterodyne Spectrum Mapping,"A four-in-one electrical method is proposed based on heterodyne spectrum mapping for self-calibrated frequency response measurements of high-speed semiconductor laser diodes, Mach-Zehnder modulators, phase modulators, and photodetectors with a shared self-heterodyne interferometer. The self-heterodyne interferometer provides mapping of the desired optical spectrum components from the optical domain to electrical domain, and allows indirect but self-calibrated measurement of these optical spectra in the electrical domain. Frequency responses including modulation index of semiconductor laser diodes, half-wave voltage and chirp parameter of Mach-Zehnder modulators, half-wave voltage of phase modulators, and responsivity of photodetectors are experimentally extracted with this method, and compared to the results obtained with conventional methods for accuracy.","Optical modulation,
Optical mixing,
Optical variables measurement,
High-speed optical techniques,
Optical interferometry,
Frequency measurement"
Matching Theory for Distributed User Association and Resource Allocation in Cognitive Femtocell Networks,"In this paper, a novel framework is proposed to jointly optimize user association and resource allocation in the uplink cognitive femtocell network (CFN). In the considered CFN, femtocell base stations (FBSs) are deployed to serve a set of femtocell user equipments (FUEs) by reusing subchannels used in a macrocell base station (MBS). The problem of joint user association, subchannel assignment, and power allocation is formulated as an optimization problem, in which the goal is to maximize the overall uplink throughput while guaranteeing FBSs overloading avoidance, data rate requirements of the served FUEs, and MBS protection. To solve this problem, a distributed framework based on the matching game is proposed to model and analyze the interactions between the FUEs and FBSs. Using this framework, distributed algorithms are developed to enable the CFN to make decisions about user association, subchannel allocation, and transmit power. The algorithms are then shown to converge to a stable matching and exhibit a low computational complexity. Simulation results show that the proposed approach yields a performance improvement in terms of the overall network throughput and outage probability, with a small number of iterations to converge.","Resource management,
Uplink,
Interference,
Femtocell networks,
Games,
Power control,
Macrocell networks"
Exploiting Data Reliability and Fuzzy Clustering for Journal Ranking,"Journal impact indicators are widely accepted as possible measurements of academic journal quality. However, much debate has recently surrounded their use, and alternative journal impact evaluation techniques are desirable. Aggregation of multiple indicators offers a promising method to produce a more robust ranking result, avoiding the possible bias caused by the use of a single impact indicator. In this paper, fuzzy aggregation and fuzzy clustering, especially the ordered weighted averaging (OWA) operators are exploited to aggregate the quality scores of academic journals that are obtained from different impact indicators. Also, a novel method for linguistic term-based fuzzy cluster grouping is proposed to rank academic journals. The paper allows for the construction of distinctive fuzzy clusters of academic journals on the basis of their performance with respect to different journal impact indicators, which may be subsequently combined via the use of the OWA operators. Journals are ranked in relation to their memberships in the resulting combined fuzzy clusters. In particular, the nearest-neighbor guided aggregation operators are adopted to characterize the reliability of the indicators, and the fuzzy clustering mechanism is utilized to enhance the interpretability of the underlying ranking procedure. The ranking results of academic journals from six subjects are systematically compared with the outlet ranking used by the Excellence in Research for Australia, demonstrating the significant potential of the proposed approach.","Open wireless architecture,
Measurement,
Robustness,
Pragmatics,
Computers,
Computer science"
QoS-aware Service Selection Using An Incentive Mechanism,"QoS-aware service selection seeks to find the optimal service providers to achieve the optimization goal of a service requester, such as the maximization of utility, while satisfying global QoS requirements. Service providers are usually self-interested and have some private information, such as minimum prices, that would significantly factor into the decision making of the service requester. Thus, service requesters face a decision making dilemma with incomplete information. Recent work has used iterative combinatorial auctions to address this problem. However, such studies do not sufficiently consider that the service requester can elicit the private information from service providers by observing their actions. This can help the service selection process achieve better outcomes. In this paper, we propose a type of incentive contract that can motivate the service providers to offer the QoS and prices that the service requester prefers. Based on the incentive contracts, we propose an incentive mechanism for effective service selection. In the mechanism, a service requester offers a set of incentive contracts to the service providers and then elicits their private information based on their responses to the incentive contracts. The process is iterated until the service requester finally obtains a solution that fulfills the global QoS requirements. Experimental results show that the incentive contracts have a positive impact on both service requesters and providers and that the incentive mechanism outperforms the existing combinatorial auction-based approaches in finding optimal solutions.","Quality of service,
Contracts,
Reliability,
Forecasting,
Decision making,
Unified modeling language,
Data collection"
Multiprocessor approximate message passing with column-wise partitioning,"Solving a large-scale regularized linear inverse problem using multiple processors is important in various real-world applications due to the limitations of individual processors and constraints on data sharing policies. This paper focuses on the setting where the matrix is partitioned column-wise. We extend the algorithmic framework and the theoretical analysis of approximate message passing (AMP), an iterative algorithm for solving linear inverse problems, whose asymptotic dynamics are characterized by state evolution (SE). In particular, we show that column-wise multiprocessor AMP (C-MP-AMP) obeys an SE under the same assumptions when the SE for AMP holds. The SE results imply that (i) the SE of C-MP-AMP converges to a state that is no worse than that of AMP and (ii) the asymptotic dynamics of C-MP-AMP and AMP can be identical. Moreover, for a setting that is not covered by SE, numerical results show that damping can improve the convergence performance of C-MP-AMP.","Program processors,
Inverse problems,
Heuristic algorithms,
Message passing,
Partitioning algorithms,
Schedules,
Standards"
Robustness of First- and Second-Order Consensus Algorithms for a Noisy Scale-Free Small-World Koch Network,"In this brief, we study first- and second-order consensus algorithms for the scale-free small-world Koch network, where vertices are subject to white noise. We focus on three cases of consensus schemes: (1) first-order leaderless algorithm; (2) first-order algorithm with a single leader; and (3) second-order leaderless algorithm. We are concerned with the coherence of the Koch network in the H2 norm, which captures the level of agreement of vertices in face of stochastic disturbances. Based on the particular network construction, we derive explicit expressions of the coherence for all the three consensus algorithms, as well as their dependence on the network size. Particularly, for the first-order leader-follower model, we show that coherence relies on the shortest-path distance between the leader and the largest-degree vertices, as well as the degree of the leader. The asymptotic behaviors for coherence of the three consensus algorithms in Koch network behave differently from those associated with other networks lacking scale-free small-world features, indicating significant influences of the scale-free small-world topology on the performance of the consensus algorithms in noisy environments.","Coherence,
Heuristic algorithms,
Laplace equations,
Eigenvalues and eigenfunctions,
Network topology,
Noise measurement,
Robustness"
Discrete Adjoint Sensitivity Analysis of Hybrid Dynamical Systems With Switching,"Sensitivity analysis is an important tool for describing power system dynamic behavior in response to parameter variations. It is a central component in preventive and corrective control applications. The existing approaches for sensitivity calculations, namely, finite-difference and forward sensitivity analysis, require a computational effort that increases linearly with the number of sensitivity parameters. In this paper, we investigate, implement, and test a discrete adjoint sensitivity approach whose computational effort is effectively independent of the number of sensitivity parameters. The proposed approach is highly efficient for calculating sensitivities of larger systems and is consistent, within machine precision, with the function whose sensitivity we are seeking. This is an essential feature for use in optimization applications. Moreover, our approach includes a consistent treatment of systems with switching, such as dc exciters, by deriving and implementing the adjoint jump conditions that arise from state-dependent and time-dependent switchings. The accuracy and the computational efficiency of the proposed approach are demonstrated in comparison with the forward sensitivity analysis approach. This paper focuses primarily on the power system dynamics, but the approach is general and can be applied to hybrid dynamical systems in a broader range of fields.","Power system stability,
Mathematical model,
Power system dynamics,
Switches,
Sensitivity analysis,
Stability analysis"
Laplacian LRR on Product Grassmann Manifolds for Human Activity Clustering in Multicamera Video Surveillance,"In multicamera video surveillance, it is challenging to represent videos from different cameras properly and fuse them efficiently for specific applications such as human activity recognition and clustering. In this paper, a novel representation for multicamera video data, namely, the product Grassmann manifold (PGM), is proposed to model video sequences as points on the Grassmann manifold and integrate them as a whole in the product manifold form. In addition, with a new geometry metric on the product manifold, the conventional low rank representation (LRR) model is extended onto PGM and the new LRR model can be used for clustering nonlinear data, such as multicamera video data. To evaluate the proposed method, a number of clustering experiments are conducted on several multicamera video data sets of human activity, including the Dongzhimen Transport Hub Crowd action data set, the ACT 42 Human Action data set, and the SKIG action data set. The experiment results show that the proposed method outperforms many state-of-the-art clustering methods.","Manifolds,
Cameras,
Data models,
Clustering methods,
Laplace equations,
Symmetric matrices,
Fuses"
Largest Matching Areas for Illumination and Occlusion Robust Face Recognition,"In this paper, we introduce a novel approach to face recognition which simultaneously tackles three combined challenges: (1) uneven illumination; (2) partial occlusion; and (3) limited training data. The new approach performs lighting normalization, occlusion de-emphasis and finally face recognition, based on finding the largest matching area (LMA) at each point on the face, as opposed to traditional fixed-size local areabased approaches. Robustness is achieved with novel approaches for feature extraction, LMA-based face image comparison and unseen data modeling. On the extended YaleB and AR face databases for face identification, our method using only a single training image per person, outperforms other methods using a single training image, and matches or exceeds methods which require multiple training images. On the labeled faces in the wild face verification database, our method outperforms comparable unsupervised methods. We also show that the new method performs competitively even when the training images are corrupted.","Lighting,
Face,
Face recognition,
Training,
Image recognition,
Testing,
Robustness"
Optimization of Electrical Energy Storage System Sizing for an Accurate Energy Management in an Aircraft,"The development of More Electrical Aircraft has lead to the adaptation of their electrical architecture and their capacity of power generation and storage. Therefore, generation and storage systems must be well sized to match their energetic performances versus the vehicle requirements. This paper deals with the optimal sizing of storage systems (secondary batteries and supercapacitors) for an aircraft. In this particular application, the global weight of the whole storage system must be minimized. An optimal sizing tool has been developed to reach this objective by acting on setting parameters that are the cut-off frequency of the low-pass filter (to share out the mission profile between storage systems according to an energy management based on a frequency approach), the discharge ratio for storage components (in relation with their technological limits and the electrical network specifications), and temperature (which can be seen as an environmental constraint as well). The optimization results, which are obtained with the simulated annealing method implemented in MATLAB, are presented and assessed throughout the whole temperature range. Finally, the impact of setting parameters on the global storage system weight is studied, and an adaptation of the energy management strategy is presented to take into account the temperature influence on battery performances.","Batteries,
Supercapacitors,
Aircraft,
Energy management,
Generators,
Discharges (electric)"
Signal Entanglement based Pinpoint Waveforming for Location-restricted Service Access Control,"We propose a novel wireless technique named pinpoint waveforming to achieve the location-restricted service access control, i.e., providing wireless services to users at eligible locations only. The proposed system is inspired by the fact that when two identical wireless signals arrive at a receiver simultaneously, they will constructively interfere with each other to form a boosted signal whose amplitude is twice of that of an individual signal. As such, the location-restricted service access control can be achieved through transmitting at a weak power, so that receivers at undesired locations (where the constructive interference vanishes), will experience a low signal-to-noise ratio (SNR), and hence a high bit error rate that retards the correct decoding of received messages. At the desired location (where the constructive interference happens), the receiver obtains a boosted SNR that enables the correct message decoding. To solve the difficulty of determining an appropriate transmit power, we propose to entangle the original transmit signals with jamming signals of opposite phase. The jamming signals can significantly reduce the SNR at the undesired receivers but cancel each other at the desired receiver to cause no impact. With the jamming entanglement, the transmit power can be any value specified by the system administrator. To enable the jamming entanglement, we create the channel calibration technique that allows the synchronization of transmit signals at the desired location. We develop a prototype system using the Universal Software Defined Radio Peripherals (USRPs). The evaluation results show that the receiver at the desired location obtains a throughput ranging between 0.9 and 0.93, whereas an eavesdropper that is 0.3 meter away from a desired location has a throughput approximately equal to 0.",
Selective object and context tracking,"Robust appearance model is significantly important to state-of-the-art trackers. However, such trackers highly rely on the reliability of foreground appearance model. When the foreground is seriously occluded or the scene contains multiple objects with similar appearance, such foundation is destroyed. To extend the ability of trackers to handle these difficulties, we propose selective object and context tracking to locate the target according to the reliability of the foreground appearance model which is determined by two measures about whether the target is occluded or surrounded by similar objects. Extensive experiments show that our method achieves better performance than state-of-the-art trackers on VOT TIR-2015 dataset and is able to track the target even when the foreground appearance is completely unreliable.","Context,
Target tracking,
Context modeling,
Reliability,
Correlation,
Computational modeling,
Training"
Model Predictive Direct Slope Control for Power Converters,"Model predictive control (MPC) schemes have become popular in the field of power electronics due to their intuitive formulation, flexibility, and ease of implementation. Typically, these schemes have been implemented with the prediction horizon limited to one time-step, and extension of the prediction horizon over multiple time-steps remains an ongoing area of research. In this paper, a variant of the MPC strategy is proposed wherein the slope of the output trajectories is used to emulate long prediction horizons. Each of the outputs, e.g., current, voltage, torque, or flux, is regulated within a set of symmetrical bounds. When switching is necessitated due to collision with a bound, the switching state that yields the set of output trajectories with the minimum slope, relative to the reference trajectory, is applied to the converter. The key benefit of this approach is its ability to achieve low switching frequencies with a minimal level of computational burden. The feasibility of the scheme, which can be adapted easily to different case studies, is demonstrated through simulations of both a medium-voltage induction machine drive and a grid-connected converter. Experimental results, which are presented for a 1.68 kVA prototype grid-connected neutral-point-clamped converter, further demonstrate the practical viability of the proposed strategy.","Switches,
Torque,
Mathematical model,
Predictive models,
Stators,
Power electronics,
Trajectory"
Bio-Inspired Embedded Vision System for Autonomous Micro-Robots: The LGMD Case,"In this paper, we present a new bio-inspired vision system embedded for micro-robots. The vision system takes inspiration from locusts in detecting fast approaching objects. Neurophysiological research suggested that locusts use a wide-field visual neuron called lobula giant movement detector (LGMD) to respond to imminent collisions. In this paper, we present the implementation of the selected neuron model by a low-cost ARM processor as part of a composite vision module. As the first embedded LGMD vision module fits to a micro-robot, the developed system performs all image acquisition and processing independently. The vision module is placed on top of a micro-robot to initiate obstacle avoidance behavior autonomously. Both simulation and real-world experiments were carried out to test the reliability and robustness of the vision system. The results of the experiments with different scenarios demonstrated the potential of the bio-inspired vision system as a low-cost embedded module for autonomous robots.",
A self-driving robot using deep convolutional neural networks on neuromorphic hardware,"Neuromorphic computing is a promising solution for reducing the size, weight and power of mobile embedded systems. In this paper, we introduce a realization of such a system by creating the first closed-loop battery-powered communication system between an IBM Neurosynaptic System (IBM TrueNorth chip) and an autonomous Android-Based Robotics platform. Using this system, we constructed a dataset of path following behavior by manually driving the Android-Based robot along steep mountain trails and recording video frames from the camera mounted on the robot along with the corresponding motor commands. We used this dataset to train a deep convolutional neural network implemented on the IBM NS1e board containing a TrueNorth chip of 4096 cores. The NS1e, which was mounted on the robot and powered by the robot's battery, resulted in a self-driving robot that could successfully traverse a steep mountain path in real time. To our knowledge, this represents the first time the IBM TrueNorth has been embedded on a mobile platform under closed-loop control.",
Video-Based Human Walking Estimation Using Joint Gait and Pose Manifolds,"We study two fundamental issues about video-based human walking estimation, where the goal is to estimate 3D gait kinematics (i.e., joint positions) from 2D gait appearances (i.e., silhouettes). One is how to model the gait kinematics from different walking styles, and the other is how to represent the gait appearances captured under different views and from individuals of distinct walking styles and body shapes. Our research is conducted in three steps. First, we propose the idea of joint gait-pose manifold (JGPM), which represents gait kinematics by coupling two nonlinear variables, pose (a specific walking stage) and gait (a particular walking style) in a unified latent space. We extend the Gaussian process latent variable model (GPLVM) for JGPM learning, where two heuristic topological priors, a torus and a cylinder, are considered and several JGPMs of different degrees of freedom (DoFs) are introduced for comparative analysis. Second, we develop a validation technique and a series of benchmark tests to evaluate multiple JGPMs and recent GPLVMs in terms of their performance for gait motion modeling. It is shown that the toroidal prior is slightly better than the cylindrical one, and the JGPM of 4 DoFs that balances the toroidal prior with the intrinsic data structure achieves the best performance. Third, a JGPM-based visual gait generative model (JGPM-VGGM) is developed, where JGPM plays a central role to bridge the gap between the gait appearances and the gait kinematics. Our proposed JGPM-VGGM is learned from Carnegie Mellon University MoCap data and tested on the HumanEva-I and HumanEva-II data sets. Our experimental results demonstrate the effectiveness and competitiveness of our algorithms compared with existing algorithms.","Manifolds,
Kinematics,
Visualization,
Legged locomotion,
Data models,
Gaussian processes"
On the Role of Artificial Noise in Training and Data Transmission for Secret Communications,"This paper considers the joint design of training and data transmission in physical-layer secret communications, and examines the role of artificial noise (AN) in both of these phases. In particular, AN in the training phase is used to prevent the eavesdropper from obtaining accurate channel state information (CSI), whereas AN in the data transmission phase can be used to mask the transmission of confidential messages. By considering AN-assisted training and secrecy beamforming, we first derive bounds on the achievable secrecy rate and utilize them to obtain approximate secrecy rate expressions that are asymptotically tight at high SNR. By maximizing these expressions, power allocation policies between signal and AN in both training and data transmission phases are then proposed for conventional and AN-assisted training-based schemes, respectively. We show that the optimal AN power at high SNR should be non-vanishing with respect to the total power, and that AN usage can be more effective in the training phase than in the data transmission phase when the coherence time is large. However, at low SNR, we show that AN cannot be effectively utilized due to the lack of accurate CSI, and thus, one can often do better without. Numerical results are presented to verify our theoretical claims.","Training,
Channel estimation,
Data communication,
Signal to noise ratio,
Array signal processing,
Resource management,
Coherence"
A Graph-Theoretic Characterization of Perfect Attackability for Secure Design of Distributed Control Systems,"This paper considers secure design in distributed control systems to ensure the detection of stealthy integrity attacks. Distributed control systems consist of many heterogeneous components, such as sensors, controllers, and actuators and may contain several independent agents. The presence of many components and agents in a system increases the attack surfaces for potential adversaries, making distributed control systems vulnerable to malicious behavior. The goal of this paper is to consider the design of distributed control systems to ensure the deterministic detection of attacks. To do this, we leverage existing results which relate the deterministic detection of a fixed set of malicious nodes to structural left invertibility. We extend the notion of structural left invertibility to consider attacks from all possible sets of malicious nodes using vertex separators. Vertex separators are then used to solve optimization problems which aim to minimize communication networks while also ensuring that a resource limited adversary cannot generate perfect attacks. Optimal bounds on communication and sensing are obtained and polynomial time design algorithms are provided.","Sensor systems,
Observers,
Decentralized control,
Optimization,
Sensor phenomena and characterization"
Deadlock Analysis of Parameterized-Chain Networks,"In areas such as computer software and hardware, manufacturing systems, and transportation, engineers encounter networks with arbitrarily large numbers of isomorphic subprocesses. Parameterized systems provide a framework for modeling such networks. The analysis of parameterized systems is a challenge as some key properties such as nonblocking and deadlock-freedom are undecidable even for the case of a parameterized system with ring topology. Here, we introduce Parameterized-Chain Networks (PCN) for modeling of systems with more generalized topologies, consisting of a finite number of `distinguished' subprocesses, and a finite number of parameterized linear subnetworks. Since deadlock analysis is undecidable, to achieve a tractable subproblem, we limit the behavior of subprocesses of the network using our previously developed mathematical notion, `weak invariant simulation.' We develop a dependency graph for analysis of PCN and show that partial and total deadlocks of the proposed PCN are characterized by full, consistent subgraphs of the dependency graph. We investigate deadlock in a traffic network as an illustrative example.","System recovery,
Generators,
Automobiles,
Indexes,
Topology,
Mathematical model,
Network topology"
Bounded Auditable Restoration of Distributed Systems,"We focus on protocols for auditable restoration of distributed systems. The need for such protocols arises due to conflicting requirements (e.g., access to the system should be restricted but emergency access should be provided). One can design such systems with a tamper detection approach (based on the intuition of In-case-of-emergency-break-glass). However, in a distributed system, such tampering, which are denoted as auditable events, is visible only for a single node. This is unacceptable since the actions they take in these situations can be different than those in the normal mode. Moreover, eventually, the auditable event needs to be cleared so that system resumes the normal operation. With this motivation, in this paper, we present two protocols for auditable restoration, where any process can potentially identify an auditable event. The first protocol has an unbounded state space while the second protocol uses bounded state space that does not increase with the length of the computation. In both protocols, whenever a new auditable event occurs, the system must reach an auditable state where every process is aware of the auditable event. Only after the system reaches an auditable state, it can begin the operation of restoration. Although any process can observe an auditable event, we require that only authorized processes can begin the task of restoration. Moreover, these processes can begin the restoration only when the system is in an auditable state. Our protocols are self-stabilizing and can effectively handle the case where faults or auditable events occur during the restoration protocol. Moreover, they can be used to provide auditable restoration to other distributed protocols.",
Anti-Jamming Rendezvous Scheme for Cognitive Radio Networks,"In cognitive radio networks (CRNs), channel hopping-based communications are widely used to improve channel utilization. However, channel hopping schemes for CRNs are usually vulnerable to jamming attacks, especially when jammers have cognitive radios to perform channel sensing and fast channel switching. Many mitigating approaches for coping with jamming attacks in wireless communications rely on pre-shared secrets (e.g., pre-shared hopping sequences). In CRNs, pre-sharing secrets between senders and receivers is usually impractical (because neighborhood dynamically changes, and receivers of a broadcast may be unknown to the sender). Hence, anti-jamming channel hopping approaches without pre-shared secrets have gained more and more research interests. However, existing approaches either have unbounded time to rendezvous on an available channel (even no signals of jammers and PUs appear), or require role pre-assignment (SUs should be pre-assigned as a sender or receiver). Role pre-assignment is not applicable to environments where each SU may play a sender and a receiver, simultaneously. In this paper, we propose an antijamming channel hopping scheme, Sec-CH. Sec-CH has bounded time to rendezvous and can work without role pre-assignment.","Jamming,
Receivers,
Sensors,
Cognitive radio,
Resistance,
Measurement,
Mobile computing"
The Derived Equivalent Circuit Model for Magnetized Anisotropic Graphene,"Due to the static magnetic field, the conductivity for graphene becomes a dispersive and anisotropic tensor, which complicates most modeling methodologies. In this communication, a novel equivalent circuit model is proposed for graphene with the magnetostatic bias based on the electric field integral equation. To characterize the anisotropic property of the biased graphene, the resistive part of the unit circuit is replaced by a resistor in series with current-controlled voltage sources (CCVSs). The CCVSs account for the off-diagonal parts of the surface conductivity tensor for the magnetized graphene. This proposed method is benchmarked with numerical examples. This communication also provides a new equivalent circuit model to deal with anisotropic materials.","Graphene,
Conductivity,
Integrated circuit modeling,
Perpendicular magnetic anisotropy,
Equivalent circuits,
Tensile stress"
Joint Gaussian Based Measures for Multiple-Instance Learning,"As an actively investigated topic in machine learning, Multiple-Instance Learning (MIL) has many proposed solutions, including both supervised and unsupervised methods. Most of these solutions are restricted to the original assumption that comes with the notion of MIL: the label of a multipleinstance object is directly determined by the labels of its instances. However, this assumption faces adverse circumstances when there is no clear relation between the over-all label and the labels of instances. Most previous approaches avoid this problem in practice by taking each multiple-instance object as a whole instead of starting with learning in instance spaces, but they either lose information or are time consuming. In this paper, we introduce two joint Gaussian based measures for MIL, Joint Gaussian Similarity (JGS) and Joint Gaussian Distance (JGD), which require no prior knowledge of relations between the labels of multiple-instance objects and their instances. JGS is a measure of similarity while JGD is a metric of which the properties are necessary for many techniques like clustering and embedding. JGS and JGD take all the information into account and many traditional machine learning methods can be introduced to MIL. Extensive experimental evaluations on various real-world data demonstrate the effectiveness of both measures, and better performances than state-of-the-art MIL algorithms on benchmark tasks.","Density measurement,
Clustering algorithms,
Benchmark testing,
Extraterrestrial measurements,
Meteorology,
Computer science"
Improving LDPC performance via asymmetric sensing level placement on flash memory,"Flash memory development through technology scaling and bit density has significant impact on the reliability of flash cells. Hence strong error correction code (ECC) schemes are highly recommended. With a strong error correction capability, low-density-parity code (LDPC) is now applied for the state-of-the-art flash memory. However, LDPC has long decoding latency when the raw bit error rates (RBER) are high. This is because it needs fine-grained soft sensing between states to iteratively decode the raw data. In this work, we propose a smart sensing level placement scheme to reduce the LDPC decoding latency. The basic idea for the placement scheme is motivated by two asymmetric error characteristics of flash memory: the asymmetric errors at different states, and the asymmetric errors caused by voltage left-shifts and right-shifts. With understanding of these two types of error characteristics, the sensing levels are smartly placed to achieve reduced sensing levels while maintaining the error correction capability of LDPC. Experiment analysis shows that the proposed scheme achieves significant performance improvement.",
Online learning control for harmonics reduction based on current controlled voltage source power inverters,"Nonlinear loads in the power distribution system cause non-sinusoidal currents and voltages with harmonic components. Shunt active filters (SAF) with current controlled voltage source inverters (CCVSI) are usually used to obtain balanced and sinusoidal source currents by injecting compensation currents. However, CCVSI with traditional controllers have a limited transient and steady state performance. In this paper, we propose an adaptive dynamic programming (ADP) controller with online learning capability to improve transient response and harmonics. The proposed controller works alongside existing proportional integral (PI) controllers to efficiently track the reference currents in the d - q domain. It can generate adaptive control actions to compensate the PI controller. The proposed system was simulated under different nonlinear (three-phase full wave rectifier) load conditions. The performance of the proposed approach was compared with the traditional approach. We have also included the simulation results without connecting the traditional PI control based power inverter for reference comparison. The online learning based ADP controller not only reduced average total harmonic distortion by 18.41 %, but also outperformed traditional PI controllers during transients.","Harmonic analysis,
Power system harmonics,
Inverters,
Voltage control,
Reactive power,
Current control,
Capacitors"
SEND: A Situation-Aware Emergency Navigation Algorithm with Sensor Networks,"When emergencies happen, navigation services that guide people to exits while keeping them away from emergencies are critical in saving lives. To achieve timely emergency navigation, early and automatic detection of potential dangers, and quick response with safe paths to exits are the core requirements, both of which rely on continuous environment monitoring and reliable data transmission. Wireless sensor networks (WSNs) are a natural choice of the infrastructure to support emergency navigation services, given their relatively easy deployment and affordable costs, and the ability of ubiquitous sensing and communication. Although many efforts have been made to WSN-assisted emergency navigation, almost all existing works neglect to consider the hazard levels of emergencies and the evacuation capabilities of exits. Without considering such aspects, existing navigation approaches may fail to keep people farther away from emergencies of high hazard levels and would probably encounter congestions at exits with lower evacuation capabilities. In this paper, we propose SEND, a situation-aware emergency navigation algorithm, which takes the hazard levels of emergencies and the evacuation capabilities of exits into account and provides the mobile users the safest navigation paths accordingly. We formally model the situation-aware emergency navigation problem and establish a hazard potential field in the network, which is theoretically free of local minima. By guiding users following the descend gradient of the hazard potential field, SEND can thereby achieve guaranteed success of navigation and provide optimal safety. The effectiveness of SEND is validated by both experiments and extensive simulations in 2D and 3D scenarios.","Hazards,
Navigation,
Wireless sensor networks,
Mobile computing,
Mobile communication,
Three-dimensional displays"
Precoder Design for Signal Superposition in MIMO-NOMA Multicell Networks,"The throughput of users with poor channel conditions, such as those at a cell edge, is a bottleneck in wireless systems. A major part of the power budget must be allocated to serve these users in guaranteeing their quality-of-service (QoS) requirements, hampering QoS for other users, and thus compromising the system reliability. In non-orthogonal multiple access (NOMA), the message intended for a user with a poor channel condition is decoded by itself and by another user with a better channel condition. The message intended for the latter is then successively decoded by itself after canceling the interference of the former. The overall information throughput is thus improved by this particular successive decoding and interference cancellation. This paper aims to design linear precoders/beamformers for signal superposition at the base stations of NOMA multiple-input multiple-output multi-cellular systems to maximize the overall sum throughput subject to the users’ QoS requirements, which are imposed independently on the users’ channel conditions. This design problem is formulated as the maximization of a highly nonlinear and nonsmooth function subject to nonconvex constraints, which is very computationally challenging. Path-following algorithms for its solution, which invoke only a simple convex problem of moderate dimension at each iteration, are developed. Generating a sequence of improved points, these algorithms converge at least to a local optimum. Extensive numerical simulations are then provided to demonstrate their merit.","NOMA,
Throughput,
Quality of service,
Interference,
MIMO,
Array signal processing,
Symmetric matrices,
5G mobile communication"
EC-MRPL: An energy-efficient and mobility support routing protocol for Internet of Mobile Things,"Internet of Mobile Things (IoMT) is a new paradigm of the Internet of Things (IoT) where devices such as sensors, robots, unmanned aerial vehicles (UAV) and cars, are inherently mobile. While mobility enables innovative applications and allows new services, it remains a challenging issue as it causes disconnection of nodes and intermittent connectivity, which negatively impact the network performance; namely data loss, large handover delay and application functionality failures. In this paper, we propose a new energy efficient and mobility aware routing protocol named EC-MRPL based on the well-known Routing Protocol for Low power and Lossy Networks (RPL standard). Unlike RPL which is designed for low resources networks with basically static devices, the proposed protocol enables to better conserve the energy and sustain the connectivity of mobile nodes. EC-MRPL integrates an enhanced mobility detection method and a novel point of attachment prediction and replacement strategy aware of the resources constraints. As such, EC-MRPL overcomes and mitigates problems caused by mobility. Obtained simulation results using Cooja/Contiki show that EC-MRPL outperforms both the RPL and the MRPL protocols in terms of handover delay, data loss rate, signaling cost and energy consumption.",
Coupling Analysis for Wires in a Cable Tray Using Circuit Extraction Based on Mixed-Potential Integral Equation Formulation,"The China high-speed trains use cable trays to neatly arrange the cables running through the distributed systems. On one hand, they protect cables against external electromagnetic interference and reduce external radiation from the cables. On the other hand, the cable trays create waveguide structures that affect the coupling among cables inside the cable trays. To simplify coupling analysis for cables going through a cable tray, a lumped circuit model was built using admittance blocks extracted from a mixed-potential integral equation (MPIE) formulation. In the MPIE formulation, either the half-free space or the waveguide dyadic Green's function was used depending on the region where the cables were. A test case was investigated. Results by the proposed circuit model were validated by measurement and full-wave simulation results.","Power cables,
Wires,
Electric potential,
Couplings,
Mathematical model,
Green's function methods,
Transmission line matrix methods"
Direct Modulation of a Laser Using 112-Gb/s 16-QAM Nyquist Subcarrier Modulation,"A 112-Gb/s single-carrier, single-polarization short reach transmission system using a high bandwidth 1310 nm directly modulated laser is demonstrated. Spectrally efficient signal generation is achieved by using: 1) half-cycle Nyquist subcarrier modulation with 16-ary quadrature-amplitude-modulation; 2) pre-compensation for the frequency response of the end-toend system; and 3) and a Volterra nonlinear equalizer to postcompensate for the nonlinear modulation dynamics of the laser. Digital signal processing techniques for signal recovery enable transmission over 20 km of standard single mode fiber with a bit error ratio below the 7% overhead hard-decision forward error correction coding threshold of 4.6 × 10-3 at a received optical power of -5.25 dBm.","Nonlinear distortion,
Bandwidth,
Laser noise,
Nonlinear optics,
Optical modulation"
Green Spectrum Assignment in Secure Cloud Radio Network with Cluster Formation,"As the occurrence of cloud computing, the exponential growth of various application services results in the urgent demand for green computing and resource sustainability on the premise of guaranteeing service performance. Especially, Cloud Radio Access Network (CRAN) has been recognized as a promising approach to provide smart computing and sustainable resource usage for fulfilling the increasing traffic demand. Moreover, the secure network environment is also a vital element for achieving reliable application services. In this paper, we propose a cluster-based secure Cloud Radio Access Network(CSC-RAN), which optimizes the trade-off between performance and resource utilization to satisfy the requirements of the sustainable green network. Based on the powerful ability of cloud computing, the abundant network resource can be dynamically allocated according to the varying traffic. A traffic-aware RRHs cluster formation (TRCF) algorithm is proposed for realizing efficient resource utilization while improving the Quality of Service(QoS). Furthermore, a spectrum allocation genetic algorithm (SAGA) is introduced to solve the optimal spectrum allocation problem for the formatted cluster, which is proved to be a mixed-integer programming problem. Finally, the effectiveness of the TRCF and SAGA algorithms are verified through a series of numerical simulations.",
Workload Factoring and Resource Sharing via Joint Vertical and Horizontal Cloud Federation Networks,"In cloud computing, a private (secondary) cloud can: 1) outsource workload to public (primary) clouds via vertical federation or 2) share resources with other secondary clouds through horizontal federation to enhance its service quality. While there have been attempts to establish a joint vertical and horizontal cloud federation (VHCF), little is known regarding the economic aspects (e.g., what stable cooperation pattern will form, will it improve efficiency) of such a complex cloud network, where secondary clouds are self-interested. To fill the gap, we analyze the interrelated workload factoring and federation formation among secondary clouds, while providing scalable algorithms to assist them to optimally select partners and outsource workload. We use a game theoretic approach to model the federation formation of clouds as a coalition game with externalities. We adopt a pessimistic core to characterize the cooperation stability and formulate its computation as a bilevel optimization problem. The properties of the problem are explored and efficient algorithms are developed to solve it. Experimental results show that the two common practices (no-cooperation and all-in-one federation) are not always stable. The results also show that compared with the two common practices, secondary clouds can decrease service delay penalty by around 11% with the proposed VHCF network.","Cloud computing,
Game theory,
Resource management,
Economics,
Optimization,
Computational modeling,
Delays"
Direct-to-Reverberant Energy Ratio Estimation Using a First-Order Microphone,"The direct-to-reverberant ratio (DRR) is an important characterization of a reverberant environment. This paper presents a novel blind DRR estimation method based on the coherence function between the sound pressure and particle velocity at a point. First, a general expression of coherence function and DRR is derived in the spherical harmonic domain, without imposing assumptions on the reverberation. In this paper, DRR is expressed in terms of the coherence function as well as two parameters that are related to statistical characteristics of the reverberant environment. Then, a method to estimate the values of these two parameters using a microphone system capable of capturing first-order spherical harmonics is proposed, under three assumptions which are more realistic than the diffuse field model. Furthermore, a theoretical analysis on the use of plane wave model for direct path signal and its effect on DRR estimation is presented, and a rule of thumb is provided for determining whether the point source model should be used for the direct path signal. Finally, the ACE challenge dataset is used to validate the proposed DRR estimation method. The results show that the average full band estimation error is within 2 dB, with no clear trend of bias.","Microphones,
Estimation,
Harmonic analysis,
Coherence,
Reverberation,
Speech"
Effects of Temperature and Supply Voltage on SEU- and SET-Induced Errors in Bulk 40-nm Sequential Circuits,"The single-event sensitivity of bulk 40-nm sequential circuits is investigated as a function of temperature and supply voltage. An overall increase in SEU cross section versus temperature is observed at relatively high supply voltages. However, at low supply voltages, there is a threshold temperature beyond which the SEU cross section decreases with further increases in temperature. Single-event transient induced errors in flip-flops also increase versus temperature at relatively high supply voltages and are more sensitive to temperature variation than those caused by single-event upsets.","Temperature sensors,
Flip-flops,
Alpha particles,
Integrated circuits,
Shift registers,
Single event upsets,
Threshold voltage"
The Feasibility of Mobile Physical-Layer Network Coding with BPSK Modulation,"This paper considers applying physical-layer network coding (PNC) to orthogonal frequency division multiplexing (OFDM) modulated mobile ad-hoc networks (MANETs) to resolve the outstanding issue of short contact time between nodes due to their mobility. Ideally, PNC enables data exchange twice as fast as the traditional scheduling, and thus, it is a potential performance booster in MANETs. However, the application of PNC in MANETs is challenged by the carrier frequency offset (CFO) problem inherently caused by node-motion-induced Doppler shifts and asynchronous oscillators. CFO induces intercarrier interference (ICI) that degrades PNC performance. In this paper, we investigate the CFO/ICI impact on the signal-to-interference-and-noise ratio (SINR) and bit error rate (BER) in the signal detection of PNC in a two-way relay channel (TWRC) based on binary phase-shift keying (BPSK) modulation. We find that PNC with power control suffers, at most, a 3 dB SINR penalty compared with generic point-to-point communications in both the flat-fading and the frequency-selective channels. We also find that a belief propagation (BP) algorithm could be employed in the signal detection of PNC to effectively tackle ICI and reduce its impact on the BER of PNC. For CFO compensation in PNC, we propose a method that amounts to positioning the relay's local oscillator frequency at the middle of the received frequencies from the two end nodes in the TWRC. Importantly, we show that 1) this compensation method can theoretically maximize the worst SINR in PNC and that 2) in the case of similar CFO of the two uplinks in TWRC, it allows PNC to achieve a BER at the relay close to that in the ideal case, i.e., in point-to-point communications without CFO. Overall, this paper demonstrates that mobile PNC is feasible in general, laying the foundation for future studies.","Relays,
Ad hoc networks,
OFDM,
Mobile computing,
Interference,
Signal to noise ratio,
Uplink"
Sparse Signal Processing With Linear and Nonlinear Observations: A Unified Shannon-Theoretic Approach,"We derive fundamental sample complexity bounds for recovering sparse and structured signals for linear and nonlinear observation models, including sparse regression, group testing, multivariate regression, and problems with missing features. In general, sparse signal processing problems can be characterized in terms of the following Markovian property. We are given a set of N variables X1,X2,...,XN, and there is an unknown subset of variables S ⊂ {1,...,N} that are relevant for predicting outcomes Y. More specifically, when Y is conditioned on {Xn}n∈S, it is conditionally independent of the other variables, {Xn}n∉S. Our goal is to identify the set S from samples of the variables X and the associated outcomes Y. We characterize this problem as a version of the noisy channel coding problem. Using asymptotic information theoretic analyses, we establish mutual information formulas that provide sufficient and necessary conditions on the number of samples required to successfully recover the salient variables. These mutual information expressions unify conditions for both linear and nonlinear observations. We then compute sample complexity bounds for the aforementioned models, based on the mutual information expressions in order to demonstrate the applicability and flexibility of our results in general sparse signal processing models.","Complexity theory,
Channel coding,
Mutual information,
Computational modeling,
Sparse matrices,
Noise measurement,
Signal processing"
Fall Prediction in Hypertensive Patients via Short-Term HRV Analysis,"Falls are a major problem of later life having severe consequences on quality of life and a significant burden in occidental countries. Many technological solutions have been proposed to assess the risk or to predict falls and the majority is based on accelerometers and gyroscopes. However, very little was done for identifying first time fallers, which are very difficult to recognize. This paper presents a metamodel predicting falls using short term Heart Rate Variability (HRV) analysis acquired at the baseline. About 170 hypertensive patients (age: 72 ± 8 years, 56 female) were investigated, of which 34 fell once in the 3 months after the baseline assessment. This study is focused on hypertensive patients, which were considered as convenient pragmatic sample, as they undergo regular outpatient visits, during which short term Electrocardiogram (ECG) can be easily recorded without significant increase of healthcare costs. For each subject, 11 consecutive excerpts of 5 min each (55 min) were extracted from ECGs recorded between 10:30 and 12:30 and analysed. Linear and nonlinear HRV features were extracted and averaged among the 11 excerpts, which were, then, considered for the statistical and data mining analysis. The best predictive metamodel was based on Multinomial Naïve Bayes, which enabled to predict first-time fallers with sensitivity, specificity, and accuracy rates of 72%, 61%, and 68%, respectively.","Heart rate variability,
Electrocardiography,
Monitoring,
Feature extraction,
Standards,
Hypertension,
Sensors"
Exploring Parallel Data Access Methods in Emerging Non-Volatile Memory Systems,"The exploitation of internal parallelism over hundreds of NAND flash memories is becoming a key design issue in highspeed solid state disks (SSDs). In this study, we simulate a cycle-accurate SSD platform with diverse parallel data access methods and 24 page allocation strategies, which are geared toward exploiting both system-level parallelism and flash-level parallelism, using a variety of design parameters. Our extensive experimental analysis reveals that 1) the previously proposed channel striping-based page allocation strategy is not the best from a performance perspective, 2) as opposed to the common belief that system-level and flash-level concurrency mechanisms are largely orthogonal, the system-level parallel data access methods employed interferes with flash-level parallelism, 3) when most of the current currency controls and page allocation strategies are implemented, the SSD internal resources are significantly underutilized, and 4) while the performance of all the page allocation strategies on read-intensive workloads (reads > 99 percent) is improved by employing a high frequency flash interface, the performance enhancements are significantly limited. Finally, we present several optimization points to extract the maximum internal parallelism by offering comprehensive evaluations with controllable and easy-to-understand micro-benchmarks.","Resource management,
Pipeline processing,
Registers,
Solids,
Radio spectrum management,
Distributed databases"
Giant Magnetoresistive Biosensor Array for Detecting Magnetorelaxation,"In this paper, a time-domain magnetorelaxometry biosensing scheme is presented using giant magnetoresistive (GMR) sensors to measure the fast relaxation response of superparamagnetic magnetic nanoparticles (MNPs) in a pulsed magnetic field. The system consists of an 8 × 10 GMR sensor array, a Helmholtz coil, an electromagnet driver, and an integrator-based analog front-end needed to capture the fast relaxation dynamics of MNPs. A custom designed electromagnet driver and Helmholtz coil improve the switch-off speed to >5 Oe/μs, limiting the dead zone time to <;10 μs, and thus enables the system to monitor fast relaxation processes of 30 nm MNPs. A magnetic correlated double sampling technique is proposed to reduce sensor-to-sensor variation by 99.98% while also reducing temperature drift, circuit offset, and nonlinearity below the noise level. An optimum integration time is calculated and experimentally verified to maximize the SNR. Experiments with dried MNPs have shown successful relaxation detection, and immunoassay experiments have demonstrated their binding kinetics.","Magnetic sensors,
Magnetic resonance,
Biosensors,
Switches,
Magnetic circuits,
Temperature sensors"
Bag of Events: An Efficient Probability-Based Feature Extraction Method for AER Image Sensors,"Address event representation (AER) image sensors represent the visual information as a sequence of events that denotes the luminance changes of the scene. In this paper, we introduce a feature extraction method for AER image sensors based on the probability theory, namely, bag of events (BOE). The proposed approach represents each object as the joint probability distribution of the concurrent events, and each event corresponds to a unique activated pixel of the AER sensor. The advantages of BOE include: 1) it is a statistical learning method and has a good interpretability in mathematics; 2) BOE can significantly reduce the effort to tune parameters for different data sets, because it only has one hyperparameter and is robust to the value of the parameter; 3) BOE is an online learning algorithm, which does not require the training data to be collected in advance; 4) BOE can achieve competitive results in real time for feature extraction (>275 frames/s and >120000 events/s); and 5) the implementation complexity of BOE only involves some basic operations, e.g., addition and multiplication. This guarantees the hardware friendliness of our method. The experimental results on three popular AER databases (i.e., MNIST-dynamic vision sensor, Poker Card, and Posture) show that our method is remarkably faster than two recently proposed AER categorization systems while preserving a good classification accuracy.","Feature extraction,
Voltage control,
Neurons,
Hardware,
Training data,
Cameras,
Image sensors"
Crowd Foraging: A QoS-Oriented Self-Organized Mobile Crowdsourcing Framework Over Opportunistic Networks,"Recent years have witnessed the proliferation of mobile crowdsourcing that brings a new opportunity to leverage human intelligence and movement behaviors to wider application areas. In parallel with the development of online centralized platforms, we look into the realization of self-organized mobile crowdsourcing drawing on opportunistic networks, and propose the Crowd Foraging framework, in which a mobile task requester can proactively recruit a massive crowd of opportunistic encountered mobile workers in real time for quick and high-quality results. We present a comprehensive framework model that fully integrates human behavior factors for modeling task profile, worker arrival, and work ability, and then introduce a service quality concept to indicate the expected service gain that a requester can enjoy when she recruits an arrival worker by jointly considering the work ability of workers as well as timeliness and reward of tasks. Furthermore, we formulate a sequential worker recruitment problem as an online multiple stopping problem to maximize the expected sum of service quality, and accordingly derive an optimal worker recruitment policy through the dynamic programming principle, which exhibits a nice threshold-based structure. We provide data-driven case studies to validate the assumptions used in the policy design, and conduct extensive trace-driven numerical evaluations, which demonstrate that our policy can achieve superior performance (e.g., improve more than 30% performance over classic policies). Besides, our Android prototype shows that the Crowd Foraging framework is cost-efficient, such as requiring less than 7 s and 6 J in terms of time and energy consumption for the optimal threshold calculation in our policy in most cases.","Mobile communication,
Crowdsourcing,
Recruitment,
Mobile computing,
Quality of service,
Device-to-device communication,
Sensors"
A Joint Network Coding and Device Association Design for Optimal Local Data Exchange in Fiber-Wireless Access Network,"For many emerging mobile broadband services and applications, the source and destination are located in the same local region. Consequently, it is very important to design access networks to facilitate efficient local data exchange. In the past few years, most existing studies focus on either the wired or wireless domains. In this paper, we aim to exploit both the wired and wireless domains. Specifically, we consider a fiber-wireless access network in which a passive optical network (PON), consisting of one optical line terminal and multiple optical network units (ONUs), connects densely deployed base stations. In such a scenario, we propose two novel access schemes to utilize both network coding and device association in the following two cases: each device can be associated with one ONU for uploading and downloading its data packets; and each device can be associated with two different ONUs for uploading and downloading its data packets, which are referred to as, the network coding design and symmetric device association (NCsDA) problem and the network coding design and asymmetric device association (NCaDA) problem, respectively. To understand the potentials of NCsDA, we first formulate a mixed integer nonlinear programming to minimize the weighted number of packet transmissions (WNT), which is related to both the energy consumption and system capacity. We then theoretically analyze the tight upper bounds of the minimal WNT in the PON, which helps us to approximate the NCsDA problem by mixed integer linear programming. We also give theoretical analysis on the NCaDA problem and formulate it as a mixed integer linear programming. Next, we develop efficient algorithms based on linear programming relaxation and give network coding designs to solve the NCsDA problem and the NCaDA problem. To validate our design, we conduct extensive simulations, which demonstrate the impact of important network parameters and the promising potentials of the proposed NCsDA and NCaDA schemes.",
Semantics-Enhanced Online Intellectual Capital Mining Service for Enterprise Customer Centers,"One of the greatest challenges of an enterprise's service center is to ensure that their engineers and customers are provided with the right information in a timely fashion. For this purpose, modern organizations operate a wide range of information support systems to assist customers with critical service requests and to provide proactive monitoring, where possible, to prevent service requests from occurring in the first place. It is often the case that relevant information is scattered over the Internet and/or maintained on disparate systems, buried in large amount of noisy data, and in heterogeneous formats, thereby complicating the access to reusable knowledge and extending the response time to reach a resolution. To address these challenges, in this paper we propose an effective knowledge mining solution to improve the quality of service request resolution. We model the service resolution problem as an online search and classification problem, and use domain knowledge in the form of ontology to guide effective machine learning. Our proposed solution has been extensively evaluated with experiments and has been used in a real enterprise customer center.",
Delay Mitigation in Offloaded Cloud Controllers in Industrial IoT,"This paper investigates the interplay of cloud computing, fog computing, and Internet of Things (IoT) in control applications targeting the automation industry. In this context, a prototype is developed to explore the use of IoT devices that communicate with a cloud-based controller, i.e., the controller is offloaded to cloud or fog. Several experiments are performed to investigate the consequences of having a cloud server between the end device and the controller. The experiments are performed while considering arbitrary jitter and delays, i.e., they can be smaller than, equal to, or greater than the sampling period. This paper also applies mitigation mechanisms to deal with the delays and jitter that are caused by the networks when the controller is offloaded to the fog or cloud.",
Learning a Coupled Linearized Method in Online Setting,"Based on the alternating direction method of multipliers, in this paper, we propose, analyze, and test a coupled linearized method, which aims to minimize an unconstrained problem consisting of a loss term and a regularization term in an online setting. To solve this problem, we first transform it into an equivalent constrained minimization problem with a separable structure. Then, we split the corresponding augmented Lagrangian function and minimize the resulting subproblems distributedly with one variable by fixing another one. This method is easy to execute without calculating matrix inversion by implementing three linearized operations per iteration, and at each iteration, we can obtain a closed-form solution. In particular, our update rule contains the well-known softthresholding operator as a special case. Moreover, upper bound on the regret of the proposed method is analyzed. Under some mild conditions, it can achieve O(1/√T) convergence rate for convex learning problems and O((logT)/T) for strongly convex learning. Numerical experiments and comparisons with several state-of-the-art methods are reported, which demonstrate the efficiency and effectiveness of our approach.","Optimization,
Convergence,
Minimization,
Convex functions,
Machine learning algorithms,
Learning systems,
Lagrangian functions"
FALCON: Feature Driven Selective Classification for Energy-Efficient Image Recognition,"Machine-learning algorithms have shown outstanding image recognition/classification performance for computer vision applications. However, the compute and energy requirement for implementing such classifier models for large-scale problems is quite high. In this paper, we propose feature driven selective classification (FALCON) inspired by the biological visual attention mechanism in the brain to optimize the energy-efficiency of machine-learning classifiers. We use the consensus in the characteristic features (color/texture) across images in a dataset to decompose the original classification problem and construct a tree of classifiers (nodes) with a generic-to-specific transition in the classification hierarchy. The initial nodes of the tree separate the instances based on feature information and selectively enable the latter nodes to perform object specific classification. The proposed methodology allows selective activation of only those branches and nodes of the classification tree that are relevant to the input while keeping the remaining nodes idle. Additionally, we propose a programmable and scalable neuromorphic engine (NeuE) that utilizes arrays of specialized neural computational elements to execute the FALCON-based classifier models for diverse datasets. The structure of FALCON facilitates the reuse of nodes while scaling up from small classification problems to larger ones thus allowing us to construct classifier implementations that are significantly more efficient. We evaluate our approach for a 12-object classification task on the Caltech101 dataset and ten-object task on CIFAR-10 dataset by constructing FALCON models on the NeuE platform in 45-nm technology. Our results demonstrate up to 3.66× improvement in energy-efficiency for no loss in output quality, and even higher improvements of up to 5.91× with 3.9% accuracy loss compared to an optimized baseline network. In addition, FALCON shows an improvement in training time of up to 1.96× as compared to the traditional classification approach.","Neuromorphics,
Computational modeling,
Training data,
Visualization,
Energy efficiency,
Image color analysis,
Machine learning,
Neuromorphic engineering"
Ad-hoc Cloudlet Based Cooperative Cloud Gaming,"As the game industry matures, processing complex game logics in a timely manner is no longer an insurmountable problem. However, current cloud-based mobile gaming solutions are limited by their relatively high requirements on Internet resources. Also, they typically do not consider the geographical locations of nearby mobile users and thus ignore the potential cooperation among them. Therefore, inspired by existing cloud computing techniques, we propose an ad hoc mobilecloudlet- cloud based approach to implement cooperative gaming architecture. In this paper, two modules of the architecture are introduced: 1) progressive game resources download, by which mobile users can adaptively download gaming resources from cloud servers or nearby mobile users, 2) ad-hoc mobile based cooperative task allocation, by which gaming components can be executed dynamically on local devices, nearby devices, stationary cloudlet(s), or cloud servers. The mechanisms of both modules are formulated as optimization problems and algorithms are proposed to solve them. Simulations results based on real mobility traces show that our system’s performance depends highly on the ad-hoc network environment. Our scheme has lower system resource usage while utilizing resources of nearby devices, compared to the cloud-based gaming architecture; and performs better with short on-device task duration compared to code-offloading based architecture.","Cloud computing,
Games,
Mobile communication,
Ad hoc networks,
Computer architecture,
Mobile handsets,
Resource management"
Understanding Co-Running Behaviors on Integrated CPU/GPU Architectures,"Architecture designers tend to integrate both CPUs and GPUs on the same chip to deliver energy-efficient designs. It is still an open problem to effectively leverage the advantages of both CPUs and GPUs on integrated architectures. In this work, we port 42 programs in Rodinia, Parboil, and Polybench benchmark suites and analyze the co-running behaviors of these programs on both AMD and Intel integrated architectures. We find that co-running performance is not always better than running the program only with CPUs or GPUs. Among these programs, only eight programs can benefit from the co-running, while 24 programs only using GPUs and seven programs only using CPUs achieve the best performance. The remaining three programs show little performance preference for different devices. Through extensive workload characterization analysis, we find that architecture differences between CPUs and GPUs and limited shared memory bandwidth are two main factors affecting current co-running performance. Since not all the programs can benefit from integrated architectures, we build an automatic decision-tree-based model to help application developers predict the co-running performance for a given CPU-only or GPU-only program. Results show that our model correctly predicts 14 programs out of 15 for evaluated programs. For a co-run friendly program, we further propose a profiling-based method to predict the optimal workload partition ratio between CPUs and GPUs. Results show that our model can achieve 87.7 percent of the optimal performance relative to the best partition. The co-running programs acquired with our method outperform the original CPU-only and GPU-only programs by 34.5 and 20.9 percent respectively.","Computer architecture,
Performance evaluation,
Graphics processing units,
Predictive models,
Bandwidth,
Kernel,
Ports (Computers)"
Quality of Sensing Aware Budget Feasible Mechanism for Mobile Crowdsensing,"In a mobile crowdsensing system, the platform utilizes ubiquitous smartphones to perform sensing tasks. For a successful mobile crowdsensing application, the consideration of the heterogeneity of quality of sensing from different users as well as a proper incentive mechanism to motivate users to contribute to the system are essential. In this paper, we introduce the quality of sensing into incentive mechanism design. Under a budget constraint, the platform aims to maximize the valuation of the performed tasks, which depends on the quality of sensing of the users. We propose ABSee, an auction-based budget feasible mechanism, which consists of a winner selection rule and a payment determination rule. ABSee is designed by adopting a greedy approach. We obtain the approximation ratio of ABSee, which significantly improves the approximation ratio of the existing budget feasible mechanisms in many cases. We further show that the approximation ratio approaches 2e/e-1 when a large number of smartphone users participate in the system. ABSee also satisfies the properties of computational efficiency, truthfulness, individual rationality, and budget feasibility. Extensive simulation results show that ABSee provides a higher valuation to the platform when compared with existing budget feasible mechanisms in the literature.",
Analysis of data pre-processing influence on intrusion detection using NSL-KDD dataset,"Data pre-processing for machine learning methods is key step for knowledge discovery process. Depending on nature of the data, pre-processing might take the majority time of data analysis. Correctly prepared data for processing guarantees precise and reliable results of data analysis. This paper analyses initial data pre-processing influence to attack detection accuracy by using Decision Trees, Naïve Bayes and Rule-Based classifiers with NSL-KDD dataset. In addition, the results of detected attacks accuracy dependency by selecting different attacks grouping options and using ensembles of various classifiers are presented.","Testing,
Data models,
Training,
Predictive models,
Load modeling,
Distributed databases,
Intrusion detection"
Collaborative Recommendation with Multiclass Preference Context,"Factorization- and neighborhood-based methods have been recognized as state-of-the-art approaches for collaborative recommendation tasks. In this article, the authors take user ratings as categorical multiclass preferences and propose a novel method called matrix factorization with multiclass preference context (MF-MPC), which integrates an enhanced neighborhood based on the assumption that users with similar past multiclass preferences (instead of one-class preferences in SVD++) will have similar tastes in the future. The main merit of MF-MPC is its ability to make use of the multiclass preference context in the factorization framework in a fine-grained manner and thus inherit the advantages of those two methods. Experimental results on three real-world datasets show that their solution can perform significantly better than factorization-based methods, neighborhood-based methods, and integrated methods with a one-class preference context.","Mathematical model,
Context modeling,
Predictive models,
Collaboration,
Training data,
Data models,
Prediction algorithms"
Sensitivity Characterization of a COTS 90-nm SRAM at Ultralow Bias Voltage,"This paper presents the characterization of the sensitivity to 14-MeV neutrons of a commercial off-the-shelf 90-nm static random access memories manufactured by Cypress Semiconductor, when biased at ultralow voltage. First, experiments exposing this memory at 14-MeV neutrons, when powering it up at bias voltages ranging from 0.5 to 3.3 V, are presented and discussed. These results are in good concordance with theoretical predictions issued by the modeling tool MUlti-SCAles Single Event Phenomena Predictive Platform. Then, this tool has been used to obtain soft error rate predictions at different altitudes above the Earth's surface of this device versus its bias voltage. Finally, the effect of contamination by α particles has also been estimated at said range of bias voltages.",
Inter-Operator Resource Management for Millimeter Wave Multi-Hop Backhaul Networks,"In this paper, a novel framework is proposed for optimizing the operation and performance of a large-scale multi-hop millimeter wave (mmW) backhaul within a wireless small cell network having multiple mobile network operators (MNOs). The proposed framework enables the small base stations to jointly decide on forming the multi-hop, mmW links over backhaul infrastructure that belongs to multiple, independent MNOs, while properly allocating resources across those links. In this regard, the problem is addressed using a novel framework based on matching theory composed of two, highly inter-related stages: a multi-hop network formation stage and a resource management stage. One unique feature of this framework is that it jointly accounts for both wireless channel characteristics and economic factors during both network formation and resource management. The multi-hop network formation stage is formulated as a one-to-many matching game, which is solved using a novel algorithm, that builds on the so-called deferred acceptance algorithm and is shown to yield a stable and Pareto optimal multi-hop mmW backhaul network. Then, a one-to-many matching game is formulated to enable proper resource allocation across the formed multi-hop network. This game is then shown to exhibit peer effects and, as such, a novel algorithm is developed to find a stable and optimal resource management solution that can properly cope with these peer effects. Simulation results show that, with manageable complexity, the proposed framework yields substantial gains, in terms of the average sum rate, reaching up to 27% and 54%, respectively, compared with a non-cooperative scheme in which inter-operator sharing is not allowed and a random allocation approach. The results also show that our framework improves the statistics of the backhaul sum rate and provides insights on how to manage pricing and the cost of the cooperative mmW backhaul network for the MNOs.","Resource management,
Wireless communication,
Spread spectrum communication,
Games,
Base stations,
Economics,
Electronic mail"
Non-Linear Matrix Completion for Social Image Tagging,"In this paper, we address the problem of social image tagging using practical vocabulary for mobile users on the social media. On the social media, images usually have an incomplete or noisy set of social tags provided by the mobile users, and we consider this issue as defective tag assignments. Previous studies on social image tagging have mostly focused on multi-label classification without considering the defective tags. In these studies, the usage of multi-label classification techniques is expected to synergically exploit the linear relations between the image features and the semantic tags. However, these approaches usually aimed to capture the linear relations from the training data while ignoring the helpful information from the test data. In addition, they failed to incorporate the non-linear associations residing in the visual features as well as in the semantic tags. To overcome these drawbacks, we introduce a novel approach based on non-linear matrix completion for image tagging task with defective tags. Specifically, we first construct the entire feature-tag matrix based on the visual features with non-linear kernel mapping. Then, we present a formal methodology together with an optimization method under the matrix completion framework to jointly complete the tags of training and test images. Experimental evaluations demonstrate that our method shows promising results on image tagging task on two benchmark social image datasets with defective tags, and establishes a baseline for such models in this research domain.","Training,
Tagging,
Visualization,
Sparse matrices,
Noise measurement,
Social network services,
Semantics"
Leave-one-out Kernel Optimization for Shadow Detection and Removal,"The objective of this work is to detect shadows in images. We pose this as the problem of labeling image regions, where each region corresponds to a group of superpixels. To predict the label of each region, we train a kernel Least-Squares Support Vector Machine(LSSVM) for separating shadow and non-shadow regions. The parameters of the kernel and the classifier are jointly learned to minimize the leave-one-out cross validation error. Optimizing the leave-one-out cross validation error is typically difficult, but it can be done efficiently in our framework. Experiments on two challenging shadow datasets, UCF and UIUC, show that our region classifier outperforms more complex methods. We further enhance the performance of the region classifier by embedding it in a Markov Random Field(MRF) framework and adding pairwise contextual cues. This leads to a method that outperforms the state-of-the-art for shadow detection. In addition we propose a new method for shadow removal based on region relighting. For each shadow region we use a trained classifier to identify a neighboring lit region of the same material. Given a pair of lit-shadow regions we perform a region relighting transformation based on histogram matching of luminance values between the shadow region and the lit region. Once a shadow is detected, we demonstrate that our shadow removal approach produces results that outperform the state of the art by evaluating our method using a publicly available benchmark dataset.","Kernel,
Support vector machines,
Lighting,
Training,
Training data,
Optimization,
Labeling"
Hole Filling Method for Depth Image Based Rendering Based on Boundary Decision,"In three-dimensional display systems, depth image based rendering is the most commonly used technique for generating images captured from a virtual viewpoint through reference views and depth maps. However, disoccluded hole filling remain a challenging issue as newly exposed area appears in the virtual view. Image inpainting based hole filling is a popular approach for filling in the hole, but the conventional methods generate annoying artifacts along the boundaries of the foreground objects. This letter presents a robust hole filling method that generates a virtual view with high quality. First, by using the local and neighboring property of the depth map, the background region is filled prior to the foreground region. Also, in the matching step to find the data to fill in, depth homogeneity is considered. Finally, based on the boundary decision using the depth property, the boundary regions are filled with background-relevant data to reduce boundary artifacts. Experimental results show that the views synthesized by the proposed method achieve higher visual comfort than the view synthesized by the existing methods.","Three-dimensional displays,
Rendering (computer graphics),
Cameras,
Color,
Electronic mail,
Visualization,
Filling"
Energy harvesting in secret key generation systems under jamming attacks,"Secret key generation (SKG) from shared randomness at two remote locations has been shown to be vulnerable to denial of service attacks in the form of jamming. Typically, such attacks are alleviated with frequency hopping/spreading techniques that rely on expansion of the system bandwidth. In the present study, energy harvesting (EH) is exploited as a novel counter-jamming approach that alleviates the need for extra bandwidth resources. Assuming the legitimate users have EH capabilities, the idea is that part of the jamming signal can potentially be harvested and converted into useful communication power. In this framework, the competitive interaction between a pair of legitimate users and a jammer is formulated as a zero-sum game. A critical transmission power for the legitimate users is identified which allows to completely characterize the unique NE of the game in closed form. Remarkably, this threshold also provides the option to effectively neutralize the jammer, i.e., prevent the jammer from carrying out the attack altogether. Through numerical evaluations, EH is shown to be a counter-jamming approach that can offer substantial gains in terms of relative SKG rates.","Jamming,
Games,
Fading channels,
Game theory,
Energy harvesting,
Wireless communication"
Full-Duplex-Based Rate/Mode Adaptation Strategies for Wi-Fi/LTE-U Coexistence: A POMDP Approach,"The rapid increase in wireless demand prompted the FCC to open up parts of the 5-GHz band for unlicensed access. This caught the interest of 4G/LTE providers, who wish to extend their LTE-A services to the unlicensed spectrum (LTE-U). In LTE-U, small-cell base stations aggregate unlicensed and licensed bands to increase the throughput. Wi-Fi/LTE-U coexistence is a challenging issue due to the different access mechanisms of these two systems, which may cause high collision rates and delays. By leveraging self-interference-suppression techniques, we propose joint mode/rate adaptation strategies for Wi-Fi/LTE-U coexistence. Specifically, a full-duplex enabled Wi-Fi station can transmit and receive data simultaneously to increase the throughput, or transmit and sense (TS mode) simultaneously to monitor the LTE-U activity. We model the LTE-U interference as a hidden Markov process, and solve the problem of jointly adapting Wi-Fi rates/modes using a framework of partially observable Markov decision process. A detection approach based on the sliding window correlator is analyzed for the TS mode, which can differentiate between Wi-Fi and LTE-U signals. Our results indicate that our scheme provides 1.5x (1.9x) average throughput gain for Wi-Fi system in the low (high) signal-to-interference-and-noise regime relative to a half-duplex-based scheme.","IEEE 802.11 Standard,
Interference,
OFDM,
Hidden Markov models,
Signal to noise ratio,
Silicon,
Throughput"
Diversified Visual Attention Networks for Fine-Grained Object Classification,"Fine-grained object classification attracts increasing attention in multimedia applications. However, it is a quite challenging problem due to the subtle interclass difference and large intraclass variation. Recently, visual attention models have been applied to automatically localize the discriminative regions of an image for better capturing critical difference, which have demonstrated promising performance. Unfortunately, without consideration of the diversity in attention process, most of existing attention models perform poorly in classifying fine-grained objects. In this paper, we propose a diversified visual attention network (DVAN) to address the problem of fine-grained object classification, which substantially relieves the dependency on strongly supervised information for learning to localize discriminative regions compared with attention-less models. More importantly, DVAN explicitly pursues the diversity of attention and is able to gather discriminative information to the maximal extent. Multiple attention canvases are generated to extract convolutional features for attention. An LSTM recurrent unit is employed to learn the attentiveness and discrimination of attention canvases. The proposed DVAN has the ability to attend the object from coarse to fine granularity, and a dynamic internal representation for classification is built up by incrementally combining the information from different locations and scales of the image. Extensive experiments conducted on CUB-2011, Stanford Dogs, and Stanford Cars datasets have demonstrated that the pro-posed DVAN achieves competitive performance compared to the state-of-the-art approaches, without using any prior knowledge, user interaction, or external resource in training and testing.",
Towards Trustworthy Multi-Cloud Services Communities: A Trust-based Hedonic Coalitional Game,"The prominence of cloud computing led to unprecedented proliferation in the number of Web services deployed in cloud data centers. In parallel, service communities have gained recently increasing interest due to their ability to facilitate discovery, composition, and resource scaling in large-scale services’ markets. The problem is that traditional community formation models may work well when all services reside in a single cloud but cannot support a multi-cloud environment. Particularly, these models overlook having malicious services that misbehave to illegally maximize their benefits and that arises from grouping together services owned by different providers. Besides, they rely on a centralized architecture whereby a central entity regulates the community formation; which contradicts with the distributed nature of cloud-based services. In this paper, we propose a three-fold solution that includes: trust establishment framework that is resilient to collusion attacks that occur to mislead trust results; bootstrapping mechanism that capitalizes on the endorsement concept in online social networks to assign initial trust values; and trust-based hedonic coalitional game that enables services to distributively form trustworthy multi-cloud communities. Experiments conducted on a real-life dataset demonstrate that our model minimizes the number of malicious services compared to three state-of-the-art cloud federations and service communities models.","Cloud computing,
Games,
Computer architecture,
Computational modeling,
Social network services,
Google"
Using Linear Spectral Unmixing for Subpixel Mapping of Hyperspectral Imagery: A Quantitative Assessment,"Subpixel mapping techniques have been widely utilized to determine the spatial distribution of the different land-cover classes in mixed pixels at a subpixel scale by converting low-resolution fractional abundance maps (estimated by a linear mixture model) into a finer classification map. Over the past decades, many subpixel mapping algorithms have been proposed to tackle this problem. It has been obvious that the utilized abundance map has a strong impact on the subsequent subpixel mapping procedure. However, limited attention has been given to the impact of the different aspects in the spectral unmixing model on the subpixel mapping performance. In this paper, a detailed quantitative assessment of different aspects in linear spectral mixture analysis, such as the criteria used to determine the types of pixels, the abundance sum-to-one constraint in the unmixing, and the accuracy of the utilized abundance maps, is investigated. This is accomplished by designing an experimental procedure with replaceable components. A total of six hyperspectral images (four synthetic and two real) were utilized in our experiments. By investigating these critical issues, we can further improve the performance of subpixel mapping techniques.","Hyperspectral imaging,
Earth,
Support vector machines,
Graphical models,
Distribution functions"
Palette-Based Image Recoloring Using Color Decomposition Optimization,"Previous works on palette-based color manipulation typically fail to produce visually pleasing results with vivid color and natural appearance. In this paper, we present an approach to edit colors of an image by adjusting a compact color palette. Different from existing methods that fail to preserve inherent color characteristics residing in the source image, we propose a color decomposition optimization for flexible recoloring while retaining these characteristics. For an input image, we first employ a variant of the k -means algorithm to create a palette consisting of a small set of most representative colors. Next, we propose a color decomposition optimization to decompose colors of the entire image into linear combinations of basis colors in the palette. The captured linear relationships then allow us to recolor the image by recombining the coding coefficients with a user-modified palette. Qualitative comparisons with existing methods show that our approach can more effectively recolor images. Further user study quantitatively demonstrates that our method is a good candidate for color manipulation tasks. In addition, we showcase some applications enabled by our method, including pattern colorings suggesting, color transfer, tissue staining analysis and color image segmentation.","Image color analysis,
Optimization,
Histograms,
Image coding,
Color,
Image segmentation,
Electronic mail"
Checkerboard Plasma Electromagnetic Surface for Wideband and Wide-Angle Bistatic Radar Cross Section Reduction,"Bistatic radar cross section (RCS) of a metal plate is reduced by an improved checkerboard surface cover. Plasma and metallic frequency selective surfaces are studied analytically to achieve a proper reflection phase interval. More than 140° phase of the reflected wave is obtained as a promising method to reduce the returned wave in the way of incident wave or any other directions. Hence, a checkerboard surface is designed using the concrete numerical and analytical solutions for backscattering cancellation. Monostatic and bistatic cross sections of metal screens are reduced with the designed plasma electromagnetic surface coat. The amount of bistatic (RCS) is analyzed with a valuable equation. Wide frequency band, vast incident wave angles, and different wave polarizations are achieved for the bistatic analysis. Incorporation of plasma dielectric with metal surface, reconfigurable design, and analysis of the bistatic backscattering of the structure are the promising achievements.","Plasmas,
Frequency selective surfaces,
Metals,
Surface waves,
Dielectrics,
Glass,
Electromagnetics"
Long-Term Ship Speed Prediction for Intelligent Traffic Signaling,"Yangtze River is probably the world's busiest inland waterway. Ships need to be guided when passing through a controlled waterway based on their long-term speed prediction. Inaccurate ship speed prediction leads to nonoptimal traffic signaling, which may cause a significant traffic jam. For the existing intelligent traffic signaling system, the ship speed is assumed to be constant, which has caused many problems and issues. This paper proposes a novel algorithm to construct an improved multilayer perceptron (MLP) network for accurate long-term ship speed prediction, in which the hidden neurons of the MLP are optimized by the particle swarm optimization method. The effectiveness and efficiency of the method are guaranteed by using the orthogonal least squares method, which is the fast approach for the construction of the MLP network in a stepwise forward procedure. The model is driven by easily acquired dynamic data of the ships, including the speed and the position. The effectiveness of the proposed method is further confirmed by comparing with several traditional modeling techniques. To the best of our knowledge, this is the first time that a ship speed model is built for long-term prediction. The experimental results show that the developed model is in good agreement with the real-life data, with more than 97% accuracy. It will help to generate the optimal traffic commands for Yangtze River in an intelligent traffic signaling system.","Marine vehicles,
Rivers,
Neurons,
Communication system signaling,
Predictive models,
Trajectory"
Optimal Sensor Velocity Configuration for TDOA-FDOA Geolocation,"This paper establishes the velocity orientation requirements for dual or multiple mobile sensors to achieve optimal localization of a stationary emitter, based on TDOA and FDOA measurements. In one approach, optimal velocities are obtained by maximizing the determinant of the Fisher Information Matrix (FIM). The other approach calls for minimizing the trace of the FIM inverse. The paper shows that for a given source-sensor position geometry, two opposite optimal sensor velocity configurations are possible. One way to apply the results of this paper is to deploy sensors onboard highly maneuvering platforms, which are able to rapidly align the platform velocities with those computed by one of the optimization approaches. This usually brings a significant increase in emitter localization accuracy even if the initial sensor-source position geometry is poor. A number of computer simulations are given in the paper, which confirms the paper's theoretical findings.","Robot sensing systems,
Geology,
Geometry,
Vehicles,
Mobile communication,
Optimization,
Satellites"
Towards Correct Cloud Resource Allocation in Business Processes,"Cloud environments are being increasingly used for deploying and executing business processes to provide a high level of performance with low operating cost. Nevertheless, due to the lack of an explicit and formal description of the resource perspective in the existing business processes, the correctness of Cloud resources management can not be verified. The aim of the present work is to offer a formal definition of the resource perspective in business processes as a step towards ensuring a correct and consistent Cloud resource allocation in business process modeling. Concretely, we propose a formalism based on the Event-B language for specifying Cloud resource allocation policies in business process models. This formal specification is used to formally validate the consistency of Cloud resource allocation for process modeling at design time, and to analyze and check its correctness according to user requirements and resource capabilities. In order to show its feasibility, our approach has been tested using a real use case study from an industrial partner.","Cloud computing,
Resource management,
Runtime,
Computational modeling,
Process modeling,
Virtual machining"
SpatialRecruiter: Maximizing Sensing Coverage in Selecting Workers for Spatial Crowdsourcing,"Spatial crowdsourcing and crowdsensing are two emerging crowdsourcing paradigms, which enable a variety of location-based query and sensing tasks. In spatial crowdsourcing, mobile workers are required to travel physically to target locations in order to complete query tasks. Most existing work, hence, has focused on designing efficient query task assignment schemes to maximize the task completion rate under traveling constraints of workers for spatial crowdsourcing systems. In crowdsensing, on the other hand, sensor recordings of workers' smartphones are of interest and have been collected to build various applications. Therefore, work concerning crowdsensing has strived to maximize the coverage area of sensor trajectories by selecting a set of workers. In this paper, we investigate the integration of these two paradigms. We notice a key link between these paradigms: While a worker is traveling to the target location of a query task, his trajectory may provide valuable coverage for a sensing task. Therefore, we propose a task management framework, named SpatialRecruiter, to efficiently match workers to the merged query and sensing tasks. We propose two coverage estimation functions to compute the coverage potential of a worker. Then, we design a greedy heuristic to select and assign workers. The experimental results on a real-world dataset demonstrate that the proposed strategies are efficient and effective in meeting the requirements of both paradigms.","Sensors,
Crowdsourcing,
Mobile communication,
Smart phones,
Trajectory,
Estimation"
Frequency domain analysis of robust demodulators for high-speed atomic force microscopy,"A fundamental but often overlooked component in the z-axis feedback loop of the atomic force microscope (AFM) operated in dynamic mode is the demodulator. Its purpose is to obtain a preferably fast and low-noise estimate of amplitude and phase of the cantilever deflection signal in the presence of sensor noise and additional distinct frequency components. In this paper, we implement both traditional and recently developed robust methods on a LabVIEW digital processing system for high-bandwidth demodulation. The techniques are rigorously compared experimentally in terms of measurement bandwidth, implementation complexity and robustness to noise. We conclude with showing high-speed tapping-mode AFM images in constant height, highlighting the significance of an adequate demodulator bandwidth.","Bandwidth,
Demodulation,
Robustness,
Frequency measurement,
Kalman filters,
Standards,
Tuning"
Evaluating Secrecy Outage of Physical Layer Security in Large-Scale MIMO Wireless Communications for Cyber-Physical Systems,"Large-scale multiple input multiple output (MIMO) wireless system is regarded as a solution to provide high speed connection for exponentially increasing wireless subscriptions for emerging cyber-physical systems (CPSs) and Internet of Things. In order to realize its full potential, there are several challenges to be addressed to achieve high secrecy rate or data rate. In this paper, we analyze outage probability for secrecy rate in MIMO wireless systems in the presence of eavesdroppers and jammers for CPS devices. Our proposed approach takes into account the impact of jammers while finding the best response to minimize the jamming/interfering effect (or to enhance the secrecy rate) and the impact of eavesdropper in secrecy rates of the users. We present formal analysis for secrecy outage probability and interception probability considering Rayleigh fading scenario. The performance is evaluated by using numerical results obtained from Monte Carlo simulations. Numerical results indicate that the system performance is improved significantly when the users adapt their transmit vectors based on their observed interference values. Furthermore, the secrecy outage probability increases with power of jammer and the secrecy capacity decreases when jammer power increases. We observed that the proposed approach outperforms the other existing approaches.","Interference,
Jamming,
MIMO,
Wireless communication,
Base stations,
Signal to noise ratio,
Physical layer"
Resource Allocation for Virtualized Wireless Networks with Backhaul Constraints,"In this letter, we study resource allocation for wireless virtualized networks considering both the backhaul capacity of the infrastructure provider (InP) and the users' quality-of-service (QoS) requirements. We focus on the profit gained by a mobile virtual network operator (MVNO), which is a middleman who buys physical resource from the InP, bundling them into virtual resources called slides before selling off the service providers. The objective of the MVNO is to maximize its profit while guaranteeing the backhaul constraint and users' QoS by jointly allocating the slices and the uplink transmit power to the users. To solve the formulated mixed integer non-convex problem, we propose a distributed solution framework based on Lagrangian relaxation to a find suboptimal decision about slice and transmit power allocations. We further propose a low-complexity solution based on the concept of a matching game that does not require any global information. Numerical results are provided to evaluate the performance of the proposed schemes.",
On a Variant of the Mobile Observer Method,"The mobile observer method has been used by traffic engineers since the middle of the last century to estimate traffic velocity, flow and density. Although simple and intuitive, the method suffers from two major issues. First, the vehicle must traverse a given road segment both in the direction of the traffic whose parameters are of interest and also in the opposite direction, essentially driving in a loop. Second, to get accurate results, several runs must be taken and the results aggregated. Our variant utilizes the communication capabilities in present-day vehicles to mitigate both these issues, thus enabling faster and more accurate traffic maps and traffic routing applications. Extensive simulation results have confirmed that our variant of the mobile observer method is comparable in accuracy with the stationary observer method even at lower flow rates.","Observers,
Roads,
Mobile communication,
Automobiles,
Radar"
Experimental Demonstration of Software-Configurable Asynchronous Real-Time OFDM Signal Transmission in a Hybrid Fiber-VLLC System,"For the first time, we demonstrated a real-time OFDM lightwave transport system based on fiber and VLLC convergence. The system can be dynamically adjusted by using software. By adjusting the symbols number of one OFDM frame and the mapping scheme, the system can operate in a asynchronous way. After 100-km fiber and 6-m free-space transmission, the system can still achieve a BER at below 1e-3. And the data rate of the system is up to 2.65 Gb/s.","OFDM,
Real-time systems,
Optical fibers,
Optical fiber networks,
Optical transmitters,
Receivers"
3D Model Generation of Human Musculoskeletal System Based on Image Processing: An Intermediary Step while Developing a Learning Solution Using Virtual and Augmented Reality,"The aim of this paper is to describe the methods used for obtaining the 3D models of the human musculoskeletal system based on image processing. The resulted models are integrated into a system based on emerging technologies, such as VR (Virtual Reality) and AR (Augmented Reality), aimed to aid the learning process in the study of the human movement biomechanics. The constructed system is designed to be more interactive to capture the users' attention and, to achieve this, the avatar of the musculoskeletal system is animated using full body skeletal tracking of an observed user. We are presenting the software solutions used in the model generation pipeline and the benefits and drawbacks of the selected methods. Also, the early results of the system implementation are showcased along the described pipeline.","Solid modeling,
Three-dimensional displays,
Muscles,
Biological system modeling,
Bones,
Skin,
Computational modeling"
Robust AN-Aided Secure Precoding for an AF MIMO Untrusted Relay System,"Robust artificial noise (AN) aided secure precoding for an amplify-and-forward multiple-input multiple-output untrusted relay system is studied, where the relay is untrusted and willing to help forwarding multiple data streams from the source to destination. We consider that the available channel state information is imperfect and modeled by the worst case model. Our objective is to maximize the worst case secrecy rate under the robust transmit power constraints at the source and relay, by jointly designing the signal and AN precoding matrices at the source and the precoding matrix at the relay. The robust secure precoding problem is nonconvex and hard to solve. To overcome this difficulty, we propose the weighted minimum mean square error based method, where the signdefiniteness lemma is used to eliminate the channel uncertainties and an effective iterative optimization algorithm is developed. Simulation results are provided to demonstrate the effectiveness of the proposed scheme.","Relays,
Precoding,
Robustness,
MIMO,
Uncertainty,
Wireless communication,
Channel estimation"
A Stealthy Attack Against Electricity Market Using Independent Component Analysis,"In smart grid, the strong coupling between cyber and physical operations makes power systems vulnerable to cyber attacks. In this paper, we investigate a new but serious type of attack, stealthy false data attack. In addition, we demonstrate that the attackers are able to, without prior knowledge of the power grid topology, make inferences through phasor observations. For the attackers to achieve this ability, we show that when the change of operating conditions is relatively mild and can be approximated linearly, linear independent component analysis can be applied to estimate the Jacobian matrix multiplied by the eigenvectors of the covariance matrix of the state variables. Then, the inferred structural information is used to launch the stealthy attack. This attack is formulated to change the price of electricity in the realtime market for the benefits of attackers. As demonstrated by the simulation results using data generated by MATPOWER, the proposed scheme injects undetectable false data and changes the price of electricity at the desired locations.","Transmission line measurements,
Smart grids,
State estimation,
Electricity supply industry,
Topology,
Real-time systems"
Channel Compensation for Reciprocal TDD Massive MIMO-OFDM With IQ Imbalance,"Massive multiple-input multiple-output (MIMO) orthogonal frequency division multiplexing (OFDM) systems are sensitive to in-phase and quadrature (IQ) imbalances, which destroys the reciprocity of time-division duplex (TDD) uplink/downlink channels with potentially large performance degradation. In this letter, we investigate the compensation of channel reciprocity for TDD massive MIMO-OFDM systems in the presence of IQ imbalances at both the transmitter and receiver. A frequency-domain compensation scheme is proposed, which uses compensation matrices to precode uplink and downlink transmissions. By disassembling the effective channel model into pairs of mirror subcarriers and utilizing block matrix inversion, the compensation matrices can be calculated with a complexity that is linear in the number of antennas at the base station and mobile station. Simulations verify the effectiveness of the proposed scheme.",
"Planning Wireless Cellular Networks of Future: Outlook, Challenges and Opportunities","Cell planning (CP) is the most important phase in the life cycle of a cellular system as it determines the operational expenditure, capital expenditure, as well as the long-term performance of the system. Therefore, it is not surprising that CP problems have been studied extensively for the past three decades for all four generations of cellular systems. However, the fact that small cells, a major component of future networks, are anticipated to be deployed in an impromptu fashion makes CP for future networks vis-a-vis 5G a conundrum. Furthermore, in emerging cellular systems that incorporate a variety of different cell sizes and types, heterogeneous networks (HetNets), energy efficiency, self-organizing network features, control and data plane split architectures (CDSA), massive multiple input multiple out (MIMO), coordinated multipoint (CoMP), cloud radio access network, and millimetre-wave-based cells plus the need to support Internet of Things (IoT) and device-to-device (D2D) communication require a major paradigm shift in the way cellular networks have been planned in the past. The objective of this paper is to characterize this paradigm shift by concisely reviewing past developments, analyzing the state-of-the-art challenges, and identifying future trends, challenges, and opportunities in CP in the wake of 5G. More specifically, in this paper, we investigate the problem of planning future cellular networks in detail. To this end, we first provide a brief tutorial on the CP process to identify the peculiarities that make CP one of the most challenging problems in wireless communications. This tutorial is followed by a concise recap of past research in CP. We then review key findings from recent studies that have attempted to address the aforementioned challenges in planning emerging networks. Finally, we discuss the range of technical factors that need to be taken into account while planning future networks and the promising research directions that necessitates the paradigm shift to do so.","Planning,
5G mobile communication,
Optimization,
Cellular networks,
Object recognition,
Tutorials,
Wireless communication"
High-Performance Low-Area Video Up-Scaling Architecture for 4-K UHD Video,"A new algorithm and its hardware architecture are presented to up-scale high-definition (HD) and full-HD video streams to 4-K ultra-HD video streams in real time. The Lagrange interpolation is employed, as it provides high estimation accuracy and hardware-friendly properties. To enhance the accuracy further, the pixels at the edge regions are specially processed by employing an image-sharpening technique. Experimental results show that the proposed architecture provides the best visual quality at the cost of reasonable hardware resources.","Interpolation,
Image edge detection,
Streaming media,
Computer architecture,
Hardware,
Laplace equations,
Kernel"
Driving with Sharks: Rethinking Connected Vehicles with Vehicle Cybersecurity,"In a public service announcement on 17 March 2016, the Federal Bureau of Investigation jointly with the U.S. Department of Transportation and the National Highway Traffic Safety Administration (NHTSA) released a warning regarding the increasing vulnerability of motor vehicles to remote exploits [18]. Engine shutdowns, disabled brakes, and locked doors are a few examples of possible vehicle cybersecurity attacks. Modern cars grow into a new target for cyberattacks as they become increasingly connected. While driving on the road, sharks (i.e., hackers) need only to be within communication range of a vehicle to attack it. However, in some cases, they can hack into it while they are miles away. In this article, we aim to illuminate the latest vehicle cybersecurity threats including malware attacks, on-board diagnostic (OBD) vulnerabilities, and automobile apps threats. We illustrate the in-vehicle network architecture and demonstrate the latest defending mechanisms designed to mitigate such threats.","Automobiles,
Computer hacking,
Computer crime,
Wireless fidelity,
Safety,
Logic gates,
Ports (Computers)"
Detecting and Preventing Kernel Rootkit Attacks with Bus Snooping,"To protect the integrity of operating system kernels, we present Vigilare system, a kernel integrity monitor that is architected to snoop the bus traffic of the host system from a separate independent hardware. This snoop-based monitoring enabled by the Vigilare system, overcomes the limitations of the snapshot-based monitoring employed in previous kernel integrity monitoring solutions. Being based on inspecting snapshots collected over a certain interval, the previous hardware-based monitoring solutions cannot detect transient attacks that can occur in between snapshots, and cannot protect the kernel against permanent damage. We implemented three prototypes of the Vigilare system by adding Snooper hardware connections module to the host system for bus snooping, and a snapshot-based monitor to be compared with, in order to evaluate the benefit of snoop-based monitoring. The prototypes of Vigilare system detected all the transient attacks and the second one protected the kernel with negligible performance degradation while the snapshot-based monitor could not detect all the attacks and induced considerable performance degradation as much as 10 percent in our tuned STREAM benchmark test.","Kernel,
Monitoring,
Transient analysis,
Prototypes,
Hardware,
Linux,
Memory management"
"A Reduced-Bias Approach With a Lightweight Hard-Multiple Generator to Design a Radix-8 Modulo
2
n
+1
Multiplier","The modulo 2n + 1 multiplier is the bottleneck of a wide range of applications from residue number system arithmetic to cryptography. Recently, with demand for low-power and energy-efficient designs, the radix-8 Booth recoding has been considered to derive modulo 2n + 1 multipliers. This brief presents two novel methods to increase the performance and improve the efficiency of radix-8 modulo 2n + 1 multipliers. The first technique is a method to significantly reduce the amount of bias terms that need to be handled. The second technique is a new hard multiple generator based on a parallel-prefix structure that computes only for odd positions; it results in a lightweight parallel-prefix adder for the computation of the triple of a number with significant area-saving and improved fan-out. The implementation results based on the TSMC 65-nm technology show improvements of at least 27% and up to 57% in the area-time2 product when compared with the recently proposed radix-8 multiplier.","Adders,
Logic gates,
Delays,
Generators,
Electronic mail,
Computers"
Hashing With Pairwise Correlation Learning and Reconstruction,"Existing hashing methods normally define certain specific forms of hash functions, after which an objective function can be formulated to optimize the loss on training set to learn the parameters. However, in this way, the hash function will be tightly coupled with the generated objective in most cases. Moreover, since the objectives are generally formulated with binary quantization, most of them are nonconvex, which makes the optimization difficult and consequently decreases the similarity preserving performance of hashing. To solve this problem, we propose a novel pairwise correlation preserving framework to learn compact binary codes for hashing. First, we project each data into a metric space and represent it as a vector encoding the underlying local and global structure by pairwise correlation learning. Afterwards, pairwise correlation reconstruction (PCR), is further proposed to preserve the correlations of data between the metric space and the hamming space to learn binary codes. The PCR model is convex. Moreover, no specific hash functions are needed to be predefined and the steps of correlation learning and reconstruction are independent. The above characteristics make the optimization of PCR easily and efficiently, and thus leads to better preservation of data similarity in hamming space.","Binary codes,
Correlation,
Pairwise error probability,
Quantization (signal),
Nearest neighbor searches,
Optimization,
Measurement"
Multimodal Optimization by Covariance Matrix Self-Adaptation Evolution Strategy with Repelling Subpopulations,"During the recent decades, many niching methods have been proposed and empirically verified on some available test problems. They often rely on some particular assumptions associated with the distribution, shape, and size of the basins, which can seldom be made in practical optimization problems. This study utilizes several existing concepts and techniques, such as taboo points, normalized Mahalanobis distance, and the Ursem’s hill-valley function in order to develop a new tool for multimodal optimization, which does not make any of these assumptions. In the proposed method, several subpopulations explore the search space in parallel. Offspring of a subpopulation are forced to maintain a sufficient distance to the center of fitter subpopulations and the previously identified basins, which are marked as taboo points. The taboo points repel the subpopulation to prevent convergence to the same basin. A strategy to update the repelling power of the taboo points is proposed to address the challenge of basins of dissimilar size. The local shape of a basin is also approximated by the distribution of the subpopulation members converging to that basin. The proposed niching strategy is incorporated into the covariance matrix self-adaptation evolution strategy (CMSA-ES), a potent global optimization method. The resultant method, called the covariance matrix self-adaptation with repelling subpopulations (RS-CMSA), is assessed and compared to several state-of-the-art niching methods on a standard test suite for multimodal optimization. An organized procedure for parameter setting is followed which assumes a rough estimation of the desired/expected number of minima available. Performance sensitivity to the accuracy of this estimation is also studied by introducing the concept of robust mean peak ratio. Based on the numerical results using the available and the introduced performance measures, RS-CMSA emerges as the most successful method when robustness and efficiency are considered at the same time.","Niching,
adaptive normalized niche radius,
Mahalanobis distance metric,
robust mean peak ratio,
CEC2013 test suite"
Efficient Graph Similarity Search in External Memory,"Many real-world applications, such as bioinformatics, data mining, pattern recognition, and social network analysis, benefit from efficient solutions for the graph similarity search problem. Existing methods have limited scalability when they handle the large graph databases, for example, those with millions or billions of graphs that cannot fit in main memory. In this paper, we study the problem of graph similarity search under the graph edit distance constraint in external memory. We present an efficient framework for arbitrary q-gram-based representations of a graph. Specifically, we propose a q-gram matrix index stored in hybrid layout in external memory to achieve efficient query processing, by converting the q-gram counting filter into a sparse matrix-vector multiplication problem. Furthermore, we also boost the query performance by transforming the global filter to a 2-D query rectangle, which allows us to perform a query in a reduced region, significantly reducing the number of query I/Os in practice. Extensive experiments on real data sets confirm that 1) our method can compete with the state-of-the-art in-memory methods in index size and filtering ability, and outperform them on scalability of coping with the PubChem data set including 25 million chemical structure graphs and 2) compared with the popular q-gram-based external inverted index, our external index structure needs much fewer number of query I/Os on the PubChem data set.","Indexes,
Search problems,
Transforms,
Data mining,
Sparse matrices"
Interconnection Allocation Between Functional Units and Registers in High-Level Synthesis,"Data path interconnection on VLSI chips usually consumes a significant amount of both power and area. In this paper, we focus on the port assignment problem for binary commutative operators for interconnection complexity reduction. First, the port assignment problem is formulated on a constraint graph, and a practical method is proposed to find a valid and initial solution. For solution optimization, an elementary spanning-tree-transformation-based local search algorithm is proposed. To improve the efficiency of optimization, a matrix formulation, which meets the simplex tabuleau format, is proposed and thus the simplex method is adopted for optimization. Moreover, operation pivoting and successive pivoting are discussed for algorithm speedup. The experimental results show that on the randomly generated test cases, the matrix-based algorithm shows the highest solution optimality and is five times faster than the elementary transformation method. On the real high-level synthesis benchmarks, the matrix-based method reduced 14% interconnections, while the previous greedy algorithm reduced 8% on average.","Registers,
Integrated circuit interconnections,
Optimization,
Complexity theory,
Very large scale integration,
Resource management,
Heuristic algorithms"
Effect of Mechanical Strain on Hydrogenated Amorphous Silicon Thin-Film Transistors and Compensation Circuits on Flexible Substrates,"Hydrogenated amorphous silicon (a-Si:H) thin-film transistor (TFT) compensation pixel circuits were fabricated on polyethylene naphthalate substrates at a maximum temperature of 170 °C. The typical a-Si:H TFTs showed a field-effect mobility (μFE) of 0.8-1.1 cm2/Vs, a threshold voltage (VT) of 2-3.3 V, a subthreshold swing (SS) of ~0.65 V/decade, and an ON/OFF current ratio of 107-108. Under DC gate-bias stress without compensation, the TFT drive current decreased by ~50% without mechanical strain and ~60% with applied tensile strain. The TFT circuits effectively compensated for the change in the TFT drive current to within 10% of the original drive current value under mechanically strained and unstrained states. The orientation of the TFT within the circuit was found to affect the circuit compensation; TFTs having a channel length perpendicular to the mechanical strain were found to have a 50% higher threshold voltage shift (ΔVT) compared to devices parallel to the applied strain.","Thin film transistors,
Strain,
Logic gates,
Substrates,
Degradation,
Organic light emitting diodes,
Plasma temperature"
Wearable Flexible Sensors: A Review,"This paper provides a review on some of the significant research work done on wearable flexible sensors (WFSs). Sensors fabricated with the flexible materials have been attached to a person along with the embedded system to monitor a parameter and transfer the significant data to the monitoring unit for the further analyses. The use of wearable sensors has played a quite important role to monitor the physiological parameters of a person to minimize any malfunctioning happening in the body. This paper categorizes the work according to the materials used for designing the system, the network protocols, and different types of activities that were being monitored. The challenges faced by the current sensing systems and future opportunities for the WFSs regarding its market values are also briefly explained in this paper.","Biomedical monitoring,
Monitoring,
Wearable sensors,
Electrodes,
Polymers,
Substrates"
Construction of Hierarchical Cognitive Academic Map,"Nowadays, mobile devices have been considered as a new platform for information services, and have been widely used in many fields. In mobile application services, the processing and representation of data is a key issue which has a great impact on the service quality. Knowledge map is regarded as an effective method and has been widely utilized in mobile devices. However, traditional knowledge maps employed in mobile devices are subject to a lack of cognition characteristics, which results in corresponding information services' being unable to match the users' cognition level, thus affecting the quality of services. In this paper, we propose a hierarchical cognitive academic map (HCAM) for the specific academic domain application background. HCAM can meet the needs of three basic levels of Bloom's cognition taxonomy model by distinguishing the academic attributes of nodes and relations between nodes. First, academic concepts are the basic units in HCAM and are classified into research object concepts and method/technique concepts, which meet the human's remembering cognition levels. Second, HCAM provides the implementation and collaboration relation between concepts, which satisfies the human's applying and understanding cognition levels. Third, technique/method concepts are organized in the form of hierarchical structure from the top down of which concepts' specificity for the domain get higher and higher. In addition, Bayesian rose tree clustering is adopted in the construction of this hierarchical structure and acquiring the cognition depth for each concept. Furthermore, experiments on information retrieval field and data mining field are performed to demonstrate the effectiveness and cognition characteristics of HCAM.","Cognition,
Mobile handsets,
Knowledge engineering,
Information services,
Collaboration,
Mobile applications,
Data mining"
MapReduce Scheduling for Deadline-Constrained Jobs in Heterogeneous Cloud Computing Systems,"MapReduce is a software framework for processing data-intensive applications with a parallel manner in cloud computing systems. Some MapReduce jobs have the deadline requirements for their job execution. The existing deadline-constrained MapReduce scheduling schemes do not consider the following two problems: various node performance and dynamical task execution time. In this paper, we utilize the Bipartite Graph modelling to propose a new MapReduce Scheduler called the BGMRS. The BGMRS can obtain the optimal solution of the deadline-constrained scheduling problem by transforming the problem into a well-known graph problem: minimum weighted bipartite matching. The BGMRS has the following features. It considers the heterogeneous cloud computing environment, such that the computing resources of some nodes cannot meet the deadlines of some jobs. In addition to meeting the deadline requirement, the BGMRS also takes the data locality into the computing resource allocation for shortening the data access time of a job. However, if the total available computing resources of the system cannot satisfy the deadline requirements of all jobs, the BGMRS can minimize the number of jobs with the deadline violation. Finally, both simulation and testbed experiments are performed to demonstrate the effectiveness of the BGMRS in the deadline-constrained scheduling.","Cloud computing,
Optimal scheduling,
Scheduling,
Processor scheduling,
Computational modeling,
Bipartite graph,
Resource management"
A Longitudinal Measurement Study of TCP Performance and Behavior in 3G/4G Networks Over High Speed Rails,"While TCP has been extensively studied in static and low speed mobility situations, it has not yet been well explored in high speed mobility scenarios. Given the increasing deployment of high speed transport systems (such as high speed rails), there is an urgent need to understand the performance and behavior of TCP in such high speed mobility environments. In this paper, we conduct a comprehensive study to investigate the performance and behavior of TCP in a high speed environment with a peak speed of 310 km/h. Over a 16-month period spanning four years, we collect 500 GB of performance data on 3/4G networks in high speed trains in China, covering a distance of 108,490 km. We start by analyzing performance metrics, such as RTT, packet loss rate, and throughput. We then evaluate the challenges posed on the main TCP operations (establishment, transmission, congestion control, flow control, and termination) by such high speed mobility. This paper shows that RTT and packet loss rate increase significantly and throughput drops considerably in high speed situations. Moreover, TCP fails to adapt well to such extremely high speed leading to abnormal behavior, such as high spurious retransmission time out rate, aggressive congestion window reduction, long delays during connection establishment and closure, and transmission interruption. As we prepare to move into the era of 5G, and as the need for high speed travel continues to increase, our findings indicate a critical need for efforts to develop more adaptive transport protocols for such high speed environments.","Mobile communication,
Throughput,
Packet loss,
Electronic mail,
Mobile computing,
Rails"
Anatomy of Phase Locking in Hyperparametric Oscillations Based on Kerr Nonlinearity,"We investigate the dynamical origin of synchronization of hyperparametric oscillations in Kerr-nonlinear media. We derive analytical expressions revealing the essence of phase locking in frequency combs and confirm them by numerical integration of the LLE. Our results are mathematically generic, apply also to other systems described by an externally driven, damped nonlinear Schrdinger equation, and can lead to devising novel techniques for improving the coherence properties of frequency combs.","Oscillators,
Optical harmonic generation,
Amplitude modulation,
Laser excitation,
Solitons,
Steady-state,
Synchronization"
A comparison of IoT application layer protocols through a smart parking implementation,"Several IoT protocols have been introduced in order to provide an efficient communication for resource-ronstrained applications. However, their performance is not as yet well understood. To address this issue, we evaluated and compared four communication protocols, namely, CoAP, MQTT, XMPP, and WebSocket. For this, we implemented a smart parking application using open source software for these protocols and measured their response time by varying the traffic load.",
CloudScout: A Non-Intrusive Approach to Service Dependency Discovery,"Nowadays, numerous enterprises are migrating their applications into cloud computing environments. Typically, the applications are composed of several dependent service components that span many hosts and network devices. In light of this, exploring the dependency between service components can be beneficial for achieving fast network application response time. Moreover, it is significant to consolidate service components according to resource constraints, service dependency, and network structure. However, it is a tedious task to discover the dependency among service components without expert knowledge of the running application. In this paper, we propose CloudScout, a non-intrusive approach that is capable of automatically discovering dependent service components. CloudScout analyzes the correlation among service components based on the time-series information from system monitoring logs. We address two key challenges in CloudScout: service distance calculation and dependent service clustering. We conduct experiments on five applications with 290 service components that span 20 physical hosts across two data centers. The experimental results demonstrate that CloudScout can successfully discover the dependency among service components and facilitate reducing the network latency of network applications and distributed applications.","Switches,
Cloud computing,
Servers,
Network topology,
Distributed databases,
Correlation,
Data mining"
Auxiliary Beam Pair Enabled AoD and AoA Estimation in Closed-Loop Large-Scale Millimeter-Wave MIMO Systems,"Channel estimation is of critical importance in millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems. Due to the use of large antenna arrays, low-complexity mmWave specific channel estimation algorithms are required. In this paper, an auxiliary beam pair design is proposed to provide high-resolution estimates of the channel's angle-of-departure (AoD) and angle-of-arrival (AoA) for mmWave MIMO systems. By performing an amplitude comparison with respect to each auxiliary beam pair, a set of ratio measures that characterize the channel's AoD and AoA are obtained by the receiver. Either the best ratio measure or the estimated AoD is quantized and fed back to the transmitter via a feedback channel. The proposed technique can be incorporated into control channel design to minimize initial access delay. Though the design principles are derived assuming a high-power regime, evaluation under more realistic assumption shows that by employing the proposed method, good angle estimation performance is achieved under various signal-to-noise ratio levels and channel conditions.","Channel estimation,
Estimation,
Antenna arrays,
MIMO,
Receiving antennas,
Radio frequency"
A Novel ZVS Range Enhancement Technique of a High-Voltage Dual Active Bridge Converter Using Series Injection,"In this paper, a novel technique is proposed to extend the region of zero voltage switching (ZVS) of a dual active bridge (DAB) dc-dc converter using an auxiliary series injection transformer. The series voltage injection by the series transformer helps us to maintain ZVS by controlling the reactive power flow through the main converter of the DAB. A model for the series compensation is developed to compute the phase angle of the series voltage to obtain the optimum efficiency over the entire region of operation. The proposed technique is validated through simulations and the corresponding converter loss reduction is presented. The system is implemented on a high-voltage hardware with 6kV-270 V DAB using 10-kV SiC mosfet-based converter in the primary and 1200-V SiC mosfet on the secondary side of the transformer and the corresponding results are presented.","Zero voltage switching,
Silicon carbide,
Switches,
Insulated gate bipolar transistors,
Logic gates,
Probes,
Bridge circuits"
A case for stacked autoencoder based order recognition of continuous-phase FSK,"Stacked autoencoders have shown success in generating robust features for images and speech classifications, but there has been limited work in applying stacked autoencoders in signal recognition. In this paper, we study the feasibility of stacked autoencoder based order recognition of continuous phase FSK. The features used for recognition are the approximate entropy (ApEn) of the received signal, ApEn of the phase of the received signal, and ApEn of the instantaneous frequency of the received signal. The work aims in devising an unsupervised learning algorithm under noisy, carrier frequency offset and fast fading channel conditions. Performance of the stacked autoencoder neural network classifier will be compared with traditional neural network and support vector machine based classifiers for the same set of features and the advantages and disadvantages of the methods will be examined.","Modulation,
Fading channels,
Neural networks,
Support vector machines,
Entropy,
Unsupervised learning,
Training"
Tactile Sensing From Laser-Ablated Metallized PET Films,"This paper reports the design, fabrication, and implementation of a novel sensor patch developed from commercial polyethylene terephthalate films metallized with aluminum on one side. The aluminum was ablated with laser to form interdigitated electrodes to make sensor prototypes. The interdigitated electrodes were patterned on the substrate with a laser cutter. Characterization of the prototypes was done to determine their operating frequency followed by experimentation. The prototypes have been used as a tactile sensor showing promising results for using these patches in applications with contact pressures considerably lesser than normal human contact pressure.","Sensor phenomena and characterization,
Electrodes,
Substrates,
Fabrication,
Positron emission tomography,
Plastics"
Normally-Off LPCVD-SiNx/GaN MIS-FET With Crystalline Oxidation Interlayer,"Developing effective technique to protect the etched-GaN surface from the degradation in a high-temperature (i.e., at ~ 780°C) process, such as low-pressure chemical vapor deposition (LPCVD), is essential for fabricating normally-off GaN MIS-FETs with high-quality dielectric/GaN interface and highly reliable gate dielectric. In this letter, we developed an approach of obtaining such a protection layer using oxygen-plasma treatment followed by in situ annealing prior to the LPCVD-SiNx deposition. A sharp and stable crystalline oxidation interlayer (COIL) between the LPCVD-SiNx and etched-GaN was successfully formed. The LPCVD-SiNx/GaN MIS-FETs with COIL deliver normally-off operation with a VTH of 1.15 V, small ON-resistance, small hysteresis, and thermally stable VTH.","Gallium nitride,
Logic gates,
Surface treatment,
Annealing,
Oxidation,
Dielectrics,
Thermal stability"
FitLoc: Fine-Grained and Low-Cost Device-Free Localization for Multiple Targets Over Various Areas,"Many emerging applications driven the fast development of the device-free localization (DfL) technique, which does not require the target to carry any wireless devices. Most current DfL approaches have two main drawbacks in practical applications. First, as the pre-calibrated received signal strength (RSS) in each location (i.e., radio-map) of a specific area cannot be directly applied to the new areas, the manual calibration for different areas will lead to a high human effort cost. Second, a large number of RSS are needed to accurately localize the targets, thus causes a high communication cost and the areas variety will further exacerbate this problem. This paper proposes FitLoc, a fine-grained and low cost DfL approach that can localize multiple targets over various areas, especially in the outdoor environment and similar furnitured indoor environment. FitLoc unifies the radio-map over various areas through a rigorously designed transfer scheme, thus greatly reduces the human effort cost. Furthermore, benefiting from the compressive sensing theory, FitLoc collects a few RSS and performs a fine-grained localization, thus reduces the communication cost. Theoretical analyses validate the effectivity of the problem formulation and the bound of localization error is provided. Extensive experimental results illustrate the effectiveness and robustness of FitLoc.","Wireless communication,
Transceivers,
Real-time systems,
IEEE transactions,
Manuals,
Calibration,
Compressed sensing"
Hysteretic Noisy Chaotic Neural Networks for Resource Allocation in OFDMA System,"This paper addresses two-stage resource allocation in the orthogonal frequency division multiplexing access system. In the subcarrier allocation stage, hysteretic noisy chaotic neural network (HNCNN) with a newly established energy function is proposed for subcarrier allocation to improve the optimization performance and reduce the computational complexity. Activation functions with both anticlockwise and clockwise hysteretic loops are applied to the HNCNN. A new energy function is established for an objective function, which can be calculated offline, resulting in a lower computational complexity in solving subcarrier allocation than the previous energy function. In the power allocation stage, the water-filling algorithm is employed to attain optimal power allocation. Simulation results show that the energy function established in this paper can decrease the runtimes of the neural networks, and that the HNCNN with both anticlockwise and clockwise hysteretic-loop activation functions can improve probabilities of feasible and optimal solutions at higher noises. The two-stage algorithm in this paper outperforms the previous algorithms in fairness, system throughput, and resource utilization.",
An Alternating Identification Algorithm for a Class of Nonlinear Dynamical Systems,"While modeling nonlinear systems by combining a linear model with a nonlinear compensation term, namely, virtual unmodeled dynamics (VUD), the parameter estimation of the linear model and the learning-based VUD estimate influences and interacts with each other simultaneously. This paper aims to develop an alternating identification scheme for resolving such a challenging problem, where a projection algorithm is employed to identify the linear model and a feedforward neural network is used to model the VUD of a class of nonlinear dynamical systems. An open-loop estimation algorithm on the VUD is first presented under the known linear model, followed by an alternating identification algorithm for completely unknown nonlinear systems. Algorithm description is given and some simulation studies on multiple input and multiple output nonlinear systems are carried out to illustrate the effectiveness of our proposed modeling techniques.",
Privacy-preserving cybersecurity information exchange mechanism,"Cybersecurity information sharing is improving cyber incident detection and prevention by reducing the loss caused by attacks and eliminating the costs of duplication efforts for cyber-defense. However, privacy is one of the major concerns of organizations, while they are gathering security information to share externally. In order to preserve the privacy of organizations in the cybersecurity information sharing framework, we propose a novel mechanism which consists of four components: (i) Registration, (ii) Sharing, (iii) Dispute, (iv) Rewarding. Our mechanism enables the organizations to share their cybersecurity information without revealing their identities. Besides, in order to encourage collaboration and prevent free-riding, rewards are issued anonymously in return for contributions. For this purpose, we are proposing a new aggregatable blind signature based on BBS+ signature scheme. Security analysis and performance evaluation are conducted showing the effectiveness and efficiency of the proposed mechanism.","Organizations,
Computer security,
Information management,
Privacy,
Collaboration,
Information exchange"
Extensive Cooperative Caching in D2D Integrated Cellular Networks,"Device-to-device (D2D) communication is a promising supplement to cellular networks, since it provides high rate transmission without changing network infrastructure. For a D2D integrated cellular network, caching popular content (e.g., multimedia files) at a base station (BS) or a D2D device near to a requesting user not only reduces content delivery delay, but also alleviates backhaul traffic load. In order to minimize content delivery delay, in this letter, we propose an extensive cooperative caching (EC-Caching) scheme, which allows inter-BS, inter-device and between-BS-and-device cooperation in content caching. Simulation results demonstrate that the extension in degree of cooperation between the caching nodes contributes significant performance gain in terms of content delivery delay and cache hit rate, especially in populated areas.",
Recursive block Markov superposition transmission of short codes,"Extensive studies have demonstrated the effectiveness of constructing capacity-approaching codes by block Markov superposition transmission (BMST). However, to achieve high performance, BMST codes typically require large encoding memories and large decoding window sizes, which result in increased decoding complexity and decoding latency. To address this issue, we introduce the recursive BMST (rBMST), in which block-oriented feedback convolutional code is used instead of the block-oriented feedforward convolutional code. We propose to use a modified extrinsic information transfer (EXIT) chart analysis to study the convergence behavior of rBMST codes. On one hand, rBMST code shares most merits of BMST code, including near-capacity performance, low-complexity encoding, and flexible construction. On the other hand, compared with BMST code, rBMST code requires a smaller encoding memory, hence a lower decoding complexity, to approach the capacity. In particular, analytical results show that, rBMST code ensemble with encoding memory three reveals a lower error-floor than the BMST code ensemble with encoding memory twelve.","Encoding,
Decoding,
Iterative decoding,
Complexity theory,
Convolutional codes,
Delays"
Robust Integration of High-Level Dispatchable Renewables in Power System Operation,"The increasing penetration of renewable energy sources (RES) requires more flexibility resources (FR), such as thermal units and storages. FR kept in the system can help accommodate the uncertainties from RES. The challenge is how the system can survive when the RES level is very high. In this paper, RESs are considered as full-role market participants. They can bid in the day-ahead market, and the powers they deliver to the market are controllable up to their maximum available powers. Therefore, RESs are effectively dispatchable and can function as FR. To integrate dispatchable renewables, a two-stage robust unit commitment (UC) and dispatch model is established. In the first stage, a base UC and dispatch is determined. In the second stage, all FRs including RESs are used to accommodate the uncertainties, which is a mixed-integer programming (MIP) problem. It is proved that the solution to the max-min problem can be identified directly whether the strong duality holds or not for the inner minimization problem. The solution robustness can be guaranteed by considering only one extra scenario. Numerical results show the effectiveness of the proposed model and its advantages over the traditional robust UC model with high-level RES penetration.","Uncertainty,
Robustness,
Stochastic processes,
Optimization,
Power systems,
Renewable energy sources,
Programming"
Robotic Message Ferrying for Wireless Networks Using Coarse-Grained Backpressure Control,"We formulate the problem of robots ferrying messages between statically-placed source and sink pairs that they can communicate with wirelessly. We first analyze the capacity region for this problem under ideal conditions. We indicate how robots could be scheduled optimally to satisfy any arrival rate in the capacity region, given prior knowledge about arrival rate. We then consider the setting where the arrival rate is unknown and present a coarse-grained backpressure message ferrying algorithm (CBMF) for it. In CBMF, the robots are matched to sources and sinks once every epoch to maximize a queue-differential-based weight. The matching controls both motion and transmission for each robot. We show through analysis and simulations the conditions under which CBMF can stabilize the network, and its corresponding delay performance. From a practical point of view, we propose a heuristic approach to adapt the epoch duration according to network conditions that can improve the end-to-end delay while guaranteeing the network stability at the same time. We also study the structural properties with its explicit delay performance of the CBMF algorithm in a homogeneous network.","Resource management,
Schedules,
Mobile computing,
Robot sensing systems,
Electronic mail,
Electrical engineering"
Self-Repairable Smart Grids Via Online Coordination of Smart Transformers,"The introduction of active devices in Smart Grids, such as smart transformers, powered by intelligent software and networking capabilities, brings paramount opportunities for online automated control and regulation. However, online mitigation of disruptive events, such as cascading failures, is challenging. Local intelligence by itself cannot tackle such complex collective phenomena with domino effects. Collective intelligence coordinating rapid mitigation actions is required. This paper introduces analytical results from which two optimization strategies for self-repairable Smart Grids are derived. These strategies build a coordination mechanism for smart transformers that runs in three healing modes and performs collective decision-making of the phase angles in the lines of a transmission system to improve reliability under disruptive events, i.e., line failures causing cascading failures. Experimental evaluation using self-repairability envelopes in different case networks, ac power flows, and varying number of smart transformers confirms that the higher the number of smart transformers participating in the coordination, the higher the reliability and the capability of a network to self-repair.",
A Mathematical Model for Self-Priming Circuits: Getting the Most From a Dielectric Elastomer Generator,"A dielectric elastomer generator (DEG) can be used for converting mechanical energy from natural motion sources, such as walking, waves, trees, etc., into electrical energy. A DEG is comprised of a soft and flexible dielectric elastomer (DE) capacitor, a priming circuit (PC), which transfers high potential charge onto/off the DE electrodes, and a power extraction circuit that harvests the generated power. To generate power, the PC must charge and discharge the DE in synchronization with the DE's capacitance change. A simple circuit to do this exists: the self-priming circuit (SPC). The SPC consists of diodes and capacitors that passively switch between charge delivery and charge receiving states in synchronization with the DE's capacitance change. Until now, there has been no understanding of how to design an SPC in order to maximize harvested energy from the DE. A new mathematical model for an SPC is presented, leading to design and optimization. An accuracy of 0.1% between model, simulation, and experiment over five cycles is obtained, once losses are taken into consideration. The behavior of the SPC is shown to be related to the maximum and minimum capacitances of the DE, but is unaffected by the exact shape of the capacitance waveform.","Capacitance,
Capacitors,
Electric potential,
Mathematical model,
Generators,
Electrodes"
Noise Level Estimation for Natural Images Based on Scale-Invariant Kurtosis and Piecewise Stationarity,"Noise level estimation is crucial in many image processing applications, such as blind image denoising. In this paper, we propose a novel noise level estimation approach for natural images by jointly exploiting the piecewise stationarity and a regular property of the kurtosis in bandpass domains. We design a K-means-based algorithm to adaptively partition an image into a series of non-overlapping regions, each of whose clean versions is assumed to be associated with a constant, but unknown kurtosis throughout scales. The noise level estimation is then cast into a problem to optimally fit this new kurtosis model. In addition, we develop a rectification scheme to further reduce the estimation bias through noise injection mechanism. Extensive experimental results show that our method can reliably estimate the noise level for a variety of noise types, and outperforms some state-of-the-art techniques, especially for non-Gaussian noises.","Noise level,
Estimation,
Noise measurement,
Image edge detection,
Discrete cosine transforms,
Optimization"
A 4-Megapixel Cooled CCD Division of Focal Plane Polarimeter for Celestial Imaging,"The field of astronomy relies on spectral and polarization imagery recorded across a wide range of spectra to make inferences about imaged objects from nearby and distant galaxies. One of the challenges in recording celestial polarization information is recording multiple images filtered with various polarization optics, such as linear polarization filters or retarders, and with low-noise, low-dark-current sensors. In this paper, we present a division of focal plane polarimeter that can operate at room temperature down to -20 °C. When the imaging sensor operates at -20 °C, the dark currents is reduced by two orders of magnitude, which improves the polarization extinction ratio by ~5-fold. Comprehensive optoelectronic tests are presented with data recorded with the polarimeter.","Optical filters,
Sensors,
Dark current,
Image sensors,
Image quality,
Extinction ratio"
Discriminant Kernel Assignment for Image Coding,"This paper proposes discriminant kernel assignment (DKA) in the bag-of-features framework for image representation. DKA slightly modifies existing kernel assignment to learn width-variant Gaussian kernel functions to perform discriminant local feature assignment. When directly applying gradient-descent method to solve DKA, the optimization may contain multiple time-consuming reassignment implementations in iterations. Accordingly, we introduce a more practical way to locally linearize the DKA objective and the difficult task is cast as a sequence of easier ones. Since DKA only focuses on the feature assignment part, it seamlessly collaborates with other discriminative learning approaches, e.g., discriminant dictionary learning or multiple kernel learning, for even better performances. Experimental evaluations on multiple benchmark datasets verify that DKA outperforms other image assignment approaches and exhibits significant efficiency in feature coding.","Kernel,
Histograms,
Optimization,
Dictionaries,
Image coding,
Integrated circuits,
Jacobian matrices"
Optimal Gear Shift Schedule Design for Automated Vehicles: Hybrid System Based Analytical Approach,"In this paper, we present a systematic design framework for gear shift schedule using hybrid system theory primarily intended for automated vehicles. The longitudinal motion of the vehicle is regulated by a PI controller that determines the required axle torque. The longitudinal dynamics of the vehicle with a gear box is modeled as a hybrid system, and an optimization-based gear shift schedule design is introduced. This guarantees that the propulsion requirements are delivered while minimizing fuel consumption. The resulting dynamics is proven to be stable in the presence of constraints. We apply our framework to heavy-duty vehicle gear shift schedule design and evaluate the performance of the controller using numerical simulations.",
QoS in industrial wireless networks using LDM,"One of the main challenges in mechatronics is to manage large amount of information data. This information is used to control the process, manage critical errors or perform maintenance actions. The traditional communication buses are wired buses which have great reliability. But with the revolution of industry 4.0, industry and mechatronic systems increased sensor and data acquisition nodes, from few devices to several sensors and actuators interconnected between them. In this new scenario the traditional wired communications systems are more complex to deploy and to maintain, and the trend is to replace wired by wireless systems, ensuring that the reliability of the wireless systems is comparable to the wired one. A communication system based on LDM (Layered Division Multiplexing) is proposed in this article to guarantee the reliability level of a wireless system where two types of data need to be transmitted over the same physical layer, critical data and non critical data. In order to prove that the proposed system is more reliable than the traditional TDM/FDM systems and can enhance throughput, BER and throughput simulations are provided.","Receivers,
Time division multiplexing,
Reliability,
Wireless communication,
Monitoring,
Frequency division multiplexing,
Signal to noise ratio"
A two-stage algorithm for noisy and reverberant speech enhancement,"In daily listening environments, speech is commonly corrupted by room reverberation and background noise. These distortions are detrimental to speech intelligibility and quality, and also severely degrade the performance of automatic speech and speaker recognition systems. In this paper, we propose a two-stage algorithm to deal with the confounding effects of noise and reverberation separately, where denoising and dereverberation are conducted sequentially using deep neural networks. In addition, we design a new objective function that incorporates clean phase information during training. As the objective function emphasizes more important time-frequency (T-F) units, better estimated magnitude is obtained during testing. By jointly training the two-stage model to optimize the proposed objective function, our algorithm improves objective metrics of speech intelligibility and quality significantly, and substantially outperforms one-stage enhancement baselines.","Speech,
Noise measurement,
Training,
Noise reduction,
Speech enhancement,
Time-domain analysis,
Linear programming"
Multicast Routing and Wavelength Assignment in AWG-Based Clos Networks,"In wavelength-division-multiplexing (WDM) switches, such as arrayed-waveguide-grating (AWG)-based Clos networks, the supporting of multicast traffic must rise to the challenge of route and wavelength assignment (RWA) problem. In this paper, we study the non-blocking multicast RWA problem in two phases with respect to the cascaded combination of an AWG-based broadcast Clos network, called copy network, and a point-to-point AWG-based Clos network. In phase one, input requests generate broadcast trees in the copy network, and then point-to-point connections are established in the AWG-based Clos network in the second phase. The Clos-type AWG-based multicast networks can be constructed from modular AWGs of smaller sizes with the purpose of minimizing the number of wavelengths required and reducing the tuning range of the wavelength selective converters (WSCs). For solving the multicast RWA problem, we extend the rank-based routing algorithm for traditional space-division broadcast Clos networks such that broadcast trees can also be generated in the WDM copy network in a contention-free manner. However, due to wavelength routing properties of AWGs, the subset of requests input to each subnetwork in the middle stage may not satisfy the precondition of the rank-based RWA algorithm. Nevertheless, we prove that this problem can be solved by cyclically shifting the indices of wavelengths in each subnetwork, which provides the key to recursively route the multicast requests in a non-blocking and contention-free manner in the decomposed AWG-based broadcast Clos network. The time complexity of the proposed multicast RWA algorithm is comparable to that of an AWG-based unicast Clos network.","Optical switches,
Routing,
WDM networks,
Wavelength assignment,
Optical fibers"
SecRoute: End-to-end secure communications for wireless ad-hoc networks,"Railways constitute a main means of mass transportation, used by public, private, and military entities to traverse long distances every day. Railway control software must collect spatial information and effectively manage these systems. Wireless sensor networks (WSNs) are an attractive solution to cover the area along-side the railway routes. In-carriage WSNs are also studied in cases of dangerous cargo transportation. The secure communication of all these devices becomes important as successful attacks can harm the railway's business operation or cause serious injuries and deaths. This paper presents SecRoute - an end-to-end secure communications scheme for wireless ad hoc networks. The scheme implements mechanisms for cryptographic communication, trusted-based routing, and policy-based access control. SecRoute and alternative schemes are modelled on the NS-2 network simulator and a comparative analysis is conducted, indicating that the proposed scheme provides enhanced protection. A proof of concept of SecRoute is deployed on real embedded platforms and exhibits good overall performance, demonstrating that attacks on the route and carriage WSNs are effectively countered.","Routing,
Authentication,
Cryptography,
Wireless sensor networks,
Rail transportation,
Ad hoc networks,
Routing protocols"
Comprehensive Electric-Thermal Photovoltaic Modeling for Power-Hardware-in-the-Loop Simulation (PHILS) Applications,"This paper presents a dynamic, electric-thermal model for a photovoltaic (PV) cell that combines electrical and thermal parameters to accurately emulate PV panels in real time for power-hardware-in-the-loop simulation (PHILS). In this model, the irradiance and ambient temperature are used to calculate the PV cell temperature based on a five-layer thermal model. The cell temperature is then used in the electrical model to accurately adjust the PV electrical characteristics. A custom experimental setup is built to test and verify the electrical and thermal characteristics of the PV cell model. This electric-thermal model is validated using experimental data in realistic scenarios. The model is also tested with PHILS using a real-time simulator and a programmable dc power supply to emulate PV power generation under various load changes. The model is well matched to the experimental measurements with an error within 2.4% for the electrical aspects and within 1.5% for the thermal aspects in the tested scenarios.",
Graph Laplacian Regularization for Image Denoising: Analysis in the Continuous Domain,"Inverse imaging problems are inherently underdetermined, and hence, it is important to employ appropriate image priors for regularization. One recent popular prior-the graph Laplacian regularizer-assumes that the target pixel patch is smooth with respect to an appropriately chosen graph. However, the mechanisms and implications of imposing the graph Laplacian regularizer on the original inverse problem are not well understood. To address this problem, in this paper, we interpret neighborhood graphs of pixel patches as discrete counterparts of Riemannian manifolds and perform analysis in the continuous domain, providing insights into several fundamental aspects of graph Laplacian regularization for image denoising. Specifically, we first show the convergence of the graph Laplacian regularizer to a continuous-domain functional, integrating a norm measured in a locally adaptive metric space. Focusing on image denoising, we derive an optimal metric space assuming non-local self-similarity of pixel patches, leading to an optimal graph Laplacian regularizer for denoising in the discrete domain. We then interpret graph Laplacian regularization as an anisotropic diffusion scheme to explain its behavior during iterations, e.g., its tendency to promote piecewise smooth signals under certain settings. To verify our analysis, an iterative image denoising algorithm is developed. Experimental results show that our algorithm performs competitively with state-of-the-art denoising methods, such as BM3D for natural images, and outperforms them significantly for piecewise smooth images.","Laplace equations,
Noise reduction,
Image denoising,
Measurement,
Imaging,
Anisotropic magnetoresistance,
Manifolds"
Impact of Contact Resistance on the f_T and f_{\max} of Graphene Versus \text{MoS}_2 Transistors,"A key challenge in making 2-D materials viable for electronics is reducing the contact resistance ρC of the source and drain, which can otherwise severely curtail performance. We consider the impact of contact resistance on the performance of transistors made with single-layer graphene and MoS2, two of the most popular 2-D materials presently under consideration for radiofrequency (RF) applications. While our focus is on the impact of ρC, we include the impact of all the device parasitics. We consider a device structure based on the 7-nm node of the ITRS and use the unity-current-gain and unity-power-gain frequencies (fT and fmax) found from quantum-mechanical simulations, ballistic for graphene and with scattering for MoS2, as indicators of RF performance. We quantify our results in terms of the values of ρC needed to reach specific values of fT and fmax. In terms of peak performance (over all bias conditions), we show that graphene retains a significant edge over MoS2, despite graphene's poor output conductance, with MoS2 only being able to bridge the gap if considerably better contact resistances can be realized. However, with the bias current restricted to a technologically relevant value, we show that graphene loses much of its advantage, primarily due to a reduction in its transconductance gm, and we show that MoS2 can then meet or exceed the performance of graphene via the realization of contact resistances already achieved in multilayer structures. Our values of fT for short-channel devices (around the 7-nm ITRS node) are shown to be consistent with experimental data for present-day long-channel devices, supporting our approach and conclusions.","Graphene,
Molybdenum,
Sulfur,
Radio frequency,
Transistors,
Logic gates,
Contact resistance"
Semantic Slicing of Software Version Histories,"Software developers often need to transfer functionality, e.g., a set of commits implementing a new feature or a bug fix, from one branch of a configuration management system to another. That can be a challenging task as the existing configuration management tools lack support for matching high-level, semantic functionality with low-level version histories. The developer thus has to either manually identify the exact set of semantically-related commits implementing the functionality of interest or sequentially port a segment of the change history, “inheriting” additional, unwanted functionality. In this paper, we tackle this problem by providing automated support for identifying the set of semantically-related commits implementing a particular functionality, which is defined by a set of tests. We formally define the semantic slicing problem, provide an algorithm for identifying a set of commits that constitute a slice, and propose techniques to minimize the produced slice. We then instantiate the overall approach, CSLICER, in a specific implementation for Java projects managed in Git and evaluate its correctness and effectiveness on a set of open-source software repositories. We show that it allows to identify subsets of change histories that maintain the functionality of interest but are substantially smaller than the original ones.",
Accelerating the Mobile cloud: Using Amazon Mobile Analytics and k-means clustering,"Current trends show a move away from desktop computing and toward the rise in popularity of mobile devices. Yet mobile devices suffer from limitations in memory, storage, computational power, and battery life. Many of these limitations can be solved by offloading computations and storage to cloud-based platforms. E-commerce mobile applications designed to serve the global customer base of a retail outlet experience fluctuations in demand for resources based on the location of the users. Given a traditional client-server architecture, where the server application and database are deployed to a single geographic location, this can cause large disparities in response time perceived by users close to the server location and those at a much further distance. This could cause a loss of business or slow user growth in more distant regions. Using several Amazon Web Services(AWS), this paper tests a proxy system and k-means analysis based data partitioning solution to this issue. The discussion of k-means database partitioning describes a preprocessing methodology for adapting raw AWS Mobile Analytics log data for use in the k-means algorithm. The paper also compares a few alternatives for distance measurements and centroid computations for use in the k-means algorithm. Experimental results confirm that this approach significantly reduces response time. It also shows that the approach significantly increases server-side throughput.","Servers,
Mobile communication,
Databases,
Cloud computing,
Clustering algorithms,
Time factors,
Partitioning algorithms"
Malware traffic classification using convolutional neural network for representation learning,"Traffic classification is the first step for network anomaly detection or network based intrusion detection system and plays an important role in network security domain. In this paper we first presented a new taxonomy of traffic classification from an artificial intelligence perspective, and then proposed a malware traffic classification method using convolutional neural network by taking traffic data as images. This method needed no hand-designed features but directly took raw traffic as input data of classifier. To the best of our knowledge this interesting attempt is the first time of applying representation learning approach to malware traffic classification using raw traffic data. We determined that the best type of traffic representation is session with all layers through eight experiments. The method is validated in two scenarios including three types of classifiers and the experiment results show that our proposed method can satisfy the accuracy requirement of practical application.","Malware,
Feature extraction,
Artificial intelligence,
IP networks,
Image classification,
Ports (Computers),
Neural networks"
Cooperative Beamforming for Cognitive-Radio-Based Broadcasting Systems in Presence of Asynchronous Interference,"To address the asynchronous interference issue in a generalized scenario with multiple primary and multiple secondary receivers, in this paper, we propose an innovative cooperative beamforming technique. The cooperative beamforming design is formulated as an optimization problem that maximizes the weighted sum transmission rate of secondary destinations while maintaining the asynchronous interference at the primary receivers below their target thresholds. In particular, we obtain the optimum beamforming directions and allocate power values among such beamforming directions. In light of the intractability of the power allocation problem, an approximation is used to convert the nonconvex and nonlinear optimization problem into a convex and linear one. Due to the multiple interference constraints corresponding to multiple primary receivers, the power allocation scheme is still complex. Therefore, we also propose a low-complexity power allocation algorithm. The proposed beamforming technique is extended for the case when cooperating CR nodes (CCRNs) have statistical channel knowledge of the primary receivers by developing an upper bound on the probability of introducing asynchronous interference at a given primary receiver beyond a given threshold value. We also propose two CCRN selection strategies for cooperative beamforming.","Receivers,
Interference,
Resource management,
Optimization,
Complexity theory,
Transmitters,
Cognitive radio"
Trust-Based Task Assignment With Multiobjective Optimization in Service-Oriented Ad Hoc Networks,"We propose and analyze a trust management protocol in service-oriented mobile ad hoc networks (MANETs) populated with service providers and service requesters, and demonstrate the resiliency and convergence properties against bad-mouthing, ballot-stuffing, opportunistic service, and self-promotion attacks. To demonstrate the applicability, we consider a mission-driven service-oriented MANET that must handle dynamically arriving tasks to achieve multiple conflicting objectives. We devise a trust-based heuristic algorithm based on auctioning with local knowledge of node status to solve this node-to-task assignment problem with multiobjective optimization (MOO) requirements. Our trust-based heuristic algorithm has a polynomial runtime complexity, rather than an exponential runtime complexity as in existing work, thus allowing dynamic node-to-task assignment to be performed at runtime. It outperforms a nontrust-based counterpart using blacklisting techniques while performing close to the ideal solution quality with perfect knowledge of node status over a wide range of environmental conditions. We conduct extensive sensitivity analysis of the results with respect to key design parameters and alternative trust protocol designs. We also develop a table-lookup method to apply the best trust protocol parameter settings upon detection of dynamically changing environmental conditions to maximize MOO performance.","Ad hoc networks,
Mobile computing,
Protocols,
Runtime,
Resource management,
Delays,
Heuristic algorithms"
Low-Barrier Nanomagnets as p-Bits for Spin Logic,"It has recently been shown that a suitably interconnected network of tunable telegraphic noise generators or “p-bits” can be used to perform even precise arithmetic functions like a 32-bit adder. In this letter, we use simulations based on the stochastic Landau-Lifshitz-Gilbert (sLLG) equation to demonstrate that similar impressive functions can be performed using unstable nanomagnets with energy barriers as low as a fraction of a kT. This is surprising because the magnetization of low-barrier nanomagnets is not telegraphic with discrete values of ±1. Rather, it fluctuates randomly among all values between -1 and +1, and the output magnets are read with a thresholding device that translates all positive values to one and all negative values to zero. We present sLLG-based simulations demonstrating the operation of a 32-bit adder, with a network of several hundred nanomagnets, exhibiting a remarkably precise correlation: The input magnets {A} and {B} as well as the output magnets {S} all fluctuate randomly and yet the quantity A + B-S is sharply peaked around zero! If we fix {A} and {B}, the sum magnets {S} rapidly converge to a unique state with S = A + B so that the system acts as an adder. But unlike standard adders, the operation is invertible. If we fix {S} and {B}, the remaining magnets {A} converge to the difference A = S - B. These examples emphasize a new direction for the field of nanomagnetics away from stable high-barrier magnets toward stochastic low-barrier magnets that not only operate with lower currents, but are also more promising for continued downscaling.","Adders,
Magnetization,
Saturation magnetization,
Magnetomechanical effects,
Perpendicular magnetic anisotropy,
Logic gates"
Comprehensive Analysis of Magnet Defect Fault Monitoring Through Leakage Flux,"This paper presents a detailed magnet defect fault detection analysis through fluxgate sensors by monitoring the leakage flux around permanent magnet synchronous motors. The flux spectra of electric machines contain direct and most critical information to monitor and characterize magnet defect faults and their progressions. In the mainstream diagnosis techniques based on phase current and back-EMF analysis, the fault corresponding signature characteristics may vary and cause misleading results depending on motor topology, winding configuration, number and location of defective magnets, and controller parameters. In this paper, it is shown that leakage flux analysis provides some superior results for magnet defect diagnosis. For this purpose, the fault patterns in the leakage flux spectrum are exhaustively analyzed at different torque/speed profiles. Simulation and experimental results show that the deployment of a direction sensitive fluxgate sensor in magnet defect fault detection yields very promising results both in time and frequency domain analyses.","Magnetic flux,
Circuit faults,
Magnetic sensors,
Magnetic analysis,
Permanent magnet motors,
Saturation magnetization"
Dependable Structural Health Monitoring Using Wireless Sensor Networks,"As an alternative to current wired-based networks, wireless sensor networks (WSNs) are becoming an increasingly compelling platform for engineering structural health monitoring (SHM) due to relatively low-cost, easy installation, and so forth. However, there is still an unaddressed challenge: the application-specific dependability in terms of sensor fault detection and tolerance. The dependability is also affected by a reduction on the quality of monitoring when mitigating WSN constrains (e.g., limited energy, narrow bandwidth). We address these by designing a dependable distributed WSN framework for SHM (called DependSHM) and then examining its ability to cope with sensor faults and constraints. We find evidence that faulty sensors can corrupt results of a health event (e.g., damage) in a structural system without being detected. More specifically, we bring attention to an undiscovered yet interesting fact, i.e., the real measured signals introduced by one or more faulty sensors may cause an undamaged location to be identified as damaged (false positive) or a damaged location as undamaged (false negative) diagnosis. This can be caused by faults in sensor bonding, precision degradation, amplification gain, bias, drift, noise, and so forth. In DependSHM, we present a distributed automated algorithm to detect such types of faults, and we offer an online signal reconstruction algorithm to recover from the wrong diagnosis. Through comprehensive simulations and a WSN prototype system implementation, we evaluate the effectiveness of DependSHM.",
Optimal elephant flow detection,"Monitoring the traffic volumes of elephant flows, including the total byte count per flow, is a fundamental capability for online network measurements. We present an asymptotically optimal algorithm for solving this problem in terms of both space and time complexity. This improves on previous approaches, which can only count the number of packets in constant time. We evaluate our work on real packet traces, demonstrating an up to X2.5 speedup compared to the best alternative.","Radiation detectors,
Maintenance engineering,
Monitoring,
Data structures,
Software algorithms,
Runtime,
Real-time systems"
Dynamic Resource Allocation for Virtualized Wireless Networks in Massive-MIMO-Aided and Fronthaul-Limited C-RAN,"This paper considers the uplink dynamic resource allocation in a cloud radio access network (C-RAN) serving users belonging to different service providers (called slices) to form virtualized wireless networks (VWN). In particular, the C-RAN supports a pool of base-station (BS) baseband units (BBUs), which are connected to BS radio remote heads (RRHs) equipped with massive massive multiple input multiple output (MIMO), via fronthaul links with limited capacity. Assuming that each user can be assigned to a single RRH-BBU pair, we formulate a resource allocation problem aiming to maximize the total system rate, constrained on the minimum rates required by the slices and the maximum number of antennas and power allocated to each user. The effects of pilot contamination error on the VWN performance are investigated and pilot duration is considered as a new optimization variable in resource allocation. This problem is inherently nonconvex, NP-hard and, thus, computationally inefficient. By applying the successive convex approximation and complementary geometric programming approach, we propose a two-step iterative algorithm: one to adjust the RRH, BBU, and fronthaul parameters, and the other for power and antenna allocation to users. Simulation results illustrate the performance of the developed algorithm for VWNs in a massive-MIMO-aided and fronthaul-limited C-RAN, and demonstrate the effects of imperfect channel state information estimation due to pilot contamination error, and the optimal pilot duration.",
dipIQ: Blind Image Quality Assessment by Learning-to-Rank Discriminable Image Pairs,"Objective assessment of image quality is fundamentally important in many image processing tasks. In this paper, we focus on learning blind image quality assessment (BIQA) models, which predict the quality of a digital image with no access to its original pristine-quality counterpart as reference. One of the biggest challenges in learning BIQA models is the conflict between the gigantic image space (which is in the dimension of the number of image pixels) and the extremely limited reliable ground truth data for training. Such data are typically collected via subjective testing, which is cumbersome, slow, and expensive. Here, we first show that a vast amount of reliable training data in the form of quality-discriminable image pairs (DIPs) can be obtained automatically at low cost by exploiting large-scale databases with diverse image content. We then learn an opinion-unaware BIQA (OU-BIQA, meaning that no subjective opinions are used for training) model using RankNet, a pairwise learning-to-rank (L2R) algorithm, from millions of DIPs, each associated with a perceptual uncertainty level, leading to a DIP inferred quality (dipIQ) index. Extensive experiments on four benchmark IQA databases demonstrate that dipIQ outperforms the state-of-the-art OU-BIQA models. The robustness of dipIQ is also significantly improved as confirmed by the group MAximum Differentiation competition method. Furthermore, we extend the proposed framework by learning models with ListNet (a listwise L2R algorithm) on quality-discriminable image lists (DIL). The resulting DIL inferred quality index achieves an additional performance gain.","Electronics packaging,
Training,
Image quality,
Predictive models,
Feature extraction,
Indexes"
Large-Scale VM Placement with Disk Anti-Colocation Constraints Using Hierarchical Decomposition and Mixed Integer Programming,"As computational clouds offer increasingly sophisticated services, there is a dramatic increase in the variety and complexity of virtual machine (VM) placement problems. In this paper, we consider a VM placement problem with a special type of anti-colocation requirements-disk anti-colocation-which stipulate that, for every VM assigned to a PM (physical machine), its virtual disks should be spread out across the physical disks of the PM. Once such a requirement is met, the users of the VM can expect improved disk I/O performance. There will also be improvement in fault tolerance and availability. For scalable solutions, we propose a method that combines hierarchical decomposition with mixed integer programming (MIP), where the basic building blocks are independent, small MIP subproblems. We provide experimental results to demonstrate the effectiveness of the proposed method. We show that it is scalable and achieves high performance with respect to the optimization objective.","Heuristic algorithms,
Resource management,
Cloud computing,
Servers,
Clustering algorithms,
Algorithm design and analysis,
Linear programming"
Facilitating the Delegation of Use for Private Devices in the Era of the Internet of Wearable Things,"The Internet undergoes a fundamental transformation as billions of connected “things” surround us and embed themselves into the fabric of our everyday lives. However, this is only the beginning of true convergence between the realm of humans and that of machines, which materializes with the advent of connected machines worn by humans, or wearables. The resulting shift from the Internet of Things to the Internet of Wearable Things (IoWT) brings along a truly personalized user experience by capitalizing on the rich contextual information, which wearables produce more than any other today's technology. The abundance of personally identifiable information handled by wearables creates an unprecedented risk of its unauthorized exposure by the IoWT devices, which fuels novel privacy challenges. In this paper, after reviewing the relevant contemporary background, we propose efficient means for the delegation of use applicable to a wide variety of constrained wearable devices, so that to guarantee privacy and integrity of their data. Our efficient solutions facilitate contexts when one would like to offer their personal device for temporary use (delegate it) to another person in a secure and reliable manner. In connection to the proposed protocol suite for the delegation of use, we also review the possible attack surfaces related to advanced wearables.","Internet of things,
Protocols,
Data privacy,
Biomedical monitoring,
Privacy,
Authentication"
Learning Sparse Representation for Objective Image Retargeting Quality Assessment,"The goal of image retargeting is to adapt source images to target displays with different sizes and aspect ratios. Different retargeting operators create different retargeted images, and a key problem is to evaluate the performance of each retargeting operator. Subjective evaluation is most reliable, but it is cumbersome and labor-consuming, and more importantly, it is hard to be embedded into online optimization systems. This paper focuses on exploring the effectiveness of sparse representation for objective image retargeting quality assessment. The principle idea is to extract distortion sensitive features from one image (e.g., retargeted image) and further investigate how many of these features are preserved or changed in another one (e.g., source image) to measure the perceptual similarity between them. To create a compact and robust feature representation, we learn two overcomplete dictionaries to represent the distortion sensitive features of an image. Features including local geometric structure and global context information are both addressed in the proposed framework. The intrinsic discriminative power of sparse representation is then exploited to measure the similarity between the source and retargeted images. Finally, individual quality scores are fused into an overall quality by a typical regression method. Experimental results on several databases have demonstrated the superiority of the proposed method.","Distortion,
Feature extraction,
Visualization,
Distortion measurement,
Dictionaries,
Quality assessment"
A Toeplitz Covariance Matrix Reconstruction Approach for Direction-of-Arrival Estimation,"It is known that there exist two kinds of methods for direction-of-arrival (DOA) estimation in the literature: the subspace-based method and the sparsity-based method. However, pervious works reveal that the former method cannot address the case in which the number of signals is larger than that of sensors, whereas the latter one always suffers from the influence of basis mismatch. In this paper, to overcome these two shortcomings, we propose a new method called covariance matrix reconstruction approach (CMRA) for both uniform linear array and sparse linear array. In particular, by exploiting the Toeplitz structure of the covariance matrix of the array output, we formulate a low-rank matrix reconstruction (LRMR) problem for covariance matrix recovery. The nonconvex LRMR problem is then relaxed by replacing the rank norm with the nuclear norm and solved using the optimization toolbox. Next, we retrieve the DOAs from the recovered covariance matrix by using the subspace-based methods and obtain an estimated number of signals as a byproduct. We also provide two algorithm implementations for the LRMR problem based on duality and alternating direction method of multipliers, respectively. It is shown that CMRA can be regarded as an atomic norm minimization model or a gridless version of the sparsity-based methods and can recover more signals than sensors with a well-designed array. Numerical experiments are provided to validate the effectiveness of the proposed method, in comparison with some of the existing methods.","Covariance matrices,
Estimation,
Direction-of-arrival estimation,
Optimization,
Sensors,
Adaptation models,
Signal to noise ratio"
Behavior-Based SSVEP Hierarchical Architecture for Telepresence Control of Humanoid Robot to Achieve Full-Body Movement,"The challenge to telepresence control a humanoid robot through a steady-state visual evoked potential (SSVEP) based model is to rapidly and accurately control full-body movement of the robot because a subject has to synchronously recognize the complex natural environments based on live video feedback and activate the proper mental states by targeting the visual stimuli. To mitigate this problem, this paper presents a behavior-based hierarchical architecture, which coordinates a large number of robot behaviors using only the most effective five stimuli. We defined and implemented fourteen robot behaviors for motion control and object manipulation, which were encoded through the visual stimuli of SSVEPs, and classified them into four behavioral sets. We proposed switch mechanisms in the hierarchical architecture to coordinate these behaviors and control the full-body movement of a NAO humanoid robot. To improve operation performance, we investigated the individual sensitivities of visual stimuli and allocated the stimuli targets according to frequency-responsive properties of individual subjects. We compared different types of walking strategies. The experimental results showed that the behavior-based SSVEP hierarchical architecture enabled the humanoid robot to complete an operation task, including navigating to an object and picking the object up with a fast operation time and a low chance of collision in an environment cluttered with obstacles.","Humanoid robots,
Robot kinematics,
Legged locomotion,
Visualization,
Navigation,
Automation"
An Improved Bound on the Fraction of Correctable Deletions,"We consider codes over fixed alphabets against worst case symbol deletions. For any fixed k ≥ 2, we construct a family of codes over alphabet of size k with positive rate, which allow efficient recovery from a worst case deletion fraction approaching 1 - (2/(k + √k)). In particular, for binary codes, we are able to recover a fraction of deletions approaching 1/(√2+1) = √2-1 ≈ 0.414. Previously, even non-constructively, the largest deletion fraction known to be correctable with √ positive rate was 1 - θ(1/ k), and around 0.17 for the binary case. Our result pins down the largest fraction of correctable deletions for k-ary codes as 1 - Θ(1/k), since 1 - 1/k is an upper bound even for the simpler model of erasures where the locations of the missing symbols are known. Closing the gap between (√2 - 1) and 1/2 for the limit of worst case deletions correctable by binary codes remains a tantalizing open question.","Binary codes,
Decoding,
Upper bound,
Concatenated codes,
Lenses,
Electronic mail,
Pins"
Data-driven technique to estimate the required broadband speed for K-12 schools,"Technology becomes more and more involved in the learning process (specifically blending learning) of K-12 schools. The broadband requirements must be assessed for cost-effective and efficient (a reasonable download wait time) access to the Internet. With the arrival of videoconferencing, collaborative tools besides, social media, the amount of data incoming and outgoing based on students' activities need to be increased to guarantee a smooth access and effective usage of technology in K-12 school environments. In this paper, we present a novel study that analyzes broadband requirements for students and staff (teachers and administrators) in K-12 schools. Our study takes into consideration different types of applications that students and staff use, number of users and their usage behaviors. It presents to decision makers, recommended broadband per devices for a specific application and expected time to wait for downloading these applications.","Broadband communication,
Education,
Cloud computing,
Streaming media,
Google"
Coordinate Channel-Aware Page Mapping Policy and Memory Scheduling for Reducing Memory Interference Among Multimedia Applications,"In a modern multicore system, memory is shared among more and more concurrently running multimedia applications. Therefore, memory contention and interference are more and more serious, inducing system performance degradation significantly, the performance degradation of each thread differently, unfairness in resource sharing, and priority inversion, even starvation. In this paper, we propose an approach of coordinating channel-aware page mapping policy and memory scheduling (CCPS) to reduce intermultimedia application interference in a memory system. The idea is to map the data of different threads to different channels, together with memory scheduling. The key principles of the policies of page mapping and memory scheduling are: 1) the memory address space, the thread priority, and the load balance; and 2) prioritizing a low-memory request thread, a row-buffer hit access, and an older request. We evaluate the CCPS on a variety of mixed single-thread and multithread benchmarks and system configurations, and we compare them with four previously proposed state-of-the-art interference-reducing policies. Experimental results demonstrate that the CCPS improves the performance while reducing the energy consumption significantly; moreover, the CCPS incurs a much lower hardware overhead than the current existing policies.","Instruction sets,
Interference,
Message systems,
Memory management,
Multimedia communication,
Degradation,
Multicore processing"
A Markov Chain Monte Carlo Alternating Minimization Algorithm for Asynchronous Relay Network Localization,This letter proposes an algorithm to locate an object by an asynchronous relay network using time of arrival (TOA) measurements. It applies the alternating minimization approach that iterates between measurement association and TOA localization. It solves the highly complex association problem between measurements and relays efficiently using the Markov Chain Monte Carlo method. Simulations show that the proposed method has high accuracy for measurement association and yields a localization accuracy near the Cramer Rao lower bound before the measurement noise becomes large.,"Relays,
Noise measurement,
Minimization,
Markov processes,
Clocks,
Position measurement,
Force"
A Low Bandwidth DFB Laser-Based Interrogator for Terahertz-Range Fiber Bragg Grating Sensors,"This letter reports an all-electronic, low bandwidth swept frequency laser used to interrogate terahertz-range fiber Bragg gratings (THz FBGs) for distributed strain sensing applications. A distributed feedback laser with current injection modulation was employed as the swept frequency laser source. Using the resulting narrow bandwidth (~110 GHz) laser frequency sweep, high accuracy distributed strain measurements were achieved. In order to experimentally investigate this concept, a strain test was conducted using the THz FBGs. During the test, the laser sweeping time was limited to less than 2 ms. Highly linear results were found (R2 = 0.996), with an observed sensitivity of -0.142 GHz/με and the standard deviation of 1.167 με. A multiplexing test was also conducted, and no cross-talk found between sensor elements. These results demonstrate that this interrogation system holds substantial potential as a method of rapid distributed optical fiber frequency-domain sensing.","Sensors,
Strain,
Bragg gratings,
Fiber lasers,
Laser feedback,
Distributed feedback devices,
Semiconductor lasers"
Detection of sleep apnea from multiparameter monitor signals using empirical mode decomposition,"For diagnosing obstructive sleep apnea (OSA), polysomnography (PSG) is used. Use of PSG is gold standard for detection of sleep apnea. This research is basically aimed at detection of sleep apnea from more commonly available physiological signals such as electrocardiogram (ECG) and photoplethysmographic (PPG) signals in any simple bedside multiparameter monitors. Respiratory activity extracted from ECG and PPG signals is used for the detection of apnea episodes. This process is useful in situations when recording of PSG is not possible or as a preliminary screening test of possible OSA in patients. In the present work ECG-derived respiration (EDR) and PPG derived respiration (PDR) signals, obtained using empirical mode decomposition (EMD) method, and are used to detect OSA episodes. Signals from MIMIC database were used for experimentation. The test results have revealed that the proposed method has efficiently extracted respiratory information from ECG and PPG signals for detection of obstructive sleep apnea syndrome (OSAS). The similarity parameters computed in both time and frequency domains have confirmed the same. High sensitivity and positive predictivity levels have revealed high degree of correctness.","Electrocardiography,
Sleep apnea,
Databases,
MIMICs,
Heart rate variability,
Conferences,
Computers"
A New Representation of fMRI Signal by a Set of Local Meshes for Brain Decoding,"How neurons influence each other's firing depends on the strength of synaptic connections among them. Motivated by the highly interconnected structure of the brain, in this study, we propose a computational model to estimate the relationships among voxels and employ them as features for cognitive state classification. We represent the sequence of functional Magnetic Resonance Imaging (fMRI) measurements recorded during a cognitive stimulus by a set of local meshes. Then, we represent the corresponding cognitive state by the edge weights of these meshes each of which is estimated assuming a regularized linear relationship among voxel time series in a predefined locality. The estimated mesh edge weights provide a better representation of information in the brain for cognitive state or task classification. We examine the representative power of our mesh edge weights on visual recognition and emotional memory retrieval experiments by training a support vector machine classifier. Also, we use mesh edge weights as feature vectors of inter-subject classification on Human Connectome Project task fMRI dataset, and test their performance. We observe that mesh edge weights perform better than the popular fMRI features, such as, raw voxel intensity values, pairwise correlations, features extracted using PCA and ICA, for classifying the cognitive states.",
Experimental study of a miniaturized calcium atomic beam tube for small optical frequency standard,"With the advantage of relatively simple structure, the optical frequency standard based on calcium thermal atomic beam has the potential to be miniaturized and engineered. We develop a new fully vacuum-sealed calcium atomic beam tube, which divergence angle of calcium atomic beam is narrower and background noise of 423 nm laser-induced fluorescence is much lower than its predecessor. This paper describes experimental study of this new tube using the 657 nm clock transition laser and 423 nm detection laser.","Calcium,
Atomic beams,
Electron tubes,
Atom optics,
Fluorescence,
Clocks,
Optical beams"
Multi-Dimensional QoS Prediction for Service Recommendations,"Advances in mobile Internet technology have enabled the clients of Web services to be able to keep their service sessions alive while they are on the move. Since the services consumed by a mobile client may be different over time due to client location changes, a multi-dimensional spatiotemporal model is necessary for analyzing the service consumption relations. Moreover, competitive Web service recommenders for the mobile clients must be able to predict unknown quality-of-service (QoS) values well by taking into account the target client’s service requesting time and location, e.g., performing the prediction via a set of multi-dimensional QoS measures. Most contemporary QoS prediction methods exploit the QoS characteristics for one specific dimension, e.g., time or location, and do not exploit the structural relationships among the multi-dimensional QoS data. This paper proposes an integrated QoS prediction approach which unifies the modeling of multi-dimensional QoS data via multi-linear-algebra based concepts of tensor and enables efficient Web service recommendation for mobile clients via tensor decomposition and reconstruction optimization algorithms. In light of the unavailability of measured multi-dimensional QoS datasets in the public domain, this paper also presents a transformational approach to creating a credible multi-dimensional QoS dataset from a measured taxi usage dataset which contains high dimensional time and space information. Comparative experimental evaluation results show that the proposed QoS prediction approach can result in much better accuracy in recommending Web services than several other representative ones.","Quality of service,
Tensile stress,
Web services,
Data models,
Optimization,
Prediction algorithms,
Mobile communication"
Fundamental limits of location privacy using anonymization,"In [1]-[3], the concept of perfect location privacy is defined and sufficient conditions for achieving it were obtained when anonymization is used. In this paper, necessary conditions for perfect privacy are obtained. Specifically, we prove that the previous sufficient bounds are tight, and thus we obtain the threshold for achieving perfect location privacy using anonymization. First, we assume that a user's current location is independent from her past locations. Using this i.i.d model, we show that if the adversary collects more than equation anonymous observations, then the adversary can successfully recover the users' locations with high probability. Here, n is the number of users in the network and r is the number of all possible locations that users can go to. Next, we model users' movements using Markov chains to better model real-world movement patterns. We show similar results if the adversary collects more than equation observations, where |E| is the number of edges in the user's Markov chain model.","Privacy,
Markov processes,
Computers,
Data privacy,
Measurement,
Mobile communication,
Error probability"
Ship Detection From Optical Satellite Images Based on Saliency Segmentation and Structure-LBP Feature,"Automatic ship detection from optical satellite imagery is a challenging task due to cluttered scenes and variability in ship sizes. This letter proposes a detection algorithm based on saliency segmentation and the local binary pattern (LBP) descriptor combined with ship structure. First, we present a novel saliency segmentation framework with flexible integration of multiple visual cues to extract candidate regions from different sea surfaces. Then, simple shape analysis is adopted to eliminate obviously false targets. Finally, a structure-LBP feature that characterizes the inherent topology structure of ships is applied to discriminate true ship targets. Experimental results on numerous panchromatic satellite images validate that our proposed scheme outperforms other state-of-the-art methods in terms of both detection time and detection accuracy.","Marine vehicles,
Feature extraction,
Satellites,
Optical imaging,
Optical sensors,
Image segmentation,
Shape"
Unimodal Stopping Model-Based Early SKIP Mode Decision for High-Efficiency Video Coding,"High-efficiency video coding (HEVC) can greatly improve coding efficiency compared with the prior video coding standard H.264/AVC by adopting advanced hierarchical coding structures such as coding unit (CU), prediction unit (PU), and transform unit. For each CU, an exhaustive mode decision strategy is adopted to achieve the best rate distortion (RD) cost, which simultaneously results in enormous computational complexity. In this paper, an early SKIP mode decision algorithm is proposed for the HEVC encoder to speed up the process of mode decision. Each CU size is categorized into either rare used or frequent used by exploiting the correlation of CU depth, which is estimated from the temporally colocated CUs. For the rare-used CU size, the SKIP mode is directly selected as the optimal mode and the remaining mode decision process is early terminated. For the frequent-used CU size, a unimodal stopping model is designed for its early SKIP mode decision by exploiting both hierarchical mode structure and RD cost property. Experimental results show that the proposed early SKIP mode decision method achieves average 58.5% and 54.8% encoding time savings, while the Bjontegaard Delta bit rate only increases average 0.8% and 0.8% for various test sequences under the random access and the low delay B conditions, respectively.","Encoding,
Correlation,
Copper,
Video sequences,
High efficiency video coding,
Computational complexity"
Multiview Feature Analysis via Structured Sparsity and Shared Subspace Discovery,"Since combining features from heterogeneous data sources can significantly boost classification performance in many applications, it has attracted much research attention over the past few years. Most of the existing multiview feature analysis approaches separately learn features in each view, ignoring knowledge shared by multiple views. Different views of features may have some intrinsic correlations that might be beneficial to feature learning. Therefore, it is assumed that multiviews share subspaces from which common knowledge can be discovered. In this letter, we propose a new multiview feature learning algorithm, aiming to exploit common features shared by different views. To achieve this goal, we propose a feature learning algorithm in a batch mode, by which the correlations among different views are taken into account. Multiple transformation matrices for different views are simultaneously learned in a joint framework. In this way, our algorithm can exploit potential correlations among views as supplementary information that further improves the performance result. Since the proposed objective function is nonsmooth and difficult to solve directly, we propose an iterative algorithm for effective optimization. Extensive experiments have been conducted on a number of real-world data sets. Experimental results demonstrate superior performance in terms of classification against all the compared approaches. Also, the convergence guarantee has been validated in the experiment.",
Feature Constrained Multi-Task Learning Models for Spatiotemporal Event Forecasting,"Spatial event forecasting from social media is potentially extremely useful but suffers from critical challenges, such as the dynamic patterns of features (keywords) and geographic heterogeneity (e.g., spatial correlations, imbalanced samples, and different populations in different locations). Most existing approaches (e.g., LASSO regression, dynamic query expansion, and burst detection) address some, but not all, of these challenges. Here, we propose a novel multi-task learning framework that aims to concurrently address all the challenges involved. Specifically, given a collection of locations (e.g., cities), forecasting models are built for all the locations simultaneously by extracting and utilizing appropriate shared information that effectively increases the sample size for each location, thus improving the forecasting performance. The new model combines both static features derived from a predefined vocabulary by domain experts and dynamic features generated from dynamic query expansion in a multi-task feature learning framework. Different strategies to balance homogeneity and diversity between static and dynamic terms are also investigated. And, efficient algorithms based on Iterative Group Hard Thresholding are developed to achieve efficient and effective model training and prediction. Extensive experimental evaluations on Twitter data from civil unrest and influenza outbreak datasets demonstrate the effectiveness and efficiency of our proposed approach.","Forecasting,
Predictive models,
Urban areas,
Twitter,
Data models,
Spatiotemporal phenomena"
Timed Automata Modeling and Verification for Publish-Subscribe Structures Using Distributed Resources,"In this paper we present a Timed Automata model for the Publish/Subscribe paradigm in the context of Web Service Compositions with distributed resources, on the basis of an algebraic language inspired by the WSRF standard constructions. This framework allows a set of participants in a Web Service composition to interact with one another and also to manage a collection of distributed resources. The model includes operations for clients to publish, discover and subscribe to resources, so as to be notified when the resource property values fulfill certain conditions (topic-based subscription). Simulation and model-checking techniques can therefore be applied to the obtained network of timed automata, in order to check whether certain properties of interest are satisfied. A specific case study is finally presented to illustrate the model and the verification of the relevant properties on the obtained timed automata model.",
